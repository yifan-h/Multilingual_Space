Some weights of the model checkpoint at /cluster/work/sachan/yifan/huggingface_models/xlm-roberta-base/ were not used when initializing XLMRobertaModel: ['lm_head.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight']
- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of the model checkpoint at /cluster/work/sachan/yifan/huggingface_models/xlm-roberta-base/ were not used when initializing XLMRobertaModel: ['lm_head.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight']
- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of the model checkpoint at /cluster/work/sachan/yifan/huggingface_models/xlm-roberta-base/ were not used when initializing XLMRobertaModel: ['lm_head.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight']
- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of the model checkpoint at /cluster/work/sachan/yifan/huggingface_models/xlm-roberta-base/ were not used when initializing XLMRobertaModel: ['lm_head.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight']
- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of the model checkpoint at /cluster/work/sachan/yifan/huggingface_models/xlm-roberta-base/ were not used when initializing XLMRobertaModel: ['lm_head.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight']
- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of the model checkpoint at /cluster/work/sachan/yifan/huggingface_models/xlm-roberta-base/ were not used when initializing XLMRobertaModel: ['lm_head.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight']
- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Namespace(adam_epsilon=1e-08, batch_num=16, data_dir='/cluster/work/sachan/yifan/data/wikidata/downstream', device=6, epoch=50, lm_lr=1e-06, lr=1e-06, model_dir='/cluster/work/sachan/yifan/huggingface_models/xlm-roberta-base/', model_name='XLM', modelkg_dir='/cluster/project/sachan/yifan/projects/Multilingual_Space/tmp/xlm_80/final_v3.pt', neg_num=1, patience=2, tmp_dir='./tmp/checkpoints', weight_decay=0.005)
KGC: [ el ] | training loss:  2.8147 | val loss:  2.7373 | hit@1:  0.001 hit@10:  0.0157
KGC: [ el ] | training loss:  2.8194 | val loss:  2.8308 | hit@1:  0.001 hit@10:  0.0246
KGC: [ el ] | training loss:  2.8329 | val loss:  2.8304 | hit@1:  0.001 hit@10:  0.0354
KGC: [ el ] | training loss:  2.8322 | val loss:  2.8308 | hit@1:  0.002 hit@10:  0.0147
KGC: [ el ] | training loss:  2.833 | val loss:  2.8308 | hit@1:  0.002 hit@10:  0.0157
KGC: [ el ] | training loss:  2.833 | val loss:  2.8308 | hit@1:  0.002 hit@10:  0.0256
KGC: [ el ] | training loss:  2.833 | val loss:  2.8308 | hit@1:  0.002 hit@10:  0.0256
KGC: [ el ] | training loss:  2.833 | val loss:  2.8308 | hit@1:  0.002 hit@10:  0.0246
KGC: [ el ] | training loss:  2.833 | val loss:  2.8308 | hit@1:  0.002 hit@10:  0.0226
KGC: [ el ] | training loss:  2.833 | val loss:  2.8308 | hit@1:  0.002 hit@10:  0.0226
KGC: [ el ] | training loss:  2.833 | val loss:  2.8308 | hit@1:  0.001 hit@10:  0.0226
KGC: [ el ] | training loss:  2.833 | val loss:  2.8308 | hit@1:  0.001 hit@10:  0.0197
KGC: [ el ] | training loss:  2.833 | val loss:  2.8308 | hit@1:  0.001 hit@10:  0.0216
KGC: [ el ] | training loss:  2.833 | val loss:  2.8308 | hit@1:  0.001 hit@10:  0.0226
KGC: [ el ] | training loss:  2.833 | val loss:  2.8308 | hit@1:  0.0049 hit@10:  0.0216
KGC: [ el ] | training loss:  2.833 | val loss:  2.8308 | hit@1:  0.002 hit@10:  0.0216
KGC: [ el ] | training loss:  2.833 | val loss:  2.8308 | hit@1:  0.001 hit@10:  0.0187
KGC: [ el ] | training loss:  2.833 | val loss:  2.8308 | hit@1:  0.001 hit@10:  0.0521
KGC: [ el ] | training loss:  2.833 | val loss:  2.8308 | hit@1:  0.001 hit@10:  0.0108
KGC: [ el ] | training loss:  2.833 | val loss:  2.8308 | hit@1:  0.001 hit@10:  0.0108
KGC: [ el ] | training loss:  2.833 | val loss:  2.8308 | hit@1:  0.001 hit@10:  0.0118
KGC: [ el ] | training loss:  2.833 | val loss:  2.8308 | hit@1:  0.001 hit@10:  0.0138
KGC: [ el ] | training loss:  2.833 | val loss:  2.8308 | hit@1:  0.001 hit@10:  0.0108
KGC: [ el ] | training loss:  2.833 | val loss:  2.8308 | hit@1:  0.001 hit@10:  0.0098
KGC: [ el ] | training loss:  2.833 | val loss:  2.8308 | hit@1:  0.001 hit@10:  0.0098
KGC: [ el ] | training loss:  2.833 | val loss:  2.8308 | hit@1:  0.001 hit@10:  0.0108
KGC: [ el ] | training loss:  2.8328 | val loss:  2.8308 | hit@1:  0.0029 hit@10:  0.0285
KGC: [ el ] | training loss:  2.833 | val loss:  2.8308 | hit@1:  0.001 hit@10:  0.0138
KGC: [ el ] | training loss:  2.833 | val loss:  2.8308 | hit@1:  0.001 hit@10:  0.0157
KGC: [ el ] | training loss:  2.833 | val loss:  2.8308 | hit@1:  0.002 hit@10:  0.0187
KGC: [ el ] | training loss:  2.833 | val loss:  2.8308 | hit@1:  0.001 hit@10:  0.0147
KGC: [ el ] | training loss:  2.833 | val loss:  2.8308 | hit@1:  0.001 hit@10:  0.0157
KGC: [ el ] | training loss:  2.833 | val loss:  2.8308 | hit@1:  0.002 hit@10:  0.0157
KGC: [ el ] | training loss:  2.833 | val loss:  2.8308 | hit@1:  0.0029 hit@10:  0.0206
KGC: [ el ] | training loss:  2.833 | val loss:  2.8308 | hit@1:  0.0029 hit@10:  0.0197
KGC: [ el ] | training loss:  2.833 | val loss:  2.8308 | hit@1:  0.0039 hit@10:  0.0167
KGC: [ el ] | training loss:  2.833 | val loss:  2.8308 | hit@1:  0.002 hit@10:  0.0265
KGC: [ el ] | training loss:  2.833 | val loss:  2.8308 | hit@1:  0.001 hit@10:  0.0138
KGC: [ el ] | training loss:  2.833 | val loss:  2.8308 | hit@1:  0.001 hit@10:  0.056
KGC: [ el ] | training loss:  2.833 | val loss:  2.8308 | hit@1:  0.001 hit@10:  0.0216
KGC: [ el ] | training loss:  2.833 | val loss:  2.8308 | hit@1:  0.001 hit@10:  0.0147
KGC: [ el ] | training loss:  2.833 | val loss:  2.8308 | hit@1:  0.001 hit@10:  0.0128
KGC: [ el ] | training loss:  2.833 | val loss:  2.8308 | hit@1:  0.001 hit@10:  0.0167
KGC: [ el ] | training loss:  2.833 | val loss:  2.8308 | hit@1:  0.001 hit@10:  0.0128
KGC: [ el ] | training loss:  2.833 | val loss:  2.8308 | hit@1:  0.001 hit@10:  0.0118
KGC: [ el ] | training loss:  2.833 | val loss:  2.8308 | hit@1:  0.0 hit@10:  0.0098
KGC: [ el ] | training loss:  2.833 | val loss:  2.8308 | hit@1:  0.001 hit@10:  0.0206
KGC: [ el ] | training loss:  2.833 | val loss:  2.8308 | hit@1:  0.001 hit@10:  0.0128
KGC: [ el ] | training loss:  2.833 | val loss:  2.8308 | hit@1:  0.001 hit@10:  0.0197
KGC: [ el ] | training loss:  2.833 | val loss:  2.8308 | hit@1:  0.001 hit@10:  0.0108
The performance (hit@1, hit@10) of language [ el ] is:  [2.7373, 0.001, 0.0157]
KGC: [ en ] | training loss:  2.8255 | val loss:  2.8326 | hit@1:  0.0001 hit@10:  0.0039
KGC: [ en ] | training loss:  2.8332 | val loss:  2.8323 | hit@1:  0.0001 hit@10:  0.0031
KGC: [ en ] | training loss:  2.8331 | val loss:  2.8323 | hit@1:  0.0012 hit@10:  0.007
KGC: [ en ] | training loss:  2.8331 | val loss:  2.8323 | hit@1:  0.0001 hit@10:  0.0019
KGC: [ en ] | training loss:  2.8331 | val loss:  2.8323 | hit@1:  0.0001 hit@10:  0.0044
KGC: [ en ] | training loss:  2.8331 | val loss:  2.8323 | hit@1:  0.0001 hit@10:  0.0021
KGC: [ en ] | training loss:  2.8331 | val loss:  2.8323 | hit@1:  0.0001 hit@10:  0.0035
KGC: [ en ] | training loss:  2.8331 | val loss:  2.8323 | hit@1:  0.0004 hit@10:  0.0023
KGC: [ en ] | training loss:  2.8331 | val loss:  2.8323 | hit@1:  0.0004 hit@10:  0.0029
KGC: [ en ] | training loss:  2.8331 | val loss:  2.8323 | hit@1:  0.0 hit@10:  0.0028
KGC: [ en ] | training loss:  2.8331 | val loss:  2.8323 | hit@1:  0.0005 hit@10:  0.0033
KGC: [ en ] | training loss:  2.8331 | val loss:  2.8323 | hit@1:  0.0005 hit@10:  0.0044
KGC: [ en ] | training loss:  2.8331 | val loss:  2.8323 | hit@1:  0.0003 hit@10:  0.0039
KGC: [ en ] | training loss:  2.8331 | val loss:  2.8323 | hit@1:  0.0 hit@10:  0.0023
KGC: [ en ] | training loss:  2.8331 | val loss:  2.8323 | hit@1:  0.0004 hit@10:  0.0038
KGC: [ en ] | training loss:  2.8331 | val loss:  2.8323 | hit@1:  0.0003 hit@10:  0.0028
KGC: [ en ] | training loss:  2.8331 | val loss:  2.8323 | hit@1:  0.0003 hit@10:  0.0043
KGC: [ en ] | training loss:  2.8331 | val loss:  2.8323 | hit@1:  0.0003 hit@10:  0.0038
KGC: [ en ] | training loss:  2.8331 | val loss:  2.8323 | hit@1:  0.0001 hit@10:  0.0036
KGC: [ en ] | training loss:  2.8331 | val loss:  2.8323 | hit@1:  0.0003 hit@10:  0.0031
KGC: [ en ] | training loss:  2.8331 | val loss:  2.8323 | hit@1:  0.0003 hit@10:  0.0027
KGC: [ en ] | training loss:  2.8331 | val loss:  2.8323 | hit@1:  0.0003 hit@10:  0.0028
KGC: [ en ] | training loss:  2.8331 | val loss:  2.8323 | hit@1:  0.0 hit@10:  0.0023
KGC: [ en ] | training loss:  2.8331 | val loss:  2.8323 | hit@1:  0.0001 hit@10:  0.0031
KGC: [ en ] | training loss:  2.8331 | val loss:  2.8323 | hit@1:  0.0005 hit@10:  0.0024
KGC: [ en ] | training loss:  2.8331 | val loss:  2.8323 | hit@1:  0.0003 hit@10:  0.0027
KGC: [ en ] | training loss:  2.8331 | val loss:  2.8323 | hit@1:  0.0001 hit@10:  0.0033
KGC: [ en ] | training loss:  2.8331 | val loss:  2.8323 | hit@1:  0.0001 hit@10:  0.0019
KGC: [ en ] | training loss:  2.8331 | val loss:  2.8323 | hit@1:  0.0005 hit@10:  0.0032
KGC: [ en ] | training loss:  2.8331 | val loss:  2.8323 | hit@1:  0.0008 hit@10:  0.004
KGC: [ en ] | training loss:  2.8331 | val loss:  2.8323 | hit@1:  0.0001 hit@10:  0.0035
KGC: [ en ] | training loss:  2.8331 | val loss:  2.8323 | hit@1:  0.0001 hit@10:  0.0032
KGC: [ en ] | training loss:  2.8331 | val loss:  2.8323 | hit@1:  0.0003 hit@10:  0.0031
KGC: [ en ] | training loss:  2.8331 | val loss:  2.8323 | hit@1:  0.0004 hit@10:  0.004
KGC: [ en ] | training loss:  2.8331 | val loss:  2.8323 | hit@1:  0.0003 hit@10:  0.0042
KGC: [ en ] | training loss:  2.8331 | val loss:  2.8323 | hit@1:  0.0007 hit@10:  0.004
KGC: [ en ] | training loss:  2.8331 | val loss:  2.8323 | hit@1:  0.0001 hit@10:  0.0033
KGC: [ en ] | training loss:  2.8331 | val loss:  2.8323 | hit@1:  0.0007 hit@10:  0.004
KGC: [ en ] | training loss:  2.8331 | val loss:  2.8323 | hit@1:  0.0003 hit@10:  0.0028
KGC: [ en ] | training loss:  2.8331 | val loss:  2.8323 | hit@1:  0.0001 hit@10:  0.0032
KGC: [ en ] | training loss:  2.8331 | val loss:  2.8323 | hit@1:  0.0 hit@10:  0.0038
KGC: [ en ] | training loss:  2.8331 | val loss:  2.8323 | hit@1:  0.0001 hit@10:  0.0027
KGC: [ en ] | training loss:  2.8331 | val loss:  2.8323 | hit@1:  0.0005 hit@10:  0.0038
KGC: [ en ] | training loss:  2.8331 | val loss:  2.8323 | hit@1:  0.0001 hit@10:  0.0036
KGC: [ en ] | training loss:  2.8331 | val loss:  2.8323 | hit@1:  0.0001 hit@10:  0.0029
KGC: [ en ] | training loss:  2.8331 | val loss:  2.8323 | hit@1:  0.0 hit@10:  0.0028
KGC: [ en ] | training loss:  2.8331 | val loss:  2.8323 | hit@1:  0.0008 hit@10:  0.0033
KGC: [ en ] | training loss:  2.8331 | val loss:  2.8323 | hit@1:  0.0001 hit@10:  0.0033
KGC: [ en ] | training loss:  2.8331 | val loss:  2.8323 | hit@1:  0.0 hit@10:  0.0029
KGC: [ en ] | training loss:  2.8331 | val loss:  2.8323 | hit@1:  0.0003 hit@10:  0.0035
The performance (hit@1, hit@10) of language [ en ] is:  [2.8323, 0.0, 0.0023]
KGC: [ es ] | training loss:  1.9835 | val loss:  1.1825 | hit@1:  0.0389 hit@10:  0.2358
KGC: [ es ] | training loss:  1.0166 | val loss:  0.867 | hit@1:  0.1069 hit@10:  0.2216
KGC: [ es ] | training loss:  2.4892 | val loss:  2.8329 | hit@1:  0.0002 hit@10:  0.0162
KGC: [ es ] | training loss:  2.8331 | val loss:  2.8329 | hit@1:  0.0002 hit@10:  0.0177
KGC: [ es ] | training loss:  2.8331 | val loss:  2.8329 | hit@1:  0.0002 hit@10:  0.0027
KGC: [ es ] | training loss:  2.8331 | val loss:  2.8329 | hit@1:  0.0002 hit@10:  0.0075
KGC: [ es ] | training loss:  2.8331 | val loss:  2.8329 | hit@1:  0.001 hit@10:  0.0069
KGC: [ es ] | training loss:  2.8331 | val loss:  2.8329 | hit@1:  0.0002 hit@10:  0.0064
KGC: [ es ] | training loss:  2.8331 | val loss:  2.8329 | hit@1:  0.0006 hit@10:  0.0023
KGC: [ es ] | training loss:  2.8331 | val loss:  2.8329 | hit@1:  0.0006 hit@10:  0.0029
KGC: [ es ] | training loss:  2.8331 | val loss:  2.8329 | hit@1:  0.0019 hit@10:  0.0112
KGC: [ es ] | training loss:  2.8331 | val loss:  2.8329 | hit@1:  0.0056 hit@10:  0.0152
KGC: [ es ] | training loss:  2.8331 | val loss:  2.8329 | hit@1:  0.0008 hit@10:  0.0085
KGC: [ es ] | training loss:  2.8331 | val loss:  2.8329 | hit@1:  0.0056 hit@10:  0.021
KGC: [ es ] | training loss:  2.8331 | val loss:  2.8329 | hit@1:  0.0008 hit@10:  0.0079
KGC: [ es ] | training loss:  2.8331 | val loss:  2.8329 | hit@1:  0.0002 hit@10:  0.005
KGC: [ es ] | training loss:  2.8331 | val loss:  2.8329 | hit@1:  0.0025 hit@10:  0.0143
KGC: [ es ] | training loss:  2.8331 | val loss:  2.8329 | hit@1:  0.0004 hit@10:  0.0067
KGC: [ es ] | training loss:  2.8331 | val loss:  2.8329 | hit@1:  0.0006 hit@10:  0.0048
KGC: [ es ] | training loss:  2.8331 | val loss:  2.8329 | hit@1:  0.0002 hit@10:  0.005
KGC: [ es ] | training loss:  2.8331 | val loss:  2.8329 | hit@1:  0.0002 hit@10:  0.0062
KGC: [ es ] | training loss:  2.8331 | val loss:  2.8329 | hit@1:  0.0004 hit@10:  0.0064
KGC: [ es ] | training loss:  2.8331 | val loss:  2.8329 | hit@1:  0.0004 hit@10:  0.004
KGC: [ es ] | training loss:  2.8331 | val loss:  2.8329 | hit@1:  0.0 hit@10:  0.0037
KGC: [ es ] | training loss:  2.8331 | val loss:  2.8329 | hit@1:  0.0002 hit@10:  0.0033
KGC: [ es ] | training loss:  2.8331 | val loss:  2.8329 | hit@1:  0.0012 hit@10:  0.0069
KGC: [ es ] | training loss:  2.8331 | val loss:  2.8329 | hit@1:  0.0008 hit@10:  0.005
KGC: [ es ] | training loss:  2.8331 | val loss:  2.8329 | hit@1:  0.0004 hit@10:  0.0054
KGC: [ es ] | training loss:  2.8331 | val loss:  2.8329 | hit@1:  0.0004 hit@10:  0.0031
KGC: [ es ] | training loss:  2.8331 | val loss:  2.8329 | hit@1:  0.0006 hit@10:  0.0062
KGC: [ es ] | training loss:  2.8331 | val loss:  2.8329 | hit@1:  0.0004 hit@10:  0.0033
KGC: [ es ] | training loss:  2.8331 | val loss:  2.8329 | hit@1:  0.0002 hit@10:  0.0035
KGC: [ es ] | training loss:  2.8331 | val loss:  2.8329 | hit@1:  0.0 hit@10:  0.0054
KGC: [ es ] | training loss:  2.8331 | val loss:  2.8329 | hit@1:  0.0006 hit@10:  0.0035
KGC: [ es ] | training loss:  2.8331 | val loss:  2.8329 | hit@1:  0.0002 hit@10:  0.0027
KGC: [ es ] | training loss:  2.8331 | val loss:  2.8329 | hit@1:  0.0002 hit@10:  0.0042
KGC: [ es ] | training loss:  2.8331 | val loss:  2.8329 | hit@1:  0.0 hit@10:  0.0023
KGC: [ es ] | training loss:  2.8331 | val loss:  2.8329 | hit@1:  0.0 hit@10:  0.0033
KGC: [ es ] | training loss:  2.8331 | val loss:  2.8329 | hit@1:  0.0002 hit@10:  0.0035
KGC: [ es ] | training loss:  2.8331 | val loss:  2.8329 | hit@1:  0.0004 hit@10:  0.0056
KGC: [ es ] | training loss:  2.8331 | val loss:  2.8329 | hit@1:  0.0 hit@10:  0.0048
KGC: [ es ] | training loss:  2.8331 | val loss:  2.8329 | hit@1:  0.0008 hit@10:  0.0048
KGC: [ es ] | training loss:  2.8331 | val loss:  2.8329 | hit@1:  0.0 hit@10:  0.0064
KGC: [ es ] | training loss:  2.8331 | val loss:  2.8329 | hit@1:  0.0004 hit@10:  0.0029
KGC: [ es ] | training loss:  2.8331 | val loss:  2.8329 | hit@1:  0.0002 hit@10:  0.0048
KGC: [ es ] | training loss:  2.8331 | val loss:  2.8329 | hit@1:  0.0004 hit@10:  0.0052
KGC: [ es ] | training loss:  2.8331 | val loss:  2.8329 | hit@1:  0.0 hit@10:  0.0054
KGC: [ es ] | training loss:  2.8331 | val loss:  2.8329 | hit@1:  0.001 hit@10:  0.0054
KGC: [ es ] | training loss:  2.8331 | val loss:  2.8329 | hit@1:  0.0002 hit@10:  0.0046
KGC: [ es ] | training loss:  2.8331 | val loss:  2.8329 | hit@1:  0.0 hit@10:  0.0023
The performance (hit@1, hit@10) of language [ es ] is:  [0.867, 0.1069, 0.2216]
KGC: [ fr ] | training loss:  2.3236 | val loss:  2.1043 | hit@1:  0.005 hit@10:  0.1371
KGC: [ fr ] | training loss:  1.6235 | val loss:  1.4221 | hit@1:  0.0014 hit@10:  0.2083
KGC: [ fr ] | training loss:  1.3302 | val loss:  1.2276 | hit@1:  0.0014 hit@10:  0.1942
KGC: [ fr ] | training loss:  1.16 | val loss:  1.0959 | hit@1:  0.0038 hit@10:  0.2021
KGC: [ fr ] | training loss:  1.3815 | val loss:  1.4546 | hit@1:  0.0295 hit@10:  0.1719
KGC: [ fr ] | training loss:  1.2707 | val loss:  1.1859 | hit@1:  0.0995 hit@10:  0.2549
KGC: [ fr ] | training loss:  1.1103 | val loss:  1.1438 | hit@1:  0.1263 hit@10:  0.2539
KGC: [ fr ] | training loss:  1.7883 | val loss:  2.8309 | hit@1:  0.0002 hit@10:  0.0034
KGC: [ fr ] | training loss:  2.833 | val loss:  2.8309 | hit@1:  0.0002 hit@10:  0.0031
KGC: [ fr ] | training loss:  2.833 | val loss:  2.8309 | hit@1:  0.0005 hit@10:  0.0091
KGC: [ fr ] | training loss:  2.833 | val loss:  2.8309 | hit@1:  0.0002 hit@10:  0.0048
KGC: [ fr ] | training loss:  2.833 | val loss:  2.8309 | hit@1:  0.0002 hit@10:  0.0065
KGC: [ fr ] | training loss:  2.833 | val loss:  2.8309 | hit@1:  0.0002 hit@10:  0.0024
KGC: [ fr ] | training loss:  2.833 | val loss:  2.8309 | hit@1:  0.0002 hit@10:  0.0026
KGC: [ fr ] | training loss:  2.833 | val loss:  2.8309 | hit@1:  0.0017 hit@10:  0.0055
KGC: [ fr ] | training loss:  2.833 | val loss:  2.8309 | hit@1:  0.0048 hit@10:  0.0103
KGC: [ fr ] | training loss:  2.833 | val loss:  2.8309 | hit@1:  0.0005 hit@10:  0.0067
KGC: [ fr ] | training loss:  2.833 | val loss:  2.8309 | hit@1:  0.0002 hit@10:  0.0091
KGC: [ fr ] | training loss:  2.833 | val loss:  2.8309 | hit@1:  0.0002 hit@10:  0.0038
KGC: [ fr ] | training loss:  2.833 | val loss:  2.8309 | hit@1:  0.0002 hit@10:  0.0029
KGC: [ fr ] | training loss:  2.833 | val loss:  2.8309 | hit@1:  0.0002 hit@10:  0.0036
KGC: [ fr ] | training loss:  2.833 | val loss:  2.8309 | hit@1:  0.0002 hit@10:  0.0038
KGC: [ fr ] | training loss:  2.833 | val loss:  2.8309 | hit@1:  0.0002 hit@10:  0.0029
KGC: [ fr ] | training loss:  2.833 | val loss:  2.8309 | hit@1:  0.0002 hit@10:  0.0026
KGC: [ fr ] | training loss:  2.833 | val loss:  2.8309 | hit@1:  0.0005 hit@10:  0.0036
KGC: [ fr ] | training loss:  2.833 | val loss:  2.8309 | hit@1:  0.0002 hit@10:  0.0074
KGC: [ fr ] | training loss:  2.833 | val loss:  2.8309 | hit@1:  0.0012 hit@10:  0.0096
KGC: [ fr ] | training loss:  2.833 | val loss:  2.8309 | hit@1:  0.0014 hit@10:  0.0091
KGC: [ fr ] | training loss:  2.833 | val loss:  2.8309 | hit@1:  0.0 hit@10:  0.0098
KGC: [ fr ] | training loss:  2.833 | val loss:  2.8309 | hit@1:  0.0031 hit@10:  0.0079
KGC: [ fr ] | training loss:  2.833 | val loss:  2.8309 | hit@1:  0.0007 hit@10:  0.0043
KGC: [ fr ] | training loss:  2.833 | val loss:  2.8309 | hit@1:  0.0002 hit@10:  0.0038
KGC: [ fr ] | training loss:  2.833 | val loss:  2.8309 | hit@1:  0.0007 hit@10:  0.0065
KGC: [ fr ] | training loss:  2.833 | val loss:  2.8309 | hit@1:  0.0 hit@10:  0.0062
KGC: [ fr ] | training loss:  2.833 | val loss:  2.8309 | hit@1:  0.0024 hit@10:  0.0084
KGC: [ fr ] | training loss:  2.833 | val loss:  2.8309 | hit@1:  0.0029 hit@10:  0.0062
KGC: [ fr ] | training loss:  2.833 | val loss:  2.8309 | hit@1:  0.0005 hit@10:  0.007
KGC: [ fr ] | training loss:  2.833 | val loss:  2.8309 | hit@1:  0.001 hit@10:  0.007
KGC: [ fr ] | training loss:  2.833 | val loss:  2.8309 | hit@1:  0.0005 hit@10:  0.0101
KGC: [ fr ] | training loss:  2.833 | val loss:  2.8309 | hit@1:  0.0002 hit@10:  0.0046
KGC: [ fr ] | training loss:  2.833 | val loss:  2.8309 | hit@1:  0.001 hit@10:  0.0034
KGC: [ fr ] | training loss:  2.833 | val loss:  2.8309 | hit@1:  0.0012 hit@10:  0.0077
KGC: [ fr ] | training loss:  2.833 | val loss:  2.8309 | hit@1:  0.0024 hit@10:  0.0096
KGC: [ fr ] | training loss:  2.833 | val loss:  2.8309 | hit@1:  0.0019 hit@10:  0.0079
KGC: [ fr ] | training loss:  2.833 | val loss:  2.8309 | hit@1:  0.0002 hit@10:  0.0065
KGC: [ fr ] | training loss:  2.833 | val loss:  2.8309 | hit@1:  0.0005 hit@10:  0.0048
KGC: [ fr ] | training loss:  2.833 | val loss:  2.8309 | hit@1:  0.0007 hit@10:  0.0058
KGC: [ fr ] | training loss:  2.833 | val loss:  2.8309 | hit@1:  0.001 hit@10:  0.0065
KGC: [ fr ] | training loss:  2.833 | val loss:  2.8309 | hit@1:  0.0005 hit@10:  0.0055
KGC: [ fr ] | training loss:  2.833 | val loss:  2.8309 | hit@1:  0.0012 hit@10:  0.0058
The performance (hit@1, hit@10) of language [ fr ] is:  [1.0959, 0.0038, 0.2021]
KGC: [ ja ] | training loss:  2.4286 | val loss:  2.7614 | hit@1:  0.012 hit@10:  0.0333
KGC: [ ja ] | training loss:  2.8008 | val loss:  2.7733 | hit@1:  0.0005 hit@10:  0.0116
KGC: [ ja ] | training loss:  2.7089 | val loss:  2.695 | hit@1:  0.0005 hit@10:  0.0051
KGC: [ ja ] | training loss:  2.6885 | val loss:  2.6669 | hit@1:  0.0005 hit@10:  0.0083
KGC: [ ja ] | training loss:  2.7874 | val loss:  2.8322 | hit@1:  0.0009 hit@10:  0.0056
KGC: [ ja ] | training loss:  2.8329 | val loss:  2.8322 | hit@1:  0.0005 hit@10:  0.0079
KGC: [ ja ] | training loss:  2.8329 | val loss:  2.8322 | hit@1:  0.0009 hit@10:  0.0056
KGC: [ ja ] | training loss:  2.8329 | val loss:  2.8322 | hit@1:  0.0005 hit@10:  0.012
KGC: [ ja ] | training loss:  2.8329 | val loss:  2.8322 | hit@1:  0.0009 hit@10:  0.0074
KGC: [ ja ] | training loss:  2.8329 | val loss:  2.8322 | hit@1:  0.0005 hit@10:  0.006
KGC: [ ja ] | training loss:  2.8329 | val loss:  2.8322 | hit@1:  0.0009 hit@10:  0.0083
KGC: [ ja ] | training loss:  2.8329 | val loss:  2.8322 | hit@1:  0.0005 hit@10:  0.0083
KGC: [ ja ] | training loss:  2.8329 | val loss:  2.8322 | hit@1:  0.0005 hit@10:  0.0093
KGC: [ ja ] | training loss:  2.8329 | val loss:  2.8322 | hit@1:  0.0005 hit@10:  0.006
KGC: [ ja ] | training loss:  2.8329 | val loss:  2.8322 | hit@1:  0.0005 hit@10:  0.0056
KGC: [ ja ] | training loss:  2.8326 | val loss:  2.8696 | hit@1:  0.0009 hit@10:  0.0069
KGC: [ ja ] | training loss:  2.8329 | val loss:  2.8322 | hit@1:  0.0005 hit@10:  0.0079
KGC: [ ja ] | training loss:  2.8329 | val loss:  2.8322 | hit@1:  0.0014 hit@10:  0.0791
KGC: [ ja ] | training loss:  2.8329 | val loss:  2.8322 | hit@1:  0.0005 hit@10:  0.0074
KGC: [ ja ] | training loss:  2.8329 | val loss:  2.8322 | hit@1:  0.0019 hit@10:  0.0083
KGC: [ ja ] | training loss:  2.8329 | val loss:  2.8322 | hit@1:  0.0005 hit@10:  0.006
KGC: [ ja ] | training loss:  2.8329 | val loss:  2.8322 | hit@1:  0.0 hit@10:  0.0102
KGC: [ ja ] | training loss:  2.8329 | val loss:  2.8322 | hit@1:  0.0005 hit@10:  0.0083
KGC: [ ja ] | training loss:  2.8329 | val loss:  2.8322 | hit@1:  0.0009 hit@10:  0.0074
KGC: [ ja ] | training loss:  2.8329 | val loss:  2.8322 | hit@1:  0.0009 hit@10:  0.0065
KGC: [ ja ] | training loss:  2.8329 | val loss:  2.8322 | hit@1:  0.0005 hit@10:  0.006
KGC: [ ja ] | training loss:  2.8329 | val loss:  2.8322 | hit@1:  0.0005 hit@10:  0.006
KGC: [ ja ] | training loss:  2.8329 | val loss:  2.8322 | hit@1:  0.0005 hit@10:  0.0083
KGC: [ ja ] | training loss:  2.8329 | val loss:  2.8322 | hit@1:  0.0 hit@10:  0.0051
KGC: [ ja ] | training loss:  2.8329 | val loss:  2.8322 | hit@1:  0.0009 hit@10:  0.0093
KGC: [ ja ] | training loss:  2.8329 | val loss:  2.8322 | hit@1:  0.0005 hit@10:  0.0065
KGC: [ ja ] | training loss:  2.8329 | val loss:  2.8322 | hit@1:  0.0005 hit@10:  0.0093
KGC: [ ja ] | training loss:  2.8329 | val loss:  2.8322 | hit@1:  0.0005 hit@10:  0.0097
KGC: [ ja ] | training loss:  2.8329 | val loss:  2.8322 | hit@1:  0.0005 hit@10:  0.0069
KGC: [ ja ] | training loss:  2.8329 | val loss:  2.8322 | hit@1:  0.0005 hit@10:  0.0069
KGC: [ ja ] | training loss:  2.8329 | val loss:  2.8322 | hit@1:  0.0005 hit@10:  0.0069
KGC: [ ja ] | training loss:  2.8329 | val loss:  2.8322 | hit@1:  0.0009 hit@10:  0.006
KGC: [ ja ] | training loss:  2.8329 | val loss:  2.8322 | hit@1:  0.0005 hit@10:  0.0106
KGC: [ ja ] | training loss:  2.8329 | val loss:  2.8322 | hit@1:  0.0005 hit@10:  0.0097
KGC: [ ja ] | training loss:  2.8329 | val loss:  2.8322 | hit@1:  0.0005 hit@10:  0.0079
KGC: [ ja ] | training loss:  2.8329 | val loss:  2.8322 | hit@1:  0.0005 hit@10:  0.0069
KGC: [ ja ] | training loss:  2.8329 | val loss:  2.8322 | hit@1:  0.0005 hit@10:  0.0069
KGC: [ ja ] | training loss:  2.8329 | val loss:  2.8322 | hit@1:  0.0005 hit@10:  0.0088
KGC: [ ja ] | training loss:  2.8329 | val loss:  2.8322 | hit@1:  0.0056 hit@10:  0.0139
KGC: [ ja ] | training loss:  2.8329 | val loss:  2.8322 | hit@1:  0.0056 hit@10:  0.013
KGC: [ ja ] | training loss:  2.8329 | val loss:  2.8322 | hit@1:  0.0009 hit@10:  0.0125
KGC: [ ja ] | training loss:  2.8329 | val loss:  2.8322 | hit@1:  0.0009 hit@10:  0.012
KGC: [ ja ] | training loss:  2.8329 | val loss:  2.8322 | hit@1:  0.0009 hit@10:  0.0088
KGC: [ ja ] | training loss:  2.8329 | val loss:  2.8322 | hit@1:  0.0014 hit@10:  0.0065
KGC: [ ja ] | training loss:  2.8329 | val loss:  2.8322 | hit@1:  0.0005 hit@10:  0.006
The performance (hit@1, hit@10) of language [ ja ] is:  [2.6669, 0.0005, 0.0083]
