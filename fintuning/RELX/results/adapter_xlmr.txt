cuda:4
8
True
Some weights of the model checkpoint at /cluster/work/sachan/yifan/huggingface_models/xlm-roberta-large were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.dense.weight']
- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Overwriting existing adapter 'ep'.
Overwriting existing adapter 'tp'.
Overwriting existing adapter 'es'.
Overwriting existing adapter 'ts'.
Overwriting existing adapter fusion module 'ep,tp,es,ts'
[FREE]: embeddings.word_embeddings.weight
[FREE]: embeddings.position_embeddings.weight
[FREE]: embeddings.token_type_embeddings.weight
[FREE]: embeddings.LayerNorm.weight
[FREE]: embeddings.LayerNorm.bias
[FREE]: encoder.layer.0.attention.self.query.weight
[FREE]: encoder.layer.0.attention.self.query.bias
[FREE]: encoder.layer.0.attention.self.key.weight
[FREE]: encoder.layer.0.attention.self.key.bias
[FREE]: encoder.layer.0.attention.self.value.weight
[FREE]: encoder.layer.0.attention.self.value.bias
[FREE]: encoder.layer.0.attention.output.dense.weight
[FREE]: encoder.layer.0.attention.output.dense.bias
[FREE]: encoder.layer.0.attention.output.LayerNorm.weight
[FREE]: encoder.layer.0.attention.output.LayerNorm.bias
[FREE]: encoder.layer.0.intermediate.dense.weight
[FREE]: encoder.layer.0.intermediate.dense.bias
[FREE]: encoder.layer.0.output.dense.weight
[FREE]: encoder.layer.0.output.dense.bias
[FREE]: encoder.layer.0.output.LayerNorm.weight
[FREE]: encoder.layer.0.output.LayerNorm.bias
[FREE]: encoder.layer.0.output.adapters.ep.adapter_down.0.weight
[FREE]: encoder.layer.0.output.adapters.ep.adapter_down.0.bias
[FREE]: encoder.layer.0.output.adapters.ep.adapter_up.weight
[FREE]: encoder.layer.0.output.adapters.ep.adapter_up.bias
[FREE]: encoder.layer.0.output.adapters.tp.adapter_down.0.weight
[FREE]: encoder.layer.0.output.adapters.tp.adapter_down.0.bias
[FREE]: encoder.layer.0.output.adapters.tp.adapter_up.weight
[FREE]: encoder.layer.0.output.adapters.tp.adapter_up.bias
[FREE]: encoder.layer.0.output.adapters.es.adapter_down.0.weight
[FREE]: encoder.layer.0.output.adapters.es.adapter_down.0.bias
[FREE]: encoder.layer.0.output.adapters.es.adapter_up.weight
[FREE]: encoder.layer.0.output.adapters.es.adapter_up.bias
[FREE]: encoder.layer.0.output.adapters.ts.adapter_down.0.weight
[FREE]: encoder.layer.0.output.adapters.ts.adapter_down.0.bias
[FREE]: encoder.layer.0.output.adapters.ts.adapter_up.weight
[FREE]: encoder.layer.0.output.adapters.ts.adapter_up.bias
[FREE]: encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.query.weight
[FREE]: encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.query.bias
[FREE]: encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.key.weight
[FREE]: encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.key.bias
[FREE]: encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.value.weight
[FREE]: encoder.layer.1.attention.self.query.weight
[FREE]: encoder.layer.1.attention.self.query.bias
[FREE]: encoder.layer.1.attention.self.key.weight
[FREE]: encoder.layer.1.attention.self.key.bias
[FREE]: encoder.layer.1.attention.self.value.weight
[FREE]: encoder.layer.1.attention.self.value.bias
[FREE]: encoder.layer.1.attention.output.dense.weight
[FREE]: encoder.layer.1.attention.output.dense.bias
[FREE]: encoder.layer.1.attention.output.LayerNorm.weight
[FREE]: encoder.layer.1.attention.output.LayerNorm.bias
[FREE]: encoder.layer.1.intermediate.dense.weight
[FREE]: encoder.layer.1.intermediate.dense.bias
[FREE]: encoder.layer.1.output.dense.weight
[FREE]: encoder.layer.1.output.dense.bias
[FREE]: encoder.layer.1.output.LayerNorm.weight
[FREE]: encoder.layer.1.output.LayerNorm.bias
[FREE]: encoder.layer.1.output.adapters.ep.adapter_down.0.weight
[FREE]: encoder.layer.1.output.adapters.ep.adapter_down.0.bias
[FREE]: encoder.layer.1.output.adapters.ep.adapter_up.weight
[FREE]: encoder.layer.1.output.adapters.ep.adapter_up.bias
[FREE]: encoder.layer.1.output.adapters.tp.adapter_down.0.weight
[FREE]: encoder.layer.1.output.adapters.tp.adapter_down.0.bias
[FREE]: encoder.layer.1.output.adapters.tp.adapter_up.weight
[FREE]: encoder.layer.1.output.adapters.tp.adapter_up.bias
[FREE]: encoder.layer.1.output.adapters.es.adapter_down.0.weight
[FREE]: encoder.layer.1.output.adapters.es.adapter_down.0.bias
[FREE]: encoder.layer.1.output.adapters.es.adapter_up.weight
[FREE]: encoder.layer.1.output.adapters.es.adapter_up.bias
[FREE]: encoder.layer.1.output.adapters.ts.adapter_down.0.weight
[FREE]: encoder.layer.1.output.adapters.ts.adapter_down.0.bias
[FREE]: encoder.layer.1.output.adapters.ts.adapter_up.weight
[FREE]: encoder.layer.1.output.adapters.ts.adapter_up.bias
[FREE]: encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.query.weight
[FREE]: encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.query.bias
[FREE]: encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.key.weight
[FREE]: encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.key.bias
[FREE]: encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.value.weight
[FREE]: encoder.layer.2.attention.self.query.weight
[FREE]: encoder.layer.2.attention.self.query.bias
[FREE]: encoder.layer.2.attention.self.key.weight
[FREE]: encoder.layer.2.attention.self.key.bias
[FREE]: encoder.layer.2.attention.self.value.weight
[FREE]: encoder.layer.2.attention.self.value.bias
[FREE]: encoder.layer.2.attention.output.dense.weight
[FREE]: encoder.layer.2.attention.output.dense.bias
[FREE]: encoder.layer.2.attention.output.LayerNorm.weight
[FREE]: encoder.layer.2.attention.output.LayerNorm.bias
[FREE]: encoder.layer.2.intermediate.dense.weight
[FREE]: encoder.layer.2.intermediate.dense.bias
[FREE]: encoder.layer.2.output.dense.weight
[FREE]: encoder.layer.2.output.dense.bias
[FREE]: encoder.layer.2.output.LayerNorm.weight
[FREE]: encoder.layer.2.output.LayerNorm.bias
[FREE]: encoder.layer.2.output.adapters.ep.adapter_down.0.weight
[FREE]: encoder.layer.2.output.adapters.ep.adapter_down.0.bias
[FREE]: encoder.layer.2.output.adapters.ep.adapter_up.weight
[FREE]: encoder.layer.2.output.adapters.ep.adapter_up.bias
[FREE]: encoder.layer.2.output.adapters.tp.adapter_down.0.weight
[FREE]: encoder.layer.2.output.adapters.tp.adapter_down.0.bias
[FREE]: encoder.layer.2.output.adapters.tp.adapter_up.weight
[FREE]: encoder.layer.2.output.adapters.tp.adapter_up.bias
[FREE]: encoder.layer.2.output.adapters.es.adapter_down.0.weight
[FREE]: encoder.layer.2.output.adapters.es.adapter_down.0.bias
[FREE]: encoder.layer.2.output.adapters.es.adapter_up.weight
[FREE]: encoder.layer.2.output.adapters.es.adapter_up.bias
[FREE]: encoder.layer.2.output.adapters.ts.adapter_down.0.weight
[FREE]: encoder.layer.2.output.adapters.ts.adapter_down.0.bias
[FREE]: encoder.layer.2.output.adapters.ts.adapter_up.weight
[FREE]: encoder.layer.2.output.adapters.ts.adapter_up.bias
[FREE]: encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.query.weight
[FREE]: encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.query.bias
[FREE]: encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.key.weight
[FREE]: encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.key.bias
[FREE]: encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.value.weight
[FREE]: encoder.layer.3.attention.self.query.weight
[FREE]: encoder.layer.3.attention.self.query.bias
[FREE]: encoder.layer.3.attention.self.key.weight
[FREE]: encoder.layer.3.attention.self.key.bias
[FREE]: encoder.layer.3.attention.self.value.weight
[FREE]: encoder.layer.3.attention.self.value.bias
[FREE]: encoder.layer.3.attention.output.dense.weight
[FREE]: encoder.layer.3.attention.output.dense.bias
[FREE]: encoder.layer.3.attention.output.LayerNorm.weight
[FREE]: encoder.layer.3.attention.output.LayerNorm.bias
[FREE]: encoder.layer.3.intermediate.dense.weight
[FREE]: encoder.layer.3.intermediate.dense.bias
[FREE]: encoder.layer.3.output.dense.weight
[FREE]: encoder.layer.3.output.dense.bias
[FREE]: encoder.layer.3.output.LayerNorm.weight
[FREE]: encoder.layer.3.output.LayerNorm.bias
[FREE]: encoder.layer.3.output.adapters.ep.adapter_down.0.weight
[FREE]: encoder.layer.3.output.adapters.ep.adapter_down.0.bias
[FREE]: encoder.layer.3.output.adapters.ep.adapter_up.weight
[FREE]: encoder.layer.3.output.adapters.ep.adapter_up.bias
[FREE]: encoder.layer.3.output.adapters.tp.adapter_down.0.weight
[FREE]: encoder.layer.3.output.adapters.tp.adapter_down.0.bias
[FREE]: encoder.layer.3.output.adapters.tp.adapter_up.weight
[FREE]: encoder.layer.3.output.adapters.tp.adapter_up.bias
[FREE]: encoder.layer.3.output.adapters.es.adapter_down.0.weight
[FREE]: encoder.layer.3.output.adapters.es.adapter_down.0.bias
[FREE]: encoder.layer.3.output.adapters.es.adapter_up.weight
[FREE]: encoder.layer.3.output.adapters.es.adapter_up.bias
[FREE]: encoder.layer.3.output.adapters.ts.adapter_down.0.weight
[FREE]: encoder.layer.3.output.adapters.ts.adapter_down.0.bias
[FREE]: encoder.layer.3.output.adapters.ts.adapter_up.weight
[FREE]: encoder.layer.3.output.adapters.ts.adapter_up.bias
[FREE]: encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.query.weight
[FREE]: encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.query.bias
[FREE]: encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.key.weight
[FREE]: encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.key.bias
[FREE]: encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.value.weight
[FREE]: encoder.layer.4.attention.self.query.weight
[FREE]: encoder.layer.4.attention.self.query.bias
[FREE]: encoder.layer.4.attention.self.key.weight
[FREE]: encoder.layer.4.attention.self.key.bias
[FREE]: encoder.layer.4.attention.self.value.weight
[FREE]: encoder.layer.4.attention.self.value.bias
[FREE]: encoder.layer.4.attention.output.dense.weight
[FREE]: encoder.layer.4.attention.output.dense.bias
[FREE]: encoder.layer.4.attention.output.LayerNorm.weight
[FREE]: encoder.layer.4.attention.output.LayerNorm.bias
[FREE]: encoder.layer.4.intermediate.dense.weight
[FREE]: encoder.layer.4.intermediate.dense.bias
[FREE]: encoder.layer.4.output.dense.weight
[FREE]: encoder.layer.4.output.dense.bias
[FREE]: encoder.layer.4.output.LayerNorm.weight
[FREE]: encoder.layer.4.output.LayerNorm.bias
[FREE]: encoder.layer.4.output.adapters.ep.adapter_down.0.weight
[FREE]: encoder.layer.4.output.adapters.ep.adapter_down.0.bias
[FREE]: encoder.layer.4.output.adapters.ep.adapter_up.weight
[FREE]: encoder.layer.4.output.adapters.ep.adapter_up.bias
[FREE]: encoder.layer.4.output.adapters.tp.adapter_down.0.weight
[FREE]: encoder.layer.4.output.adapters.tp.adapter_down.0.bias
[FREE]: encoder.layer.4.output.adapters.tp.adapter_up.weight
[FREE]: encoder.layer.4.output.adapters.tp.adapter_up.bias
[FREE]: encoder.layer.4.output.adapters.es.adapter_down.0.weight
[FREE]: encoder.layer.4.output.adapters.es.adapter_down.0.bias
[FREE]: encoder.layer.4.output.adapters.es.adapter_up.weight
[FREE]: encoder.layer.4.output.adapters.es.adapter_up.bias
[FREE]: encoder.layer.4.output.adapters.ts.adapter_down.0.weight
[FREE]: encoder.layer.4.output.adapters.ts.adapter_down.0.bias
[FREE]: encoder.layer.4.output.adapters.ts.adapter_up.weight
[FREE]: encoder.layer.4.output.adapters.ts.adapter_up.bias
[FREE]: encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.query.weight
[FREE]: encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.query.bias
[FREE]: encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.key.weight
[FREE]: encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.key.bias
[FREE]: encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.value.weight
[FREE]: encoder.layer.5.attention.self.query.weight
[FREE]: encoder.layer.5.attention.self.query.bias
[FREE]: encoder.layer.5.attention.self.key.weight
[FREE]: encoder.layer.5.attention.self.key.bias
[FREE]: encoder.layer.5.attention.self.value.weight
[FREE]: encoder.layer.5.attention.self.value.bias
[FREE]: encoder.layer.5.attention.output.dense.weight
[FREE]: encoder.layer.5.attention.output.dense.bias
[FREE]: encoder.layer.5.attention.output.LayerNorm.weight
[FREE]: encoder.layer.5.attention.output.LayerNorm.bias
[FREE]: encoder.layer.5.intermediate.dense.weight
[FREE]: encoder.layer.5.intermediate.dense.bias
[FREE]: encoder.layer.5.output.dense.weight
[FREE]: encoder.layer.5.output.dense.bias
[FREE]: encoder.layer.5.output.LayerNorm.weight
[FREE]: encoder.layer.5.output.LayerNorm.bias
[FREE]: encoder.layer.5.output.adapters.ep.adapter_down.0.weight
[FREE]: encoder.layer.5.output.adapters.ep.adapter_down.0.bias
[FREE]: encoder.layer.5.output.adapters.ep.adapter_up.weight
[FREE]: encoder.layer.5.output.adapters.ep.adapter_up.bias
[FREE]: encoder.layer.5.output.adapters.tp.adapter_down.0.weight
[FREE]: encoder.layer.5.output.adapters.tp.adapter_down.0.bias
[FREE]: encoder.layer.5.output.adapters.tp.adapter_up.weight
[FREE]: encoder.layer.5.output.adapters.tp.adapter_up.bias
[FREE]: encoder.layer.5.output.adapters.es.adapter_down.0.weight
[FREE]: encoder.layer.5.output.adapters.es.adapter_down.0.bias
[FREE]: encoder.layer.5.output.adapters.es.adapter_up.weight
[FREE]: encoder.layer.5.output.adapters.es.adapter_up.bias
[FREE]: encoder.layer.5.output.adapters.ts.adapter_down.0.weight
[FREE]: encoder.layer.5.output.adapters.ts.adapter_down.0.bias
[FREE]: encoder.layer.5.output.adapters.ts.adapter_up.weight
[FREE]: encoder.layer.5.output.adapters.ts.adapter_up.bias
[FREE]: encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.query.weight
[FREE]: encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.query.bias
[FREE]: encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.key.weight
[FREE]: encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.key.bias
[FREE]: encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.value.weight
[FREE]: encoder.layer.6.attention.self.query.weight
[FREE]: encoder.layer.6.attention.self.query.bias
[FREE]: encoder.layer.6.attention.self.key.weight
[FREE]: encoder.layer.6.attention.self.key.bias
[FREE]: encoder.layer.6.attention.self.value.weight
[FREE]: encoder.layer.6.attention.self.value.bias
[FREE]: encoder.layer.6.attention.output.dense.weight
[FREE]: encoder.layer.6.attention.output.dense.bias
[FREE]: encoder.layer.6.attention.output.LayerNorm.weight
[FREE]: encoder.layer.6.attention.output.LayerNorm.bias
[FREE]: encoder.layer.6.intermediate.dense.weight
[FREE]: encoder.layer.6.intermediate.dense.bias
[FREE]: encoder.layer.6.output.dense.weight
[FREE]: encoder.layer.6.output.dense.bias
[FREE]: encoder.layer.6.output.LayerNorm.weight
[FREE]: encoder.layer.6.output.LayerNorm.bias
[FREE]: encoder.layer.6.output.adapters.ep.adapter_down.0.weight
[FREE]: encoder.layer.6.output.adapters.ep.adapter_down.0.bias
[FREE]: encoder.layer.6.output.adapters.ep.adapter_up.weight
[FREE]: encoder.layer.6.output.adapters.ep.adapter_up.bias
[FREE]: encoder.layer.6.output.adapters.tp.adapter_down.0.weight
[FREE]: encoder.layer.6.output.adapters.tp.adapter_down.0.bias
[FREE]: encoder.layer.6.output.adapters.tp.adapter_up.weight
[FREE]: encoder.layer.6.output.adapters.tp.adapter_up.bias
[FREE]: encoder.layer.6.output.adapters.es.adapter_down.0.weight
[FREE]: encoder.layer.6.output.adapters.es.adapter_down.0.bias
[FREE]: encoder.layer.6.output.adapters.es.adapter_up.weight
[FREE]: encoder.layer.6.output.adapters.es.adapter_up.bias
[FREE]: encoder.layer.6.output.adapters.ts.adapter_down.0.weight
[FREE]: encoder.layer.6.output.adapters.ts.adapter_down.0.bias
[FREE]: encoder.layer.6.output.adapters.ts.adapter_up.weight
[FREE]: encoder.layer.6.output.adapters.ts.adapter_up.bias
[FREE]: encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.query.weight
[FREE]: encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.query.bias
[FREE]: encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.key.weight
[FREE]: encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.key.bias
[FREE]: encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.value.weight
[FREE]: encoder.layer.7.attention.self.query.weight
[FREE]: encoder.layer.7.attention.self.query.bias
[FREE]: encoder.layer.7.attention.self.key.weight
[FREE]: encoder.layer.7.attention.self.key.bias
[FREE]: encoder.layer.7.attention.self.value.weight
[FREE]: encoder.layer.7.attention.self.value.bias
[FREE]: encoder.layer.7.attention.output.dense.weight
[FREE]: encoder.layer.7.attention.output.dense.bias
[FREE]: encoder.layer.7.attention.output.LayerNorm.weight
[FREE]: encoder.layer.7.attention.output.LayerNorm.bias
[FREE]: encoder.layer.7.intermediate.dense.weight
[FREE]: encoder.layer.7.intermediate.dense.bias
[FREE]: encoder.layer.7.output.dense.weight
[FREE]: encoder.layer.7.output.dense.bias
[FREE]: encoder.layer.7.output.LayerNorm.weight
[FREE]: encoder.layer.7.output.LayerNorm.bias
[FREE]: encoder.layer.7.output.adapters.ep.adapter_down.0.weight
[FREE]: encoder.layer.7.output.adapters.ep.adapter_down.0.bias
[FREE]: encoder.layer.7.output.adapters.ep.adapter_up.weight
[FREE]: encoder.layer.7.output.adapters.ep.adapter_up.bias
[FREE]: encoder.layer.7.output.adapters.tp.adapter_down.0.weight
[FREE]: encoder.layer.7.output.adapters.tp.adapter_down.0.bias
[FREE]: encoder.layer.7.output.adapters.tp.adapter_up.weight
[FREE]: encoder.layer.7.output.adapters.tp.adapter_up.bias
[FREE]: encoder.layer.7.output.adapters.es.adapter_down.0.weight
[FREE]: encoder.layer.7.output.adapters.es.adapter_down.0.bias
[FREE]: encoder.layer.7.output.adapters.es.adapter_up.weight
[FREE]: encoder.layer.7.output.adapters.es.adapter_up.bias
[FREE]: encoder.layer.7.output.adapters.ts.adapter_down.0.weight
[FREE]: encoder.layer.7.output.adapters.ts.adapter_down.0.bias
[FREE]: encoder.layer.7.output.adapters.ts.adapter_up.weight
[FREE]: encoder.layer.7.output.adapters.ts.adapter_up.bias
[FREE]: encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.query.weight
[FREE]: encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.query.bias
[FREE]: encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.key.weight
[FREE]: encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.key.bias
[FREE]: encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.value.weight
[FREE]: encoder.layer.8.attention.self.query.weight
[FREE]: encoder.layer.8.attention.self.query.bias
[FREE]: encoder.layer.8.attention.self.key.weight
[FREE]: encoder.layer.8.attention.self.key.bias
[FREE]: encoder.layer.8.attention.self.value.weight
[FREE]: encoder.layer.8.attention.self.value.bias
[FREE]: encoder.layer.8.attention.output.dense.weight
[FREE]: encoder.layer.8.attention.output.dense.bias
[FREE]: encoder.layer.8.attention.output.LayerNorm.weight
[FREE]: encoder.layer.8.attention.output.LayerNorm.bias
[FREE]: encoder.layer.8.intermediate.dense.weight
[FREE]: encoder.layer.8.intermediate.dense.bias
[FREE]: encoder.layer.8.output.dense.weight
[FREE]: encoder.layer.8.output.dense.bias
[FREE]: encoder.layer.8.output.LayerNorm.weight
[FREE]: encoder.layer.8.output.LayerNorm.bias
[FREE]: encoder.layer.8.output.adapters.ep.adapter_down.0.weight
[FREE]: encoder.layer.8.output.adapters.ep.adapter_down.0.bias
[FREE]: encoder.layer.8.output.adapters.ep.adapter_up.weight
[FREE]: encoder.layer.8.output.adapters.ep.adapter_up.bias
[FREE]: encoder.layer.8.output.adapters.tp.adapter_down.0.weight
[FREE]: encoder.layer.8.output.adapters.tp.adapter_down.0.bias
[FREE]: encoder.layer.8.output.adapters.tp.adapter_up.weight
[FREE]: encoder.layer.8.output.adapters.tp.adapter_up.bias
[FREE]: encoder.layer.8.output.adapters.es.adapter_down.0.weight
[FREE]: encoder.layer.8.output.adapters.es.adapter_down.0.bias
[FREE]: encoder.layer.8.output.adapters.es.adapter_up.weight
[FREE]: encoder.layer.8.output.adapters.es.adapter_up.bias
[FREE]: encoder.layer.8.output.adapters.ts.adapter_down.0.weight
[FREE]: encoder.layer.8.output.adapters.ts.adapter_down.0.bias
[FREE]: encoder.layer.8.output.adapters.ts.adapter_up.weight
[FREE]: encoder.layer.8.output.adapters.ts.adapter_up.bias
[FREE]: encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.query.weight
[FREE]: encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.query.bias
[FREE]: encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.key.weight
[FREE]: encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.key.bias
[FREE]: encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.value.weight
[FREE]: encoder.layer.9.attention.self.query.weight
[FREE]: encoder.layer.9.attention.self.query.bias
[FREE]: encoder.layer.9.attention.self.key.weight
[FREE]: encoder.layer.9.attention.self.key.bias
[FREE]: encoder.layer.9.attention.self.value.weight
[FREE]: encoder.layer.9.attention.self.value.bias
[FREE]: encoder.layer.9.attention.output.dense.weight
[FREE]: encoder.layer.9.attention.output.dense.bias
[FREE]: encoder.layer.9.attention.output.LayerNorm.weight
[FREE]: encoder.layer.9.attention.output.LayerNorm.bias
[FREE]: encoder.layer.9.intermediate.dense.weight
[FREE]: encoder.layer.9.intermediate.dense.bias
[FREE]: encoder.layer.9.output.dense.weight
[FREE]: encoder.layer.9.output.dense.bias
[FREE]: encoder.layer.9.output.LayerNorm.weight
[FREE]: encoder.layer.9.output.LayerNorm.bias
[FREE]: encoder.layer.9.output.adapters.ep.adapter_down.0.weight
[FREE]: encoder.layer.9.output.adapters.ep.adapter_down.0.bias
[FREE]: encoder.layer.9.output.adapters.ep.adapter_up.weight
[FREE]: encoder.layer.9.output.adapters.ep.adapter_up.bias
[FREE]: encoder.layer.9.output.adapters.tp.adapter_down.0.weight
[FREE]: encoder.layer.9.output.adapters.tp.adapter_down.0.bias
[FREE]: encoder.layer.9.output.adapters.tp.adapter_up.weight
[FREE]: encoder.layer.9.output.adapters.tp.adapter_up.bias
[FREE]: encoder.layer.9.output.adapters.es.adapter_down.0.weight
[FREE]: encoder.layer.9.output.adapters.es.adapter_down.0.bias
[FREE]: encoder.layer.9.output.adapters.es.adapter_up.weight
[FREE]: encoder.layer.9.output.adapters.es.adapter_up.bias
[FREE]: encoder.layer.9.output.adapters.ts.adapter_down.0.weight
[FREE]: encoder.layer.9.output.adapters.ts.adapter_down.0.bias
[FREE]: encoder.layer.9.output.adapters.ts.adapter_up.weight
[FREE]: encoder.layer.9.output.adapters.ts.adapter_up.bias
[FREE]: encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.query.weight
[FREE]: encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.query.bias
[FREE]: encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.key.weight
[FREE]: encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.key.bias
[FREE]: encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.value.weight
[FREE]: encoder.layer.10.attention.self.query.weight
[FREE]: encoder.layer.10.attention.self.query.bias
[FREE]: encoder.layer.10.attention.self.key.weight
[FREE]: encoder.layer.10.attention.self.key.bias
[FREE]: encoder.layer.10.attention.self.value.weight
[FREE]: encoder.layer.10.attention.self.value.bias
[FREE]: encoder.layer.10.attention.output.dense.weight
[FREE]: encoder.layer.10.attention.output.dense.bias
[FREE]: encoder.layer.10.attention.output.LayerNorm.weight
[FREE]: encoder.layer.10.attention.output.LayerNorm.bias
[FREE]: encoder.layer.10.intermediate.dense.weight
[FREE]: encoder.layer.10.intermediate.dense.bias
[FREE]: encoder.layer.10.output.dense.weight
[FREE]: encoder.layer.10.output.dense.bias
[FREE]: encoder.layer.10.output.LayerNorm.weight
[FREE]: encoder.layer.10.output.LayerNorm.bias
[FREE]: encoder.layer.10.output.adapters.ep.adapter_down.0.weight
[FREE]: encoder.layer.10.output.adapters.ep.adapter_down.0.bias
[FREE]: encoder.layer.10.output.adapters.ep.adapter_up.weight
[FREE]: encoder.layer.10.output.adapters.ep.adapter_up.bias
[FREE]: encoder.layer.10.output.adapters.tp.adapter_down.0.weight
[FREE]: encoder.layer.10.output.adapters.tp.adapter_down.0.bias
[FREE]: encoder.layer.10.output.adapters.tp.adapter_up.weight
[FREE]: encoder.layer.10.output.adapters.tp.adapter_up.bias
[FREE]: encoder.layer.10.output.adapters.es.adapter_down.0.weight
[FREE]: encoder.layer.10.output.adapters.es.adapter_down.0.bias
[FREE]: encoder.layer.10.output.adapters.es.adapter_up.weight
[FREE]: encoder.layer.10.output.adapters.es.adapter_up.bias
[FREE]: encoder.layer.10.output.adapters.ts.adapter_down.0.weight
[FREE]: encoder.layer.10.output.adapters.ts.adapter_down.0.bias
[FREE]: encoder.layer.10.output.adapters.ts.adapter_up.weight
[FREE]: encoder.layer.10.output.adapters.ts.adapter_up.bias
[FREE]: encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.query.weight
[FREE]: encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.query.bias
[FREE]: encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.key.weight
[FREE]: encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.key.bias
[FREE]: encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.value.weight
[FREE]: encoder.layer.11.attention.self.query.weight
[FREE]: encoder.layer.11.attention.self.query.bias
[FREE]: encoder.layer.11.attention.self.key.weight
[FREE]: encoder.layer.11.attention.self.key.bias
[FREE]: encoder.layer.11.attention.self.value.weight
[FREE]: encoder.layer.11.attention.self.value.bias
[FREE]: encoder.layer.11.attention.output.dense.weight
[FREE]: encoder.layer.11.attention.output.dense.bias
[FREE]: encoder.layer.11.attention.output.LayerNorm.weight
[FREE]: encoder.layer.11.attention.output.LayerNorm.bias
[FREE]: encoder.layer.11.intermediate.dense.weight
[FREE]: encoder.layer.11.intermediate.dense.bias
[FREE]: encoder.layer.11.output.dense.weight
[FREE]: encoder.layer.11.output.dense.bias
[FREE]: encoder.layer.11.output.LayerNorm.weight
[FREE]: encoder.layer.11.output.LayerNorm.bias
[FREE]: encoder.layer.11.output.adapters.ep.adapter_down.0.weight
[FREE]: encoder.layer.11.output.adapters.ep.adapter_down.0.bias
[FREE]: encoder.layer.11.output.adapters.ep.adapter_up.weight
[FREE]: encoder.layer.11.output.adapters.ep.adapter_up.bias
[FREE]: encoder.layer.11.output.adapters.tp.adapter_down.0.weight
[FREE]: encoder.layer.11.output.adapters.tp.adapter_down.0.bias
[FREE]: encoder.layer.11.output.adapters.tp.adapter_up.weight
[FREE]: encoder.layer.11.output.adapters.tp.adapter_up.bias
[FREE]: encoder.layer.11.output.adapters.es.adapter_down.0.weight
[FREE]: encoder.layer.11.output.adapters.es.adapter_down.0.bias
[FREE]: encoder.layer.11.output.adapters.es.adapter_up.weight
[FREE]: encoder.layer.11.output.adapters.es.adapter_up.bias
[FREE]: encoder.layer.11.output.adapters.ts.adapter_down.0.weight
[FREE]: encoder.layer.11.output.adapters.ts.adapter_down.0.bias
[FREE]: encoder.layer.11.output.adapters.ts.adapter_up.weight
[FREE]: encoder.layer.11.output.adapters.ts.adapter_up.bias
[FREE]: encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.query.weight
[FREE]: encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.query.bias
[FREE]: encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.key.weight
[FREE]: encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.key.bias
[FREE]: encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.value.weight
[FREE]: encoder.layer.12.attention.self.query.weight
[FREE]: encoder.layer.12.attention.self.query.bias
[FREE]: encoder.layer.12.attention.self.key.weight
[FREE]: encoder.layer.12.attention.self.key.bias
[FREE]: encoder.layer.12.attention.self.value.weight
[FREE]: encoder.layer.12.attention.self.value.bias
[FREE]: encoder.layer.12.attention.output.dense.weight
[FREE]: encoder.layer.12.attention.output.dense.bias
[FREE]: encoder.layer.12.attention.output.LayerNorm.weight
[FREE]: encoder.layer.12.attention.output.LayerNorm.bias
[FREE]: encoder.layer.12.intermediate.dense.weight
[FREE]: encoder.layer.12.intermediate.dense.bias
[FREE]: encoder.layer.12.output.dense.weight
[FREE]: encoder.layer.12.output.dense.bias
[FREE]: encoder.layer.12.output.LayerNorm.weight
[FREE]: encoder.layer.12.output.LayerNorm.bias
[FREE]: encoder.layer.12.output.adapters.ep.adapter_down.0.weight
[FREE]: encoder.layer.12.output.adapters.ep.adapter_down.0.bias
[FREE]: encoder.layer.12.output.adapters.ep.adapter_up.weight
[FREE]: encoder.layer.12.output.adapters.ep.adapter_up.bias
[FREE]: encoder.layer.12.output.adapters.tp.adapter_down.0.weight
[FREE]: encoder.layer.12.output.adapters.tp.adapter_down.0.bias
[FREE]: encoder.layer.12.output.adapters.tp.adapter_up.weight
[FREE]: encoder.layer.12.output.adapters.tp.adapter_up.bias
[FREE]: encoder.layer.12.output.adapters.es.adapter_down.0.weight
[FREE]: encoder.layer.12.output.adapters.es.adapter_down.0.bias
[FREE]: encoder.layer.12.output.adapters.es.adapter_up.weight
[FREE]: encoder.layer.12.output.adapters.es.adapter_up.bias
[FREE]: encoder.layer.12.output.adapters.ts.adapter_down.0.weight
[FREE]: encoder.layer.12.output.adapters.ts.adapter_down.0.bias
[FREE]: encoder.layer.12.output.adapters.ts.adapter_up.weight
[FREE]: encoder.layer.12.output.adapters.ts.adapter_up.bias
[FREE]: encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.query.weight
[FREE]: encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.query.bias
[FREE]: encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.key.weight
[FREE]: encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.key.bias
[FREE]: encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.value.weight
[FREE]: encoder.layer.13.attention.self.query.weight
[FREE]: encoder.layer.13.attention.self.query.bias
[FREE]: encoder.layer.13.attention.self.key.weight
[FREE]: encoder.layer.13.attention.self.key.bias
[FREE]: encoder.layer.13.attention.self.value.weight
[FREE]: encoder.layer.13.attention.self.value.bias
[FREE]: encoder.layer.13.attention.output.dense.weight
[FREE]: encoder.layer.13.attention.output.dense.bias
[FREE]: encoder.layer.13.attention.output.LayerNorm.weight
[FREE]: encoder.layer.13.attention.output.LayerNorm.bias
[FREE]: encoder.layer.13.intermediate.dense.weight
[FREE]: encoder.layer.13.intermediate.dense.bias
[FREE]: encoder.layer.13.output.dense.weight
[FREE]: encoder.layer.13.output.dense.bias
[FREE]: encoder.layer.13.output.LayerNorm.weight
[FREE]: encoder.layer.13.output.LayerNorm.bias
[FREE]: encoder.layer.13.output.adapters.ep.adapter_down.0.weight
[FREE]: encoder.layer.13.output.adapters.ep.adapter_down.0.bias
[FREE]: encoder.layer.13.output.adapters.ep.adapter_up.weight
[FREE]: encoder.layer.13.output.adapters.ep.adapter_up.bias
[FREE]: encoder.layer.13.output.adapters.tp.adapter_down.0.weight
[FREE]: encoder.layer.13.output.adapters.tp.adapter_down.0.bias
[FREE]: encoder.layer.13.output.adapters.tp.adapter_up.weight
[FREE]: encoder.layer.13.output.adapters.tp.adapter_up.bias
[FREE]: encoder.layer.13.output.adapters.es.adapter_down.0.weight
[FREE]: encoder.layer.13.output.adapters.es.adapter_down.0.bias
[FREE]: encoder.layer.13.output.adapters.es.adapter_up.weight
[FREE]: encoder.layer.13.output.adapters.es.adapter_up.bias
[FREE]: encoder.layer.13.output.adapters.ts.adapter_down.0.weight
[FREE]: encoder.layer.13.output.adapters.ts.adapter_down.0.bias
[FREE]: encoder.layer.13.output.adapters.ts.adapter_up.weight
[FREE]: encoder.layer.13.output.adapters.ts.adapter_up.bias
[FREE]: encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.query.weight
[FREE]: encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.query.bias
[FREE]: encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.key.weight
[FREE]: encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.key.bias
[FREE]: encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.value.weight
[FREE]: encoder.layer.14.attention.self.query.weight
[FREE]: encoder.layer.14.attention.self.query.bias
[FREE]: encoder.layer.14.attention.self.key.weight
[FREE]: encoder.layer.14.attention.self.key.bias
[FREE]: encoder.layer.14.attention.self.value.weight
[FREE]: encoder.layer.14.attention.self.value.bias
[FREE]: encoder.layer.14.attention.output.dense.weight
[FREE]: encoder.layer.14.attention.output.dense.bias
[FREE]: encoder.layer.14.attention.output.LayerNorm.weight
[FREE]: encoder.layer.14.attention.output.LayerNorm.bias
[FREE]: encoder.layer.14.intermediate.dense.weight
[FREE]: encoder.layer.14.intermediate.dense.bias
[FREE]: encoder.layer.14.output.dense.weight
[FREE]: encoder.layer.14.output.dense.bias
[FREE]: encoder.layer.14.output.LayerNorm.weight
[FREE]: encoder.layer.14.output.LayerNorm.bias
[FREE]: encoder.layer.14.output.adapters.ep.adapter_down.0.weight
[FREE]: encoder.layer.14.output.adapters.ep.adapter_down.0.bias
[FREE]: encoder.layer.14.output.adapters.ep.adapter_up.weight
[FREE]: encoder.layer.14.output.adapters.ep.adapter_up.bias
[FREE]: encoder.layer.14.output.adapters.tp.adapter_down.0.weight
[FREE]: encoder.layer.14.output.adapters.tp.adapter_down.0.bias
[FREE]: encoder.layer.14.output.adapters.tp.adapter_up.weight
[FREE]: encoder.layer.14.output.adapters.tp.adapter_up.bias
[FREE]: encoder.layer.14.output.adapters.es.adapter_down.0.weight
[FREE]: encoder.layer.14.output.adapters.es.adapter_down.0.bias
[FREE]: encoder.layer.14.output.adapters.es.adapter_up.weight
[FREE]: encoder.layer.14.output.adapters.es.adapter_up.bias
[FREE]: encoder.layer.14.output.adapters.ts.adapter_down.0.weight
[FREE]: encoder.layer.14.output.adapters.ts.adapter_down.0.bias
[FREE]: encoder.layer.14.output.adapters.ts.adapter_up.weight
[FREE]: encoder.layer.14.output.adapters.ts.adapter_up.bias
[FREE]: encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.query.weight
[FREE]: encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.query.bias
[FREE]: encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.key.weight
[FREE]: encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.key.bias
[FREE]: encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.value.weight
[FREE]: encoder.layer.15.attention.self.query.weight
[FREE]: encoder.layer.15.attention.self.query.bias
[FREE]: encoder.layer.15.attention.self.key.weight
[FREE]: encoder.layer.15.attention.self.key.bias
[FREE]: encoder.layer.15.attention.self.value.weight
[FREE]: encoder.layer.15.attention.self.value.bias
[FREE]: encoder.layer.15.attention.output.dense.weight
[FREE]: encoder.layer.15.attention.output.dense.bias
[FREE]: encoder.layer.15.attention.output.LayerNorm.weight
[FREE]: encoder.layer.15.attention.output.LayerNorm.bias
[FREE]: encoder.layer.15.intermediate.dense.weight
[FREE]: encoder.layer.15.intermediate.dense.bias
[FREE]: encoder.layer.15.output.dense.weight
[FREE]: encoder.layer.15.output.dense.bias
[FREE]: encoder.layer.15.output.LayerNorm.weight
[FREE]: encoder.layer.15.output.LayerNorm.bias
[FREE]: encoder.layer.15.output.adapters.ep.adapter_down.0.weight
[FREE]: encoder.layer.15.output.adapters.ep.adapter_down.0.bias
[FREE]: encoder.layer.15.output.adapters.ep.adapter_up.weight
[FREE]: encoder.layer.15.output.adapters.ep.adapter_up.bias
[FREE]: encoder.layer.15.output.adapters.tp.adapter_down.0.weight
[FREE]: encoder.layer.15.output.adapters.tp.adapter_down.0.bias
[FREE]: encoder.layer.15.output.adapters.tp.adapter_up.weight
[FREE]: encoder.layer.15.output.adapters.tp.adapter_up.bias
[FREE]: encoder.layer.15.output.adapters.es.adapter_down.0.weight
[FREE]: encoder.layer.15.output.adapters.es.adapter_down.0.bias
[FREE]: encoder.layer.15.output.adapters.es.adapter_up.weight
[FREE]: encoder.layer.15.output.adapters.es.adapter_up.bias
[FREE]: encoder.layer.15.output.adapters.ts.adapter_down.0.weight
[FREE]: encoder.layer.15.output.adapters.ts.adapter_down.0.bias
[FREE]: encoder.layer.15.output.adapters.ts.adapter_up.weight
[FREE]: encoder.layer.15.output.adapters.ts.adapter_up.bias
[FREE]: encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.query.weight
[FREE]: encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.query.bias
[FREE]: encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.key.weight
[FREE]: encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.key.bias
[FREE]: encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.value.weight
[FREE]: encoder.layer.16.attention.self.query.weight
[FREE]: encoder.layer.16.attention.self.query.bias
[FREE]: encoder.layer.16.attention.self.key.weight
[FREE]: encoder.layer.16.attention.self.key.bias
[FREE]: encoder.layer.16.attention.self.value.weight
[FREE]: encoder.layer.16.attention.self.value.bias
[FREE]: encoder.layer.16.attention.output.dense.weight
[FREE]: encoder.layer.16.attention.output.dense.bias
[FREE]: encoder.layer.16.attention.output.LayerNorm.weight
[FREE]: encoder.layer.16.attention.output.LayerNorm.bias
[FREE]: encoder.layer.16.intermediate.dense.weight
[FREE]: encoder.layer.16.intermediate.dense.bias
[FREE]: encoder.layer.16.output.dense.weight
[FREE]: encoder.layer.16.output.dense.bias
[FREE]: encoder.layer.16.output.LayerNorm.weight
[FREE]: encoder.layer.16.output.LayerNorm.bias
[FREE]: encoder.layer.16.output.adapters.ep.adapter_down.0.weight
[FREE]: encoder.layer.16.output.adapters.ep.adapter_down.0.bias
[FREE]: encoder.layer.16.output.adapters.ep.adapter_up.weight
[FREE]: encoder.layer.16.output.adapters.ep.adapter_up.bias
[FREE]: encoder.layer.16.output.adapters.tp.adapter_down.0.weight
[FREE]: encoder.layer.16.output.adapters.tp.adapter_down.0.bias
[FREE]: encoder.layer.16.output.adapters.tp.adapter_up.weight
[FREE]: encoder.layer.16.output.adapters.tp.adapter_up.bias
[FREE]: encoder.layer.16.output.adapters.es.adapter_down.0.weight
[FREE]: encoder.layer.16.output.adapters.es.adapter_down.0.bias
[FREE]: encoder.layer.16.output.adapters.es.adapter_up.weight
[FREE]: encoder.layer.16.output.adapters.es.adapter_up.bias
[FREE]: encoder.layer.16.output.adapters.ts.adapter_down.0.weight
[FREE]: encoder.layer.16.output.adapters.ts.adapter_down.0.bias
[FREE]: encoder.layer.16.output.adapters.ts.adapter_up.weight
[FREE]: encoder.layer.16.output.adapters.ts.adapter_up.bias
[FREE]: encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.query.weight
[FREE]: encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.query.bias
[FREE]: encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.key.weight
[FREE]: encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.key.bias
[FREE]: encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.value.weight
[FREE]: encoder.layer.17.attention.self.query.weight
[FREE]: encoder.layer.17.attention.self.query.bias
[FREE]: encoder.layer.17.attention.self.key.weight
[FREE]: encoder.layer.17.attention.self.key.bias
[FREE]: encoder.layer.17.attention.self.value.weight
[FREE]: encoder.layer.17.attention.self.value.bias
[FREE]: encoder.layer.17.attention.output.dense.weight
[FREE]: encoder.layer.17.attention.output.dense.bias
[FREE]: encoder.layer.17.attention.output.LayerNorm.weight
[FREE]: encoder.layer.17.attention.output.LayerNorm.bias
[FREE]: encoder.layer.17.intermediate.dense.weight
[FREE]: encoder.layer.17.intermediate.dense.bias
[FREE]: encoder.layer.17.output.dense.weight
[FREE]: encoder.layer.17.output.dense.bias
[FREE]: encoder.layer.17.output.LayerNorm.weight
[FREE]: encoder.layer.17.output.LayerNorm.bias
[FREE]: encoder.layer.17.output.adapters.ep.adapter_down.0.weight
[FREE]: encoder.layer.17.output.adapters.ep.adapter_down.0.bias
[FREE]: encoder.layer.17.output.adapters.ep.adapter_up.weight
[FREE]: encoder.layer.17.output.adapters.ep.adapter_up.bias
[FREE]: encoder.layer.17.output.adapters.tp.adapter_down.0.weight
[FREE]: encoder.layer.17.output.adapters.tp.adapter_down.0.bias
[FREE]: encoder.layer.17.output.adapters.tp.adapter_up.weight
[FREE]: encoder.layer.17.output.adapters.tp.adapter_up.bias
[FREE]: encoder.layer.17.output.adapters.es.adapter_down.0.weight
[FREE]: encoder.layer.17.output.adapters.es.adapter_down.0.bias
[FREE]: encoder.layer.17.output.adapters.es.adapter_up.weight
[FREE]: encoder.layer.17.output.adapters.es.adapter_up.bias
[FREE]: encoder.layer.17.output.adapters.ts.adapter_down.0.weight
[FREE]: encoder.layer.17.output.adapters.ts.adapter_down.0.bias
[FREE]: encoder.layer.17.output.adapters.ts.adapter_up.weight
[FREE]: encoder.layer.17.output.adapters.ts.adapter_up.bias
[FREE]: encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.query.weight
[FREE]: encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.query.bias
[FREE]: encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.key.weight
[FREE]: encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.key.bias
[FREE]: encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.value.weight
[FREE]: encoder.layer.18.attention.self.query.weight
[FREE]: encoder.layer.18.attention.self.query.bias
[FREE]: encoder.layer.18.attention.self.key.weight
[FREE]: encoder.layer.18.attention.self.key.bias
[FREE]: encoder.layer.18.attention.self.value.weight
[FREE]: encoder.layer.18.attention.self.value.bias
[FREE]: encoder.layer.18.attention.output.dense.weight
[FREE]: encoder.layer.18.attention.output.dense.bias
[FREE]: encoder.layer.18.attention.output.LayerNorm.weight
[FREE]: encoder.layer.18.attention.output.LayerNorm.bias
[FREE]: encoder.layer.18.intermediate.dense.weight
[FREE]: encoder.layer.18.intermediate.dense.bias
[FREE]: encoder.layer.18.output.dense.weight
[FREE]: encoder.layer.18.output.dense.bias
[FREE]: encoder.layer.18.output.LayerNorm.weight
[FREE]: encoder.layer.18.output.LayerNorm.bias
[FREE]: encoder.layer.18.output.adapters.ep.adapter_down.0.weight
[FREE]: encoder.layer.18.output.adapters.ep.adapter_down.0.bias
[FREE]: encoder.layer.18.output.adapters.ep.adapter_up.weight
[FREE]: encoder.layer.18.output.adapters.ep.adapter_up.bias
[FREE]: encoder.layer.18.output.adapters.tp.adapter_down.0.weight
[FREE]: encoder.layer.18.output.adapters.tp.adapter_down.0.bias
[FREE]: encoder.layer.18.output.adapters.tp.adapter_up.weight
[FREE]: encoder.layer.18.output.adapters.tp.adapter_up.bias
[FREE]: encoder.layer.18.output.adapters.es.adapter_down.0.weight
[FREE]: encoder.layer.18.output.adapters.es.adapter_down.0.bias
[FREE]: encoder.layer.18.output.adapters.es.adapter_up.weight
[FREE]: encoder.layer.18.output.adapters.es.adapter_up.bias
[FREE]: encoder.layer.18.output.adapters.ts.adapter_down.0.weight
[FREE]: encoder.layer.18.output.adapters.ts.adapter_down.0.bias
[FREE]: encoder.layer.18.output.adapters.ts.adapter_up.weight
[FREE]: encoder.layer.18.output.adapters.ts.adapter_up.bias
[FREE]: encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.query.weight
[FREE]: encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.query.bias
[FREE]: encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.key.weight
[FREE]: encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.key.bias
[FREE]: encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.value.weight
[FREE]: encoder.layer.19.attention.self.query.weight
[FREE]: encoder.layer.19.attention.self.query.bias
[FREE]: encoder.layer.19.attention.self.key.weight
[FREE]: encoder.layer.19.attention.self.key.bias
[FREE]: encoder.layer.19.attention.self.value.weight
[FREE]: encoder.layer.19.attention.self.value.bias
[FREE]: encoder.layer.19.attention.output.dense.weight
[FREE]: encoder.layer.19.attention.output.dense.bias
[FREE]: encoder.layer.19.attention.output.LayerNorm.weight
[FREE]: encoder.layer.19.attention.output.LayerNorm.bias
[FREE]: encoder.layer.19.intermediate.dense.weight
[FREE]: encoder.layer.19.intermediate.dense.bias
[FREE]: encoder.layer.19.output.dense.weight
[FREE]: encoder.layer.19.output.dense.bias
[FREE]: encoder.layer.19.output.LayerNorm.weight
[FREE]: encoder.layer.19.output.LayerNorm.bias
[FREE]: encoder.layer.19.output.adapters.ep.adapter_down.0.weight
[FREE]: encoder.layer.19.output.adapters.ep.adapter_down.0.bias
[FREE]: encoder.layer.19.output.adapters.ep.adapter_up.weight
[FREE]: encoder.layer.19.output.adapters.ep.adapter_up.bias
[FREE]: encoder.layer.19.output.adapters.tp.adapter_down.0.weight
[FREE]: encoder.layer.19.output.adapters.tp.adapter_down.0.bias
[FREE]: encoder.layer.19.output.adapters.tp.adapter_up.weight
[FREE]: encoder.layer.19.output.adapters.tp.adapter_up.bias
[FREE]: encoder.layer.19.output.adapters.es.adapter_down.0.weight
[FREE]: encoder.layer.19.output.adapters.es.adapter_down.0.bias
[FREE]: encoder.layer.19.output.adapters.es.adapter_up.weight
[FREE]: encoder.layer.19.output.adapters.es.adapter_up.bias
[FREE]: encoder.layer.19.output.adapters.ts.adapter_down.0.weight
[FREE]: encoder.layer.19.output.adapters.ts.adapter_down.0.bias
[FREE]: encoder.layer.19.output.adapters.ts.adapter_up.weight
[FREE]: encoder.layer.19.output.adapters.ts.adapter_up.bias
[FREE]: encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.query.weight
[FREE]: encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.query.bias
[FREE]: encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.key.weight
[FREE]: encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.key.bias
[FREE]: encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.value.weight
[FREE]: encoder.layer.20.attention.self.query.weight
[FREE]: encoder.layer.20.attention.self.query.bias
[FREE]: encoder.layer.20.attention.self.key.weight
[FREE]: encoder.layer.20.attention.self.key.bias
[FREE]: encoder.layer.20.attention.self.value.weight
[FREE]: encoder.layer.20.attention.self.value.bias
[FREE]: encoder.layer.20.attention.output.dense.weight
[FREE]: encoder.layer.20.attention.output.dense.bias
[FREE]: encoder.layer.20.attention.output.LayerNorm.weight
[FREE]: encoder.layer.20.attention.output.LayerNorm.bias
[FREE]: encoder.layer.20.intermediate.dense.weight
[FREE]: encoder.layer.20.intermediate.dense.bias
[FREE]: encoder.layer.20.output.dense.weight
[FREE]: encoder.layer.20.output.dense.bias
[FREE]: encoder.layer.20.output.LayerNorm.weight
[FREE]: encoder.layer.20.output.LayerNorm.bias
[FREE]: encoder.layer.20.output.adapters.ep.adapter_down.0.weight
[FREE]: encoder.layer.20.output.adapters.ep.adapter_down.0.bias
[FREE]: encoder.layer.20.output.adapters.ep.adapter_up.weight
[FREE]: encoder.layer.20.output.adapters.ep.adapter_up.bias
[FREE]: encoder.layer.20.output.adapters.tp.adapter_down.0.weight
[FREE]: encoder.layer.20.output.adapters.tp.adapter_down.0.bias
[FREE]: encoder.layer.20.output.adapters.tp.adapter_up.weight
[FREE]: encoder.layer.20.output.adapters.tp.adapter_up.bias
[FREE]: encoder.layer.20.output.adapters.es.adapter_down.0.weight
[FREE]: encoder.layer.20.output.adapters.es.adapter_down.0.bias
[FREE]: encoder.layer.20.output.adapters.es.adapter_up.weight
[FREE]: encoder.layer.20.output.adapters.es.adapter_up.bias
[FREE]: encoder.layer.20.output.adapters.ts.adapter_down.0.weight
[FREE]: encoder.layer.20.output.adapters.ts.adapter_down.0.bias
[FREE]: encoder.layer.20.output.adapters.ts.adapter_up.weight
[FREE]: encoder.layer.20.output.adapters.ts.adapter_up.bias
[FREE]: encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.query.weight
[FREE]: encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.query.bias
[FREE]: encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.key.weight
[FREE]: encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.key.bias
[FREE]: encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.value.weight
[FREE]: encoder.layer.21.attention.self.query.weight
[FREE]: encoder.layer.21.attention.self.query.bias
[FREE]: encoder.layer.21.attention.self.key.weight
[FREE]: encoder.layer.21.attention.self.key.bias
[FREE]: encoder.layer.21.attention.self.value.weight
[FREE]: encoder.layer.21.attention.self.value.bias
[FREE]: encoder.layer.21.attention.output.dense.weight
[FREE]: encoder.layer.21.attention.output.dense.bias
[FREE]: encoder.layer.21.attention.output.LayerNorm.weight
[FREE]: encoder.layer.21.attention.output.LayerNorm.bias
[FREE]: encoder.layer.21.intermediate.dense.weight
[FREE]: encoder.layer.21.intermediate.dense.bias
[FREE]: encoder.layer.21.output.dense.weight
[FREE]: encoder.layer.21.output.dense.bias
[FREE]: encoder.layer.21.output.LayerNorm.weight
[FREE]: encoder.layer.21.output.LayerNorm.bias
[FREE]: encoder.layer.21.output.adapters.ep.adapter_down.0.weight
[FREE]: encoder.layer.21.output.adapters.ep.adapter_down.0.bias
[FREE]: encoder.layer.21.output.adapters.ep.adapter_up.weight
[FREE]: encoder.layer.21.output.adapters.ep.adapter_up.bias
[FREE]: encoder.layer.21.output.adapters.tp.adapter_down.0.weight
[FREE]: encoder.layer.21.output.adapters.tp.adapter_down.0.bias
[FREE]: encoder.layer.21.output.adapters.tp.adapter_up.weight
[FREE]: encoder.layer.21.output.adapters.tp.adapter_up.bias
[FREE]: encoder.layer.21.output.adapters.es.adapter_down.0.weight
[FREE]: encoder.layer.21.output.adapters.es.adapter_down.0.bias
[FREE]: encoder.layer.21.output.adapters.es.adapter_up.weight
[FREE]: encoder.layer.21.output.adapters.es.adapter_up.bias
[FREE]: encoder.layer.21.output.adapters.ts.adapter_down.0.weight
[FREE]: encoder.layer.21.output.adapters.ts.adapter_down.0.bias
[FREE]: encoder.layer.21.output.adapters.ts.adapter_up.weight
[FREE]: encoder.layer.21.output.adapters.ts.adapter_up.bias
[FREE]: encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.query.weight
[FREE]: encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.query.bias
[FREE]: encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.key.weight
[FREE]: encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.key.bias
[FREE]: encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.value.weight
[FREE]: encoder.layer.22.attention.self.query.weight
[FREE]: encoder.layer.22.attention.self.query.bias
[FREE]: encoder.layer.22.attention.self.key.weight
[FREE]: encoder.layer.22.attention.self.key.bias
[FREE]: encoder.layer.22.attention.self.value.weight
[FREE]: encoder.layer.22.attention.self.value.bias
[FREE]: encoder.layer.22.attention.output.dense.weight
[FREE]: encoder.layer.22.attention.output.dense.bias
[FREE]: encoder.layer.22.attention.output.LayerNorm.weight
[FREE]: encoder.layer.22.attention.output.LayerNorm.bias
[FREE]: encoder.layer.22.intermediate.dense.weight
[FREE]: encoder.layer.22.intermediate.dense.bias
[FREE]: encoder.layer.22.output.dense.weight
[FREE]: encoder.layer.22.output.dense.bias
[FREE]: encoder.layer.22.output.LayerNorm.weight
[FREE]: encoder.layer.22.output.LayerNorm.bias
[FREE]: encoder.layer.22.output.adapters.ep.adapter_down.0.weight
[FREE]: encoder.layer.22.output.adapters.ep.adapter_down.0.bias
[FREE]: encoder.layer.22.output.adapters.ep.adapter_up.weight
[FREE]: encoder.layer.22.output.adapters.ep.adapter_up.bias
[FREE]: encoder.layer.22.output.adapters.tp.adapter_down.0.weight
[FREE]: encoder.layer.22.output.adapters.tp.adapter_down.0.bias
[FREE]: encoder.layer.22.output.adapters.tp.adapter_up.weight
[FREE]: encoder.layer.22.output.adapters.tp.adapter_up.bias
[FREE]: encoder.layer.22.output.adapters.es.adapter_down.0.weight
[FREE]: encoder.layer.22.output.adapters.es.adapter_down.0.bias
[FREE]: encoder.layer.22.output.adapters.es.adapter_up.weight
[FREE]: encoder.layer.22.output.adapters.es.adapter_up.bias
[FREE]: encoder.layer.22.output.adapters.ts.adapter_down.0.weight
[FREE]: encoder.layer.22.output.adapters.ts.adapter_down.0.bias
[FREE]: encoder.layer.22.output.adapters.ts.adapter_up.weight
[FREE]: encoder.layer.22.output.adapters.ts.adapter_up.bias
[FREE]: encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.query.weight
[FREE]: encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.query.bias
[FREE]: encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.key.weight
[FREE]: encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.key.bias
[FREE]: encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.value.weight
[FREE]: encoder.layer.23.attention.self.query.weight
[FREE]: encoder.layer.23.attention.self.query.bias
[FREE]: encoder.layer.23.attention.self.key.weight
[FREE]: encoder.layer.23.attention.self.key.bias
[FREE]: encoder.layer.23.attention.self.value.weight
[FREE]: encoder.layer.23.attention.self.value.bias
[FREE]: encoder.layer.23.attention.output.dense.weight
[FREE]: encoder.layer.23.attention.output.dense.bias
[FREE]: encoder.layer.23.attention.output.LayerNorm.weight
[FREE]: encoder.layer.23.attention.output.LayerNorm.bias
[FREE]: encoder.layer.23.intermediate.dense.weight
[FREE]: encoder.layer.23.intermediate.dense.bias
[FREE]: encoder.layer.23.output.dense.weight
[FREE]: encoder.layer.23.output.dense.bias
[FREE]: encoder.layer.23.output.LayerNorm.weight
[FREE]: encoder.layer.23.output.LayerNorm.bias
[FREE]: encoder.layer.23.output.adapters.ep.adapter_down.0.weight
[FREE]: encoder.layer.23.output.adapters.ep.adapter_down.0.bias
[FREE]: encoder.layer.23.output.adapters.ep.adapter_up.weight
[FREE]: encoder.layer.23.output.adapters.ep.adapter_up.bias
[FREE]: encoder.layer.23.output.adapters.tp.adapter_down.0.weight
[FREE]: encoder.layer.23.output.adapters.tp.adapter_down.0.bias
[FREE]: encoder.layer.23.output.adapters.tp.adapter_up.weight
[FREE]: encoder.layer.23.output.adapters.tp.adapter_up.bias
[FREE]: encoder.layer.23.output.adapters.es.adapter_down.0.weight
[FREE]: encoder.layer.23.output.adapters.es.adapter_down.0.bias
[FREE]: encoder.layer.23.output.adapters.es.adapter_up.weight
[FREE]: encoder.layer.23.output.adapters.es.adapter_up.bias
[FREE]: encoder.layer.23.output.adapters.ts.adapter_down.0.weight
[FREE]: encoder.layer.23.output.adapters.ts.adapter_down.0.bias
[FREE]: encoder.layer.23.output.adapters.ts.adapter_up.weight
[FREE]: encoder.layer.23.output.adapters.ts.adapter_up.bias
[FREE]: encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.query.weight
[FREE]: encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.query.bias
[FREE]: encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.key.weight
[FREE]: encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.key.bias
[FREE]: encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.value.weight
[FREE]: pooler.dense.weight
[FREE]: pooler.dense.bias
  0%|          | 0/15917 [00:00<?, ?it/s]
  0%|          | 0/1724 [00:00<?, ?it/s]
  0%|          | 0/3405 [00:00<?, ?it/s]
  0%|          | 0/501 [00:00<?, ?it/s]
  0%|          | 0/501 [00:00<?, ?it/s]
  0%|          | 0/501 [00:00<?, ?it/s]
  0%|          | 0/501 [00:00<?, ?it/s]
  0%|          | 0/502 [00:00<?, ?it/s]
[1_0,     4/994] loss: 3.796 accuracy: 0.000
[1_0,     8/994] loss: 3.773 accuracy: 0.023
[1_0,    12/994] loss: 3.955 accuracy: 0.021
[1_0,    16/994] loss: 3.311 accuracy: 0.039
[1_0,    20/994] loss: 3.165 accuracy: 0.062
[1_0,    24/994] loss: 3.158 accuracy: 0.073
[1_0,    28/994] loss: 3.429 accuracy: 0.078
[1_0,    32/994] loss: 3.302 accuracy: 0.080
[1_0,    36/994] loss: 3.214 accuracy: 0.085
[1_0,    40/994] loss: 2.938 accuracy: 0.089
[1_0,    44/994] loss: 3.254 accuracy: 0.091
[1_0,    48/994] loss: 3.348 accuracy: 0.089
[1_0,    52/994] loss: 3.761 accuracy: 0.084
[1_0,    56/994] loss: 3.437 accuracy: 0.086
[1_0,    60/994] loss: 3.065 accuracy: 0.089
[1_0,    64/994] loss: 3.367 accuracy: 0.089
[1_0,    68/994] loss: 3.135 accuracy: 0.093
[1_0,    72/994] loss: 3.400 accuracy: 0.091
[1_0,    76/994] loss: 3.333 accuracy: 0.091
[1_0,    80/994] loss: 3.223 accuracy: 0.089
[1_0,    84/994] loss: 3.319 accuracy: 0.088
[1_0,    88/994] loss: 3.438 accuracy: 0.086
[1_0,    92/994] loss: 3.304 accuracy: 0.088
[1_0,    96/994] loss: 3.208 accuracy: 0.090
[1_0,   100/994] loss: 3.142 accuracy: 0.092
[1_0,   104/994] loss: 2.821 accuracy: 0.097
[1_0,   108/994] loss: 2.941 accuracy: 0.099
[1_0,   112/994] loss: 2.962 accuracy: 0.102
[1_0,   116/994] loss: 3.046 accuracy: 0.107
[1_0,   120/994] loss: 3.115 accuracy: 0.108
[1_0,   124/994] loss: 3.155 accuracy: 0.108
[1_0,   128/994] loss: 3.075 accuracy: 0.109
[1_0,   132/994] loss: 2.927 accuracy: 0.113
[1_0,   136/994] loss: 3.114 accuracy: 0.114
[1_0,   140/994] loss: 3.158 accuracy: 0.114
[1_0,   144/994] loss: 3.246 accuracy: 0.113
[1_0,   148/994] loss: 3.080 accuracy: 0.112
[1_0,   152/994] loss: 3.219 accuracy: 0.112
[1_0,   156/994] loss: 2.741 accuracy: 0.115
[1_0,   160/994] loss: 2.950 accuracy: 0.116
[1_0,   164/994] loss: 3.198 accuracy: 0.116
[1_0,   168/994] loss: 3.084 accuracy: 0.117
[1_0,   172/994] loss: 3.164 accuracy: 0.117
[1_0,   176/994] loss: 3.144 accuracy: 0.116
[1_0,   180/994] loss: 2.882 accuracy: 0.116
[1_0,   184/994] loss: 2.893 accuracy: 0.118
[1_0,   188/994] loss: 2.893 accuracy: 0.118
[1_0,   192/994] loss: 3.372 accuracy: 0.118
[1_0,   196/994] loss: 3.199 accuracy: 0.119
[1_0,   200/994] loss: 3.034 accuracy: 0.119
[1_0,   204/994] loss: 2.795 accuracy: 0.120
[1_0,   208/994] loss: 3.125 accuracy: 0.120
[1_0,   212/994] loss: 2.816 accuracy: 0.122
[1_0,   216/994] loss: 3.110 accuracy: 0.122
[1_0,   220/994] loss: 3.003 accuracy: 0.122
[1_0,   224/994] loss: 2.939 accuracy: 0.121
[1_0,   228/994] loss: 3.021 accuracy: 0.121
[1_0,   232/994] loss: 3.317 accuracy: 0.121
[1_0,   236/994] loss: 2.758 accuracy: 0.123
[1_0,   240/994] loss: 3.067 accuracy: 0.124
[1_0,   244/994] loss: 2.733 accuracy: 0.124
[1_0,   248/994] loss: 3.082 accuracy: 0.126
[1_0,   252/994] loss: 2.762 accuracy: 0.127
[1_0,   256/994] loss: 2.915 accuracy: 0.128
[1_0,   260/994] loss: 3.223 accuracy: 0.128
[1_0,   264/994] loss: 2.989 accuracy: 0.129
[1_0,   268/994] loss: 2.965 accuracy: 0.129
[1_0,   272/994] loss: 2.998 accuracy: 0.130
[1_0,   276/994] loss: 2.855 accuracy: 0.130
[1_0,   280/994] loss: 2.942 accuracy: 0.131
[1_0,   284/994] loss: 2.911 accuracy: 0.133
[1_0,   288/994] loss: 2.897 accuracy: 0.134
[1_0,   292/994] loss: 2.791 accuracy: 0.135
[1_0,   296/994] loss: 2.880 accuracy: 0.136
[1_0,   300/994] loss: 2.712 accuracy: 0.138
[1_0,   304/994] loss: 2.710 accuracy: 0.139
[1_0,   308/994] loss: 2.909 accuracy: 0.139
[1_0,   312/994] loss: 2.625 accuracy: 0.140
[1_0,   316/994] loss: 3.018 accuracy: 0.140
[1_0,   320/994] loss: 2.759 accuracy: 0.141
[1_0,   324/994] loss: 2.549 accuracy: 0.143
[1_0,   328/994] loss: 2.927 accuracy: 0.143
[1_0,   332/994] loss: 2.763 accuracy: 0.144
[1_0,   336/994] loss: 2.615 accuracy: 0.144
[1_0,   340/994] loss: 2.943 accuracy: 0.144
[1_0,   344/994] loss: 2.681 accuracy: 0.144
[1_0,   348/994] loss: 2.905 accuracy: 0.145
[1_0,   352/994] loss: 2.658 accuracy: 0.146
[1_0,   356/994] loss: 2.464 accuracy: 0.147
[1_0,   360/994] loss: 2.555 accuracy: 0.147
[1_0,   364/994] loss: 2.728 accuracy: 0.147
[1_0,   368/994] loss: 2.377 accuracy: 0.149
[1_0,   372/994] loss: 2.821 accuracy: 0.149
[1_0,   376/994] loss: 2.537 accuracy: 0.149
[1_0,   380/994] loss: 2.621 accuracy: 0.150
[1_0,   384/994] loss: 2.823 accuracy: 0.149
[1_0,   388/994] loss: 2.720 accuracy: 0.149
[1_0,   392/994] loss: 2.361 accuracy: 0.151
[1_0,   396/994] loss: 2.512 accuracy: 0.151
[1_0,   400/994] loss: 2.513 accuracy: 0.152
[1_0,   404/994] loss: 2.573 accuracy: 0.153
[1_0,   408/994] loss: 2.758 accuracy: 0.153
[1_0,   412/994] loss: 2.691 accuracy: 0.154
[1_0,   416/994] loss: 2.447 accuracy: 0.154
[1_0,   420/994] loss: 2.844 accuracy: 0.154
[1_0,   424/994] loss: 2.596 accuracy: 0.154
[1_0,   428/994] loss: 2.533 accuracy: 0.155
[1_0,   432/994] loss: 2.449 accuracy: 0.156
[1_0,   436/994] loss: 2.630 accuracy: 0.157
[1_0,   440/994] loss: 2.645 accuracy: 0.157
[1_0,   444/994] loss: 2.737 accuracy: 0.158
[1_0,   448/994] loss: 2.578 accuracy: 0.158
[1_0,   452/994] loss: 2.682 accuracy: 0.160
[1_0,   456/994] loss: 2.535 accuracy: 0.160
[1_0,   460/994] loss: 2.566 accuracy: 0.160
[1_0,   464/994] loss: 2.636 accuracy: 0.161
[1_0,   468/994] loss: 2.586 accuracy: 0.162
[1_0,   472/994] loss: 2.615 accuracy: 0.162
[1_0,   476/994] loss: 2.488 accuracy: 0.163
[1_0,   480/994] loss: 2.385 accuracy: 0.164
[1_0,   484/994] loss: 2.816 accuracy: 0.164
[1_0,   488/994] loss: 2.547 accuracy: 0.165
[1_0,   492/994] loss: 2.365 accuracy: 0.165
[1_0,   496/994] loss: 2.217 accuracy: 0.166
[1_0,   500/994] loss: 2.329 accuracy: 0.168
[1_0,   504/994] loss: 2.416 accuracy: 0.168
[1_0,   508/994] loss: 2.341 accuracy: 0.169
[1_0,   512/994] loss: 2.340 accuracy: 0.171
[1_0,   516/994] loss: 2.768 accuracy: 0.172
[1_0,   520/994] loss: 2.483 accuracy: 0.172
[1_0,   524/994] loss: 2.439 accuracy: 0.173
[1_0,   528/994] loss: 2.903 accuracy: 0.173
[1_0,   532/994] loss: 2.123 accuracy: 0.174
[1_0,   536/994] loss: 2.254 accuracy: 0.174
[1_0,   540/994] loss: 2.446 accuracy: 0.174
[1_0,   544/994] loss: 2.505 accuracy: 0.175
[1_0,   548/994] loss: 2.051 accuracy: 0.176
[1_0,   552/994] loss: 2.177 accuracy: 0.178
[1_0,   556/994] loss: 2.478 accuracy: 0.177
[1_0,   560/994] loss: 2.546 accuracy: 0.178
[1_0,   564/994] loss: 2.369 accuracy: 0.178
[1_0,   568/994] loss: 2.268 accuracy: 0.179
[1_0,   572/994] loss: 2.381 accuracy: 0.180
[1_0,   576/994] loss: 2.376 accuracy: 0.181
[1_0,   580/994] loss: 2.240 accuracy: 0.182
[1_0,   584/994] loss: 2.081 accuracy: 0.183
[1_0,   588/994] loss: 1.813 accuracy: 0.185
[1_0,   592/994] loss: 2.173 accuracy: 0.186
[1_0,   596/994] loss: 1.869 accuracy: 0.188
[1_0,   600/994] loss: 1.826 accuracy: 0.190
[1_0,   604/994] loss: 1.936 accuracy: 0.191
[1_0,   608/994] loss: 2.269 accuracy: 0.192
[1_0,   612/994] loss: 2.256 accuracy: 0.193
[1_0,   616/994] loss: 2.309 accuracy: 0.194
[1_0,   620/994] loss: 2.334 accuracy: 0.194
[1_0,   624/994] loss: 2.033 accuracy: 0.195
[1_0,   628/994] loss: 1.955 accuracy: 0.197
[1_0,   632/994] loss: 2.335 accuracy: 0.197
[1_0,   636/994] loss: 2.035 accuracy: 0.198
[1_0,   640/994] loss: 2.001 accuracy: 0.199
[1_0,   644/994] loss: 2.127 accuracy: 0.200
[1_0,   648/994] loss: 2.034 accuracy: 0.202
[1_0,   652/994] loss: 1.919 accuracy: 0.203
[1_0,   656/994] loss: 2.007 accuracy: 0.204
[1_0,   660/994] loss: 1.803 accuracy: 0.205
[1_0,   664/994] loss: 2.216 accuracy: 0.206
[1_0,   668/994] loss: 1.821 accuracy: 0.208
[1_0,   672/994] loss: 2.513 accuracy: 0.208
[1_0,   676/994] loss: 1.899 accuracy: 0.209
[1_0,   680/994] loss: 2.086 accuracy: 0.210
[1_0,   684/994] loss: 2.264 accuracy: 0.210
[1_0,   688/994] loss: 1.802 accuracy: 0.211
[1_0,   692/994] loss: 1.898 accuracy: 0.212
[1_0,   696/994] loss: 1.930 accuracy: 0.213
[1_0,   700/994] loss: 2.277 accuracy: 0.213
[1_0,   704/994] loss: 1.991 accuracy: 0.215
[1_0,   708/994] loss: 1.938 accuracy: 0.216
[1_0,   712/994] loss: 2.113 accuracy: 0.216
[1_0,   716/994] loss: 1.867 accuracy: 0.217
[1_0,   720/994] loss: 1.915 accuracy: 0.218
[1_0,   724/994] loss: 2.473 accuracy: 0.218
[1_0,   728/994] loss: 1.902 accuracy: 0.219
[1_0,   732/994] loss: 1.563 accuracy: 0.220
[1_0,   736/994] loss: 1.897 accuracy: 0.221
[1_0,   740/994] loss: 1.809 accuracy: 0.223
[1_0,   744/994] loss: 1.895 accuracy: 0.224
[1_0,   748/994] loss: 2.210 accuracy: 0.224
[1_0,   752/994] loss: 1.925 accuracy: 0.225
[1_0,   756/994] loss: 1.661 accuracy: 0.227
[1_0,   760/994] loss: 1.862 accuracy: 0.228
[1_0,   764/994] loss: 1.755 accuracy: 0.229
[1_0,   768/994] loss: 2.010 accuracy: 0.229
[1_0,   772/994] loss: 2.084 accuracy: 0.230
[1_0,   776/994] loss: 1.933 accuracy: 0.231
[1_0,   780/994] loss: 1.829 accuracy: 0.232
[1_0,   784/994] loss: 2.008 accuracy: 0.232
[1_0,   788/994] loss: 1.806 accuracy: 0.234
[1_0,   792/994] loss: 1.731 accuracy: 0.235
[1_0,   796/994] loss: 2.130 accuracy: 0.235
[1_0,   800/994] loss: 1.804 accuracy: 0.236
[1_0,   804/994] loss: 1.864 accuracy: 0.237
[1_0,   808/994] loss: 1.851 accuracy: 0.237
[1_0,   812/994] loss: 1.682 accuracy: 0.238
[1_0,   816/994] loss: 1.588 accuracy: 0.240
[1_0,   820/994] loss: 2.197 accuracy: 0.241
[1_0,   824/994] loss: 2.430 accuracy: 0.241
[1_0,   828/994] loss: 1.908 accuracy: 0.241
[1_0,   832/994] loss: 1.821 accuracy: 0.242
[1_0,   836/994] loss: 1.911 accuracy: 0.242
[1_0,   840/994] loss: 1.742 accuracy: 0.243
[1_0,   844/994] loss: 1.819 accuracy: 0.244
[1_0,   848/994] loss: 1.780 accuracy: 0.245
[1_0,   852/994] loss: 1.777 accuracy: 0.246
[1_0,   856/994] loss: 2.050 accuracy: 0.246
[1_0,   860/994] loss: 1.768 accuracy: 0.247
[1_0,   864/994] loss: 1.983 accuracy: 0.248
[1_0,   868/994] loss: 1.862 accuracy: 0.248
[1_0,   872/994] loss: 1.823 accuracy: 0.249
[1_0,   876/994] loss: 2.330 accuracy: 0.249
[1_0,   880/994] loss: 2.182 accuracy: 0.249
[1_0,   884/994] loss: 1.955 accuracy: 0.250
[1_0,   888/994] loss: 1.606 accuracy: 0.251
[1_0,   892/994] loss: 2.741 accuracy: 0.251
[1_0,   896/994] loss: 2.092 accuracy: 0.251
[1_0,   900/994] loss: 2.089 accuracy: 0.252
[1_0,   904/994] loss: 1.893 accuracy: 0.252
[1_0,   908/994] loss: 1.653 accuracy: 0.254
[1_0,   912/994] loss: 1.579 accuracy: 0.255
[1_0,   916/994] loss: 1.663 accuracy: 0.256
[1_0,   920/994] loss: 1.892 accuracy: 0.256
[1_0,   924/994] loss: 1.681 accuracy: 0.257
[1_0,   928/994] loss: 1.685 accuracy: 0.258
[1_0,   932/994] loss: 2.232 accuracy: 0.258
[1_0,   936/994] loss: 1.479 accuracy: 0.259
[1_0,   940/994] loss: 1.946 accuracy: 0.260
[1_0,   944/994] loss: 2.076 accuracy: 0.260
[1_0,   948/994] loss: 1.695 accuracy: 0.261
[1_0,   952/994] loss: 1.358 accuracy: 0.262
[1_0,   956/994] loss: 2.084 accuracy: 0.263
[1_0,   960/994] loss: 1.948 accuracy: 0.263
[1_0,   964/994] loss: 2.290 accuracy: 0.263
[1_0,   968/994] loss: 1.527 accuracy: 0.265
[1_0,   972/994] loss: 1.885 accuracy: 0.265
[1_0,   976/994] loss: 1.759 accuracy: 0.266
[1_0,   980/994] loss: 2.000 accuracy: 0.267
[1_0,   984/994] loss: 1.748 accuracy: 0.267
[1_0,   988/994] loss: 2.013 accuracy: 0.268
[1_0,   992/994] loss: 1.678 accuracy: 0.269
2022-05-06 11:27:47.782986  :  0.32064696759780864 is higher than the best(0). Saving the model at ../Models/KBP37/bert_multilingual_adam_finetune_kbp37_1_0.3239109352817232_sigmoid_long2.pt
Epoch:  1
Training Loss: 613.5883, Val Loss: 1.9494, Test Loss: 1.9612
Training accuracy:0.2692, Training F1:0.1889, Validation accuracy:0.3782, Validation F1:0.3206, Test accuracy:0.3815, Test F1:0.3239
German F1: 0.3128, English F1: 0.3144, Spanish F1: 0.3025, French F1: 0.2807, Turkish F1: 0.2653
[2_0,     4/994] loss: 1.720 accuracy: 0.422
[2_0,     8/994] loss: 1.582 accuracy: 0.445
[2_0,    12/994] loss: 1.986 accuracy: 0.417
[2_0,    16/994] loss: 1.609 accuracy: 0.426
[2_0,    20/994] loss: 1.419 accuracy: 0.447
[2_0,    24/994] loss: 1.518 accuracy: 0.443
[2_0,    28/994] loss: 1.918 accuracy: 0.431
[2_0,    32/994] loss: 1.564 accuracy: 0.436
[2_0,    36/994] loss: 1.723 accuracy: 0.432
[2_0,    40/994] loss: 1.743 accuracy: 0.434
[2_0,    44/994] loss: 1.869 accuracy: 0.430
[2_0,    48/994] loss: 1.402 accuracy: 0.439
[2_0,    52/994] loss: 1.419 accuracy: 0.442
[2_0,    56/994] loss: 1.452 accuracy: 0.452
[2_0,    60/994] loss: 1.527 accuracy: 0.456
[2_0,    64/994] loss: 1.655 accuracy: 0.456
[2_0,    68/994] loss: 1.526 accuracy: 0.460
[2_0,    72/994] loss: 1.583 accuracy: 0.465
[2_0,    76/994] loss: 1.502 accuracy: 0.465
[2_0,    80/994] loss: 1.398 accuracy: 0.470
[2_0,    84/994] loss: 1.744 accuracy: 0.467
[2_0,    88/994] loss: 1.643 accuracy: 0.467
[2_0,    92/994] loss: 1.440 accuracy: 0.471
[2_0,    96/994] loss: 1.740 accuracy: 0.471
[2_0,   100/994] loss: 1.265 accuracy: 0.476
[2_0,   104/994] loss: 1.490 accuracy: 0.475
[2_0,   108/994] loss: 1.451 accuracy: 0.478
[2_0,   112/994] loss: 1.652 accuracy: 0.478
[2_0,   116/994] loss: 1.624 accuracy: 0.478
[2_0,   120/994] loss: 1.548 accuracy: 0.477
[2_0,   124/994] loss: 1.267 accuracy: 0.480
[2_0,   128/994] loss: 1.648 accuracy: 0.478
[2_0,   132/994] loss: 1.336 accuracy: 0.479
[2_0,   136/994] loss: 1.435 accuracy: 0.478
[2_0,   140/994] loss: 1.477 accuracy: 0.479
[2_0,   144/994] loss: 1.713 accuracy: 0.477
[2_0,   148/994] loss: 1.593 accuracy: 0.479
[2_0,   152/994] loss: 1.578 accuracy: 0.479
[2_0,   156/994] loss: 1.474 accuracy: 0.481
[2_0,   160/994] loss: 1.854 accuracy: 0.480
[2_0,   164/994] loss: 1.767 accuracy: 0.479
[2_0,   168/994] loss: 1.459 accuracy: 0.482
[2_0,   172/994] loss: 1.694 accuracy: 0.483
[2_0,   176/994] loss: 1.543 accuracy: 0.483
[2_0,   180/994] loss: 1.830 accuracy: 0.481
[2_0,   184/994] loss: 1.792 accuracy: 0.480
[2_0,   188/994] loss: 1.616 accuracy: 0.479
[2_0,   192/994] loss: 1.786 accuracy: 0.478
[2_0,   196/994] loss: 1.527 accuracy: 0.477
[2_0,   200/994] loss: 1.738 accuracy: 0.476
[2_0,   204/994] loss: 1.398 accuracy: 0.478
[2_0,   208/994] loss: 1.594 accuracy: 0.479
[2_0,   212/994] loss: 1.615 accuracy: 0.479
[2_0,   216/994] loss: 1.417 accuracy: 0.482
[2_0,   220/994] loss: 1.787 accuracy: 0.481
[2_0,   224/994] loss: 1.288 accuracy: 0.482
[2_0,   228/994] loss: 1.578 accuracy: 0.483
[2_0,   232/994] loss: 1.552 accuracy: 0.482
[2_0,   236/994] loss: 1.359 accuracy: 0.483
[2_0,   240/994] loss: 1.602 accuracy: 0.482
[2_0,   244/994] loss: 1.635 accuracy: 0.482
[2_0,   248/994] loss: 1.301 accuracy: 0.484
[2_0,   252/994] loss: 1.492 accuracy: 0.484
[2_0,   256/994] loss: 1.388 accuracy: 0.485
[2_0,   260/994] loss: 1.539 accuracy: 0.485
[2_0,   264/994] loss: 1.408 accuracy: 0.486
[2_0,   268/994] loss: 1.790 accuracy: 0.485
[2_0,   272/994] loss: 1.418 accuracy: 0.484
[2_0,   276/994] loss: 1.660 accuracy: 0.483
[2_0,   280/994] loss: 1.482 accuracy: 0.485
[2_0,   284/994] loss: 1.498 accuracy: 0.485
[2_0,   288/994] loss: 1.359 accuracy: 0.487
[2_0,   292/994] loss: 1.233 accuracy: 0.488
[2_0,   296/994] loss: 1.028 accuracy: 0.489
[2_0,   300/994] loss: 1.546 accuracy: 0.489
[2_0,   304/994] loss: 1.540 accuracy: 0.489
[2_0,   308/994] loss: 1.577 accuracy: 0.490
[2_0,   312/994] loss: 1.429 accuracy: 0.491
[2_0,   316/994] loss: 1.365 accuracy: 0.492
[2_0,   320/994] loss: 1.236 accuracy: 0.494
[2_0,   324/994] loss: 1.362 accuracy: 0.494
[2_0,   328/994] loss: 1.273 accuracy: 0.494
[2_0,   332/994] loss: 1.621 accuracy: 0.495
[2_0,   336/994] loss: 1.179 accuracy: 0.496
[2_0,   340/994] loss: 1.461 accuracy: 0.497
[2_0,   344/994] loss: 1.316 accuracy: 0.496
[2_0,   348/994] loss: 1.388 accuracy: 0.497
[2_0,   352/994] loss: 1.396 accuracy: 0.497
[2_0,   356/994] loss: 1.411 accuracy: 0.497
[2_0,   360/994] loss: 1.392 accuracy: 0.498
[2_0,   364/994] loss: 1.415 accuracy: 0.498
[2_0,   368/994] loss: 1.443 accuracy: 0.499
[2_0,   372/994] loss: 1.490 accuracy: 0.500
[2_0,   376/994] loss: 1.335 accuracy: 0.501
[2_0,   380/994] loss: 1.255 accuracy: 0.501
[2_0,   384/994] loss: 1.528 accuracy: 0.502
[2_0,   388/994] loss: 1.211 accuracy: 0.502
[2_0,   392/994] loss: 1.323 accuracy: 0.503
[2_0,   396/994] loss: 1.431 accuracy: 0.503
[2_0,   400/994] loss: 1.257 accuracy: 0.504
[2_0,   404/994] loss: 1.592 accuracy: 0.503
[2_0,   408/994] loss: 1.591 accuracy: 0.503
[2_0,   412/994] loss: 1.614 accuracy: 0.503
[2_0,   416/994] loss: 1.619 accuracy: 0.502
[2_0,   420/994] loss: 1.299 accuracy: 0.502
[2_0,   424/994] loss: 1.222 accuracy: 0.503
[2_0,   428/994] loss: 1.498 accuracy: 0.502
[2_0,   432/994] loss: 1.464 accuracy: 0.503
[2_0,   436/994] loss: 1.518 accuracy: 0.503
[2_0,   440/994] loss: 1.325 accuracy: 0.504
[2_0,   444/994] loss: 1.330 accuracy: 0.505
[2_0,   448/994] loss: 1.654 accuracy: 0.504
[2_0,   452/994] loss: 1.673 accuracy: 0.504
[2_0,   456/994] loss: 1.594 accuracy: 0.504
[2_0,   460/994] loss: 1.587 accuracy: 0.504
[2_0,   464/994] loss: 1.072 accuracy: 0.505
[2_0,   468/994] loss: 1.527 accuracy: 0.505
[2_0,   472/994] loss: 1.091 accuracy: 0.505
[2_0,   476/994] loss: 1.254 accuracy: 0.506
[2_0,   480/994] loss: 1.478 accuracy: 0.506
[2_0,   484/994] loss: 1.591 accuracy: 0.506
[2_0,   488/994] loss: 1.406 accuracy: 0.506
[2_0,   492/994] loss: 1.398 accuracy: 0.505
[2_0,   496/994] loss: 1.018 accuracy: 0.507
[2_0,   500/994] loss: 1.731 accuracy: 0.507
[2_0,   504/994] loss: 1.327 accuracy: 0.507
[2_0,   508/994] loss: 1.707 accuracy: 0.507
[2_0,   512/994] loss: 1.801 accuracy: 0.506
[2_0,   516/994] loss: 1.257 accuracy: 0.506
[2_0,   520/994] loss: 1.230 accuracy: 0.507
[2_0,   524/994] loss: 1.453 accuracy: 0.506
[2_0,   528/994] loss: 1.762 accuracy: 0.506
[2_0,   532/994] loss: 1.197 accuracy: 0.506
[2_0,   536/994] loss: 1.308 accuracy: 0.506
[2_0,   540/994] loss: 1.024 accuracy: 0.507
[2_0,   544/994] loss: 1.107 accuracy: 0.508
[2_0,   548/994] loss: 1.582 accuracy: 0.508
[2_0,   552/994] loss: 1.123 accuracy: 0.509
[2_0,   556/994] loss: 1.393 accuracy: 0.510
[2_0,   560/994] loss: 1.410 accuracy: 0.510
[2_0,   564/994] loss: 1.502 accuracy: 0.510
[2_0,   568/994] loss: 1.575 accuracy: 0.510
[2_0,   572/994] loss: 1.793 accuracy: 0.509
[2_0,   576/994] loss: 1.629 accuracy: 0.509
[2_0,   580/994] loss: 1.603 accuracy: 0.509
[2_0,   584/994] loss: 1.738 accuracy: 0.508
[2_0,   588/994] loss: 1.229 accuracy: 0.509
[2_0,   592/994] loss: 1.292 accuracy: 0.508
[2_0,   596/994] loss: 1.687 accuracy: 0.508
[2_0,   600/994] loss: 1.293 accuracy: 0.508
[2_0,   604/994] loss: 1.449 accuracy: 0.508
[2_0,   608/994] loss: 1.244 accuracy: 0.508
[2_0,   612/994] loss: 1.375 accuracy: 0.509
[2_0,   616/994] loss: 1.289 accuracy: 0.509
[2_0,   620/994] loss: 1.204 accuracy: 0.510
[2_0,   624/994] loss: 1.361 accuracy: 0.510
[2_0,   628/994] loss: 0.927 accuracy: 0.511
[2_0,   632/994] loss: 1.161 accuracy: 0.512
[2_0,   636/994] loss: 1.531 accuracy: 0.512
[2_0,   640/994] loss: 1.760 accuracy: 0.512
[2_0,   644/994] loss: 1.507 accuracy: 0.512
[2_0,   648/994] loss: 1.369 accuracy: 0.513
[2_0,   652/994] loss: 1.090 accuracy: 0.513
[2_0,   656/994] loss: 1.154 accuracy: 0.514
[2_0,   660/994] loss: 1.424 accuracy: 0.514
[2_0,   664/994] loss: 1.139 accuracy: 0.515
[2_0,   668/994] loss: 1.126 accuracy: 0.516
[2_0,   672/994] loss: 1.153 accuracy: 0.516
[2_0,   676/994] loss: 1.337 accuracy: 0.517
[2_0,   680/994] loss: 1.377 accuracy: 0.517
[2_0,   684/994] loss: 1.533 accuracy: 0.517
[2_0,   688/994] loss: 1.316 accuracy: 0.517
[2_0,   692/994] loss: 1.133 accuracy: 0.518
[2_0,   696/994] loss: 1.254 accuracy: 0.518
[2_0,   700/994] loss: 1.579 accuracy: 0.518
[2_0,   704/994] loss: 1.379 accuracy: 0.518
[2_0,   708/994] loss: 1.243 accuracy: 0.519
[2_0,   712/994] loss: 1.559 accuracy: 0.519
[2_0,   716/994] loss: 1.651 accuracy: 0.518
[2_0,   720/994] loss: 1.396 accuracy: 0.518
[2_0,   724/994] loss: 1.200 accuracy: 0.518
[2_0,   728/994] loss: 1.657 accuracy: 0.517
[2_0,   732/994] loss: 1.253 accuracy: 0.518
[2_0,   736/994] loss: 1.817 accuracy: 0.517
[2_0,   740/994] loss: 1.404 accuracy: 0.517
[2_0,   744/994] loss: 1.297 accuracy: 0.517
[2_0,   748/994] loss: 1.301 accuracy: 0.518
[2_0,   752/994] loss: 1.193 accuracy: 0.518
[2_0,   756/994] loss: 1.142 accuracy: 0.519
[2_0,   760/994] loss: 1.682 accuracy: 0.518
[2_0,   764/994] loss: 1.351 accuracy: 0.519
[2_0,   768/994] loss: 1.137 accuracy: 0.519
[2_0,   772/994] loss: 1.419 accuracy: 0.519
[2_0,   776/994] loss: 1.338 accuracy: 0.519
[2_0,   780/994] loss: 1.094 accuracy: 0.520
[2_0,   784/994] loss: 1.408 accuracy: 0.520
[2_0,   788/994] loss: 1.680 accuracy: 0.520
[2_0,   792/994] loss: 1.323 accuracy: 0.520
[2_0,   796/994] loss: 1.354 accuracy: 0.520
[2_0,   800/994] loss: 1.586 accuracy: 0.520
[2_0,   804/994] loss: 1.389 accuracy: 0.520
[2_0,   808/994] loss: 1.385 accuracy: 0.521
[2_0,   812/994] loss: 1.539 accuracy: 0.521
[2_0,   816/994] loss: 1.334 accuracy: 0.521
[2_0,   820/994] loss: 1.531 accuracy: 0.521
[2_0,   824/994] loss: 1.589 accuracy: 0.521
[2_0,   828/994] loss: 1.239 accuracy: 0.521
[2_0,   832/994] loss: 1.280 accuracy: 0.521
[2_0,   836/994] loss: 1.365 accuracy: 0.521
[2_0,   840/994] loss: 1.300 accuracy: 0.522
[2_0,   844/994] loss: 1.133 accuracy: 0.522
[2_0,   848/994] loss: 1.203 accuracy: 0.522
[2_0,   852/994] loss: 1.213 accuracy: 0.522
[2_0,   856/994] loss: 1.222 accuracy: 0.522
[2_0,   860/994] loss: 1.296 accuracy: 0.523
[2_0,   864/994] loss: 1.126 accuracy: 0.523
[2_0,   868/994] loss: 1.419 accuracy: 0.523
[2_0,   872/994] loss: 1.447 accuracy: 0.523
[2_0,   876/994] loss: 1.240 accuracy: 0.524
[2_0,   880/994] loss: 1.455 accuracy: 0.524
[2_0,   884/994] loss: 1.208 accuracy: 0.525
[2_0,   888/994] loss: 1.303 accuracy: 0.525
[2_0,   892/994] loss: 1.381 accuracy: 0.525
[2_0,   896/994] loss: 1.280 accuracy: 0.525
[2_0,   900/994] loss: 1.429 accuracy: 0.525
[2_0,   904/994] loss: 1.219 accuracy: 0.525
[2_0,   908/994] loss: 1.346 accuracy: 0.525
[2_0,   912/994] loss: 1.090 accuracy: 0.525
[2_0,   916/994] loss: 1.114 accuracy: 0.526
[2_0,   920/994] loss: 0.856 accuracy: 0.527
[2_0,   924/994] loss: 1.031 accuracy: 0.528
[2_0,   928/994] loss: 1.309 accuracy: 0.528
[2_0,   932/994] loss: 0.964 accuracy: 0.528
[2_0,   936/994] loss: 1.214 accuracy: 0.529
[2_0,   940/994] loss: 1.232 accuracy: 0.529
[2_0,   944/994] loss: 1.241 accuracy: 0.529
[2_0,   948/994] loss: 1.307 accuracy: 0.530
[2_0,   952/994] loss: 1.192 accuracy: 0.530
[2_0,   956/994] loss: 1.583 accuracy: 0.530
[2_0,   960/994] loss: 1.280 accuracy: 0.530
[2_0,   964/994] loss: 1.522 accuracy: 0.530
[2_0,   968/994] loss: 1.530 accuracy: 0.530
[2_0,   972/994] loss: 1.259 accuracy: 0.531
[2_0,   976/994] loss: 1.085 accuracy: 0.531
[2_0,   980/994] loss: 1.216 accuracy: 0.532
[2_0,   984/994] loss: 1.133 accuracy: 0.532
[2_0,   988/994] loss: 1.258 accuracy: 0.532
[2_0,   992/994] loss: 1.262 accuracy: 0.532
2022-05-06 11:53:35.003138  :  0.5384707046739196 is higher than the best(0.32064696759780864). Saving the model at ../Models/KBP37/bert_multilingual_adam_finetune_kbp37_2_0.5432092623378186_sigmoid_long2.pt
Epoch:  2
Training Loss: 352.8198, Val Loss: 1.4960, Test Loss: 1.4816
Training accuracy:0.5327, Training F1:0.4967, Validation accuracy:0.5360, Validation F1:0.5385, Test accuracy:0.5463, Test F1:0.5432
German F1: 0.5078, English F1: 0.5362, Spanish F1: 0.5288, French F1: 0.4799, Turkish F1: 0.4628
[3_0,     4/994] loss: 1.331 accuracy: 0.547
[3_0,     8/994] loss: 0.984 accuracy: 0.578
[3_0,    12/994] loss: 1.411 accuracy: 0.531
[3_0,    16/994] loss: 1.283 accuracy: 0.551
[3_0,    20/994] loss: 1.290 accuracy: 0.553
[3_0,    24/994] loss: 0.967 accuracy: 0.562
[3_0,    28/994] loss: 1.287 accuracy: 0.558
[3_0,    32/994] loss: 1.116 accuracy: 0.568
[3_0,    36/994] loss: 1.142 accuracy: 0.573
[3_0,    40/994] loss: 0.941 accuracy: 0.581
[3_0,    44/994] loss: 1.018 accuracy: 0.588
[3_0,    48/994] loss: 1.291 accuracy: 0.586
[3_0,    52/994] loss: 1.015 accuracy: 0.596
[3_0,    56/994] loss: 0.885 accuracy: 0.606
[3_0,    60/994] loss: 1.329 accuracy: 0.603
[3_0,    64/994] loss: 1.374 accuracy: 0.600
[3_0,    68/994] loss: 1.296 accuracy: 0.602
[3_0,    72/994] loss: 1.160 accuracy: 0.601
[3_0,    76/994] loss: 1.348 accuracy: 0.602
[3_0,    80/994] loss: 1.334 accuracy: 0.602
[3_0,    84/994] loss: 1.290 accuracy: 0.600
[3_0,    88/994] loss: 1.266 accuracy: 0.600
[3_0,    92/994] loss: 1.355 accuracy: 0.599
[3_0,    96/994] loss: 1.014 accuracy: 0.600
[3_0,   100/994] loss: 1.136 accuracy: 0.599
[3_0,   104/994] loss: 1.084 accuracy: 0.600
[3_0,   108/994] loss: 1.090 accuracy: 0.600
[3_0,   112/994] loss: 0.946 accuracy: 0.600
[3_0,   116/994] loss: 0.893 accuracy: 0.603
[3_0,   120/994] loss: 1.089 accuracy: 0.605
[3_0,   124/994] loss: 1.056 accuracy: 0.605
[3_0,   128/994] loss: 1.819 accuracy: 0.601
[3_0,   132/994] loss: 1.202 accuracy: 0.605
[3_0,   136/994] loss: 1.062 accuracy: 0.608
[3_0,   140/994] loss: 1.257 accuracy: 0.608
[3_0,   144/994] loss: 1.322 accuracy: 0.609
[3_0,   148/994] loss: 1.690 accuracy: 0.606
[3_0,   152/994] loss: 0.857 accuracy: 0.608
[3_0,   156/994] loss: 1.354 accuracy: 0.610
[3_0,   160/994] loss: 1.135 accuracy: 0.609
[3_0,   164/994] loss: 1.201 accuracy: 0.609
[3_0,   168/994] loss: 0.984 accuracy: 0.611
[3_0,   172/994] loss: 1.164 accuracy: 0.612
[3_0,   176/994] loss: 1.597 accuracy: 0.608
[3_0,   180/994] loss: 0.763 accuracy: 0.611
[3_0,   184/994] loss: 0.971 accuracy: 0.612
[3_0,   188/994] loss: 1.275 accuracy: 0.611
[3_0,   192/994] loss: 1.126 accuracy: 0.611
[3_0,   196/994] loss: 0.851 accuracy: 0.613
[3_0,   200/994] loss: 1.124 accuracy: 0.613
[3_0,   204/994] loss: 1.177 accuracy: 0.614
[3_0,   208/994] loss: 1.327 accuracy: 0.614
[3_0,   212/994] loss: 0.893 accuracy: 0.615
[3_0,   216/994] loss: 1.190 accuracy: 0.615
[3_0,   220/994] loss: 1.005 accuracy: 0.615
[3_0,   224/994] loss: 1.525 accuracy: 0.615
[3_0,   228/994] loss: 1.182 accuracy: 0.614
[3_0,   232/994] loss: 1.221 accuracy: 0.614
[3_0,   236/994] loss: 1.497 accuracy: 0.614
[3_0,   240/994] loss: 1.322 accuracy: 0.614
[3_0,   244/994] loss: 1.140 accuracy: 0.614
[3_0,   248/994] loss: 1.128 accuracy: 0.613
[3_0,   252/994] loss: 1.096 accuracy: 0.614
[3_0,   256/994] loss: 0.989 accuracy: 0.615
[3_0,   260/994] loss: 0.963 accuracy: 0.617
[3_0,   264/994] loss: 0.925 accuracy: 0.617
[3_0,   268/994] loss: 1.248 accuracy: 0.616
[3_0,   272/994] loss: 0.999 accuracy: 0.617
[3_0,   276/994] loss: 1.244 accuracy: 0.617
[3_0,   280/994] loss: 1.424 accuracy: 0.616
[3_0,   284/994] loss: 0.984 accuracy: 0.616
[3_0,   288/994] loss: 1.018 accuracy: 0.617
[3_0,   292/994] loss: 1.216 accuracy: 0.617
[3_0,   296/994] loss: 1.024 accuracy: 0.617
[3_0,   300/994] loss: 1.078 accuracy: 0.617
[3_0,   304/994] loss: 0.946 accuracy: 0.617
[3_0,   308/994] loss: 1.033 accuracy: 0.618
[3_0,   312/994] loss: 1.600 accuracy: 0.618
[3_0,   316/994] loss: 1.424 accuracy: 0.616
[3_0,   320/994] loss: 1.044 accuracy: 0.617
[3_0,   324/994] loss: 1.280 accuracy: 0.616
[3_0,   328/994] loss: 1.300 accuracy: 0.615
[3_0,   332/994] loss: 1.344 accuracy: 0.614
[3_0,   336/994] loss: 1.406 accuracy: 0.614
[3_0,   340/994] loss: 1.044 accuracy: 0.615
[3_0,   344/994] loss: 1.281 accuracy: 0.614
[3_0,   348/994] loss: 1.149 accuracy: 0.614
[3_0,   352/994] loss: 1.184 accuracy: 0.614
[3_0,   356/994] loss: 1.351 accuracy: 0.614
[3_0,   360/994] loss: 0.936 accuracy: 0.615
[3_0,   364/994] loss: 0.935 accuracy: 0.615
[3_0,   368/994] loss: 1.128 accuracy: 0.616
[3_0,   372/994] loss: 1.231 accuracy: 0.616
[3_0,   376/994] loss: 0.951 accuracy: 0.616
[3_0,   380/994] loss: 1.015 accuracy: 0.615
[3_0,   384/994] loss: 0.888 accuracy: 0.617
[3_0,   388/994] loss: 0.999 accuracy: 0.617
[3_0,   392/994] loss: 0.973 accuracy: 0.617
[3_0,   396/994] loss: 1.596 accuracy: 0.616
[3_0,   400/994] loss: 1.121 accuracy: 0.617
[3_0,   404/994] loss: 1.107 accuracy: 0.618
[3_0,   408/994] loss: 1.312 accuracy: 0.617
[3_0,   412/994] loss: 1.353 accuracy: 0.617
[3_0,   416/994] loss: 1.453 accuracy: 0.616
[3_0,   420/994] loss: 0.854 accuracy: 0.617
[3_0,   424/994] loss: 1.082 accuracy: 0.617
[3_0,   428/994] loss: 0.948 accuracy: 0.617
[3_0,   432/994] loss: 1.111 accuracy: 0.617
[3_0,   436/994] loss: 1.001 accuracy: 0.617
[3_0,   440/994] loss: 1.180 accuracy: 0.617
[3_0,   444/994] loss: 1.030 accuracy: 0.617
[3_0,   448/994] loss: 0.959 accuracy: 0.618
[3_0,   452/994] loss: 0.976 accuracy: 0.618
[3_0,   456/994] loss: 1.095 accuracy: 0.619
[3_0,   460/994] loss: 1.028 accuracy: 0.619
[3_0,   464/994] loss: 0.854 accuracy: 0.620
[3_0,   468/994] loss: 1.394 accuracy: 0.619
[3_0,   472/994] loss: 1.082 accuracy: 0.619
[3_0,   476/994] loss: 1.061 accuracy: 0.619
[3_0,   480/994] loss: 1.018 accuracy: 0.619
[3_0,   484/994] loss: 1.261 accuracy: 0.619
[3_0,   488/994] loss: 0.984 accuracy: 0.619
[3_0,   492/994] loss: 0.942 accuracy: 0.620
[3_0,   496/994] loss: 1.044 accuracy: 0.620
[3_0,   500/994] loss: 0.977 accuracy: 0.620
[3_0,   504/994] loss: 1.202 accuracy: 0.620
[3_0,   508/994] loss: 1.235 accuracy: 0.620
[3_0,   512/994] loss: 1.240 accuracy: 0.620
[3_0,   516/994] loss: 1.207 accuracy: 0.620
[3_0,   520/994] loss: 1.058 accuracy: 0.621
[3_0,   524/994] loss: 1.182 accuracy: 0.621
[3_0,   528/994] loss: 1.326 accuracy: 0.621
[3_0,   532/994] loss: 1.182 accuracy: 0.621
[3_0,   536/994] loss: 1.334 accuracy: 0.621
[3_0,   540/994] loss: 0.877 accuracy: 0.622
[3_0,   544/994] loss: 1.133 accuracy: 0.622
[3_0,   548/994] loss: 1.327 accuracy: 0.622
[3_0,   552/994] loss: 1.009 accuracy: 0.622
[3_0,   556/994] loss: 1.369 accuracy: 0.621
[3_0,   560/994] loss: 1.082 accuracy: 0.620
[3_0,   564/994] loss: 0.976 accuracy: 0.620
[3_0,   568/994] loss: 1.363 accuracy: 0.619
[3_0,   572/994] loss: 1.127 accuracy: 0.619
[3_0,   576/994] loss: 1.103 accuracy: 0.619
[3_0,   580/994] loss: 0.899 accuracy: 0.620
[3_0,   584/994] loss: 1.448 accuracy: 0.619
[3_0,   588/994] loss: 1.256 accuracy: 0.619
[3_0,   592/994] loss: 1.328 accuracy: 0.618
[3_0,   596/994] loss: 1.031 accuracy: 0.619
[3_0,   600/994] loss: 1.279 accuracy: 0.619
[3_0,   604/994] loss: 1.021 accuracy: 0.620
[3_0,   608/994] loss: 1.012 accuracy: 0.619
[3_0,   612/994] loss: 1.245 accuracy: 0.619
[3_0,   616/994] loss: 1.026 accuracy: 0.619
[3_0,   620/994] loss: 0.954 accuracy: 0.619
[3_0,   624/994] loss: 1.482 accuracy: 0.618
[3_0,   628/994] loss: 0.785 accuracy: 0.619
[3_0,   632/994] loss: 1.307 accuracy: 0.619
[3_0,   636/994] loss: 1.151 accuracy: 0.619
[3_0,   640/994] loss: 1.225 accuracy: 0.619
[3_0,   644/994] loss: 0.929 accuracy: 0.619
[3_0,   648/994] loss: 1.150 accuracy: 0.619
[3_0,   652/994] loss: 0.658 accuracy: 0.620
[3_0,   656/994] loss: 1.213 accuracy: 0.620
[3_0,   660/994] loss: 1.249 accuracy: 0.620
[3_0,   664/994] loss: 1.080 accuracy: 0.620
[3_0,   668/994] loss: 1.202 accuracy: 0.620
[3_0,   672/994] loss: 1.098 accuracy: 0.620
[3_0,   676/994] loss: 1.320 accuracy: 0.620
[3_0,   680/994] loss: 1.164 accuracy: 0.620
[3_0,   684/994] loss: 1.162 accuracy: 0.620
[3_0,   688/994] loss: 1.308 accuracy: 0.620
[3_0,   692/994] loss: 1.264 accuracy: 0.619
[3_0,   696/994] loss: 0.767 accuracy: 0.620
[3_0,   700/994] loss: 1.122 accuracy: 0.620
[3_0,   704/994] loss: 1.190 accuracy: 0.620
[3_0,   708/994] loss: 1.187 accuracy: 0.620
[3_0,   712/994] loss: 1.176 accuracy: 0.620
[3_0,   716/994] loss: 1.158 accuracy: 0.620
[3_0,   720/994] loss: 0.915 accuracy: 0.620
[3_0,   724/994] loss: 0.977 accuracy: 0.621
[3_0,   728/994] loss: 1.268 accuracy: 0.621
[3_0,   732/994] loss: 1.085 accuracy: 0.621
[3_0,   736/994] loss: 1.069 accuracy: 0.621
[3_0,   740/994] loss: 1.291 accuracy: 0.621
[3_0,   744/994] loss: 0.979 accuracy: 0.621
[3_0,   748/994] loss: 1.196 accuracy: 0.621
[3_0,   752/994] loss: 1.230 accuracy: 0.621
[3_0,   756/994] loss: 0.873 accuracy: 0.622
[3_0,   760/994] loss: 1.095 accuracy: 0.622
[3_0,   764/994] loss: 1.094 accuracy: 0.622
[3_0,   768/994] loss: 1.119 accuracy: 0.622
[3_0,   772/994] loss: 1.012 accuracy: 0.622
[3_0,   776/994] loss: 0.913 accuracy: 0.623
[3_0,   780/994] loss: 0.921 accuracy: 0.623
[3_0,   784/994] loss: 1.103 accuracy: 0.623
[3_0,   788/994] loss: 1.096 accuracy: 0.623
[3_0,   792/994] loss: 0.946 accuracy: 0.623
[3_0,   796/994] loss: 1.163 accuracy: 0.623
[3_0,   800/994] loss: 1.115 accuracy: 0.623
[3_0,   804/994] loss: 1.405 accuracy: 0.623
[3_0,   808/994] loss: 1.128 accuracy: 0.623
[3_0,   812/994] loss: 0.925 accuracy: 0.624
[3_0,   816/994] loss: 1.278 accuracy: 0.623
[3_0,   820/994] loss: 1.001 accuracy: 0.624
[3_0,   824/994] loss: 1.166 accuracy: 0.624
[3_0,   828/994] loss: 0.992 accuracy: 0.624
[3_0,   832/994] loss: 1.099 accuracy: 0.624
[3_0,   836/994] loss: 0.891 accuracy: 0.624
[3_0,   840/994] loss: 0.834 accuracy: 0.625
[3_0,   844/994] loss: 1.223 accuracy: 0.625
[3_0,   848/994] loss: 0.823 accuracy: 0.625
[3_0,   852/994] loss: 1.316 accuracy: 0.624
[3_0,   856/994] loss: 1.002 accuracy: 0.624
[3_0,   860/994] loss: 0.975 accuracy: 0.624
[3_0,   864/994] loss: 1.616 accuracy: 0.624
[3_0,   868/994] loss: 1.114 accuracy: 0.624
[3_0,   872/994] loss: 1.034 accuracy: 0.624
[3_0,   876/994] loss: 0.999 accuracy: 0.625
[3_0,   880/994] loss: 1.275 accuracy: 0.625
[3_0,   884/994] loss: 1.051 accuracy: 0.625
[3_0,   888/994] loss: 1.368 accuracy: 0.625
[3_0,   892/994] loss: 0.929 accuracy: 0.625
[3_0,   896/994] loss: 1.148 accuracy: 0.625
[3_0,   900/994] loss: 1.208 accuracy: 0.625
[3_0,   904/994] loss: 1.303 accuracy: 0.625
[3_0,   908/994] loss: 1.010 accuracy: 0.625
[3_0,   912/994] loss: 1.088 accuracy: 0.625
[3_0,   916/994] loss: 1.010 accuracy: 0.625
[3_0,   920/994] loss: 1.046 accuracy: 0.625
[3_0,   924/994] loss: 0.972 accuracy: 0.625
[3_0,   928/994] loss: 1.356 accuracy: 0.625
[3_0,   932/994] loss: 1.204 accuracy: 0.625
[3_0,   936/994] loss: 0.701 accuracy: 0.626
[3_0,   940/994] loss: 1.332 accuracy: 0.625
[3_0,   944/994] loss: 1.120 accuracy: 0.625
[3_0,   948/994] loss: 0.969 accuracy: 0.625
[3_0,   952/994] loss: 0.941 accuracy: 0.626
[3_0,   956/994] loss: 1.215 accuracy: 0.625
[3_0,   960/994] loss: 1.156 accuracy: 0.625
[3_0,   964/994] loss: 1.225 accuracy: 0.626
[3_0,   968/994] loss: 1.259 accuracy: 0.625
[3_0,   972/994] loss: 1.175 accuracy: 0.625
[3_0,   976/994] loss: 0.900 accuracy: 0.625
[3_0,   980/994] loss: 1.083 accuracy: 0.625
[3_0,   984/994] loss: 1.147 accuracy: 0.625
[3_0,   988/994] loss: 1.049 accuracy: 0.625
[3_0,   992/994] loss: 1.068 accuracy: 0.625
2022-05-06 12:19:21.460610  :  0.6174847126118785 is higher than the best(0.5384707046739196). Saving the model at ../Models/KBP37/bert_multilingual_adam_finetune_kbp37_3_0.614892919431485_sigmoid_long2.pt
Epoch:  3
Training Loss: 281.6231, Val Loss: 1.2902, Test Loss: 1.2486
Training accuracy:0.6252, Training F1:0.6149, Validation accuracy:0.5992, Validation F1:0.6175, Test accuracy:0.6021, Test F1:0.6149
German F1: 0.5847, English F1: 0.6002, Spanish F1: 0.5343, French F1: 0.5658, Turkish F1: 0.5256
[4_0,     4/994] loss: 1.274 accuracy: 0.641
[4_0,     8/994] loss: 1.180 accuracy: 0.664
[4_0,    12/994] loss: 0.811 accuracy: 0.672
[4_0,    16/994] loss: 0.983 accuracy: 0.652
[4_0,    20/994] loss: 1.049 accuracy: 0.662
[4_0,    24/994] loss: 0.827 accuracy: 0.674
[4_0,    28/994] loss: 0.848 accuracy: 0.679
[4_0,    32/994] loss: 1.252 accuracy: 0.666
[4_0,    36/994] loss: 0.900 accuracy: 0.668
[4_0,    40/994] loss: 1.260 accuracy: 0.664
[4_0,    44/994] loss: 1.033 accuracy: 0.663
[4_0,    48/994] loss: 1.124 accuracy: 0.669
[4_0,    52/994] loss: 1.229 accuracy: 0.668
[4_0,    56/994] loss: 1.035 accuracy: 0.673
[4_0,    60/994] loss: 0.985 accuracy: 0.676
[4_0,    64/994] loss: 0.964 accuracy: 0.675
[4_0,    68/994] loss: 1.063 accuracy: 0.667
[4_0,    72/994] loss: 1.176 accuracy: 0.667
[4_0,    76/994] loss: 0.761 accuracy: 0.671
[4_0,    80/994] loss: 1.409 accuracy: 0.667
[4_0,    84/994] loss: 0.883 accuracy: 0.669
[4_0,    88/994] loss: 1.131 accuracy: 0.669
[4_0,    92/994] loss: 1.062 accuracy: 0.669
[4_0,    96/994] loss: 0.826 accuracy: 0.672
[4_0,   100/994] loss: 0.895 accuracy: 0.672
[4_0,   104/994] loss: 0.812 accuracy: 0.672
[4_0,   108/994] loss: 0.870 accuracy: 0.674
[4_0,   112/994] loss: 0.587 accuracy: 0.681
[4_0,   116/994] loss: 0.889 accuracy: 0.683
[4_0,   120/994] loss: 0.777 accuracy: 0.684
[4_0,   124/994] loss: 1.012 accuracy: 0.681
[4_0,   128/994] loss: 1.052 accuracy: 0.678
[4_0,   132/994] loss: 0.860 accuracy: 0.679
[4_0,   136/994] loss: 0.878 accuracy: 0.680
[4_0,   140/994] loss: 1.186 accuracy: 0.676
[4_0,   144/994] loss: 1.069 accuracy: 0.675
[4_0,   148/994] loss: 0.881 accuracy: 0.675
[4_0,   152/994] loss: 1.026 accuracy: 0.676
[4_0,   156/994] loss: 1.036 accuracy: 0.675
[4_0,   160/994] loss: 0.977 accuracy: 0.677
[4_0,   164/994] loss: 0.882 accuracy: 0.679
[4_0,   168/994] loss: 0.780 accuracy: 0.680
[4_0,   172/994] loss: 1.171 accuracy: 0.678
[4_0,   176/994] loss: 0.821 accuracy: 0.678
[4_0,   180/994] loss: 1.041 accuracy: 0.677
[4_0,   184/994] loss: 0.936 accuracy: 0.678
[4_0,   188/994] loss: 0.773 accuracy: 0.680
[4_0,   192/994] loss: 1.203 accuracy: 0.678
[4_0,   196/994] loss: 0.873 accuracy: 0.679
[4_0,   200/994] loss: 0.937 accuracy: 0.679
[4_0,   204/994] loss: 0.909 accuracy: 0.680
[4_0,   208/994] loss: 0.651 accuracy: 0.682
[4_0,   212/994] loss: 0.912 accuracy: 0.681
[4_0,   216/994] loss: 1.230 accuracy: 0.680
[4_0,   220/994] loss: 0.997 accuracy: 0.679
[4_0,   224/994] loss: 0.611 accuracy: 0.681
[4_0,   228/994] loss: 0.968 accuracy: 0.681
[4_0,   232/994] loss: 0.895 accuracy: 0.681
[4_0,   236/994] loss: 0.980 accuracy: 0.681
[4_0,   240/994] loss: 0.949 accuracy: 0.681
[4_0,   244/994] loss: 1.087 accuracy: 0.681
[4_0,   248/994] loss: 0.885 accuracy: 0.681
[4_0,   252/994] loss: 1.009 accuracy: 0.680
[4_0,   256/994] loss: 0.685 accuracy: 0.682
[4_0,   260/994] loss: 1.104 accuracy: 0.681
[4_0,   264/994] loss: 0.961 accuracy: 0.680
[4_0,   268/994] loss: 1.002 accuracy: 0.681
[4_0,   272/994] loss: 0.782 accuracy: 0.682
[4_0,   276/994] loss: 0.711 accuracy: 0.683
[4_0,   280/994] loss: 1.356 accuracy: 0.681
[4_0,   284/994] loss: 1.118 accuracy: 0.680
[4_0,   288/994] loss: 1.250 accuracy: 0.679
[4_0,   292/994] loss: 1.200 accuracy: 0.677
[4_0,   296/994] loss: 0.972 accuracy: 0.677
[4_0,   300/994] loss: 1.138 accuracy: 0.676
[4_0,   304/994] loss: 0.918 accuracy: 0.676
[4_0,   308/994] loss: 1.226 accuracy: 0.675
[4_0,   312/994] loss: 1.007 accuracy: 0.675
[4_0,   316/994] loss: 0.987 accuracy: 0.675
[4_0,   320/994] loss: 1.114 accuracy: 0.674
[4_0,   324/994] loss: 1.121 accuracy: 0.673
[4_0,   328/994] loss: 0.687 accuracy: 0.674
[4_0,   332/994] loss: 1.074 accuracy: 0.673
[4_0,   336/994] loss: 0.775 accuracy: 0.673
[4_0,   340/994] loss: 1.040 accuracy: 0.672
[4_0,   344/994] loss: 0.886 accuracy: 0.673
[4_0,   348/994] loss: 1.249 accuracy: 0.672
[4_0,   352/994] loss: 1.179 accuracy: 0.671
[4_0,   356/994] loss: 1.090 accuracy: 0.671
[4_0,   360/994] loss: 1.163 accuracy: 0.670
[4_0,   364/994] loss: 1.069 accuracy: 0.671
[4_0,   368/994] loss: 0.999 accuracy: 0.670
[4_0,   372/994] loss: 0.896 accuracy: 0.670
[4_0,   376/994] loss: 1.022 accuracy: 0.669
[4_0,   380/994] loss: 1.109 accuracy: 0.669
[4_0,   384/994] loss: 0.872 accuracy: 0.669
[4_0,   388/994] loss: 1.218 accuracy: 0.668
[4_0,   392/994] loss: 1.178 accuracy: 0.668
[4_0,   396/994] loss: 1.043 accuracy: 0.668
[4_0,   400/994] loss: 1.031 accuracy: 0.668
[4_0,   404/994] loss: 1.267 accuracy: 0.667
[4_0,   408/994] loss: 0.633 accuracy: 0.669
[4_0,   412/994] loss: 0.956 accuracy: 0.669
[4_0,   416/994] loss: 1.166 accuracy: 0.669
[4_0,   420/994] loss: 1.136 accuracy: 0.669
[4_0,   424/994] loss: 1.288 accuracy: 0.669
[4_0,   428/994] loss: 1.574 accuracy: 0.668
[4_0,   432/994] loss: 1.122 accuracy: 0.667
[4_0,   436/994] loss: 1.114 accuracy: 0.667
[4_0,   440/994] loss: 1.019 accuracy: 0.666
[4_0,   444/994] loss: 1.363 accuracy: 0.665
[4_0,   448/994] loss: 1.348 accuracy: 0.664
[4_0,   452/994] loss: 1.046 accuracy: 0.664
[4_0,   456/994] loss: 0.744 accuracy: 0.665
[4_0,   460/994] loss: 1.191 accuracy: 0.664
[4_0,   464/994] loss: 0.903 accuracy: 0.664
[4_0,   468/994] loss: 0.864 accuracy: 0.665
[4_0,   472/994] loss: 1.448 accuracy: 0.664
[4_0,   476/994] loss: 1.162 accuracy: 0.664
[4_0,   480/994] loss: 0.886 accuracy: 0.665
[4_0,   484/994] loss: 0.918 accuracy: 0.665
[4_0,   488/994] loss: 1.287 accuracy: 0.664
[4_0,   492/994] loss: 1.189 accuracy: 0.664
[4_0,   496/994] loss: 0.998 accuracy: 0.664
[4_0,   500/994] loss: 1.073 accuracy: 0.664
[4_0,   504/994] loss: 1.232 accuracy: 0.664
[4_0,   508/994] loss: 0.886 accuracy: 0.664
[4_0,   512/994] loss: 0.992 accuracy: 0.664
[4_0,   516/994] loss: 0.882 accuracy: 0.664
[4_0,   520/994] loss: 1.023 accuracy: 0.663
[4_0,   524/994] loss: 1.012 accuracy: 0.663
[4_0,   528/994] loss: 0.826 accuracy: 0.664
[4_0,   532/994] loss: 0.920 accuracy: 0.664
[4_0,   536/994] loss: 0.807 accuracy: 0.664
[4_0,   540/994] loss: 1.034 accuracy: 0.664
[4_0,   544/994] loss: 0.864 accuracy: 0.665
[4_0,   548/994] loss: 1.157 accuracy: 0.664
[4_0,   552/994] loss: 1.168 accuracy: 0.665
[4_0,   556/994] loss: 0.934 accuracy: 0.665
[4_0,   560/994] loss: 1.396 accuracy: 0.664
[4_0,   564/994] loss: 1.498 accuracy: 0.663
[4_0,   568/994] loss: 1.033 accuracy: 0.663
[4_0,   572/994] loss: 1.115 accuracy: 0.662
[4_0,   576/994] loss: 1.086 accuracy: 0.662
[4_0,   580/994] loss: 1.315 accuracy: 0.662
[4_0,   584/994] loss: 0.983 accuracy: 0.662
[4_0,   588/994] loss: 1.325 accuracy: 0.661
[4_0,   592/994] loss: 1.149 accuracy: 0.661
[4_0,   596/994] loss: 0.744 accuracy: 0.661
[4_0,   600/994] loss: 0.946 accuracy: 0.661
[4_0,   604/994] loss: 1.180 accuracy: 0.661
[4_0,   608/994] loss: 1.038 accuracy: 0.661
[4_0,   612/994] loss: 1.145 accuracy: 0.661
[4_0,   616/994] loss: 1.121 accuracy: 0.661
[4_0,   620/994] loss: 0.948 accuracy: 0.661
[4_0,   624/994] loss: 0.867 accuracy: 0.662
[4_0,   628/994] loss: 1.040 accuracy: 0.662
[4_0,   632/994] loss: 0.855 accuracy: 0.662
[4_0,   636/994] loss: 1.150 accuracy: 0.662
[4_0,   640/994] loss: 1.280 accuracy: 0.661
[4_0,   644/994] loss: 0.784 accuracy: 0.662
[4_0,   648/994] loss: 0.942 accuracy: 0.662
[4_0,   652/994] loss: 0.964 accuracy: 0.662
[4_0,   656/994] loss: 1.152 accuracy: 0.661
[4_0,   660/994] loss: 1.035 accuracy: 0.661
[4_0,   664/994] loss: 0.963 accuracy: 0.661
[4_0,   668/994] loss: 0.955 accuracy: 0.661
[4_0,   672/994] loss: 0.891 accuracy: 0.661
[4_0,   676/994] loss: 1.148 accuracy: 0.661
[4_0,   680/994] loss: 1.272 accuracy: 0.662
[4_0,   684/994] loss: 0.918 accuracy: 0.662
[4_0,   688/994] loss: 0.914 accuracy: 0.662
[4_0,   692/994] loss: 1.157 accuracy: 0.662
[4_0,   696/994] loss: 1.160 accuracy: 0.662
[4_0,   700/994] loss: 0.915 accuracy: 0.662
[4_0,   704/994] loss: 0.893 accuracy: 0.662
[4_0,   708/994] loss: 1.134 accuracy: 0.662
[4_0,   712/994] loss: 1.114 accuracy: 0.662
[4_0,   716/994] loss: 0.986 accuracy: 0.662
[4_0,   720/994] loss: 0.924 accuracy: 0.662
[4_0,   724/994] loss: 0.907 accuracy: 0.662
[4_0,   728/994] loss: 0.975 accuracy: 0.663
[4_0,   732/994] loss: 0.832 accuracy: 0.663
[4_0,   736/994] loss: 1.135 accuracy: 0.663
[4_0,   740/994] loss: 0.823 accuracy: 0.663
[4_0,   744/994] loss: 1.009 accuracy: 0.663
[4_0,   748/994] loss: 0.986 accuracy: 0.663
[4_0,   752/994] loss: 0.779 accuracy: 0.663
[4_0,   756/994] loss: 0.973 accuracy: 0.664
[4_0,   760/994] loss: 1.021 accuracy: 0.663
[4_0,   764/994] loss: 0.992 accuracy: 0.664
[4_0,   768/994] loss: 0.947 accuracy: 0.664
[4_0,   772/994] loss: 0.850 accuracy: 0.664
[4_0,   776/994] loss: 0.815 accuracy: 0.665
[4_0,   780/994] loss: 1.128 accuracy: 0.664
[4_0,   784/994] loss: 1.043 accuracy: 0.664
[4_0,   788/994] loss: 1.165 accuracy: 0.664
[4_0,   792/994] loss: 1.095 accuracy: 0.663
[4_0,   796/994] loss: 0.983 accuracy: 0.663
[4_0,   800/994] loss: 0.992 accuracy: 0.663
[4_0,   804/994] loss: 1.001 accuracy: 0.663
[4_0,   808/994] loss: 0.758 accuracy: 0.664
[4_0,   812/994] loss: 1.064 accuracy: 0.664
[4_0,   816/994] loss: 0.963 accuracy: 0.663
[4_0,   820/994] loss: 0.921 accuracy: 0.663
[4_0,   824/994] loss: 0.829 accuracy: 0.664
[4_0,   828/994] loss: 1.133 accuracy: 0.664
[4_0,   832/994] loss: 1.110 accuracy: 0.664
[4_0,   836/994] loss: 0.884 accuracy: 0.664
[4_0,   840/994] loss: 0.921 accuracy: 0.665
[4_0,   844/994] loss: 1.413 accuracy: 0.664
[4_0,   848/994] loss: 1.252 accuracy: 0.664
[4_0,   852/994] loss: 0.952 accuracy: 0.664
[4_0,   856/994] loss: 0.931 accuracy: 0.664
[4_0,   860/994] loss: 1.219 accuracy: 0.664
[4_0,   864/994] loss: 1.384 accuracy: 0.663
[4_0,   868/994] loss: 1.185 accuracy: 0.663
[4_0,   872/994] loss: 0.950 accuracy: 0.663
[4_0,   876/994] loss: 1.196 accuracy: 0.663
[4_0,   880/994] loss: 0.858 accuracy: 0.663
[4_0,   884/994] loss: 1.338 accuracy: 0.663
[4_0,   888/994] loss: 1.191 accuracy: 0.662
[4_0,   892/994] loss: 1.342 accuracy: 0.662
[4_0,   896/994] loss: 1.229 accuracy: 0.661
[4_0,   900/994] loss: 0.900 accuracy: 0.662
[4_0,   904/994] loss: 0.953 accuracy: 0.662
[4_0,   908/994] loss: 0.996 accuracy: 0.662
[4_0,   912/994] loss: 1.535 accuracy: 0.662
[4_0,   916/994] loss: 1.056 accuracy: 0.661
[4_0,   920/994] loss: 1.168 accuracy: 0.661
[4_0,   924/994] loss: 1.025 accuracy: 0.661
[4_0,   928/994] loss: 1.090 accuracy: 0.661
[4_0,   932/994] loss: 0.939 accuracy: 0.661
[4_0,   936/994] loss: 0.924 accuracy: 0.662
[4_0,   940/994] loss: 1.197 accuracy: 0.661
[4_0,   944/994] loss: 0.991 accuracy: 0.662
[4_0,   948/994] loss: 0.895 accuracy: 0.661
[4_0,   952/994] loss: 0.901 accuracy: 0.662
[4_0,   956/994] loss: 0.867 accuracy: 0.662
[4_0,   960/994] loss: 0.911 accuracy: 0.662
[4_0,   964/994] loss: 0.933 accuracy: 0.662
[4_0,   968/994] loss: 1.073 accuracy: 0.662
[4_0,   972/994] loss: 1.007 accuracy: 0.662
[4_0,   976/994] loss: 1.048 accuracy: 0.662
[4_0,   980/994] loss: 1.056 accuracy: 0.662
[4_0,   984/994] loss: 0.924 accuracy: 0.662
[4_0,   988/994] loss: 0.868 accuracy: 0.662
[4_0,   992/994] loss: 0.959 accuracy: 0.662
Epoch:  4
Training Loss: 254.1609, Val Loss: 1.2926, Test Loss: 1.2128
Training accuracy:0.6621, Training F1:0.6529, Validation accuracy:0.5893, Validation F1:0.6058, Test accuracy:0.6053, Test F1:0.6073
German F1: 0.5362, English F1: 0.5960, Spanish F1: 0.5708, French F1: 0.5402, Turkish F1: 0.5235
[5_0,     4/994] loss: 0.951 accuracy: 0.656
[5_0,     8/994] loss: 0.810 accuracy: 0.680
[5_0,    12/994] loss: 0.763 accuracy: 0.708
[5_0,    16/994] loss: 0.954 accuracy: 0.695
[5_0,    20/994] loss: 0.955 accuracy: 0.694
[5_0,    24/994] loss: 0.800 accuracy: 0.698
[5_0,    28/994] loss: 0.703 accuracy: 0.703
[5_0,    32/994] loss: 0.724 accuracy: 0.711
[5_0,    36/994] loss: 1.328 accuracy: 0.696
[5_0,    40/994] loss: 1.031 accuracy: 0.697
[5_0,    44/994] loss: 0.899 accuracy: 0.703
[5_0,    48/994] loss: 0.826 accuracy: 0.702
[5_0,    52/994] loss: 1.008 accuracy: 0.697
[5_0,    56/994] loss: 0.853 accuracy: 0.701
[5_0,    60/994] loss: 0.632 accuracy: 0.706
[5_0,    64/994] loss: 1.185 accuracy: 0.696
[5_0,    68/994] loss: 0.665 accuracy: 0.699
[5_0,    72/994] loss: 0.754 accuracy: 0.699
[5_0,    76/994] loss: 1.116 accuracy: 0.693
[5_0,    80/994] loss: 0.827 accuracy: 0.694
[5_0,    84/994] loss: 0.692 accuracy: 0.696
[5_0,    88/994] loss: 0.874 accuracy: 0.695
[5_0,    92/994] loss: 1.255 accuracy: 0.690
[5_0,    96/994] loss: 0.777 accuracy: 0.691
[5_0,   100/994] loss: 1.135 accuracy: 0.689
[5_0,   104/994] loss: 0.838 accuracy: 0.692
[5_0,   108/994] loss: 1.196 accuracy: 0.691
[5_0,   112/994] loss: 0.700 accuracy: 0.691
[5_0,   116/994] loss: 0.984 accuracy: 0.690
[5_0,   120/994] loss: 1.268 accuracy: 0.686
[5_0,   124/994] loss: 0.996 accuracy: 0.687
[5_0,   128/994] loss: 1.150 accuracy: 0.686
[5_0,   132/994] loss: 0.775 accuracy: 0.685
[5_0,   136/994] loss: 0.815 accuracy: 0.684
[5_0,   140/994] loss: 0.776 accuracy: 0.685
[5_0,   144/994] loss: 1.019 accuracy: 0.685
[5_0,   148/994] loss: 0.987 accuracy: 0.683
[5_0,   152/994] loss: 0.987 accuracy: 0.684
[5_0,   156/994] loss: 1.199 accuracy: 0.682
[5_0,   160/994] loss: 0.978 accuracy: 0.681
[5_0,   164/994] loss: 0.962 accuracy: 0.680
[5_0,   168/994] loss: 1.034 accuracy: 0.679
[5_0,   172/994] loss: 0.960 accuracy: 0.679
[5_0,   176/994] loss: 1.229 accuracy: 0.678
[5_0,   180/994] loss: 0.913 accuracy: 0.677
[5_0,   184/994] loss: 0.970 accuracy: 0.677
[5_0,   188/994] loss: 0.848 accuracy: 0.678
[5_0,   192/994] loss: 0.911 accuracy: 0.678
[5_0,   196/994] loss: 0.913 accuracy: 0.678
[5_0,   200/994] loss: 1.162 accuracy: 0.677
[5_0,   204/994] loss: 0.793 accuracy: 0.677
[5_0,   208/994] loss: 1.040 accuracy: 0.676
[5_0,   212/994] loss: 0.810 accuracy: 0.678
[5_0,   216/994] loss: 1.011 accuracy: 0.678
[5_0,   220/994] loss: 0.814 accuracy: 0.678
[5_0,   224/994] loss: 1.162 accuracy: 0.677
[5_0,   228/994] loss: 0.780 accuracy: 0.677
[5_0,   232/994] loss: 1.183 accuracy: 0.676
[5_0,   236/994] loss: 1.049 accuracy: 0.675
[5_0,   240/994] loss: 1.053 accuracy: 0.675
[5_0,   244/994] loss: 0.906 accuracy: 0.676
[5_0,   248/994] loss: 0.928 accuracy: 0.675
[5_0,   252/994] loss: 1.115 accuracy: 0.674
[5_0,   256/994] loss: 0.837 accuracy: 0.674
[5_0,   260/994] loss: 1.016 accuracy: 0.673
[5_0,   264/994] loss: 1.067 accuracy: 0.672
[5_0,   268/994] loss: 0.877 accuracy: 0.673
[5_0,   272/994] loss: 1.149 accuracy: 0.673
[5_0,   276/994] loss: 0.885 accuracy: 0.674
[5_0,   280/994] loss: 0.798 accuracy: 0.674
[5_0,   284/994] loss: 0.891 accuracy: 0.674
[5_0,   288/994] loss: 0.893 accuracy: 0.673
[5_0,   292/994] loss: 0.791 accuracy: 0.674
[5_0,   296/994] loss: 0.896 accuracy: 0.675
[5_0,   300/994] loss: 0.668 accuracy: 0.676
[5_0,   304/994] loss: 0.864 accuracy: 0.675
[5_0,   308/994] loss: 0.890 accuracy: 0.676
[5_0,   312/994] loss: 1.119 accuracy: 0.676
[5_0,   316/994] loss: 0.810 accuracy: 0.677
[5_0,   320/994] loss: 0.817 accuracy: 0.678
[5_0,   324/994] loss: 0.919 accuracy: 0.678
[5_0,   328/994] loss: 0.829 accuracy: 0.678
[5_0,   332/994] loss: 0.660 accuracy: 0.680
[5_0,   336/994] loss: 0.960 accuracy: 0.680
[5_0,   340/994] loss: 0.959 accuracy: 0.679
[5_0,   344/994] loss: 1.220 accuracy: 0.678
[5_0,   348/994] loss: 0.705 accuracy: 0.679
[5_0,   352/994] loss: 0.975 accuracy: 0.679
[5_0,   356/994] loss: 0.745 accuracy: 0.680
[5_0,   360/994] loss: 0.794 accuracy: 0.681
[5_0,   364/994] loss: 0.977 accuracy: 0.681
[5_0,   368/994] loss: 1.290 accuracy: 0.678
[5_0,   372/994] loss: 1.127 accuracy: 0.678
[5_0,   376/994] loss: 0.978 accuracy: 0.679
[5_0,   380/994] loss: 0.972 accuracy: 0.678
[5_0,   384/994] loss: 1.093 accuracy: 0.678
[5_0,   388/994] loss: 0.734 accuracy: 0.679
[5_0,   392/994] loss: 0.984 accuracy: 0.679
[5_0,   396/994] loss: 0.743 accuracy: 0.679
[5_0,   400/994] loss: 1.222 accuracy: 0.678
[5_0,   404/994] loss: 0.706 accuracy: 0.679
[5_0,   408/994] loss: 1.060 accuracy: 0.679
[5_0,   412/994] loss: 0.862 accuracy: 0.680
[5_0,   416/994] loss: 0.951 accuracy: 0.680
[5_0,   420/994] loss: 0.991 accuracy: 0.680
[5_0,   424/994] loss: 0.796 accuracy: 0.680
[5_0,   428/994] loss: 0.865 accuracy: 0.681
[5_0,   432/994] loss: 0.704 accuracy: 0.681
[5_0,   436/994] loss: 0.974 accuracy: 0.681
[5_0,   440/994] loss: 1.358 accuracy: 0.680
[5_0,   444/994] loss: 0.829 accuracy: 0.681
[5_0,   448/994] loss: 0.804 accuracy: 0.681
[5_0,   452/994] loss: 1.105 accuracy: 0.680
[5_0,   456/994] loss: 1.064 accuracy: 0.680
[5_0,   460/994] loss: 1.053 accuracy: 0.679
[5_0,   464/994] loss: 1.208 accuracy: 0.679
[5_0,   468/994] loss: 0.778 accuracy: 0.679
[5_0,   472/994] loss: 0.908 accuracy: 0.679
[5_0,   476/994] loss: 0.949 accuracy: 0.679
[5_0,   480/994] loss: 1.064 accuracy: 0.679
[5_0,   484/994] loss: 0.709 accuracy: 0.680
[5_0,   488/994] loss: 1.252 accuracy: 0.679
[5_0,   492/994] loss: 0.954 accuracy: 0.679
[5_0,   496/994] loss: 1.071 accuracy: 0.679
[5_0,   500/994] loss: 1.107 accuracy: 0.678
[5_0,   504/994] loss: 1.092 accuracy: 0.678
[5_0,   508/994] loss: 0.818 accuracy: 0.678
[5_0,   512/994] loss: 0.975 accuracy: 0.678
[5_0,   516/994] loss: 1.244 accuracy: 0.678
[5_0,   520/994] loss: 0.915 accuracy: 0.678
[5_0,   524/994] loss: 0.606 accuracy: 0.678
[5_0,   528/994] loss: 0.745 accuracy: 0.678
[5_0,   532/994] loss: 1.151 accuracy: 0.678
[5_0,   536/994] loss: 0.580 accuracy: 0.678
[5_0,   540/994] loss: 0.962 accuracy: 0.679
[5_0,   544/994] loss: 0.743 accuracy: 0.679
[5_0,   548/994] loss: 0.815 accuracy: 0.680
[5_0,   552/994] loss: 0.811 accuracy: 0.681
[5_0,   556/994] loss: 0.852 accuracy: 0.681
[5_0,   560/994] loss: 1.140 accuracy: 0.681
[5_0,   564/994] loss: 1.011 accuracy: 0.681
[5_0,   568/994] loss: 0.882 accuracy: 0.681
[5_0,   572/994] loss: 1.089 accuracy: 0.681
[5_0,   576/994] loss: 1.004 accuracy: 0.681
[5_0,   580/994] loss: 0.999 accuracy: 0.681
[5_0,   584/994] loss: 0.760 accuracy: 0.681
[5_0,   588/994] loss: 1.174 accuracy: 0.681
[5_0,   592/994] loss: 0.819 accuracy: 0.681
[5_0,   596/994] loss: 0.929 accuracy: 0.681
[5_0,   600/994] loss: 0.547 accuracy: 0.682
[5_0,   604/994] loss: 1.166 accuracy: 0.681
[5_0,   608/994] loss: 0.981 accuracy: 0.682
[5_0,   612/994] loss: 0.995 accuracy: 0.681
[5_0,   616/994] loss: 1.196 accuracy: 0.681
[5_0,   620/994] loss: 0.879 accuracy: 0.682
[5_0,   624/994] loss: 0.901 accuracy: 0.682
[5_0,   628/994] loss: 1.038 accuracy: 0.681
[5_0,   632/994] loss: 1.003 accuracy: 0.681
[5_0,   636/994] loss: 0.732 accuracy: 0.682
[5_0,   640/994] loss: 0.986 accuracy: 0.682
[5_0,   644/994] loss: 0.719 accuracy: 0.682
[5_0,   648/994] loss: 1.171 accuracy: 0.682
[5_0,   652/994] loss: 0.924 accuracy: 0.682
[5_0,   656/994] loss: 1.195 accuracy: 0.682
[5_0,   660/994] loss: 0.969 accuracy: 0.682
[5_0,   664/994] loss: 0.832 accuracy: 0.682
[5_0,   668/994] loss: 0.904 accuracy: 0.682
[5_0,   672/994] loss: 0.989 accuracy: 0.682
[5_0,   676/994] loss: 1.197 accuracy: 0.681
[5_0,   680/994] loss: 0.785 accuracy: 0.682
[5_0,   684/994] loss: 0.810 accuracy: 0.682
[5_0,   688/994] loss: 0.762 accuracy: 0.682
[5_0,   692/994] loss: 0.739 accuracy: 0.682
[5_0,   696/994] loss: 0.881 accuracy: 0.682
[5_0,   700/994] loss: 1.053 accuracy: 0.682
[5_0,   704/994] loss: 0.924 accuracy: 0.682
[5_0,   708/994] loss: 0.904 accuracy: 0.682
[5_0,   712/994] loss: 1.095 accuracy: 0.682
[5_0,   716/994] loss: 0.745 accuracy: 0.682
[5_0,   720/994] loss: 0.724 accuracy: 0.682
[5_0,   724/994] loss: 0.971 accuracy: 0.683
[5_0,   728/994] loss: 0.845 accuracy: 0.683
[5_0,   732/994] loss: 0.894 accuracy: 0.683
[5_0,   736/994] loss: 0.798 accuracy: 0.683
[5_0,   740/994] loss: 0.925 accuracy: 0.683
[5_0,   744/994] loss: 0.931 accuracy: 0.684
[5_0,   748/994] loss: 1.038 accuracy: 0.684
[5_0,   752/994] loss: 1.278 accuracy: 0.683
[5_0,   756/994] loss: 0.907 accuracy: 0.683
[5_0,   760/994] loss: 1.264 accuracy: 0.683
[5_0,   764/994] loss: 0.862 accuracy: 0.683
[5_0,   768/994] loss: 0.984 accuracy: 0.683
[5_0,   772/994] loss: 1.079 accuracy: 0.683
[5_0,   776/994] loss: 0.891 accuracy: 0.683
[5_0,   780/994] loss: 0.741 accuracy: 0.683
[5_0,   784/994] loss: 0.813 accuracy: 0.684
[5_0,   788/994] loss: 1.216 accuracy: 0.683
[5_0,   792/994] loss: 1.221 accuracy: 0.683
[5_0,   796/994] loss: 0.656 accuracy: 0.683
[5_0,   800/994] loss: 0.883 accuracy: 0.683
[5_0,   804/994] loss: 1.103 accuracy: 0.683
[5_0,   808/994] loss: 0.987 accuracy: 0.683
[5_0,   812/994] loss: 1.098 accuracy: 0.683
[5_0,   816/994] loss: 0.789 accuracy: 0.683
[5_0,   820/994] loss: 0.856 accuracy: 0.683
[5_0,   824/994] loss: 1.001 accuracy: 0.684
[5_0,   828/994] loss: 0.761 accuracy: 0.684
[5_0,   832/994] loss: 0.881 accuracy: 0.684
[5_0,   836/994] loss: 0.781 accuracy: 0.684
[5_0,   840/994] loss: 1.093 accuracy: 0.683
[5_0,   844/994] loss: 1.038 accuracy: 0.683
[5_0,   848/994] loss: 0.946 accuracy: 0.683
[5_0,   852/994] loss: 0.823 accuracy: 0.683
[5_0,   856/994] loss: 0.916 accuracy: 0.683
[5_0,   860/994] loss: 1.075 accuracy: 0.683
[5_0,   864/994] loss: 1.032 accuracy: 0.683
[5_0,   868/994] loss: 0.918 accuracy: 0.683
[5_0,   872/994] loss: 0.879 accuracy: 0.683
[5_0,   876/994] loss: 0.963 accuracy: 0.683
[5_0,   880/994] loss: 1.057 accuracy: 0.683
[5_0,   884/994] loss: 0.794 accuracy: 0.683
[5_0,   888/994] loss: 0.886 accuracy: 0.683
[5_0,   892/994] loss: 0.982 accuracy: 0.683
[5_0,   896/994] loss: 0.914 accuracy: 0.683
[5_0,   900/994] loss: 1.174 accuracy: 0.683
[5_0,   904/994] loss: 1.172 accuracy: 0.682
[5_0,   908/994] loss: 0.788 accuracy: 0.683
[5_0,   912/994] loss: 0.913 accuracy: 0.683
[5_0,   916/994] loss: 0.827 accuracy: 0.683
[5_0,   920/994] loss: 0.905 accuracy: 0.683
[5_0,   924/994] loss: 0.892 accuracy: 0.683
[5_0,   928/994] loss: 0.861 accuracy: 0.683
[5_0,   932/994] loss: 1.100 accuracy: 0.683
[5_0,   936/994] loss: 0.977 accuracy: 0.683
[5_0,   940/994] loss: 0.854 accuracy: 0.683
[5_0,   944/994] loss: 0.989 accuracy: 0.683
[5_0,   948/994] loss: 0.759 accuracy: 0.683
[5_0,   952/994] loss: 0.713 accuracy: 0.684
[5_0,   956/994] loss: 0.805 accuracy: 0.684
[5_0,   960/994] loss: 0.756 accuracy: 0.684
[5_0,   964/994] loss: 0.922 accuracy: 0.684
[5_0,   968/994] loss: 1.036 accuracy: 0.684
[5_0,   972/994] loss: 0.908 accuracy: 0.684
[5_0,   976/994] loss: 0.586 accuracy: 0.685
[5_0,   980/994] loss: 1.086 accuracy: 0.685
[5_0,   984/994] loss: 1.152 accuracy: 0.684
[5_0,   988/994] loss: 0.632 accuracy: 0.685
[5_0,   992/994] loss: 1.089 accuracy: 0.684
Epoch:  5
Training Loss: 232.5280, Val Loss: 1.2930, Test Loss: 1.2317
Training accuracy:0.6844, Training F1:0.6832, Validation accuracy:0.5940, Validation F1:0.6099, Test accuracy:0.6147, Test F1:0.6233
German F1: 0.5615, English F1: 0.6074, Spanish F1: 0.5832, French F1: 0.5474, Turkish F1: 0.5333
[6_0,     4/994] loss: 0.968 accuracy: 0.656
[6_0,     8/994] loss: 0.777 accuracy: 0.719
[6_0,    12/994] loss: 0.652 accuracy: 0.740
[6_0,    16/994] loss: 0.999 accuracy: 0.727
[6_0,    20/994] loss: 1.017 accuracy: 0.722
[6_0,    24/994] loss: 1.128 accuracy: 0.719
[6_0,    28/994] loss: 1.041 accuracy: 0.710
[6_0,    32/994] loss: 0.480 accuracy: 0.730
[6_0,    36/994] loss: 0.855 accuracy: 0.724
[6_0,    40/994] loss: 0.724 accuracy: 0.723
[6_0,    44/994] loss: 0.375 accuracy: 0.739
[6_0,    48/994] loss: 0.875 accuracy: 0.736
[6_0,    52/994] loss: 0.651 accuracy: 0.739
[6_0,    56/994] loss: 0.692 accuracy: 0.741
[6_0,    60/994] loss: 0.727 accuracy: 0.741
[6_0,    64/994] loss: 0.821 accuracy: 0.738
[6_0,    68/994] loss: 0.947 accuracy: 0.734
[6_0,    72/994] loss: 0.819 accuracy: 0.734
[6_0,    76/994] loss: 0.710 accuracy: 0.735
[6_0,    80/994] loss: 0.663 accuracy: 0.734
[6_0,    84/994] loss: 0.802 accuracy: 0.735
[6_0,    88/994] loss: 0.822 accuracy: 0.732
[6_0,    92/994] loss: 0.840 accuracy: 0.730
[6_0,    96/994] loss: 0.688 accuracy: 0.729
[6_0,   100/994] loss: 0.975 accuracy: 0.726
[6_0,   104/994] loss: 0.787 accuracy: 0.725
[6_0,   108/994] loss: 0.744 accuracy: 0.724
[6_0,   112/994] loss: 0.794 accuracy: 0.723
[6_0,   116/994] loss: 0.700 accuracy: 0.724
[6_0,   120/994] loss: 0.728 accuracy: 0.726
[6_0,   124/994] loss: 0.739 accuracy: 0.726
[6_0,   128/994] loss: 1.011 accuracy: 0.724
[6_0,   132/994] loss: 0.584 accuracy: 0.725
[6_0,   136/994] loss: 0.785 accuracy: 0.722
[6_0,   140/994] loss: 0.824 accuracy: 0.721
[6_0,   144/994] loss: 1.080 accuracy: 0.720
[6_0,   148/994] loss: 0.840 accuracy: 0.717
[6_0,   152/994] loss: 0.542 accuracy: 0.718
[6_0,   156/994] loss: 0.883 accuracy: 0.718
[6_0,   160/994] loss: 0.740 accuracy: 0.717
[6_0,   164/994] loss: 0.639 accuracy: 0.717
[6_0,   168/994] loss: 0.736 accuracy: 0.718
[6_0,   172/994] loss: 0.738 accuracy: 0.719
[6_0,   176/994] loss: 1.110 accuracy: 0.716
[6_0,   180/994] loss: 0.761 accuracy: 0.716
[6_0,   184/994] loss: 0.937 accuracy: 0.715
[6_0,   188/994] loss: 1.118 accuracy: 0.714
[6_0,   192/994] loss: 0.771 accuracy: 0.714
[6_0,   196/994] loss: 0.699 accuracy: 0.713
[6_0,   200/994] loss: 0.793 accuracy: 0.713
[6_0,   204/994] loss: 1.036 accuracy: 0.712
[6_0,   208/994] loss: 0.725 accuracy: 0.714
[6_0,   212/994] loss: 0.664 accuracy: 0.714
[6_0,   216/994] loss: 0.699 accuracy: 0.716
[6_0,   220/994] loss: 0.792 accuracy: 0.717
[6_0,   224/994] loss: 0.540 accuracy: 0.718
[6_0,   228/994] loss: 0.804 accuracy: 0.718
[6_0,   232/994] loss: 0.851 accuracy: 0.718
[6_0,   236/994] loss: 1.093 accuracy: 0.717
[6_0,   240/994] loss: 0.983 accuracy: 0.717
[6_0,   244/994] loss: 0.684 accuracy: 0.718
[6_0,   248/994] loss: 0.741 accuracy: 0.719
[6_0,   252/994] loss: 0.784 accuracy: 0.718
[6_0,   256/994] loss: 0.856 accuracy: 0.719
[6_0,   260/994] loss: 0.693 accuracy: 0.719
[6_0,   264/994] loss: 0.900 accuracy: 0.720
[6_0,   268/994] loss: 1.075 accuracy: 0.719
[6_0,   272/994] loss: 0.725 accuracy: 0.719
[6_0,   276/994] loss: 1.164 accuracy: 0.718
[6_0,   280/994] loss: 0.680 accuracy: 0.719
[6_0,   284/994] loss: 0.753 accuracy: 0.720
[6_0,   288/994] loss: 0.690 accuracy: 0.720
[6_0,   292/994] loss: 1.002 accuracy: 0.719
[6_0,   296/994] loss: 0.866 accuracy: 0.720
[6_0,   300/994] loss: 1.074 accuracy: 0.720
[6_0,   304/994] loss: 0.753 accuracy: 0.721
[6_0,   308/994] loss: 0.945 accuracy: 0.722
[6_0,   312/994] loss: 0.869 accuracy: 0.721
[6_0,   316/994] loss: 0.886 accuracy: 0.722
[6_0,   320/994] loss: 0.775 accuracy: 0.721
[6_0,   324/994] loss: 0.745 accuracy: 0.721
[6_0,   328/994] loss: 0.789 accuracy: 0.722
[6_0,   332/994] loss: 0.852 accuracy: 0.723
[6_0,   336/994] loss: 0.720 accuracy: 0.723
[6_0,   340/994] loss: 0.649 accuracy: 0.723
[6_0,   344/994] loss: 1.122 accuracy: 0.722
[6_0,   348/994] loss: 0.947 accuracy: 0.722
[6_0,   352/994] loss: 0.564 accuracy: 0.722
[6_0,   356/994] loss: 0.997 accuracy: 0.721
[6_0,   360/994] loss: 0.641 accuracy: 0.722
[6_0,   364/994] loss: 0.568 accuracy: 0.722
[6_0,   368/994] loss: 0.801 accuracy: 0.721
[6_0,   372/994] loss: 0.798 accuracy: 0.721
[6_0,   376/994] loss: 1.157 accuracy: 0.721
[6_0,   380/994] loss: 0.632 accuracy: 0.722
[6_0,   384/994] loss: 0.774 accuracy: 0.722
[6_0,   388/994] loss: 0.797 accuracy: 0.722
[6_0,   392/994] loss: 0.793 accuracy: 0.722
[6_0,   396/994] loss: 0.735 accuracy: 0.722
[6_0,   400/994] loss: 0.912 accuracy: 0.722
[6_0,   404/994] loss: 0.843 accuracy: 0.722
[6_0,   408/994] loss: 0.862 accuracy: 0.721
[6_0,   412/994] loss: 0.807 accuracy: 0.721
[6_0,   416/994] loss: 0.635 accuracy: 0.722
[6_0,   420/994] loss: 0.672 accuracy: 0.722
[6_0,   424/994] loss: 0.959 accuracy: 0.722
[6_0,   428/994] loss: 0.879 accuracy: 0.722
[6_0,   432/994] loss: 0.816 accuracy: 0.722
[6_0,   436/994] loss: 0.669 accuracy: 0.723
[6_0,   440/994] loss: 0.831 accuracy: 0.723
[6_0,   444/994] loss: 0.748 accuracy: 0.723
[6_0,   448/994] loss: 0.605 accuracy: 0.723
[6_0,   452/994] loss: 0.660 accuracy: 0.724
[6_0,   456/994] loss: 0.774 accuracy: 0.724
[6_0,   460/994] loss: 0.680 accuracy: 0.724
[6_0,   464/994] loss: 0.898 accuracy: 0.724
[6_0,   468/994] loss: 0.644 accuracy: 0.724
[6_0,   472/994] loss: 0.720 accuracy: 0.725
[6_0,   476/994] loss: 1.159 accuracy: 0.725
[6_0,   480/994] loss: 1.001 accuracy: 0.724
[6_0,   484/994] loss: 0.698 accuracy: 0.725
[6_0,   488/994] loss: 0.751 accuracy: 0.725
[6_0,   492/994] loss: 0.955 accuracy: 0.724
[6_0,   496/994] loss: 0.830 accuracy: 0.724
[6_0,   500/994] loss: 0.951 accuracy: 0.724
[6_0,   504/994] loss: 0.877 accuracy: 0.724
[6_0,   508/994] loss: 0.709 accuracy: 0.725
[6_0,   512/994] loss: 0.575 accuracy: 0.726
[6_0,   516/994] loss: 0.600 accuracy: 0.726
[6_0,   520/994] loss: 1.129 accuracy: 0.726
[6_0,   524/994] loss: 0.787 accuracy: 0.726
[6_0,   528/994] loss: 0.786 accuracy: 0.726
[6_0,   532/994] loss: 1.071 accuracy: 0.725
[6_0,   536/994] loss: 0.741 accuracy: 0.725
[6_0,   540/994] loss: 0.566 accuracy: 0.726
[6_0,   544/994] loss: 0.714 accuracy: 0.726
[6_0,   548/994] loss: 0.850 accuracy: 0.726
[6_0,   552/994] loss: 0.905 accuracy: 0.725
[6_0,   556/994] loss: 0.922 accuracy: 0.725
[6_0,   560/994] loss: 0.791 accuracy: 0.725
[6_0,   564/994] loss: 0.621 accuracy: 0.726
[6_0,   568/994] loss: 0.780 accuracy: 0.726
[6_0,   572/994] loss: 0.826 accuracy: 0.725
[6_0,   576/994] loss: 0.846 accuracy: 0.725
[6_0,   580/994] loss: 0.691 accuracy: 0.725
[6_0,   584/994] loss: 0.858 accuracy: 0.725
[6_0,   588/994] loss: 1.011 accuracy: 0.725
[6_0,   592/994] loss: 0.928 accuracy: 0.724
[6_0,   596/994] loss: 0.702 accuracy: 0.725
[6_0,   600/994] loss: 0.692 accuracy: 0.725
[6_0,   604/994] loss: 0.937 accuracy: 0.725
[6_0,   608/994] loss: 0.857 accuracy: 0.725
[6_0,   612/994] loss: 0.617 accuracy: 0.725
[6_0,   616/994] loss: 0.767 accuracy: 0.725
[6_0,   620/994] loss: 0.885 accuracy: 0.726
[6_0,   624/994] loss: 0.627 accuracy: 0.726
[6_0,   628/994] loss: 0.881 accuracy: 0.726
[6_0,   632/994] loss: 0.774 accuracy: 0.726
[6_0,   636/994] loss: 0.926 accuracy: 0.725
[6_0,   640/994] loss: 0.551 accuracy: 0.726
[6_0,   644/994] loss: 0.592 accuracy: 0.726
[6_0,   648/994] loss: 0.846 accuracy: 0.726
[6_0,   652/994] loss: 0.839 accuracy: 0.726
[6_0,   656/994] loss: 0.900 accuracy: 0.726
[6_0,   660/994] loss: 0.723 accuracy: 0.726
[6_0,   664/994] loss: 0.870 accuracy: 0.726
[6_0,   668/994] loss: 0.631 accuracy: 0.726
[6_0,   672/994] loss: 0.916 accuracy: 0.726
[6_0,   676/994] loss: 0.615 accuracy: 0.726
[6_0,   680/994] loss: 0.602 accuracy: 0.726
[6_0,   684/994] loss: 0.697 accuracy: 0.727
[6_0,   688/994] loss: 0.727 accuracy: 0.727
[6_0,   692/994] loss: 0.761 accuracy: 0.727
[6_0,   696/994] loss: 0.816 accuracy: 0.727
[6_0,   700/994] loss: 0.772 accuracy: 0.726
[6_0,   704/994] loss: 0.666 accuracy: 0.727
[6_0,   708/994] loss: 0.889 accuracy: 0.727
[6_0,   712/994] loss: 0.811 accuracy: 0.726
[6_0,   716/994] loss: 0.773 accuracy: 0.727
[6_0,   720/994] loss: 0.936 accuracy: 0.727
[6_0,   724/994] loss: 0.734 accuracy: 0.727
[6_0,   728/994] loss: 0.825 accuracy: 0.727
[6_0,   732/994] loss: 1.165 accuracy: 0.727
[6_0,   736/994] loss: 0.937 accuracy: 0.726
[6_0,   740/994] loss: 0.866 accuracy: 0.726
[6_0,   744/994] loss: 0.868 accuracy: 0.726
[6_0,   748/994] loss: 0.779 accuracy: 0.726
[6_0,   752/994] loss: 0.661 accuracy: 0.726
[6_0,   756/994] loss: 0.820 accuracy: 0.727
[6_0,   760/994] loss: 1.240 accuracy: 0.726
[6_0,   764/994] loss: 0.971 accuracy: 0.726
[6_0,   768/994] loss: 0.582 accuracy: 0.726
[6_0,   772/994] loss: 0.903 accuracy: 0.726
[6_0,   776/994] loss: 0.767 accuracy: 0.726
[6_0,   780/994] loss: 0.886 accuracy: 0.726
[6_0,   784/994] loss: 0.733 accuracy: 0.726
[6_0,   788/994] loss: 0.818 accuracy: 0.726
[6_0,   792/994] loss: 0.907 accuracy: 0.726
[6_0,   796/994] loss: 0.996 accuracy: 0.726
[6_0,   800/994] loss: 0.899 accuracy: 0.725
[6_0,   804/994] loss: 0.941 accuracy: 0.725
[6_0,   808/994] loss: 1.078 accuracy: 0.724
[6_0,   812/994] loss: 0.979 accuracy: 0.724
[6_0,   816/994] loss: 0.866 accuracy: 0.724
[6_0,   820/994] loss: 0.876 accuracy: 0.724
[6_0,   824/994] loss: 0.970 accuracy: 0.724
[6_0,   828/994] loss: 0.914 accuracy: 0.724
[6_0,   832/994] loss: 0.784 accuracy: 0.724
[6_0,   836/994] loss: 0.993 accuracy: 0.724
[6_0,   840/994] loss: 0.915 accuracy: 0.723
[6_0,   844/994] loss: 0.767 accuracy: 0.723
[6_0,   848/994] loss: 0.684 accuracy: 0.724
[6_0,   852/994] loss: 0.655 accuracy: 0.724
[6_0,   856/994] loss: 0.914 accuracy: 0.723
[6_0,   860/994] loss: 1.073 accuracy: 0.723
[6_0,   864/994] loss: 0.895 accuracy: 0.723
[6_0,   868/994] loss: 0.701 accuracy: 0.723
[6_0,   872/994] loss: 0.792 accuracy: 0.723
[6_0,   876/994] loss: 1.016 accuracy: 0.723
[6_0,   880/994] loss: 0.846 accuracy: 0.723
[6_0,   884/994] loss: 0.924 accuracy: 0.723
[6_0,   888/994] loss: 0.765 accuracy: 0.723
[6_0,   892/994] loss: 0.767 accuracy: 0.723
[6_0,   896/994] loss: 0.594 accuracy: 0.723
[6_0,   900/994] loss: 0.673 accuracy: 0.724
[6_0,   904/994] loss: 0.729 accuracy: 0.724
[6_0,   908/994] loss: 0.670 accuracy: 0.724
[6_0,   912/994] loss: 0.636 accuracy: 0.724
[6_0,   916/994] loss: 0.531 accuracy: 0.724
[6_0,   920/994] loss: 0.986 accuracy: 0.724
[6_0,   924/994] loss: 1.136 accuracy: 0.724
[6_0,   928/994] loss: 0.897 accuracy: 0.724
[6_0,   932/994] loss: 0.825 accuracy: 0.723
[6_0,   936/994] loss: 1.062 accuracy: 0.723
[6_0,   940/994] loss: 0.911 accuracy: 0.723
[6_0,   944/994] loss: 0.827 accuracy: 0.723
[6_0,   948/994] loss: 0.947 accuracy: 0.723
[6_0,   952/994] loss: 0.993 accuracy: 0.723
[6_0,   956/994] loss: 0.608 accuracy: 0.723
[6_0,   960/994] loss: 1.121 accuracy: 0.723
[6_0,   964/994] loss: 0.977 accuracy: 0.723
[6_0,   968/994] loss: 0.804 accuracy: 0.723
[6_0,   972/994] loss: 0.655 accuracy: 0.723
[6_0,   976/994] loss: 0.668 accuracy: 0.723
[6_0,   980/994] loss: 0.870 accuracy: 0.723
[6_0,   984/994] loss: 0.910 accuracy: 0.723
[6_0,   988/994] loss: 0.780 accuracy: 0.723
[6_0,   992/994] loss: 0.774 accuracy: 0.723
2022-05-06 13:35:15.918742  :  0.6313457226475255 is higher than the best(0.6174847126118785). Saving the model at ../Models/KBP37/bert_multilingual_adam_finetune_kbp37_6_0.637413531473342_sigmoid_long2.pt
Epoch:  6
Training Loss: 202.5016, Val Loss: 1.2680, Test Loss: 1.1811
Training accuracy:0.7226, Training F1:0.7183, Validation accuracy:0.6119, Validation F1:0.6313, Test accuracy:0.6297, Test F1:0.6374
German F1: 0.5804, English F1: 0.6347, Spanish F1: 0.5930, French F1: 0.5934, Turkish F1: 0.5369
[7_0,     4/994] loss: 0.829 accuracy: 0.719
[7_0,     8/994] loss: 0.842 accuracy: 0.711
[7_0,    12/994] loss: 0.551 accuracy: 0.750
[7_0,    16/994] loss: 0.789 accuracy: 0.758
[7_0,    20/994] loss: 0.704 accuracy: 0.762
[7_0,    24/994] loss: 0.605 accuracy: 0.763
[7_0,    28/994] loss: 0.650 accuracy: 0.766
[7_0,    32/994] loss: 0.635 accuracy: 0.768
[7_0,    36/994] loss: 0.561 accuracy: 0.774
[7_0,    40/994] loss: 0.656 accuracy: 0.773
[7_0,    44/994] loss: 0.621 accuracy: 0.773
[7_0,    48/994] loss: 0.883 accuracy: 0.764
[7_0,    52/994] loss: 0.837 accuracy: 0.767
[7_0,    56/994] loss: 0.715 accuracy: 0.765
[7_0,    60/994] loss: 0.724 accuracy: 0.762
[7_0,    64/994] loss: 0.398 accuracy: 0.766
[7_0,    68/994] loss: 0.758 accuracy: 0.763
[7_0,    72/994] loss: 0.727 accuracy: 0.762
[7_0,    76/994] loss: 0.695 accuracy: 0.762
[7_0,    80/994] loss: 0.577 accuracy: 0.764
[7_0,    84/994] loss: 0.797 accuracy: 0.760
[7_0,    88/994] loss: 0.527 accuracy: 0.761
[7_0,    92/994] loss: 0.671 accuracy: 0.759
[7_0,    96/994] loss: 0.557 accuracy: 0.760
[7_0,   100/994] loss: 0.742 accuracy: 0.760
[7_0,   104/994] loss: 0.561 accuracy: 0.762
[7_0,   108/994] loss: 0.255 accuracy: 0.770
[7_0,   112/994] loss: 0.701 accuracy: 0.769
[7_0,   116/994] loss: 0.601 accuracy: 0.770
[7_0,   120/994] loss: 0.628 accuracy: 0.772
[7_0,   124/994] loss: 0.718 accuracy: 0.770
[7_0,   128/994] loss: 0.587 accuracy: 0.771
[7_0,   132/994] loss: 0.579 accuracy: 0.772
[7_0,   136/994] loss: 0.749 accuracy: 0.772
[7_0,   140/994] loss: 0.670 accuracy: 0.772
[7_0,   144/994] loss: 0.775 accuracy: 0.772
[7_0,   148/994] loss: 0.585 accuracy: 0.772
[7_0,   152/994] loss: 0.587 accuracy: 0.773
[7_0,   156/994] loss: 0.708 accuracy: 0.774
[7_0,   160/994] loss: 0.683 accuracy: 0.773
[7_0,   164/994] loss: 0.869 accuracy: 0.773
[7_0,   168/994] loss: 0.713 accuracy: 0.773
[7_0,   172/994] loss: 1.047 accuracy: 0.773
[7_0,   176/994] loss: 0.454 accuracy: 0.774
[7_0,   180/994] loss: 0.577 accuracy: 0.774
[7_0,   184/994] loss: 0.729 accuracy: 0.773
[7_0,   188/994] loss: 0.613 accuracy: 0.773
[7_0,   192/994] loss: 0.553 accuracy: 0.774
[7_0,   196/994] loss: 0.685 accuracy: 0.774
[7_0,   200/994] loss: 0.868 accuracy: 0.773
[7_0,   204/994] loss: 0.902 accuracy: 0.771
[7_0,   208/994] loss: 0.752 accuracy: 0.770
[7_0,   212/994] loss: 0.544 accuracy: 0.771
[7_0,   216/994] loss: 0.670 accuracy: 0.770
[7_0,   220/994] loss: 0.496 accuracy: 0.771
[7_0,   224/994] loss: 0.526 accuracy: 0.771
[7_0,   228/994] loss: 0.640 accuracy: 0.771
[7_0,   232/994] loss: 0.786 accuracy: 0.770
[7_0,   236/994] loss: 0.569 accuracy: 0.771
[7_0,   240/994] loss: 0.698 accuracy: 0.771
[7_0,   244/994] loss: 0.776 accuracy: 0.769
[7_0,   248/994] loss: 0.341 accuracy: 0.771
[7_0,   252/994] loss: 0.529 accuracy: 0.772
[7_0,   256/994] loss: 0.811 accuracy: 0.771
[7_0,   260/994] loss: 0.695 accuracy: 0.770
[7_0,   264/994] loss: 0.376 accuracy: 0.772
[7_0,   268/994] loss: 0.699 accuracy: 0.771
[7_0,   272/994] loss: 0.671 accuracy: 0.771
[7_0,   276/994] loss: 0.662 accuracy: 0.771
[7_0,   280/994] loss: 0.531 accuracy: 0.772
[7_0,   284/994] loss: 0.689 accuracy: 0.771
[7_0,   288/994] loss: 0.583 accuracy: 0.772
[7_0,   292/994] loss: 0.556 accuracy: 0.772
[7_0,   296/994] loss: 0.461 accuracy: 0.773
[7_0,   300/994] loss: 0.717 accuracy: 0.772
[7_0,   304/994] loss: 0.553 accuracy: 0.772
[7_0,   308/994] loss: 0.982 accuracy: 0.771
[7_0,   312/994] loss: 0.549 accuracy: 0.771
[7_0,   316/994] loss: 0.532 accuracy: 0.771
[7_0,   320/994] loss: 0.731 accuracy: 0.772
[7_0,   324/994] loss: 0.794 accuracy: 0.772
[7_0,   328/994] loss: 0.924 accuracy: 0.772
[7_0,   332/994] loss: 0.590 accuracy: 0.772
[7_0,   336/994] loss: 0.863 accuracy: 0.771
[7_0,   340/994] loss: 0.686 accuracy: 0.771
[7_0,   344/994] loss: 0.554 accuracy: 0.771
[7_0,   348/994] loss: 0.890 accuracy: 0.771
[7_0,   352/994] loss: 0.573 accuracy: 0.771
[7_0,   356/994] loss: 0.582 accuracy: 0.772
[7_0,   360/994] loss: 0.753 accuracy: 0.771
[7_0,   364/994] loss: 0.817 accuracy: 0.771
[7_0,   368/994] loss: 0.682 accuracy: 0.771
[7_0,   372/994] loss: 0.494 accuracy: 0.771
[7_0,   376/994] loss: 0.822 accuracy: 0.770
[7_0,   380/994] loss: 0.709 accuracy: 0.770
[7_0,   384/994] loss: 0.472 accuracy: 0.770
[7_0,   388/994] loss: 0.626 accuracy: 0.770
[7_0,   392/994] loss: 0.627 accuracy: 0.770
[7_0,   396/994] loss: 0.545 accuracy: 0.770
[7_0,   400/994] loss: 0.686 accuracy: 0.770
[7_0,   404/994] loss: 0.481 accuracy: 0.770
[7_0,   408/994] loss: 0.782 accuracy: 0.770
[7_0,   412/994] loss: 0.418 accuracy: 0.771
[7_0,   416/994] loss: 0.595 accuracy: 0.771
[7_0,   420/994] loss: 0.873 accuracy: 0.770
[7_0,   424/994] loss: 0.631 accuracy: 0.770
[7_0,   428/994] loss: 0.622 accuracy: 0.770
[7_0,   432/994] loss: 1.258 accuracy: 0.768
[7_0,   436/994] loss: 0.949 accuracy: 0.768
[7_0,   440/994] loss: 0.655 accuracy: 0.768
[7_0,   444/994] loss: 0.730 accuracy: 0.767
[7_0,   448/994] loss: 0.604 accuracy: 0.767
[7_0,   452/994] loss: 0.914 accuracy: 0.766
[7_0,   456/994] loss: 0.884 accuracy: 0.765
[7_0,   460/994] loss: 1.153 accuracy: 0.764
[7_0,   464/994] loss: 0.998 accuracy: 0.763
[7_0,   468/994] loss: 0.675 accuracy: 0.763
[7_0,   472/994] loss: 0.689 accuracy: 0.762
[7_0,   476/994] loss: 0.722 accuracy: 0.763
[7_0,   480/994] loss: 0.508 accuracy: 0.763
[7_0,   484/994] loss: 0.819 accuracy: 0.763
[7_0,   488/994] loss: 0.789 accuracy: 0.762
[7_0,   492/994] loss: 0.771 accuracy: 0.762
[7_0,   496/994] loss: 0.657 accuracy: 0.762
[7_0,   500/994] loss: 0.598 accuracy: 0.762
[7_0,   504/994] loss: 0.793 accuracy: 0.762
[7_0,   508/994] loss: 0.645 accuracy: 0.762
[7_0,   512/994] loss: 0.684 accuracy: 0.762
[7_0,   516/994] loss: 0.688 accuracy: 0.762
[7_0,   520/994] loss: 0.649 accuracy: 0.762
[7_0,   524/994] loss: 0.636 accuracy: 0.762
[7_0,   528/994] loss: 0.996 accuracy: 0.762
[7_0,   532/994] loss: 0.674 accuracy: 0.761
[7_0,   536/994] loss: 0.960 accuracy: 0.760
[7_0,   540/994] loss: 0.779 accuracy: 0.760
[7_0,   544/994] loss: 0.966 accuracy: 0.760
[7_0,   548/994] loss: 0.552 accuracy: 0.760
[7_0,   552/994] loss: 0.632 accuracy: 0.760
[7_0,   556/994] loss: 0.544 accuracy: 0.760
[7_0,   560/994] loss: 0.812 accuracy: 0.760
[7_0,   564/994] loss: 0.915 accuracy: 0.760
[7_0,   568/994] loss: 0.617 accuracy: 0.760
[7_0,   572/994] loss: 0.899 accuracy: 0.760
[7_0,   576/994] loss: 0.715 accuracy: 0.760
[7_0,   580/994] loss: 0.550 accuracy: 0.760
[7_0,   584/994] loss: 0.646 accuracy: 0.760
[7_0,   588/994] loss: 1.013 accuracy: 0.760
[7_0,   592/994] loss: 0.652 accuracy: 0.760
[7_0,   596/994] loss: 0.545 accuracy: 0.760
[7_0,   600/994] loss: 0.546 accuracy: 0.760
[7_0,   604/994] loss: 0.457 accuracy: 0.761
[7_0,   608/994] loss: 0.659 accuracy: 0.761
[7_0,   612/994] loss: 0.704 accuracy: 0.761
[7_0,   616/994] loss: 0.570 accuracy: 0.761
[7_0,   620/994] loss: 1.008 accuracy: 0.762
[7_0,   624/994] loss: 0.645 accuracy: 0.762
[7_0,   628/994] loss: 1.118 accuracy: 0.761
[7_0,   632/994] loss: 0.532 accuracy: 0.761
[7_0,   636/994] loss: 1.112 accuracy: 0.761
[7_0,   640/994] loss: 0.604 accuracy: 0.761
[7_0,   644/994] loss: 0.626 accuracy: 0.761
[7_0,   648/994] loss: 0.735 accuracy: 0.761
[7_0,   652/994] loss: 0.482 accuracy: 0.761
[7_0,   656/994] loss: 0.824 accuracy: 0.760
[7_0,   660/994] loss: 0.960 accuracy: 0.759
[7_0,   664/994] loss: 1.098 accuracy: 0.759
[7_0,   668/994] loss: 0.436 accuracy: 0.759
[7_0,   672/994] loss: 0.794 accuracy: 0.759
[7_0,   676/994] loss: 0.936 accuracy: 0.759
[7_0,   680/994] loss: 0.858 accuracy: 0.759
[7_0,   684/994] loss: 0.643 accuracy: 0.759
[7_0,   688/994] loss: 0.692 accuracy: 0.759
[7_0,   692/994] loss: 0.517 accuracy: 0.759
[7_0,   696/994] loss: 0.648 accuracy: 0.759
[7_0,   700/994] loss: 0.755 accuracy: 0.759
[7_0,   704/994] loss: 0.632 accuracy: 0.759
[7_0,   708/994] loss: 0.884 accuracy: 0.758
[7_0,   712/994] loss: 0.830 accuracy: 0.758
[7_0,   716/994] loss: 0.796 accuracy: 0.758
[7_0,   720/994] loss: 0.818 accuracy: 0.757
[7_0,   724/994] loss: 0.716 accuracy: 0.757
[7_0,   728/994] loss: 1.076 accuracy: 0.757
[7_0,   732/994] loss: 0.734 accuracy: 0.756
[7_0,   736/994] loss: 0.752 accuracy: 0.757
[7_0,   740/994] loss: 0.937 accuracy: 0.756
[7_0,   744/994] loss: 0.649 accuracy: 0.756
[7_0,   748/994] loss: 0.679 accuracy: 0.757
[7_0,   752/994] loss: 0.750 accuracy: 0.756
[7_0,   756/994] loss: 0.644 accuracy: 0.757
[7_0,   760/994] loss: 0.819 accuracy: 0.756
[7_0,   764/994] loss: 0.867 accuracy: 0.756
[7_0,   768/994] loss: 0.637 accuracy: 0.756
[7_0,   772/994] loss: 0.880 accuracy: 0.756
[7_0,   776/994] loss: 0.529 accuracy: 0.756
[7_0,   780/994] loss: 0.597 accuracy: 0.756
[7_0,   784/994] loss: 0.461 accuracy: 0.757
[7_0,   788/994] loss: 0.845 accuracy: 0.757
[7_0,   792/994] loss: 0.841 accuracy: 0.756
[7_0,   796/994] loss: 0.717 accuracy: 0.757
[7_0,   800/994] loss: 0.684 accuracy: 0.756
[7_0,   804/994] loss: 0.583 accuracy: 0.756
[7_0,   808/994] loss: 0.529 accuracy: 0.756
[7_0,   812/994] loss: 0.739 accuracy: 0.757
[7_0,   816/994] loss: 0.575 accuracy: 0.757
[7_0,   820/994] loss: 0.899 accuracy: 0.757
[7_0,   824/994] loss: 0.693 accuracy: 0.757
[7_0,   828/994] loss: 0.714 accuracy: 0.757
[7_0,   832/994] loss: 0.556 accuracy: 0.757
[7_0,   836/994] loss: 0.862 accuracy: 0.757
[7_0,   840/994] loss: 0.611 accuracy: 0.757
[7_0,   844/994] loss: 0.874 accuracy: 0.757
[7_0,   848/994] loss: 0.720 accuracy: 0.757
[7_0,   852/994] loss: 0.377 accuracy: 0.757
[7_0,   856/994] loss: 0.610 accuracy: 0.758
[7_0,   860/994] loss: 1.014 accuracy: 0.758
[7_0,   864/994] loss: 0.802 accuracy: 0.758
[7_0,   868/994] loss: 0.929 accuracy: 0.757
[7_0,   872/994] loss: 0.987 accuracy: 0.757
[7_0,   876/994] loss: 0.762 accuracy: 0.756
[7_0,   880/994] loss: 0.782 accuracy: 0.756
[7_0,   884/994] loss: 0.681 accuracy: 0.756
[7_0,   888/994] loss: 0.667 accuracy: 0.756
[7_0,   892/994] loss: 0.743 accuracy: 0.755
[7_0,   896/994] loss: 1.046 accuracy: 0.755
[7_0,   900/994] loss: 0.458 accuracy: 0.756
[7_0,   904/994] loss: 0.783 accuracy: 0.755
[7_0,   908/994] loss: 0.903 accuracy: 0.755
[7_0,   912/994] loss: 0.655 accuracy: 0.755
[7_0,   916/994] loss: 0.593 accuracy: 0.755
[7_0,   920/994] loss: 0.489 accuracy: 0.755
[7_0,   924/994] loss: 0.632 accuracy: 0.756
[7_0,   928/994] loss: 0.857 accuracy: 0.756
[7_0,   932/994] loss: 1.110 accuracy: 0.755
[7_0,   936/994] loss: 0.800 accuracy: 0.755
[7_0,   940/994] loss: 0.582 accuracy: 0.755
[7_0,   944/994] loss: 0.755 accuracy: 0.755
[7_0,   948/994] loss: 0.771 accuracy: 0.755
[7_0,   952/994] loss: 0.841 accuracy: 0.755
[7_0,   956/994] loss: 0.738 accuracy: 0.754
[7_0,   960/994] loss: 0.654 accuracy: 0.754
[7_0,   964/994] loss: 0.987 accuracy: 0.754
[7_0,   968/994] loss: 0.623 accuracy: 0.754
[7_0,   972/994] loss: 0.719 accuracy: 0.754
[7_0,   976/994] loss: 0.741 accuracy: 0.754
[7_0,   980/994] loss: 0.731 accuracy: 0.754
[7_0,   984/994] loss: 0.442 accuracy: 0.755
[7_0,   988/994] loss: 0.531 accuracy: 0.755
[7_0,   992/994] loss: 0.748 accuracy: 0.755
2022-05-06 14:00:48.961600  :  0.6346002833005657 is higher than the best(0.6313457226475255). Saving the model at ../Models/KBP37/bert_multilingual_adam_finetune_kbp37_7_0.6416019302877013_sigmoid_long2.pt
Epoch:  7
Training Loss: 175.2278, Val Loss: 1.3320, Test Loss: 1.2328
Training accuracy:0.7548, Training F1:0.7454, Validation accuracy:0.6253, Validation F1:0.6346, Test accuracy:0.6364, Test F1:0.6416
German F1: 0.5987, English F1: 0.6218, Spanish F1: 0.6349, French F1: 0.5937, Turkish F1: 0.5595
[8_0,     4/994] loss: 0.490 accuracy: 0.812
[8_0,     8/994] loss: 0.554 accuracy: 0.797
[8_0,    12/994] loss: 0.638 accuracy: 0.802
[8_0,    16/994] loss: 0.503 accuracy: 0.812
[8_0,    20/994] loss: 0.666 accuracy: 0.806
[8_0,    24/994] loss: 0.592 accuracy: 0.802
[8_0,    28/994] loss: 0.575 accuracy: 0.801
[8_0,    32/994] loss: 0.678 accuracy: 0.793
[8_0,    36/994] loss: 0.468 accuracy: 0.792
[8_0,    40/994] loss: 0.495 accuracy: 0.795
[8_0,    44/994] loss: 0.725 accuracy: 0.790
[8_0,    48/994] loss: 0.730 accuracy: 0.792
[8_0,    52/994] loss: 0.684 accuracy: 0.788
[8_0,    56/994] loss: 0.498 accuracy: 0.790
[8_0,    60/994] loss: 0.865 accuracy: 0.783
[8_0,    64/994] loss: 0.603 accuracy: 0.783
[8_0,    68/994] loss: 0.520 accuracy: 0.784
[8_0,    72/994] loss: 0.781 accuracy: 0.781
[8_0,    76/994] loss: 0.439 accuracy: 0.782
[8_0,    80/994] loss: 0.261 accuracy: 0.787
[8_0,    84/994] loss: 0.667 accuracy: 0.786
[8_0,    88/994] loss: 0.563 accuracy: 0.788
[8_0,    92/994] loss: 0.555 accuracy: 0.791
[8_0,    96/994] loss: 0.349 accuracy: 0.793
[8_0,   100/994] loss: 0.514 accuracy: 0.793
[8_0,   104/994] loss: 0.477 accuracy: 0.795
[8_0,   108/994] loss: 0.479 accuracy: 0.795
[8_0,   112/994] loss: 0.621 accuracy: 0.794
[8_0,   116/994] loss: 0.524 accuracy: 0.796
[8_0,   120/994] loss: 0.565 accuracy: 0.797
[8_0,   124/994] loss: 0.465 accuracy: 0.798
[8_0,   128/994] loss: 0.762 accuracy: 0.797
[8_0,   132/994] loss: 0.584 accuracy: 0.799
[8_0,   136/994] loss: 0.754 accuracy: 0.797
[8_0,   140/994] loss: 0.486 accuracy: 0.797
[8_0,   144/994] loss: 0.661 accuracy: 0.796
[8_0,   148/994] loss: 0.709 accuracy: 0.796
[8_0,   152/994] loss: 0.503 accuracy: 0.798
[8_0,   156/994] loss: 0.682 accuracy: 0.797
[8_0,   160/994] loss: 0.546 accuracy: 0.797
[8_0,   164/994] loss: 0.664 accuracy: 0.797
[8_0,   168/994] loss: 0.959 accuracy: 0.796
[8_0,   172/994] loss: 0.467 accuracy: 0.797
[8_0,   176/994] loss: 0.411 accuracy: 0.798
[8_0,   180/994] loss: 0.582 accuracy: 0.798
[8_0,   184/994] loss: 0.701 accuracy: 0.799
[8_0,   188/994] loss: 0.651 accuracy: 0.799
[8_0,   192/994] loss: 0.604 accuracy: 0.798
[8_0,   196/994] loss: 0.779 accuracy: 0.796
[8_0,   200/994] loss: 0.704 accuracy: 0.796
[8_0,   204/994] loss: 0.611 accuracy: 0.796
[8_0,   208/994] loss: 0.658 accuracy: 0.795
[8_0,   212/994] loss: 0.464 accuracy: 0.795
[8_0,   216/994] loss: 0.642 accuracy: 0.795
[8_0,   220/994] loss: 0.466 accuracy: 0.795
[8_0,   224/994] loss: 0.560 accuracy: 0.795
[8_0,   228/994] loss: 0.590 accuracy: 0.796
[8_0,   232/994] loss: 0.435 accuracy: 0.795
[8_0,   236/994] loss: 0.386 accuracy: 0.796
[8_0,   240/994] loss: 0.759 accuracy: 0.796
[8_0,   244/994] loss: 0.580 accuracy: 0.794
[8_0,   248/994] loss: 0.767 accuracy: 0.795
[8_0,   252/994] loss: 0.594 accuracy: 0.794
[8_0,   256/994] loss: 0.784 accuracy: 0.794
[8_0,   260/994] loss: 0.384 accuracy: 0.794
[8_0,   264/994] loss: 0.361 accuracy: 0.795
[8_0,   268/994] loss: 0.596 accuracy: 0.795
[8_0,   272/994] loss: 0.554 accuracy: 0.796
[8_0,   276/994] loss: 0.524 accuracy: 0.796
[8_0,   280/994] loss: 0.619 accuracy: 0.797
[8_0,   284/994] loss: 0.396 accuracy: 0.797
[8_0,   288/994] loss: 0.552 accuracy: 0.797
[8_0,   292/994] loss: 0.522 accuracy: 0.797
[8_0,   296/994] loss: 0.556 accuracy: 0.797
[8_0,   300/994] loss: 0.490 accuracy: 0.797
[8_0,   304/994] loss: 0.658 accuracy: 0.797
[8_0,   308/994] loss: 0.656 accuracy: 0.796
[8_0,   312/994] loss: 0.731 accuracy: 0.795
[8_0,   316/994] loss: 0.753 accuracy: 0.795
[8_0,   320/994] loss: 0.593 accuracy: 0.794
[8_0,   324/994] loss: 0.610 accuracy: 0.794
[8_0,   328/994] loss: 0.829 accuracy: 0.792
[8_0,   332/994] loss: 0.749 accuracy: 0.792
[8_0,   336/994] loss: 0.842 accuracy: 0.791
[8_0,   340/994] loss: 0.619 accuracy: 0.792
[8_0,   344/994] loss: 0.835 accuracy: 0.791
[8_0,   348/994] loss: 0.770 accuracy: 0.790
[8_0,   352/994] loss: 0.819 accuracy: 0.790
[8_0,   356/994] loss: 0.658 accuracy: 0.789
[8_0,   360/994] loss: 0.620 accuracy: 0.789
[8_0,   364/994] loss: 0.736 accuracy: 0.789
[8_0,   368/994] loss: 0.908 accuracy: 0.787
[8_0,   372/994] loss: 0.533 accuracy: 0.787
[8_0,   376/994] loss: 0.734 accuracy: 0.787
[8_0,   380/994] loss: 0.762 accuracy: 0.786
[8_0,   384/994] loss: 0.686 accuracy: 0.785
[8_0,   388/994] loss: 0.614 accuracy: 0.785
[8_0,   392/994] loss: 0.303 accuracy: 0.787
[8_0,   396/994] loss: 0.582 accuracy: 0.786
[8_0,   400/994] loss: 0.803 accuracy: 0.786
[8_0,   404/994] loss: 0.728 accuracy: 0.786
[8_0,   408/994] loss: 0.845 accuracy: 0.784
[8_0,   412/994] loss: 0.764 accuracy: 0.784
[8_0,   416/994] loss: 0.913 accuracy: 0.784
[8_0,   420/994] loss: 0.636 accuracy: 0.783
[8_0,   424/994] loss: 0.661 accuracy: 0.783
[8_0,   428/994] loss: 0.872 accuracy: 0.783
[8_0,   432/994] loss: 0.676 accuracy: 0.783
[8_0,   436/994] loss: 0.777 accuracy: 0.783
[8_0,   440/994] loss: 0.578 accuracy: 0.782
[8_0,   444/994] loss: 0.604 accuracy: 0.782
[8_0,   448/994] loss: 0.816 accuracy: 0.781
[8_0,   452/994] loss: 0.626 accuracy: 0.781
[8_0,   456/994] loss: 0.426 accuracy: 0.781
[8_0,   460/994] loss: 0.939 accuracy: 0.781
[8_0,   464/994] loss: 0.744 accuracy: 0.781
[8_0,   468/994] loss: 0.519 accuracy: 0.781
[8_0,   472/994] loss: 0.797 accuracy: 0.781
[8_0,   476/994] loss: 0.422 accuracy: 0.782
[8_0,   480/994] loss: 0.550 accuracy: 0.782
[8_0,   484/994] loss: 0.904 accuracy: 0.781
[8_0,   488/994] loss: 0.743 accuracy: 0.781
[8_0,   492/994] loss: 0.849 accuracy: 0.780
[8_0,   496/994] loss: 0.636 accuracy: 0.780
[8_0,   500/994] loss: 0.807 accuracy: 0.780
[8_0,   504/994] loss: 0.812 accuracy: 0.780
[8_0,   508/994] loss: 0.658 accuracy: 0.779
[8_0,   512/994] loss: 0.720 accuracy: 0.780
[8_0,   516/994] loss: 0.408 accuracy: 0.780
[8_0,   520/994] loss: 0.731 accuracy: 0.780
[8_0,   524/994] loss: 0.935 accuracy: 0.779
[8_0,   528/994] loss: 0.882 accuracy: 0.779
[8_0,   532/994] loss: 0.889 accuracy: 0.778
[8_0,   536/994] loss: 0.556 accuracy: 0.778
[8_0,   540/994] loss: 0.657 accuracy: 0.778
[8_0,   544/994] loss: 0.795 accuracy: 0.777
[8_0,   548/994] loss: 0.739 accuracy: 0.777
[8_0,   552/994] loss: 1.058 accuracy: 0.776
[8_0,   556/994] loss: 0.712 accuracy: 0.776
[8_0,   560/994] loss: 0.475 accuracy: 0.776
[8_0,   564/994] loss: 0.841 accuracy: 0.776
[8_0,   568/994] loss: 0.881 accuracy: 0.776
[8_0,   572/994] loss: 0.561 accuracy: 0.776
[8_0,   576/994] loss: 0.722 accuracy: 0.776
[8_0,   580/994] loss: 0.832 accuracy: 0.775
[8_0,   584/994] loss: 0.570 accuracy: 0.775
[8_0,   588/994] loss: 0.531 accuracy: 0.776
[8_0,   592/994] loss: 0.620 accuracy: 0.775
[8_0,   596/994] loss: 0.780 accuracy: 0.776
[8_0,   600/994] loss: 0.721 accuracy: 0.775
[8_0,   604/994] loss: 0.668 accuracy: 0.775
[8_0,   608/994] loss: 0.896 accuracy: 0.774
[8_0,   612/994] loss: 0.581 accuracy: 0.775
[8_0,   616/994] loss: 1.055 accuracy: 0.774
[8_0,   620/994] loss: 0.757 accuracy: 0.773
[8_0,   624/994] loss: 0.458 accuracy: 0.774
[8_0,   628/994] loss: 0.819 accuracy: 0.774
[8_0,   632/994] loss: 0.694 accuracy: 0.773
[8_0,   636/994] loss: 0.606 accuracy: 0.774
[8_0,   640/994] loss: 0.632 accuracy: 0.774
[8_0,   644/994] loss: 0.521 accuracy: 0.774
[8_0,   648/994] loss: 0.433 accuracy: 0.775
[8_0,   652/994] loss: 0.809 accuracy: 0.775
[8_0,   656/994] loss: 0.549 accuracy: 0.775
[8_0,   660/994] loss: 0.542 accuracy: 0.775
[8_0,   664/994] loss: 0.646 accuracy: 0.775
[8_0,   668/994] loss: 0.611 accuracy: 0.775
[8_0,   672/994] loss: 0.563 accuracy: 0.775
[8_0,   676/994] loss: 0.573 accuracy: 0.775
[8_0,   680/994] loss: 0.578 accuracy: 0.775
[8_0,   684/994] loss: 0.536 accuracy: 0.775
[8_0,   688/994] loss: 0.678 accuracy: 0.775
[8_0,   692/994] loss: 0.543 accuracy: 0.775
[8_0,   696/994] loss: 0.817 accuracy: 0.775
[8_0,   700/994] loss: 0.632 accuracy: 0.775
[8_0,   704/994] loss: 0.739 accuracy: 0.775
[8_0,   708/994] loss: 0.433 accuracy: 0.776
[8_0,   712/994] loss: 0.341 accuracy: 0.776
[8_0,   716/994] loss: 0.555 accuracy: 0.776
[8_0,   720/994] loss: 0.277 accuracy: 0.777
[8_0,   724/994] loss: 1.038 accuracy: 0.776
[8_0,   728/994] loss: 0.584 accuracy: 0.776
[8_0,   732/994] loss: 0.355 accuracy: 0.776
[8_0,   736/994] loss: 0.646 accuracy: 0.776
[8_0,   740/994] loss: 0.454 accuracy: 0.777
[8_0,   744/994] loss: 0.651 accuracy: 0.777
[8_0,   748/994] loss: 0.372 accuracy: 0.777
[8_0,   752/994] loss: 0.479 accuracy: 0.777
[8_0,   756/994] loss: 0.606 accuracy: 0.777
[8_0,   760/994] loss: 0.678 accuracy: 0.778
[8_0,   764/994] loss: 0.641 accuracy: 0.778
[8_0,   768/994] loss: 0.825 accuracy: 0.777
[8_0,   772/994] loss: 0.465 accuracy: 0.778
[8_0,   776/994] loss: 0.695 accuracy: 0.778
[8_0,   780/994] loss: 0.748 accuracy: 0.778
[8_0,   784/994] loss: 0.957 accuracy: 0.778
[8_0,   788/994] loss: 0.529 accuracy: 0.778
[8_0,   792/994] loss: 0.712 accuracy: 0.778
[8_0,   796/994] loss: 0.716 accuracy: 0.778
[8_0,   800/994] loss: 0.739 accuracy: 0.778
[8_0,   804/994] loss: 0.745 accuracy: 0.778
[8_0,   808/994] loss: 0.676 accuracy: 0.778
[8_0,   812/994] loss: 0.811 accuracy: 0.777
[8_0,   816/994] loss: 0.529 accuracy: 0.778
[8_0,   820/994] loss: 0.479 accuracy: 0.778
[8_0,   824/994] loss: 0.450 accuracy: 0.778
[8_0,   828/994] loss: 0.636 accuracy: 0.778
[8_0,   832/994] loss: 0.626 accuracy: 0.778
[8_0,   836/994] loss: 0.427 accuracy: 0.779
[8_0,   840/994] loss: 0.610 accuracy: 0.779
[8_0,   844/994] loss: 0.678 accuracy: 0.779
[8_0,   848/994] loss: 0.583 accuracy: 0.779
[8_0,   852/994] loss: 0.662 accuracy: 0.779
[8_0,   856/994] loss: 0.584 accuracy: 0.779
[8_0,   860/994] loss: 0.606 accuracy: 0.779
[8_0,   864/994] loss: 0.653 accuracy: 0.779
[8_0,   868/994] loss: 0.669 accuracy: 0.779
[8_0,   872/994] loss: 0.621 accuracy: 0.779
[8_0,   876/994] loss: 0.690 accuracy: 0.779
[8_0,   880/994] loss: 0.705 accuracy: 0.779
[8_0,   884/994] loss: 0.480 accuracy: 0.779
[8_0,   888/994] loss: 0.601 accuracy: 0.779
[8_0,   892/994] loss: 0.410 accuracy: 0.779
[8_0,   896/994] loss: 0.694 accuracy: 0.779
[8_0,   900/994] loss: 0.786 accuracy: 0.778
[8_0,   904/994] loss: 0.502 accuracy: 0.778
[8_0,   908/994] loss: 1.119 accuracy: 0.778
[8_0,   912/994] loss: 0.718 accuracy: 0.777
[8_0,   916/994] loss: 0.486 accuracy: 0.778
[8_0,   920/994] loss: 0.708 accuracy: 0.777
[8_0,   924/994] loss: 0.378 accuracy: 0.778
[8_0,   928/994] loss: 0.551 accuracy: 0.778
[8_0,   932/994] loss: 0.874 accuracy: 0.778
[8_0,   936/994] loss: 0.867 accuracy: 0.777
[8_0,   940/994] loss: 0.692 accuracy: 0.777
[8_0,   944/994] loss: 0.582 accuracy: 0.777
[8_0,   948/994] loss: 0.555 accuracy: 0.778
[8_0,   952/994] loss: 0.598 accuracy: 0.777
[8_0,   956/994] loss: 0.856 accuracy: 0.777
[8_0,   960/994] loss: 1.266 accuracy: 0.777
[8_0,   964/994] loss: 0.670 accuracy: 0.777
[8_0,   968/994] loss: 0.750 accuracy: 0.776
[8_0,   972/994] loss: 0.618 accuracy: 0.776
[8_0,   976/994] loss: 0.804 accuracy: 0.776
[8_0,   980/994] loss: 0.739 accuracy: 0.776
[8_0,   984/994] loss: 0.444 accuracy: 0.776
[8_0,   988/994] loss: 0.748 accuracy: 0.776
[8_0,   992/994] loss: 0.886 accuracy: 0.776
2022-05-06 14:26:27.492964  :  0.6368995549409188 is higher than the best(0.6346002833005657). Saving the model at ../Models/KBP37/bert_multilingual_adam_finetune_kbp37_8_0.6330635176096913_sigmoid_long2.pt
Epoch:  8
Training Loss: 160.1720, Val Loss: 1.4394, Test Loss: 1.3829
Training accuracy:0.7761, Training F1:0.7660, Validation accuracy:0.6183, Validation F1:0.6369, Test accuracy:0.6297, Test F1:0.6331
German F1: 0.5819, English F1: 0.6104, Spanish F1: 0.5570, French F1: 0.5719, Turkish F1: 0.5703
[9_0,     4/994] loss: 0.529 accuracy: 0.781
[9_0,     8/994] loss: 0.675 accuracy: 0.812
[9_0,    12/994] loss: 0.588 accuracy: 0.797
[9_0,    16/994] loss: 0.500 accuracy: 0.797
[9_0,    20/994] loss: 0.534 accuracy: 0.794
[9_0,    24/994] loss: 0.655 accuracy: 0.794
[9_0,    28/994] loss: 0.675 accuracy: 0.788
[9_0,    32/994] loss: 0.477 accuracy: 0.797
[9_0,    36/994] loss: 0.670 accuracy: 0.792
[9_0,    40/994] loss: 0.497 accuracy: 0.792
[9_0,    44/994] loss: 0.419 accuracy: 0.794
[9_0,    48/994] loss: 0.569 accuracy: 0.788
[9_0,    52/994] loss: 0.589 accuracy: 0.790
[9_0,    56/994] loss: 0.731 accuracy: 0.786
[9_0,    60/994] loss: 0.552 accuracy: 0.785
[9_0,    64/994] loss: 0.727 accuracy: 0.787
[9_0,    68/994] loss: 0.667 accuracy: 0.789
[9_0,    72/994] loss: 0.439 accuracy: 0.791
[9_0,    76/994] loss: 0.408 accuracy: 0.794
[9_0,    80/994] loss: 0.437 accuracy: 0.795
[9_0,    84/994] loss: 0.398 accuracy: 0.798
[9_0,    88/994] loss: 0.293 accuracy: 0.802
[9_0,    92/994] loss: 0.335 accuracy: 0.806
[9_0,    96/994] loss: 0.359 accuracy: 0.808
[9_0,   100/994] loss: 0.337 accuracy: 0.811
[9_0,   104/994] loss: 0.696 accuracy: 0.807
[9_0,   108/994] loss: 0.416 accuracy: 0.809
[9_0,   112/994] loss: 0.536 accuracy: 0.810
[9_0,   116/994] loss: 0.472 accuracy: 0.812
[9_0,   120/994] loss: 0.306 accuracy: 0.816
[9_0,   124/994] loss: 0.292 accuracy: 0.820
[9_0,   128/994] loss: 0.487 accuracy: 0.819
[9_0,   132/994] loss: 0.539 accuracy: 0.821
[9_0,   136/994] loss: 0.549 accuracy: 0.819
[9_0,   140/994] loss: 0.374 accuracy: 0.822
[9_0,   144/994] loss: 0.532 accuracy: 0.822
[9_0,   148/994] loss: 0.395 accuracy: 0.823
[9_0,   152/994] loss: 0.440 accuracy: 0.824
[9_0,   156/994] loss: 0.584 accuracy: 0.823
[9_0,   160/994] loss: 0.306 accuracy: 0.824
[9_0,   164/994] loss: 0.539 accuracy: 0.823
[9_0,   168/994] loss: 0.489 accuracy: 0.824
[9_0,   172/994] loss: 0.457 accuracy: 0.824
[9_0,   176/994] loss: 0.670 accuracy: 0.823
[9_0,   180/994] loss: 0.400 accuracy: 0.824
[9_0,   184/994] loss: 0.691 accuracy: 0.822
[9_0,   188/994] loss: 0.411 accuracy: 0.823
[9_0,   192/994] loss: 0.715 accuracy: 0.821
[9_0,   196/994] loss: 0.503 accuracy: 0.821
[9_0,   200/994] loss: 0.605 accuracy: 0.819
[9_0,   204/994] loss: 0.489 accuracy: 0.819
[9_0,   208/994] loss: 0.565 accuracy: 0.817
[9_0,   212/994] loss: 0.667 accuracy: 0.815
[9_0,   216/994] loss: 0.517 accuracy: 0.815
[9_0,   220/994] loss: 0.492 accuracy: 0.815
[9_0,   224/994] loss: 0.583 accuracy: 0.813
[9_0,   228/994] loss: 0.552 accuracy: 0.813
[9_0,   232/994] loss: 0.568 accuracy: 0.813
[9_0,   236/994] loss: 0.437 accuracy: 0.814
[9_0,   240/994] loss: 0.448 accuracy: 0.814
[9_0,   244/994] loss: 0.698 accuracy: 0.814
[9_0,   248/994] loss: 0.421 accuracy: 0.815
[9_0,   252/994] loss: 0.588 accuracy: 0.815
[9_0,   256/994] loss: 0.449 accuracy: 0.815
[9_0,   260/994] loss: 0.585 accuracy: 0.815
[9_0,   264/994] loss: 0.511 accuracy: 0.815
[9_0,   268/994] loss: 0.493 accuracy: 0.815
[9_0,   272/994] loss: 0.606 accuracy: 0.814
[9_0,   276/994] loss: 0.382 accuracy: 0.814
[9_0,   280/994] loss: 0.738 accuracy: 0.813
[9_0,   284/994] loss: 0.555 accuracy: 0.813
[9_0,   288/994] loss: 0.483 accuracy: 0.812
[9_0,   292/994] loss: 0.586 accuracy: 0.812
[9_0,   296/994] loss: 0.654 accuracy: 0.811
[9_0,   300/994] loss: 0.659 accuracy: 0.810
[9_0,   304/994] loss: 0.600 accuracy: 0.810
[9_0,   308/994] loss: 0.664 accuracy: 0.809
[9_0,   312/994] loss: 0.670 accuracy: 0.809
[9_0,   316/994] loss: 0.699 accuracy: 0.809
[9_0,   320/994] loss: 0.523 accuracy: 0.810
[9_0,   324/994] loss: 0.710 accuracy: 0.809
[9_0,   328/994] loss: 0.594 accuracy: 0.809
[9_0,   332/994] loss: 0.488 accuracy: 0.809
[9_0,   336/994] loss: 0.692 accuracy: 0.808
[9_0,   340/994] loss: 0.293 accuracy: 0.810
[9_0,   344/994] loss: 0.486 accuracy: 0.810
[9_0,   348/994] loss: 0.501 accuracy: 0.810
[9_0,   352/994] loss: 0.423 accuracy: 0.811
[9_0,   356/994] loss: 0.207 accuracy: 0.812
[9_0,   360/994] loss: 0.420 accuracy: 0.812
[9_0,   364/994] loss: 0.321 accuracy: 0.813
[9_0,   368/994] loss: 0.709 accuracy: 0.812
[9_0,   372/994] loss: 0.604 accuracy: 0.812
[9_0,   376/994] loss: 0.604 accuracy: 0.812
[9_0,   380/994] loss: 0.464 accuracy: 0.812
[9_0,   384/994] loss: 0.545 accuracy: 0.812
[9_0,   388/994] loss: 0.541 accuracy: 0.812
[9_0,   392/994] loss: 0.584 accuracy: 0.812
[9_0,   396/994] loss: 0.682 accuracy: 0.811
[9_0,   400/994] loss: 0.448 accuracy: 0.812
[9_0,   404/994] loss: 0.459 accuracy: 0.812
[9_0,   408/994] loss: 0.591 accuracy: 0.812
[9_0,   412/994] loss: 0.385 accuracy: 0.812
[9_0,   416/994] loss: 0.535 accuracy: 0.812
[9_0,   420/994] loss: 0.501 accuracy: 0.812
[9_0,   424/994] loss: 0.358 accuracy: 0.812
[9_0,   428/994] loss: 0.439 accuracy: 0.812
[9_0,   432/994] loss: 0.654 accuracy: 0.812
[9_0,   436/994] loss: 0.547 accuracy: 0.811
[9_0,   440/994] loss: 0.441 accuracy: 0.811
[9_0,   444/994] loss: 0.572 accuracy: 0.812
[9_0,   448/994] loss: 0.481 accuracy: 0.812
[9_0,   452/994] loss: 0.447 accuracy: 0.812
[9_0,   456/994] loss: 0.580 accuracy: 0.811
[9_0,   460/994] loss: 0.351 accuracy: 0.812
[9_0,   464/994] loss: 0.641 accuracy: 0.812
[9_0,   468/994] loss: 0.654 accuracy: 0.812
[9_0,   472/994] loss: 0.539 accuracy: 0.812
[9_0,   476/994] loss: 0.635 accuracy: 0.811
[9_0,   480/994] loss: 0.587 accuracy: 0.811
[9_0,   484/994] loss: 0.601 accuracy: 0.811
[9_0,   488/994] loss: 0.569 accuracy: 0.811
[9_0,   492/994] loss: 0.552 accuracy: 0.810
[9_0,   496/994] loss: 0.394 accuracy: 0.811
[9_0,   500/994] loss: 0.639 accuracy: 0.810
[9_0,   504/994] loss: 0.518 accuracy: 0.810
[9_0,   508/994] loss: 0.318 accuracy: 0.810
[9_0,   512/994] loss: 0.328 accuracy: 0.811
[9_0,   516/994] loss: 0.685 accuracy: 0.810
[9_0,   520/994] loss: 0.670 accuracy: 0.810
[9_0,   524/994] loss: 0.469 accuracy: 0.810
[9_0,   528/994] loss: 0.503 accuracy: 0.810
[9_0,   532/994] loss: 0.543 accuracy: 0.810
[9_0,   536/994] loss: 0.396 accuracy: 0.810
[9_0,   540/994] loss: 0.724 accuracy: 0.809
[9_0,   544/994] loss: 0.512 accuracy: 0.809
[9_0,   548/994] loss: 0.474 accuracy: 0.809
[9_0,   552/994] loss: 0.379 accuracy: 0.809
[9_0,   556/994] loss: 0.456 accuracy: 0.809
[9_0,   560/994] loss: 0.751 accuracy: 0.808
[9_0,   564/994] loss: 0.554 accuracy: 0.808
[9_0,   568/994] loss: 0.741 accuracy: 0.808
[9_0,   572/994] loss: 0.403 accuracy: 0.808
[9_0,   576/994] loss: 0.563 accuracy: 0.808
[9_0,   580/994] loss: 0.487 accuracy: 0.808
[9_0,   584/994] loss: 0.741 accuracy: 0.808
[9_0,   588/994] loss: 0.822 accuracy: 0.807
[9_0,   592/994] loss: 0.501 accuracy: 0.807
[9_0,   596/994] loss: 0.537 accuracy: 0.807
[9_0,   600/994] loss: 0.575 accuracy: 0.807
[9_0,   604/994] loss: 0.583 accuracy: 0.806
[9_0,   608/994] loss: 0.390 accuracy: 0.806
[9_0,   612/994] loss: 0.522 accuracy: 0.806
[9_0,   616/994] loss: 0.716 accuracy: 0.806
[9_0,   620/994] loss: 0.734 accuracy: 0.805
[9_0,   624/994] loss: 0.340 accuracy: 0.805
[9_0,   628/994] loss: 0.739 accuracy: 0.805
[9_0,   632/994] loss: 0.499 accuracy: 0.805
[9_0,   636/994] loss: 0.669 accuracy: 0.805
[9_0,   640/994] loss: 0.466 accuracy: 0.805
[9_0,   644/994] loss: 0.457 accuracy: 0.805
[9_0,   648/994] loss: 0.496 accuracy: 0.805
[9_0,   652/994] loss: 0.574 accuracy: 0.805
[9_0,   656/994] loss: 0.515 accuracy: 0.805
[9_0,   660/994] loss: 0.409 accuracy: 0.806
[9_0,   664/994] loss: 0.380 accuracy: 0.806
[9_0,   668/994] loss: 0.332 accuracy: 0.806
[9_0,   672/994] loss: 0.490 accuracy: 0.807
[9_0,   676/994] loss: 0.427 accuracy: 0.807
[9_0,   680/994] loss: 0.421 accuracy: 0.807
[9_0,   684/994] loss: 0.556 accuracy: 0.807
[9_0,   688/994] loss: 0.456 accuracy: 0.807
[9_0,   692/994] loss: 0.768 accuracy: 0.807
[9_0,   696/994] loss: 0.559 accuracy: 0.807
[9_0,   700/994] loss: 0.436 accuracy: 0.807
[9_0,   704/994] loss: 0.608 accuracy: 0.807
[9_0,   708/994] loss: 0.424 accuracy: 0.807
[9_0,   712/994] loss: 0.511 accuracy: 0.807
[9_0,   716/994] loss: 0.375 accuracy: 0.808
[9_0,   720/994] loss: 0.463 accuracy: 0.808
[9_0,   724/994] loss: 0.339 accuracy: 0.808
[9_0,   728/994] loss: 0.533 accuracy: 0.808
[9_0,   732/994] loss: 0.433 accuracy: 0.808
[9_0,   736/994] loss: 0.457 accuracy: 0.808
[9_0,   740/994] loss: 0.546 accuracy: 0.809
[9_0,   744/994] loss: 0.339 accuracy: 0.809
[9_0,   748/994] loss: 0.544 accuracy: 0.809
[9_0,   752/994] loss: 0.440 accuracy: 0.809
[9_0,   756/994] loss: 0.388 accuracy: 0.809
[9_0,   760/994] loss: 0.475 accuracy: 0.809
[9_0,   764/994] loss: 0.880 accuracy: 0.808
[9_0,   768/994] loss: 0.735 accuracy: 0.808
[9_0,   772/994] loss: 0.463 accuracy: 0.808
[9_0,   776/994] loss: 0.366 accuracy: 0.808
[9_0,   780/994] loss: 0.573 accuracy: 0.808
[9_0,   784/994] loss: 0.464 accuracy: 0.808
[9_0,   788/994] loss: 0.646 accuracy: 0.808
[9_0,   792/994] loss: 0.681 accuracy: 0.808
[9_0,   796/994] loss: 0.426 accuracy: 0.808
[9_0,   800/994] loss: 0.481 accuracy: 0.808
[9_0,   804/994] loss: 0.427 accuracy: 0.808
[9_0,   808/994] loss: 0.499 accuracy: 0.809
[9_0,   812/994] loss: 0.764 accuracy: 0.808
[9_0,   816/994] loss: 0.488 accuracy: 0.808
[9_0,   820/994] loss: 0.616 accuracy: 0.808
[9_0,   824/994] loss: 0.400 accuracy: 0.808
[9_0,   828/994] loss: 0.506 accuracy: 0.808
[9_0,   832/994] loss: 0.814 accuracy: 0.808
[9_0,   836/994] loss: 0.723 accuracy: 0.808
[9_0,   840/994] loss: 0.352 accuracy: 0.808
[9_0,   844/994] loss: 0.516 accuracy: 0.809
[9_0,   848/994] loss: 0.549 accuracy: 0.808
[9_0,   852/994] loss: 0.729 accuracy: 0.808
[9_0,   856/994] loss: 0.624 accuracy: 0.808
[9_0,   860/994] loss: 0.574 accuracy: 0.808
[9_0,   864/994] loss: 0.644 accuracy: 0.807
[9_0,   868/994] loss: 0.612 accuracy: 0.807
[9_0,   872/994] loss: 0.830 accuracy: 0.807
[9_0,   876/994] loss: 0.961 accuracy: 0.806
[9_0,   880/994] loss: 0.563 accuracy: 0.806
[9_0,   884/994] loss: 0.384 accuracy: 0.807
[9_0,   888/994] loss: 0.756 accuracy: 0.807
[9_0,   892/994] loss: 0.412 accuracy: 0.807
[9_0,   896/994] loss: 0.738 accuracy: 0.807
[9_0,   900/994] loss: 0.473 accuracy: 0.807
[9_0,   904/994] loss: 0.732 accuracy: 0.807
[9_0,   908/994] loss: 0.409 accuracy: 0.807
[9_0,   912/994] loss: 0.482 accuracy: 0.807
[9_0,   916/994] loss: 0.527 accuracy: 0.807
[9_0,   920/994] loss: 0.466 accuracy: 0.807
[9_0,   924/994] loss: 0.728 accuracy: 0.806
[9_0,   928/994] loss: 0.853 accuracy: 0.806
[9_0,   932/994] loss: 0.615 accuracy: 0.806
[9_0,   936/994] loss: 0.509 accuracy: 0.806
[9_0,   940/994] loss: 0.800 accuracy: 0.806
[9_0,   944/994] loss: 0.506 accuracy: 0.806
[9_0,   948/994] loss: 0.579 accuracy: 0.806
[9_0,   952/994] loss: 0.760 accuracy: 0.806
[9_0,   956/994] loss: 0.598 accuracy: 0.806
[9_0,   960/994] loss: 0.796 accuracy: 0.805
[9_0,   964/994] loss: 0.680 accuracy: 0.805
[9_0,   968/994] loss: 0.539 accuracy: 0.805
[9_0,   972/994] loss: 1.156 accuracy: 0.804
[9_0,   976/994] loss: 0.439 accuracy: 0.804
[9_0,   980/994] loss: 0.751 accuracy: 0.804
[9_0,   984/994] loss: 0.435 accuracy: 0.804
[9_0,   988/994] loss: 0.460 accuracy: 0.804
[9_0,   992/994] loss: 0.660 accuracy: 0.804
Epoch:  9
Training Loss: 134.4248, Val Loss: 1.5214, Test Loss: 1.4487
Training accuracy:0.8037, Training F1:0.7896, Validation accuracy:0.6195, Validation F1:0.6346, Test accuracy:0.6282, Test F1:0.6361
German F1: 0.5608, English F1: 0.5944, Spanish F1: 0.5744, French F1: 0.5653, Turkish F1: 0.5472
[10_0,     4/994] loss: 0.320 accuracy: 0.844
[10_0,     8/994] loss: 0.479 accuracy: 0.820
[10_0,    12/994] loss: 0.485 accuracy: 0.823
[10_0,    16/994] loss: 0.386 accuracy: 0.828
[10_0,    20/994] loss: 0.699 accuracy: 0.816
[10_0,    24/994] loss: 0.512 accuracy: 0.812
[10_0,    28/994] loss: 0.297 accuracy: 0.819
[10_0,    32/994] loss: 0.685 accuracy: 0.812
[10_0,    36/994] loss: 0.479 accuracy: 0.812
[10_0,    40/994] loss: 0.406 accuracy: 0.814
[10_0,    44/994] loss: 0.529 accuracy: 0.815
[10_0,    48/994] loss: 0.195 accuracy: 0.824
[10_0,    52/994] loss: 0.286 accuracy: 0.829
[10_0,    56/994] loss: 0.416 accuracy: 0.833
[10_0,    60/994] loss: 0.544 accuracy: 0.830
[10_0,    64/994] loss: 0.239 accuracy: 0.837
[10_0,    68/994] loss: 0.354 accuracy: 0.839
[10_0,    72/994] loss: 0.355 accuracy: 0.841
[10_0,    76/994] loss: 0.519 accuracy: 0.841
[10_0,    80/994] loss: 0.513 accuracy: 0.841
[10_0,    84/994] loss: 0.503 accuracy: 0.842
[10_0,    88/994] loss: 0.455 accuracy: 0.842
[10_0,    92/994] loss: 0.334 accuracy: 0.844
[10_0,    96/994] loss: 0.348 accuracy: 0.844
[10_0,   100/994] loss: 0.176 accuracy: 0.849
[10_0,   104/994] loss: 0.467 accuracy: 0.846
[10_0,   108/994] loss: 0.403 accuracy: 0.844
[10_0,   112/994] loss: 0.514 accuracy: 0.843
[10_0,   116/994] loss: 0.331 accuracy: 0.844
[10_0,   120/994] loss: 0.430 accuracy: 0.844
[10_0,   124/994] loss: 0.336 accuracy: 0.845
[10_0,   128/994] loss: 0.483 accuracy: 0.844
[10_0,   132/994] loss: 0.356 accuracy: 0.845
[10_0,   136/994] loss: 0.471 accuracy: 0.844
[10_0,   140/994] loss: 0.415 accuracy: 0.845
[10_0,   144/994] loss: 0.289 accuracy: 0.847
[10_0,   148/994] loss: 0.494 accuracy: 0.845
[10_0,   152/994] loss: 0.449 accuracy: 0.844
[10_0,   156/994] loss: 0.332 accuracy: 0.846
[10_0,   160/994] loss: 0.222 accuracy: 0.846
[10_0,   164/994] loss: 0.309 accuracy: 0.846
[10_0,   168/994] loss: 0.342 accuracy: 0.847
[10_0,   172/994] loss: 0.316 accuracy: 0.848
[10_0,   176/994] loss: 0.347 accuracy: 0.848
[10_0,   180/994] loss: 0.406 accuracy: 0.847
[10_0,   184/994] loss: 0.415 accuracy: 0.847
[10_0,   188/994] loss: 0.278 accuracy: 0.848
[10_0,   192/994] loss: 0.505 accuracy: 0.848
[10_0,   196/994] loss: 0.343 accuracy: 0.848
[10_0,   200/994] loss: 0.493 accuracy: 0.847
[10_0,   204/994] loss: 0.498 accuracy: 0.845
[10_0,   208/994] loss: 0.512 accuracy: 0.845
[10_0,   212/994] loss: 0.510 accuracy: 0.844
[10_0,   216/994] loss: 0.558 accuracy: 0.843
[10_0,   220/994] loss: 0.252 accuracy: 0.845
[10_0,   224/994] loss: 0.453 accuracy: 0.845
[10_0,   228/994] loss: 0.667 accuracy: 0.844
[10_0,   232/994] loss: 0.334 accuracy: 0.845
[10_0,   236/994] loss: 0.535 accuracy: 0.844
[10_0,   240/994] loss: 0.310 accuracy: 0.844
[10_0,   244/994] loss: 0.482 accuracy: 0.844
[10_0,   248/994] loss: 0.491 accuracy: 0.843
[10_0,   252/994] loss: 0.380 accuracy: 0.844
[10_0,   256/994] loss: 0.407 accuracy: 0.844
[10_0,   260/994] loss: 0.344 accuracy: 0.844
[10_0,   264/994] loss: 0.289 accuracy: 0.845
[10_0,   268/994] loss: 0.505 accuracy: 0.845
[10_0,   272/994] loss: 0.531 accuracy: 0.844
[10_0,   276/994] loss: 0.459 accuracy: 0.844
[10_0,   280/994] loss: 0.457 accuracy: 0.843
[10_0,   284/994] loss: 0.367 accuracy: 0.843
[10_0,   288/994] loss: 0.210 accuracy: 0.844
[10_0,   292/994] loss: 0.471 accuracy: 0.843
[10_0,   296/994] loss: 0.383 accuracy: 0.844
[10_0,   300/994] loss: 0.322 accuracy: 0.845
[10_0,   304/994] loss: 0.424 accuracy: 0.845
[10_0,   308/994] loss: 0.370 accuracy: 0.845
[10_0,   312/994] loss: 0.496 accuracy: 0.845
[10_0,   316/994] loss: 0.272 accuracy: 0.845
[10_0,   320/994] loss: 0.398 accuracy: 0.845
[10_0,   324/994] loss: 0.464 accuracy: 0.845
[10_0,   328/994] loss: 0.715 accuracy: 0.844
[10_0,   332/994] loss: 0.573 accuracy: 0.843
[10_0,   336/994] loss: 0.392 accuracy: 0.844
[10_0,   340/994] loss: 0.662 accuracy: 0.843
[10_0,   344/994] loss: 0.599 accuracy: 0.843
[10_0,   348/994] loss: 0.553 accuracy: 0.842
[10_0,   352/994] loss: 0.283 accuracy: 0.843
[10_0,   356/994] loss: 0.401 accuracy: 0.843
[10_0,   360/994] loss: 0.584 accuracy: 0.843
[10_0,   364/994] loss: 0.641 accuracy: 0.842
[10_0,   368/994] loss: 0.395 accuracy: 0.842
[10_0,   372/994] loss: 0.263 accuracy: 0.842
[10_0,   376/994] loss: 0.461 accuracy: 0.842
[10_0,   380/994] loss: 0.580 accuracy: 0.841
[10_0,   384/994] loss: 0.658 accuracy: 0.841
[10_0,   388/994] loss: 0.470 accuracy: 0.841
[10_0,   392/994] loss: 0.279 accuracy: 0.841
[10_0,   396/994] loss: 0.323 accuracy: 0.842
[10_0,   400/994] loss: 0.700 accuracy: 0.841
[10_0,   404/994] loss: 0.676 accuracy: 0.840
[10_0,   408/994] loss: 0.304 accuracy: 0.841
[10_0,   412/994] loss: 0.315 accuracy: 0.841
[10_0,   416/994] loss: 0.608 accuracy: 0.841
[10_0,   420/994] loss: 0.355 accuracy: 0.841
[10_0,   424/994] loss: 0.368 accuracy: 0.841
[10_0,   428/994] loss: 0.332 accuracy: 0.841
[10_0,   432/994] loss: 0.475 accuracy: 0.841
[10_0,   436/994] loss: 0.480 accuracy: 0.841
[10_0,   440/994] loss: 0.451 accuracy: 0.840
[10_0,   444/994] loss: 0.393 accuracy: 0.841
[10_0,   448/994] loss: 0.339 accuracy: 0.841
[10_0,   452/994] loss: 0.514 accuracy: 0.841
[10_0,   456/994] loss: 0.359 accuracy: 0.841
[10_0,   460/994] loss: 0.283 accuracy: 0.841
[10_0,   464/994] loss: 0.729 accuracy: 0.840
[10_0,   468/994] loss: 0.395 accuracy: 0.840
[10_0,   472/994] loss: 0.426 accuracy: 0.841
[10_0,   476/994] loss: 0.472 accuracy: 0.840
[10_0,   480/994] loss: 0.365 accuracy: 0.840
[10_0,   484/994] loss: 0.351 accuracy: 0.841
[10_0,   488/994] loss: 0.530 accuracy: 0.841
[10_0,   492/994] loss: 0.394 accuracy: 0.841
[10_0,   496/994] loss: 0.496 accuracy: 0.840
[10_0,   500/994] loss: 0.616 accuracy: 0.840
[10_0,   504/994] loss: 0.457 accuracy: 0.839
[10_0,   508/994] loss: 0.539 accuracy: 0.839
[10_0,   512/994] loss: 0.308 accuracy: 0.839
[10_0,   516/994] loss: 0.360 accuracy: 0.839
[10_0,   520/994] loss: 0.504 accuracy: 0.838
[10_0,   524/994] loss: 0.462 accuracy: 0.838
[10_0,   528/994] loss: 0.274 accuracy: 0.839
[10_0,   532/994] loss: 0.681 accuracy: 0.838
[10_0,   536/994] loss: 0.460 accuracy: 0.838
[10_0,   540/994] loss: 0.323 accuracy: 0.839
[10_0,   544/994] loss: 0.515 accuracy: 0.838
[10_0,   548/994] loss: 0.611 accuracy: 0.838
[10_0,   552/994] loss: 0.368 accuracy: 0.838
[10_0,   556/994] loss: 0.566 accuracy: 0.838
[10_0,   560/994] loss: 0.407 accuracy: 0.838
[10_0,   564/994] loss: 0.435 accuracy: 0.838
[10_0,   568/994] loss: 0.359 accuracy: 0.838
[10_0,   572/994] loss: 0.639 accuracy: 0.838
[10_0,   576/994] loss: 0.336 accuracy: 0.838
[10_0,   580/994] loss: 0.830 accuracy: 0.838
[10_0,   584/994] loss: 0.703 accuracy: 0.837
[10_0,   588/994] loss: 0.301 accuracy: 0.838
[10_0,   592/994] loss: 0.395 accuracy: 0.838
[10_0,   596/994] loss: 0.598 accuracy: 0.837
[10_0,   600/994] loss: 0.281 accuracy: 0.838
[10_0,   604/994] loss: 0.544 accuracy: 0.837
[10_0,   608/994] loss: 0.437 accuracy: 0.837
[10_0,   612/994] loss: 0.802 accuracy: 0.837
[10_0,   616/994] loss: 0.644 accuracy: 0.837
[10_0,   620/994] loss: 0.416 accuracy: 0.836
[10_0,   624/994] loss: 0.442 accuracy: 0.837
[10_0,   628/994] loss: 0.552 accuracy: 0.836
[10_0,   632/994] loss: 0.440 accuracy: 0.836
[10_0,   636/994] loss: 0.656 accuracy: 0.835
[10_0,   640/994] loss: 0.383 accuracy: 0.836
[10_0,   644/994] loss: 0.684 accuracy: 0.835
[10_0,   648/994] loss: 0.418 accuracy: 0.835
[10_0,   652/994] loss: 0.530 accuracy: 0.835
[10_0,   656/994] loss: 0.550 accuracy: 0.835
[10_0,   660/994] loss: 0.307 accuracy: 0.835
[10_0,   664/994] loss: 0.434 accuracy: 0.835
[10_0,   668/994] loss: 0.354 accuracy: 0.835
[10_0,   672/994] loss: 0.374 accuracy: 0.836
[10_0,   676/994] loss: 0.604 accuracy: 0.835
[10_0,   680/994] loss: 0.627 accuracy: 0.835
[10_0,   684/994] loss: 0.537 accuracy: 0.835
[10_0,   688/994] loss: 0.511 accuracy: 0.835
[10_0,   692/994] loss: 0.380 accuracy: 0.835
[10_0,   696/994] loss: 0.728 accuracy: 0.835
[10_0,   700/994] loss: 0.549 accuracy: 0.835
[10_0,   704/994] loss: 0.515 accuracy: 0.835
[10_0,   708/994] loss: 0.643 accuracy: 0.834
[10_0,   712/994] loss: 0.255 accuracy: 0.835
[10_0,   716/994] loss: 0.525 accuracy: 0.835
[10_0,   720/994] loss: 0.568 accuracy: 0.834
[10_0,   724/994] loss: 0.570 accuracy: 0.834
[10_0,   728/994] loss: 0.332 accuracy: 0.834
[10_0,   732/994] loss: 0.501 accuracy: 0.834
[10_0,   736/994] loss: 0.470 accuracy: 0.833
[10_0,   740/994] loss: 0.512 accuracy: 0.833
[10_0,   744/994] loss: 0.403 accuracy: 0.833
[10_0,   748/994] loss: 0.433 accuracy: 0.833
[10_0,   752/994] loss: 0.665 accuracy: 0.833
[10_0,   756/994] loss: 0.411 accuracy: 0.833
[10_0,   760/994] loss: 0.455 accuracy: 0.833
[10_0,   764/994] loss: 0.339 accuracy: 0.834
[10_0,   768/994] loss: 0.346 accuracy: 0.834
[10_0,   772/994] loss: 0.319 accuracy: 0.834
[10_0,   776/994] loss: 0.204 accuracy: 0.834
[10_0,   780/994] loss: 0.481 accuracy: 0.834
[10_0,   784/994] loss: 0.249 accuracy: 0.835
[10_0,   788/994] loss: 0.476 accuracy: 0.835
[10_0,   792/994] loss: 0.491 accuracy: 0.834
[10_0,   796/994] loss: 0.417 accuracy: 0.835
[10_0,   800/994] loss: 0.462 accuracy: 0.835
[10_0,   804/994] loss: 0.440 accuracy: 0.835
[10_0,   808/994] loss: 0.549 accuracy: 0.834
[10_0,   812/994] loss: 0.409 accuracy: 0.835
[10_0,   816/994] loss: 0.936 accuracy: 0.834
[10_0,   820/994] loss: 0.606 accuracy: 0.834
[10_0,   824/994] loss: 0.313 accuracy: 0.834
[10_0,   828/994] loss: 0.547 accuracy: 0.834
[10_0,   832/994] loss: 0.495 accuracy: 0.834
[10_0,   836/994] loss: 0.629 accuracy: 0.834
[10_0,   840/994] loss: 0.418 accuracy: 0.834
[10_0,   844/994] loss: 0.418 accuracy: 0.834
[10_0,   848/994] loss: 0.397 accuracy: 0.834
[10_0,   852/994] loss: 0.373 accuracy: 0.834
[10_0,   856/994] loss: 0.513 accuracy: 0.834
[10_0,   860/994] loss: 0.502 accuracy: 0.834
[10_0,   864/994] loss: 0.431 accuracy: 0.833
[10_0,   868/994] loss: 0.330 accuracy: 0.834
[10_0,   872/994] loss: 0.531 accuracy: 0.833
[10_0,   876/994] loss: 0.479 accuracy: 0.833
[10_0,   880/994] loss: 0.528 accuracy: 0.833
[10_0,   884/994] loss: 0.398 accuracy: 0.833
[10_0,   888/994] loss: 0.304 accuracy: 0.833
[10_0,   892/994] loss: 0.514 accuracy: 0.833
[10_0,   896/994] loss: 0.510 accuracy: 0.833
[10_0,   900/994] loss: 0.729 accuracy: 0.833
[10_0,   904/994] loss: 0.801 accuracy: 0.833
[10_0,   908/994] loss: 0.732 accuracy: 0.833
[10_0,   912/994] loss: 0.527 accuracy: 0.833
[10_0,   916/994] loss: 0.491 accuracy: 0.833
[10_0,   920/994] loss: 0.318 accuracy: 0.833
[10_0,   924/994] loss: 0.426 accuracy: 0.833
[10_0,   928/994] loss: 0.541 accuracy: 0.833
[10_0,   932/994] loss: 0.538 accuracy: 0.833
[10_0,   936/994] loss: 0.507 accuracy: 0.833
[10_0,   940/994] loss: 0.495 accuracy: 0.833
[10_0,   944/994] loss: 0.333 accuracy: 0.833
[10_0,   948/994] loss: 0.441 accuracy: 0.833
[10_0,   952/994] loss: 0.430 accuracy: 0.833
[10_0,   956/994] loss: 0.562 accuracy: 0.832
[10_0,   960/994] loss: 0.324 accuracy: 0.833
[10_0,   964/994] loss: 0.367 accuracy: 0.833
[10_0,   968/994] loss: 0.377 accuracy: 0.833
[10_0,   972/994] loss: 0.245 accuracy: 0.833
[10_0,   976/994] loss: 0.649 accuracy: 0.833
[10_0,   980/994] loss: 0.314 accuracy: 0.833
[10_0,   984/994] loss: 0.375 accuracy: 0.833
[10_0,   988/994] loss: 0.596 accuracy: 0.833
[10_0,   992/994] loss: 0.540 accuracy: 0.833
2022-05-06 15:17:10.932172  :  0.6433877570000848 is higher than the best(0.6368995549409188). Saving the model at ../Models/KBP37/bert_multilingual_adam_finetune_kbp37_10_0.6423571840197543_sigmoid_long2.pt
Epoch:  10
Training Loss: 112.8621, Val Loss: 1.5649, Test Loss: 1.4996
Training accuracy:0.8329, Training F1:0.8242, Validation accuracy:0.6288, Validation F1:0.6434, Test accuracy:0.6323, Test F1:0.6424
German F1: 0.6065, English F1: 0.6689, Spanish F1: 0.5784, French F1: 0.5971, Turkish F1: 0.5725
