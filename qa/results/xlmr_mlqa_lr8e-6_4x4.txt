Fine-tuning /cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/xlm-roberta-large on mlqa using GPU 7
Load data from /cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/download/, and save models to /cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter/
************************
/cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/xlm-roberta-large
************************

Predictions on mlqa
  en 
2022-05-09 21:37:11.928558: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0
05/09/2022 21:37:15 - WARNING - __main__ -   Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, 16-bits training: False
You are using a model of type xlm-roberta to instantiate a model of type xlm. This is not supported for all configurations of models and can yield errors.
Some weights of the model checkpoint at /cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//squad/xlm-KG_LR8e-6_EPOCH2.0_maxlen384_batchsize4_gradacc4 were not used when initializing XLMRobertaModel: ['base_model.encoder.layer.10.attention.self.key.bias', 'base_model.encoder.layer.18.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.22.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.16.attention.self.value.bias', 'base_model.encoder.layer.13.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.18.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.2.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.19.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.17.attention.output.LayerNorm.bias', 'base_model.encoder.layer.15.attention.output.LayerNorm.weight', 'base_model.encoder.layer.22.attention.self.value.weight', 'base_model.encoder.layer.21.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.5.attention.output.dense.weight', 'base_model.encoder.layer.2.attention.output.LayerNorm.weight', 'base_model.encoder.layer.15.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.6.output.LayerNorm.weight', 'base_model.encoder.layer.18.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.15.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.1.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.8.output.LayerNorm.weight', 'base_model.encoder.layer.11.attention.self.value.bias', 'base_model.encoder.layer.11.output.LayerNorm.bias', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.13.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.23.intermediate.dense.weight', 'base_model.encoder.layer.8.attention.self.key.bias', 'base_model.encoder.layer.17.output.dense.bias', 'base_model.encoder.layer.15.attention.output.dense.bias', 'base_model.encoder.layer.21.attention.output.LayerNorm.bias', 'base_model.encoder.layer.5.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.12.output.LayerNorm.weight', 'base_model.encoder.layer.3.attention.self.query.bias', 'base_model.encoder.layer.10.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.5.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.12.attention.self.query.weight', 'base_model.encoder.layer.6.attention.output.dense.bias', 'base_model.encoder.layer.11.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.3.output.LayerNorm.weight', 'base_model.encoder.layer.6.attention.output.LayerNorm.weight', 'base_model.encoder.layer.7.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.13.attention.output.LayerNorm.weight', 'base_model.encoder.layer.21.attention.self.value.weight', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.12.output.LayerNorm.bias', 'base_model.encoder.layer.13.output.dense.weight', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.14.attention.output.dense.weight', 'base_model.encoder.layer.15.attention.self.key.bias', 'base_model.encoder.layer.21.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.19.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.15.attention.output.dense.weight', 'base_model.encoder.layer.7.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.11.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.19.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.17.intermediate.dense.bias', 'base_model.encoder.layer.14.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.21.output.adapters.ep.adapter_up.bias', 'qa_outputs.weight', 'base_model.encoder.layer.5.attention.self.query.weight', 'base_model.encoder.layer.11.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.4.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.5.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.12.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.1.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.9.attention.output.LayerNorm.bias', 'base_model.encoder.layer.17.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.23.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.14.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.23.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.23.output.LayerNorm.bias', 'base_model.encoder.layer.6.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.0.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.14.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.21.attention.self.key.weight', 'base_model.encoder.layer.22.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.14.attention.self.key.weight', 'base_model.encoder.layer.10.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.23.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.15.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.8.attention.output.dense.bias', 'base_model.encoder.layer.15.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.18.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.16.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.12.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.22.output.LayerNorm.bias', 'base_model.encoder.layer.10.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.16.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.21.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.2.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.0.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.7.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.7.attention.self.value.weight', 'base_model.encoder.layer.10.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.4.attention.output.LayerNorm.bias', 'base_model.encoder.layer.20.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.23.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.3.attention.self.value.weight', 'base_model.encoder.layer.11.output.LayerNorm.weight', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.17.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.20.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.22.attention.self.value.bias', 'base_model.encoder.layer.18.attention.output.dense.weight', 'base_model.encoder.layer.22.attention.self.query.weight', 'base_model.encoder.layer.1.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.17.attention.output.dense.bias', 'base_model.encoder.layer.13.output.dense.bias', 'base_model.encoder.layer.0.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.19.output.dense.weight', 'base_model.encoder.layer.23.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.18.attention.self.value.bias', 'base_model.encoder.layer.4.output.dense.weight', 'base_model.encoder.layer.13.attention.self.key.weight', 'base_model.encoder.layer.15.output.dense.bias', 'base_model.encoder.layer.8.attention.self.key.weight', 'base_model.encoder.layer.9.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.3.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.11.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.22.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.12.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.4.attention.output.dense.weight', 'base_model.encoder.layer.16.output.LayerNorm.weight', 'base_model.encoder.layer.17.attention.self.value.bias', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.22.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.22.attention.output.dense.weight', 'base_model.encoder.layer.8.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.17.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.2.intermediate.dense.weight', 'base_model.encoder.layer.19.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.16.output.LayerNorm.bias', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.20.attention.self.value.weight', 'base_model.encoder.layer.22.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.8.attention.self.query.weight', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.3.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.3.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.7.output.dense.bias', 'base_model.encoder.layer.6.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.5.attention.self.key.weight', 'base_model.encoder.layer.6.attention.self.key.weight', 'base_model.encoder.layer.22.attention.output.LayerNorm.weight', 'base_model.encoder.layer.6.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.9.attention.output.dense.bias', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.12.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.19.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.12.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.20.output.LayerNorm.weight', 'base_model.encoder.layer.2.attention.self.value.bias', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.3.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.9.output.LayerNorm.weight', 'base_model.encoder.layer.16.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.6.intermediate.dense.bias', 'base_model.encoder.layer.23.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.20.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.16.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.10.output.dense.bias', 'base_model.encoder.layer.11.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.18.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.2.attention.output.dense.weight', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.4.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.4.output.LayerNorm.weight', 'base_model.encoder.layer.14.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.7.output.dense.weight', 'base_model.encoder.layer.10.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.17.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.14.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.15.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.19.attention.self.value.weight', 'base_model.encoder.layer.8.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.10.output.LayerNorm.weight', 'base_model.encoder.layer.19.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.20.intermediate.dense.bias', 'base_model.encoder.layer.5.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.20.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.12.attention.output.LayerNorm.weight', 'base_model.embeddings.position_ids', 'base_model.encoder.layer.20.output.LayerNorm.bias', 'base_model.encoder.layer.18.attention.output.LayerNorm.bias', 'base_model.encoder.layer.15.attention.output.LayerNorm.bias', 'base_model.encoder.layer.16.intermediate.dense.weight', 'base_model.encoder.layer.13.attention.output.LayerNorm.bias', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.5.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.19.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.9.attention.output.LayerNorm.weight', 'base_model.encoder.layer.9.attention.self.query.weight', 'base_model.encoder.layer.12.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.5.output.LayerNorm.weight', 'base_model.encoder.layer.10.intermediate.dense.weight', 'base_model.encoder.layer.2.attention.self.query.weight', 'base_model.encoder.layer.6.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.21.attention.output.LayerNorm.weight', 'base_model.encoder.layer.19.attention.output.LayerNorm.bias', 'base_model.encoder.layer.17.intermediate.dense.weight', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.15.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.4.intermediate.dense.bias', 'base_model.encoder.layer.11.attention.output.dense.bias', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.1.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.14.intermediate.dense.weight', 'base_model.encoder.layer.8.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.21.output.dense.bias', 'base_model.encoder.layer.0.intermediate.dense.weight', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.8.intermediate.dense.weight', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.21.attention.self.query.weight', 'base_model.encoder.layer.5.attention.output.LayerNorm.bias', 'base_model.encoder.layer.18.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.0.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.1.intermediate.dense.weight', 'base_model.encoder.layer.19.attention.output.dense.bias', 'base_model.encoder.layer.12.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.16.attention.self.query.bias', 'base_model.encoder.layer.21.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.14.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.7.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.20.attention.self.key.weight', 'base_model.encoder.layer.10.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.18.attention.self.query.bias', 'base_model.encoder.layer.2.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.18.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.19.output.LayerNorm.weight', 'base_model.encoder.layer.21.intermediate.dense.weight', 'base_model.encoder.layer.9.attention.self.key.weight', 'base_model.encoder.layer.12.attention.output.dense.bias', 'base_model.encoder.layer.9.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.11.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.17.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.14.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.16.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.4.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.2.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.2.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.15.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.17.output.LayerNorm.bias', 'base_model.encoder.layer.9.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.12.attention.output.dense.weight', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.15.attention.self.query.weight', 'base_model.encoder.layer.21.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.6.output.dense.bias', 'base_model.encoder.layer.9.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.2.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.1.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.22.output.dense.bias', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.14.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.10.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.2.attention.self.key.bias', 'base_model.encoder.layer.12.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.13.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.22.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.0.attention.output.LayerNorm.weight', 'base_model.encoder.layer.17.output.LayerNorm.weight', 'base_model.encoder.layer.22.attention.output.dense.bias', 'base_model.pooler.dense.bias', 'base_model.encoder.layer.5.intermediate.dense.weight', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.0.attention.self.value.weight', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.19.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.12.output.dense.bias', 'base_model.encoder.layer.1.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.23.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.15.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.8.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.11.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.19.attention.self.query.bias', 'base_model.encoder.layer.15.output.LayerNorm.bias', 'base_model.encoder.layer.3.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.11.attention.self.query.bias', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.7.attention.output.LayerNorm.bias', 'base_model.encoder.layer.14.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.7.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.19.attention.self.query.weight', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.19.attention.output.LayerNorm.weight', 'base_model.encoder.layer.13.output.LayerNorm.bias', 'base_model.encoder.layer.6.attention.output.dense.weight', 'base_model.encoder.layer.16.attention.output.dense.bias', 'base_model.encoder.layer.0.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.2.attention.output.LayerNorm.bias', 'base_model.encoder.layer.10.output.LayerNorm.bias', 'base_model.encoder.layer.8.attention.self.value.weight', 'base_model.encoder.layer.23.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.18.output.dense.weight', 'base_model.encoder.layer.6.attention.self.value.bias', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.22.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.17.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.0.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.0.output.dense.bias', 'base_model.encoder.layer.2.attention.output.dense.bias', 'base_model.encoder.layer.7.attention.self.key.bias', 'base_model.encoder.layer.1.attention.self.value.weight', 'base_model.encoder.layer.14.attention.self.query.bias', 'base_model.encoder.layer.16.attention.self.key.bias', 'base_model.encoder.layer.20.output.dense.bias', 'base_model.encoder.layer.20.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.13.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.10.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.21.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.2.output.dense.bias', 'base_model.encoder.layer.10.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.17.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.11.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.17.attention.self.query.bias', 'base_model.encoder.layer.23.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.14.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.18.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.6.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.6.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.21.attention.self.key.bias', 'base_model.encoder.layer.16.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.22.attention.output.LayerNorm.bias', 'base_model.encoder.layer.6.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.20.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.6.output.LayerNorm.bias', 'base_model.encoder.layer.3.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.22.intermediate.dense.weight', 'base_model.encoder.layer.11.intermediate.dense.weight', 'base_model.encoder.layer.21.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.5.output.dense.bias', 'base_model.encoder.layer.4.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.23.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.9.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.16.output.dense.weight', 'base_model.encoder.layer.1.attention.output.dense.bias', 'base_model.encoder.layer.9.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.5.attention.self.value.weight', 'base_model.encoder.layer.0.attention.self.query.bias', 'base_model.encoder.layer.12.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.19.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.17.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.21.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.0.attention.output.LayerNorm.bias', 'base_model.encoder.layer.22.attention.self.query.bias', 'base_model.encoder.layer.8.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.15.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.19.attention.self.key.weight', 'base_model.encoder.layer.23.attention.output.dense.weight', 'base_model.encoder.layer.8.attention.output.LayerNorm.bias', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.9.intermediate.dense.weight', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.8.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.10.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.16.attention.self.key.weight', 'base_model.encoder.layer.15.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.8.attention.output.dense.weight', 'base_model.encoder.layer.18.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.0.attention.self.key.bias', 'base_model.encoder.layer.4.attention.output.LayerNorm.weight', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.22.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.8.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.4.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.5.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.1.attention.output.LayerNorm.weight', 'base_model.encoder.layer.5.attention.output.dense.bias', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.19.output.dense.bias', 'base_model.encoder.layer.13.output.LayerNorm.weight', 'base_model.encoder.layer.7.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.18.attention.self.key.weight', 'base_model.encoder.layer.22.intermediate.dense.bias', 'base_model.encoder.layer.0.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.16.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.5.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.21.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.3.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.0.intermediate.dense.bias', 'base_model.encoder.layer.20.attention.output.LayerNorm.bias', 'base_model.encoder.layer.0.attention.self.key.weight', 'base_model.encoder.layer.11.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.4.output.dense.bias', 'base_model.encoder.layer.5.attention.self.value.bias', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.20.attention.self.key.bias', 'base_model.encoder.layer.8.output.LayerNorm.bias', 'base_model.encoder.layer.8.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.0.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.10.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.9.attention.output.dense.weight', 'base_model.encoder.layer.13.intermediate.dense.bias', 'base_model.encoder.layer.9.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.7.attention.output.dense.bias', 'base_model.encoder.layer.7.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.5.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.12.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.18.intermediate.dense.bias', 'base_model.encoder.layer.1.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.15.intermediate.dense.weight', 'base_model.encoder.layer.17.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.12.attention.self.query.bias', 'base_model.encoder.layer.17.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.8.attention.self.query.bias', 'base_model.encoder.layer.3.attention.self.value.bias', 'base_model.encoder.layer.22.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.14.output.LayerNorm.weight', 'base_model.encoder.layer.10.attention.output.dense.weight', 'base_model.encoder.layer.1.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.23.attention.self.value.bias', 'base_model.encoder.layer.10.attention.output.dense.bias', 'base_model.encoder.layer.16.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.13.attention.output.dense.bias', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.7.output.LayerNorm.weight', 'base_model.encoder.layer.19.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.9.intermediate.dense.bias', 'base_model.encoder.layer.18.output.LayerNorm.bias', 'base_model.encoder.layer.1.output.LayerNorm.bias', 'base_model.encoder.layer.17.output.adapters.ts.adapter_down.0.bias', 'base_model.embeddings.token_type_embeddings.weight', 'base_model.encoder.layer.9.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.6.attention.self.key.bias', 'base_model.embeddings.LayerNorm.weight', 'base_model.encoder.layer.6.attention.self.query.weight', 'base_model.encoder.layer.21.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.6.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.13.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.14.output.adapters.es.adapter_down.0.bias', 'base_model.embeddings.position_embeddings.weight', 'base_model.encoder.layer.9.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.20.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.6.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.14.attention.output.dense.bias', 'base_model.encoder.layer.2.output.LayerNorm.bias', 'base_model.encoder.layer.5.attention.output.LayerNorm.weight', 'base_model.encoder.layer.1.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.23.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.1.attention.output.dense.weight', 'base_model.encoder.layer.17.output.dense.weight', 'base_model.encoder.layer.11.attention.self.key.weight', 'base_model.encoder.layer.18.output.dense.bias', 'base_model.encoder.layer.18.attention.output.LayerNorm.weight', 'base_model.encoder.layer.23.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.1.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.8.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.2.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.13.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.1.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.18.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.16.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.5.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.17.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.22.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.11.attention.output.dense.weight', 'base_model.encoder.layer.6.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.2.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.15.output.LayerNorm.weight', 'base_model.encoder.layer.5.attention.self.query.bias', 'base_model.encoder.layer.13.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.2.attention.self.value.weight', 'base_model.encoder.layer.10.attention.self.value.weight', 'base_model.encoder.layer.3.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.9.attention.self.value.weight', 'base_model.encoder.layer.18.attention.self.value.weight', 'base_model.encoder.layer.3.attention.self.key.bias', 'base_model.encoder.layer.21.output.LayerNorm.bias', 'base_model.encoder.layer.1.attention.self.key.bias', 'base_model.encoder.layer.4.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.10.attention.self.query.bias', 'base_model.encoder.layer.7.attention.self.value.bias', 'base_model.encoder.layer.13.attention.self.value.bias', 'base_model.encoder.layer.4.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.3.intermediate.dense.bias', 'base_model.encoder.layer.5.output.dense.weight', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.9.attention.self.value.bias', 'base_model.encoder.layer.4.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.1.output.dense.bias', 'base_model.encoder.layer.13.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.23.attention.self.query.weight', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.embeddings.LayerNorm.bias', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.15.attention.self.value.bias', 'base_model.encoder.layer.12.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.9.output.LayerNorm.bias', 'base_model.encoder.layer.4.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.12.intermediate.dense.bias', 'base_model.encoder.layer.16.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.19.attention.output.dense.weight', 'base_model.encoder.layer.17.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.1.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.12.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.15.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.7.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.7.output.LayerNorm.bias', 'base_model.encoder.layer.11.intermediate.dense.bias', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.3.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.14.output.dense.weight', 'base_model.encoder.layer.15.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.10.intermediate.dense.bias', 'base_model.encoder.layer.22.output.dense.weight', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.3.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.0.output.LayerNorm.weight', 'base_model.encoder.layer.12.attention.self.value.weight', 'base_model.encoder.layer.15.attention.self.value.weight', 'base_model.encoder.layer.17.attention.output.dense.weight', 'base_model.encoder.layer.15.output.dense.weight', 'base_model.encoder.layer.5.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.21.attention.output.dense.bias', 'base_model.encoder.layer.18.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.19.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.21.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.6.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.13.intermediate.dense.weight', 'base_model.encoder.layer.1.attention.self.key.weight', 'base_model.encoder.layer.20.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.13.attention.self.key.bias', 'base_model.encoder.layer.23.output.dense.bias', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.14.attention.self.value.bias', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.15.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.16.attention.output.LayerNorm.weight', 'base_model.encoder.layer.5.intermediate.dense.bias', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.14.attention.output.LayerNorm.weight', 'base_model.encoder.layer.12.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.11.attention.self.query.weight', 'base_model.encoder.layer.4.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.13.attention.self.query.weight', 'base_model.encoder.layer.14.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.19.intermediate.dense.bias', 'base_model.encoder.layer.10.attention.output.LayerNorm.weight', 'base_model.encoder.layer.16.attention.self.value.weight', 'base_model.encoder.layer.11.attention.output.LayerNorm.bias', 'base_model.encoder.layer.16.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.20.attention.self.query.weight', 'base_model.encoder.layer.14.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.5.attention.self.key.bias', 'base_model.encoder.layer.8.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.13.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.0.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.20.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.3.attention.self.query.weight', 'base_model.encoder.layer.14.attention.output.LayerNorm.bias', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.8.intermediate.dense.bias', 'base_model.encoder.layer.23.attention.self.key.weight', 'base_model.encoder.layer.14.attention.self.key.bias', 'base_model.encoder.layer.2.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.4.attention.self.query.weight', 'base_model.encoder.layer.3.attention.output.dense.weight', 'base_model.encoder.layer.12.attention.self.key.bias', 'base_model.encoder.layer.8.attention.self.value.bias', 'base_model.encoder.layer.23.attention.self.key.bias', 'base_model.encoder.layer.2.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.7.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.7.attention.self.query.bias', 'base_model.encoder.layer.5.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.2.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.9.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.10.output.dense.weight', 'base_model.encoder.layer.0.attention.output.dense.weight', 'base_model.encoder.layer.13.attention.output.dense.weight', 'base_model.encoder.layer.0.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.0.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.10.attention.self.key.weight', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.20.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.23.attention.output.dense.bias', 'base_model.encoder.layer.10.attention.self.value.bias', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.18.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.3.intermediate.dense.weight', 'base_model.encoder.layer.3.attention.output.dense.bias', 'base_model.encoder.layer.7.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.7.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.9.attention.self.key.bias', 'base_model.encoder.layer.6.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.16.attention.self.query.weight', 'base_model.encoder.layer.2.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.1.output.dense.weight', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.4.attention.self.query.bias', 'base_model.encoder.layer.20.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.11.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.20.attention.self.query.bias', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.11.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.13.attention.self.value.weight', 'base_model.encoder.layer.23.attention.output.LayerNorm.weight', 'base_model.encoder.layer.1.attention.output.LayerNorm.bias', 'base_model.encoder.layer.20.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.5.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.8.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.8.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.11.attention.output.LayerNorm.weight', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.6.intermediate.dense.weight', 'qa_outputs.bias', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.19.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.20.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.4.attention.self.value.bias', 'base_model.encoder.layer.23.intermediate.dense.bias', 'base_model.encoder.layer.22.attention.self.key.bias', 'base_model.encoder.layer.4.attention.self.key.weight', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.0.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.17.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.3.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.18.attention.self.key.bias', 'base_model.encoder.layer.4.intermediate.dense.weight', 'base_model.encoder.layer.9.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.14.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.10.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.21.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.21.attention.self.query.bias', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.3.output.dense.bias', 'base_model.encoder.layer.10.attention.self.query.weight', 'base_model.encoder.layer.1.attention.self.query.bias', 'base_model.encoder.layer.6.attention.output.LayerNorm.bias', 'base_model.encoder.layer.3.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.21.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.6.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.21.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.10.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.16.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.3.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.4.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.19.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.13.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.18.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.4.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.7.intermediate.dense.bias', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.6.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.15.attention.self.key.weight', 'base_model.encoder.layer.16.attention.output.LayerNorm.bias', 'base_model.encoder.layer.23.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.20.attention.output.LayerNorm.weight', 'base_model.encoder.layer.12.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.17.attention.self.key.weight', 'base_model.encoder.layer.0.attention.output.dense.bias', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.19.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.20.intermediate.dense.weight', 'base_model.encoder.layer.21.attention.self.value.bias', 'base_model.encoder.layer.10.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.15.attention.self.query.bias', 'base_model.encoder.layer.18.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.19.attention.self.key.bias', 'base_model.encoder.layer.18.attention.self.query.weight', 'base_model.encoder.layer.16.attention.output.dense.weight', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.16.output.dense.bias', 'base_model.encoder.layer.19.intermediate.dense.weight', 'base_model.encoder.layer.2.output.dense.weight', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.20.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.5.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.8.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.14.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.22.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.13.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.11.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.23.output.LayerNorm.weight', 'base_model.encoder.layer.11.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.0.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.1.attention.self.query.weight', 'base_model.encoder.layer.3.attention.output.LayerNorm.weight', 'base_model.encoder.layer.21.attention.output.dense.weight', 'base_model.encoder.layer.23.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.12.attention.self.value.bias', 'base_model.encoder.layer.12.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.19.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.9.attention.self.query.bias', 'base_model.encoder.layer.9.output.dense.bias', 'base_model.encoder.layer.4.output.LayerNorm.bias', 'base_model.encoder.layer.3.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.5.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.4.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.13.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.23.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.22.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.4.attention.output.dense.bias', 'base_model.encoder.layer.0.output.dense.weight', 'base_model.encoder.layer.9.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.10.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.16.intermediate.dense.bias', 'base_model.encoder.layer.7.intermediate.dense.weight', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.17.attention.self.query.weight', 'base_model.encoder.layer.23.attention.self.value.weight', 'base_model.encoder.layer.5.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.3.attention.output.LayerNorm.bias', 'base_model.encoder.layer.12.intermediate.dense.weight', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.9.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.22.output.LayerNorm.weight', 'base_model.encoder.layer.2.attention.self.query.bias', 'base_model.encoder.layer.21.intermediate.dense.bias', 'base_model.encoder.layer.14.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.1.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.9.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.9.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.14.output.dense.bias', 'base_model.encoder.layer.16.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.0.output.LayerNorm.bias', 'base_model.encoder.layer.1.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.2.output.LayerNorm.weight', 'base_model.encoder.layer.21.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.10.attention.output.LayerNorm.bias', 'base_model.encoder.layer.12.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.15.intermediate.dense.bias', 'base_model.encoder.layer.3.output.LayerNorm.bias', 'base_model.embeddings.word_embeddings.weight', 'base_model.encoder.layer.3.attention.self.key.weight', 'base_model.encoder.layer.7.attention.self.key.weight', 'base_model.encoder.layer.11.attention.self.value.weight', 'base_model.encoder.layer.9.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.17.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.20.attention.output.dense.bias', 'base_model.encoder.layer.20.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.4.attention.self.key.bias', 'base_model.encoder.layer.2.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.8.attention.output.LayerNorm.weight', 'base_model.encoder.layer.22.attention.self.key.weight', 'base_model.encoder.layer.8.output.dense.weight', 'base_model.encoder.layer.7.attention.output.LayerNorm.weight', 'base_model.encoder.layer.18.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.22.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.10.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.11.output.dense.weight', 'base_model.encoder.layer.7.attention.self.query.weight', 'base_model.encoder.layer.2.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.2.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.4.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.13.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.7.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.2.attention.self.key.weight', 'base_model.encoder.layer.18.attention.output.dense.bias', 'base_model.encoder.layer.1.attention.self.value.bias', 'base_model.encoder.layer.16.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.0.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.6.attention.self.query.bias', 'base_model.encoder.layer.7.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.21.output.dense.weight', 'base_model.encoder.layer.3.output.adapters.ep.adapter_down.0.weight', 'base_model.pooler.dense.weight', 'base_model.encoder.layer.13.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.18.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.11.output.dense.bias', 'base_model.encoder.layer.19.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.14.attention.self.query.weight', 'base_model.encoder.layer.11.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.20.attention.self.value.bias', 'base_model.encoder.layer.17.attention.output.LayerNorm.weight', 'base_model.encoder.layer.19.output.LayerNorm.bias', 'base_model.encoder.layer.14.output.LayerNorm.bias', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.16.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.5.output.LayerNorm.bias', 'base_model.encoder.layer.11.attention.self.key.bias', 'base_model.encoder.layer.0.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.20.attention.output.dense.weight', 'base_model.encoder.layer.8.output.dense.bias', 'base_model.encoder.layer.20.output.dense.weight', 'base_model.encoder.layer.11.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.23.attention.self.query.bias', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.5.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.4.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.7.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.20.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.2.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.8.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.15.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.3.output.dense.weight', 'base_model.encoder.layer.6.attention.self.value.weight', 'base_model.encoder.layer.11.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.6.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.18.output.LayerNorm.weight', 'base_model.encoder.layer.15.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.2.intermediate.dense.bias', 'base_model.encoder.layer.12.attention.self.key.weight', 'base_model.encoder.layer.1.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.4.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.19.attention.self.value.bias', 'base_model.encoder.layer.1.intermediate.dense.bias', 'base_model.encoder.layer.1.output.LayerNorm.weight', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.12.attention.output.LayerNorm.bias', 'base_model.encoder.layer.14.attention.self.value.weight', 'base_model.encoder.layer.7.attention.output.dense.weight', 'base_model.encoder.layer.4.attention.self.value.weight', 'base_model.encoder.layer.17.attention.self.value.weight', 'base_model.encoder.layer.23.attention.output.LayerNorm.bias', 'base_model.encoder.layer.6.output.dense.weight', 'base_model.encoder.layer.13.attention.self.query.bias', 'base_model.encoder.layer.8.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.6.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.9.output.dense.weight', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.13.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.0.attention.self.value.bias', 'base_model.encoder.layer.22.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.21.output.LayerNorm.weight', 'base_model.encoder.layer.1.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.22.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.8.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.12.output.dense.weight', 'base_model.encoder.layer.23.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.16.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.7.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.17.attention.self.key.bias', 'base_model.encoder.layer.3.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.7.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.17.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.23.output.dense.weight', 'base_model.encoder.layer.22.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.0.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.13.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.0.attention.self.query.weight', 'base_model.encoder.layer.18.intermediate.dense.weight', 'base_model.encoder.layer.14.intermediate.dense.bias', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.15.output.adapters.tp.adapter_down.0.bias']
- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of XLMRobertaModel were not initialized from the model checkpoint at /cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//squad/xlm-KG_LR8e-6_EPOCH2.0_maxlen384_batchsize4_gradacc4 and are newly initialized: ['encoder.layer.0.attention.output.LayerNorm.weight', 'encoder.layer.23.attention.self.query.bias', 'encoder.layer.13.output.LayerNorm.bias', 'encoder.layer.17.attention.output.dense.bias', 'encoder.layer.15.attention.self.key.bias', 'encoder.layer.14.output.dense.bias', 'encoder.layer.20.attention.self.value.weight', 'encoder.layer.17.attention.self.query.bias', 'encoder.layer.10.attention.self.query.weight', 'encoder.layer.2.attention.self.key.bias', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.6.output.dense.bias', 'encoder.layer.2.attention.output.LayerNorm.weight', 'encoder.layer.18.intermediate.dense.weight', 'encoder.layer.16.intermediate.dense.weight', 'encoder.layer.11.attention.output.dense.weight', 'encoder.layer.1.attention.self.query.weight', 'pooler.dense.bias', 'encoder.layer.20.output.LayerNorm.bias', 'encoder.layer.9.attention.self.value.bias', 'encoder.layer.12.intermediate.dense.bias', 'encoder.layer.1.attention.self.key.bias', 'encoder.layer.19.attention.self.value.bias', 'encoder.layer.2.output.dense.weight', 'encoder.layer.17.output.dense.weight', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.17.attention.self.value.weight', 'encoder.layer.21.attention.output.dense.bias', 'encoder.layer.18.output.dense.bias', 'encoder.layer.9.output.dense.weight', 'encoder.layer.12.output.LayerNorm.weight', 'encoder.layer.20.output.dense.bias', 'encoder.layer.0.attention.self.query.bias', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.8.attention.self.key.weight', 'encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.layer.5.attention.output.dense.weight', 'encoder.layer.22.output.dense.bias', 'encoder.layer.14.attention.self.query.bias', 'encoder.layer.19.attention.output.dense.bias', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.19.output.LayerNorm.weight', 'embeddings.LayerNorm.weight', 'encoder.layer.11.attention.self.query.weight', 'encoder.layer.11.attention.self.value.weight', 'encoder.layer.10.intermediate.dense.weight', 'encoder.layer.18.attention.self.query.weight', 'encoder.layer.16.attention.output.dense.weight', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.10.attention.self.key.bias', 'encoder.layer.20.attention.self.value.bias', 'encoder.layer.13.attention.self.value.weight', 'encoder.layer.5.attention.self.query.bias', 'encoder.layer.13.attention.output.LayerNorm.bias', 'encoder.layer.16.intermediate.dense.bias', 'encoder.layer.3.attention.self.value.bias', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.19.attention.self.query.weight', 'encoder.layer.4.attention.self.query.bias', 'encoder.layer.1.attention.self.query.bias', 'encoder.layer.12.attention.output.dense.bias', 'encoder.layer.19.output.dense.bias', 'encoder.layer.2.attention.self.key.weight', 'encoder.layer.1.attention.output.dense.bias', 'encoder.layer.21.intermediate.dense.bias', 'encoder.layer.5.attention.output.dense.bias', 'encoder.layer.18.attention.self.key.bias', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.15.output.LayerNorm.weight', 'encoder.layer.13.attention.output.dense.bias', 'encoder.layer.11.output.LayerNorm.weight', 'encoder.layer.4.attention.self.query.weight', 'encoder.layer.14.output.LayerNorm.bias', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.8.output.dense.bias', 'encoder.layer.10.attention.self.value.bias', 'encoder.layer.21.output.LayerNorm.weight', 'encoder.layer.6.attention.output.dense.weight', 'encoder.layer.13.attention.self.key.weight', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.3.output.dense.weight', 'encoder.layer.12.output.LayerNorm.bias', 'encoder.layer.5.output.dense.weight', 'encoder.layer.0.attention.self.value.weight', 'encoder.layer.11.output.dense.weight', 'encoder.layer.15.attention.self.value.bias', 'encoder.layer.17.attention.output.LayerNorm.bias', 'encoder.layer.9.output.LayerNorm.weight', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.7.attention.self.value.weight', 'encoder.layer.11.attention.self.key.bias', 'encoder.layer.0.output.dense.bias', 'encoder.layer.15.output.dense.weight', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.9.attention.self.key.bias', 'encoder.layer.1.output.dense.weight', 'encoder.layer.19.attention.self.query.bias', 'encoder.layer.4.attention.self.value.weight', 'encoder.layer.4.attention.self.key.weight', 'encoder.layer.17.output.LayerNorm.bias', 'encoder.layer.10.attention.self.key.weight', 'encoder.layer.17.attention.output.LayerNorm.weight', 'encoder.layer.22.output.LayerNorm.bias', 'encoder.layer.22.attention.self.query.weight', 'encoder.layer.7.attention.output.dense.bias', 'encoder.layer.21.attention.self.query.bias', 'encoder.layer.13.attention.self.query.bias', 'encoder.layer.2.attention.self.value.bias', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.14.attention.output.dense.weight', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.3.attention.self.key.weight', 'encoder.layer.20.attention.output.dense.weight', 'encoder.layer.5.attention.self.query.weight', 'encoder.layer.2.attention.self.query.bias', 'encoder.layer.23.output.LayerNorm.bias', 'encoder.layer.16.attention.output.LayerNorm.bias', 'encoder.layer.9.attention.output.dense.weight', 'encoder.layer.15.output.dense.bias', 'encoder.layer.16.output.LayerNorm.weight', 'encoder.layer.18.output.dense.weight', 'encoder.layer.20.attention.output.LayerNorm.bias', 'embeddings.LayerNorm.bias', 'encoder.layer.4.attention.self.value.bias', 'encoder.layer.10.output.dense.bias', 'encoder.layer.7.output.LayerNorm.weight', 'encoder.layer.16.attention.self.query.bias', 'encoder.layer.11.attention.self.value.bias', 'encoder.layer.23.attention.self.key.weight', 'encoder.layer.16.attention.self.value.weight', 'encoder.layer.19.attention.output.dense.weight', 'encoder.layer.8.attention.self.key.bias', 'encoder.layer.12.attention.self.query.weight', 'encoder.layer.21.intermediate.dense.weight', 'encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.layer.21.attention.output.LayerNorm.bias', 'encoder.layer.20.attention.self.key.weight', 'encoder.layer.17.intermediate.dense.weight', 'encoder.layer.15.attention.output.dense.weight', 'encoder.layer.8.attention.self.value.weight', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.21.attention.self.value.bias', 'encoder.layer.0.attention.self.key.weight', 'encoder.layer.18.attention.output.dense.bias', 'encoder.layer.21.attention.self.value.weight', 'encoder.layer.18.attention.output.LayerNorm.bias', 'encoder.layer.20.attention.output.LayerNorm.weight', 'encoder.layer.1.attention.self.key.weight', 'encoder.layer.4.attention.output.dense.weight', 'encoder.layer.9.attention.self.query.weight', 'encoder.layer.14.attention.self.query.weight', 'encoder.layer.23.attention.output.dense.weight', 'encoder.layer.13.attention.output.dense.weight', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.15.output.LayerNorm.bias', 'encoder.layer.22.attention.self.key.weight', 'encoder.layer.22.attention.output.LayerNorm.weight', 'encoder.layer.12.attention.self.query.bias', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.14.intermediate.dense.bias', 'encoder.layer.12.attention.self.value.bias', 'encoder.layer.6.attention.output.dense.bias', 'encoder.layer.11.attention.output.dense.bias', 'encoder.layer.21.attention.self.key.bias', 'encoder.layer.14.intermediate.dense.weight', 'encoder.layer.6.attention.self.key.bias', 'encoder.layer.7.attention.self.value.bias', 'encoder.layer.7.attention.output.dense.weight', 'encoder.layer.15.intermediate.dense.weight', 'encoder.layer.12.intermediate.dense.weight', 'encoder.layer.15.attention.self.key.weight', 'encoder.layer.13.attention.self.query.weight', 'encoder.layer.14.output.dense.weight', 'encoder.layer.18.attention.output.LayerNorm.weight', 'encoder.layer.6.attention.self.key.weight', 'encoder.layer.15.attention.output.LayerNorm.bias', 'encoder.layer.6.attention.output.LayerNorm.weight', 'encoder.layer.13.attention.self.key.bias', 'encoder.layer.4.output.dense.bias', 'encoder.layer.8.attention.output.LayerNorm.weight', 'encoder.layer.2.attention.output.dense.bias', 'encoder.layer.3.attention.self.query.bias', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.8.attention.output.dense.weight', 'encoder.layer.12.attention.self.value.weight', 'encoder.layer.19.output.dense.weight', 'encoder.layer.13.attention.self.value.bias', 'encoder.layer.0.attention.output.dense.bias', 'encoder.layer.0.attention.output.dense.weight', 'encoder.layer.5.output.dense.bias', 'encoder.layer.18.output.LayerNorm.bias', 'encoder.layer.22.attention.output.dense.bias', 'encoder.layer.23.attention.self.query.weight', 'encoder.layer.18.attention.self.value.bias', 'encoder.layer.20.output.dense.weight', 'encoder.layer.21.output.dense.bias', 'embeddings.token_type_embeddings.weight', 'encoder.layer.22.attention.self.value.bias', 'encoder.layer.7.attention.output.LayerNorm.weight', 'encoder.layer.22.attention.self.value.weight', 'encoder.layer.23.attention.self.value.weight', 'encoder.layer.19.intermediate.dense.weight', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.6.output.LayerNorm.bias', 'encoder.layer.21.output.LayerNorm.bias', 'encoder.layer.16.attention.self.key.weight', 'encoder.layer.22.attention.output.LayerNorm.bias', 'encoder.layer.6.attention.output.LayerNorm.bias', 'encoder.layer.12.attention.output.LayerNorm.bias', 'encoder.layer.17.attention.self.value.bias', 'encoder.layer.15.attention.output.dense.bias', 'encoder.layer.19.attention.output.LayerNorm.weight', 'encoder.layer.6.output.dense.weight', 'encoder.layer.13.attention.output.LayerNorm.weight', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.18.attention.self.query.bias', 'encoder.layer.15.attention.output.LayerNorm.weight', 'encoder.layer.3.attention.output.dense.bias', 'encoder.layer.11.output.dense.bias', 'encoder.layer.12.attention.self.key.bias', 'encoder.layer.23.intermediate.dense.bias', 'encoder.layer.3.attention.self.key.bias', 'encoder.layer.12.attention.output.dense.weight', 'encoder.layer.18.intermediate.dense.bias', 'encoder.layer.23.output.dense.weight', 'encoder.layer.21.attention.output.LayerNorm.weight', 'encoder.layer.5.attention.self.value.weight', 'encoder.layer.2.attention.output.dense.weight', 'encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.layer.23.intermediate.dense.weight', 'encoder.layer.7.attention.self.query.weight', 'encoder.layer.15.attention.self.value.weight', 'encoder.layer.12.attention.output.LayerNorm.weight', 'encoder.layer.8.attention.self.query.weight', 'encoder.layer.5.attention.self.key.weight', 'encoder.layer.14.attention.output.dense.bias', 'encoder.layer.17.attention.self.query.weight', 'encoder.layer.0.attention.self.key.bias', 'encoder.layer.5.attention.self.value.bias', 'encoder.layer.9.attention.self.value.weight', 'encoder.layer.23.attention.output.dense.bias', 'encoder.layer.1.attention.output.dense.weight', 'encoder.layer.7.intermediate.dense.bias', 'encoder.layer.2.attention.self.value.weight', 'encoder.layer.14.attention.output.LayerNorm.bias', 'encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.layer.13.output.dense.bias', 'encoder.layer.11.attention.self.query.bias', 'encoder.layer.22.output.LayerNorm.weight', 'encoder.layer.22.intermediate.dense.bias', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.19.attention.self.key.bias', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.16.output.LayerNorm.bias', 'encoder.layer.1.output.dense.bias', 'encoder.layer.7.attention.self.query.bias', 'encoder.layer.1.attention.self.value.weight', 'encoder.layer.22.attention.self.query.bias', 'encoder.layer.17.attention.self.key.bias', 'encoder.layer.4.output.dense.weight', 'encoder.layer.17.output.LayerNorm.weight', 'encoder.layer.3.attention.output.dense.weight', 'encoder.layer.9.attention.output.LayerNorm.bias', 'encoder.layer.22.attention.self.key.bias', 'encoder.layer.23.output.dense.bias', 'encoder.layer.16.attention.self.key.bias', 'encoder.layer.15.intermediate.dense.bias', 'encoder.layer.8.output.dense.weight', 'encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.8.attention.output.LayerNorm.bias', 'encoder.layer.20.output.LayerNorm.weight', 'encoder.layer.20.attention.self.query.bias', 'encoder.layer.20.attention.output.dense.bias', 'embeddings.word_embeddings.weight', 'encoder.layer.14.attention.self.key.bias', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.16.attention.self.query.weight', 'encoder.layer.12.attention.self.key.weight', 'encoder.layer.20.intermediate.dense.weight', 'encoder.layer.10.attention.self.value.weight', 'encoder.layer.19.intermediate.dense.bias', 'encoder.layer.13.intermediate.dense.bias', 'encoder.layer.18.output.LayerNorm.weight', 'encoder.layer.10.output.LayerNorm.bias', 'encoder.layer.19.attention.self.value.weight', 'encoder.layer.23.attention.output.LayerNorm.weight', 'encoder.layer.14.attention.self.value.bias', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.1.attention.output.LayerNorm.weight', 'encoder.layer.21.output.dense.weight', 'encoder.layer.8.output.LayerNorm.bias', 'encoder.layer.9.attention.self.key.weight', 'encoder.layer.7.output.LayerNorm.bias', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.3.attention.self.query.weight', 'encoder.layer.17.output.dense.bias', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.10.attention.output.dense.weight', 'encoder.layer.11.attention.output.LayerNorm.weight', 'encoder.layer.11.output.LayerNorm.bias', 'encoder.layer.9.output.LayerNorm.bias', 'encoder.layer.12.output.dense.bias', 'encoder.layer.4.attention.output.LayerNorm.bias', 'encoder.layer.16.attention.output.LayerNorm.weight', 'encoder.layer.0.output.dense.weight', 'encoder.layer.6.attention.self.query.bias', 'encoder.layer.7.output.dense.weight', 'encoder.layer.7.output.dense.bias', 'encoder.layer.9.attention.self.query.bias', 'encoder.layer.19.attention.output.LayerNorm.bias', 'encoder.layer.23.attention.output.LayerNorm.bias', 'encoder.layer.23.attention.self.value.bias', 'encoder.layer.13.output.LayerNorm.weight', 'encoder.layer.7.attention.self.key.bias', 'encoder.layer.22.output.dense.weight', 'encoder.layer.10.attention.self.query.bias', 'encoder.layer.9.output.dense.bias', 'encoder.layer.10.attention.output.dense.bias', 'encoder.layer.18.attention.output.dense.weight', 'encoder.layer.4.attention.self.key.bias', 'encoder.layer.11.attention.self.key.weight', 'encoder.layer.10.attention.output.LayerNorm.bias', 'encoder.layer.6.attention.self.value.bias', 'encoder.layer.15.attention.self.query.bias', 'encoder.layer.22.intermediate.dense.weight', 'encoder.layer.1.attention.self.value.bias', 'encoder.layer.5.output.LayerNorm.bias', 'encoder.layer.2.output.dense.bias', 'encoder.layer.14.attention.output.LayerNorm.weight', 'encoder.layer.7.attention.self.key.weight', 'encoder.layer.23.attention.self.key.bias', 'encoder.layer.8.attention.self.query.bias', 'encoder.layer.14.attention.self.value.weight', 'encoder.layer.6.attention.self.value.weight', 'encoder.layer.7.attention.output.LayerNorm.bias', 'encoder.layer.13.output.dense.weight', 'encoder.layer.17.attention.self.key.weight', 'encoder.layer.10.output.dense.weight', 'encoder.layer.21.attention.output.dense.weight', 'encoder.layer.14.output.LayerNorm.weight', 'encoder.layer.16.output.dense.bias', 'encoder.layer.2.attention.self.query.weight', 'encoder.layer.10.attention.output.LayerNorm.weight', 'encoder.layer.8.output.LayerNorm.weight', 'encoder.layer.21.attention.self.key.weight', 'encoder.layer.18.attention.self.value.weight', 'encoder.layer.16.output.dense.weight', 'encoder.layer.17.attention.output.dense.weight', 'encoder.layer.0.attention.self.query.weight', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.22.attention.output.dense.weight', 'encoder.layer.9.attention.output.LayerNorm.weight', 'pooler.dense.weight', 'encoder.layer.21.attention.self.query.weight', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.3.attention.self.value.weight', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.4.attention.output.dense.bias', 'encoder.layer.16.attention.self.value.bias', 'encoder.layer.19.attention.self.key.weight', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.20.attention.self.key.bias', 'encoder.layer.10.output.LayerNorm.weight', 'encoder.layer.17.intermediate.dense.bias', 'encoder.layer.19.output.LayerNorm.bias', 'encoder.layer.16.attention.output.dense.bias', 'encoder.layer.9.attention.output.dense.bias', 'encoder.layer.20.attention.self.query.weight', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.0.attention.self.value.bias', 'encoder.layer.6.attention.self.query.weight', 'encoder.layer.3.output.dense.bias', 'encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.layer.8.attention.output.dense.bias', 'encoder.layer.4.attention.output.LayerNorm.weight', 'encoder.layer.18.attention.self.key.weight', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.23.output.LayerNorm.weight', 'encoder.layer.5.attention.self.key.bias', 'encoder.layer.5.attention.output.LayerNorm.weight', 'encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.layer.13.intermediate.dense.weight', 'encoder.layer.20.intermediate.dense.bias', 'embeddings.position_embeddings.weight', 'encoder.layer.2.attention.output.LayerNorm.bias', 'encoder.layer.14.attention.self.key.weight', 'encoder.layer.8.attention.self.value.bias', 'encoder.layer.15.attention.self.query.weight', 'encoder.layer.12.output.dense.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Overwriting existing adapter 'ep'.
Overwriting existing adapter 'tp'.
Overwriting existing adapter 'es'.
Overwriting existing adapter 'ts'.
Overwriting existing adapter fusion module 'ep,tp,es,ts'
05/09/2022 21:37:38 - INFO - __main__ -   lang2id = None
05/09/2022 21:37:41 - INFO - __main__ -   Training/evaluation parameters Namespace(adam_epsilon=1e-08, cache_dir='', config_name='', data_dir=None, device=device(type='cuda'), do_eval=True, do_lower_case=False, do_train=False, doc_stride=128, eval_all_checkpoints=False, eval_lang='en', evaluate_during_training=False, fp16=False, fp16_opt_level='O1', gradient_accumulation_steps=1, learning_rate=5e-05, local_rank=-1, logging_steps=50, max_answer_length=30, max_grad_norm=1.0, max_query_length=64, max_seq_length=384, max_steps=-1, model_name='xlm-KG', model_name_or_path='/cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//squad/xlm-KG_LR8e-6_EPOCH2.0_maxlen384_batchsize4_gradacc4', model_type='xlm', modelkg_dir='/cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/adapter/xlmr_adapter', n_best_size=20, n_gpu=1, no_cuda=False, null_score_diff_threshold=0.0, num_train_epochs=3.0, output_dir='/cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//squad/xlm-KG_LR8e-6_EPOCH2.0_maxlen384_batchsize4_gradacc4/predictions/mlqa/', overwrite_cache=False, overwrite_output_dir=False, per_gpu_eval_batch_size=8, per_gpu_train_batch_size=8, predict_file='/cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/download//mlqa//MLQA_V1/test/test-context-en-question-en.json', save_steps=50, seed=42, server_ip='', server_port='', threads=1, tokenizer_name='', train_file=None, train_lang='en', verbose_logging=False, version_2_with_negative=False, warmup_steps=0, weight_decay=0.0)
05/09/2022 21:37:41 - INFO - __main__ -   Loading checkpoint /cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//squad/xlm-KG_LR8e-6_EPOCH2.0_maxlen384_batchsize4_gradacc4 for evaluation
05/09/2022 21:37:41 - INFO - __main__ -   Evaluate the following checkpoints: ['/cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//squad/xlm-KG_LR8e-6_EPOCH2.0_maxlen384_batchsize4_gradacc4']
Some weights of the model checkpoint at /cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//squad/xlm-KG_LR8e-6_EPOCH2.0_maxlen384_batchsize4_gradacc4 were not used when initializing XLMRobertaModel: ['base_model.encoder.layer.10.attention.self.key.bias', 'base_model.encoder.layer.18.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.22.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.16.attention.self.value.bias', 'base_model.encoder.layer.13.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.18.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.2.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.19.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.17.attention.output.LayerNorm.bias', 'base_model.encoder.layer.15.attention.output.LayerNorm.weight', 'base_model.encoder.layer.22.attention.self.value.weight', 'base_model.encoder.layer.21.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.5.attention.output.dense.weight', 'base_model.encoder.layer.2.attention.output.LayerNorm.weight', 'base_model.encoder.layer.15.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.6.output.LayerNorm.weight', 'base_model.encoder.layer.18.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.15.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.1.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.8.output.LayerNorm.weight', 'base_model.encoder.layer.11.attention.self.value.bias', 'base_model.encoder.layer.11.output.LayerNorm.bias', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.13.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.23.intermediate.dense.weight', 'base_model.encoder.layer.8.attention.self.key.bias', 'base_model.encoder.layer.17.output.dense.bias', 'base_model.encoder.layer.15.attention.output.dense.bias', 'base_model.encoder.layer.21.attention.output.LayerNorm.bias', 'base_model.encoder.layer.5.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.12.output.LayerNorm.weight', 'base_model.encoder.layer.3.attention.self.query.bias', 'base_model.encoder.layer.10.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.5.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.12.attention.self.query.weight', 'base_model.encoder.layer.6.attention.output.dense.bias', 'base_model.encoder.layer.11.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.3.output.LayerNorm.weight', 'base_model.encoder.layer.6.attention.output.LayerNorm.weight', 'base_model.encoder.layer.7.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.13.attention.output.LayerNorm.weight', 'base_model.encoder.layer.21.attention.self.value.weight', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.12.output.LayerNorm.bias', 'base_model.encoder.layer.13.output.dense.weight', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.14.attention.output.dense.weight', 'base_model.encoder.layer.15.attention.self.key.bias', 'base_model.encoder.layer.21.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.19.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.15.attention.output.dense.weight', 'base_model.encoder.layer.7.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.11.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.19.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.17.intermediate.dense.bias', 'base_model.encoder.layer.14.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.21.output.adapters.ep.adapter_up.bias', 'qa_outputs.weight', 'base_model.encoder.layer.5.attention.self.query.weight', 'base_model.encoder.layer.11.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.4.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.5.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.12.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.1.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.9.attention.output.LayerNorm.bias', 'base_model.encoder.layer.17.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.23.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.14.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.23.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.23.output.LayerNorm.bias', 'base_model.encoder.layer.6.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.0.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.14.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.21.attention.self.key.weight', 'base_model.encoder.layer.22.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.14.attention.self.key.weight', 'base_model.encoder.layer.10.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.23.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.15.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.8.attention.output.dense.bias', 'base_model.encoder.layer.15.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.18.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.16.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.12.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.22.output.LayerNorm.bias', 'base_model.encoder.layer.10.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.16.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.21.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.2.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.0.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.7.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.7.attention.self.value.weight', 'base_model.encoder.layer.10.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.4.attention.output.LayerNorm.bias', 'base_model.encoder.layer.20.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.23.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.3.attention.self.value.weight', 'base_model.encoder.layer.11.output.LayerNorm.weight', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.17.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.20.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.22.attention.self.value.bias', 'base_model.encoder.layer.18.attention.output.dense.weight', 'base_model.encoder.layer.22.attention.self.query.weight', 'base_model.encoder.layer.1.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.17.attention.output.dense.bias', 'base_model.encoder.layer.13.output.dense.bias', 'base_model.encoder.layer.0.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.19.output.dense.weight', 'base_model.encoder.layer.23.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.18.attention.self.value.bias', 'base_model.encoder.layer.4.output.dense.weight', 'base_model.encoder.layer.13.attention.self.key.weight', 'base_model.encoder.layer.15.output.dense.bias', 'base_model.encoder.layer.8.attention.self.key.weight', 'base_model.encoder.layer.9.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.3.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.11.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.22.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.12.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.4.attention.output.dense.weight', 'base_model.encoder.layer.16.output.LayerNorm.weight', 'base_model.encoder.layer.17.attention.self.value.bias', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.22.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.22.attention.output.dense.weight', 'base_model.encoder.layer.8.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.17.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.2.intermediate.dense.weight', 'base_model.encoder.layer.19.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.16.output.LayerNorm.bias', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.20.attention.self.value.weight', 'base_model.encoder.layer.22.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.8.attention.self.query.weight', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.3.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.3.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.7.output.dense.bias', 'base_model.encoder.layer.6.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.5.attention.self.key.weight', 'base_model.encoder.layer.6.attention.self.key.weight', 'base_model.encoder.layer.22.attention.output.LayerNorm.weight', 'base_model.encoder.layer.6.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.9.attention.output.dense.bias', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.12.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.19.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.12.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.20.output.LayerNorm.weight', 'base_model.encoder.layer.2.attention.self.value.bias', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.3.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.9.output.LayerNorm.weight', 'base_model.encoder.layer.16.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.6.intermediate.dense.bias', 'base_model.encoder.layer.23.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.20.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.16.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.10.output.dense.bias', 'base_model.encoder.layer.11.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.18.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.2.attention.output.dense.weight', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.4.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.4.output.LayerNorm.weight', 'base_model.encoder.layer.14.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.7.output.dense.weight', 'base_model.encoder.layer.10.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.17.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.14.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.15.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.19.attention.self.value.weight', 'base_model.encoder.layer.8.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.10.output.LayerNorm.weight', 'base_model.encoder.layer.19.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.20.intermediate.dense.bias', 'base_model.encoder.layer.5.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.20.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.12.attention.output.LayerNorm.weight', 'base_model.embeddings.position_ids', 'base_model.encoder.layer.20.output.LayerNorm.bias', 'base_model.encoder.layer.18.attention.output.LayerNorm.bias', 'base_model.encoder.layer.15.attention.output.LayerNorm.bias', 'base_model.encoder.layer.16.intermediate.dense.weight', 'base_model.encoder.layer.13.attention.output.LayerNorm.bias', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.5.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.19.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.9.attention.output.LayerNorm.weight', 'base_model.encoder.layer.9.attention.self.query.weight', 'base_model.encoder.layer.12.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.5.output.LayerNorm.weight', 'base_model.encoder.layer.10.intermediate.dense.weight', 'base_model.encoder.layer.2.attention.self.query.weight', 'base_model.encoder.layer.6.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.21.attention.output.LayerNorm.weight', 'base_model.encoder.layer.19.attention.output.LayerNorm.bias', 'base_model.encoder.layer.17.intermediate.dense.weight', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.15.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.4.intermediate.dense.bias', 'base_model.encoder.layer.11.attention.output.dense.bias', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.1.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.14.intermediate.dense.weight', 'base_model.encoder.layer.8.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.21.output.dense.bias', 'base_model.encoder.layer.0.intermediate.dense.weight', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.8.intermediate.dense.weight', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.21.attention.self.query.weight', 'base_model.encoder.layer.5.attention.output.LayerNorm.bias', 'base_model.encoder.layer.18.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.0.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.1.intermediate.dense.weight', 'base_model.encoder.layer.19.attention.output.dense.bias', 'base_model.encoder.layer.12.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.16.attention.self.query.bias', 'base_model.encoder.layer.21.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.14.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.7.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.20.attention.self.key.weight', 'base_model.encoder.layer.10.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.18.attention.self.query.bias', 'base_model.encoder.layer.2.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.18.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.19.output.LayerNorm.weight', 'base_model.encoder.layer.21.intermediate.dense.weight', 'base_model.encoder.layer.9.attention.self.key.weight', 'base_model.encoder.layer.12.attention.output.dense.bias', 'base_model.encoder.layer.9.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.11.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.17.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.14.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.16.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.4.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.2.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.2.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.15.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.17.output.LayerNorm.bias', 'base_model.encoder.layer.9.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.12.attention.output.dense.weight', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.15.attention.self.query.weight', 'base_model.encoder.layer.21.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.6.output.dense.bias', 'base_model.encoder.layer.9.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.2.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.1.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.22.output.dense.bias', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.14.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.10.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.2.attention.self.key.bias', 'base_model.encoder.layer.12.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.13.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.22.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.0.attention.output.LayerNorm.weight', 'base_model.encoder.layer.17.output.LayerNorm.weight', 'base_model.encoder.layer.22.attention.output.dense.bias', 'base_model.pooler.dense.bias', 'base_model.encoder.layer.5.intermediate.dense.weight', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.0.attention.self.value.weight', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.19.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.12.output.dense.bias', 'base_model.encoder.layer.1.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.23.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.15.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.8.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.11.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.19.attention.self.query.bias', 'base_model.encoder.layer.15.output.LayerNorm.bias', 'base_model.encoder.layer.3.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.11.attention.self.query.bias', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.7.attention.output.LayerNorm.bias', 'base_model.encoder.layer.14.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.7.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.19.attention.self.query.weight', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.19.attention.output.LayerNorm.weight', 'base_model.encoder.layer.13.output.LayerNorm.bias', 'base_model.encoder.layer.6.attention.output.dense.weight', 'base_model.encoder.layer.16.attention.output.dense.bias', 'base_model.encoder.layer.0.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.2.attention.output.LayerNorm.bias', 'base_model.encoder.layer.10.output.LayerNorm.bias', 'base_model.encoder.layer.8.attention.self.value.weight', 'base_model.encoder.layer.23.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.18.output.dense.weight', 'base_model.encoder.layer.6.attention.self.value.bias', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.22.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.17.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.0.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.0.output.dense.bias', 'base_model.encoder.layer.2.attention.output.dense.bias', 'base_model.encoder.layer.7.attention.self.key.bias', 'base_model.encoder.layer.1.attention.self.value.weight', 'base_model.encoder.layer.14.attention.self.query.bias', 'base_model.encoder.layer.16.attention.self.key.bias', 'base_model.encoder.layer.20.output.dense.bias', 'base_model.encoder.layer.20.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.13.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.10.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.21.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.2.output.dense.bias', 'base_model.encoder.layer.10.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.17.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.11.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.17.attention.self.query.bias', 'base_model.encoder.layer.23.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.14.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.18.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.6.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.6.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.21.attention.self.key.bias', 'base_model.encoder.layer.16.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.22.attention.output.LayerNorm.bias', 'base_model.encoder.layer.6.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.20.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.6.output.LayerNorm.bias', 'base_model.encoder.layer.3.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.22.intermediate.dense.weight', 'base_model.encoder.layer.11.intermediate.dense.weight', 'base_model.encoder.layer.21.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.5.output.dense.bias', 'base_model.encoder.layer.4.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.23.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.9.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.16.output.dense.weight', 'base_model.encoder.layer.1.attention.output.dense.bias', 'base_model.encoder.layer.9.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.5.attention.self.value.weight', 'base_model.encoder.layer.0.attention.self.query.bias', 'base_model.encoder.layer.12.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.19.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.17.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.21.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.0.attention.output.LayerNorm.bias', 'base_model.encoder.layer.22.attention.self.query.bias', 'base_model.encoder.layer.8.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.15.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.19.attention.self.key.weight', 'base_model.encoder.layer.23.attention.output.dense.weight', 'base_model.encoder.layer.8.attention.output.LayerNorm.bias', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.9.intermediate.dense.weight', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.8.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.10.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.16.attention.self.key.weight', 'base_model.encoder.layer.15.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.8.attention.output.dense.weight', 'base_model.encoder.layer.18.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.0.attention.self.key.bias', 'base_model.encoder.layer.4.attention.output.LayerNorm.weight', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.22.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.8.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.4.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.5.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.1.attention.output.LayerNorm.weight', 'base_model.encoder.layer.5.attention.output.dense.bias', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.19.output.dense.bias', 'base_model.encoder.layer.13.output.LayerNorm.weight', 'base_model.encoder.layer.7.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.18.attention.self.key.weight', 'base_model.encoder.layer.22.intermediate.dense.bias', 'base_model.encoder.layer.0.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.16.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.5.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.21.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.3.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.0.intermediate.dense.bias', 'base_model.encoder.layer.20.attention.output.LayerNorm.bias', 'base_model.encoder.layer.0.attention.self.key.weight', 'base_model.encoder.layer.11.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.4.output.dense.bias', 'base_model.encoder.layer.5.attention.self.value.bias', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.20.attention.self.key.bias', 'base_model.encoder.layer.8.output.LayerNorm.bias', 'base_model.encoder.layer.8.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.0.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.10.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.9.attention.output.dense.weight', 'base_model.encoder.layer.13.intermediate.dense.bias', 'base_model.encoder.layer.9.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.7.attention.output.dense.bias', 'base_model.encoder.layer.7.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.5.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.12.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.18.intermediate.dense.bias', 'base_model.encoder.layer.1.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.15.intermediate.dense.weight', 'base_model.encoder.layer.17.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.12.attention.self.query.bias', 'base_model.encoder.layer.17.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.8.attention.self.query.bias', 'base_model.encoder.layer.3.attention.self.value.bias', 'base_model.encoder.layer.22.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.14.output.LayerNorm.weight', 'base_model.encoder.layer.10.attention.output.dense.weight', 'base_model.encoder.layer.1.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.23.attention.self.value.bias', 'base_model.encoder.layer.10.attention.output.dense.bias', 'base_model.encoder.layer.16.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.13.attention.output.dense.bias', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.7.output.LayerNorm.weight', 'base_model.encoder.layer.19.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.9.intermediate.dense.bias', 'base_model.encoder.layer.18.output.LayerNorm.bias', 'base_model.encoder.layer.1.output.LayerNorm.bias', 'base_model.encoder.layer.17.output.adapters.ts.adapter_down.0.bias', 'base_model.embeddings.token_type_embeddings.weight', 'base_model.encoder.layer.9.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.6.attention.self.key.bias', 'base_model.embeddings.LayerNorm.weight', 'base_model.encoder.layer.6.attention.self.query.weight', 'base_model.encoder.layer.21.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.6.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.13.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.14.output.adapters.es.adapter_down.0.bias', 'base_model.embeddings.position_embeddings.weight', 'base_model.encoder.layer.9.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.20.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.6.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.14.attention.output.dense.bias', 'base_model.encoder.layer.2.output.LayerNorm.bias', 'base_model.encoder.layer.5.attention.output.LayerNorm.weight', 'base_model.encoder.layer.1.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.23.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.1.attention.output.dense.weight', 'base_model.encoder.layer.17.output.dense.weight', 'base_model.encoder.layer.11.attention.self.key.weight', 'base_model.encoder.layer.18.output.dense.bias', 'base_model.encoder.layer.18.attention.output.LayerNorm.weight', 'base_model.encoder.layer.23.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.1.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.8.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.2.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.13.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.1.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.18.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.16.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.5.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.17.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.22.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.11.attention.output.dense.weight', 'base_model.encoder.layer.6.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.2.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.15.output.LayerNorm.weight', 'base_model.encoder.layer.5.attention.self.query.bias', 'base_model.encoder.layer.13.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.2.attention.self.value.weight', 'base_model.encoder.layer.10.attention.self.value.weight', 'base_model.encoder.layer.3.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.9.attention.self.value.weight', 'base_model.encoder.layer.18.attention.self.value.weight', 'base_model.encoder.layer.3.attention.self.key.bias', 'base_model.encoder.layer.21.output.LayerNorm.bias', 'base_model.encoder.layer.1.attention.self.key.bias', 'base_model.encoder.layer.4.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.10.attention.self.query.bias', 'base_model.encoder.layer.7.attention.self.value.bias', 'base_model.encoder.layer.13.attention.self.value.bias', 'base_model.encoder.layer.4.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.3.intermediate.dense.bias', 'base_model.encoder.layer.5.output.dense.weight', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.9.attention.self.value.bias', 'base_model.encoder.layer.4.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.1.output.dense.bias', 'base_model.encoder.layer.13.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.23.attention.self.query.weight', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.embeddings.LayerNorm.bias', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.15.attention.self.value.bias', 'base_model.encoder.layer.12.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.9.output.LayerNorm.bias', 'base_model.encoder.layer.4.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.12.intermediate.dense.bias', 'base_model.encoder.layer.16.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.19.attention.output.dense.weight', 'base_model.encoder.layer.17.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.1.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.12.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.15.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.7.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.7.output.LayerNorm.bias', 'base_model.encoder.layer.11.intermediate.dense.bias', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.3.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.14.output.dense.weight', 'base_model.encoder.layer.15.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.10.intermediate.dense.bias', 'base_model.encoder.layer.22.output.dense.weight', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.3.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.0.output.LayerNorm.weight', 'base_model.encoder.layer.12.attention.self.value.weight', 'base_model.encoder.layer.15.attention.self.value.weight', 'base_model.encoder.layer.17.attention.output.dense.weight', 'base_model.encoder.layer.15.output.dense.weight', 'base_model.encoder.layer.5.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.21.attention.output.dense.bias', 'base_model.encoder.layer.18.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.19.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.21.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.6.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.13.intermediate.dense.weight', 'base_model.encoder.layer.1.attention.self.key.weight', 'base_model.encoder.layer.20.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.13.attention.self.key.bias', 'base_model.encoder.layer.23.output.dense.bias', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.14.attention.self.value.bias', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.15.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.16.attention.output.LayerNorm.weight', 'base_model.encoder.layer.5.intermediate.dense.bias', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.14.attention.output.LayerNorm.weight', 'base_model.encoder.layer.12.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.11.attention.self.query.weight', 'base_model.encoder.layer.4.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.13.attention.self.query.weight', 'base_model.encoder.layer.14.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.19.intermediate.dense.bias', 'base_model.encoder.layer.10.attention.output.LayerNorm.weight', 'base_model.encoder.layer.16.attention.self.value.weight', 'base_model.encoder.layer.11.attention.output.LayerNorm.bias', 'base_model.encoder.layer.16.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.20.attention.self.query.weight', 'base_model.encoder.layer.14.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.5.attention.self.key.bias', 'base_model.encoder.layer.8.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.13.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.0.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.20.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.3.attention.self.query.weight', 'base_model.encoder.layer.14.attention.output.LayerNorm.bias', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.8.intermediate.dense.bias', 'base_model.encoder.layer.23.attention.self.key.weight', 'base_model.encoder.layer.14.attention.self.key.bias', 'base_model.encoder.layer.2.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.4.attention.self.query.weight', 'base_model.encoder.layer.3.attention.output.dense.weight', 'base_model.encoder.layer.12.attention.self.key.bias', 'base_model.encoder.layer.8.attention.self.value.bias', 'base_model.encoder.layer.23.attention.self.key.bias', 'base_model.encoder.layer.2.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.7.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.7.attention.self.query.bias', 'base_model.encoder.layer.5.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.2.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.9.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.10.output.dense.weight', 'base_model.encoder.layer.0.attention.output.dense.weight', 'base_model.encoder.layer.13.attention.output.dense.weight', 'base_model.encoder.layer.0.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.0.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.10.attention.self.key.weight', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.20.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.23.attention.output.dense.bias', 'base_model.encoder.layer.10.attention.self.value.bias', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.18.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.3.intermediate.dense.weight', 'base_model.encoder.layer.3.attention.output.dense.bias', 'base_model.encoder.layer.7.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.7.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.9.attention.self.key.bias', 'base_model.encoder.layer.6.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.16.attention.self.query.weight', 'base_model.encoder.layer.2.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.1.output.dense.weight', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.4.attention.self.query.bias', 'base_model.encoder.layer.20.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.11.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.20.attention.self.query.bias', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.11.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.13.attention.self.value.weight', 'base_model.encoder.layer.23.attention.output.LayerNorm.weight', 'base_model.encoder.layer.1.attention.output.LayerNorm.bias', 'base_model.encoder.layer.20.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.5.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.8.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.8.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.11.attention.output.LayerNorm.weight', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.6.intermediate.dense.weight', 'qa_outputs.bias', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.19.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.20.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.4.attention.self.value.bias', 'base_model.encoder.layer.23.intermediate.dense.bias', 'base_model.encoder.layer.22.attention.self.key.bias', 'base_model.encoder.layer.4.attention.self.key.weight', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.0.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.17.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.3.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.18.attention.self.key.bias', 'base_model.encoder.layer.4.intermediate.dense.weight', 'base_model.encoder.layer.9.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.14.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.10.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.21.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.21.attention.self.query.bias', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.3.output.dense.bias', 'base_model.encoder.layer.10.attention.self.query.weight', 'base_model.encoder.layer.1.attention.self.query.bias', 'base_model.encoder.layer.6.attention.output.LayerNorm.bias', 'base_model.encoder.layer.3.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.21.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.6.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.21.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.10.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.16.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.3.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.4.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.19.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.13.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.18.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.4.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.7.intermediate.dense.bias', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.6.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.15.attention.self.key.weight', 'base_model.encoder.layer.16.attention.output.LayerNorm.bias', 'base_model.encoder.layer.23.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.20.attention.output.LayerNorm.weight', 'base_model.encoder.layer.12.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.17.attention.self.key.weight', 'base_model.encoder.layer.0.attention.output.dense.bias', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.19.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.20.intermediate.dense.weight', 'base_model.encoder.layer.21.attention.self.value.bias', 'base_model.encoder.layer.10.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.15.attention.self.query.bias', 'base_model.encoder.layer.18.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.19.attention.self.key.bias', 'base_model.encoder.layer.18.attention.self.query.weight', 'base_model.encoder.layer.16.attention.output.dense.weight', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.16.output.dense.bias', 'base_model.encoder.layer.19.intermediate.dense.weight', 'base_model.encoder.layer.2.output.dense.weight', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.20.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.5.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.8.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.14.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.22.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.13.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.11.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.23.output.LayerNorm.weight', 'base_model.encoder.layer.11.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.0.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.1.attention.self.query.weight', 'base_model.encoder.layer.3.attention.output.LayerNorm.weight', 'base_model.encoder.layer.21.attention.output.dense.weight', 'base_model.encoder.layer.23.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.12.attention.self.value.bias', 'base_model.encoder.layer.12.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.19.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.9.attention.self.query.bias', 'base_model.encoder.layer.9.output.dense.bias', 'base_model.encoder.layer.4.output.LayerNorm.bias', 'base_model.encoder.layer.3.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.5.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.4.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.13.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.23.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.22.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.4.attention.output.dense.bias', 'base_model.encoder.layer.0.output.dense.weight', 'base_model.encoder.layer.9.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.10.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.16.intermediate.dense.bias', 'base_model.encoder.layer.7.intermediate.dense.weight', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.17.attention.self.query.weight', 'base_model.encoder.layer.23.attention.self.value.weight', 'base_model.encoder.layer.5.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.3.attention.output.LayerNorm.bias', 'base_model.encoder.layer.12.intermediate.dense.weight', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.9.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.22.output.LayerNorm.weight', 'base_model.encoder.layer.2.attention.self.query.bias', 'base_model.encoder.layer.21.intermediate.dense.bias', 'base_model.encoder.layer.14.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.1.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.9.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.9.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.14.output.dense.bias', 'base_model.encoder.layer.16.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.0.output.LayerNorm.bias', 'base_model.encoder.layer.1.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.2.output.LayerNorm.weight', 'base_model.encoder.layer.21.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.10.attention.output.LayerNorm.bias', 'base_model.encoder.layer.12.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.15.intermediate.dense.bias', 'base_model.encoder.layer.3.output.LayerNorm.bias', 'base_model.embeddings.word_embeddings.weight', 'base_model.encoder.layer.3.attention.self.key.weight', 'base_model.encoder.layer.7.attention.self.key.weight', 'base_model.encoder.layer.11.attention.self.value.weight', 'base_model.encoder.layer.9.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.17.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.20.attention.output.dense.bias', 'base_model.encoder.layer.20.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.4.attention.self.key.bias', 'base_model.encoder.layer.2.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.8.attention.output.LayerNorm.weight', 'base_model.encoder.layer.22.attention.self.key.weight', 'base_model.encoder.layer.8.output.dense.weight', 'base_model.encoder.layer.7.attention.output.LayerNorm.weight', 'base_model.encoder.layer.18.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.22.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.10.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.11.output.dense.weight', 'base_model.encoder.layer.7.attention.self.query.weight', 'base_model.encoder.layer.2.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.2.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.4.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.13.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.7.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.2.attention.self.key.weight', 'base_model.encoder.layer.18.attention.output.dense.bias', 'base_model.encoder.layer.1.attention.self.value.bias', 'base_model.encoder.layer.16.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.0.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.6.attention.self.query.bias', 'base_model.encoder.layer.7.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.21.output.dense.weight', 'base_model.encoder.layer.3.output.adapters.ep.adapter_down.0.weight', 'base_model.pooler.dense.weight', 'base_model.encoder.layer.13.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.18.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.11.output.dense.bias', 'base_model.encoder.layer.19.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.14.attention.self.query.weight', 'base_model.encoder.layer.11.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.20.attention.self.value.bias', 'base_model.encoder.layer.17.attention.output.LayerNorm.weight', 'base_model.encoder.layer.19.output.LayerNorm.bias', 'base_model.encoder.layer.14.output.LayerNorm.bias', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.16.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.5.output.LayerNorm.bias', 'base_model.encoder.layer.11.attention.self.key.bias', 'base_model.encoder.layer.0.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.20.attention.output.dense.weight', 'base_model.encoder.layer.8.output.dense.bias', 'base_model.encoder.layer.20.output.dense.weight', 'base_model.encoder.layer.11.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.23.attention.self.query.bias', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.5.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.4.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.7.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.20.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.2.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.8.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.15.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.3.output.dense.weight', 'base_model.encoder.layer.6.attention.self.value.weight', 'base_model.encoder.layer.11.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.6.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.18.output.LayerNorm.weight', 'base_model.encoder.layer.15.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.2.intermediate.dense.bias', 'base_model.encoder.layer.12.attention.self.key.weight', 'base_model.encoder.layer.1.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.4.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.19.attention.self.value.bias', 'base_model.encoder.layer.1.intermediate.dense.bias', 'base_model.encoder.layer.1.output.LayerNorm.weight', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.12.attention.output.LayerNorm.bias', 'base_model.encoder.layer.14.attention.self.value.weight', 'base_model.encoder.layer.7.attention.output.dense.weight', 'base_model.encoder.layer.4.attention.self.value.weight', 'base_model.encoder.layer.17.attention.self.value.weight', 'base_model.encoder.layer.23.attention.output.LayerNorm.bias', 'base_model.encoder.layer.6.output.dense.weight', 'base_model.encoder.layer.13.attention.self.query.bias', 'base_model.encoder.layer.8.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.6.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.9.output.dense.weight', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.13.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.0.attention.self.value.bias', 'base_model.encoder.layer.22.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.21.output.LayerNorm.weight', 'base_model.encoder.layer.1.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.22.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.8.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.12.output.dense.weight', 'base_model.encoder.layer.23.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.16.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.7.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.17.attention.self.key.bias', 'base_model.encoder.layer.3.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.7.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.17.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.23.output.dense.weight', 'base_model.encoder.layer.22.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.0.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.13.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.0.attention.self.query.weight', 'base_model.encoder.layer.18.intermediate.dense.weight', 'base_model.encoder.layer.14.intermediate.dense.bias', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.15.output.adapters.tp.adapter_down.0.bias']
- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of XLMRobertaModel were not initialized from the model checkpoint at /cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//squad/xlm-KG_LR8e-6_EPOCH2.0_maxlen384_batchsize4_gradacc4 and are newly initialized: ['encoder.layer.0.attention.output.LayerNorm.weight', 'encoder.layer.23.attention.self.query.bias', 'encoder.layer.13.output.LayerNorm.bias', 'encoder.layer.17.attention.output.dense.bias', 'encoder.layer.15.attention.self.key.bias', 'encoder.layer.14.output.dense.bias', 'encoder.layer.20.attention.self.value.weight', 'encoder.layer.17.attention.self.query.bias', 'encoder.layer.10.attention.self.query.weight', 'encoder.layer.2.attention.self.key.bias', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.6.output.dense.bias', 'encoder.layer.2.attention.output.LayerNorm.weight', 'encoder.layer.18.intermediate.dense.weight', 'encoder.layer.16.intermediate.dense.weight', 'encoder.layer.11.attention.output.dense.weight', 'encoder.layer.1.attention.self.query.weight', 'pooler.dense.bias', 'encoder.layer.20.output.LayerNorm.bias', 'encoder.layer.9.attention.self.value.bias', 'encoder.layer.12.intermediate.dense.bias', 'encoder.layer.1.attention.self.key.bias', 'encoder.layer.19.attention.self.value.bias', 'encoder.layer.2.output.dense.weight', 'encoder.layer.17.output.dense.weight', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.17.attention.self.value.weight', 'encoder.layer.21.attention.output.dense.bias', 'encoder.layer.18.output.dense.bias', 'encoder.layer.9.output.dense.weight', 'encoder.layer.12.output.LayerNorm.weight', 'encoder.layer.20.output.dense.bias', 'encoder.layer.0.attention.self.query.bias', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.8.attention.self.key.weight', 'encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.layer.5.attention.output.dense.weight', 'encoder.layer.22.output.dense.bias', 'encoder.layer.14.attention.self.query.bias', 'encoder.layer.19.attention.output.dense.bias', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.19.output.LayerNorm.weight', 'embeddings.LayerNorm.weight', 'encoder.layer.11.attention.self.query.weight', 'encoder.layer.11.attention.self.value.weight', 'encoder.layer.10.intermediate.dense.weight', 'encoder.layer.18.attention.self.query.weight', 'encoder.layer.16.attention.output.dense.weight', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.10.attention.self.key.bias', 'encoder.layer.20.attention.self.value.bias', 'encoder.layer.13.attention.self.value.weight', 'encoder.layer.5.attention.self.query.bias', 'encoder.layer.13.attention.output.LayerNorm.bias', 'encoder.layer.16.intermediate.dense.bias', 'encoder.layer.3.attention.self.value.bias', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.19.attention.self.query.weight', 'encoder.layer.4.attention.self.query.bias', 'encoder.layer.1.attention.self.query.bias', 'encoder.layer.12.attention.output.dense.bias', 'encoder.layer.19.output.dense.bias', 'encoder.layer.2.attention.self.key.weight', 'encoder.layer.1.attention.output.dense.bias', 'encoder.layer.21.intermediate.dense.bias', 'encoder.layer.5.attention.output.dense.bias', 'encoder.layer.18.attention.self.key.bias', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.15.output.LayerNorm.weight', 'encoder.layer.13.attention.output.dense.bias', 'encoder.layer.11.output.LayerNorm.weight', 'encoder.layer.4.attention.self.query.weight', 'encoder.layer.14.output.LayerNorm.bias', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.8.output.dense.bias', 'encoder.layer.10.attention.self.value.bias', 'encoder.layer.21.output.LayerNorm.weight', 'encoder.layer.6.attention.output.dense.weight', 'encoder.layer.13.attention.self.key.weight', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.3.output.dense.weight', 'encoder.layer.12.output.LayerNorm.bias', 'encoder.layer.5.output.dense.weight', 'encoder.layer.0.attention.self.value.weight', 'encoder.layer.11.output.dense.weight', 'encoder.layer.15.attention.self.value.bias', 'encoder.layer.17.attention.output.LayerNorm.bias', 'encoder.layer.9.output.LayerNorm.weight', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.7.attention.self.value.weight', 'encoder.layer.11.attention.self.key.bias', 'encoder.layer.0.output.dense.bias', 'encoder.layer.15.output.dense.weight', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.9.attention.self.key.bias', 'encoder.layer.1.output.dense.weight', 'encoder.layer.19.attention.self.query.bias', 'encoder.layer.4.attention.self.value.weight', 'encoder.layer.4.attention.self.key.weight', 'encoder.layer.17.output.LayerNorm.bias', 'encoder.layer.10.attention.self.key.weight', 'encoder.layer.17.attention.output.LayerNorm.weight', 'encoder.layer.22.output.LayerNorm.bias', 'encoder.layer.22.attention.self.query.weight', 'encoder.layer.7.attention.output.dense.bias', 'encoder.layer.21.attention.self.query.bias', 'encoder.layer.13.attention.self.query.bias', 'encoder.layer.2.attention.self.value.bias', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.14.attention.output.dense.weight', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.3.attention.self.key.weight', 'encoder.layer.20.attention.output.dense.weight', 'encoder.layer.5.attention.self.query.weight', 'encoder.layer.2.attention.self.query.bias', 'encoder.layer.23.output.LayerNorm.bias', 'encoder.layer.16.attention.output.LayerNorm.bias', 'encoder.layer.9.attention.output.dense.weight', 'encoder.layer.15.output.dense.bias', 'encoder.layer.16.output.LayerNorm.weight', 'encoder.layer.18.output.dense.weight', 'encoder.layer.20.attention.output.LayerNorm.bias', 'embeddings.LayerNorm.bias', 'encoder.layer.4.attention.self.value.bias', 'encoder.layer.10.output.dense.bias', 'encoder.layer.7.output.LayerNorm.weight', 'encoder.layer.16.attention.self.query.bias', 'encoder.layer.11.attention.self.value.bias', 'encoder.layer.23.attention.self.key.weight', 'encoder.layer.16.attention.self.value.weight', 'encoder.layer.19.attention.output.dense.weight', 'encoder.layer.8.attention.self.key.bias', 'encoder.layer.12.attention.self.query.weight', 'encoder.layer.21.intermediate.dense.weight', 'encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.layer.21.attention.output.LayerNorm.bias', 'encoder.layer.20.attention.self.key.weight', 'encoder.layer.17.intermediate.dense.weight', 'encoder.layer.15.attention.output.dense.weight', 'encoder.layer.8.attention.self.value.weight', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.21.attention.self.value.bias', 'encoder.layer.0.attention.self.key.weight', 'encoder.layer.18.attention.output.dense.bias', 'encoder.layer.21.attention.self.value.weight', 'encoder.layer.18.attention.output.LayerNorm.bias', 'encoder.layer.20.attention.output.LayerNorm.weight', 'encoder.layer.1.attention.self.key.weight', 'encoder.layer.4.attention.output.dense.weight', 'encoder.layer.9.attention.self.query.weight', 'encoder.layer.14.attention.self.query.weight', 'encoder.layer.23.attention.output.dense.weight', 'encoder.layer.13.attention.output.dense.weight', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.15.output.LayerNorm.bias', 'encoder.layer.22.attention.self.key.weight', 'encoder.layer.22.attention.output.LayerNorm.weight', 'encoder.layer.12.attention.self.query.bias', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.14.intermediate.dense.bias', 'encoder.layer.12.attention.self.value.bias', 'encoder.layer.6.attention.output.dense.bias', 'encoder.layer.11.attention.output.dense.bias', 'encoder.layer.21.attention.self.key.bias', 'encoder.layer.14.intermediate.dense.weight', 'encoder.layer.6.attention.self.key.bias', 'encoder.layer.7.attention.self.value.bias', 'encoder.layer.7.attention.output.dense.weight', 'encoder.layer.15.intermediate.dense.weight', 'encoder.layer.12.intermediate.dense.weight', 'encoder.layer.15.attention.self.key.weight', 'encoder.layer.13.attention.self.query.weight', 'encoder.layer.14.output.dense.weight', 'encoder.layer.18.attention.output.LayerNorm.weight', 'encoder.layer.6.attention.self.key.weight', 'encoder.layer.15.attention.output.LayerNorm.bias', 'encoder.layer.6.attention.output.LayerNorm.weight', 'encoder.layer.13.attention.self.key.bias', 'encoder.layer.4.output.dense.bias', 'encoder.layer.8.attention.output.LayerNorm.weight', 'encoder.layer.2.attention.output.dense.bias', 'encoder.layer.3.attention.self.query.bias', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.8.attention.output.dense.weight', 'encoder.layer.12.attention.self.value.weight', 'encoder.layer.19.output.dense.weight', 'encoder.layer.13.attention.self.value.bias', 'encoder.layer.0.attention.output.dense.bias', 'encoder.layer.0.attention.output.dense.weight', 'encoder.layer.5.output.dense.bias', 'encoder.layer.18.output.LayerNorm.bias', 'encoder.layer.22.attention.output.dense.bias', 'encoder.layer.23.attention.self.query.weight', 'encoder.layer.18.attention.self.value.bias', 'encoder.layer.20.output.dense.weight', 'encoder.layer.21.output.dense.bias', 'embeddings.token_type_embeddings.weight', 'encoder.layer.22.attention.self.value.bias', 'encoder.layer.7.attention.output.LayerNorm.weight', 'encoder.layer.22.attention.self.value.weight', 'encoder.layer.23.attention.self.value.weight', 'encoder.layer.19.intermediate.dense.weight', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.6.output.LayerNorm.bias', 'encoder.layer.21.output.LayerNorm.bias', 'encoder.layer.16.attention.self.key.weight', 'encoder.layer.22.attention.output.LayerNorm.bias', 'encoder.layer.6.attention.output.LayerNorm.bias', 'encoder.layer.12.attention.output.LayerNorm.bias', 'encoder.layer.17.attention.self.value.bias', 'encoder.layer.15.attention.output.dense.bias', 'encoder.layer.19.attention.output.LayerNorm.weight', 'encoder.layer.6.output.dense.weight', 'encoder.layer.13.attention.output.LayerNorm.weight', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.18.attention.self.query.bias', 'encoder.layer.15.attention.output.LayerNorm.weight', 'encoder.layer.3.attention.output.dense.bias', 'encoder.layer.11.output.dense.bias', 'encoder.layer.12.attention.self.key.bias', 'encoder.layer.23.intermediate.dense.bias', 'encoder.layer.3.attention.self.key.bias', 'encoder.layer.12.attention.output.dense.weight', 'encoder.layer.18.intermediate.dense.bias', 'encoder.layer.23.output.dense.weight', 'encoder.layer.21.attention.output.LayerNorm.weight', 'encoder.layer.5.attention.self.value.weight', 'encoder.layer.2.attention.output.dense.weight', 'encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.layer.23.intermediate.dense.weight', 'encoder.layer.7.attention.self.query.weight', 'encoder.layer.15.attention.self.value.weight', 'encoder.layer.12.attention.output.LayerNorm.weight', 'encoder.layer.8.attention.self.query.weight', 'encoder.layer.5.attention.self.key.weight', 'encoder.layer.14.attention.output.dense.bias', 'encoder.layer.17.attention.self.query.weight', 'encoder.layer.0.attention.self.key.bias', 'encoder.layer.5.attention.self.value.bias', 'encoder.layer.9.attention.self.value.weight', 'encoder.layer.23.attention.output.dense.bias', 'encoder.layer.1.attention.output.dense.weight', 'encoder.layer.7.intermediate.dense.bias', 'encoder.layer.2.attention.self.value.weight', 'encoder.layer.14.attention.output.LayerNorm.bias', 'encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.layer.13.output.dense.bias', 'encoder.layer.11.attention.self.query.bias', 'encoder.layer.22.output.LayerNorm.weight', 'encoder.layer.22.intermediate.dense.bias', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.19.attention.self.key.bias', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.16.output.LayerNorm.bias', 'encoder.layer.1.output.dense.bias', 'encoder.layer.7.attention.self.query.bias', 'encoder.layer.1.attention.self.value.weight', 'encoder.layer.22.attention.self.query.bias', 'encoder.layer.17.attention.self.key.bias', 'encoder.layer.4.output.dense.weight', 'encoder.layer.17.output.LayerNorm.weight', 'encoder.layer.3.attention.output.dense.weight', 'encoder.layer.9.attention.output.LayerNorm.bias', 'encoder.layer.22.attention.self.key.bias', 'encoder.layer.23.output.dense.bias', 'encoder.layer.16.attention.self.key.bias', 'encoder.layer.15.intermediate.dense.bias', 'encoder.layer.8.output.dense.weight', 'encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.8.attention.output.LayerNorm.bias', 'encoder.layer.20.output.LayerNorm.weight', 'encoder.layer.20.attention.self.query.bias', 'encoder.layer.20.attention.output.dense.bias', 'embeddings.word_embeddings.weight', 'encoder.layer.14.attention.self.key.bias', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.16.attention.self.query.weight', 'encoder.layer.12.attention.self.key.weight', 'encoder.layer.20.intermediate.dense.weight', 'encoder.layer.10.attention.self.value.weight', 'encoder.layer.19.intermediate.dense.bias', 'encoder.layer.13.intermediate.dense.bias', 'encoder.layer.18.output.LayerNorm.weight', 'encoder.layer.10.output.LayerNorm.bias', 'encoder.layer.19.attention.self.value.weight', 'encoder.layer.23.attention.output.LayerNorm.weight', 'encoder.layer.14.attention.self.value.bias', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.1.attention.output.LayerNorm.weight', 'encoder.layer.21.output.dense.weight', 'encoder.layer.8.output.LayerNorm.bias', 'encoder.layer.9.attention.self.key.weight', 'encoder.layer.7.output.LayerNorm.bias', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.3.attention.self.query.weight', 'encoder.layer.17.output.dense.bias', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.10.attention.output.dense.weight', 'encoder.layer.11.attention.output.LayerNorm.weight', 'encoder.layer.11.output.LayerNorm.bias', 'encoder.layer.9.output.LayerNorm.bias', 'encoder.layer.12.output.dense.bias', 'encoder.layer.4.attention.output.LayerNorm.bias', 'encoder.layer.16.attention.output.LayerNorm.weight', 'encoder.layer.0.output.dense.weight', 'encoder.layer.6.attention.self.query.bias', 'encoder.layer.7.output.dense.weight', 'encoder.layer.7.output.dense.bias', 'encoder.layer.9.attention.self.query.bias', 'encoder.layer.19.attention.output.LayerNorm.bias', 'encoder.layer.23.attention.output.LayerNorm.bias', 'encoder.layer.23.attention.self.value.bias', 'encoder.layer.13.output.LayerNorm.weight', 'encoder.layer.7.attention.self.key.bias', 'encoder.layer.22.output.dense.weight', 'encoder.layer.10.attention.self.query.bias', 'encoder.layer.9.output.dense.bias', 'encoder.layer.10.attention.output.dense.bias', 'encoder.layer.18.attention.output.dense.weight', 'encoder.layer.4.attention.self.key.bias', 'encoder.layer.11.attention.self.key.weight', 'encoder.layer.10.attention.output.LayerNorm.bias', 'encoder.layer.6.attention.self.value.bias', 'encoder.layer.15.attention.self.query.bias', 'encoder.layer.22.intermediate.dense.weight', 'encoder.layer.1.attention.self.value.bias', 'encoder.layer.5.output.LayerNorm.bias', 'encoder.layer.2.output.dense.bias', 'encoder.layer.14.attention.output.LayerNorm.weight', 'encoder.layer.7.attention.self.key.weight', 'encoder.layer.23.attention.self.key.bias', 'encoder.layer.8.attention.self.query.bias', 'encoder.layer.14.attention.self.value.weight', 'encoder.layer.6.attention.self.value.weight', 'encoder.layer.7.attention.output.LayerNorm.bias', 'encoder.layer.13.output.dense.weight', 'encoder.layer.17.attention.self.key.weight', 'encoder.layer.10.output.dense.weight', 'encoder.layer.21.attention.output.dense.weight', 'encoder.layer.14.output.LayerNorm.weight', 'encoder.layer.16.output.dense.bias', 'encoder.layer.2.attention.self.query.weight', 'encoder.layer.10.attention.output.LayerNorm.weight', 'encoder.layer.8.output.LayerNorm.weight', 'encoder.layer.21.attention.self.key.weight', 'encoder.layer.18.attention.self.value.weight', 'encoder.layer.16.output.dense.weight', 'encoder.layer.17.attention.output.dense.weight', 'encoder.layer.0.attention.self.query.weight', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.22.attention.output.dense.weight', 'encoder.layer.9.attention.output.LayerNorm.weight', 'pooler.dense.weight', 'encoder.layer.21.attention.self.query.weight', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.3.attention.self.value.weight', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.4.attention.output.dense.bias', 'encoder.layer.16.attention.self.value.bias', 'encoder.layer.19.attention.self.key.weight', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.20.attention.self.key.bias', 'encoder.layer.10.output.LayerNorm.weight', 'encoder.layer.17.intermediate.dense.bias', 'encoder.layer.19.output.LayerNorm.bias', 'encoder.layer.16.attention.output.dense.bias', 'encoder.layer.9.attention.output.dense.bias', 'encoder.layer.20.attention.self.query.weight', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.0.attention.self.value.bias', 'encoder.layer.6.attention.self.query.weight', 'encoder.layer.3.output.dense.bias', 'encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.layer.8.attention.output.dense.bias', 'encoder.layer.4.attention.output.LayerNorm.weight', 'encoder.layer.18.attention.self.key.weight', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.23.output.LayerNorm.weight', 'encoder.layer.5.attention.self.key.bias', 'encoder.layer.5.attention.output.LayerNorm.weight', 'encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.layer.13.intermediate.dense.weight', 'encoder.layer.20.intermediate.dense.bias', 'embeddings.position_embeddings.weight', 'encoder.layer.2.attention.output.LayerNorm.bias', 'encoder.layer.14.attention.self.key.weight', 'encoder.layer.8.attention.self.value.bias', 'encoder.layer.15.attention.self.query.weight', 'encoder.layer.12.output.dense.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Overwriting existing adapter 'ep'.
Overwriting existing adapter 'tp'.
Overwriting existing adapter 'es'.
Overwriting existing adapter 'ts'.
Overwriting existing adapter fusion module 'ep,tp,es,ts'
/cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//squad/xlm-KG_LR8e-6_EPOCH2.0_maxlen384_batchsize4_gradacc4
XLMConfig {
  "architectures": [
    "XLMRobertaForMaskedLM"
  ],
  "asm": false,
  "attention_dropout": 0.1,
  "attention_probs_dropout_prob": 0.1,
  "bos_index": 0,
  "bos_token_id": 0,
  "causal": false,
  "dropout": 0.1,
  "emb_dim": 1024,
  "embed_init_std": 0.02209708691207961,
  "end_n_top": 5,
  "eos_index": 1,
  "eos_token_id": 2,
  "gelu_activation": true,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "init_std": 0.02,
  "initializer_range": 0.02,
  "intermediate_size": 4096,
  "is_encoder": true,
  "lang_id": 0,
  "layer_norm_eps": 1e-05,
  "mask_index": 5,
  "mask_token_id": 0,
  "max_position_embeddings": 514,
  "model_type": "xlm",
  "n_heads": 16,
  "n_langs": 1,
  "n_layers": 24,
  "output_past": true,
  "pad_index": 2,
  "pad_token_id": 1,
  "sinusoidal_embeddings": false,
  "start_n_top": 5,
  "summary_activation": null,
  "summary_first_dropout": 0.1,
  "summary_proj_to_labels": true,
  "summary_type": "first",
  "summary_use_proj": true,
  "transformers_version": "4.17.0",
  "type_vocab_size": 1,
  "unk_index": 3,
  "use_lang_emb": false,
  "vocab_size": 250002
}

Traceback (most recent call last):
  File "third_party/run_squad.py", line 958, in <module>
    main()
  File "third_party/run_squad.py", line 941, in main
    load_model(model, os.path.join(args.output_dir, "pytorch_model.bin"))
  File "third_party/run_squad.py", line 98, in load_model
    model.load_state_dict(torch.load(path, map_location='cpu'), strict=False)
  File "/cluster/project/sachan/yifan/softwares/anaconda/anaconda3/envs/xfactr/lib/python3.8/site-packages/torch/serialization.py", line 581, in load
    with _open_file_like(f, 'rb') as opened_file:
  File "/cluster/project/sachan/yifan/softwares/anaconda/anaconda3/envs/xfactr/lib/python3.8/site-packages/torch/serialization.py", line 230, in _open_file_like
    return _open_file(name_or_buffer, mode)
  File "/cluster/project/sachan/yifan/softwares/anaconda/anaconda3/envs/xfactr/lib/python3.8/site-packages/torch/serialization.py", line 211, in __init__
    super(_open_file, self).__init__(open(name, mode))
FileNotFoundError: [Errno 2] No such file or directory: '/cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//squad/xlm-KG_LR8e-6_EPOCH2.0_maxlen384_batchsize4_gradacc4/predictions/mlqa/pytorch_model.bin'
  es 
2022-05-09 21:38:03.622230: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0
05/09/2022 21:38:06 - WARNING - __main__ -   Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, 16-bits training: False
You are using a model of type xlm-roberta to instantiate a model of type xlm. This is not supported for all configurations of models and can yield errors.
Some weights of the model checkpoint at /cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//squad/xlm-KG_LR8e-6_EPOCH2.0_maxlen384_batchsize4_gradacc4 were not used when initializing XLMRobertaModel: ['base_model.encoder.layer.8.output.dense.weight', 'base_model.encoder.layer.1.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.5.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.3.attention.output.dense.weight', 'base_model.encoder.layer.22.attention.self.query.weight', 'base_model.encoder.layer.0.attention.output.LayerNorm.bias', 'base_model.encoder.layer.18.output.LayerNorm.bias', 'base_model.encoder.layer.3.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.9.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.0.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.14.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.20.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.9.attention.self.value.weight', 'base_model.encoder.layer.18.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.15.attention.self.value.weight', 'base_model.encoder.layer.7.attention.self.query.weight', 'base_model.encoder.layer.17.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.4.attention.self.query.bias', 'base_model.encoder.layer.4.attention.self.key.bias', 'base_model.encoder.layer.10.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.13.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.10.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.11.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.14.attention.output.dense.weight', 'base_model.encoder.layer.18.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.23.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.22.output.LayerNorm.weight', 'base_model.encoder.layer.8.attention.output.LayerNorm.weight', 'base_model.encoder.layer.2.attention.self.key.bias', 'base_model.encoder.layer.22.attention.output.dense.bias', 'base_model.encoder.layer.8.attention.self.value.bias', 'base_model.encoder.layer.10.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.23.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.23.attention.self.value.weight', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.5.intermediate.dense.bias', 'base_model.encoder.layer.9.attention.self.key.bias', 'base_model.encoder.layer.4.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.11.attention.self.value.weight', 'base_model.encoder.layer.13.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.8.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.15.attention.self.key.weight', 'base_model.encoder.layer.1.attention.self.key.weight', 'base_model.encoder.layer.16.output.LayerNorm.bias', 'base_model.encoder.layer.23.attention.self.value.bias', 'base_model.encoder.layer.12.output.LayerNorm.bias', 'base_model.encoder.layer.20.attention.output.LayerNorm.weight', 'base_model.encoder.layer.23.intermediate.dense.bias', 'base_model.encoder.layer.12.output.dense.bias', 'base_model.encoder.layer.23.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.21.attention.output.dense.weight', 'base_model.encoder.layer.10.attention.self.key.bias', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.21.output.dense.bias', 'base_model.encoder.layer.18.attention.self.query.bias', 'base_model.encoder.layer.5.attention.self.key.bias', 'base_model.encoder.layer.14.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.5.output.dense.weight', 'base_model.encoder.layer.17.attention.self.value.bias', 'base_model.encoder.layer.22.attention.self.value.weight', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.23.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.16.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.15.intermediate.dense.weight', 'base_model.encoder.layer.0.attention.output.dense.weight', 'base_model.encoder.layer.16.attention.output.dense.bias', 'base_model.encoder.layer.1.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.5.output.LayerNorm.bias', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.2.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.9.output.dense.bias', 'base_model.encoder.layer.10.attention.output.dense.weight', 'base_model.encoder.layer.1.attention.self.key.bias', 'base_model.encoder.layer.14.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.10.intermediate.dense.weight', 'base_model.encoder.layer.0.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.1.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.19.intermediate.dense.weight', 'base_model.encoder.layer.11.intermediate.dense.weight', 'base_model.encoder.layer.4.attention.self.key.weight', 'base_model.encoder.layer.7.output.dense.bias', 'base_model.encoder.layer.16.output.dense.bias', 'base_model.encoder.layer.11.attention.output.LayerNorm.bias', 'base_model.encoder.layer.4.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.9.attention.output.LayerNorm.bias', 'base_model.encoder.layer.11.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.13.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.14.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.0.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.1.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'qa_outputs.bias', 'base_model.encoder.layer.3.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.0.output.LayerNorm.bias', 'base_model.encoder.layer.10.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.4.attention.output.LayerNorm.bias', 'base_model.encoder.layer.0.attention.self.value.weight', 'base_model.encoder.layer.1.attention.output.dense.bias', 'base_model.encoder.layer.2.attention.output.LayerNorm.weight', 'base_model.encoder.layer.7.attention.self.key.weight', 'base_model.encoder.layer.10.output.dense.bias', 'base_model.encoder.layer.10.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.7.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.20.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.2.output.adapters.ts.adapter_down.0.bias', 'qa_outputs.weight', 'base_model.encoder.layer.19.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.16.attention.output.LayerNorm.bias', 'base_model.encoder.layer.6.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.9.attention.self.query.weight', 'base_model.encoder.layer.18.output.dense.bias', 'base_model.encoder.layer.10.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.13.attention.output.LayerNorm.weight', 'base_model.encoder.layer.12.attention.self.query.weight', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.14.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.7.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.16.attention.self.value.bias', 'base_model.encoder.layer.11.attention.self.query.bias', 'base_model.encoder.layer.8.intermediate.dense.weight', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.22.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.9.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.23.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.18.attention.self.value.bias', 'base_model.encoder.layer.11.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.21.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.4.output.dense.weight', 'base_model.encoder.layer.8.output.dense.bias', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.3.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.6.attention.self.value.bias', 'base_model.encoder.layer.19.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.17.attention.self.key.bias', 'base_model.encoder.layer.2.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.15.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.3.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.19.attention.self.value.bias', 'base_model.encoder.layer.7.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.2.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.10.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.9.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.22.output.dense.weight', 'base_model.encoder.layer.10.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.17.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.1.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.13.intermediate.dense.weight', 'base_model.encoder.layer.0.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.10.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.18.output.adapters.tp.adapter_down.0.bias', 'base_model.pooler.dense.weight', 'base_model.encoder.layer.15.intermediate.dense.bias', 'base_model.encoder.layer.13.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.6.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.4.intermediate.dense.bias', 'base_model.encoder.layer.6.attention.self.key.weight', 'base_model.encoder.layer.8.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.9.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.19.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.14.attention.self.value.bias', 'base_model.encoder.layer.17.attention.output.LayerNorm.bias', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.4.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.10.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.20.output.LayerNorm.weight', 'base_model.encoder.layer.19.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.6.attention.self.query.bias', 'base_model.encoder.layer.23.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.6.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.18.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.7.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.5.attention.output.LayerNorm.bias', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.20.attention.output.dense.weight', 'base_model.encoder.layer.9.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.7.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.18.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.4.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.0.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.12.attention.self.value.weight', 'base_model.encoder.layer.0.intermediate.dense.weight', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.5.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.4.attention.output.LayerNorm.weight', 'base_model.encoder.layer.23.attention.self.query.bias', 'base_model.encoder.layer.4.attention.self.value.bias', 'base_model.encoder.layer.14.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.21.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.3.attention.self.value.weight', 'base_model.encoder.layer.22.output.dense.bias', 'base_model.encoder.layer.20.attention.self.query.weight', 'base_model.encoder.layer.1.output.LayerNorm.bias', 'base_model.encoder.layer.21.attention.output.dense.bias', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.5.output.dense.bias', 'base_model.encoder.layer.10.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.12.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.2.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.19.attention.output.dense.weight', 'base_model.encoder.layer.12.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.11.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.11.attention.output.dense.bias', 'base_model.encoder.layer.11.attention.output.dense.weight', 'base_model.encoder.layer.6.attention.self.key.bias', 'base_model.encoder.layer.7.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.6.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.5.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.12.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.16.attention.self.key.bias', 'base_model.encoder.layer.22.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.3.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.8.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.1.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.10.intermediate.dense.bias', 'base_model.encoder.layer.20.attention.output.LayerNorm.bias', 'base_model.encoder.layer.17.attention.self.query.bias', 'base_model.encoder.layer.15.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.22.attention.output.dense.weight', 'base_model.encoder.layer.20.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.16.attention.output.LayerNorm.weight', 'base_model.encoder.layer.17.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.15.attention.output.LayerNorm.weight', 'base_model.encoder.layer.22.intermediate.dense.bias', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.13.output.LayerNorm.bias', 'base_model.encoder.layer.17.attention.self.key.weight', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.12.output.dense.weight', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.12.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.21.output.adapters.es.adapter_down.0.weight', 'base_model.embeddings.word_embeddings.weight', 'base_model.encoder.layer.1.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.16.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.20.attention.self.key.bias', 'base_model.encoder.layer.13.intermediate.dense.bias', 'base_model.encoder.layer.2.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.3.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.7.output.dense.weight', 'base_model.encoder.layer.4.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.10.attention.self.query.bias', 'base_model.encoder.layer.3.output.dense.bias', 'base_model.encoder.layer.2.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.7.attention.output.LayerNorm.weight', 'base_model.encoder.layer.8.intermediate.dense.bias', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.11.output.dense.bias', 'base_model.encoder.layer.4.output.LayerNorm.weight', 'base_model.encoder.layer.9.attention.output.dense.bias', 'base_model.encoder.layer.17.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.14.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.7.attention.output.dense.weight', 'base_model.encoder.layer.17.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.21.output.dense.weight', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.22.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.12.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.7.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.8.attention.self.query.weight', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.21.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.1.attention.self.query.weight', 'base_model.encoder.layer.8.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.10.output.LayerNorm.weight', 'base_model.encoder.layer.6.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.2.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.15.attention.output.LayerNorm.bias', 'base_model.encoder.layer.15.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.18.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.18.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.7.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.8.attention.self.query.bias', 'base_model.encoder.layer.18.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.0.attention.output.dense.bias', 'base_model.encoder.layer.18.intermediate.dense.weight', 'base_model.encoder.layer.6.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.19.output.LayerNorm.bias', 'base_model.encoder.layer.21.output.LayerNorm.weight', 'base_model.encoder.layer.14.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.16.output.dense.weight', 'base_model.encoder.layer.11.attention.self.key.bias', 'base_model.encoder.layer.14.attention.self.key.weight', 'base_model.encoder.layer.14.output.dense.weight', 'base_model.encoder.layer.20.output.LayerNorm.bias', 'base_model.encoder.layer.16.attention.self.key.weight', 'base_model.encoder.layer.15.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.10.output.dense.weight', 'base_model.encoder.layer.13.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.6.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.13.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.11.output.dense.weight', 'base_model.encoder.layer.16.intermediate.dense.bias', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.22.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.10.attention.self.key.weight', 'base_model.encoder.layer.17.intermediate.dense.bias', 'base_model.encoder.layer.20.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.21.output.LayerNorm.bias', 'base_model.encoder.layer.23.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.19.intermediate.dense.bias', 'base_model.encoder.layer.0.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.11.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.12.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.19.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.16.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.21.attention.self.value.weight', 'base_model.encoder.layer.9.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.19.attention.self.query.weight', 'base_model.encoder.layer.6.attention.self.query.weight', 'base_model.encoder.layer.21.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.6.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.0.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.19.attention.self.key.weight', 'base_model.encoder.layer.22.attention.output.LayerNorm.bias', 'base_model.encoder.layer.15.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.12.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.13.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.2.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.21.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.12.intermediate.dense.weight', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.2.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.12.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.16.attention.self.query.bias', 'base_model.encoder.layer.9.attention.self.key.weight', 'base_model.encoder.layer.20.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.18.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.16.output.LayerNorm.weight', 'base_model.encoder.layer.3.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.14.output.LayerNorm.weight', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.13.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.14.attention.output.LayerNorm.bias', 'base_model.encoder.layer.23.output.dense.bias', 'base_model.encoder.layer.23.intermediate.dense.weight', 'base_model.encoder.layer.15.output.dense.bias', 'base_model.encoder.layer.12.attention.output.LayerNorm.weight', 'base_model.encoder.layer.9.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.1.output.dense.bias', 'base_model.encoder.layer.6.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.12.attention.self.value.bias', 'base_model.encoder.layer.23.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.17.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.8.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.8.attention.output.LayerNorm.bias', 'base_model.encoder.layer.8.attention.output.dense.bias', 'base_model.encoder.layer.19.attention.self.key.bias', 'base_model.encoder.layer.19.attention.self.query.bias', 'base_model.pooler.dense.bias', 'base_model.embeddings.token_type_embeddings.weight', 'base_model.encoder.layer.16.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.15.attention.output.dense.weight', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.12.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.20.output.dense.weight', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.0.attention.output.LayerNorm.weight', 'base_model.encoder.layer.12.attention.output.dense.weight', 'base_model.encoder.layer.14.attention.self.value.weight', 'base_model.encoder.layer.2.intermediate.dense.bias', 'base_model.encoder.layer.14.attention.output.dense.bias', 'base_model.encoder.layer.4.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.11.output.LayerNorm.bias', 'base_model.encoder.layer.10.attention.output.LayerNorm.weight', 'base_model.encoder.layer.2.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.15.attention.self.key.bias', 'base_model.encoder.layer.11.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.22.attention.self.key.bias', 'base_model.encoder.layer.4.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.5.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.4.attention.self.query.weight', 'base_model.encoder.layer.12.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.4.intermediate.dense.weight', 'base_model.encoder.layer.0.output.LayerNorm.weight', 'base_model.encoder.layer.14.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.2.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.15.attention.self.value.bias', 'base_model.encoder.layer.17.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.2.intermediate.dense.weight', 'base_model.encoder.layer.9.attention.self.value.bias', 'base_model.encoder.layer.11.attention.self.query.weight', 'base_model.encoder.layer.4.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.15.attention.output.dense.bias', 'base_model.encoder.layer.15.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.17.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.21.attention.self.query.bias', 'base_model.encoder.layer.7.attention.output.dense.bias', 'base_model.encoder.layer.19.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.13.output.dense.bias', 'base_model.encoder.layer.13.output.LayerNorm.weight', 'base_model.encoder.layer.23.attention.output.LayerNorm.bias', 'base_model.encoder.layer.20.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.13.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.17.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.embeddings.position_ids', 'base_model.encoder.layer.5.intermediate.dense.weight', 'base_model.encoder.layer.12.attention.output.LayerNorm.bias', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.12.attention.self.key.weight', 'base_model.encoder.layer.16.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.15.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.13.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.15.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.1.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.2.attention.self.query.weight', 'base_model.encoder.layer.5.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.2.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.14.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.7.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.19.output.dense.bias', 'base_model.encoder.layer.8.output.LayerNorm.bias', 'base_model.encoder.layer.1.intermediate.dense.bias', 'base_model.encoder.layer.13.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.4.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.11.attention.self.key.weight', 'base_model.encoder.layer.2.attention.self.value.weight', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.22.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.8.attention.self.key.weight', 'base_model.encoder.layer.21.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.21.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.2.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.14.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.15.output.LayerNorm.bias', 'base_model.encoder.layer.10.attention.self.query.weight', 'base_model.encoder.layer.19.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.20.attention.self.value.bias', 'base_model.encoder.layer.1.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.15.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.19.attention.output.LayerNorm.weight', 'base_model.encoder.layer.22.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.2.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.22.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.3.attention.output.LayerNorm.weight', 'base_model.embeddings.position_embeddings.weight', 'base_model.encoder.layer.14.attention.self.key.bias', 'base_model.encoder.layer.13.attention.self.value.bias', 'base_model.encoder.layer.17.output.dense.weight', 'base_model.encoder.layer.3.intermediate.dense.weight', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.1.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.13.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.2.attention.output.LayerNorm.bias', 'base_model.encoder.layer.6.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.1.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.7.intermediate.dense.bias', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.22.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.10.attention.self.value.weight', 'base_model.encoder.layer.9.output.dense.weight', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.23.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.8.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.7.output.LayerNorm.weight', 'base_model.encoder.layer.0.attention.self.key.bias', 'base_model.encoder.layer.11.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.4.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.4.output.dense.bias', 'base_model.encoder.layer.11.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.2.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.9.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.7.attention.self.value.bias', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.9.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.3.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.5.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.20.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.21.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.20.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.8.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.19.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.20.attention.output.dense.bias', 'base_model.encoder.layer.17.attention.self.query.weight', 'base_model.encoder.layer.7.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.6.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.18.attention.self.key.bias', 'base_model.encoder.layer.1.attention.self.query.bias', 'base_model.encoder.layer.18.attention.output.dense.weight', 'base_model.encoder.layer.18.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.23.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.7.attention.self.value.weight', 'base_model.encoder.layer.20.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.14.attention.self.query.bias', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.11.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.15.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.5.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.0.attention.self.value.bias', 'base_model.encoder.layer.2.attention.self.value.bias', 'base_model.encoder.layer.16.attention.self.value.weight', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.6.attention.self.value.weight', 'base_model.encoder.layer.8.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.7.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.8.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.22.attention.self.value.bias', 'base_model.encoder.layer.21.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.20.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.22.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.0.attention.self.query.weight', 'base_model.encoder.layer.16.attention.output.dense.weight', 'base_model.encoder.layer.5.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.16.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.6.intermediate.dense.weight', 'base_model.encoder.layer.19.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.21.attention.self.key.weight', 'base_model.encoder.layer.0.output.dense.bias', 'base_model.encoder.layer.23.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.18.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.8.output.LayerNorm.weight', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.8.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.14.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.16.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.23.attention.output.LayerNorm.weight', 'base_model.encoder.layer.20.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.1.attention.output.dense.weight', 'base_model.encoder.layer.10.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.18.attention.self.key.weight', 'base_model.encoder.layer.0.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.8.attention.self.key.bias', 'base_model.encoder.layer.17.attention.output.LayerNorm.weight', 'base_model.encoder.layer.22.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.23.attention.output.dense.weight', 'base_model.encoder.layer.4.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.1.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.12.output.LayerNorm.weight', 'base_model.encoder.layer.20.intermediate.dense.weight', 'base_model.encoder.layer.5.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.1.attention.self.value.weight', 'base_model.encoder.layer.12.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.6.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.13.attention.self.key.bias', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.14.output.LayerNorm.bias', 'base_model.encoder.layer.9.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.8.attention.output.dense.weight', 'base_model.encoder.layer.11.attention.output.LayerNorm.weight', 'base_model.encoder.layer.4.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.12.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.19.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.0.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.1.attention.output.LayerNorm.weight', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.11.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.5.attention.self.value.bias', 'base_model.encoder.layer.13.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.21.attention.self.key.bias', 'base_model.encoder.layer.17.attention.self.value.weight', 'base_model.encoder.layer.0.intermediate.dense.bias', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.5.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.8.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.21.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.0.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.12.attention.self.key.bias', 'base_model.encoder.layer.0.attention.self.key.weight', 'base_model.encoder.layer.3.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.18.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.23.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.8.attention.self.value.weight', 'base_model.encoder.layer.6.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.9.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.16.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.5.output.LayerNorm.weight', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.4.attention.output.dense.weight', 'base_model.encoder.layer.6.output.LayerNorm.weight', 'base_model.encoder.layer.21.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.12.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.22.intermediate.dense.weight', 'base_model.encoder.layer.11.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.10.output.LayerNorm.bias', 'base_model.encoder.layer.16.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.12.attention.output.dense.bias', 'base_model.encoder.layer.21.attention.self.value.bias', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.5.attention.self.query.weight', 'base_model.encoder.layer.8.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.9.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.17.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.1.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.11.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.11.output.LayerNorm.weight', 'base_model.encoder.layer.11.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.20.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.5.attention.self.query.bias', 'base_model.encoder.layer.7.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.13.attention.self.key.weight', 'base_model.encoder.layer.17.output.dense.bias', 'base_model.encoder.layer.21.attention.output.LayerNorm.bias', 'base_model.encoder.layer.12.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.13.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.0.output.dense.weight', 'base_model.encoder.layer.3.output.LayerNorm.bias', 'base_model.encoder.layer.6.attention.output.LayerNorm.bias', 'base_model.encoder.layer.2.attention.self.query.bias', 'base_model.encoder.layer.18.attention.self.query.weight', 'base_model.encoder.layer.22.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.6.output.LayerNorm.bias', 'base_model.encoder.layer.7.attention.self.key.bias', 'base_model.encoder.layer.11.attention.self.value.bias', 'base_model.encoder.layer.6.output.dense.bias', 'base_model.encoder.layer.10.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.0.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.16.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.14.output.dense.bias', 'base_model.encoder.layer.5.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.19.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.11.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.2.attention.self.key.weight', 'base_model.encoder.layer.23.output.LayerNorm.weight', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.18.attention.output.dense.bias', 'base_model.encoder.layer.21.output.adapters.ts.adapter_up.weight', 'base_model.embeddings.LayerNorm.weight', 'base_model.encoder.layer.22.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.6.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.14.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.18.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.18.attention.output.LayerNorm.weight', 'base_model.encoder.layer.3.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.15.output.dense.weight', 'base_model.encoder.layer.2.output.LayerNorm.weight', 'base_model.encoder.layer.9.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.4.attention.self.value.weight', 'base_model.encoder.layer.23.output.LayerNorm.bias', 'base_model.encoder.layer.11.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.7.attention.self.query.bias', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.5.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.7.output.LayerNorm.bias', 'base_model.encoder.layer.13.output.dense.weight', 'base_model.encoder.layer.9.attention.self.query.bias', 'base_model.encoder.layer.10.attention.output.LayerNorm.bias', 'base_model.encoder.layer.20.output.dense.bias', 'base_model.encoder.layer.21.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.18.output.LayerNorm.weight', 'base_model.encoder.layer.6.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.16.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.9.output.LayerNorm.bias', 'base_model.encoder.layer.14.intermediate.dense.bias', 'base_model.encoder.layer.5.attention.output.dense.bias', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.9.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.3.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.10.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.3.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.16.attention.self.query.weight', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.12.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.12.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.9.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.13.attention.output.dense.weight', 'base_model.encoder.layer.20.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.0.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.1.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.3.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.7.intermediate.dense.weight', 'base_model.encoder.layer.1.intermediate.dense.weight', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.7.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.15.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.16.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.13.attention.self.query.weight', 'base_model.encoder.layer.5.attention.self.key.weight', 'base_model.encoder.layer.3.attention.output.LayerNorm.bias', 'base_model.encoder.layer.5.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.0.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.17.attention.output.dense.bias', 'base_model.encoder.layer.23.attention.self.query.weight', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.18.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.4.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.15.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.2.attention.output.dense.bias', 'base_model.encoder.layer.22.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.22.attention.self.query.bias', 'base_model.encoder.layer.3.attention.self.query.weight', 'base_model.encoder.layer.15.output.LayerNorm.weight', 'base_model.encoder.layer.1.output.dense.weight', 'base_model.encoder.layer.2.attention.output.dense.weight', 'base_model.encoder.layer.3.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.17.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.15.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.13.attention.output.dense.bias', 'base_model.encoder.layer.10.attention.output.dense.bias', 'base_model.encoder.layer.19.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.23.output.dense.weight', 'base_model.encoder.layer.16.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.23.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.3.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.20.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.23.attention.self.key.bias', 'base_model.encoder.layer.18.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.23.attention.self.key.weight', 'base_model.encoder.layer.2.output.dense.bias', 'base_model.encoder.layer.6.output.dense.weight', 'base_model.encoder.layer.0.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.6.attention.output.LayerNorm.weight', 'base_model.encoder.layer.21.intermediate.dense.weight', 'base_model.encoder.layer.5.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.10.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.17.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.19.output.LayerNorm.weight', 'base_model.encoder.layer.19.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.19.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.17.intermediate.dense.weight', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.0.attention.self.query.bias', 'base_model.encoder.layer.8.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.18.intermediate.dense.bias', 'base_model.encoder.layer.5.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.14.attention.self.query.weight', 'base_model.encoder.layer.20.attention.self.value.weight', 'base_model.encoder.layer.0.output.adapters.es.adapter_down.0.weight', 'base_model.embeddings.LayerNorm.bias', 'base_model.encoder.layer.3.output.dense.weight', 'base_model.encoder.layer.17.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.13.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.9.intermediate.dense.weight', 'base_model.encoder.layer.19.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.1.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.17.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.14.intermediate.dense.weight', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.3.attention.output.dense.bias', 'base_model.encoder.layer.20.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.4.output.LayerNorm.bias', 'base_model.encoder.layer.10.attention.self.value.bias', 'base_model.encoder.layer.18.attention.self.value.weight', 'base_model.encoder.layer.22.attention.output.LayerNorm.weight', 'base_model.encoder.layer.3.attention.self.query.bias', 'base_model.encoder.layer.20.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.17.output.LayerNorm.weight', 'base_model.encoder.layer.7.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.2.output.LayerNorm.bias', 'base_model.encoder.layer.14.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.18.output.dense.weight', 'base_model.encoder.layer.17.attention.output.dense.weight', 'base_model.encoder.layer.8.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.18.attention.output.LayerNorm.bias', 'base_model.encoder.layer.15.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.9.attention.output.LayerNorm.weight', 'base_model.encoder.layer.23.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.1.attention.self.value.bias', 'base_model.encoder.layer.21.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.3.attention.self.key.bias', 'base_model.encoder.layer.5.attention.self.value.weight', 'base_model.encoder.layer.19.attention.output.dense.bias', 'base_model.encoder.layer.19.attention.self.value.weight', 'base_model.encoder.layer.6.intermediate.dense.bias', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.7.attention.output.LayerNorm.bias', 'base_model.encoder.layer.14.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.18.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.23.attention.output.dense.bias', 'base_model.encoder.layer.11.intermediate.dense.bias', 'base_model.encoder.layer.19.output.dense.weight', 'base_model.encoder.layer.3.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.9.output.LayerNorm.weight', 'base_model.encoder.layer.3.attention.self.key.weight', 'base_model.encoder.layer.19.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.20.intermediate.dense.bias', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.23.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.9.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.4.attention.output.dense.bias', 'base_model.encoder.layer.10.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.15.attention.self.query.weight', 'base_model.encoder.layer.13.attention.self.value.weight', 'base_model.encoder.layer.3.intermediate.dense.bias', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.13.attention.self.query.bias', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.16.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.22.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.6.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.1.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.23.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.20.attention.self.key.weight', 'base_model.encoder.layer.16.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.20.attention.self.query.bias', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.4.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.15.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.17.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.5.attention.output.LayerNorm.weight', 'base_model.encoder.layer.21.intermediate.dense.bias', 'base_model.encoder.layer.5.attention.output.dense.weight', 'base_model.encoder.layer.3.attention.self.value.bias', 'base_model.encoder.layer.15.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.1.output.LayerNorm.weight', 'base_model.encoder.layer.7.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.6.attention.output.dense.weight', 'base_model.encoder.layer.16.intermediate.dense.weight', 'base_model.encoder.layer.22.attention.self.key.weight', 'base_model.encoder.layer.9.attention.output.dense.weight', 'base_model.encoder.layer.21.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.22.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.8.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.14.attention.output.LayerNorm.weight', 'base_model.encoder.layer.1.attention.output.LayerNorm.bias', 'base_model.encoder.layer.9.intermediate.dense.bias', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.21.attention.self.query.weight', 'base_model.encoder.layer.2.output.dense.weight', 'base_model.encoder.layer.12.attention.self.query.bias', 'base_model.encoder.layer.13.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.17.output.LayerNorm.bias', 'base_model.encoder.layer.19.attention.output.LayerNorm.bias', 'base_model.encoder.layer.22.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.12.intermediate.dense.bias', 'base_model.encoder.layer.15.attention.self.query.bias', 'base_model.encoder.layer.4.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.5.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.4.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.0.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.11.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.16.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.3.output.LayerNorm.weight', 'base_model.encoder.layer.6.attention.output.dense.bias', 'base_model.encoder.layer.21.attention.output.LayerNorm.weight', 'base_model.encoder.layer.22.output.LayerNorm.bias', 'base_model.encoder.layer.8.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.13.attention.output.LayerNorm.bias', 'base_model.encoder.layer.14.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.7.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.17.output.adapters.ep.adapter_up.bias']
- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of XLMRobertaModel were not initialized from the model checkpoint at /cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//squad/xlm-KG_LR8e-6_EPOCH2.0_maxlen384_batchsize4_gradacc4 and are newly initialized: ['encoder.layer.5.attention.self.value.bias', 'encoder.layer.15.attention.self.value.weight', 'encoder.layer.16.attention.self.query.weight', 'encoder.layer.20.output.LayerNorm.weight', 'encoder.layer.23.output.LayerNorm.weight', 'encoder.layer.7.attention.self.value.bias', 'encoder.layer.13.attention.self.key.weight', 'encoder.layer.2.attention.output.dense.bias', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.13.attention.self.key.bias', 'encoder.layer.23.output.dense.bias', 'encoder.layer.2.attention.output.dense.weight', 'encoder.layer.19.attention.self.query.bias', 'encoder.layer.4.attention.self.key.bias', 'encoder.layer.0.attention.output.dense.bias', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.19.attention.output.dense.bias', 'encoder.layer.11.attention.self.value.weight', 'encoder.layer.18.attention.output.LayerNorm.weight', 'encoder.layer.22.output.LayerNorm.bias', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.3.attention.output.dense.bias', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.9.attention.self.key.bias', 'encoder.layer.16.intermediate.dense.weight', 'encoder.layer.17.intermediate.dense.weight', 'encoder.layer.13.attention.output.LayerNorm.weight', 'encoder.layer.19.attention.self.key.weight', 'encoder.layer.17.attention.self.value.bias', 'encoder.layer.20.output.LayerNorm.bias', 'encoder.layer.23.attention.self.query.bias', 'encoder.layer.16.attention.self.value.bias', 'encoder.layer.15.output.LayerNorm.bias', 'encoder.layer.23.output.dense.weight', 'encoder.layer.3.output.dense.weight', 'encoder.layer.6.attention.output.dense.weight', 'encoder.layer.14.output.LayerNorm.weight', 'encoder.layer.18.attention.self.key.bias', 'embeddings.token_type_embeddings.weight', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.18.output.dense.weight', 'encoder.layer.10.attention.output.dense.weight', 'encoder.layer.17.attention.self.query.bias', 'encoder.layer.23.attention.self.key.bias', 'encoder.layer.14.attention.self.value.bias', 'encoder.layer.23.attention.self.query.weight', 'encoder.layer.22.attention.self.value.bias', 'encoder.layer.15.intermediate.dense.weight', 'encoder.layer.9.attention.output.dense.bias', 'encoder.layer.21.attention.self.query.weight', 'encoder.layer.19.attention.output.LayerNorm.bias', 'encoder.layer.7.output.dense.bias', 'encoder.layer.19.attention.self.query.weight', 'encoder.layer.14.output.LayerNorm.bias', 'encoder.layer.21.attention.output.dense.weight', 'encoder.layer.19.output.LayerNorm.bias', 'encoder.layer.8.attention.output.dense.bias', 'encoder.layer.11.attention.output.dense.bias', 'encoder.layer.20.attention.output.dense.bias', 'encoder.layer.3.attention.self.query.bias', 'encoder.layer.8.attention.self.query.weight', 'encoder.layer.22.attention.output.dense.bias', 'encoder.layer.22.attention.self.query.weight', 'encoder.layer.12.attention.self.query.weight', 'encoder.layer.6.attention.output.LayerNorm.bias', 'encoder.layer.23.attention.output.dense.weight', 'encoder.layer.5.attention.self.key.bias', 'encoder.layer.19.attention.self.key.bias', 'encoder.layer.17.intermediate.dense.bias', 'encoder.layer.0.attention.self.value.weight', 'encoder.layer.16.attention.self.query.bias', 'encoder.layer.12.output.LayerNorm.bias', 'encoder.layer.13.attention.self.query.weight', 'encoder.layer.19.attention.output.LayerNorm.weight', 'encoder.layer.16.output.LayerNorm.weight', 'encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.layer.4.attention.output.LayerNorm.bias', 'encoder.layer.7.attention.output.LayerNorm.bias', 'encoder.layer.18.attention.self.query.bias', 'encoder.layer.0.attention.self.query.weight', 'encoder.layer.16.attention.self.key.bias', 'encoder.layer.2.attention.self.query.bias', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.13.attention.self.value.weight', 'encoder.layer.11.output.LayerNorm.bias', 'encoder.layer.10.attention.output.dense.bias', 'encoder.layer.17.output.LayerNorm.weight', 'encoder.layer.13.output.dense.weight', 'encoder.layer.7.output.LayerNorm.weight', 'encoder.layer.18.attention.self.query.weight', 'encoder.layer.20.attention.output.LayerNorm.bias', 'encoder.layer.4.attention.self.value.bias', 'encoder.layer.14.attention.self.key.bias', 'encoder.layer.10.output.LayerNorm.bias', 'encoder.layer.2.output.dense.bias', 'encoder.layer.11.attention.self.value.bias', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.7.attention.self.key.weight', 'encoder.layer.22.attention.self.value.weight', 'encoder.layer.22.output.dense.bias', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.16.attention.self.key.weight', 'encoder.layer.10.attention.self.query.weight', 'encoder.layer.14.intermediate.dense.weight', 'encoder.layer.20.attention.self.key.bias', 'encoder.layer.2.output.dense.weight', 'encoder.layer.21.attention.output.dense.bias', 'encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.layer.1.attention.self.key.weight', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.5.output.LayerNorm.bias', 'encoder.layer.12.output.LayerNorm.weight', 'encoder.layer.10.attention.self.key.bias', 'encoder.layer.22.attention.self.key.bias', 'encoder.layer.11.attention.self.key.bias', 'encoder.layer.6.output.dense.weight', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.7.attention.output.LayerNorm.weight', 'encoder.layer.6.attention.self.value.bias', 'encoder.layer.11.attention.self.key.weight', 'encoder.layer.15.attention.self.query.bias', 'encoder.layer.23.intermediate.dense.weight', 'encoder.layer.22.attention.output.LayerNorm.weight', 'encoder.layer.13.intermediate.dense.bias', 'encoder.layer.20.attention.self.value.weight', 'encoder.layer.21.output.LayerNorm.weight', 'encoder.layer.4.output.dense.weight', 'encoder.layer.5.attention.self.query.weight', 'encoder.layer.3.attention.self.query.weight', 'encoder.layer.3.attention.self.value.weight', 'encoder.layer.16.attention.output.LayerNorm.weight', 'encoder.layer.15.attention.self.key.bias', 'encoder.layer.21.attention.self.value.bias', 'encoder.layer.5.attention.output.LayerNorm.weight', 'encoder.layer.22.intermediate.dense.weight', 'encoder.layer.10.output.LayerNorm.weight', 'encoder.layer.16.attention.output.dense.bias', 'encoder.layer.7.attention.output.dense.bias', 'encoder.layer.12.attention.output.dense.bias', 'encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.9.attention.self.query.weight', 'encoder.layer.8.attention.output.LayerNorm.bias', 'encoder.layer.2.attention.self.key.bias', 'encoder.layer.5.attention.self.query.bias', 'encoder.layer.12.attention.self.value.weight', 'encoder.layer.0.attention.self.value.bias', 'encoder.layer.18.attention.output.dense.bias', 'encoder.layer.8.attention.output.LayerNorm.weight', 'encoder.layer.6.attention.self.key.weight', 'encoder.layer.17.attention.output.dense.weight', 'encoder.layer.2.attention.self.value.bias', 'encoder.layer.5.attention.output.dense.weight', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.6.attention.self.key.bias', 'encoder.layer.7.attention.output.dense.weight', 'encoder.layer.12.intermediate.dense.weight', 'encoder.layer.9.attention.output.dense.weight', 'encoder.layer.20.intermediate.dense.bias', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.8.output.LayerNorm.bias', 'encoder.layer.14.attention.self.value.weight', 'encoder.layer.0.output.dense.weight', 'encoder.layer.20.output.dense.bias', 'encoder.layer.11.attention.output.dense.weight', 'encoder.layer.4.attention.self.query.weight', 'encoder.layer.15.attention.output.LayerNorm.bias', 'encoder.layer.15.output.dense.weight', 'encoder.layer.15.intermediate.dense.bias', 'encoder.layer.21.attention.output.LayerNorm.weight', 'encoder.layer.20.attention.self.key.weight', 'encoder.layer.20.attention.output.dense.weight', 'encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.layer.13.attention.self.query.bias', 'encoder.layer.16.attention.output.LayerNorm.bias', 'encoder.layer.8.output.dense.bias', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.6.output.LayerNorm.bias', 'encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.layer.10.output.dense.weight', 'encoder.layer.18.intermediate.dense.bias', 'encoder.layer.15.output.LayerNorm.weight', 'encoder.layer.1.output.dense.bias', 'encoder.layer.4.attention.output.dense.bias', 'embeddings.word_embeddings.weight', 'encoder.layer.1.attention.output.LayerNorm.weight', 'encoder.layer.17.output.LayerNorm.bias', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.1.attention.self.key.bias', 'encoder.layer.15.attention.self.key.weight', 'encoder.layer.8.attention.output.dense.weight', 'encoder.layer.19.intermediate.dense.bias', 'encoder.layer.9.output.dense.weight', 'encoder.layer.16.attention.output.dense.weight', 'encoder.layer.9.output.dense.bias', 'pooler.dense.weight', 'encoder.layer.21.attention.self.key.weight', 'encoder.layer.21.attention.self.query.bias', 'encoder.layer.15.attention.output.LayerNorm.weight', 'encoder.layer.23.attention.output.LayerNorm.weight', 'encoder.layer.8.output.dense.weight', 'encoder.layer.17.attention.self.key.bias', 'encoder.layer.5.attention.self.key.weight', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.0.output.dense.bias', 'encoder.layer.12.attention.output.LayerNorm.bias', 'encoder.layer.8.attention.self.query.bias', 'encoder.layer.9.output.LayerNorm.bias', 'encoder.layer.21.attention.self.key.bias', 'encoder.layer.22.attention.self.key.weight', 'encoder.layer.0.attention.self.query.bias', 'encoder.layer.5.attention.output.dense.bias', 'encoder.layer.3.attention.self.key.weight', 'encoder.layer.11.output.LayerNorm.weight', 'encoder.layer.16.output.dense.weight', 'encoder.layer.18.attention.output.dense.weight', 'encoder.layer.12.output.dense.weight', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.3.output.dense.bias', 'encoder.layer.1.attention.self.query.bias', 'encoder.layer.20.intermediate.dense.weight', 'encoder.layer.6.attention.output.dense.bias', 'encoder.layer.13.output.LayerNorm.bias', 'encoder.layer.8.output.LayerNorm.weight', 'encoder.layer.17.output.dense.weight', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.16.output.dense.bias', 'encoder.layer.7.output.LayerNorm.bias', 'encoder.layer.9.attention.self.value.bias', 'encoder.layer.21.attention.self.value.weight', 'encoder.layer.18.output.LayerNorm.bias', 'encoder.layer.10.output.dense.bias', 'encoder.layer.11.output.dense.bias', 'encoder.layer.17.attention.self.key.weight', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.13.attention.output.dense.bias', 'encoder.layer.2.attention.self.value.weight', 'encoder.layer.2.attention.output.LayerNorm.bias', 'encoder.layer.9.attention.output.LayerNorm.weight', 'encoder.layer.15.attention.self.query.weight', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.19.intermediate.dense.weight', 'encoder.layer.0.attention.output.LayerNorm.weight', 'encoder.layer.4.attention.self.query.bias', 'encoder.layer.23.output.LayerNorm.bias', 'encoder.layer.10.attention.output.LayerNorm.bias', 'encoder.layer.11.attention.output.LayerNorm.weight', 'encoder.layer.21.output.LayerNorm.bias', 'encoder.layer.6.attention.output.LayerNorm.weight', 'encoder.layer.4.attention.self.key.weight', 'encoder.layer.3.attention.self.value.bias', 'encoder.layer.23.attention.self.value.bias', 'encoder.layer.20.attention.self.query.bias', 'encoder.layer.0.attention.self.key.bias', 'encoder.layer.9.attention.output.LayerNorm.bias', 'encoder.layer.22.output.dense.weight', 'encoder.layer.23.attention.output.LayerNorm.bias', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.10.attention.self.query.bias', 'encoder.layer.22.attention.output.LayerNorm.bias', 'encoder.layer.19.output.dense.weight', 'encoder.layer.14.attention.self.key.weight', 'encoder.layer.4.output.dense.bias', 'encoder.layer.6.attention.self.value.weight', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.13.attention.self.value.bias', 'encoder.layer.6.attention.self.query.bias', 'encoder.layer.1.attention.self.value.weight', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.15.output.dense.bias', 'encoder.layer.3.attention.output.dense.weight', 'encoder.layer.1.attention.output.dense.weight', 'encoder.layer.16.intermediate.dense.bias', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.18.output.LayerNorm.weight', 'encoder.layer.0.output.LayerNorm.bias', 'embeddings.LayerNorm.bias', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.7.attention.self.key.bias', 'encoder.layer.12.attention.output.dense.weight', 'encoder.layer.16.output.LayerNorm.bias', 'encoder.layer.6.attention.self.query.weight', 'encoder.layer.17.output.dense.bias', 'encoder.layer.21.output.dense.bias', 'encoder.layer.19.output.dense.bias', 'encoder.layer.19.output.LayerNorm.weight', 'encoder.layer.3.attention.self.key.bias', 'encoder.layer.14.output.dense.weight', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.10.attention.self.value.bias', 'encoder.layer.15.attention.output.dense.weight', 'encoder.layer.4.attention.output.LayerNorm.weight', 'encoder.layer.12.attention.self.value.bias', 'encoder.layer.8.attention.self.value.bias', 'encoder.layer.23.attention.self.value.weight', 'encoder.layer.5.output.dense.weight', 'encoder.layer.0.attention.self.key.weight', 'encoder.layer.14.attention.self.query.weight', 'encoder.layer.2.attention.output.LayerNorm.weight', 'encoder.layer.14.attention.output.LayerNorm.bias', 'embeddings.LayerNorm.weight', 'encoder.layer.10.attention.output.LayerNorm.weight', 'encoder.layer.20.attention.output.LayerNorm.weight', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.14.attention.self.query.bias', 'encoder.layer.17.attention.output.LayerNorm.bias', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.4.attention.self.value.weight', 'encoder.layer.11.attention.self.query.bias', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.18.attention.self.value.weight', 'encoder.layer.17.attention.self.value.weight', 'encoder.layer.7.output.dense.weight', 'encoder.layer.17.attention.output.dense.bias', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.13.output.LayerNorm.weight', 'encoder.layer.6.output.dense.bias', 'encoder.layer.15.attention.self.value.bias', 'encoder.layer.12.attention.self.query.bias', 'encoder.layer.14.intermediate.dense.bias', 'encoder.layer.13.intermediate.dense.weight', 'encoder.layer.10.intermediate.dense.weight', 'encoder.layer.21.output.dense.weight', 'encoder.layer.1.attention.output.dense.bias', 'encoder.layer.2.attention.self.key.weight', 'encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.layer.11.attention.self.query.weight', 'encoder.layer.23.intermediate.dense.bias', 'encoder.layer.2.attention.self.query.weight', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.1.attention.self.value.bias', 'encoder.layer.1.attention.self.query.weight', 'encoder.layer.20.attention.self.value.bias', 'encoder.layer.18.output.dense.bias', 'embeddings.position_embeddings.weight', 'encoder.layer.19.attention.output.dense.weight', 'encoder.layer.5.output.dense.bias', 'encoder.layer.18.intermediate.dense.weight', 'encoder.layer.8.attention.self.key.weight', 'encoder.layer.4.attention.output.dense.weight', 'encoder.layer.9.output.LayerNorm.weight', 'encoder.layer.7.attention.self.value.weight', 'encoder.layer.18.attention.self.key.weight', 'encoder.layer.22.intermediate.dense.bias', 'encoder.layer.13.output.dense.bias', 'encoder.layer.21.intermediate.dense.weight', 'encoder.layer.12.attention.output.LayerNorm.weight', 'encoder.layer.0.attention.output.dense.weight', 'encoder.layer.17.attention.output.LayerNorm.weight', 'encoder.layer.12.attention.self.key.weight', 'encoder.layer.18.attention.self.value.bias', 'encoder.layer.22.attention.output.dense.weight', 'encoder.layer.18.attention.output.LayerNorm.bias', 'encoder.layer.1.output.dense.weight', 'encoder.layer.19.attention.self.value.bias', 'encoder.layer.7.attention.self.query.bias', 'encoder.layer.20.attention.self.query.weight', 'encoder.layer.15.attention.output.dense.bias', 'encoder.layer.23.attention.self.key.weight', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.12.output.dense.bias', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.8.attention.self.key.bias', 'encoder.layer.22.attention.self.query.bias', 'encoder.layer.14.attention.output.LayerNorm.weight', 'encoder.layer.14.attention.output.dense.bias', 'encoder.layer.20.output.dense.weight', 'encoder.layer.16.attention.self.value.weight', 'encoder.layer.9.attention.self.key.weight', 'encoder.layer.11.output.dense.weight', 'encoder.layer.10.attention.self.value.weight', 'encoder.layer.12.intermediate.dense.bias', 'encoder.layer.9.attention.self.value.weight', 'encoder.layer.8.attention.self.value.weight', 'encoder.layer.13.attention.output.LayerNorm.bias', 'encoder.layer.13.attention.output.dense.weight', 'encoder.layer.23.attention.output.dense.bias', 'encoder.layer.14.attention.output.dense.weight', 'encoder.layer.7.intermediate.dense.bias', 'encoder.layer.19.attention.self.value.weight', 'encoder.layer.21.intermediate.dense.bias', 'encoder.layer.7.attention.self.query.weight', 'encoder.layer.14.output.dense.bias', 'pooler.dense.bias', 'encoder.layer.10.attention.self.key.weight', 'encoder.layer.17.attention.self.query.weight', 'encoder.layer.21.attention.output.LayerNorm.bias', 'encoder.layer.22.output.LayerNorm.weight', 'encoder.layer.5.attention.self.value.weight', 'encoder.layer.9.attention.self.query.bias', 'encoder.layer.12.attention.self.key.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Overwriting existing adapter 'ep'.
Overwriting existing adapter 'tp'.
Overwriting existing adapter 'es'.
Overwriting existing adapter 'ts'.
Overwriting existing adapter fusion module 'ep,tp,es,ts'
05/09/2022 21:38:26 - INFO - __main__ -   lang2id = None
05/09/2022 21:38:30 - INFO - __main__ -   Training/evaluation parameters Namespace(adam_epsilon=1e-08, cache_dir='', config_name='', data_dir=None, device=device(type='cuda'), do_eval=True, do_lower_case=False, do_train=False, doc_stride=128, eval_all_checkpoints=False, eval_lang='es', evaluate_during_training=False, fp16=False, fp16_opt_level='O1', gradient_accumulation_steps=1, learning_rate=5e-05, local_rank=-1, logging_steps=50, max_answer_length=30, max_grad_norm=1.0, max_query_length=64, max_seq_length=384, max_steps=-1, model_name='xlm-KG', model_name_or_path='/cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//squad/xlm-KG_LR8e-6_EPOCH2.0_maxlen384_batchsize4_gradacc4', model_type='xlm', modelkg_dir='/cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/adapter/xlmr_adapter', n_best_size=20, n_gpu=1, no_cuda=False, null_score_diff_threshold=0.0, num_train_epochs=3.0, output_dir='/cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//squad/xlm-KG_LR8e-6_EPOCH2.0_maxlen384_batchsize4_gradacc4/predictions/mlqa/', overwrite_cache=False, overwrite_output_dir=False, per_gpu_eval_batch_size=8, per_gpu_train_batch_size=8, predict_file='/cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/download//mlqa//MLQA_V1/test/test-context-es-question-es.json', save_steps=50, seed=42, server_ip='', server_port='', threads=1, tokenizer_name='', train_file=None, train_lang='en', verbose_logging=False, version_2_with_negative=False, warmup_steps=0, weight_decay=0.0)
05/09/2022 21:38:30 - INFO - __main__ -   Loading checkpoint /cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//squad/xlm-KG_LR8e-6_EPOCH2.0_maxlen384_batchsize4_gradacc4 for evaluation
05/09/2022 21:38:30 - INFO - __main__ -   Evaluate the following checkpoints: ['/cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//squad/xlm-KG_LR8e-6_EPOCH2.0_maxlen384_batchsize4_gradacc4']
Some weights of the model checkpoint at /cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//squad/xlm-KG_LR8e-6_EPOCH2.0_maxlen384_batchsize4_gradacc4 were not used when initializing XLMRobertaModel: ['base_model.encoder.layer.8.output.dense.weight', 'base_model.encoder.layer.1.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.5.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.3.attention.output.dense.weight', 'base_model.encoder.layer.22.attention.self.query.weight', 'base_model.encoder.layer.0.attention.output.LayerNorm.bias', 'base_model.encoder.layer.18.output.LayerNorm.bias', 'base_model.encoder.layer.3.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.9.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.0.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.14.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.20.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.9.attention.self.value.weight', 'base_model.encoder.layer.18.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.15.attention.self.value.weight', 'base_model.encoder.layer.7.attention.self.query.weight', 'base_model.encoder.layer.17.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.4.attention.self.query.bias', 'base_model.encoder.layer.4.attention.self.key.bias', 'base_model.encoder.layer.10.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.13.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.10.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.11.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.14.attention.output.dense.weight', 'base_model.encoder.layer.18.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.23.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.22.output.LayerNorm.weight', 'base_model.encoder.layer.8.attention.output.LayerNorm.weight', 'base_model.encoder.layer.2.attention.self.key.bias', 'base_model.encoder.layer.22.attention.output.dense.bias', 'base_model.encoder.layer.8.attention.self.value.bias', 'base_model.encoder.layer.10.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.23.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.23.attention.self.value.weight', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.5.intermediate.dense.bias', 'base_model.encoder.layer.9.attention.self.key.bias', 'base_model.encoder.layer.4.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.11.attention.self.value.weight', 'base_model.encoder.layer.13.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.8.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.15.attention.self.key.weight', 'base_model.encoder.layer.1.attention.self.key.weight', 'base_model.encoder.layer.16.output.LayerNorm.bias', 'base_model.encoder.layer.23.attention.self.value.bias', 'base_model.encoder.layer.12.output.LayerNorm.bias', 'base_model.encoder.layer.20.attention.output.LayerNorm.weight', 'base_model.encoder.layer.23.intermediate.dense.bias', 'base_model.encoder.layer.12.output.dense.bias', 'base_model.encoder.layer.23.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.21.attention.output.dense.weight', 'base_model.encoder.layer.10.attention.self.key.bias', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.21.output.dense.bias', 'base_model.encoder.layer.18.attention.self.query.bias', 'base_model.encoder.layer.5.attention.self.key.bias', 'base_model.encoder.layer.14.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.5.output.dense.weight', 'base_model.encoder.layer.17.attention.self.value.bias', 'base_model.encoder.layer.22.attention.self.value.weight', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.23.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.16.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.15.intermediate.dense.weight', 'base_model.encoder.layer.0.attention.output.dense.weight', 'base_model.encoder.layer.16.attention.output.dense.bias', 'base_model.encoder.layer.1.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.5.output.LayerNorm.bias', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.2.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.9.output.dense.bias', 'base_model.encoder.layer.10.attention.output.dense.weight', 'base_model.encoder.layer.1.attention.self.key.bias', 'base_model.encoder.layer.14.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.10.intermediate.dense.weight', 'base_model.encoder.layer.0.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.1.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.19.intermediate.dense.weight', 'base_model.encoder.layer.11.intermediate.dense.weight', 'base_model.encoder.layer.4.attention.self.key.weight', 'base_model.encoder.layer.7.output.dense.bias', 'base_model.encoder.layer.16.output.dense.bias', 'base_model.encoder.layer.11.attention.output.LayerNorm.bias', 'base_model.encoder.layer.4.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.9.attention.output.LayerNorm.bias', 'base_model.encoder.layer.11.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.13.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.14.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.0.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.1.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'qa_outputs.bias', 'base_model.encoder.layer.3.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.0.output.LayerNorm.bias', 'base_model.encoder.layer.10.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.4.attention.output.LayerNorm.bias', 'base_model.encoder.layer.0.attention.self.value.weight', 'base_model.encoder.layer.1.attention.output.dense.bias', 'base_model.encoder.layer.2.attention.output.LayerNorm.weight', 'base_model.encoder.layer.7.attention.self.key.weight', 'base_model.encoder.layer.10.output.dense.bias', 'base_model.encoder.layer.10.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.7.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.20.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.2.output.adapters.ts.adapter_down.0.bias', 'qa_outputs.weight', 'base_model.encoder.layer.19.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.16.attention.output.LayerNorm.bias', 'base_model.encoder.layer.6.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.9.attention.self.query.weight', 'base_model.encoder.layer.18.output.dense.bias', 'base_model.encoder.layer.10.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.13.attention.output.LayerNorm.weight', 'base_model.encoder.layer.12.attention.self.query.weight', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.14.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.7.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.16.attention.self.value.bias', 'base_model.encoder.layer.11.attention.self.query.bias', 'base_model.encoder.layer.8.intermediate.dense.weight', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.22.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.9.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.23.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.18.attention.self.value.bias', 'base_model.encoder.layer.11.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.21.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.4.output.dense.weight', 'base_model.encoder.layer.8.output.dense.bias', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.3.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.6.attention.self.value.bias', 'base_model.encoder.layer.19.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.17.attention.self.key.bias', 'base_model.encoder.layer.2.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.15.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.3.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.19.attention.self.value.bias', 'base_model.encoder.layer.7.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.2.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.10.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.9.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.22.output.dense.weight', 'base_model.encoder.layer.10.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.17.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.1.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.13.intermediate.dense.weight', 'base_model.encoder.layer.0.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.10.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.18.output.adapters.tp.adapter_down.0.bias', 'base_model.pooler.dense.weight', 'base_model.encoder.layer.15.intermediate.dense.bias', 'base_model.encoder.layer.13.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.6.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.4.intermediate.dense.bias', 'base_model.encoder.layer.6.attention.self.key.weight', 'base_model.encoder.layer.8.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.9.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.19.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.14.attention.self.value.bias', 'base_model.encoder.layer.17.attention.output.LayerNorm.bias', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.4.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.10.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.20.output.LayerNorm.weight', 'base_model.encoder.layer.19.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.6.attention.self.query.bias', 'base_model.encoder.layer.23.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.6.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.18.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.7.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.5.attention.output.LayerNorm.bias', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.20.attention.output.dense.weight', 'base_model.encoder.layer.9.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.7.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.18.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.4.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.0.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.12.attention.self.value.weight', 'base_model.encoder.layer.0.intermediate.dense.weight', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.5.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.4.attention.output.LayerNorm.weight', 'base_model.encoder.layer.23.attention.self.query.bias', 'base_model.encoder.layer.4.attention.self.value.bias', 'base_model.encoder.layer.14.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.21.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.3.attention.self.value.weight', 'base_model.encoder.layer.22.output.dense.bias', 'base_model.encoder.layer.20.attention.self.query.weight', 'base_model.encoder.layer.1.output.LayerNorm.bias', 'base_model.encoder.layer.21.attention.output.dense.bias', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.5.output.dense.bias', 'base_model.encoder.layer.10.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.12.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.2.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.19.attention.output.dense.weight', 'base_model.encoder.layer.12.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.11.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.11.attention.output.dense.bias', 'base_model.encoder.layer.11.attention.output.dense.weight', 'base_model.encoder.layer.6.attention.self.key.bias', 'base_model.encoder.layer.7.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.6.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.5.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.12.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.16.attention.self.key.bias', 'base_model.encoder.layer.22.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.3.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.8.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.1.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.10.intermediate.dense.bias', 'base_model.encoder.layer.20.attention.output.LayerNorm.bias', 'base_model.encoder.layer.17.attention.self.query.bias', 'base_model.encoder.layer.15.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.22.attention.output.dense.weight', 'base_model.encoder.layer.20.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.16.attention.output.LayerNorm.weight', 'base_model.encoder.layer.17.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.15.attention.output.LayerNorm.weight', 'base_model.encoder.layer.22.intermediate.dense.bias', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.13.output.LayerNorm.bias', 'base_model.encoder.layer.17.attention.self.key.weight', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.12.output.dense.weight', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.12.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.21.output.adapters.es.adapter_down.0.weight', 'base_model.embeddings.word_embeddings.weight', 'base_model.encoder.layer.1.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.16.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.20.attention.self.key.bias', 'base_model.encoder.layer.13.intermediate.dense.bias', 'base_model.encoder.layer.2.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.3.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.7.output.dense.weight', 'base_model.encoder.layer.4.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.10.attention.self.query.bias', 'base_model.encoder.layer.3.output.dense.bias', 'base_model.encoder.layer.2.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.7.attention.output.LayerNorm.weight', 'base_model.encoder.layer.8.intermediate.dense.bias', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.11.output.dense.bias', 'base_model.encoder.layer.4.output.LayerNorm.weight', 'base_model.encoder.layer.9.attention.output.dense.bias', 'base_model.encoder.layer.17.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.14.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.7.attention.output.dense.weight', 'base_model.encoder.layer.17.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.21.output.dense.weight', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.22.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.12.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.7.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.8.attention.self.query.weight', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.21.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.1.attention.self.query.weight', 'base_model.encoder.layer.8.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.10.output.LayerNorm.weight', 'base_model.encoder.layer.6.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.2.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.15.attention.output.LayerNorm.bias', 'base_model.encoder.layer.15.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.18.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.18.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.7.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.8.attention.self.query.bias', 'base_model.encoder.layer.18.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.0.attention.output.dense.bias', 'base_model.encoder.layer.18.intermediate.dense.weight', 'base_model.encoder.layer.6.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.19.output.LayerNorm.bias', 'base_model.encoder.layer.21.output.LayerNorm.weight', 'base_model.encoder.layer.14.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.16.output.dense.weight', 'base_model.encoder.layer.11.attention.self.key.bias', 'base_model.encoder.layer.14.attention.self.key.weight', 'base_model.encoder.layer.14.output.dense.weight', 'base_model.encoder.layer.20.output.LayerNorm.bias', 'base_model.encoder.layer.16.attention.self.key.weight', 'base_model.encoder.layer.15.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.10.output.dense.weight', 'base_model.encoder.layer.13.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.6.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.13.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.11.output.dense.weight', 'base_model.encoder.layer.16.intermediate.dense.bias', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.22.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.10.attention.self.key.weight', 'base_model.encoder.layer.17.intermediate.dense.bias', 'base_model.encoder.layer.20.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.21.output.LayerNorm.bias', 'base_model.encoder.layer.23.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.19.intermediate.dense.bias', 'base_model.encoder.layer.0.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.11.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.12.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.19.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.16.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.21.attention.self.value.weight', 'base_model.encoder.layer.9.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.19.attention.self.query.weight', 'base_model.encoder.layer.6.attention.self.query.weight', 'base_model.encoder.layer.21.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.6.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.0.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.19.attention.self.key.weight', 'base_model.encoder.layer.22.attention.output.LayerNorm.bias', 'base_model.encoder.layer.15.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.12.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.13.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.2.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.21.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.12.intermediate.dense.weight', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.2.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.12.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.16.attention.self.query.bias', 'base_model.encoder.layer.9.attention.self.key.weight', 'base_model.encoder.layer.20.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.18.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.16.output.LayerNorm.weight', 'base_model.encoder.layer.3.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.14.output.LayerNorm.weight', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.13.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.14.attention.output.LayerNorm.bias', 'base_model.encoder.layer.23.output.dense.bias', 'base_model.encoder.layer.23.intermediate.dense.weight', 'base_model.encoder.layer.15.output.dense.bias', 'base_model.encoder.layer.12.attention.output.LayerNorm.weight', 'base_model.encoder.layer.9.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.1.output.dense.bias', 'base_model.encoder.layer.6.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.12.attention.self.value.bias', 'base_model.encoder.layer.23.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.17.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.8.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.8.attention.output.LayerNorm.bias', 'base_model.encoder.layer.8.attention.output.dense.bias', 'base_model.encoder.layer.19.attention.self.key.bias', 'base_model.encoder.layer.19.attention.self.query.bias', 'base_model.pooler.dense.bias', 'base_model.embeddings.token_type_embeddings.weight', 'base_model.encoder.layer.16.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.15.attention.output.dense.weight', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.12.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.20.output.dense.weight', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.0.attention.output.LayerNorm.weight', 'base_model.encoder.layer.12.attention.output.dense.weight', 'base_model.encoder.layer.14.attention.self.value.weight', 'base_model.encoder.layer.2.intermediate.dense.bias', 'base_model.encoder.layer.14.attention.output.dense.bias', 'base_model.encoder.layer.4.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.11.output.LayerNorm.bias', 'base_model.encoder.layer.10.attention.output.LayerNorm.weight', 'base_model.encoder.layer.2.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.15.attention.self.key.bias', 'base_model.encoder.layer.11.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.22.attention.self.key.bias', 'base_model.encoder.layer.4.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.5.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.4.attention.self.query.weight', 'base_model.encoder.layer.12.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.4.intermediate.dense.weight', 'base_model.encoder.layer.0.output.LayerNorm.weight', 'base_model.encoder.layer.14.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.2.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.15.attention.self.value.bias', 'base_model.encoder.layer.17.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.2.intermediate.dense.weight', 'base_model.encoder.layer.9.attention.self.value.bias', 'base_model.encoder.layer.11.attention.self.query.weight', 'base_model.encoder.layer.4.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.15.attention.output.dense.bias', 'base_model.encoder.layer.15.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.17.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.21.attention.self.query.bias', 'base_model.encoder.layer.7.attention.output.dense.bias', 'base_model.encoder.layer.19.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.13.output.dense.bias', 'base_model.encoder.layer.13.output.LayerNorm.weight', 'base_model.encoder.layer.23.attention.output.LayerNorm.bias', 'base_model.encoder.layer.20.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.13.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.17.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.embeddings.position_ids', 'base_model.encoder.layer.5.intermediate.dense.weight', 'base_model.encoder.layer.12.attention.output.LayerNorm.bias', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.12.attention.self.key.weight', 'base_model.encoder.layer.16.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.15.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.13.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.15.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.1.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.2.attention.self.query.weight', 'base_model.encoder.layer.5.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.2.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.14.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.7.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.19.output.dense.bias', 'base_model.encoder.layer.8.output.LayerNorm.bias', 'base_model.encoder.layer.1.intermediate.dense.bias', 'base_model.encoder.layer.13.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.4.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.11.attention.self.key.weight', 'base_model.encoder.layer.2.attention.self.value.weight', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.22.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.8.attention.self.key.weight', 'base_model.encoder.layer.21.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.21.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.2.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.14.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.15.output.LayerNorm.bias', 'base_model.encoder.layer.10.attention.self.query.weight', 'base_model.encoder.layer.19.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.20.attention.self.value.bias', 'base_model.encoder.layer.1.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.15.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.19.attention.output.LayerNorm.weight', 'base_model.encoder.layer.22.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.2.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.22.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.3.attention.output.LayerNorm.weight', 'base_model.embeddings.position_embeddings.weight', 'base_model.encoder.layer.14.attention.self.key.bias', 'base_model.encoder.layer.13.attention.self.value.bias', 'base_model.encoder.layer.17.output.dense.weight', 'base_model.encoder.layer.3.intermediate.dense.weight', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.1.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.13.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.2.attention.output.LayerNorm.bias', 'base_model.encoder.layer.6.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.1.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.7.intermediate.dense.bias', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.22.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.10.attention.self.value.weight', 'base_model.encoder.layer.9.output.dense.weight', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.23.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.8.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.7.output.LayerNorm.weight', 'base_model.encoder.layer.0.attention.self.key.bias', 'base_model.encoder.layer.11.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.4.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.4.output.dense.bias', 'base_model.encoder.layer.11.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.2.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.9.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.7.attention.self.value.bias', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.9.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.3.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.5.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.20.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.21.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.20.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.8.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.19.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.20.attention.output.dense.bias', 'base_model.encoder.layer.17.attention.self.query.weight', 'base_model.encoder.layer.7.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.6.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.18.attention.self.key.bias', 'base_model.encoder.layer.1.attention.self.query.bias', 'base_model.encoder.layer.18.attention.output.dense.weight', 'base_model.encoder.layer.18.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.23.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.7.attention.self.value.weight', 'base_model.encoder.layer.20.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.14.attention.self.query.bias', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.11.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.15.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.5.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.0.attention.self.value.bias', 'base_model.encoder.layer.2.attention.self.value.bias', 'base_model.encoder.layer.16.attention.self.value.weight', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.6.attention.self.value.weight', 'base_model.encoder.layer.8.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.7.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.8.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.22.attention.self.value.bias', 'base_model.encoder.layer.21.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.20.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.22.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.0.attention.self.query.weight', 'base_model.encoder.layer.16.attention.output.dense.weight', 'base_model.encoder.layer.5.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.16.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.6.intermediate.dense.weight', 'base_model.encoder.layer.19.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.21.attention.self.key.weight', 'base_model.encoder.layer.0.output.dense.bias', 'base_model.encoder.layer.23.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.18.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.8.output.LayerNorm.weight', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.8.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.14.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.16.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.23.attention.output.LayerNorm.weight', 'base_model.encoder.layer.20.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.1.attention.output.dense.weight', 'base_model.encoder.layer.10.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.18.attention.self.key.weight', 'base_model.encoder.layer.0.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.8.attention.self.key.bias', 'base_model.encoder.layer.17.attention.output.LayerNorm.weight', 'base_model.encoder.layer.22.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.23.attention.output.dense.weight', 'base_model.encoder.layer.4.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.1.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.12.output.LayerNorm.weight', 'base_model.encoder.layer.20.intermediate.dense.weight', 'base_model.encoder.layer.5.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.1.attention.self.value.weight', 'base_model.encoder.layer.12.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.6.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.13.attention.self.key.bias', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.14.output.LayerNorm.bias', 'base_model.encoder.layer.9.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.8.attention.output.dense.weight', 'base_model.encoder.layer.11.attention.output.LayerNorm.weight', 'base_model.encoder.layer.4.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.12.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.19.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.0.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.1.attention.output.LayerNorm.weight', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.11.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.5.attention.self.value.bias', 'base_model.encoder.layer.13.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.21.attention.self.key.bias', 'base_model.encoder.layer.17.attention.self.value.weight', 'base_model.encoder.layer.0.intermediate.dense.bias', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.5.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.8.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.21.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.0.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.12.attention.self.key.bias', 'base_model.encoder.layer.0.attention.self.key.weight', 'base_model.encoder.layer.3.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.18.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.23.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.8.attention.self.value.weight', 'base_model.encoder.layer.6.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.9.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.16.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.5.output.LayerNorm.weight', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.4.attention.output.dense.weight', 'base_model.encoder.layer.6.output.LayerNorm.weight', 'base_model.encoder.layer.21.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.12.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.22.intermediate.dense.weight', 'base_model.encoder.layer.11.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.10.output.LayerNorm.bias', 'base_model.encoder.layer.16.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.12.attention.output.dense.bias', 'base_model.encoder.layer.21.attention.self.value.bias', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.5.attention.self.query.weight', 'base_model.encoder.layer.8.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.9.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.17.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.1.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.11.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.11.output.LayerNorm.weight', 'base_model.encoder.layer.11.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.20.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.5.attention.self.query.bias', 'base_model.encoder.layer.7.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.13.attention.self.key.weight', 'base_model.encoder.layer.17.output.dense.bias', 'base_model.encoder.layer.21.attention.output.LayerNorm.bias', 'base_model.encoder.layer.12.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.13.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.0.output.dense.weight', 'base_model.encoder.layer.3.output.LayerNorm.bias', 'base_model.encoder.layer.6.attention.output.LayerNorm.bias', 'base_model.encoder.layer.2.attention.self.query.bias', 'base_model.encoder.layer.18.attention.self.query.weight', 'base_model.encoder.layer.22.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.6.output.LayerNorm.bias', 'base_model.encoder.layer.7.attention.self.key.bias', 'base_model.encoder.layer.11.attention.self.value.bias', 'base_model.encoder.layer.6.output.dense.bias', 'base_model.encoder.layer.10.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.0.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.16.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.14.output.dense.bias', 'base_model.encoder.layer.5.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.19.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.11.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.2.attention.self.key.weight', 'base_model.encoder.layer.23.output.LayerNorm.weight', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.18.attention.output.dense.bias', 'base_model.encoder.layer.21.output.adapters.ts.adapter_up.weight', 'base_model.embeddings.LayerNorm.weight', 'base_model.encoder.layer.22.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.6.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.14.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.18.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.18.attention.output.LayerNorm.weight', 'base_model.encoder.layer.3.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.15.output.dense.weight', 'base_model.encoder.layer.2.output.LayerNorm.weight', 'base_model.encoder.layer.9.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.4.attention.self.value.weight', 'base_model.encoder.layer.23.output.LayerNorm.bias', 'base_model.encoder.layer.11.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.7.attention.self.query.bias', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.5.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.7.output.LayerNorm.bias', 'base_model.encoder.layer.13.output.dense.weight', 'base_model.encoder.layer.9.attention.self.query.bias', 'base_model.encoder.layer.10.attention.output.LayerNorm.bias', 'base_model.encoder.layer.20.output.dense.bias', 'base_model.encoder.layer.21.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.18.output.LayerNorm.weight', 'base_model.encoder.layer.6.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.16.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.9.output.LayerNorm.bias', 'base_model.encoder.layer.14.intermediate.dense.bias', 'base_model.encoder.layer.5.attention.output.dense.bias', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.9.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.3.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.10.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.3.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.16.attention.self.query.weight', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.12.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.12.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.9.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.13.attention.output.dense.weight', 'base_model.encoder.layer.20.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.0.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.1.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.3.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.7.intermediate.dense.weight', 'base_model.encoder.layer.1.intermediate.dense.weight', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.7.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.15.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.16.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.13.attention.self.query.weight', 'base_model.encoder.layer.5.attention.self.key.weight', 'base_model.encoder.layer.3.attention.output.LayerNorm.bias', 'base_model.encoder.layer.5.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.0.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.17.attention.output.dense.bias', 'base_model.encoder.layer.23.attention.self.query.weight', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.18.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.4.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.15.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.2.attention.output.dense.bias', 'base_model.encoder.layer.22.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.22.attention.self.query.bias', 'base_model.encoder.layer.3.attention.self.query.weight', 'base_model.encoder.layer.15.output.LayerNorm.weight', 'base_model.encoder.layer.1.output.dense.weight', 'base_model.encoder.layer.2.attention.output.dense.weight', 'base_model.encoder.layer.3.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.17.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.15.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.13.attention.output.dense.bias', 'base_model.encoder.layer.10.attention.output.dense.bias', 'base_model.encoder.layer.19.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.23.output.dense.weight', 'base_model.encoder.layer.16.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.23.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.3.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.20.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.23.attention.self.key.bias', 'base_model.encoder.layer.18.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.23.attention.self.key.weight', 'base_model.encoder.layer.2.output.dense.bias', 'base_model.encoder.layer.6.output.dense.weight', 'base_model.encoder.layer.0.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.6.attention.output.LayerNorm.weight', 'base_model.encoder.layer.21.intermediate.dense.weight', 'base_model.encoder.layer.5.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.10.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.17.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.19.output.LayerNorm.weight', 'base_model.encoder.layer.19.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.19.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.17.intermediate.dense.weight', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.0.attention.self.query.bias', 'base_model.encoder.layer.8.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.18.intermediate.dense.bias', 'base_model.encoder.layer.5.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.14.attention.self.query.weight', 'base_model.encoder.layer.20.attention.self.value.weight', 'base_model.encoder.layer.0.output.adapters.es.adapter_down.0.weight', 'base_model.embeddings.LayerNorm.bias', 'base_model.encoder.layer.3.output.dense.weight', 'base_model.encoder.layer.17.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.13.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.9.intermediate.dense.weight', 'base_model.encoder.layer.19.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.1.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.17.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.14.intermediate.dense.weight', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.3.attention.output.dense.bias', 'base_model.encoder.layer.20.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.4.output.LayerNorm.bias', 'base_model.encoder.layer.10.attention.self.value.bias', 'base_model.encoder.layer.18.attention.self.value.weight', 'base_model.encoder.layer.22.attention.output.LayerNorm.weight', 'base_model.encoder.layer.3.attention.self.query.bias', 'base_model.encoder.layer.20.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.17.output.LayerNorm.weight', 'base_model.encoder.layer.7.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.2.output.LayerNorm.bias', 'base_model.encoder.layer.14.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.18.output.dense.weight', 'base_model.encoder.layer.17.attention.output.dense.weight', 'base_model.encoder.layer.8.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.18.attention.output.LayerNorm.bias', 'base_model.encoder.layer.15.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.9.attention.output.LayerNorm.weight', 'base_model.encoder.layer.23.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.1.attention.self.value.bias', 'base_model.encoder.layer.21.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.3.attention.self.key.bias', 'base_model.encoder.layer.5.attention.self.value.weight', 'base_model.encoder.layer.19.attention.output.dense.bias', 'base_model.encoder.layer.19.attention.self.value.weight', 'base_model.encoder.layer.6.intermediate.dense.bias', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.7.attention.output.LayerNorm.bias', 'base_model.encoder.layer.14.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.18.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.23.attention.output.dense.bias', 'base_model.encoder.layer.11.intermediate.dense.bias', 'base_model.encoder.layer.19.output.dense.weight', 'base_model.encoder.layer.3.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.9.output.LayerNorm.weight', 'base_model.encoder.layer.3.attention.self.key.weight', 'base_model.encoder.layer.19.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.20.intermediate.dense.bias', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.23.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.9.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.4.attention.output.dense.bias', 'base_model.encoder.layer.10.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.15.attention.self.query.weight', 'base_model.encoder.layer.13.attention.self.value.weight', 'base_model.encoder.layer.3.intermediate.dense.bias', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.13.attention.self.query.bias', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.16.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.22.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.6.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.1.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.23.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.20.attention.self.key.weight', 'base_model.encoder.layer.16.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.20.attention.self.query.bias', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.4.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.15.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.17.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.5.attention.output.LayerNorm.weight', 'base_model.encoder.layer.21.intermediate.dense.bias', 'base_model.encoder.layer.5.attention.output.dense.weight', 'base_model.encoder.layer.3.attention.self.value.bias', 'base_model.encoder.layer.15.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.1.output.LayerNorm.weight', 'base_model.encoder.layer.7.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.6.attention.output.dense.weight', 'base_model.encoder.layer.16.intermediate.dense.weight', 'base_model.encoder.layer.22.attention.self.key.weight', 'base_model.encoder.layer.9.attention.output.dense.weight', 'base_model.encoder.layer.21.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.22.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.8.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.14.attention.output.LayerNorm.weight', 'base_model.encoder.layer.1.attention.output.LayerNorm.bias', 'base_model.encoder.layer.9.intermediate.dense.bias', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.21.attention.self.query.weight', 'base_model.encoder.layer.2.output.dense.weight', 'base_model.encoder.layer.12.attention.self.query.bias', 'base_model.encoder.layer.13.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.17.output.LayerNorm.bias', 'base_model.encoder.layer.19.attention.output.LayerNorm.bias', 'base_model.encoder.layer.22.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.12.intermediate.dense.bias', 'base_model.encoder.layer.15.attention.self.query.bias', 'base_model.encoder.layer.4.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.5.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.4.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.0.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.11.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.16.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.3.output.LayerNorm.weight', 'base_model.encoder.layer.6.attention.output.dense.bias', 'base_model.encoder.layer.21.attention.output.LayerNorm.weight', 'base_model.encoder.layer.22.output.LayerNorm.bias', 'base_model.encoder.layer.8.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.13.attention.output.LayerNorm.bias', 'base_model.encoder.layer.14.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.7.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.17.output.adapters.ep.adapter_up.bias']
- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of XLMRobertaModel were not initialized from the model checkpoint at /cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//squad/xlm-KG_LR8e-6_EPOCH2.0_maxlen384_batchsize4_gradacc4 and are newly initialized: ['encoder.layer.5.attention.self.value.bias', 'encoder.layer.15.attention.self.value.weight', 'encoder.layer.16.attention.self.query.weight', 'encoder.layer.20.output.LayerNorm.weight', 'encoder.layer.23.output.LayerNorm.weight', 'encoder.layer.7.attention.self.value.bias', 'encoder.layer.13.attention.self.key.weight', 'encoder.layer.2.attention.output.dense.bias', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.13.attention.self.key.bias', 'encoder.layer.23.output.dense.bias', 'encoder.layer.2.attention.output.dense.weight', 'encoder.layer.19.attention.self.query.bias', 'encoder.layer.4.attention.self.key.bias', 'encoder.layer.0.attention.output.dense.bias', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.19.attention.output.dense.bias', 'encoder.layer.11.attention.self.value.weight', 'encoder.layer.18.attention.output.LayerNorm.weight', 'encoder.layer.22.output.LayerNorm.bias', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.3.attention.output.dense.bias', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.9.attention.self.key.bias', 'encoder.layer.16.intermediate.dense.weight', 'encoder.layer.17.intermediate.dense.weight', 'encoder.layer.13.attention.output.LayerNorm.weight', 'encoder.layer.19.attention.self.key.weight', 'encoder.layer.17.attention.self.value.bias', 'encoder.layer.20.output.LayerNorm.bias', 'encoder.layer.23.attention.self.query.bias', 'encoder.layer.16.attention.self.value.bias', 'encoder.layer.15.output.LayerNorm.bias', 'encoder.layer.23.output.dense.weight', 'encoder.layer.3.output.dense.weight', 'encoder.layer.6.attention.output.dense.weight', 'encoder.layer.14.output.LayerNorm.weight', 'encoder.layer.18.attention.self.key.bias', 'embeddings.token_type_embeddings.weight', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.18.output.dense.weight', 'encoder.layer.10.attention.output.dense.weight', 'encoder.layer.17.attention.self.query.bias', 'encoder.layer.23.attention.self.key.bias', 'encoder.layer.14.attention.self.value.bias', 'encoder.layer.23.attention.self.query.weight', 'encoder.layer.22.attention.self.value.bias', 'encoder.layer.15.intermediate.dense.weight', 'encoder.layer.9.attention.output.dense.bias', 'encoder.layer.21.attention.self.query.weight', 'encoder.layer.19.attention.output.LayerNorm.bias', 'encoder.layer.7.output.dense.bias', 'encoder.layer.19.attention.self.query.weight', 'encoder.layer.14.output.LayerNorm.bias', 'encoder.layer.21.attention.output.dense.weight', 'encoder.layer.19.output.LayerNorm.bias', 'encoder.layer.8.attention.output.dense.bias', 'encoder.layer.11.attention.output.dense.bias', 'encoder.layer.20.attention.output.dense.bias', 'encoder.layer.3.attention.self.query.bias', 'encoder.layer.8.attention.self.query.weight', 'encoder.layer.22.attention.output.dense.bias', 'encoder.layer.22.attention.self.query.weight', 'encoder.layer.12.attention.self.query.weight', 'encoder.layer.6.attention.output.LayerNorm.bias', 'encoder.layer.23.attention.output.dense.weight', 'encoder.layer.5.attention.self.key.bias', 'encoder.layer.19.attention.self.key.bias', 'encoder.layer.17.intermediate.dense.bias', 'encoder.layer.0.attention.self.value.weight', 'encoder.layer.16.attention.self.query.bias', 'encoder.layer.12.output.LayerNorm.bias', 'encoder.layer.13.attention.self.query.weight', 'encoder.layer.19.attention.output.LayerNorm.weight', 'encoder.layer.16.output.LayerNorm.weight', 'encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.layer.4.attention.output.LayerNorm.bias', 'encoder.layer.7.attention.output.LayerNorm.bias', 'encoder.layer.18.attention.self.query.bias', 'encoder.layer.0.attention.self.query.weight', 'encoder.layer.16.attention.self.key.bias', 'encoder.layer.2.attention.self.query.bias', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.13.attention.self.value.weight', 'encoder.layer.11.output.LayerNorm.bias', 'encoder.layer.10.attention.output.dense.bias', 'encoder.layer.17.output.LayerNorm.weight', 'encoder.layer.13.output.dense.weight', 'encoder.layer.7.output.LayerNorm.weight', 'encoder.layer.18.attention.self.query.weight', 'encoder.layer.20.attention.output.LayerNorm.bias', 'encoder.layer.4.attention.self.value.bias', 'encoder.layer.14.attention.self.key.bias', 'encoder.layer.10.output.LayerNorm.bias', 'encoder.layer.2.output.dense.bias', 'encoder.layer.11.attention.self.value.bias', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.7.attention.self.key.weight', 'encoder.layer.22.attention.self.value.weight', 'encoder.layer.22.output.dense.bias', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.16.attention.self.key.weight', 'encoder.layer.10.attention.self.query.weight', 'encoder.layer.14.intermediate.dense.weight', 'encoder.layer.20.attention.self.key.bias', 'encoder.layer.2.output.dense.weight', 'encoder.layer.21.attention.output.dense.bias', 'encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.layer.1.attention.self.key.weight', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.5.output.LayerNorm.bias', 'encoder.layer.12.output.LayerNorm.weight', 'encoder.layer.10.attention.self.key.bias', 'encoder.layer.22.attention.self.key.bias', 'encoder.layer.11.attention.self.key.bias', 'encoder.layer.6.output.dense.weight', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.7.attention.output.LayerNorm.weight', 'encoder.layer.6.attention.self.value.bias', 'encoder.layer.11.attention.self.key.weight', 'encoder.layer.15.attention.self.query.bias', 'encoder.layer.23.intermediate.dense.weight', 'encoder.layer.22.attention.output.LayerNorm.weight', 'encoder.layer.13.intermediate.dense.bias', 'encoder.layer.20.attention.self.value.weight', 'encoder.layer.21.output.LayerNorm.weight', 'encoder.layer.4.output.dense.weight', 'encoder.layer.5.attention.self.query.weight', 'encoder.layer.3.attention.self.query.weight', 'encoder.layer.3.attention.self.value.weight', 'encoder.layer.16.attention.output.LayerNorm.weight', 'encoder.layer.15.attention.self.key.bias', 'encoder.layer.21.attention.self.value.bias', 'encoder.layer.5.attention.output.LayerNorm.weight', 'encoder.layer.22.intermediate.dense.weight', 'encoder.layer.10.output.LayerNorm.weight', 'encoder.layer.16.attention.output.dense.bias', 'encoder.layer.7.attention.output.dense.bias', 'encoder.layer.12.attention.output.dense.bias', 'encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.9.attention.self.query.weight', 'encoder.layer.8.attention.output.LayerNorm.bias', 'encoder.layer.2.attention.self.key.bias', 'encoder.layer.5.attention.self.query.bias', 'encoder.layer.12.attention.self.value.weight', 'encoder.layer.0.attention.self.value.bias', 'encoder.layer.18.attention.output.dense.bias', 'encoder.layer.8.attention.output.LayerNorm.weight', 'encoder.layer.6.attention.self.key.weight', 'encoder.layer.17.attention.output.dense.weight', 'encoder.layer.2.attention.self.value.bias', 'encoder.layer.5.attention.output.dense.weight', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.6.attention.self.key.bias', 'encoder.layer.7.attention.output.dense.weight', 'encoder.layer.12.intermediate.dense.weight', 'encoder.layer.9.attention.output.dense.weight', 'encoder.layer.20.intermediate.dense.bias', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.8.output.LayerNorm.bias', 'encoder.layer.14.attention.self.value.weight', 'encoder.layer.0.output.dense.weight', 'encoder.layer.20.output.dense.bias', 'encoder.layer.11.attention.output.dense.weight', 'encoder.layer.4.attention.self.query.weight', 'encoder.layer.15.attention.output.LayerNorm.bias', 'encoder.layer.15.output.dense.weight', 'encoder.layer.15.intermediate.dense.bias', 'encoder.layer.21.attention.output.LayerNorm.weight', 'encoder.layer.20.attention.self.key.weight', 'encoder.layer.20.attention.output.dense.weight', 'encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.layer.13.attention.self.query.bias', 'encoder.layer.16.attention.output.LayerNorm.bias', 'encoder.layer.8.output.dense.bias', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.6.output.LayerNorm.bias', 'encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.layer.10.output.dense.weight', 'encoder.layer.18.intermediate.dense.bias', 'encoder.layer.15.output.LayerNorm.weight', 'encoder.layer.1.output.dense.bias', 'encoder.layer.4.attention.output.dense.bias', 'embeddings.word_embeddings.weight', 'encoder.layer.1.attention.output.LayerNorm.weight', 'encoder.layer.17.output.LayerNorm.bias', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.1.attention.self.key.bias', 'encoder.layer.15.attention.self.key.weight', 'encoder.layer.8.attention.output.dense.weight', 'encoder.layer.19.intermediate.dense.bias', 'encoder.layer.9.output.dense.weight', 'encoder.layer.16.attention.output.dense.weight', 'encoder.layer.9.output.dense.bias', 'pooler.dense.weight', 'encoder.layer.21.attention.self.key.weight', 'encoder.layer.21.attention.self.query.bias', 'encoder.layer.15.attention.output.LayerNorm.weight', 'encoder.layer.23.attention.output.LayerNorm.weight', 'encoder.layer.8.output.dense.weight', 'encoder.layer.17.attention.self.key.bias', 'encoder.layer.5.attention.self.key.weight', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.0.output.dense.bias', 'encoder.layer.12.attention.output.LayerNorm.bias', 'encoder.layer.8.attention.self.query.bias', 'encoder.layer.9.output.LayerNorm.bias', 'encoder.layer.21.attention.self.key.bias', 'encoder.layer.22.attention.self.key.weight', 'encoder.layer.0.attention.self.query.bias', 'encoder.layer.5.attention.output.dense.bias', 'encoder.layer.3.attention.self.key.weight', 'encoder.layer.11.output.LayerNorm.weight', 'encoder.layer.16.output.dense.weight', 'encoder.layer.18.attention.output.dense.weight', 'encoder.layer.12.output.dense.weight', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.3.output.dense.bias', 'encoder.layer.1.attention.self.query.bias', 'encoder.layer.20.intermediate.dense.weight', 'encoder.layer.6.attention.output.dense.bias', 'encoder.layer.13.output.LayerNorm.bias', 'encoder.layer.8.output.LayerNorm.weight', 'encoder.layer.17.output.dense.weight', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.16.output.dense.bias', 'encoder.layer.7.output.LayerNorm.bias', 'encoder.layer.9.attention.self.value.bias', 'encoder.layer.21.attention.self.value.weight', 'encoder.layer.18.output.LayerNorm.bias', 'encoder.layer.10.output.dense.bias', 'encoder.layer.11.output.dense.bias', 'encoder.layer.17.attention.self.key.weight', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.13.attention.output.dense.bias', 'encoder.layer.2.attention.self.value.weight', 'encoder.layer.2.attention.output.LayerNorm.bias', 'encoder.layer.9.attention.output.LayerNorm.weight', 'encoder.layer.15.attention.self.query.weight', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.19.intermediate.dense.weight', 'encoder.layer.0.attention.output.LayerNorm.weight', 'encoder.layer.4.attention.self.query.bias', 'encoder.layer.23.output.LayerNorm.bias', 'encoder.layer.10.attention.output.LayerNorm.bias', 'encoder.layer.11.attention.output.LayerNorm.weight', 'encoder.layer.21.output.LayerNorm.bias', 'encoder.layer.6.attention.output.LayerNorm.weight', 'encoder.layer.4.attention.self.key.weight', 'encoder.layer.3.attention.self.value.bias', 'encoder.layer.23.attention.self.value.bias', 'encoder.layer.20.attention.self.query.bias', 'encoder.layer.0.attention.self.key.bias', 'encoder.layer.9.attention.output.LayerNorm.bias', 'encoder.layer.22.output.dense.weight', 'encoder.layer.23.attention.output.LayerNorm.bias', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.10.attention.self.query.bias', 'encoder.layer.22.attention.output.LayerNorm.bias', 'encoder.layer.19.output.dense.weight', 'encoder.layer.14.attention.self.key.weight', 'encoder.layer.4.output.dense.bias', 'encoder.layer.6.attention.self.value.weight', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.13.attention.self.value.bias', 'encoder.layer.6.attention.self.query.bias', 'encoder.layer.1.attention.self.value.weight', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.15.output.dense.bias', 'encoder.layer.3.attention.output.dense.weight', 'encoder.layer.1.attention.output.dense.weight', 'encoder.layer.16.intermediate.dense.bias', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.18.output.LayerNorm.weight', 'encoder.layer.0.output.LayerNorm.bias', 'embeddings.LayerNorm.bias', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.7.attention.self.key.bias', 'encoder.layer.12.attention.output.dense.weight', 'encoder.layer.16.output.LayerNorm.bias', 'encoder.layer.6.attention.self.query.weight', 'encoder.layer.17.output.dense.bias', 'encoder.layer.21.output.dense.bias', 'encoder.layer.19.output.dense.bias', 'encoder.layer.19.output.LayerNorm.weight', 'encoder.layer.3.attention.self.key.bias', 'encoder.layer.14.output.dense.weight', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.10.attention.self.value.bias', 'encoder.layer.15.attention.output.dense.weight', 'encoder.layer.4.attention.output.LayerNorm.weight', 'encoder.layer.12.attention.self.value.bias', 'encoder.layer.8.attention.self.value.bias', 'encoder.layer.23.attention.self.value.weight', 'encoder.layer.5.output.dense.weight', 'encoder.layer.0.attention.self.key.weight', 'encoder.layer.14.attention.self.query.weight', 'encoder.layer.2.attention.output.LayerNorm.weight', 'encoder.layer.14.attention.output.LayerNorm.bias', 'embeddings.LayerNorm.weight', 'encoder.layer.10.attention.output.LayerNorm.weight', 'encoder.layer.20.attention.output.LayerNorm.weight', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.14.attention.self.query.bias', 'encoder.layer.17.attention.output.LayerNorm.bias', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.4.attention.self.value.weight', 'encoder.layer.11.attention.self.query.bias', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.18.attention.self.value.weight', 'encoder.layer.17.attention.self.value.weight', 'encoder.layer.7.output.dense.weight', 'encoder.layer.17.attention.output.dense.bias', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.13.output.LayerNorm.weight', 'encoder.layer.6.output.dense.bias', 'encoder.layer.15.attention.self.value.bias', 'encoder.layer.12.attention.self.query.bias', 'encoder.layer.14.intermediate.dense.bias', 'encoder.layer.13.intermediate.dense.weight', 'encoder.layer.10.intermediate.dense.weight', 'encoder.layer.21.output.dense.weight', 'encoder.layer.1.attention.output.dense.bias', 'encoder.layer.2.attention.self.key.weight', 'encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.layer.11.attention.self.query.weight', 'encoder.layer.23.intermediate.dense.bias', 'encoder.layer.2.attention.self.query.weight', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.1.attention.self.value.bias', 'encoder.layer.1.attention.self.query.weight', 'encoder.layer.20.attention.self.value.bias', 'encoder.layer.18.output.dense.bias', 'embeddings.position_embeddings.weight', 'encoder.layer.19.attention.output.dense.weight', 'encoder.layer.5.output.dense.bias', 'encoder.layer.18.intermediate.dense.weight', 'encoder.layer.8.attention.self.key.weight', 'encoder.layer.4.attention.output.dense.weight', 'encoder.layer.9.output.LayerNorm.weight', 'encoder.layer.7.attention.self.value.weight', 'encoder.layer.18.attention.self.key.weight', 'encoder.layer.22.intermediate.dense.bias', 'encoder.layer.13.output.dense.bias', 'encoder.layer.21.intermediate.dense.weight', 'encoder.layer.12.attention.output.LayerNorm.weight', 'encoder.layer.0.attention.output.dense.weight', 'encoder.layer.17.attention.output.LayerNorm.weight', 'encoder.layer.12.attention.self.key.weight', 'encoder.layer.18.attention.self.value.bias', 'encoder.layer.22.attention.output.dense.weight', 'encoder.layer.18.attention.output.LayerNorm.bias', 'encoder.layer.1.output.dense.weight', 'encoder.layer.19.attention.self.value.bias', 'encoder.layer.7.attention.self.query.bias', 'encoder.layer.20.attention.self.query.weight', 'encoder.layer.15.attention.output.dense.bias', 'encoder.layer.23.attention.self.key.weight', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.12.output.dense.bias', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.8.attention.self.key.bias', 'encoder.layer.22.attention.self.query.bias', 'encoder.layer.14.attention.output.LayerNorm.weight', 'encoder.layer.14.attention.output.dense.bias', 'encoder.layer.20.output.dense.weight', 'encoder.layer.16.attention.self.value.weight', 'encoder.layer.9.attention.self.key.weight', 'encoder.layer.11.output.dense.weight', 'encoder.layer.10.attention.self.value.weight', 'encoder.layer.12.intermediate.dense.bias', 'encoder.layer.9.attention.self.value.weight', 'encoder.layer.8.attention.self.value.weight', 'encoder.layer.13.attention.output.LayerNorm.bias', 'encoder.layer.13.attention.output.dense.weight', 'encoder.layer.23.attention.output.dense.bias', 'encoder.layer.14.attention.output.dense.weight', 'encoder.layer.7.intermediate.dense.bias', 'encoder.layer.19.attention.self.value.weight', 'encoder.layer.21.intermediate.dense.bias', 'encoder.layer.7.attention.self.query.weight', 'encoder.layer.14.output.dense.bias', 'pooler.dense.bias', 'encoder.layer.10.attention.self.key.weight', 'encoder.layer.17.attention.self.query.weight', 'encoder.layer.21.attention.output.LayerNorm.bias', 'encoder.layer.22.output.LayerNorm.weight', 'encoder.layer.5.attention.self.value.weight', 'encoder.layer.9.attention.self.query.bias', 'encoder.layer.12.attention.self.key.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Overwriting existing adapter 'ep'.
Overwriting existing adapter 'tp'.
Overwriting existing adapter 'es'.
Overwriting existing adapter 'ts'.
Overwriting existing adapter fusion module 'ep,tp,es,ts'
/cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//squad/xlm-KG_LR8e-6_EPOCH2.0_maxlen384_batchsize4_gradacc4
XLMConfig {
  "architectures": [
    "XLMRobertaForMaskedLM"
  ],
  "asm": false,
  "attention_dropout": 0.1,
  "attention_probs_dropout_prob": 0.1,
  "bos_index": 0,
  "bos_token_id": 0,
  "causal": false,
  "dropout": 0.1,
  "emb_dim": 1024,
  "embed_init_std": 0.02209708691207961,
  "end_n_top": 5,
  "eos_index": 1,
  "eos_token_id": 2,
  "gelu_activation": true,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "init_std": 0.02,
  "initializer_range": 0.02,
  "intermediate_size": 4096,
  "is_encoder": true,
  "lang_id": 0,
  "layer_norm_eps": 1e-05,
  "mask_index": 5,
  "mask_token_id": 0,
  "max_position_embeddings": 514,
  "model_type": "xlm",
  "n_heads": 16,
  "n_langs": 1,
  "n_layers": 24,
  "output_past": true,
  "pad_index": 2,
  "pad_token_id": 1,
  "sinusoidal_embeddings": false,
  "start_n_top": 5,
  "summary_activation": null,
  "summary_first_dropout": 0.1,
  "summary_proj_to_labels": true,
  "summary_type": "first",
  "summary_use_proj": true,
  "transformers_version": "4.17.0",
  "type_vocab_size": 1,
  "unk_index": 3,
  "use_lang_emb": false,
  "vocab_size": 250002
}

Traceback (most recent call last):
  File "third_party/run_squad.py", line 958, in <module>
    main()
  File "third_party/run_squad.py", line 941, in main
    load_model(model, os.path.join(args.output_dir, "pytorch_model.bin"))
  File "third_party/run_squad.py", line 98, in load_model
    model.load_state_dict(torch.load(path, map_location='cpu'), strict=False)
  File "/cluster/project/sachan/yifan/softwares/anaconda/anaconda3/envs/xfactr/lib/python3.8/site-packages/torch/serialization.py", line 581, in load
    with _open_file_like(f, 'rb') as opened_file:
  File "/cluster/project/sachan/yifan/softwares/anaconda/anaconda3/envs/xfactr/lib/python3.8/site-packages/torch/serialization.py", line 230, in _open_file_like
    return _open_file(name_or_buffer, mode)
  File "/cluster/project/sachan/yifan/softwares/anaconda/anaconda3/envs/xfactr/lib/python3.8/site-packages/torch/serialization.py", line 211, in __init__
    super(_open_file, self).__init__(open(name, mode))
FileNotFoundError: [Errno 2] No such file or directory: '/cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//squad/xlm-KG_LR8e-6_EPOCH2.0_maxlen384_batchsize4_gradacc4/predictions/mlqa/pytorch_model.bin'
  de 
2022-05-09 21:38:52.586407: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0
05/09/2022 21:38:56 - WARNING - __main__ -   Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, 16-bits training: False
You are using a model of type xlm-roberta to instantiate a model of type xlm. This is not supported for all configurations of models and can yield errors.
Some weights of the model checkpoint at /cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//squad/xlm-KG_LR8e-6_EPOCH2.0_maxlen384_batchsize4_gradacc4 were not used when initializing XLMRobertaModel: ['base_model.encoder.layer.14.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.18.output.LayerNorm.weight', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.13.attention.self.key.bias', 'base_model.encoder.layer.13.attention.output.dense.bias', 'base_model.encoder.layer.14.attention.output.LayerNorm.weight', 'base_model.encoder.layer.20.attention.self.query.bias', 'base_model.encoder.layer.21.attention.self.value.bias', 'base_model.encoder.layer.13.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.1.attention.self.key.bias', 'base_model.encoder.layer.9.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.8.attention.output.LayerNorm.weight', 'base_model.encoder.layer.18.attention.output.dense.bias', 'base_model.encoder.layer.7.attention.self.value.bias', 'base_model.encoder.layer.7.attention.self.query.bias', 'base_model.encoder.layer.20.attention.output.dense.weight', 'base_model.encoder.layer.23.output.LayerNorm.bias', 'base_model.encoder.layer.10.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.8.attention.output.LayerNorm.bias', 'base_model.encoder.layer.18.attention.output.dense.weight', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.20.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.17.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.21.attention.output.LayerNorm.bias', 'base_model.encoder.layer.15.attention.output.LayerNorm.bias', 'base_model.encoder.layer.5.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.17.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.17.attention.self.key.weight', 'base_model.encoder.layer.7.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.9.output.dense.bias', 'base_model.encoder.layer.15.attention.output.LayerNorm.weight', 'base_model.encoder.layer.17.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.17.attention.output.LayerNorm.weight', 'base_model.encoder.layer.7.attention.self.query.weight', 'base_model.encoder.layer.23.output.LayerNorm.weight', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.20.attention.output.dense.bias', 'base_model.encoder.layer.4.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.22.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.0.intermediate.dense.bias', 'base_model.encoder.layer.2.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.15.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.6.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.7.attention.output.dense.weight', 'base_model.encoder.layer.21.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.10.attention.self.key.weight', 'base_model.encoder.layer.22.attention.self.value.weight', 'base_model.encoder.layer.23.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.0.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.20.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.1.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.22.output.LayerNorm.weight', 'base_model.encoder.layer.2.attention.self.key.weight', 'base_model.encoder.layer.3.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.16.attention.self.value.bias', 'base_model.encoder.layer.7.output.dense.weight', 'base_model.encoder.layer.11.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.5.attention.output.LayerNorm.bias', 'base_model.encoder.layer.3.attention.self.query.bias', 'base_model.encoder.layer.20.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.14.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.3.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.9.output.dense.weight', 'base_model.encoder.layer.13.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.2.attention.output.dense.weight', 'base_model.encoder.layer.9.attention.self.query.weight', 'base_model.encoder.layer.22.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.3.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.13.attention.self.query.weight', 'base_model.encoder.layer.13.attention.output.dense.weight', 'base_model.encoder.layer.8.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.23.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.2.attention.self.query.bias', 'base_model.encoder.layer.7.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.12.attention.output.LayerNorm.bias', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.15.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.20.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.8.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.18.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.9.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.12.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.17.output.LayerNorm.bias', 'base_model.encoder.layer.14.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.19.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.1.output.LayerNorm.weight', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.20.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.12.attention.self.value.bias', 'base_model.encoder.layer.0.attention.self.query.weight', 'base_model.encoder.layer.19.output.LayerNorm.weight', 'base_model.encoder.layer.12.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.15.attention.self.query.weight', 'base_model.encoder.layer.23.output.dense.weight', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.20.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.20.attention.output.LayerNorm.weight', 'base_model.encoder.layer.23.intermediate.dense.bias', 'base_model.encoder.layer.22.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.9.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.18.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.15.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.1.attention.self.query.weight', 'base_model.encoder.layer.3.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.8.attention.self.value.weight', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.1.attention.output.dense.weight', 'base_model.encoder.layer.3.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.4.intermediate.dense.weight', 'base_model.encoder.layer.7.attention.output.dense.bias', 'base_model.encoder.layer.11.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.12.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.11.attention.output.dense.bias', 'base_model.encoder.layer.1.attention.output.dense.bias', 'base_model.encoder.layer.0.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.6.attention.output.dense.bias', 'base_model.encoder.layer.6.attention.output.dense.weight', 'base_model.encoder.layer.13.attention.self.key.weight', 'base_model.encoder.layer.4.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.16.attention.output.LayerNorm.bias', 'base_model.encoder.layer.19.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.4.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.7.attention.self.key.bias', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.8.output.LayerNorm.bias', 'base_model.encoder.layer.13.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.6.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.19.attention.self.key.bias', 'base_model.encoder.layer.19.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.22.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.21.output.LayerNorm.weight', 'base_model.encoder.layer.16.intermediate.dense.bias', 'base_model.encoder.layer.13.attention.self.value.bias', 'base_model.encoder.layer.1.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.11.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.embeddings.position_embeddings.weight', 'base_model.encoder.layer.17.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.9.attention.output.LayerNorm.bias', 'base_model.encoder.layer.21.output.dense.weight', 'base_model.encoder.layer.21.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.3.attention.self.key.weight', 'base_model.encoder.layer.10.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.0.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.19.output.dense.bias', 'base_model.encoder.layer.10.output.dense.weight', 'base_model.encoder.layer.10.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.2.attention.self.key.bias', 'base_model.encoder.layer.17.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.11.intermediate.dense.bias', 'base_model.encoder.layer.11.attention.output.LayerNorm.weight', 'base_model.encoder.layer.11.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.18.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.15.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.20.attention.self.value.bias', 'base_model.encoder.layer.21.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.20.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.22.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.20.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.23.output.dense.bias', 'base_model.encoder.layer.9.attention.self.value.bias', 'base_model.encoder.layer.11.attention.output.dense.weight', 'base_model.encoder.layer.23.attention.self.value.bias', 'base_model.encoder.layer.23.attention.output.LayerNorm.bias', 'base_model.encoder.layer.15.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.20.attention.output.LayerNorm.bias', 'base_model.encoder.layer.9.output.LayerNorm.bias', 'base_model.encoder.layer.8.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.10.output.LayerNorm.bias', 'base_model.encoder.layer.5.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.1.output.dense.bias', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.5.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.16.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.11.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.7.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.0.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.21.attention.self.key.weight', 'base_model.encoder.layer.10.intermediate.dense.weight', 'base_model.encoder.layer.23.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.8.output.LayerNorm.weight', 'base_model.encoder.layer.8.attention.self.key.weight', 'base_model.encoder.layer.11.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.20.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.14.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.6.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.14.attention.self.value.bias', 'base_model.encoder.layer.2.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.1.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.15.attention.self.key.bias', 'base_model.encoder.layer.7.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.17.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.22.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.11.output.dense.weight', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.10.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.0.attention.output.LayerNorm.weight', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.14.attention.self.value.weight', 'base_model.encoder.layer.14.output.LayerNorm.bias', 'base_model.encoder.layer.21.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.3.attention.output.dense.weight', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.22.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.16.attention.self.key.weight', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.0.output.dense.bias', 'base_model.encoder.layer.5.attention.self.value.bias', 'base_model.encoder.layer.7.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.19.output.LayerNorm.bias', 'base_model.encoder.layer.9.output.LayerNorm.weight', 'base_model.encoder.layer.3.attention.self.value.bias', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.11.intermediate.dense.weight', 'base_model.encoder.layer.11.output.LayerNorm.weight', 'base_model.encoder.layer.15.output.LayerNorm.weight', 'base_model.encoder.layer.14.attention.self.query.weight', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.9.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.21.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.13.attention.output.LayerNorm.bias', 'base_model.encoder.layer.15.output.dense.weight', 'base_model.encoder.layer.13.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.9.attention.self.query.bias', 'base_model.encoder.layer.6.attention.output.LayerNorm.weight', 'base_model.encoder.layer.8.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.2.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.23.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.11.attention.self.key.weight', 'base_model.encoder.layer.17.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.7.intermediate.dense.weight', 'base_model.encoder.layer.1.attention.output.LayerNorm.bias', 'base_model.encoder.layer.16.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.8.attention.self.key.bias', 'base_model.encoder.layer.10.output.dense.bias', 'base_model.encoder.layer.16.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.10.attention.output.dense.bias', 'base_model.encoder.layer.17.attention.self.value.weight', 'base_model.encoder.layer.18.attention.self.key.bias', 'base_model.encoder.layer.18.attention.output.LayerNorm.weight', 'base_model.encoder.layer.1.attention.self.query.bias', 'base_model.encoder.layer.12.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.7.attention.self.value.weight', 'base_model.encoder.layer.22.attention.self.key.weight', 'base_model.encoder.layer.4.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.21.attention.self.key.bias', 'base_model.encoder.layer.16.output.LayerNorm.bias', 'base_model.encoder.layer.16.attention.output.LayerNorm.weight', 'base_model.encoder.layer.2.output.dense.bias', 'base_model.encoder.layer.13.output.LayerNorm.bias', 'base_model.encoder.layer.13.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.19.attention.self.value.weight', 'base_model.encoder.layer.22.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.15.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.16.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.0.attention.self.key.weight', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.15.attention.self.value.weight', 'base_model.encoder.layer.23.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.10.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.19.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.1.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.19.attention.output.LayerNorm.weight', 'base_model.encoder.layer.9.attention.output.dense.weight', 'base_model.encoder.layer.22.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.20.intermediate.dense.weight', 'base_model.encoder.layer.3.attention.self.query.weight', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.17.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.16.output.dense.weight', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.4.attention.self.value.weight', 'base_model.encoder.layer.3.output.dense.bias', 'base_model.encoder.layer.15.attention.self.key.weight', 'base_model.encoder.layer.17.output.dense.bias', 'base_model.encoder.layer.0.attention.self.key.bias', 'base_model.encoder.layer.5.attention.output.dense.weight', 'base_model.encoder.layer.16.attention.output.dense.bias', 'base_model.encoder.layer.5.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.7.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.21.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.1.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.19.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.19.attention.self.value.bias', 'base_model.encoder.layer.21.attention.self.value.weight', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.7.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.8.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.2.attention.self.query.weight', 'base_model.encoder.layer.16.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.4.attention.output.dense.bias', 'base_model.encoder.layer.11.attention.output.LayerNorm.bias', 'base_model.encoder.layer.14.output.dense.weight', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.13.intermediate.dense.weight', 'base_model.encoder.layer.4.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.13.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.9.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.7.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.6.attention.self.value.weight', 'base_model.encoder.layer.10.attention.self.value.bias', 'base_model.encoder.layer.15.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.8.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.22.attention.self.value.bias', 'base_model.encoder.layer.7.output.dense.bias', 'base_model.encoder.layer.1.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.13.output.dense.bias', 'base_model.encoder.layer.16.output.LayerNorm.weight', 'base_model.encoder.layer.12.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.10.attention.output.LayerNorm.weight', 'base_model.encoder.layer.5.output.LayerNorm.weight', 'base_model.encoder.layer.11.attention.self.query.weight', 'base_model.encoder.layer.19.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.9.attention.self.key.bias', 'base_model.encoder.layer.5.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.19.output.dense.weight', 'base_model.encoder.layer.11.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.21.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.4.attention.self.query.weight', 'base_model.encoder.layer.12.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.4.output.dense.bias', 'base_model.encoder.layer.15.intermediate.dense.weight', 'base_model.encoder.layer.6.output.LayerNorm.weight', 'base_model.encoder.layer.15.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.23.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.9.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.5.output.dense.bias', 'base_model.encoder.layer.8.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.14.output.LayerNorm.weight', 'base_model.encoder.layer.5.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.8.attention.self.value.bias', 'base_model.encoder.layer.18.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.22.intermediate.dense.weight', 'base_model.encoder.layer.9.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.1.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.22.intermediate.dense.bias', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.2.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.8.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.18.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.13.intermediate.dense.bias', 'base_model.encoder.layer.16.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.15.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.1.intermediate.dense.weight', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.7.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.6.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.16.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.1.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.3.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.5.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.9.attention.output.LayerNorm.weight', 'base_model.encoder.layer.5.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.9.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.13.attention.output.LayerNorm.weight', 'base_model.encoder.layer.14.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.14.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.8.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.4.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.0.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.0.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.7.intermediate.dense.bias', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.21.attention.self.query.bias', 'base_model.encoder.layer.9.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.15.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.15.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.17.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.20.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.21.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.13.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.6.output.dense.bias', 'base_model.pooler.dense.bias', 'base_model.encoder.layer.5.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.20.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.19.intermediate.dense.weight', 'base_model.encoder.layer.18.attention.output.LayerNorm.bias', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.embeddings.LayerNorm.weight', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.11.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.3.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.17.attention.self.query.weight', 'base_model.encoder.layer.21.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.19.attention.self.query.weight', 'base_model.encoder.layer.9.intermediate.dense.weight', 'base_model.encoder.layer.2.attention.self.value.bias', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.17.attention.self.value.bias', 'base_model.encoder.layer.6.attention.self.key.weight', 'base_model.pooler.dense.weight', 'base_model.encoder.layer.13.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.9.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.19.attention.output.dense.bias', 'base_model.encoder.layer.22.attention.output.dense.bias', 'base_model.encoder.layer.1.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.14.attention.self.query.bias', 'base_model.encoder.layer.3.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.5.attention.self.key.weight', 'base_model.encoder.layer.21.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.0.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.22.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.3.output.LayerNorm.weight', 'base_model.encoder.layer.4.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.11.attention.self.value.weight', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.22.attention.self.key.bias', 'base_model.encoder.layer.15.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.2.attention.output.LayerNorm.bias', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.5.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.2.output.LayerNorm.bias', 'base_model.encoder.layer.11.attention.self.key.bias', 'base_model.encoder.layer.13.attention.self.value.weight', 'base_model.encoder.layer.6.attention.output.LayerNorm.bias', 'base_model.encoder.layer.20.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.14.intermediate.dense.weight', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.15.output.dense.bias', 'base_model.encoder.layer.22.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.2.intermediate.dense.weight', 'base_model.encoder.layer.5.attention.self.value.weight', 'base_model.encoder.layer.3.output.LayerNorm.bias', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.3.intermediate.dense.weight', 'base_model.encoder.layer.13.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.18.output.dense.weight', 'base_model.encoder.layer.20.attention.self.key.bias', 'base_model.encoder.layer.14.attention.output.dense.bias', 'base_model.encoder.layer.1.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.10.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.16.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.12.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.19.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.23.attention.self.key.weight', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.17.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.21.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.8.attention.self.query.weight', 'base_model.encoder.layer.5.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.16.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.0.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.3.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.12.attention.self.query.bias', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.18.attention.self.value.weight', 'base_model.encoder.layer.18.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.18.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.2.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.4.output.LayerNorm.bias', 'base_model.encoder.layer.13.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.0.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.12.attention.self.key.bias', 'base_model.encoder.layer.18.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.22.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.22.output.dense.weight', 'base_model.encoder.layer.3.output.dense.weight', 'base_model.encoder.layer.6.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.3.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.11.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.23.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.7.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.4.intermediate.dense.bias', 'base_model.encoder.layer.14.attention.output.LayerNorm.bias', 'base_model.encoder.layer.0.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.23.attention.self.query.bias', 'base_model.encoder.layer.0.attention.self.value.weight', 'base_model.encoder.layer.22.attention.self.query.weight', 'base_model.encoder.layer.5.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.16.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.3.attention.output.LayerNorm.weight', 'base_model.encoder.layer.1.intermediate.dense.bias', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.20.output.dense.weight', 'base_model.encoder.layer.6.output.dense.weight', 'base_model.encoder.layer.12.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.7.attention.output.LayerNorm.weight', 'base_model.encoder.layer.8.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.9.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.1.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.2.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.18.attention.self.query.weight', 'base_model.encoder.layer.17.attention.self.query.bias', 'base_model.encoder.layer.10.intermediate.dense.bias', 'base_model.encoder.layer.20.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.19.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.3.intermediate.dense.bias', 'base_model.encoder.layer.6.attention.self.query.weight', 'base_model.encoder.layer.10.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.5.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.10.output.LayerNorm.weight', 'base_model.encoder.layer.18.output.dense.bias', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.5.attention.output.LayerNorm.weight', 'base_model.encoder.layer.11.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.19.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.19.attention.self.query.bias', 'base_model.encoder.layer.4.output.LayerNorm.weight', 'base_model.encoder.layer.22.attention.output.dense.weight', 'base_model.encoder.layer.10.attention.output.LayerNorm.bias', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.3.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.17.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.8.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.20.output.LayerNorm.weight', 'base_model.encoder.layer.10.attention.output.dense.weight', 'base_model.encoder.layer.10.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.14.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.0.output.LayerNorm.bias', 'base_model.encoder.layer.2.output.LayerNorm.weight', 'base_model.encoder.layer.17.output.LayerNorm.weight', 'base_model.encoder.layer.15.intermediate.dense.bias', 'base_model.encoder.layer.14.output.dense.bias', 'base_model.encoder.layer.6.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.12.intermediate.dense.weight', 'base_model.encoder.layer.20.output.LayerNorm.bias', 'base_model.encoder.layer.4.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.23.attention.output.dense.bias', 'base_model.encoder.layer.20.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.2.attention.output.dense.bias', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.22.output.dense.bias', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.2.attention.output.LayerNorm.weight', 'base_model.encoder.layer.12.attention.self.key.weight', 'base_model.encoder.layer.6.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.20.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.6.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.8.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.1.output.LayerNorm.bias', 'base_model.encoder.layer.9.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.21.output.LayerNorm.bias', 'base_model.encoder.layer.6.output.LayerNorm.bias', 'base_model.encoder.layer.12.attention.output.dense.bias', 'base_model.encoder.layer.21.intermediate.dense.weight', 'base_model.encoder.layer.23.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.11.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.1.attention.output.LayerNorm.weight', 'base_model.encoder.layer.15.attention.output.dense.bias', 'base_model.encoder.layer.19.attention.output.LayerNorm.bias', 'base_model.encoder.layer.4.attention.self.key.weight', 'base_model.encoder.layer.0.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.6.intermediate.dense.weight', 'base_model.encoder.layer.3.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.10.attention.self.query.bias', 'base_model.encoder.layer.21.attention.output.dense.bias', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.2.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.18.intermediate.dense.weight', 'base_model.encoder.layer.5.output.LayerNorm.bias', 'base_model.encoder.layer.7.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.14.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.20.intermediate.dense.bias', 'base_model.encoder.layer.4.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.4.attention.self.key.bias', 'base_model.encoder.layer.6.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.8.output.dense.bias', 'base_model.encoder.layer.12.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.2.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.19.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.23.intermediate.dense.weight', 'base_model.encoder.layer.0.attention.output.dense.weight', 'base_model.encoder.layer.0.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.10.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.15.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.4.attention.self.query.bias', 'base_model.encoder.layer.2.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.8.intermediate.dense.weight', 'base_model.encoder.layer.8.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.21.intermediate.dense.bias', 'base_model.encoder.layer.15.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.4.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.5.attention.self.query.weight', 'base_model.encoder.layer.20.attention.self.key.weight', 'base_model.encoder.layer.21.attention.output.LayerNorm.weight', 'base_model.encoder.layer.23.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.13.attention.self.query.bias', 'base_model.encoder.layer.16.attention.self.query.weight', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.23.attention.output.dense.weight', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.6.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.15.attention.output.dense.weight', 'base_model.encoder.layer.17.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.14.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.6.output.adapters.ts.adapter_down.0.weight', 'base_model.embeddings.word_embeddings.weight', 'base_model.encoder.layer.14.attention.self.key.bias', 'base_model.encoder.layer.17.attention.output.dense.bias', 'base_model.encoder.layer.17.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.18.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.16.attention.self.key.bias', 'base_model.embeddings.LayerNorm.bias', 'base_model.encoder.layer.21.output.dense.bias', 'base_model.encoder.layer.5.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.17.attention.output.LayerNorm.bias', 'base_model.encoder.layer.14.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.19.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.14.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.19.output.adapters.ep.adapter_down.0.bias', 'base_model.embeddings.token_type_embeddings.weight', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.6.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.22.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.18.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.13.output.dense.weight', 'base_model.encoder.layer.22.attention.output.LayerNorm.bias', 'base_model.encoder.layer.17.intermediate.dense.weight', 'base_model.encoder.layer.21.attention.output.dense.weight', 'base_model.encoder.layer.10.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.16.attention.output.dense.weight', 'base_model.encoder.layer.5.intermediate.dense.weight', 'base_model.encoder.layer.21.attention.self.query.weight', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.7.attention.output.LayerNorm.bias', 'base_model.encoder.layer.1.output.dense.weight', 'base_model.encoder.layer.22.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.4.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.18.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.0.output.dense.weight', 'qa_outputs.bias', 'base_model.encoder.layer.9.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.5.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.11.output.dense.bias', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.16.output.dense.bias', 'base_model.encoder.layer.10.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.10.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.3.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.4.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.23.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.9.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.3.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.0.attention.output.dense.bias', 'base_model.encoder.layer.14.intermediate.dense.bias', 'base_model.encoder.layer.19.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.13.output.LayerNorm.weight', 'base_model.encoder.layer.9.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.19.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.7.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.7.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.10.attention.self.query.weight', 'base_model.encoder.layer.11.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.2.intermediate.dense.bias', 'base_model.encoder.layer.7.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.22.attention.output.LayerNorm.weight', 'base_model.encoder.layer.9.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.10.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.12.output.dense.weight', 'base_model.encoder.layer.23.attention.self.key.bias', 'base_model.encoder.layer.12.intermediate.dense.bias', 'base_model.encoder.layer.8.output.dense.weight', 'base_model.encoder.layer.11.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.17.intermediate.dense.bias', 'base_model.encoder.layer.1.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.16.attention.self.value.weight', 'base_model.encoder.layer.7.output.LayerNorm.bias', 'base_model.encoder.layer.10.attention.self.value.weight', 'base_model.encoder.layer.11.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.23.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.14.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.20.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.2.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.2.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.9.attention.output.dense.bias', 'base_model.encoder.layer.10.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.0.intermediate.dense.weight', 'base_model.encoder.layer.1.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.0.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.19.attention.output.dense.weight', 'base_model.encoder.layer.13.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.23.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.3.attention.self.key.bias', 'base_model.encoder.layer.4.output.dense.weight', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.4.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.23.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.18.intermediate.dense.bias', 'base_model.encoder.layer.16.intermediate.dense.weight', 'base_model.encoder.layer.20.attention.self.value.weight', 'base_model.encoder.layer.11.output.LayerNorm.bias', 'base_model.encoder.layer.16.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.4.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.12.attention.self.query.weight', 'base_model.encoder.layer.7.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.17.attention.self.key.bias', 'base_model.encoder.layer.7.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.12.output.LayerNorm.bias', 'base_model.encoder.layer.17.attention.output.dense.weight', 'base_model.encoder.layer.12.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.0.attention.self.value.bias', 'base_model.encoder.layer.6.attention.self.key.bias', 'base_model.encoder.layer.18.attention.self.key.weight', 'base_model.encoder.layer.6.attention.self.query.bias', 'base_model.encoder.layer.12.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.7.attention.self.key.weight', 'base_model.encoder.layer.12.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.14.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.16.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.9.intermediate.dense.bias', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.21.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.13.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.12.attention.output.dense.weight', 'base_model.encoder.layer.7.output.LayerNorm.weight', 'base_model.encoder.layer.3.attention.output.LayerNorm.bias', 'base_model.encoder.layer.5.attention.self.query.bias', 'base_model.encoder.layer.6.intermediate.dense.bias', 'base_model.encoder.layer.9.attention.self.key.weight', 'base_model.encoder.layer.15.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.12.attention.output.LayerNorm.weight', 'base_model.encoder.layer.16.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.19.intermediate.dense.bias', 'base_model.encoder.layer.12.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.2.attention.self.value.weight', 'base_model.encoder.layer.10.attention.self.key.bias', 'base_model.encoder.layer.19.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.13.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.4.attention.output.dense.weight', 'base_model.encoder.layer.21.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.4.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.8.attention.output.dense.weight', 'base_model.encoder.layer.22.output.adapters.es.adapter_up.bias', 'base_model.embeddings.position_ids', 'base_model.encoder.layer.16.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.8.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.6.attention.self.value.bias', 'base_model.encoder.layer.21.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.11.attention.self.query.bias', 'base_model.encoder.layer.11.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.6.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.14.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.18.attention.self.value.bias', 'base_model.encoder.layer.18.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.12.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.17.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.6.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.14.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.3.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.21.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.1.attention.self.value.weight', 'base_model.encoder.layer.2.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.15.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.18.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.23.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.2.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.3.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.15.attention.self.value.bias', 'qa_outputs.weight', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.15.attention.self.query.bias', 'base_model.encoder.layer.2.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.22.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.11.attention.self.value.bias', 'base_model.encoder.layer.16.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.23.attention.self.value.weight', 'base_model.encoder.layer.12.output.dense.bias', 'base_model.encoder.layer.4.attention.self.value.bias', 'base_model.encoder.layer.21.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.18.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.5.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.8.intermediate.dense.bias', 'base_model.encoder.layer.16.attention.self.query.bias', 'base_model.encoder.layer.13.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.1.attention.self.key.weight', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.5.output.dense.weight', 'base_model.encoder.layer.12.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.2.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.8.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.2.output.dense.weight', 'base_model.encoder.layer.3.attention.output.dense.bias', 'base_model.encoder.layer.0.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.4.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.12.output.LayerNorm.weight', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.6.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.23.attention.self.query.weight', 'base_model.encoder.layer.14.attention.output.dense.weight', 'base_model.encoder.layer.20.output.dense.bias', 'base_model.encoder.layer.0.attention.output.LayerNorm.bias', 'base_model.encoder.layer.17.output.dense.weight', 'base_model.encoder.layer.19.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.5.intermediate.dense.bias', 'base_model.encoder.layer.8.attention.self.query.bias', 'base_model.encoder.layer.10.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.1.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.15.output.LayerNorm.bias', 'base_model.encoder.layer.22.attention.self.query.bias', 'base_model.encoder.layer.13.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.6.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.23.attention.output.LayerNorm.weight', 'base_model.encoder.layer.4.attention.output.LayerNorm.bias', 'base_model.encoder.layer.5.attention.output.dense.bias', 'base_model.encoder.layer.17.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.8.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.4.attention.output.LayerNorm.weight', 'base_model.encoder.layer.10.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.1.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.18.output.LayerNorm.bias', 'base_model.encoder.layer.18.attention.self.query.bias', 'base_model.encoder.layer.12.attention.self.value.weight', 'base_model.encoder.layer.0.attention.self.query.bias', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.9.attention.self.value.weight', 'base_model.encoder.layer.11.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.14.attention.self.key.weight', 'base_model.encoder.layer.1.attention.self.value.bias', 'base_model.encoder.layer.23.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.12.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.19.attention.self.key.weight', 'base_model.encoder.layer.1.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.2.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.22.output.LayerNorm.bias', 'base_model.encoder.layer.0.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.8.attention.output.dense.bias', 'base_model.encoder.layer.14.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.18.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.3.attention.self.value.weight', 'base_model.encoder.layer.5.attention.self.key.bias', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.0.output.LayerNorm.weight', 'base_model.encoder.layer.16.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.17.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.23.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.0.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.20.attention.self.query.weight', 'base_model.encoder.layer.13.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.18.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.query.weight']
- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of XLMRobertaModel were not initialized from the model checkpoint at /cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//squad/xlm-KG_LR8e-6_EPOCH2.0_maxlen384_batchsize4_gradacc4 and are newly initialized: ['encoder.layer.4.attention.self.query.bias', 'encoder.layer.7.output.LayerNorm.bias', 'encoder.layer.16.output.dense.weight', 'encoder.layer.23.attention.self.key.bias', 'encoder.layer.2.attention.self.query.weight', 'encoder.layer.23.attention.output.dense.bias', 'encoder.layer.16.intermediate.dense.weight', 'encoder.layer.8.attention.self.key.weight', 'encoder.layer.4.attention.self.key.weight', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.5.attention.output.LayerNorm.weight', 'encoder.layer.21.output.LayerNorm.bias', 'encoder.layer.10.output.dense.weight', 'embeddings.token_type_embeddings.weight', 'encoder.layer.18.attention.self.value.bias', 'encoder.layer.2.attention.self.value.bias', 'encoder.layer.21.attention.output.LayerNorm.weight', 'encoder.layer.15.output.dense.weight', 'encoder.layer.16.attention.output.dense.bias', 'encoder.layer.5.attention.output.dense.bias', 'encoder.layer.16.attention.self.key.bias', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.1.output.dense.bias', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.2.attention.output.LayerNorm.bias', 'encoder.layer.13.attention.output.LayerNorm.weight', 'encoder.layer.4.attention.self.key.bias', 'encoder.layer.3.attention.self.query.weight', 'encoder.layer.20.attention.output.dense.bias', 'encoder.layer.6.output.dense.weight', 'encoder.layer.9.attention.self.key.bias', 'encoder.layer.8.attention.output.dense.weight', 'encoder.layer.20.output.dense.weight', 'encoder.layer.19.attention.self.query.weight', 'encoder.layer.19.attention.output.LayerNorm.weight', 'encoder.layer.22.attention.self.query.weight', 'encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.layer.12.attention.self.query.weight', 'encoder.layer.3.output.dense.weight', 'encoder.layer.8.attention.self.value.bias', 'encoder.layer.10.attention.self.key.weight', 'encoder.layer.18.intermediate.dense.weight', 'encoder.layer.4.output.dense.bias', 'encoder.layer.20.attention.output.dense.weight', 'encoder.layer.10.output.LayerNorm.weight', 'encoder.layer.10.attention.self.query.bias', 'encoder.layer.4.output.dense.weight', 'encoder.layer.3.attention.self.value.weight', 'encoder.layer.11.output.dense.weight', 'encoder.layer.6.attention.self.query.bias', 'encoder.layer.6.attention.output.LayerNorm.weight', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.20.attention.self.value.bias', 'encoder.layer.16.attention.self.query.weight', 'encoder.layer.12.attention.self.value.bias', 'encoder.layer.14.attention.self.key.weight', 'encoder.layer.14.intermediate.dense.bias', 'encoder.layer.20.output.LayerNorm.weight', 'encoder.layer.12.attention.output.dense.bias', 'encoder.layer.0.attention.self.value.weight', 'encoder.layer.20.attention.output.LayerNorm.weight', 'encoder.layer.11.attention.self.key.bias', 'encoder.layer.2.attention.output.LayerNorm.weight', 'encoder.layer.8.attention.output.dense.bias', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.layer.15.attention.output.dense.weight', 'encoder.layer.15.intermediate.dense.weight', 'encoder.layer.13.output.LayerNorm.bias', 'encoder.layer.1.attention.self.key.weight', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.17.attention.self.value.weight', 'encoder.layer.18.intermediate.dense.bias', 'encoder.layer.22.attention.self.key.weight', 'encoder.layer.9.attention.output.dense.bias', 'encoder.layer.12.attention.output.LayerNorm.weight', 'encoder.layer.22.output.dense.weight', 'encoder.layer.2.attention.self.key.bias', 'encoder.layer.14.attention.output.LayerNorm.weight', 'encoder.layer.17.output.LayerNorm.bias', 'encoder.layer.17.attention.self.value.bias', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.12.intermediate.dense.weight', 'encoder.layer.16.attention.output.LayerNorm.bias', 'encoder.layer.0.attention.self.key.bias', 'encoder.layer.19.attention.output.LayerNorm.bias', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.10.output.dense.bias', 'encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.18.output.dense.bias', 'encoder.layer.11.attention.output.dense.bias', 'encoder.layer.9.attention.output.LayerNorm.bias', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.1.attention.self.query.bias', 'encoder.layer.9.attention.output.dense.weight', 'encoder.layer.0.attention.output.LayerNorm.weight', 'encoder.layer.1.attention.output.dense.bias', 'encoder.layer.1.output.dense.weight', 'encoder.layer.19.attention.self.key.weight', 'encoder.layer.22.attention.self.key.bias', 'encoder.layer.0.attention.output.dense.bias', 'encoder.layer.2.attention.output.dense.weight', 'encoder.layer.20.attention.self.key.bias', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.11.attention.self.value.bias', 'encoder.layer.10.attention.self.key.bias', 'encoder.layer.10.output.LayerNorm.bias', 'encoder.layer.20.attention.self.query.bias', 'encoder.layer.6.attention.self.key.bias', 'encoder.layer.15.attention.self.query.bias', 'encoder.layer.23.attention.output.LayerNorm.bias', 'encoder.layer.19.output.LayerNorm.bias', 'encoder.layer.2.output.dense.weight', 'encoder.layer.22.attention.self.value.bias', 'encoder.layer.4.attention.output.dense.weight', 'encoder.layer.4.attention.self.value.bias', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.13.attention.output.LayerNorm.bias', 'encoder.layer.13.attention.output.dense.weight', 'encoder.layer.15.attention.output.dense.bias', 'encoder.layer.20.intermediate.dense.weight', 'encoder.layer.20.attention.self.key.weight', 'encoder.layer.23.attention.self.value.bias', 'encoder.layer.8.output.dense.weight', 'encoder.layer.11.attention.self.value.weight', 'encoder.layer.17.attention.self.query.weight', 'encoder.layer.22.attention.output.LayerNorm.weight', 'encoder.layer.18.attention.self.key.weight', 'encoder.layer.4.attention.output.LayerNorm.bias', 'encoder.layer.0.output.dense.bias', 'encoder.layer.14.intermediate.dense.weight', 'encoder.layer.17.attention.self.query.bias', 'encoder.layer.6.attention.self.query.weight', 'encoder.layer.19.attention.output.dense.weight', 'encoder.layer.0.attention.self.value.bias', 'encoder.layer.12.output.LayerNorm.bias', 'encoder.layer.22.output.dense.bias', 'encoder.layer.16.output.LayerNorm.bias', 'encoder.layer.9.output.LayerNorm.weight', 'encoder.layer.22.attention.output.dense.bias', 'encoder.layer.14.output.dense.weight', 'encoder.layer.18.attention.output.LayerNorm.bias', 'encoder.layer.8.attention.self.query.weight', 'encoder.layer.22.attention.self.query.bias', 'encoder.layer.23.intermediate.dense.bias', 'encoder.layer.20.attention.self.value.weight', 'encoder.layer.12.attention.self.key.weight', 'encoder.layer.21.intermediate.dense.weight', 'encoder.layer.21.attention.output.dense.weight', 'pooler.dense.weight', 'encoder.layer.0.output.dense.weight', 'encoder.layer.9.output.LayerNorm.bias', 'encoder.layer.23.output.dense.weight', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.17.output.dense.weight', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.17.attention.output.LayerNorm.weight', 'encoder.layer.8.attention.output.LayerNorm.weight', 'encoder.layer.21.output.dense.weight', 'encoder.layer.21.attention.self.query.weight', 'encoder.layer.23.output.LayerNorm.bias', 'pooler.dense.bias', 'encoder.layer.5.output.LayerNorm.bias', 'encoder.layer.8.attention.self.key.bias', 'encoder.layer.12.attention.self.key.bias', 'encoder.layer.22.attention.output.LayerNorm.bias', 'encoder.layer.22.output.LayerNorm.weight', 'encoder.layer.15.attention.self.key.weight', 'encoder.layer.19.output.LayerNorm.weight', 'encoder.layer.8.attention.self.value.weight', 'encoder.layer.14.attention.self.value.weight', 'encoder.layer.15.attention.self.value.weight', 'encoder.layer.7.output.dense.weight', 'encoder.layer.10.attention.self.value.bias', 'encoder.layer.7.attention.self.query.weight', 'encoder.layer.18.attention.output.dense.bias', 'encoder.layer.21.attention.output.dense.bias', 'encoder.layer.21.attention.self.key.bias', 'encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.layer.21.attention.self.value.bias', 'encoder.layer.9.attention.self.query.bias', 'encoder.layer.22.attention.output.dense.weight', 'encoder.layer.2.attention.output.dense.bias', 'encoder.layer.12.output.dense.bias', 'encoder.layer.10.attention.self.query.weight', 'encoder.layer.17.attention.output.dense.bias', 'encoder.layer.18.attention.self.value.weight', 'encoder.layer.14.output.LayerNorm.weight', 'encoder.layer.9.attention.self.key.weight', 'encoder.layer.18.attention.self.key.bias', 'encoder.layer.7.attention.output.LayerNorm.bias', 'encoder.layer.12.attention.output.dense.weight', 'encoder.layer.13.attention.self.query.bias', 'encoder.layer.17.intermediate.dense.bias', 'encoder.layer.19.attention.self.key.bias', 'encoder.layer.0.attention.self.key.weight', 'encoder.layer.23.attention.self.query.bias', 'encoder.layer.21.output.dense.bias', 'encoder.layer.23.attention.output.dense.weight', 'encoder.layer.14.output.LayerNorm.bias', 'encoder.layer.7.attention.self.value.bias', 'encoder.layer.2.attention.self.query.bias', 'encoder.layer.19.attention.self.value.weight', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.17.output.LayerNorm.weight', 'encoder.layer.18.output.LayerNorm.bias', 'encoder.layer.7.attention.self.value.weight', 'encoder.layer.12.attention.output.LayerNorm.bias', 'encoder.layer.17.intermediate.dense.weight', 'embeddings.LayerNorm.bias', 'encoder.layer.5.output.dense.bias', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.4.attention.output.LayerNorm.weight', 'encoder.layer.6.attention.output.dense.weight', 'encoder.layer.11.attention.output.LayerNorm.weight', 'encoder.layer.23.output.LayerNorm.weight', 'encoder.layer.17.attention.self.key.weight', 'encoder.layer.1.attention.self.value.bias', 'encoder.layer.13.output.dense.bias', 'encoder.layer.1.attention.self.query.weight', 'encoder.layer.20.attention.self.query.weight', 'encoder.layer.16.output.LayerNorm.weight', 'encoder.layer.6.attention.output.LayerNorm.bias', 'encoder.layer.12.output.LayerNorm.weight', 'encoder.layer.14.attention.output.dense.weight', 'encoder.layer.6.output.dense.bias', 'encoder.layer.10.attention.output.LayerNorm.weight', 'encoder.layer.11.attention.self.query.weight', 'encoder.layer.15.output.LayerNorm.weight', 'encoder.layer.20.output.LayerNorm.bias', 'encoder.layer.12.intermediate.dense.bias', 'encoder.layer.19.attention.self.value.bias', 'encoder.layer.17.attention.self.key.bias', 'encoder.layer.18.attention.output.dense.weight', 'encoder.layer.9.attention.self.query.weight', 'encoder.layer.13.output.LayerNorm.weight', 'encoder.layer.19.output.dense.weight', 'encoder.layer.4.attention.output.dense.bias', 'encoder.layer.3.attention.self.value.bias', 'encoder.layer.5.attention.output.dense.weight', 'encoder.layer.8.output.LayerNorm.weight', 'encoder.layer.9.attention.output.LayerNorm.weight', 'encoder.layer.2.output.dense.bias', 'encoder.layer.11.output.LayerNorm.bias', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.16.attention.self.value.bias', 'encoder.layer.13.attention.self.value.weight', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.18.attention.output.LayerNorm.weight', 'encoder.layer.14.attention.output.dense.bias', 'encoder.layer.23.attention.self.value.weight', 'encoder.layer.15.intermediate.dense.bias', 'encoder.layer.19.output.dense.bias', 'encoder.layer.16.intermediate.dense.bias', 'encoder.layer.7.attention.self.key.bias', 'encoder.layer.14.output.dense.bias', 'encoder.layer.6.output.LayerNorm.bias', 'encoder.layer.13.attention.self.query.weight', 'encoder.layer.1.attention.self.key.bias', 'encoder.layer.6.attention.self.value.weight', 'encoder.layer.4.attention.self.query.weight', 'encoder.layer.10.intermediate.dense.weight', 'encoder.layer.14.attention.self.query.bias', 'encoder.layer.23.intermediate.dense.weight', 'encoder.layer.21.attention.self.key.weight', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.14.attention.output.LayerNorm.bias', 'encoder.layer.9.attention.self.value.bias', 'embeddings.word_embeddings.weight', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.5.attention.self.query.weight', 'encoder.layer.7.attention.self.query.bias', 'encoder.layer.22.intermediate.dense.weight', 'encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.layer.13.output.dense.weight', 'encoder.layer.1.attention.self.value.weight', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.13.intermediate.dense.bias', 'encoder.layer.18.output.LayerNorm.weight', 'encoder.layer.16.attention.output.dense.weight', 'encoder.layer.20.attention.output.LayerNorm.bias', 'encoder.layer.21.output.LayerNorm.weight', 'encoder.layer.19.attention.output.dense.bias', 'encoder.layer.15.attention.self.query.weight', 'encoder.layer.3.attention.self.query.bias', 'encoder.layer.7.intermediate.dense.bias', 'encoder.layer.7.attention.output.LayerNorm.weight', 'encoder.layer.22.output.LayerNorm.bias', 'encoder.layer.11.attention.output.dense.weight', 'encoder.layer.20.intermediate.dense.bias', 'encoder.layer.15.attention.output.LayerNorm.weight', 'encoder.layer.21.attention.self.value.weight', 'encoder.layer.8.output.dense.bias', 'encoder.layer.9.output.dense.weight', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.18.output.dense.weight', 'encoder.layer.7.attention.output.dense.weight', 'encoder.layer.5.output.dense.weight', 'encoder.layer.13.attention.self.key.weight', 'encoder.layer.16.attention.self.value.weight', 'encoder.layer.8.attention.output.LayerNorm.bias', 'encoder.layer.6.attention.output.dense.bias', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.19.attention.self.query.bias', 'encoder.layer.6.attention.self.value.bias', 'encoder.layer.11.output.LayerNorm.weight', 'encoder.layer.13.attention.self.value.bias', 'encoder.layer.11.attention.self.key.weight', 'encoder.layer.18.attention.self.query.bias', 'encoder.layer.10.attention.output.dense.bias', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.22.intermediate.dense.bias', 'encoder.layer.3.attention.self.key.weight', 'encoder.layer.21.attention.self.query.bias', 'encoder.layer.5.attention.self.value.bias', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.13.attention.self.key.bias', 'encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.layer.3.output.dense.bias', 'encoder.layer.12.attention.self.value.weight', 'encoder.layer.3.attention.output.dense.bias', 'encoder.layer.15.attention.output.LayerNorm.bias', 'encoder.layer.6.attention.self.key.weight', 'encoder.layer.10.attention.output.dense.weight', 'encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.layer.5.attention.self.key.bias', 'encoder.layer.0.attention.self.query.bias', 'encoder.layer.19.intermediate.dense.weight', 'encoder.layer.20.output.dense.bias', 'encoder.layer.15.output.dense.bias', 'encoder.layer.22.attention.self.value.weight', 'encoder.layer.16.attention.self.query.bias', 'encoder.layer.11.output.dense.bias', 'encoder.layer.2.attention.self.value.weight', 'encoder.layer.23.output.dense.bias', 'encoder.layer.8.output.LayerNorm.bias', 'encoder.layer.16.attention.self.key.weight', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.11.attention.self.query.bias', 'encoder.layer.17.output.dense.bias', 'encoder.layer.9.attention.self.value.weight', 'encoder.layer.16.attention.output.LayerNorm.weight', 'encoder.layer.5.attention.self.key.weight', 'encoder.layer.23.attention.output.LayerNorm.weight', 'embeddings.LayerNorm.weight', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.3.attention.output.dense.weight', 'encoder.layer.7.attention.output.dense.bias', 'encoder.layer.15.attention.self.key.bias', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.13.attention.output.dense.bias', 'encoder.layer.23.attention.self.key.weight', 'encoder.layer.13.intermediate.dense.weight', 'encoder.layer.5.attention.self.value.weight', 'encoder.layer.0.attention.output.dense.weight', 'encoder.layer.2.attention.self.key.weight', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.8.attention.self.query.bias', 'encoder.layer.21.attention.output.LayerNorm.bias', 'encoder.layer.10.attention.output.LayerNorm.bias', 'encoder.layer.1.attention.output.LayerNorm.weight', 'encoder.layer.19.intermediate.dense.bias', 'encoder.layer.16.output.dense.bias', 'encoder.layer.3.attention.self.key.bias', 'encoder.layer.14.attention.self.value.bias', 'encoder.layer.7.output.LayerNorm.weight', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.0.attention.self.query.weight', 'encoder.layer.7.output.dense.bias', 'encoder.layer.1.attention.output.dense.weight', 'encoder.layer.18.attention.self.query.weight', 'encoder.layer.15.attention.self.value.bias', 'encoder.layer.5.attention.self.query.bias', 'encoder.layer.12.output.dense.weight', 'encoder.layer.23.attention.self.query.weight', 'encoder.layer.3.intermediate.dense.weight', 'embeddings.position_embeddings.weight', 'encoder.layer.4.attention.self.value.weight', 'encoder.layer.15.output.LayerNorm.bias', 'encoder.layer.7.attention.self.key.weight', 'encoder.layer.17.attention.output.LayerNorm.bias', 'encoder.layer.12.attention.self.query.bias', 'encoder.layer.10.attention.self.value.weight', 'encoder.layer.9.output.dense.bias', 'encoder.layer.21.intermediate.dense.bias', 'encoder.layer.14.attention.self.query.weight', 'encoder.layer.14.attention.self.key.bias', 'encoder.layer.17.attention.output.dense.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Overwriting existing adapter 'ep'.
Overwriting existing adapter 'tp'.
Overwriting existing adapter 'es'.
Overwriting existing adapter 'ts'.
Overwriting existing adapter fusion module 'ep,tp,es,ts'
05/09/2022 21:39:17 - INFO - __main__ -   lang2id = None
05/09/2022 21:39:20 - INFO - __main__ -   Training/evaluation parameters Namespace(adam_epsilon=1e-08, cache_dir='', config_name='', data_dir=None, device=device(type='cuda'), do_eval=True, do_lower_case=False, do_train=False, doc_stride=128, eval_all_checkpoints=False, eval_lang='de', evaluate_during_training=False, fp16=False, fp16_opt_level='O1', gradient_accumulation_steps=1, learning_rate=5e-05, local_rank=-1, logging_steps=50, max_answer_length=30, max_grad_norm=1.0, max_query_length=64, max_seq_length=384, max_steps=-1, model_name='xlm-KG', model_name_or_path='/cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//squad/xlm-KG_LR8e-6_EPOCH2.0_maxlen384_batchsize4_gradacc4', model_type='xlm', modelkg_dir='/cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/adapter/xlmr_adapter', n_best_size=20, n_gpu=1, no_cuda=False, null_score_diff_threshold=0.0, num_train_epochs=3.0, output_dir='/cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//squad/xlm-KG_LR8e-6_EPOCH2.0_maxlen384_batchsize4_gradacc4/predictions/mlqa/', overwrite_cache=False, overwrite_output_dir=False, per_gpu_eval_batch_size=8, per_gpu_train_batch_size=8, predict_file='/cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/download//mlqa//MLQA_V1/test/test-context-de-question-de.json', save_steps=50, seed=42, server_ip='', server_port='', threads=1, tokenizer_name='', train_file=None, train_lang='en', verbose_logging=False, version_2_with_negative=False, warmup_steps=0, weight_decay=0.0)
05/09/2022 21:39:20 - INFO - __main__ -   Loading checkpoint /cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//squad/xlm-KG_LR8e-6_EPOCH2.0_maxlen384_batchsize4_gradacc4 for evaluation
05/09/2022 21:39:20 - INFO - __main__ -   Evaluate the following checkpoints: ['/cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//squad/xlm-KG_LR8e-6_EPOCH2.0_maxlen384_batchsize4_gradacc4']
Some weights of the model checkpoint at /cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//squad/xlm-KG_LR8e-6_EPOCH2.0_maxlen384_batchsize4_gradacc4 were not used when initializing XLMRobertaModel: ['base_model.encoder.layer.14.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.18.output.LayerNorm.weight', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.13.attention.self.key.bias', 'base_model.encoder.layer.13.attention.output.dense.bias', 'base_model.encoder.layer.14.attention.output.LayerNorm.weight', 'base_model.encoder.layer.20.attention.self.query.bias', 'base_model.encoder.layer.21.attention.self.value.bias', 'base_model.encoder.layer.13.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.1.attention.self.key.bias', 'base_model.encoder.layer.9.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.8.attention.output.LayerNorm.weight', 'base_model.encoder.layer.18.attention.output.dense.bias', 'base_model.encoder.layer.7.attention.self.value.bias', 'base_model.encoder.layer.7.attention.self.query.bias', 'base_model.encoder.layer.20.attention.output.dense.weight', 'base_model.encoder.layer.23.output.LayerNorm.bias', 'base_model.encoder.layer.10.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.8.attention.output.LayerNorm.bias', 'base_model.encoder.layer.18.attention.output.dense.weight', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.20.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.17.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.21.attention.output.LayerNorm.bias', 'base_model.encoder.layer.15.attention.output.LayerNorm.bias', 'base_model.encoder.layer.5.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.17.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.17.attention.self.key.weight', 'base_model.encoder.layer.7.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.9.output.dense.bias', 'base_model.encoder.layer.15.attention.output.LayerNorm.weight', 'base_model.encoder.layer.17.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.17.attention.output.LayerNorm.weight', 'base_model.encoder.layer.7.attention.self.query.weight', 'base_model.encoder.layer.23.output.LayerNorm.weight', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.20.attention.output.dense.bias', 'base_model.encoder.layer.4.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.22.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.0.intermediate.dense.bias', 'base_model.encoder.layer.2.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.15.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.6.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.7.attention.output.dense.weight', 'base_model.encoder.layer.21.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.10.attention.self.key.weight', 'base_model.encoder.layer.22.attention.self.value.weight', 'base_model.encoder.layer.23.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.0.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.20.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.1.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.22.output.LayerNorm.weight', 'base_model.encoder.layer.2.attention.self.key.weight', 'base_model.encoder.layer.3.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.16.attention.self.value.bias', 'base_model.encoder.layer.7.output.dense.weight', 'base_model.encoder.layer.11.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.5.attention.output.LayerNorm.bias', 'base_model.encoder.layer.3.attention.self.query.bias', 'base_model.encoder.layer.20.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.14.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.3.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.9.output.dense.weight', 'base_model.encoder.layer.13.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.2.attention.output.dense.weight', 'base_model.encoder.layer.9.attention.self.query.weight', 'base_model.encoder.layer.22.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.3.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.13.attention.self.query.weight', 'base_model.encoder.layer.13.attention.output.dense.weight', 'base_model.encoder.layer.8.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.23.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.2.attention.self.query.bias', 'base_model.encoder.layer.7.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.12.attention.output.LayerNorm.bias', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.15.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.20.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.8.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.18.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.9.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.12.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.17.output.LayerNorm.bias', 'base_model.encoder.layer.14.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.19.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.1.output.LayerNorm.weight', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.20.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.12.attention.self.value.bias', 'base_model.encoder.layer.0.attention.self.query.weight', 'base_model.encoder.layer.19.output.LayerNorm.weight', 'base_model.encoder.layer.12.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.15.attention.self.query.weight', 'base_model.encoder.layer.23.output.dense.weight', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.20.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.20.attention.output.LayerNorm.weight', 'base_model.encoder.layer.23.intermediate.dense.bias', 'base_model.encoder.layer.22.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.9.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.18.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.15.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.1.attention.self.query.weight', 'base_model.encoder.layer.3.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.8.attention.self.value.weight', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.1.attention.output.dense.weight', 'base_model.encoder.layer.3.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.4.intermediate.dense.weight', 'base_model.encoder.layer.7.attention.output.dense.bias', 'base_model.encoder.layer.11.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.12.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.11.attention.output.dense.bias', 'base_model.encoder.layer.1.attention.output.dense.bias', 'base_model.encoder.layer.0.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.6.attention.output.dense.bias', 'base_model.encoder.layer.6.attention.output.dense.weight', 'base_model.encoder.layer.13.attention.self.key.weight', 'base_model.encoder.layer.4.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.16.attention.output.LayerNorm.bias', 'base_model.encoder.layer.19.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.4.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.7.attention.self.key.bias', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.8.output.LayerNorm.bias', 'base_model.encoder.layer.13.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.6.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.19.attention.self.key.bias', 'base_model.encoder.layer.19.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.22.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.21.output.LayerNorm.weight', 'base_model.encoder.layer.16.intermediate.dense.bias', 'base_model.encoder.layer.13.attention.self.value.bias', 'base_model.encoder.layer.1.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.11.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.embeddings.position_embeddings.weight', 'base_model.encoder.layer.17.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.9.attention.output.LayerNorm.bias', 'base_model.encoder.layer.21.output.dense.weight', 'base_model.encoder.layer.21.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.3.attention.self.key.weight', 'base_model.encoder.layer.10.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.0.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.19.output.dense.bias', 'base_model.encoder.layer.10.output.dense.weight', 'base_model.encoder.layer.10.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.2.attention.self.key.bias', 'base_model.encoder.layer.17.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.11.intermediate.dense.bias', 'base_model.encoder.layer.11.attention.output.LayerNorm.weight', 'base_model.encoder.layer.11.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.18.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.15.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.20.attention.self.value.bias', 'base_model.encoder.layer.21.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.20.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.22.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.20.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.23.output.dense.bias', 'base_model.encoder.layer.9.attention.self.value.bias', 'base_model.encoder.layer.11.attention.output.dense.weight', 'base_model.encoder.layer.23.attention.self.value.bias', 'base_model.encoder.layer.23.attention.output.LayerNorm.bias', 'base_model.encoder.layer.15.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.20.attention.output.LayerNorm.bias', 'base_model.encoder.layer.9.output.LayerNorm.bias', 'base_model.encoder.layer.8.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.10.output.LayerNorm.bias', 'base_model.encoder.layer.5.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.1.output.dense.bias', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.5.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.16.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.11.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.7.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.0.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.21.attention.self.key.weight', 'base_model.encoder.layer.10.intermediate.dense.weight', 'base_model.encoder.layer.23.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.8.output.LayerNorm.weight', 'base_model.encoder.layer.8.attention.self.key.weight', 'base_model.encoder.layer.11.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.20.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.14.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.6.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.14.attention.self.value.bias', 'base_model.encoder.layer.2.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.1.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.15.attention.self.key.bias', 'base_model.encoder.layer.7.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.17.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.22.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.11.output.dense.weight', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.10.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.0.attention.output.LayerNorm.weight', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.14.attention.self.value.weight', 'base_model.encoder.layer.14.output.LayerNorm.bias', 'base_model.encoder.layer.21.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.3.attention.output.dense.weight', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.22.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.16.attention.self.key.weight', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.0.output.dense.bias', 'base_model.encoder.layer.5.attention.self.value.bias', 'base_model.encoder.layer.7.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.19.output.LayerNorm.bias', 'base_model.encoder.layer.9.output.LayerNorm.weight', 'base_model.encoder.layer.3.attention.self.value.bias', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.11.intermediate.dense.weight', 'base_model.encoder.layer.11.output.LayerNorm.weight', 'base_model.encoder.layer.15.output.LayerNorm.weight', 'base_model.encoder.layer.14.attention.self.query.weight', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.9.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.21.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.13.attention.output.LayerNorm.bias', 'base_model.encoder.layer.15.output.dense.weight', 'base_model.encoder.layer.13.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.9.attention.self.query.bias', 'base_model.encoder.layer.6.attention.output.LayerNorm.weight', 'base_model.encoder.layer.8.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.2.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.23.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.11.attention.self.key.weight', 'base_model.encoder.layer.17.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.7.intermediate.dense.weight', 'base_model.encoder.layer.1.attention.output.LayerNorm.bias', 'base_model.encoder.layer.16.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.8.attention.self.key.bias', 'base_model.encoder.layer.10.output.dense.bias', 'base_model.encoder.layer.16.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.10.attention.output.dense.bias', 'base_model.encoder.layer.17.attention.self.value.weight', 'base_model.encoder.layer.18.attention.self.key.bias', 'base_model.encoder.layer.18.attention.output.LayerNorm.weight', 'base_model.encoder.layer.1.attention.self.query.bias', 'base_model.encoder.layer.12.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.7.attention.self.value.weight', 'base_model.encoder.layer.22.attention.self.key.weight', 'base_model.encoder.layer.4.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.21.attention.self.key.bias', 'base_model.encoder.layer.16.output.LayerNorm.bias', 'base_model.encoder.layer.16.attention.output.LayerNorm.weight', 'base_model.encoder.layer.2.output.dense.bias', 'base_model.encoder.layer.13.output.LayerNorm.bias', 'base_model.encoder.layer.13.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.19.attention.self.value.weight', 'base_model.encoder.layer.22.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.15.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.16.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.0.attention.self.key.weight', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.15.attention.self.value.weight', 'base_model.encoder.layer.23.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.10.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.19.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.1.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.19.attention.output.LayerNorm.weight', 'base_model.encoder.layer.9.attention.output.dense.weight', 'base_model.encoder.layer.22.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.20.intermediate.dense.weight', 'base_model.encoder.layer.3.attention.self.query.weight', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.17.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.16.output.dense.weight', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.4.attention.self.value.weight', 'base_model.encoder.layer.3.output.dense.bias', 'base_model.encoder.layer.15.attention.self.key.weight', 'base_model.encoder.layer.17.output.dense.bias', 'base_model.encoder.layer.0.attention.self.key.bias', 'base_model.encoder.layer.5.attention.output.dense.weight', 'base_model.encoder.layer.16.attention.output.dense.bias', 'base_model.encoder.layer.5.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.7.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.21.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.1.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.19.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.19.attention.self.value.bias', 'base_model.encoder.layer.21.attention.self.value.weight', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.7.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.8.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.2.attention.self.query.weight', 'base_model.encoder.layer.16.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.4.attention.output.dense.bias', 'base_model.encoder.layer.11.attention.output.LayerNorm.bias', 'base_model.encoder.layer.14.output.dense.weight', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.13.intermediate.dense.weight', 'base_model.encoder.layer.4.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.13.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.9.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.7.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.6.attention.self.value.weight', 'base_model.encoder.layer.10.attention.self.value.bias', 'base_model.encoder.layer.15.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.8.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.22.attention.self.value.bias', 'base_model.encoder.layer.7.output.dense.bias', 'base_model.encoder.layer.1.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.13.output.dense.bias', 'base_model.encoder.layer.16.output.LayerNorm.weight', 'base_model.encoder.layer.12.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.10.attention.output.LayerNorm.weight', 'base_model.encoder.layer.5.output.LayerNorm.weight', 'base_model.encoder.layer.11.attention.self.query.weight', 'base_model.encoder.layer.19.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.9.attention.self.key.bias', 'base_model.encoder.layer.5.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.19.output.dense.weight', 'base_model.encoder.layer.11.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.21.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.4.attention.self.query.weight', 'base_model.encoder.layer.12.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.4.output.dense.bias', 'base_model.encoder.layer.15.intermediate.dense.weight', 'base_model.encoder.layer.6.output.LayerNorm.weight', 'base_model.encoder.layer.15.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.23.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.9.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.5.output.dense.bias', 'base_model.encoder.layer.8.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.14.output.LayerNorm.weight', 'base_model.encoder.layer.5.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.8.attention.self.value.bias', 'base_model.encoder.layer.18.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.22.intermediate.dense.weight', 'base_model.encoder.layer.9.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.1.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.22.intermediate.dense.bias', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.2.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.8.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.18.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.13.intermediate.dense.bias', 'base_model.encoder.layer.16.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.15.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.1.intermediate.dense.weight', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.7.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.6.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.16.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.1.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.3.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.5.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.9.attention.output.LayerNorm.weight', 'base_model.encoder.layer.5.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.9.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.13.attention.output.LayerNorm.weight', 'base_model.encoder.layer.14.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.14.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.8.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.4.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.0.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.0.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.7.intermediate.dense.bias', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.21.attention.self.query.bias', 'base_model.encoder.layer.9.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.15.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.15.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.17.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.20.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.21.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.13.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.6.output.dense.bias', 'base_model.pooler.dense.bias', 'base_model.encoder.layer.5.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.20.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.19.intermediate.dense.weight', 'base_model.encoder.layer.18.attention.output.LayerNorm.bias', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.embeddings.LayerNorm.weight', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.11.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.3.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.17.attention.self.query.weight', 'base_model.encoder.layer.21.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.19.attention.self.query.weight', 'base_model.encoder.layer.9.intermediate.dense.weight', 'base_model.encoder.layer.2.attention.self.value.bias', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.17.attention.self.value.bias', 'base_model.encoder.layer.6.attention.self.key.weight', 'base_model.pooler.dense.weight', 'base_model.encoder.layer.13.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.9.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.19.attention.output.dense.bias', 'base_model.encoder.layer.22.attention.output.dense.bias', 'base_model.encoder.layer.1.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.14.attention.self.query.bias', 'base_model.encoder.layer.3.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.5.attention.self.key.weight', 'base_model.encoder.layer.21.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.0.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.22.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.3.output.LayerNorm.weight', 'base_model.encoder.layer.4.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.11.attention.self.value.weight', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.22.attention.self.key.bias', 'base_model.encoder.layer.15.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.2.attention.output.LayerNorm.bias', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.5.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.2.output.LayerNorm.bias', 'base_model.encoder.layer.11.attention.self.key.bias', 'base_model.encoder.layer.13.attention.self.value.weight', 'base_model.encoder.layer.6.attention.output.LayerNorm.bias', 'base_model.encoder.layer.20.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.14.intermediate.dense.weight', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.15.output.dense.bias', 'base_model.encoder.layer.22.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.2.intermediate.dense.weight', 'base_model.encoder.layer.5.attention.self.value.weight', 'base_model.encoder.layer.3.output.LayerNorm.bias', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.3.intermediate.dense.weight', 'base_model.encoder.layer.13.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.18.output.dense.weight', 'base_model.encoder.layer.20.attention.self.key.bias', 'base_model.encoder.layer.14.attention.output.dense.bias', 'base_model.encoder.layer.1.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.10.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.16.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.12.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.19.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.23.attention.self.key.weight', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.17.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.21.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.8.attention.self.query.weight', 'base_model.encoder.layer.5.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.16.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.0.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.3.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.12.attention.self.query.bias', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.18.attention.self.value.weight', 'base_model.encoder.layer.18.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.18.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.2.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.4.output.LayerNorm.bias', 'base_model.encoder.layer.13.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.0.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.12.attention.self.key.bias', 'base_model.encoder.layer.18.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.22.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.22.output.dense.weight', 'base_model.encoder.layer.3.output.dense.weight', 'base_model.encoder.layer.6.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.3.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.11.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.23.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.7.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.4.intermediate.dense.bias', 'base_model.encoder.layer.14.attention.output.LayerNorm.bias', 'base_model.encoder.layer.0.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.23.attention.self.query.bias', 'base_model.encoder.layer.0.attention.self.value.weight', 'base_model.encoder.layer.22.attention.self.query.weight', 'base_model.encoder.layer.5.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.16.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.3.attention.output.LayerNorm.weight', 'base_model.encoder.layer.1.intermediate.dense.bias', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.20.output.dense.weight', 'base_model.encoder.layer.6.output.dense.weight', 'base_model.encoder.layer.12.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.7.attention.output.LayerNorm.weight', 'base_model.encoder.layer.8.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.9.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.1.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.2.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.18.attention.self.query.weight', 'base_model.encoder.layer.17.attention.self.query.bias', 'base_model.encoder.layer.10.intermediate.dense.bias', 'base_model.encoder.layer.20.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.19.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.3.intermediate.dense.bias', 'base_model.encoder.layer.6.attention.self.query.weight', 'base_model.encoder.layer.10.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.5.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.10.output.LayerNorm.weight', 'base_model.encoder.layer.18.output.dense.bias', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.5.attention.output.LayerNorm.weight', 'base_model.encoder.layer.11.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.19.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.19.attention.self.query.bias', 'base_model.encoder.layer.4.output.LayerNorm.weight', 'base_model.encoder.layer.22.attention.output.dense.weight', 'base_model.encoder.layer.10.attention.output.LayerNorm.bias', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.3.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.17.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.8.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.20.output.LayerNorm.weight', 'base_model.encoder.layer.10.attention.output.dense.weight', 'base_model.encoder.layer.10.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.14.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.0.output.LayerNorm.bias', 'base_model.encoder.layer.2.output.LayerNorm.weight', 'base_model.encoder.layer.17.output.LayerNorm.weight', 'base_model.encoder.layer.15.intermediate.dense.bias', 'base_model.encoder.layer.14.output.dense.bias', 'base_model.encoder.layer.6.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.12.intermediate.dense.weight', 'base_model.encoder.layer.20.output.LayerNorm.bias', 'base_model.encoder.layer.4.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.23.attention.output.dense.bias', 'base_model.encoder.layer.20.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.2.attention.output.dense.bias', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.22.output.dense.bias', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.2.attention.output.LayerNorm.weight', 'base_model.encoder.layer.12.attention.self.key.weight', 'base_model.encoder.layer.6.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.20.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.6.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.8.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.1.output.LayerNorm.bias', 'base_model.encoder.layer.9.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.21.output.LayerNorm.bias', 'base_model.encoder.layer.6.output.LayerNorm.bias', 'base_model.encoder.layer.12.attention.output.dense.bias', 'base_model.encoder.layer.21.intermediate.dense.weight', 'base_model.encoder.layer.23.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.11.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.1.attention.output.LayerNorm.weight', 'base_model.encoder.layer.15.attention.output.dense.bias', 'base_model.encoder.layer.19.attention.output.LayerNorm.bias', 'base_model.encoder.layer.4.attention.self.key.weight', 'base_model.encoder.layer.0.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.6.intermediate.dense.weight', 'base_model.encoder.layer.3.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.10.attention.self.query.bias', 'base_model.encoder.layer.21.attention.output.dense.bias', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.2.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.18.intermediate.dense.weight', 'base_model.encoder.layer.5.output.LayerNorm.bias', 'base_model.encoder.layer.7.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.14.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.20.intermediate.dense.bias', 'base_model.encoder.layer.4.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.4.attention.self.key.bias', 'base_model.encoder.layer.6.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.8.output.dense.bias', 'base_model.encoder.layer.12.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.2.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.19.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.23.intermediate.dense.weight', 'base_model.encoder.layer.0.attention.output.dense.weight', 'base_model.encoder.layer.0.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.10.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.15.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.4.attention.self.query.bias', 'base_model.encoder.layer.2.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.8.intermediate.dense.weight', 'base_model.encoder.layer.8.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.21.intermediate.dense.bias', 'base_model.encoder.layer.15.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.4.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.5.attention.self.query.weight', 'base_model.encoder.layer.20.attention.self.key.weight', 'base_model.encoder.layer.21.attention.output.LayerNorm.weight', 'base_model.encoder.layer.23.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.13.attention.self.query.bias', 'base_model.encoder.layer.16.attention.self.query.weight', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.23.attention.output.dense.weight', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.6.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.15.attention.output.dense.weight', 'base_model.encoder.layer.17.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.14.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.6.output.adapters.ts.adapter_down.0.weight', 'base_model.embeddings.word_embeddings.weight', 'base_model.encoder.layer.14.attention.self.key.bias', 'base_model.encoder.layer.17.attention.output.dense.bias', 'base_model.encoder.layer.17.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.18.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.16.attention.self.key.bias', 'base_model.embeddings.LayerNorm.bias', 'base_model.encoder.layer.21.output.dense.bias', 'base_model.encoder.layer.5.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.17.attention.output.LayerNorm.bias', 'base_model.encoder.layer.14.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.19.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.14.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.19.output.adapters.ep.adapter_down.0.bias', 'base_model.embeddings.token_type_embeddings.weight', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.6.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.22.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.18.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.13.output.dense.weight', 'base_model.encoder.layer.22.attention.output.LayerNorm.bias', 'base_model.encoder.layer.17.intermediate.dense.weight', 'base_model.encoder.layer.21.attention.output.dense.weight', 'base_model.encoder.layer.10.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.16.attention.output.dense.weight', 'base_model.encoder.layer.5.intermediate.dense.weight', 'base_model.encoder.layer.21.attention.self.query.weight', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.7.attention.output.LayerNorm.bias', 'base_model.encoder.layer.1.output.dense.weight', 'base_model.encoder.layer.22.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.4.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.18.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.0.output.dense.weight', 'qa_outputs.bias', 'base_model.encoder.layer.9.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.5.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.11.output.dense.bias', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.16.output.dense.bias', 'base_model.encoder.layer.10.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.10.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.3.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.4.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.23.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.9.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.3.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.0.attention.output.dense.bias', 'base_model.encoder.layer.14.intermediate.dense.bias', 'base_model.encoder.layer.19.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.13.output.LayerNorm.weight', 'base_model.encoder.layer.9.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.19.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.7.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.7.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.10.attention.self.query.weight', 'base_model.encoder.layer.11.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.2.intermediate.dense.bias', 'base_model.encoder.layer.7.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.22.attention.output.LayerNorm.weight', 'base_model.encoder.layer.9.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.10.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.12.output.dense.weight', 'base_model.encoder.layer.23.attention.self.key.bias', 'base_model.encoder.layer.12.intermediate.dense.bias', 'base_model.encoder.layer.8.output.dense.weight', 'base_model.encoder.layer.11.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.17.intermediate.dense.bias', 'base_model.encoder.layer.1.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.16.attention.self.value.weight', 'base_model.encoder.layer.7.output.LayerNorm.bias', 'base_model.encoder.layer.10.attention.self.value.weight', 'base_model.encoder.layer.11.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.23.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.14.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.20.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.2.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.2.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.9.attention.output.dense.bias', 'base_model.encoder.layer.10.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.0.intermediate.dense.weight', 'base_model.encoder.layer.1.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.0.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.19.attention.output.dense.weight', 'base_model.encoder.layer.13.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.23.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.3.attention.self.key.bias', 'base_model.encoder.layer.4.output.dense.weight', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.4.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.23.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.18.intermediate.dense.bias', 'base_model.encoder.layer.16.intermediate.dense.weight', 'base_model.encoder.layer.20.attention.self.value.weight', 'base_model.encoder.layer.11.output.LayerNorm.bias', 'base_model.encoder.layer.16.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.4.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.12.attention.self.query.weight', 'base_model.encoder.layer.7.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.17.attention.self.key.bias', 'base_model.encoder.layer.7.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.12.output.LayerNorm.bias', 'base_model.encoder.layer.17.attention.output.dense.weight', 'base_model.encoder.layer.12.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.0.attention.self.value.bias', 'base_model.encoder.layer.6.attention.self.key.bias', 'base_model.encoder.layer.18.attention.self.key.weight', 'base_model.encoder.layer.6.attention.self.query.bias', 'base_model.encoder.layer.12.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.7.attention.self.key.weight', 'base_model.encoder.layer.12.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.14.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.16.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.9.intermediate.dense.bias', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.21.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.13.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.12.attention.output.dense.weight', 'base_model.encoder.layer.7.output.LayerNorm.weight', 'base_model.encoder.layer.3.attention.output.LayerNorm.bias', 'base_model.encoder.layer.5.attention.self.query.bias', 'base_model.encoder.layer.6.intermediate.dense.bias', 'base_model.encoder.layer.9.attention.self.key.weight', 'base_model.encoder.layer.15.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.12.attention.output.LayerNorm.weight', 'base_model.encoder.layer.16.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.19.intermediate.dense.bias', 'base_model.encoder.layer.12.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.2.attention.self.value.weight', 'base_model.encoder.layer.10.attention.self.key.bias', 'base_model.encoder.layer.19.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.13.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.4.attention.output.dense.weight', 'base_model.encoder.layer.21.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.4.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.8.attention.output.dense.weight', 'base_model.encoder.layer.22.output.adapters.es.adapter_up.bias', 'base_model.embeddings.position_ids', 'base_model.encoder.layer.16.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.8.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.6.attention.self.value.bias', 'base_model.encoder.layer.21.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.11.attention.self.query.bias', 'base_model.encoder.layer.11.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.6.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.14.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.18.attention.self.value.bias', 'base_model.encoder.layer.18.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.12.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.17.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.6.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.14.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.3.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.21.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.1.attention.self.value.weight', 'base_model.encoder.layer.2.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.15.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.18.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.23.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.2.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.3.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.15.attention.self.value.bias', 'qa_outputs.weight', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.15.attention.self.query.bias', 'base_model.encoder.layer.2.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.22.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.11.attention.self.value.bias', 'base_model.encoder.layer.16.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.23.attention.self.value.weight', 'base_model.encoder.layer.12.output.dense.bias', 'base_model.encoder.layer.4.attention.self.value.bias', 'base_model.encoder.layer.21.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.18.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.5.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.8.intermediate.dense.bias', 'base_model.encoder.layer.16.attention.self.query.bias', 'base_model.encoder.layer.13.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.1.attention.self.key.weight', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.5.output.dense.weight', 'base_model.encoder.layer.12.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.2.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.8.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.2.output.dense.weight', 'base_model.encoder.layer.3.attention.output.dense.bias', 'base_model.encoder.layer.0.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.4.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.12.output.LayerNorm.weight', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.6.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.23.attention.self.query.weight', 'base_model.encoder.layer.14.attention.output.dense.weight', 'base_model.encoder.layer.20.output.dense.bias', 'base_model.encoder.layer.0.attention.output.LayerNorm.bias', 'base_model.encoder.layer.17.output.dense.weight', 'base_model.encoder.layer.19.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.5.intermediate.dense.bias', 'base_model.encoder.layer.8.attention.self.query.bias', 'base_model.encoder.layer.10.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.1.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.15.output.LayerNorm.bias', 'base_model.encoder.layer.22.attention.self.query.bias', 'base_model.encoder.layer.13.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.6.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.23.attention.output.LayerNorm.weight', 'base_model.encoder.layer.4.attention.output.LayerNorm.bias', 'base_model.encoder.layer.5.attention.output.dense.bias', 'base_model.encoder.layer.17.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.8.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.4.attention.output.LayerNorm.weight', 'base_model.encoder.layer.10.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.1.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.18.output.LayerNorm.bias', 'base_model.encoder.layer.18.attention.self.query.bias', 'base_model.encoder.layer.12.attention.self.value.weight', 'base_model.encoder.layer.0.attention.self.query.bias', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.9.attention.self.value.weight', 'base_model.encoder.layer.11.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.14.attention.self.key.weight', 'base_model.encoder.layer.1.attention.self.value.bias', 'base_model.encoder.layer.23.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.12.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.19.attention.self.key.weight', 'base_model.encoder.layer.1.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.2.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.22.output.LayerNorm.bias', 'base_model.encoder.layer.0.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.8.attention.output.dense.bias', 'base_model.encoder.layer.14.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.18.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.3.attention.self.value.weight', 'base_model.encoder.layer.5.attention.self.key.bias', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.0.output.LayerNorm.weight', 'base_model.encoder.layer.16.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.17.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.23.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.0.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.20.attention.self.query.weight', 'base_model.encoder.layer.13.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.18.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.query.weight']
- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of XLMRobertaModel were not initialized from the model checkpoint at /cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//squad/xlm-KG_LR8e-6_EPOCH2.0_maxlen384_batchsize4_gradacc4 and are newly initialized: ['encoder.layer.4.attention.self.query.bias', 'encoder.layer.7.output.LayerNorm.bias', 'encoder.layer.16.output.dense.weight', 'encoder.layer.23.attention.self.key.bias', 'encoder.layer.2.attention.self.query.weight', 'encoder.layer.23.attention.output.dense.bias', 'encoder.layer.16.intermediate.dense.weight', 'encoder.layer.8.attention.self.key.weight', 'encoder.layer.4.attention.self.key.weight', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.5.attention.output.LayerNorm.weight', 'encoder.layer.21.output.LayerNorm.bias', 'encoder.layer.10.output.dense.weight', 'embeddings.token_type_embeddings.weight', 'encoder.layer.18.attention.self.value.bias', 'encoder.layer.2.attention.self.value.bias', 'encoder.layer.21.attention.output.LayerNorm.weight', 'encoder.layer.15.output.dense.weight', 'encoder.layer.16.attention.output.dense.bias', 'encoder.layer.5.attention.output.dense.bias', 'encoder.layer.16.attention.self.key.bias', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.1.output.dense.bias', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.2.attention.output.LayerNorm.bias', 'encoder.layer.13.attention.output.LayerNorm.weight', 'encoder.layer.4.attention.self.key.bias', 'encoder.layer.3.attention.self.query.weight', 'encoder.layer.20.attention.output.dense.bias', 'encoder.layer.6.output.dense.weight', 'encoder.layer.9.attention.self.key.bias', 'encoder.layer.8.attention.output.dense.weight', 'encoder.layer.20.output.dense.weight', 'encoder.layer.19.attention.self.query.weight', 'encoder.layer.19.attention.output.LayerNorm.weight', 'encoder.layer.22.attention.self.query.weight', 'encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.layer.12.attention.self.query.weight', 'encoder.layer.3.output.dense.weight', 'encoder.layer.8.attention.self.value.bias', 'encoder.layer.10.attention.self.key.weight', 'encoder.layer.18.intermediate.dense.weight', 'encoder.layer.4.output.dense.bias', 'encoder.layer.20.attention.output.dense.weight', 'encoder.layer.10.output.LayerNorm.weight', 'encoder.layer.10.attention.self.query.bias', 'encoder.layer.4.output.dense.weight', 'encoder.layer.3.attention.self.value.weight', 'encoder.layer.11.output.dense.weight', 'encoder.layer.6.attention.self.query.bias', 'encoder.layer.6.attention.output.LayerNorm.weight', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.20.attention.self.value.bias', 'encoder.layer.16.attention.self.query.weight', 'encoder.layer.12.attention.self.value.bias', 'encoder.layer.14.attention.self.key.weight', 'encoder.layer.14.intermediate.dense.bias', 'encoder.layer.20.output.LayerNorm.weight', 'encoder.layer.12.attention.output.dense.bias', 'encoder.layer.0.attention.self.value.weight', 'encoder.layer.20.attention.output.LayerNorm.weight', 'encoder.layer.11.attention.self.key.bias', 'encoder.layer.2.attention.output.LayerNorm.weight', 'encoder.layer.8.attention.output.dense.bias', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.layer.15.attention.output.dense.weight', 'encoder.layer.15.intermediate.dense.weight', 'encoder.layer.13.output.LayerNorm.bias', 'encoder.layer.1.attention.self.key.weight', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.17.attention.self.value.weight', 'encoder.layer.18.intermediate.dense.bias', 'encoder.layer.22.attention.self.key.weight', 'encoder.layer.9.attention.output.dense.bias', 'encoder.layer.12.attention.output.LayerNorm.weight', 'encoder.layer.22.output.dense.weight', 'encoder.layer.2.attention.self.key.bias', 'encoder.layer.14.attention.output.LayerNorm.weight', 'encoder.layer.17.output.LayerNorm.bias', 'encoder.layer.17.attention.self.value.bias', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.12.intermediate.dense.weight', 'encoder.layer.16.attention.output.LayerNorm.bias', 'encoder.layer.0.attention.self.key.bias', 'encoder.layer.19.attention.output.LayerNorm.bias', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.10.output.dense.bias', 'encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.18.output.dense.bias', 'encoder.layer.11.attention.output.dense.bias', 'encoder.layer.9.attention.output.LayerNorm.bias', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.1.attention.self.query.bias', 'encoder.layer.9.attention.output.dense.weight', 'encoder.layer.0.attention.output.LayerNorm.weight', 'encoder.layer.1.attention.output.dense.bias', 'encoder.layer.1.output.dense.weight', 'encoder.layer.19.attention.self.key.weight', 'encoder.layer.22.attention.self.key.bias', 'encoder.layer.0.attention.output.dense.bias', 'encoder.layer.2.attention.output.dense.weight', 'encoder.layer.20.attention.self.key.bias', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.11.attention.self.value.bias', 'encoder.layer.10.attention.self.key.bias', 'encoder.layer.10.output.LayerNorm.bias', 'encoder.layer.20.attention.self.query.bias', 'encoder.layer.6.attention.self.key.bias', 'encoder.layer.15.attention.self.query.bias', 'encoder.layer.23.attention.output.LayerNorm.bias', 'encoder.layer.19.output.LayerNorm.bias', 'encoder.layer.2.output.dense.weight', 'encoder.layer.22.attention.self.value.bias', 'encoder.layer.4.attention.output.dense.weight', 'encoder.layer.4.attention.self.value.bias', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.13.attention.output.LayerNorm.bias', 'encoder.layer.13.attention.output.dense.weight', 'encoder.layer.15.attention.output.dense.bias', 'encoder.layer.20.intermediate.dense.weight', 'encoder.layer.20.attention.self.key.weight', 'encoder.layer.23.attention.self.value.bias', 'encoder.layer.8.output.dense.weight', 'encoder.layer.11.attention.self.value.weight', 'encoder.layer.17.attention.self.query.weight', 'encoder.layer.22.attention.output.LayerNorm.weight', 'encoder.layer.18.attention.self.key.weight', 'encoder.layer.4.attention.output.LayerNorm.bias', 'encoder.layer.0.output.dense.bias', 'encoder.layer.14.intermediate.dense.weight', 'encoder.layer.17.attention.self.query.bias', 'encoder.layer.6.attention.self.query.weight', 'encoder.layer.19.attention.output.dense.weight', 'encoder.layer.0.attention.self.value.bias', 'encoder.layer.12.output.LayerNorm.bias', 'encoder.layer.22.output.dense.bias', 'encoder.layer.16.output.LayerNorm.bias', 'encoder.layer.9.output.LayerNorm.weight', 'encoder.layer.22.attention.output.dense.bias', 'encoder.layer.14.output.dense.weight', 'encoder.layer.18.attention.output.LayerNorm.bias', 'encoder.layer.8.attention.self.query.weight', 'encoder.layer.22.attention.self.query.bias', 'encoder.layer.23.intermediate.dense.bias', 'encoder.layer.20.attention.self.value.weight', 'encoder.layer.12.attention.self.key.weight', 'encoder.layer.21.intermediate.dense.weight', 'encoder.layer.21.attention.output.dense.weight', 'pooler.dense.weight', 'encoder.layer.0.output.dense.weight', 'encoder.layer.9.output.LayerNorm.bias', 'encoder.layer.23.output.dense.weight', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.17.output.dense.weight', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.17.attention.output.LayerNorm.weight', 'encoder.layer.8.attention.output.LayerNorm.weight', 'encoder.layer.21.output.dense.weight', 'encoder.layer.21.attention.self.query.weight', 'encoder.layer.23.output.LayerNorm.bias', 'pooler.dense.bias', 'encoder.layer.5.output.LayerNorm.bias', 'encoder.layer.8.attention.self.key.bias', 'encoder.layer.12.attention.self.key.bias', 'encoder.layer.22.attention.output.LayerNorm.bias', 'encoder.layer.22.output.LayerNorm.weight', 'encoder.layer.15.attention.self.key.weight', 'encoder.layer.19.output.LayerNorm.weight', 'encoder.layer.8.attention.self.value.weight', 'encoder.layer.14.attention.self.value.weight', 'encoder.layer.15.attention.self.value.weight', 'encoder.layer.7.output.dense.weight', 'encoder.layer.10.attention.self.value.bias', 'encoder.layer.7.attention.self.query.weight', 'encoder.layer.18.attention.output.dense.bias', 'encoder.layer.21.attention.output.dense.bias', 'encoder.layer.21.attention.self.key.bias', 'encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.layer.21.attention.self.value.bias', 'encoder.layer.9.attention.self.query.bias', 'encoder.layer.22.attention.output.dense.weight', 'encoder.layer.2.attention.output.dense.bias', 'encoder.layer.12.output.dense.bias', 'encoder.layer.10.attention.self.query.weight', 'encoder.layer.17.attention.output.dense.bias', 'encoder.layer.18.attention.self.value.weight', 'encoder.layer.14.output.LayerNorm.weight', 'encoder.layer.9.attention.self.key.weight', 'encoder.layer.18.attention.self.key.bias', 'encoder.layer.7.attention.output.LayerNorm.bias', 'encoder.layer.12.attention.output.dense.weight', 'encoder.layer.13.attention.self.query.bias', 'encoder.layer.17.intermediate.dense.bias', 'encoder.layer.19.attention.self.key.bias', 'encoder.layer.0.attention.self.key.weight', 'encoder.layer.23.attention.self.query.bias', 'encoder.layer.21.output.dense.bias', 'encoder.layer.23.attention.output.dense.weight', 'encoder.layer.14.output.LayerNorm.bias', 'encoder.layer.7.attention.self.value.bias', 'encoder.layer.2.attention.self.query.bias', 'encoder.layer.19.attention.self.value.weight', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.17.output.LayerNorm.weight', 'encoder.layer.18.output.LayerNorm.bias', 'encoder.layer.7.attention.self.value.weight', 'encoder.layer.12.attention.output.LayerNorm.bias', 'encoder.layer.17.intermediate.dense.weight', 'embeddings.LayerNorm.bias', 'encoder.layer.5.output.dense.bias', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.4.attention.output.LayerNorm.weight', 'encoder.layer.6.attention.output.dense.weight', 'encoder.layer.11.attention.output.LayerNorm.weight', 'encoder.layer.23.output.LayerNorm.weight', 'encoder.layer.17.attention.self.key.weight', 'encoder.layer.1.attention.self.value.bias', 'encoder.layer.13.output.dense.bias', 'encoder.layer.1.attention.self.query.weight', 'encoder.layer.20.attention.self.query.weight', 'encoder.layer.16.output.LayerNorm.weight', 'encoder.layer.6.attention.output.LayerNorm.bias', 'encoder.layer.12.output.LayerNorm.weight', 'encoder.layer.14.attention.output.dense.weight', 'encoder.layer.6.output.dense.bias', 'encoder.layer.10.attention.output.LayerNorm.weight', 'encoder.layer.11.attention.self.query.weight', 'encoder.layer.15.output.LayerNorm.weight', 'encoder.layer.20.output.LayerNorm.bias', 'encoder.layer.12.intermediate.dense.bias', 'encoder.layer.19.attention.self.value.bias', 'encoder.layer.17.attention.self.key.bias', 'encoder.layer.18.attention.output.dense.weight', 'encoder.layer.9.attention.self.query.weight', 'encoder.layer.13.output.LayerNorm.weight', 'encoder.layer.19.output.dense.weight', 'encoder.layer.4.attention.output.dense.bias', 'encoder.layer.3.attention.self.value.bias', 'encoder.layer.5.attention.output.dense.weight', 'encoder.layer.8.output.LayerNorm.weight', 'encoder.layer.9.attention.output.LayerNorm.weight', 'encoder.layer.2.output.dense.bias', 'encoder.layer.11.output.LayerNorm.bias', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.16.attention.self.value.bias', 'encoder.layer.13.attention.self.value.weight', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.18.attention.output.LayerNorm.weight', 'encoder.layer.14.attention.output.dense.bias', 'encoder.layer.23.attention.self.value.weight', 'encoder.layer.15.intermediate.dense.bias', 'encoder.layer.19.output.dense.bias', 'encoder.layer.16.intermediate.dense.bias', 'encoder.layer.7.attention.self.key.bias', 'encoder.layer.14.output.dense.bias', 'encoder.layer.6.output.LayerNorm.bias', 'encoder.layer.13.attention.self.query.weight', 'encoder.layer.1.attention.self.key.bias', 'encoder.layer.6.attention.self.value.weight', 'encoder.layer.4.attention.self.query.weight', 'encoder.layer.10.intermediate.dense.weight', 'encoder.layer.14.attention.self.query.bias', 'encoder.layer.23.intermediate.dense.weight', 'encoder.layer.21.attention.self.key.weight', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.14.attention.output.LayerNorm.bias', 'encoder.layer.9.attention.self.value.bias', 'embeddings.word_embeddings.weight', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.5.attention.self.query.weight', 'encoder.layer.7.attention.self.query.bias', 'encoder.layer.22.intermediate.dense.weight', 'encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.layer.13.output.dense.weight', 'encoder.layer.1.attention.self.value.weight', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.13.intermediate.dense.bias', 'encoder.layer.18.output.LayerNorm.weight', 'encoder.layer.16.attention.output.dense.weight', 'encoder.layer.20.attention.output.LayerNorm.bias', 'encoder.layer.21.output.LayerNorm.weight', 'encoder.layer.19.attention.output.dense.bias', 'encoder.layer.15.attention.self.query.weight', 'encoder.layer.3.attention.self.query.bias', 'encoder.layer.7.intermediate.dense.bias', 'encoder.layer.7.attention.output.LayerNorm.weight', 'encoder.layer.22.output.LayerNorm.bias', 'encoder.layer.11.attention.output.dense.weight', 'encoder.layer.20.intermediate.dense.bias', 'encoder.layer.15.attention.output.LayerNorm.weight', 'encoder.layer.21.attention.self.value.weight', 'encoder.layer.8.output.dense.bias', 'encoder.layer.9.output.dense.weight', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.18.output.dense.weight', 'encoder.layer.7.attention.output.dense.weight', 'encoder.layer.5.output.dense.weight', 'encoder.layer.13.attention.self.key.weight', 'encoder.layer.16.attention.self.value.weight', 'encoder.layer.8.attention.output.LayerNorm.bias', 'encoder.layer.6.attention.output.dense.bias', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.19.attention.self.query.bias', 'encoder.layer.6.attention.self.value.bias', 'encoder.layer.11.output.LayerNorm.weight', 'encoder.layer.13.attention.self.value.bias', 'encoder.layer.11.attention.self.key.weight', 'encoder.layer.18.attention.self.query.bias', 'encoder.layer.10.attention.output.dense.bias', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.22.intermediate.dense.bias', 'encoder.layer.3.attention.self.key.weight', 'encoder.layer.21.attention.self.query.bias', 'encoder.layer.5.attention.self.value.bias', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.13.attention.self.key.bias', 'encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.layer.3.output.dense.bias', 'encoder.layer.12.attention.self.value.weight', 'encoder.layer.3.attention.output.dense.bias', 'encoder.layer.15.attention.output.LayerNorm.bias', 'encoder.layer.6.attention.self.key.weight', 'encoder.layer.10.attention.output.dense.weight', 'encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.layer.5.attention.self.key.bias', 'encoder.layer.0.attention.self.query.bias', 'encoder.layer.19.intermediate.dense.weight', 'encoder.layer.20.output.dense.bias', 'encoder.layer.15.output.dense.bias', 'encoder.layer.22.attention.self.value.weight', 'encoder.layer.16.attention.self.query.bias', 'encoder.layer.11.output.dense.bias', 'encoder.layer.2.attention.self.value.weight', 'encoder.layer.23.output.dense.bias', 'encoder.layer.8.output.LayerNorm.bias', 'encoder.layer.16.attention.self.key.weight', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.11.attention.self.query.bias', 'encoder.layer.17.output.dense.bias', 'encoder.layer.9.attention.self.value.weight', 'encoder.layer.16.attention.output.LayerNorm.weight', 'encoder.layer.5.attention.self.key.weight', 'encoder.layer.23.attention.output.LayerNorm.weight', 'embeddings.LayerNorm.weight', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.3.attention.output.dense.weight', 'encoder.layer.7.attention.output.dense.bias', 'encoder.layer.15.attention.self.key.bias', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.13.attention.output.dense.bias', 'encoder.layer.23.attention.self.key.weight', 'encoder.layer.13.intermediate.dense.weight', 'encoder.layer.5.attention.self.value.weight', 'encoder.layer.0.attention.output.dense.weight', 'encoder.layer.2.attention.self.key.weight', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.8.attention.self.query.bias', 'encoder.layer.21.attention.output.LayerNorm.bias', 'encoder.layer.10.attention.output.LayerNorm.bias', 'encoder.layer.1.attention.output.LayerNorm.weight', 'encoder.layer.19.intermediate.dense.bias', 'encoder.layer.16.output.dense.bias', 'encoder.layer.3.attention.self.key.bias', 'encoder.layer.14.attention.self.value.bias', 'encoder.layer.7.output.LayerNorm.weight', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.0.attention.self.query.weight', 'encoder.layer.7.output.dense.bias', 'encoder.layer.1.attention.output.dense.weight', 'encoder.layer.18.attention.self.query.weight', 'encoder.layer.15.attention.self.value.bias', 'encoder.layer.5.attention.self.query.bias', 'encoder.layer.12.output.dense.weight', 'encoder.layer.23.attention.self.query.weight', 'encoder.layer.3.intermediate.dense.weight', 'embeddings.position_embeddings.weight', 'encoder.layer.4.attention.self.value.weight', 'encoder.layer.15.output.LayerNorm.bias', 'encoder.layer.7.attention.self.key.weight', 'encoder.layer.17.attention.output.LayerNorm.bias', 'encoder.layer.12.attention.self.query.bias', 'encoder.layer.10.attention.self.value.weight', 'encoder.layer.9.output.dense.bias', 'encoder.layer.21.intermediate.dense.bias', 'encoder.layer.14.attention.self.query.weight', 'encoder.layer.14.attention.self.key.bias', 'encoder.layer.17.attention.output.dense.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Overwriting existing adapter 'ep'.
Overwriting existing adapter 'tp'.
Overwriting existing adapter 'es'.
Overwriting existing adapter 'ts'.
Overwriting existing adapter fusion module 'ep,tp,es,ts'
/cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//squad/xlm-KG_LR8e-6_EPOCH2.0_maxlen384_batchsize4_gradacc4
XLMConfig {
  "architectures": [
    "XLMRobertaForMaskedLM"
  ],
  "asm": false,
  "attention_dropout": 0.1,
  "attention_probs_dropout_prob": 0.1,
  "bos_index": 0,
  "bos_token_id": 0,
  "causal": false,
  "dropout": 0.1,
  "emb_dim": 1024,
  "embed_init_std": 0.02209708691207961,
  "end_n_top": 5,
  "eos_index": 1,
  "eos_token_id": 2,
  "gelu_activation": true,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "init_std": 0.02,
  "initializer_range": 0.02,
  "intermediate_size": 4096,
  "is_encoder": true,
  "lang_id": 0,
  "layer_norm_eps": 1e-05,
  "mask_index": 5,
  "mask_token_id": 0,
  "max_position_embeddings": 514,
  "model_type": "xlm",
  "n_heads": 16,
  "n_langs": 1,
  "n_layers": 24,
  "output_past": true,
  "pad_index": 2,
  "pad_token_id": 1,
  "sinusoidal_embeddings": false,
  "start_n_top": 5,
  "summary_activation": null,
  "summary_first_dropout": 0.1,
  "summary_proj_to_labels": true,
  "summary_type": "first",
  "summary_use_proj": true,
  "transformers_version": "4.17.0",
  "type_vocab_size": 1,
  "unk_index": 3,
  "use_lang_emb": false,
  "vocab_size": 250002
}

Traceback (most recent call last):
  File "third_party/run_squad.py", line 958, in <module>
    main()
  File "third_party/run_squad.py", line 941, in main
    load_model(model, os.path.join(args.output_dir, "pytorch_model.bin"))
  File "third_party/run_squad.py", line 98, in load_model
    model.load_state_dict(torch.load(path, map_location='cpu'), strict=False)
  File "/cluster/project/sachan/yifan/softwares/anaconda/anaconda3/envs/xfactr/lib/python3.8/site-packages/torch/serialization.py", line 581, in load
    with _open_file_like(f, 'rb') as opened_file:
  File "/cluster/project/sachan/yifan/softwares/anaconda/anaconda3/envs/xfactr/lib/python3.8/site-packages/torch/serialization.py", line 230, in _open_file_like
    return _open_file(name_or_buffer, mode)
  File "/cluster/project/sachan/yifan/softwares/anaconda/anaconda3/envs/xfactr/lib/python3.8/site-packages/torch/serialization.py", line 211, in __init__
    super(_open_file, self).__init__(open(name, mode))
FileNotFoundError: [Errno 2] No such file or directory: '/cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//squad/xlm-KG_LR8e-6_EPOCH2.0_maxlen384_batchsize4_gradacc4/predictions/mlqa/pytorch_model.bin'
  ar 
2022-05-09 21:39:42.059011: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0
05/09/2022 21:39:44 - WARNING - __main__ -   Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, 16-bits training: False
You are using a model of type xlm-roberta to instantiate a model of type xlm. This is not supported for all configurations of models and can yield errors.
Some weights of the model checkpoint at /cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//squad/xlm-KG_LR8e-6_EPOCH2.0_maxlen384_batchsize4_gradacc4 were not used when initializing XLMRobertaModel: ['base_model.encoder.layer.19.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.11.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.0.attention.self.key.weight', 'base_model.encoder.layer.14.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.0.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.10.intermediate.dense.bias', 'base_model.encoder.layer.11.attention.self.value.bias', 'base_model.encoder.layer.14.attention.output.LayerNorm.bias', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.14.attention.output.dense.weight', 'base_model.encoder.layer.16.attention.output.LayerNorm.weight', 'base_model.encoder.layer.17.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.5.attention.self.query.bias', 'base_model.encoder.layer.2.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.5.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.14.output.LayerNorm.bias', 'base_model.encoder.layer.18.attention.self.value.bias', 'base_model.encoder.layer.10.attention.self.value.bias', 'base_model.encoder.layer.15.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.16.attention.output.dense.weight', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.3.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.20.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.23.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.6.intermediate.dense.bias', 'base_model.encoder.layer.5.attention.self.value.bias', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.12.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.4.attention.self.query.weight', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.21.attention.self.value.weight', 'base_model.encoder.layer.21.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.22.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.7.output.LayerNorm.bias', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.2.attention.self.query.bias', 'base_model.encoder.layer.8.attention.self.query.weight', 'base_model.encoder.layer.13.attention.output.dense.bias', 'base_model.encoder.layer.22.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.4.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.11.output.dense.bias', 'base_model.encoder.layer.16.attention.output.LayerNorm.bias', 'base_model.encoder.layer.14.attention.self.value.weight', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.4.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.11.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.10.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.12.attention.self.value.weight', 'base_model.encoder.layer.4.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.4.attention.self.value.weight', 'base_model.encoder.layer.13.attention.output.LayerNorm.weight', 'base_model.encoder.layer.13.attention.output.dense.weight', 'base_model.encoder.layer.6.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.22.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.9.output.dense.weight', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.17.intermediate.dense.weight', 'base_model.encoder.layer.6.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.17.output.dense.weight', 'base_model.encoder.layer.0.intermediate.dense.weight', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.21.attention.output.LayerNorm.weight', 'base_model.encoder.layer.23.attention.self.query.weight', 'base_model.encoder.layer.16.output.LayerNorm.weight', 'base_model.encoder.layer.16.intermediate.dense.bias', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.20.intermediate.dense.weight', 'base_model.encoder.layer.20.attention.output.dense.bias', 'base_model.encoder.layer.23.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.7.output.LayerNorm.weight', 'base_model.encoder.layer.18.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.11.attention.output.dense.weight', 'base_model.encoder.layer.14.attention.self.key.weight', 'base_model.encoder.layer.20.attention.output.LayerNorm.bias', 'base_model.encoder.layer.1.attention.self.value.weight', 'base_model.encoder.layer.18.output.dense.bias', 'base_model.encoder.layer.21.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.4.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.17.attention.self.key.bias', 'base_model.encoder.layer.18.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.23.attention.self.query.bias', 'base_model.encoder.layer.14.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.10.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.22.attention.self.value.weight', 'base_model.encoder.layer.8.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.21.attention.self.key.bias', 'base_model.encoder.layer.2.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.9.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.22.attention.self.key.weight', 'base_model.encoder.layer.20.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.22.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.17.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.16.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.9.attention.output.dense.weight', 'base_model.encoder.layer.20.output.LayerNorm.bias', 'base_model.encoder.layer.13.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.19.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.2.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.12.attention.output.dense.weight', 'base_model.encoder.layer.0.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.11.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.9.attention.output.LayerNorm.weight', 'base_model.encoder.layer.12.attention.output.dense.bias', 'base_model.encoder.layer.0.output.LayerNorm.weight', 'base_model.encoder.layer.14.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.15.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.8.attention.output.dense.weight', 'base_model.encoder.layer.12.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.6.output.LayerNorm.weight', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.1.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.13.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.13.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.17.attention.self.query.bias', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.1.output.dense.bias', 'base_model.encoder.layer.3.attention.self.key.weight', 'base_model.encoder.layer.5.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.5.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.7.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.12.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.2.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.7.attention.self.key.bias', 'base_model.encoder.layer.8.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.8.intermediate.dense.bias', 'base_model.encoder.layer.6.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.3.attention.self.value.bias', 'base_model.encoder.layer.10.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.19.attention.output.LayerNorm.bias', 'base_model.encoder.layer.23.attention.self.key.bias', 'base_model.encoder.layer.5.output.dense.bias', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.15.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.17.attention.output.dense.weight', 'base_model.encoder.layer.1.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.21.attention.output.dense.bias', 'base_model.encoder.layer.8.attention.self.key.weight', 'base_model.encoder.layer.14.attention.self.value.bias', 'base_model.encoder.layer.2.output.dense.weight', 'base_model.encoder.layer.13.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.0.attention.output.LayerNorm.weight', 'base_model.encoder.layer.23.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.21.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.11.attention.self.query.bias', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.3.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.20.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.21.attention.output.LayerNorm.bias', 'base_model.encoder.layer.2.intermediate.dense.bias', 'base_model.encoder.layer.9.intermediate.dense.bias', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.14.intermediate.dense.bias', 'base_model.encoder.layer.6.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.19.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.0.output.LayerNorm.bias', 'base_model.encoder.layer.3.output.dense.bias', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.22.attention.self.query.bias', 'base_model.encoder.layer.7.attention.self.key.weight', 'base_model.encoder.layer.3.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.15.attention.output.LayerNorm.bias', 'base_model.encoder.layer.15.intermediate.dense.weight', 'base_model.encoder.layer.6.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.16.attention.self.query.bias', 'base_model.encoder.layer.19.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.15.attention.self.value.bias', 'base_model.encoder.layer.15.attention.self.query.bias', 'base_model.encoder.layer.11.intermediate.dense.bias', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.21.attention.self.query.weight', 'base_model.encoder.layer.17.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.20.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.21.output.LayerNorm.weight', 'base_model.encoder.layer.9.output.dense.bias', 'base_model.encoder.layer.2.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.15.attention.output.dense.bias', 'base_model.encoder.layer.23.attention.output.dense.weight', 'base_model.encoder.layer.2.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.6.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.6.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.6.attention.self.key.bias', 'base_model.encoder.layer.8.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.1.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.7.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.17.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.13.attention.self.query.bias', 'base_model.encoder.layer.12.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.4.intermediate.dense.weight', 'base_model.encoder.layer.21.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.14.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.1.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.1.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.8.output.dense.weight', 'base_model.encoder.layer.2.attention.self.key.bias', 'base_model.encoder.layer.22.intermediate.dense.weight', 'base_model.encoder.layer.15.intermediate.dense.bias', 'base_model.encoder.layer.13.attention.self.key.bias', 'base_model.encoder.layer.20.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.19.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.7.attention.self.query.weight', 'base_model.encoder.layer.22.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.13.attention.self.query.weight', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.2.output.dense.bias', 'base_model.encoder.layer.9.attention.self.value.bias', 'base_model.encoder.layer.16.attention.self.key.weight', 'base_model.encoder.layer.11.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.18.output.dense.weight', 'base_model.encoder.layer.22.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.9.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.22.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.5.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.8.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.11.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.17.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.14.output.LayerNorm.weight', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.17.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.2.attention.output.LayerNorm.weight', 'base_model.encoder.layer.10.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.11.attention.output.dense.bias', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.12.attention.self.query.weight', 'base_model.encoder.layer.12.attention.output.LayerNorm.weight', 'base_model.encoder.layer.1.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.3.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.6.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.11.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.4.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.20.output.adapters.ts.adapter_down.0.weight', 'base_model.embeddings.LayerNorm.weight', 'base_model.encoder.layer.8.output.dense.bias', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.5.output.dense.weight', 'base_model.encoder.layer.22.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.7.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.22.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.5.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.19.attention.output.dense.bias', 'base_model.encoder.layer.16.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.4.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.11.attention.self.query.weight', 'base_model.encoder.layer.16.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.2.output.LayerNorm.weight', 'base_model.encoder.layer.12.output.LayerNorm.weight', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.4.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.18.intermediate.dense.bias', 'base_model.encoder.layer.12.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.0.attention.output.LayerNorm.bias', 'base_model.encoder.layer.5.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.7.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.17.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.20.attention.output.dense.weight', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.21.attention.self.query.bias', 'base_model.encoder.layer.23.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.7.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.2.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.5.intermediate.dense.bias', 'base_model.encoder.layer.12.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.15.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.0.attention.output.dense.bias', 'base_model.encoder.layer.17.output.LayerNorm.bias', 'base_model.encoder.layer.0.output.dense.bias', 'base_model.encoder.layer.4.output.dense.weight', 'base_model.encoder.layer.11.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.17.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.19.intermediate.dense.bias', 'base_model.encoder.layer.23.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.6.attention.self.query.weight', 'base_model.encoder.layer.10.attention.self.query.bias', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.22.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.19.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.18.attention.output.LayerNorm.weight', 'base_model.encoder.layer.3.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.16.attention.self.value.weight', 'base_model.encoder.layer.15.attention.self.query.weight', 'base_model.encoder.layer.15.attention.self.key.weight', 'base_model.encoder.layer.1.attention.self.key.bias', 'base_model.encoder.layer.15.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.17.attention.output.LayerNorm.bias', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.9.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.16.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.17.attention.self.query.weight', 'base_model.encoder.layer.11.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.12.attention.output.LayerNorm.bias', 'base_model.encoder.layer.19.attention.output.LayerNorm.weight', 'base_model.encoder.layer.6.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.15.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.9.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.10.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.6.attention.output.dense.bias', 'base_model.encoder.layer.10.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.17.attention.output.LayerNorm.weight', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.0.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.17.output.dense.bias', 'base_model.encoder.layer.13.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.22.output.LayerNorm.bias', 'base_model.encoder.layer.0.attention.output.dense.weight', 'base_model.encoder.layer.7.attention.output.LayerNorm.weight', 'base_model.encoder.layer.2.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.21.attention.output.dense.weight', 'base_model.encoder.layer.8.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.17.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.4.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.23.attention.output.LayerNorm.bias', 'base_model.encoder.layer.14.output.dense.weight', 'base_model.encoder.layer.0.attention.self.key.bias', 'base_model.encoder.layer.2.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.9.attention.self.query.bias', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.16.output.LayerNorm.bias', 'base_model.encoder.layer.18.attention.output.dense.weight', 'base_model.encoder.layer.9.attention.output.dense.bias', 'base_model.encoder.layer.5.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.20.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.20.intermediate.dense.bias', 'base_model.encoder.layer.8.attention.output.LayerNorm.bias', 'base_model.encoder.layer.10.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.5.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.19.attention.output.dense.weight', 'base_model.encoder.layer.8.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.16.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.18.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.18.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.12.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.18.attention.self.value.weight', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.4.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.22.attention.output.dense.weight', 'base_model.encoder.layer.3.attention.self.query.weight', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.5.attention.output.dense.bias', 'base_model.encoder.layer.18.attention.self.query.weight', 'base_model.encoder.layer.4.output.dense.bias', 'base_model.encoder.layer.13.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.6.output.dense.weight', 'base_model.encoder.layer.6.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.4.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.22.attention.output.dense.bias', 'base_model.encoder.layer.13.output.dense.weight', 'qa_outputs.bias', 'base_model.encoder.layer.13.output.dense.bias', 'base_model.encoder.layer.16.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.15.attention.self.key.bias', 'base_model.encoder.layer.3.output.LayerNorm.weight', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.19.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.14.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.6.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.14.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.21.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.13.attention.self.value.weight', 'base_model.encoder.layer.3.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.2.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.21.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.5.intermediate.dense.weight', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.11.attention.self.key.bias', 'base_model.encoder.layer.7.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.13.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.7.attention.output.LayerNorm.bias', 'base_model.encoder.layer.16.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.8.intermediate.dense.weight', 'base_model.encoder.layer.12.attention.self.value.bias', 'base_model.encoder.layer.1.attention.output.LayerNorm.weight', 'base_model.encoder.layer.18.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.17.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.13.attention.self.value.bias', 'base_model.encoder.layer.14.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.3.attention.output.dense.weight', 'base_model.encoder.layer.1.attention.self.key.weight', 'base_model.encoder.layer.17.output.LayerNorm.weight', 'base_model.encoder.layer.1.attention.self.query.weight', 'base_model.encoder.layer.16.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.2.output.LayerNorm.bias', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.1.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.16.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.7.intermediate.dense.weight', 'base_model.encoder.layer.8.output.LayerNorm.bias', 'base_model.encoder.layer.8.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.15.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.21.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.14.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.2.attention.self.value.bias', 'base_model.encoder.layer.3.attention.output.dense.bias', 'base_model.encoder.layer.5.attention.output.LayerNorm.bias', 'base_model.encoder.layer.11.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.2.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.9.attention.self.key.weight', 'base_model.encoder.layer.12.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.20.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.1.output.LayerNorm.weight', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.0.attention.self.query.bias', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.1.output.dense.weight', 'base_model.encoder.layer.9.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.16.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.19.output.LayerNorm.weight', 'base_model.encoder.layer.15.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.7.intermediate.dense.bias', 'base_model.encoder.layer.10.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.23.attention.self.value.weight', 'base_model.embeddings.position_ids', 'base_model.encoder.layer.3.attention.self.key.bias', 'base_model.encoder.layer.15.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.0.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.5.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.2.attention.self.query.weight', 'base_model.encoder.layer.5.attention.output.dense.weight', 'base_model.encoder.layer.18.intermediate.dense.weight', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.16.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.5.attention.self.key.weight', 'base_model.encoder.layer.1.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.18.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.3.attention.self.query.bias', 'base_model.encoder.layer.18.attention.self.query.bias', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.18.attention.self.key.bias', 'base_model.encoder.layer.1.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.21.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.10.output.LayerNorm.bias', 'base_model.encoder.layer.23.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.4.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.14.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.0.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.4.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.6.attention.self.value.bias', 'base_model.encoder.layer.13.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.11.attention.output.LayerNorm.bias', 'base_model.encoder.layer.20.attention.self.value.bias', 'base_model.encoder.layer.20.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.17.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.23.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.21.intermediate.dense.bias', 'base_model.encoder.layer.5.attention.self.key.bias', 'base_model.encoder.layer.18.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.20.output.LayerNorm.weight', 'base_model.encoder.layer.8.output.LayerNorm.weight', 'base_model.encoder.layer.23.intermediate.dense.weight', 'base_model.encoder.layer.22.output.adapters.ep.adapter_up.bias', 'base_model.embeddings.token_type_embeddings.weight', 'base_model.encoder.layer.5.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.15.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.21.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.4.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.23.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.15.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.6.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.16.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.0.attention.self.query.weight', 'base_model.encoder.layer.19.attention.self.key.weight', 'base_model.encoder.layer.8.attention.self.value.bias', 'base_model.encoder.layer.5.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.11.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.12.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.10.attention.output.LayerNorm.weight', 'base_model.encoder.layer.14.attention.self.query.bias', 'base_model.encoder.layer.0.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.22.output.LayerNorm.weight', 'base_model.encoder.layer.1.intermediate.dense.bias', 'base_model.encoder.layer.11.output.LayerNorm.weight', 'base_model.encoder.layer.15.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.17.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.17.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.1.attention.self.query.bias', 'base_model.encoder.layer.20.output.dense.weight', 'base_model.encoder.layer.21.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.2.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.12.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.18.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.19.attention.self.key.bias', 'base_model.encoder.layer.19.output.adapters.ep.adapter_down.0.weight', 'base_model.pooler.dense.weight', 'base_model.encoder.layer.6.attention.output.dense.weight', 'base_model.encoder.layer.13.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.5.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.9.intermediate.dense.weight', 'base_model.encoder.layer.5.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.18.attention.output.LayerNorm.bias', 'base_model.encoder.layer.14.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.2.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.0.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.9.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.23.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.21.intermediate.dense.weight', 'base_model.encoder.layer.17.attention.output.dense.bias', 'base_model.encoder.layer.20.attention.output.LayerNorm.weight', 'base_model.encoder.layer.16.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.10.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.12.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.23.attention.self.value.bias', 'base_model.encoder.layer.23.output.LayerNorm.weight', 'base_model.encoder.layer.6.output.adapters.ts.adapter_down.0.weight', 'qa_outputs.weight', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.22.output.dense.weight', 'base_model.encoder.layer.1.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.3.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.19.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.18.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.15.output.LayerNorm.bias', 'base_model.encoder.layer.7.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.22.output.dense.bias', 'base_model.encoder.layer.19.intermediate.dense.weight', 'base_model.encoder.layer.23.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.0.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.22.intermediate.dense.bias', 'base_model.encoder.layer.10.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.17.attention.self.value.bias', 'base_model.encoder.layer.23.intermediate.dense.bias', 'base_model.encoder.layer.6.attention.output.LayerNorm.weight', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.8.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.19.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.10.attention.self.value.weight', 'base_model.encoder.layer.7.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.11.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.12.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.19.attention.self.value.bias', 'base_model.encoder.layer.1.attention.self.value.bias', 'base_model.pooler.dense.bias', 'base_model.encoder.layer.22.attention.output.LayerNorm.bias', 'base_model.encoder.layer.5.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.11.attention.self.value.weight', 'base_model.encoder.layer.23.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.11.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.22.attention.self.key.bias', 'base_model.encoder.layer.10.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.11.intermediate.dense.weight', 'base_model.encoder.layer.14.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.23.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.19.output.LayerNorm.bias', 'base_model.encoder.layer.22.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.6.output.LayerNorm.bias', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.13.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.9.attention.self.key.bias', 'base_model.encoder.layer.3.attention.output.LayerNorm.weight', 'base_model.encoder.layer.19.output.dense.bias', 'base_model.encoder.layer.18.output.LayerNorm.bias', 'base_model.encoder.layer.10.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.3.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.8.attention.self.query.bias', 'base_model.encoder.layer.9.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.0.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.16.attention.self.query.weight', 'base_model.encoder.layer.7.attention.output.dense.weight', 'base_model.encoder.layer.22.attention.output.LayerNorm.weight', 'base_model.encoder.layer.7.output.dense.bias', 'base_model.encoder.layer.3.output.LayerNorm.bias', 'base_model.encoder.layer.2.attention.output.LayerNorm.bias', 'base_model.encoder.layer.11.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.13.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.16.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.13.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.16.attention.self.key.bias', 'base_model.encoder.layer.23.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.11.output.dense.weight', 'base_model.encoder.layer.7.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.17.attention.self.value.weight', 'base_model.encoder.layer.10.attention.output.LayerNorm.bias', 'base_model.encoder.layer.17.attention.self.key.weight', 'base_model.encoder.layer.7.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.10.attention.output.dense.bias', 'base_model.encoder.layer.0.intermediate.dense.bias', 'base_model.encoder.layer.1.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.0.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.1.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.3.intermediate.dense.bias', 'base_model.encoder.layer.12.intermediate.dense.bias', 'base_model.encoder.layer.13.attention.output.LayerNorm.bias', 'base_model.encoder.layer.17.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.8.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.23.output.dense.weight', 'base_model.encoder.layer.2.attention.output.dense.weight', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.1.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.18.attention.self.key.weight', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.18.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.18.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.22.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.9.output.LayerNorm.weight', 'base_model.encoder.layer.8.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.2.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.8.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.8.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.18.attention.output.dense.bias', 'base_model.encoder.layer.5.output.LayerNorm.bias', 'base_model.encoder.layer.7.attention.self.value.bias', 'base_model.encoder.layer.6.intermediate.dense.weight', 'base_model.encoder.layer.5.attention.output.LayerNorm.weight', 'base_model.encoder.layer.10.output.LayerNorm.weight', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.21.output.dense.bias', 'base_model.encoder.layer.13.attention.self.key.weight', 'base_model.encoder.layer.10.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.4.attention.output.LayerNorm.weight', 'base_model.encoder.layer.11.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.0.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.13.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.3.attention.output.LayerNorm.bias', 'base_model.encoder.layer.12.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.3.intermediate.dense.weight', 'base_model.encoder.layer.9.attention.self.query.weight', 'base_model.encoder.layer.1.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.18.output.LayerNorm.weight', 'base_model.encoder.layer.1.output.LayerNorm.bias', 'base_model.encoder.layer.14.attention.self.key.bias', 'base_model.encoder.layer.9.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.12.output.dense.bias', 'base_model.encoder.layer.15.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.0.attention.self.value.weight', 'base_model.encoder.layer.1.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.4.output.LayerNorm.weight', 'base_model.encoder.layer.19.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.23.output.dense.bias', 'base_model.encoder.layer.12.attention.self.query.bias', 'base_model.encoder.layer.9.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.22.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.5.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.11.attention.self.key.weight', 'base_model.encoder.layer.9.attention.output.LayerNorm.bias', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.10.output.dense.weight', 'base_model.encoder.layer.2.intermediate.dense.weight', 'base_model.encoder.layer.11.output.LayerNorm.bias', 'base_model.encoder.layer.12.output.LayerNorm.bias', 'base_model.encoder.layer.8.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.9.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.12.intermediate.dense.weight', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.20.attention.self.value.weight', 'base_model.encoder.layer.21.output.dense.weight', 'base_model.encoder.layer.23.attention.output.LayerNorm.weight', 'base_model.encoder.layer.8.attention.self.key.bias', 'base_model.encoder.layer.18.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.10.attention.self.key.weight', 'base_model.embeddings.LayerNorm.bias', 'base_model.encoder.layer.6.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.23.output.LayerNorm.bias', 'base_model.encoder.layer.20.attention.self.key.bias', 'base_model.encoder.layer.20.output.dense.bias', 'base_model.encoder.layer.8.attention.output.dense.bias', 'base_model.encoder.layer.15.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.21.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.20.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.19.output.dense.weight', 'base_model.embeddings.word_embeddings.weight', 'base_model.encoder.layer.20.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.23.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.20.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.3.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.10.attention.output.dense.weight', 'base_model.encoder.layer.7.attention.self.value.weight', 'base_model.encoder.layer.14.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.7.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.19.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.12.output.dense.weight', 'base_model.encoder.layer.18.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.1.intermediate.dense.weight', 'base_model.encoder.layer.3.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.23.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.10.attention.self.key.bias', 'base_model.encoder.layer.13.intermediate.dense.weight', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.19.attention.self.query.weight', 'base_model.encoder.layer.1.attention.output.LayerNorm.bias', 'base_model.encoder.layer.6.output.dense.bias', 'base_model.encoder.layer.14.intermediate.dense.weight', 'base_model.encoder.layer.3.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.16.output.dense.weight', 'base_model.encoder.layer.15.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.10.intermediate.dense.weight', 'base_model.encoder.layer.19.attention.self.query.bias', 'base_model.encoder.layer.14.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.14.attention.output.dense.bias', 'base_model.encoder.layer.6.attention.self.query.bias', 'base_model.encoder.layer.7.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.0.attention.self.value.bias', 'base_model.encoder.layer.2.attention.self.value.weight', 'base_model.encoder.layer.17.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.12.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.20.attention.self.query.bias', 'base_model.encoder.layer.4.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.7.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.4.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.19.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.4.attention.output.LayerNorm.bias', 'base_model.encoder.layer.9.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.20.attention.self.key.weight', 'base_model.encoder.layer.15.output.dense.bias', 'base_model.encoder.layer.19.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.0.output.dense.weight', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.4.attention.self.query.bias', 'base_model.encoder.layer.5.output.LayerNorm.weight', 'base_model.encoder.layer.7.attention.output.dense.bias', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.4.attention.self.key.weight', 'base_model.encoder.layer.4.attention.output.dense.weight', 'base_model.encoder.layer.5.attention.self.value.weight', 'base_model.encoder.layer.6.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.9.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.18.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.16.intermediate.dense.weight', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.22.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.4.intermediate.dense.bias', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.20.attention.self.query.weight', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.1.attention.output.dense.bias', 'base_model.encoder.layer.8.attention.output.LayerNorm.weight', 'base_model.encoder.layer.13.output.LayerNorm.bias', 'base_model.encoder.layer.22.attention.self.query.weight', 'base_model.encoder.layer.10.attention.self.query.weight', 'base_model.encoder.layer.23.attention.self.key.weight', 'base_model.encoder.layer.7.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.11.attention.output.LayerNorm.weight', 'base_model.encoder.layer.20.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.21.attention.self.value.bias', 'base_model.embeddings.position_embeddings.weight', 'base_model.encoder.layer.15.attention.output.LayerNorm.weight', 'base_model.encoder.layer.3.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.6.attention.self.value.weight', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.0.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.21.attention.self.key.weight', 'base_model.encoder.layer.14.attention.self.query.weight', 'base_model.encoder.layer.16.output.dense.bias', 'base_model.encoder.layer.16.attention.self.value.bias', 'base_model.encoder.layer.21.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.9.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.7.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.19.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.9.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.3.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.10.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.2.attention.output.dense.bias', 'base_model.encoder.layer.9.attention.self.value.weight', 'base_model.encoder.layer.15.attention.self.value.weight', 'base_model.encoder.layer.13.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.13.output.LayerNorm.weight', 'base_model.encoder.layer.13.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.5.attention.self.query.weight', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.14.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.12.attention.self.key.bias', 'base_model.encoder.layer.8.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.3.output.dense.weight', 'base_model.encoder.layer.10.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.16.attention.output.dense.bias', 'base_model.encoder.layer.17.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.12.attention.self.key.weight', 'base_model.encoder.layer.16.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.21.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.21.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.22.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.14.output.dense.bias', 'base_model.encoder.layer.14.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.18.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.21.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.4.attention.self.key.bias', 'base_model.encoder.layer.3.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.9.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.4.attention.self.value.bias', 'base_model.encoder.layer.21.output.LayerNorm.bias', 'base_model.encoder.layer.8.attention.self.value.weight', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.6.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.3.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.4.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.15.attention.output.dense.weight', 'base_model.encoder.layer.9.output.LayerNorm.bias', 'base_model.encoder.layer.14.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.0.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.4.output.LayerNorm.bias', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.2.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.7.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.1.attention.output.dense.weight', 'base_model.encoder.layer.1.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.13.intermediate.dense.bias', 'base_model.encoder.layer.0.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.21.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.23.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.20.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.2.attention.self.key.weight', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.16.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.17.intermediate.dense.bias', 'base_model.encoder.layer.23.attention.output.dense.bias', 'base_model.encoder.layer.12.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.5.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.15.output.dense.weight', 'base_model.encoder.layer.7.attention.self.query.bias', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.9.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.8.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.4.attention.output.dense.bias', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.6.attention.output.LayerNorm.bias', 'base_model.encoder.layer.15.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.18.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.10.output.dense.bias', 'base_model.encoder.layer.11.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.3.attention.self.value.weight', 'base_model.encoder.layer.12.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.20.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.13.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.10.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.6.attention.self.key.weight', 'base_model.encoder.layer.19.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.0.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.11.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.7.output.dense.weight', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.8.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.20.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.2.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.19.attention.self.value.weight', 'base_model.encoder.layer.0.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.22.attention.self.value.bias', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.15.output.LayerNorm.weight', 'base_model.encoder.layer.3.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.14.attention.output.LayerNorm.weight']
- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of XLMRobertaModel were not initialized from the model checkpoint at /cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//squad/xlm-KG_LR8e-6_EPOCH2.0_maxlen384_batchsize4_gradacc4 and are newly initialized: ['encoder.layer.0.intermediate.dense.weight', 'encoder.layer.15.output.dense.bias', 'encoder.layer.1.attention.self.key.weight', 'encoder.layer.23.output.LayerNorm.weight', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.19.attention.self.value.bias', 'encoder.layer.6.attention.output.LayerNorm.bias', 'encoder.layer.15.attention.self.value.bias', 'encoder.layer.23.attention.output.LayerNorm.bias', 'encoder.layer.5.attention.self.key.bias', 'encoder.layer.10.output.dense.bias', 'encoder.layer.18.output.dense.weight', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.22.attention.self.key.bias', 'encoder.layer.16.intermediate.dense.bias', 'encoder.layer.13.intermediate.dense.bias', 'encoder.layer.19.intermediate.dense.weight', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.8.output.dense.bias', 'encoder.layer.13.attention.output.dense.weight', 'encoder.layer.9.attention.self.key.weight', 'encoder.layer.0.attention.output.dense.weight', 'encoder.layer.6.attention.self.key.bias', 'encoder.layer.23.output.LayerNorm.bias', 'encoder.layer.21.attention.output.LayerNorm.bias', 'encoder.layer.3.attention.self.key.bias', 'encoder.layer.15.attention.self.query.weight', 'encoder.layer.21.attention.self.value.bias', 'encoder.layer.6.attention.output.LayerNorm.weight', 'encoder.layer.1.attention.self.query.weight', 'encoder.layer.14.attention.self.value.weight', 'encoder.layer.17.attention.self.query.weight', 'encoder.layer.23.intermediate.dense.weight', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.12.attention.output.LayerNorm.bias', 'encoder.layer.19.attention.output.dense.weight', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.0.output.dense.weight', 'encoder.layer.16.attention.self.query.weight', 'encoder.layer.12.output.LayerNorm.bias', 'encoder.layer.21.intermediate.dense.bias', 'encoder.layer.9.attention.self.query.bias', 'encoder.layer.20.intermediate.dense.bias', 'encoder.layer.6.attention.self.value.weight', 'encoder.layer.19.attention.self.key.weight', 'encoder.layer.0.attention.self.query.bias', 'encoder.layer.2.attention.output.LayerNorm.bias', 'encoder.layer.14.attention.self.key.bias', 'encoder.layer.0.attention.self.value.weight', 'encoder.layer.19.output.dense.weight', 'encoder.layer.8.attention.self.key.bias', 'encoder.layer.9.output.dense.bias', 'encoder.layer.14.output.LayerNorm.weight', 'encoder.layer.21.intermediate.dense.weight', 'encoder.layer.17.output.LayerNorm.bias', 'encoder.layer.22.output.LayerNorm.bias', 'encoder.layer.13.output.dense.weight', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.4.attention.self.query.weight', 'encoder.layer.11.output.dense.weight', 'encoder.layer.22.attention.output.LayerNorm.bias', 'encoder.layer.2.output.dense.bias', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.0.attention.self.key.weight', 'encoder.layer.18.intermediate.dense.bias', 'encoder.layer.22.attention.output.dense.bias', 'encoder.layer.3.attention.self.value.weight', 'encoder.layer.15.attention.self.value.weight', 'encoder.layer.0.attention.self.value.bias', 'encoder.layer.10.output.dense.weight', 'encoder.layer.7.attention.self.value.bias', 'embeddings.LayerNorm.bias', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.11.attention.self.key.bias', 'encoder.layer.16.output.LayerNorm.bias', 'encoder.layer.7.output.LayerNorm.weight', 'encoder.layer.17.attention.output.dense.bias', 'encoder.layer.16.attention.output.dense.bias', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.16.attention.self.key.bias', 'encoder.layer.7.attention.self.query.weight', 'encoder.layer.0.attention.self.key.bias', 'encoder.layer.19.attention.self.value.weight', 'encoder.layer.7.output.dense.bias', 'encoder.layer.15.attention.output.LayerNorm.bias', 'encoder.layer.12.output.dense.bias', 'embeddings.LayerNorm.weight', 'encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.layer.19.attention.output.LayerNorm.bias', 'encoder.layer.16.attention.self.key.weight', 'encoder.layer.4.attention.output.dense.bias', 'encoder.layer.21.attention.output.dense.bias', 'encoder.layer.9.attention.self.key.bias', 'encoder.layer.23.attention.self.query.weight', 'encoder.layer.21.output.dense.weight', 'encoder.layer.12.intermediate.dense.weight', 'encoder.layer.6.attention.self.key.weight', 'encoder.layer.15.attention.self.query.bias', 'encoder.layer.6.output.dense.bias', 'encoder.layer.10.attention.self.key.bias', 'encoder.layer.15.attention.output.LayerNorm.weight', 'encoder.layer.5.attention.output.LayerNorm.weight', 'encoder.layer.16.attention.output.LayerNorm.weight', 'encoder.layer.19.output.LayerNorm.bias', 'encoder.layer.4.attention.self.key.bias', 'encoder.layer.5.output.dense.bias', 'encoder.layer.22.attention.self.query.bias', 'encoder.layer.21.attention.output.dense.weight', 'encoder.layer.8.attention.self.query.weight', 'encoder.layer.4.attention.self.query.bias', 'encoder.layer.17.intermediate.dense.bias', 'encoder.layer.11.attention.self.query.weight', 'encoder.layer.9.attention.output.LayerNorm.bias', 'encoder.layer.13.attention.output.LayerNorm.bias', 'encoder.layer.14.attention.output.LayerNorm.bias', 'encoder.layer.19.output.dense.bias', 'embeddings.word_embeddings.weight', 'encoder.layer.1.attention.output.dense.weight', 'encoder.layer.11.attention.self.query.bias', 'encoder.layer.23.attention.self.key.weight', 'encoder.layer.15.intermediate.dense.weight', 'encoder.layer.2.attention.self.value.bias', 'encoder.layer.16.attention.output.dense.weight', 'encoder.layer.22.attention.output.dense.weight', 'encoder.layer.5.attention.self.key.weight', 'encoder.layer.15.output.LayerNorm.bias', 'encoder.layer.20.attention.output.dense.weight', 'encoder.layer.23.attention.self.value.weight', 'encoder.layer.9.output.LayerNorm.weight', 'encoder.layer.8.attention.output.LayerNorm.weight', 'encoder.layer.9.output.dense.weight', 'encoder.layer.1.attention.self.key.bias', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.18.output.LayerNorm.weight', 'encoder.layer.21.attention.self.key.weight', 'encoder.layer.10.attention.output.dense.bias', 'encoder.layer.16.attention.output.LayerNorm.bias', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.1.attention.self.query.bias', 'encoder.layer.13.output.LayerNorm.bias', 'encoder.layer.16.intermediate.dense.weight', 'encoder.layer.19.intermediate.dense.bias', 'encoder.layer.19.attention.self.key.bias', 'encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.2.attention.self.value.weight', 'encoder.layer.14.attention.output.dense.weight', 'encoder.layer.12.attention.output.dense.weight', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.20.output.dense.bias', 'encoder.layer.9.attention.output.dense.weight', 'encoder.layer.7.attention.output.dense.bias', 'encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.layer.2.attention.output.dense.bias', 'encoder.layer.7.attention.output.dense.weight', 'encoder.layer.13.attention.self.value.weight', 'encoder.layer.11.attention.self.value.bias', 'encoder.layer.3.output.dense.bias', 'encoder.layer.20.output.LayerNorm.bias', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.8.attention.self.value.weight', 'encoder.layer.18.attention.self.key.weight', 'encoder.layer.8.attention.output.dense.bias', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.1.attention.self.value.weight', 'encoder.layer.12.attention.self.query.bias', 'encoder.layer.11.attention.output.LayerNorm.weight', 'encoder.layer.10.attention.output.dense.weight', 'encoder.layer.15.output.dense.weight', 'encoder.layer.22.intermediate.dense.weight', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.17.attention.output.dense.weight', 'encoder.layer.7.attention.output.LayerNorm.bias', 'encoder.layer.4.attention.output.dense.weight', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.4.attention.self.value.bias', 'encoder.layer.4.output.dense.bias', 'encoder.layer.20.output.dense.weight', 'encoder.layer.13.intermediate.dense.weight', 'encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.layer.21.output.dense.bias', 'encoder.layer.14.intermediate.dense.bias', 'encoder.layer.13.attention.output.dense.bias', 'encoder.layer.9.output.LayerNorm.bias', 'encoder.layer.20.attention.output.LayerNorm.weight', 'encoder.layer.14.attention.output.LayerNorm.weight', 'encoder.layer.10.output.LayerNorm.weight', 'encoder.layer.8.output.LayerNorm.bias', 'encoder.layer.0.output.dense.bias', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.19.attention.self.query.weight', 'encoder.layer.17.attention.self.value.bias', 'encoder.layer.21.attention.self.value.weight', 'encoder.layer.3.attention.output.dense.weight', 'encoder.layer.13.attention.output.LayerNorm.weight', 'encoder.layer.9.attention.output.LayerNorm.weight', 'encoder.layer.19.attention.self.query.bias', 'encoder.layer.13.attention.self.key.weight', 'encoder.layer.11.attention.self.value.weight', 'encoder.layer.5.output.LayerNorm.bias', 'encoder.layer.10.output.LayerNorm.bias', 'encoder.layer.21.attention.output.LayerNorm.weight', 'encoder.layer.0.attention.output.dense.bias', 'encoder.layer.17.attention.self.key.bias', 'encoder.layer.8.output.dense.weight', 'encoder.layer.9.attention.self.query.weight', 'encoder.layer.6.attention.self.value.bias', 'encoder.layer.7.attention.self.key.bias', 'encoder.layer.15.attention.output.dense.weight', 'encoder.layer.5.attention.self.value.bias', 'encoder.layer.22.attention.output.LayerNorm.weight', 'encoder.layer.3.attention.self.value.bias', 'encoder.layer.22.intermediate.dense.bias', 'encoder.layer.18.attention.self.key.bias', 'encoder.layer.1.output.dense.weight', 'encoder.layer.19.attention.output.LayerNorm.weight', 'encoder.layer.20.attention.self.query.weight', 'encoder.layer.12.output.LayerNorm.weight', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.8.attention.output.dense.weight', 'encoder.layer.2.attention.output.dense.weight', 'encoder.layer.10.attention.self.value.bias', 'encoder.layer.10.attention.output.LayerNorm.bias', 'encoder.layer.20.attention.self.value.weight', 'encoder.layer.8.attention.output.LayerNorm.bias', 'encoder.layer.12.attention.self.key.weight', 'encoder.layer.18.attention.self.query.bias', 'encoder.layer.7.attention.self.key.weight', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.7.attention.self.query.bias', 'encoder.layer.15.attention.output.dense.bias', 'encoder.layer.18.attention.self.query.weight', 'encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.layer.18.output.LayerNorm.bias', 'encoder.layer.12.attention.self.value.weight', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.20.attention.self.key.bias', 'encoder.layer.2.attention.self.key.weight', 'pooler.dense.bias', 'encoder.layer.12.output.dense.weight', 'encoder.layer.17.attention.output.LayerNorm.weight', 'encoder.layer.13.attention.self.value.bias', 'encoder.layer.3.attention.self.query.weight', 'encoder.layer.11.attention.self.key.weight', 'encoder.layer.5.attention.output.dense.bias', 'encoder.layer.17.output.dense.bias', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.11.output.LayerNorm.bias', 'encoder.layer.21.output.LayerNorm.bias', 'encoder.layer.8.attention.self.key.weight', 'encoder.layer.23.intermediate.dense.bias', 'encoder.layer.14.output.LayerNorm.bias', 'encoder.layer.4.attention.self.key.weight', 'encoder.layer.23.attention.self.value.bias', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.7.output.dense.weight', 'encoder.layer.23.attention.self.query.bias', 'encoder.layer.8.attention.self.query.bias', 'encoder.layer.8.attention.self.value.bias', 'encoder.layer.7.intermediate.dense.bias', 'encoder.layer.22.output.dense.bias', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.19.attention.output.dense.bias', 'encoder.layer.6.attention.self.query.bias', 'encoder.layer.3.output.dense.weight', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.4.attention.self.value.weight', 'encoder.layer.12.attention.self.query.weight', 'encoder.layer.9.attention.self.value.bias', 'encoder.layer.17.attention.self.key.weight', 'encoder.layer.4.output.dense.weight', 'encoder.layer.12.attention.self.value.bias', 'encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.layer.13.output.LayerNorm.weight', 'encoder.layer.18.attention.output.LayerNorm.bias', 'encoder.layer.23.attention.output.dense.bias', 'encoder.layer.23.attention.output.dense.weight', 'encoder.layer.21.output.LayerNorm.weight', 'encoder.layer.1.output.dense.bias', 'encoder.layer.23.output.dense.weight', 'encoder.layer.14.output.dense.weight', 'encoder.layer.12.attention.output.dense.bias', 'encoder.layer.10.attention.self.value.weight', 'encoder.layer.23.attention.self.key.bias', 'encoder.layer.6.output.dense.weight', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.2.attention.self.key.bias', 'embeddings.position_embeddings.weight', 'encoder.layer.15.intermediate.dense.bias', 'encoder.layer.18.attention.output.dense.weight', 'encoder.layer.0.attention.self.query.weight', 'encoder.layer.9.attention.output.dense.bias', 'encoder.layer.13.output.dense.bias', 'encoder.layer.21.attention.self.query.weight', 'encoder.layer.5.attention.self.query.bias', 'encoder.layer.12.attention.self.key.bias', 'encoder.layer.14.attention.self.key.weight', 'encoder.layer.23.output.dense.bias', 'encoder.layer.18.output.dense.bias', 'encoder.layer.9.attention.self.value.weight', 'encoder.layer.18.attention.output.LayerNorm.weight', 'encoder.layer.3.attention.self.query.bias', 'encoder.layer.15.attention.self.key.bias', 'encoder.layer.3.attention.self.key.weight', 'encoder.layer.4.attention.output.LayerNorm.bias', 'encoder.layer.6.attention.self.query.weight', 'encoder.layer.17.attention.output.LayerNorm.bias', 'encoder.layer.20.output.LayerNorm.weight', 'encoder.layer.23.attention.output.LayerNorm.weight', 'encoder.layer.12.intermediate.dense.bias', 'encoder.layer.16.output.dense.bias', 'encoder.layer.18.intermediate.dense.weight', 'encoder.layer.20.attention.output.dense.bias', 'encoder.layer.6.output.LayerNorm.bias', 'encoder.layer.1.attention.self.value.bias', 'encoder.layer.17.intermediate.dense.weight', 'encoder.layer.18.attention.self.value.bias', 'encoder.layer.20.attention.self.key.weight', 'encoder.layer.11.output.LayerNorm.weight', 'encoder.layer.20.intermediate.dense.weight', 'encoder.layer.22.output.dense.weight', 'encoder.layer.6.attention.output.dense.bias', 'encoder.layer.17.attention.self.value.weight', 'encoder.layer.5.output.dense.weight', 'encoder.layer.7.output.LayerNorm.bias', 'encoder.layer.14.attention.self.value.bias', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.11.output.dense.bias', 'encoder.layer.14.intermediate.dense.weight', 'encoder.layer.2.attention.output.LayerNorm.weight', 'encoder.layer.2.attention.self.query.weight', 'encoder.layer.17.attention.self.query.bias', 'encoder.layer.3.attention.output.dense.bias', 'encoder.layer.20.attention.output.LayerNorm.bias', 'encoder.layer.6.attention.output.dense.weight', 'encoder.layer.17.output.dense.weight', 'encoder.layer.11.attention.output.dense.weight', 'encoder.layer.13.attention.self.key.bias', 'encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.2.output.dense.weight', 'encoder.layer.0.attention.output.LayerNorm.weight', 'encoder.layer.1.attention.output.dense.bias', 'encoder.layer.18.attention.self.value.weight', 'encoder.layer.8.output.LayerNorm.weight', 'encoder.layer.22.output.LayerNorm.weight', 'encoder.layer.14.attention.output.dense.bias', 'encoder.layer.13.attention.self.query.weight', 'encoder.layer.15.output.LayerNorm.weight', 'encoder.layer.17.output.LayerNorm.weight', 'encoder.layer.7.attention.output.LayerNorm.weight', 'encoder.layer.13.attention.self.query.bias', 'encoder.layer.20.attention.self.value.bias', 'encoder.layer.2.attention.self.query.bias', 'encoder.layer.22.attention.self.key.weight', 'encoder.layer.19.output.LayerNorm.weight', 'encoder.layer.11.attention.output.dense.bias', 'encoder.layer.16.attention.self.value.bias', 'encoder.layer.10.attention.output.LayerNorm.weight', 'encoder.layer.10.attention.self.query.weight', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.22.attention.self.query.weight', 'encoder.layer.14.output.dense.bias', 'encoder.layer.22.attention.self.value.weight', 'encoder.layer.22.attention.self.value.bias', 'encoder.layer.5.attention.self.query.weight', 'encoder.layer.10.attention.self.key.weight', 'encoder.layer.16.output.LayerNorm.weight', 'encoder.layer.1.attention.output.LayerNorm.weight', 'pooler.dense.weight', 'embeddings.token_type_embeddings.weight', 'encoder.layer.21.attention.self.key.bias', 'encoder.layer.14.attention.self.query.bias', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.15.attention.self.key.weight', 'encoder.layer.21.attention.self.query.bias', 'encoder.layer.12.attention.output.LayerNorm.weight', 'encoder.layer.20.attention.self.query.bias', 'encoder.layer.4.attention.output.LayerNorm.weight', 'encoder.layer.10.attention.self.query.bias', 'encoder.layer.5.attention.output.dense.weight', 'encoder.layer.16.attention.self.value.weight', 'encoder.layer.14.attention.self.query.weight', 'encoder.layer.18.attention.output.dense.bias', 'encoder.layer.7.attention.self.value.weight', 'encoder.layer.16.output.dense.weight', 'encoder.layer.10.intermediate.dense.weight', 'encoder.layer.16.attention.self.query.bias', 'encoder.layer.5.attention.self.value.weight', 'encoder.layer.9.intermediate.dense.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Overwriting existing adapter 'ep'.
Overwriting existing adapter 'tp'.
Overwriting existing adapter 'es'.
Overwriting existing adapter 'ts'.
Overwriting existing adapter fusion module 'ep,tp,es,ts'
05/09/2022 21:40:05 - INFO - __main__ -   lang2id = None
05/09/2022 21:40:09 - INFO - __main__ -   Training/evaluation parameters Namespace(adam_epsilon=1e-08, cache_dir='', config_name='', data_dir=None, device=device(type='cuda'), do_eval=True, do_lower_case=False, do_train=False, doc_stride=128, eval_all_checkpoints=False, eval_lang='ar', evaluate_during_training=False, fp16=False, fp16_opt_level='O1', gradient_accumulation_steps=1, learning_rate=5e-05, local_rank=-1, logging_steps=50, max_answer_length=30, max_grad_norm=1.0, max_query_length=64, max_seq_length=384, max_steps=-1, model_name='xlm-KG', model_name_or_path='/cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//squad/xlm-KG_LR8e-6_EPOCH2.0_maxlen384_batchsize4_gradacc4', model_type='xlm', modelkg_dir='/cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/adapter/xlmr_adapter', n_best_size=20, n_gpu=1, no_cuda=False, null_score_diff_threshold=0.0, num_train_epochs=3.0, output_dir='/cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//squad/xlm-KG_LR8e-6_EPOCH2.0_maxlen384_batchsize4_gradacc4/predictions/mlqa/', overwrite_cache=False, overwrite_output_dir=False, per_gpu_eval_batch_size=8, per_gpu_train_batch_size=8, predict_file='/cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/download//mlqa//MLQA_V1/test/test-context-ar-question-ar.json', save_steps=50, seed=42, server_ip='', server_port='', threads=1, tokenizer_name='', train_file=None, train_lang='en', verbose_logging=False, version_2_with_negative=False, warmup_steps=0, weight_decay=0.0)
05/09/2022 21:40:09 - INFO - __main__ -   Loading checkpoint /cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//squad/xlm-KG_LR8e-6_EPOCH2.0_maxlen384_batchsize4_gradacc4 for evaluation
05/09/2022 21:40:09 - INFO - __main__ -   Evaluate the following checkpoints: ['/cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//squad/xlm-KG_LR8e-6_EPOCH2.0_maxlen384_batchsize4_gradacc4']
Some weights of the model checkpoint at /cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//squad/xlm-KG_LR8e-6_EPOCH2.0_maxlen384_batchsize4_gradacc4 were not used when initializing XLMRobertaModel: ['base_model.encoder.layer.19.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.11.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.0.attention.self.key.weight', 'base_model.encoder.layer.14.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.0.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.10.intermediate.dense.bias', 'base_model.encoder.layer.11.attention.self.value.bias', 'base_model.encoder.layer.14.attention.output.LayerNorm.bias', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.14.attention.output.dense.weight', 'base_model.encoder.layer.16.attention.output.LayerNorm.weight', 'base_model.encoder.layer.17.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.5.attention.self.query.bias', 'base_model.encoder.layer.2.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.5.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.14.output.LayerNorm.bias', 'base_model.encoder.layer.18.attention.self.value.bias', 'base_model.encoder.layer.10.attention.self.value.bias', 'base_model.encoder.layer.15.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.16.attention.output.dense.weight', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.3.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.20.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.23.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.6.intermediate.dense.bias', 'base_model.encoder.layer.5.attention.self.value.bias', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.12.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.4.attention.self.query.weight', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.21.attention.self.value.weight', 'base_model.encoder.layer.21.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.22.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.7.output.LayerNorm.bias', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.2.attention.self.query.bias', 'base_model.encoder.layer.8.attention.self.query.weight', 'base_model.encoder.layer.13.attention.output.dense.bias', 'base_model.encoder.layer.22.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.4.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.11.output.dense.bias', 'base_model.encoder.layer.16.attention.output.LayerNorm.bias', 'base_model.encoder.layer.14.attention.self.value.weight', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.4.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.11.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.10.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.12.attention.self.value.weight', 'base_model.encoder.layer.4.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.4.attention.self.value.weight', 'base_model.encoder.layer.13.attention.output.LayerNorm.weight', 'base_model.encoder.layer.13.attention.output.dense.weight', 'base_model.encoder.layer.6.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.22.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.9.output.dense.weight', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.17.intermediate.dense.weight', 'base_model.encoder.layer.6.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.17.output.dense.weight', 'base_model.encoder.layer.0.intermediate.dense.weight', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.21.attention.output.LayerNorm.weight', 'base_model.encoder.layer.23.attention.self.query.weight', 'base_model.encoder.layer.16.output.LayerNorm.weight', 'base_model.encoder.layer.16.intermediate.dense.bias', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.20.intermediate.dense.weight', 'base_model.encoder.layer.20.attention.output.dense.bias', 'base_model.encoder.layer.23.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.7.output.LayerNorm.weight', 'base_model.encoder.layer.18.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.11.attention.output.dense.weight', 'base_model.encoder.layer.14.attention.self.key.weight', 'base_model.encoder.layer.20.attention.output.LayerNorm.bias', 'base_model.encoder.layer.1.attention.self.value.weight', 'base_model.encoder.layer.18.output.dense.bias', 'base_model.encoder.layer.21.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.4.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.17.attention.self.key.bias', 'base_model.encoder.layer.18.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.23.attention.self.query.bias', 'base_model.encoder.layer.14.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.10.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.22.attention.self.value.weight', 'base_model.encoder.layer.8.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.21.attention.self.key.bias', 'base_model.encoder.layer.2.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.9.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.22.attention.self.key.weight', 'base_model.encoder.layer.20.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.22.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.17.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.16.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.9.attention.output.dense.weight', 'base_model.encoder.layer.20.output.LayerNorm.bias', 'base_model.encoder.layer.13.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.19.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.2.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.12.attention.output.dense.weight', 'base_model.encoder.layer.0.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.11.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.9.attention.output.LayerNorm.weight', 'base_model.encoder.layer.12.attention.output.dense.bias', 'base_model.encoder.layer.0.output.LayerNorm.weight', 'base_model.encoder.layer.14.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.15.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.8.attention.output.dense.weight', 'base_model.encoder.layer.12.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.6.output.LayerNorm.weight', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.1.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.13.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.13.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.17.attention.self.query.bias', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.1.output.dense.bias', 'base_model.encoder.layer.3.attention.self.key.weight', 'base_model.encoder.layer.5.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.5.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.7.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.12.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.2.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.7.attention.self.key.bias', 'base_model.encoder.layer.8.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.8.intermediate.dense.bias', 'base_model.encoder.layer.6.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.3.attention.self.value.bias', 'base_model.encoder.layer.10.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.19.attention.output.LayerNorm.bias', 'base_model.encoder.layer.23.attention.self.key.bias', 'base_model.encoder.layer.5.output.dense.bias', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.15.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.17.attention.output.dense.weight', 'base_model.encoder.layer.1.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.21.attention.output.dense.bias', 'base_model.encoder.layer.8.attention.self.key.weight', 'base_model.encoder.layer.14.attention.self.value.bias', 'base_model.encoder.layer.2.output.dense.weight', 'base_model.encoder.layer.13.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.0.attention.output.LayerNorm.weight', 'base_model.encoder.layer.23.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.21.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.11.attention.self.query.bias', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.3.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.20.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.21.attention.output.LayerNorm.bias', 'base_model.encoder.layer.2.intermediate.dense.bias', 'base_model.encoder.layer.9.intermediate.dense.bias', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.14.intermediate.dense.bias', 'base_model.encoder.layer.6.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.19.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.0.output.LayerNorm.bias', 'base_model.encoder.layer.3.output.dense.bias', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.22.attention.self.query.bias', 'base_model.encoder.layer.7.attention.self.key.weight', 'base_model.encoder.layer.3.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.15.attention.output.LayerNorm.bias', 'base_model.encoder.layer.15.intermediate.dense.weight', 'base_model.encoder.layer.6.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.16.attention.self.query.bias', 'base_model.encoder.layer.19.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.15.attention.self.value.bias', 'base_model.encoder.layer.15.attention.self.query.bias', 'base_model.encoder.layer.11.intermediate.dense.bias', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.21.attention.self.query.weight', 'base_model.encoder.layer.17.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.20.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.21.output.LayerNorm.weight', 'base_model.encoder.layer.9.output.dense.bias', 'base_model.encoder.layer.2.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.15.attention.output.dense.bias', 'base_model.encoder.layer.23.attention.output.dense.weight', 'base_model.encoder.layer.2.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.6.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.6.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.6.attention.self.key.bias', 'base_model.encoder.layer.8.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.1.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.7.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.17.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.13.attention.self.query.bias', 'base_model.encoder.layer.12.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.4.intermediate.dense.weight', 'base_model.encoder.layer.21.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.14.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.1.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.1.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.8.output.dense.weight', 'base_model.encoder.layer.2.attention.self.key.bias', 'base_model.encoder.layer.22.intermediate.dense.weight', 'base_model.encoder.layer.15.intermediate.dense.bias', 'base_model.encoder.layer.13.attention.self.key.bias', 'base_model.encoder.layer.20.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.19.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.7.attention.self.query.weight', 'base_model.encoder.layer.22.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.13.attention.self.query.weight', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.2.output.dense.bias', 'base_model.encoder.layer.9.attention.self.value.bias', 'base_model.encoder.layer.16.attention.self.key.weight', 'base_model.encoder.layer.11.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.18.output.dense.weight', 'base_model.encoder.layer.22.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.9.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.22.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.5.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.8.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.11.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.17.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.14.output.LayerNorm.weight', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.17.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.2.attention.output.LayerNorm.weight', 'base_model.encoder.layer.10.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.11.attention.output.dense.bias', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.12.attention.self.query.weight', 'base_model.encoder.layer.12.attention.output.LayerNorm.weight', 'base_model.encoder.layer.1.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.3.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.6.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.11.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.4.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.20.output.adapters.ts.adapter_down.0.weight', 'base_model.embeddings.LayerNorm.weight', 'base_model.encoder.layer.8.output.dense.bias', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.5.output.dense.weight', 'base_model.encoder.layer.22.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.7.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.22.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.5.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.19.attention.output.dense.bias', 'base_model.encoder.layer.16.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.4.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.11.attention.self.query.weight', 'base_model.encoder.layer.16.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.2.output.LayerNorm.weight', 'base_model.encoder.layer.12.output.LayerNorm.weight', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.4.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.18.intermediate.dense.bias', 'base_model.encoder.layer.12.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.0.attention.output.LayerNorm.bias', 'base_model.encoder.layer.5.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.7.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.17.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.20.attention.output.dense.weight', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.21.attention.self.query.bias', 'base_model.encoder.layer.23.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.7.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.2.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.5.intermediate.dense.bias', 'base_model.encoder.layer.12.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.15.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.0.attention.output.dense.bias', 'base_model.encoder.layer.17.output.LayerNorm.bias', 'base_model.encoder.layer.0.output.dense.bias', 'base_model.encoder.layer.4.output.dense.weight', 'base_model.encoder.layer.11.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.17.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.19.intermediate.dense.bias', 'base_model.encoder.layer.23.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.6.attention.self.query.weight', 'base_model.encoder.layer.10.attention.self.query.bias', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.22.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.19.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.18.attention.output.LayerNorm.weight', 'base_model.encoder.layer.3.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.16.attention.self.value.weight', 'base_model.encoder.layer.15.attention.self.query.weight', 'base_model.encoder.layer.15.attention.self.key.weight', 'base_model.encoder.layer.1.attention.self.key.bias', 'base_model.encoder.layer.15.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.17.attention.output.LayerNorm.bias', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.9.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.16.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.17.attention.self.query.weight', 'base_model.encoder.layer.11.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.12.attention.output.LayerNorm.bias', 'base_model.encoder.layer.19.attention.output.LayerNorm.weight', 'base_model.encoder.layer.6.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.15.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.9.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.10.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.6.attention.output.dense.bias', 'base_model.encoder.layer.10.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.17.attention.output.LayerNorm.weight', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.0.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.17.output.dense.bias', 'base_model.encoder.layer.13.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.22.output.LayerNorm.bias', 'base_model.encoder.layer.0.attention.output.dense.weight', 'base_model.encoder.layer.7.attention.output.LayerNorm.weight', 'base_model.encoder.layer.2.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.21.attention.output.dense.weight', 'base_model.encoder.layer.8.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.17.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.4.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.23.attention.output.LayerNorm.bias', 'base_model.encoder.layer.14.output.dense.weight', 'base_model.encoder.layer.0.attention.self.key.bias', 'base_model.encoder.layer.2.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.9.attention.self.query.bias', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.16.output.LayerNorm.bias', 'base_model.encoder.layer.18.attention.output.dense.weight', 'base_model.encoder.layer.9.attention.output.dense.bias', 'base_model.encoder.layer.5.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.20.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.20.intermediate.dense.bias', 'base_model.encoder.layer.8.attention.output.LayerNorm.bias', 'base_model.encoder.layer.10.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.5.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.19.attention.output.dense.weight', 'base_model.encoder.layer.8.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.16.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.18.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.18.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.12.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.18.attention.self.value.weight', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.4.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.22.attention.output.dense.weight', 'base_model.encoder.layer.3.attention.self.query.weight', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.5.attention.output.dense.bias', 'base_model.encoder.layer.18.attention.self.query.weight', 'base_model.encoder.layer.4.output.dense.bias', 'base_model.encoder.layer.13.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.6.output.dense.weight', 'base_model.encoder.layer.6.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.4.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.22.attention.output.dense.bias', 'base_model.encoder.layer.13.output.dense.weight', 'qa_outputs.bias', 'base_model.encoder.layer.13.output.dense.bias', 'base_model.encoder.layer.16.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.15.attention.self.key.bias', 'base_model.encoder.layer.3.output.LayerNorm.weight', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.19.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.14.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.6.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.14.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.21.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.13.attention.self.value.weight', 'base_model.encoder.layer.3.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.2.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.21.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.5.intermediate.dense.weight', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.11.attention.self.key.bias', 'base_model.encoder.layer.7.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.13.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.7.attention.output.LayerNorm.bias', 'base_model.encoder.layer.16.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.8.intermediate.dense.weight', 'base_model.encoder.layer.12.attention.self.value.bias', 'base_model.encoder.layer.1.attention.output.LayerNorm.weight', 'base_model.encoder.layer.18.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.17.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.13.attention.self.value.bias', 'base_model.encoder.layer.14.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.3.attention.output.dense.weight', 'base_model.encoder.layer.1.attention.self.key.weight', 'base_model.encoder.layer.17.output.LayerNorm.weight', 'base_model.encoder.layer.1.attention.self.query.weight', 'base_model.encoder.layer.16.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.2.output.LayerNorm.bias', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.1.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.16.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.7.intermediate.dense.weight', 'base_model.encoder.layer.8.output.LayerNorm.bias', 'base_model.encoder.layer.8.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.15.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.21.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.14.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.2.attention.self.value.bias', 'base_model.encoder.layer.3.attention.output.dense.bias', 'base_model.encoder.layer.5.attention.output.LayerNorm.bias', 'base_model.encoder.layer.11.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.2.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.9.attention.self.key.weight', 'base_model.encoder.layer.12.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.20.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.1.output.LayerNorm.weight', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.0.attention.self.query.bias', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.1.output.dense.weight', 'base_model.encoder.layer.9.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.16.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.19.output.LayerNorm.weight', 'base_model.encoder.layer.15.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.7.intermediate.dense.bias', 'base_model.encoder.layer.10.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.23.attention.self.value.weight', 'base_model.embeddings.position_ids', 'base_model.encoder.layer.3.attention.self.key.bias', 'base_model.encoder.layer.15.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.0.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.5.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.2.attention.self.query.weight', 'base_model.encoder.layer.5.attention.output.dense.weight', 'base_model.encoder.layer.18.intermediate.dense.weight', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.16.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.5.attention.self.key.weight', 'base_model.encoder.layer.1.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.18.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.3.attention.self.query.bias', 'base_model.encoder.layer.18.attention.self.query.bias', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.18.attention.self.key.bias', 'base_model.encoder.layer.1.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.21.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.10.output.LayerNorm.bias', 'base_model.encoder.layer.23.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.4.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.14.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.0.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.4.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.6.attention.self.value.bias', 'base_model.encoder.layer.13.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.11.attention.output.LayerNorm.bias', 'base_model.encoder.layer.20.attention.self.value.bias', 'base_model.encoder.layer.20.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.17.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.23.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.21.intermediate.dense.bias', 'base_model.encoder.layer.5.attention.self.key.bias', 'base_model.encoder.layer.18.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.20.output.LayerNorm.weight', 'base_model.encoder.layer.8.output.LayerNorm.weight', 'base_model.encoder.layer.23.intermediate.dense.weight', 'base_model.encoder.layer.22.output.adapters.ep.adapter_up.bias', 'base_model.embeddings.token_type_embeddings.weight', 'base_model.encoder.layer.5.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.15.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.21.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.4.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.23.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.15.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.6.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.16.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.0.attention.self.query.weight', 'base_model.encoder.layer.19.attention.self.key.weight', 'base_model.encoder.layer.8.attention.self.value.bias', 'base_model.encoder.layer.5.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.11.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.12.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.10.attention.output.LayerNorm.weight', 'base_model.encoder.layer.14.attention.self.query.bias', 'base_model.encoder.layer.0.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.22.output.LayerNorm.weight', 'base_model.encoder.layer.1.intermediate.dense.bias', 'base_model.encoder.layer.11.output.LayerNorm.weight', 'base_model.encoder.layer.15.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.17.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.17.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.1.attention.self.query.bias', 'base_model.encoder.layer.20.output.dense.weight', 'base_model.encoder.layer.21.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.2.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.12.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.18.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.19.attention.self.key.bias', 'base_model.encoder.layer.19.output.adapters.ep.adapter_down.0.weight', 'base_model.pooler.dense.weight', 'base_model.encoder.layer.6.attention.output.dense.weight', 'base_model.encoder.layer.13.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.5.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.9.intermediate.dense.weight', 'base_model.encoder.layer.5.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.18.attention.output.LayerNorm.bias', 'base_model.encoder.layer.14.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.2.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.0.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.9.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.23.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.21.intermediate.dense.weight', 'base_model.encoder.layer.17.attention.output.dense.bias', 'base_model.encoder.layer.20.attention.output.LayerNorm.weight', 'base_model.encoder.layer.16.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.10.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.12.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.23.attention.self.value.bias', 'base_model.encoder.layer.23.output.LayerNorm.weight', 'base_model.encoder.layer.6.output.adapters.ts.adapter_down.0.weight', 'qa_outputs.weight', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.22.output.dense.weight', 'base_model.encoder.layer.1.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.3.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.19.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.18.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.15.output.LayerNorm.bias', 'base_model.encoder.layer.7.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.22.output.dense.bias', 'base_model.encoder.layer.19.intermediate.dense.weight', 'base_model.encoder.layer.23.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.0.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.22.intermediate.dense.bias', 'base_model.encoder.layer.10.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.17.attention.self.value.bias', 'base_model.encoder.layer.23.intermediate.dense.bias', 'base_model.encoder.layer.6.attention.output.LayerNorm.weight', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.8.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.19.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.10.attention.self.value.weight', 'base_model.encoder.layer.7.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.11.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.12.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.19.attention.self.value.bias', 'base_model.encoder.layer.1.attention.self.value.bias', 'base_model.pooler.dense.bias', 'base_model.encoder.layer.22.attention.output.LayerNorm.bias', 'base_model.encoder.layer.5.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.11.attention.self.value.weight', 'base_model.encoder.layer.23.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.11.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.22.attention.self.key.bias', 'base_model.encoder.layer.10.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.11.intermediate.dense.weight', 'base_model.encoder.layer.14.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.23.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.19.output.LayerNorm.bias', 'base_model.encoder.layer.22.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.6.output.LayerNorm.bias', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.13.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.9.attention.self.key.bias', 'base_model.encoder.layer.3.attention.output.LayerNorm.weight', 'base_model.encoder.layer.19.output.dense.bias', 'base_model.encoder.layer.18.output.LayerNorm.bias', 'base_model.encoder.layer.10.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.3.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.8.attention.self.query.bias', 'base_model.encoder.layer.9.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.0.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.16.attention.self.query.weight', 'base_model.encoder.layer.7.attention.output.dense.weight', 'base_model.encoder.layer.22.attention.output.LayerNorm.weight', 'base_model.encoder.layer.7.output.dense.bias', 'base_model.encoder.layer.3.output.LayerNorm.bias', 'base_model.encoder.layer.2.attention.output.LayerNorm.bias', 'base_model.encoder.layer.11.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.13.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.16.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.13.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.16.attention.self.key.bias', 'base_model.encoder.layer.23.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.11.output.dense.weight', 'base_model.encoder.layer.7.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.17.attention.self.value.weight', 'base_model.encoder.layer.10.attention.output.LayerNorm.bias', 'base_model.encoder.layer.17.attention.self.key.weight', 'base_model.encoder.layer.7.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.10.attention.output.dense.bias', 'base_model.encoder.layer.0.intermediate.dense.bias', 'base_model.encoder.layer.1.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.0.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.1.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.3.intermediate.dense.bias', 'base_model.encoder.layer.12.intermediate.dense.bias', 'base_model.encoder.layer.13.attention.output.LayerNorm.bias', 'base_model.encoder.layer.17.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.8.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.23.output.dense.weight', 'base_model.encoder.layer.2.attention.output.dense.weight', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.1.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.18.attention.self.key.weight', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.18.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.18.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.22.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.9.output.LayerNorm.weight', 'base_model.encoder.layer.8.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.2.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.8.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.8.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.18.attention.output.dense.bias', 'base_model.encoder.layer.5.output.LayerNorm.bias', 'base_model.encoder.layer.7.attention.self.value.bias', 'base_model.encoder.layer.6.intermediate.dense.weight', 'base_model.encoder.layer.5.attention.output.LayerNorm.weight', 'base_model.encoder.layer.10.output.LayerNorm.weight', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.21.output.dense.bias', 'base_model.encoder.layer.13.attention.self.key.weight', 'base_model.encoder.layer.10.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.4.attention.output.LayerNorm.weight', 'base_model.encoder.layer.11.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.0.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.13.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.3.attention.output.LayerNorm.bias', 'base_model.encoder.layer.12.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.3.intermediate.dense.weight', 'base_model.encoder.layer.9.attention.self.query.weight', 'base_model.encoder.layer.1.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.18.output.LayerNorm.weight', 'base_model.encoder.layer.1.output.LayerNorm.bias', 'base_model.encoder.layer.14.attention.self.key.bias', 'base_model.encoder.layer.9.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.12.output.dense.bias', 'base_model.encoder.layer.15.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.0.attention.self.value.weight', 'base_model.encoder.layer.1.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.4.output.LayerNorm.weight', 'base_model.encoder.layer.19.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.23.output.dense.bias', 'base_model.encoder.layer.12.attention.self.query.bias', 'base_model.encoder.layer.9.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.22.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.5.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.11.attention.self.key.weight', 'base_model.encoder.layer.9.attention.output.LayerNorm.bias', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.10.output.dense.weight', 'base_model.encoder.layer.2.intermediate.dense.weight', 'base_model.encoder.layer.11.output.LayerNorm.bias', 'base_model.encoder.layer.12.output.LayerNorm.bias', 'base_model.encoder.layer.8.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.9.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.12.intermediate.dense.weight', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.20.attention.self.value.weight', 'base_model.encoder.layer.21.output.dense.weight', 'base_model.encoder.layer.23.attention.output.LayerNorm.weight', 'base_model.encoder.layer.8.attention.self.key.bias', 'base_model.encoder.layer.18.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.10.attention.self.key.weight', 'base_model.embeddings.LayerNorm.bias', 'base_model.encoder.layer.6.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.23.output.LayerNorm.bias', 'base_model.encoder.layer.20.attention.self.key.bias', 'base_model.encoder.layer.20.output.dense.bias', 'base_model.encoder.layer.8.attention.output.dense.bias', 'base_model.encoder.layer.15.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.21.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.20.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.19.output.dense.weight', 'base_model.embeddings.word_embeddings.weight', 'base_model.encoder.layer.20.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.23.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.20.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.3.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.10.attention.output.dense.weight', 'base_model.encoder.layer.7.attention.self.value.weight', 'base_model.encoder.layer.14.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.7.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.19.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.12.output.dense.weight', 'base_model.encoder.layer.18.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.1.intermediate.dense.weight', 'base_model.encoder.layer.3.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.23.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.10.attention.self.key.bias', 'base_model.encoder.layer.13.intermediate.dense.weight', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.19.attention.self.query.weight', 'base_model.encoder.layer.1.attention.output.LayerNorm.bias', 'base_model.encoder.layer.6.output.dense.bias', 'base_model.encoder.layer.14.intermediate.dense.weight', 'base_model.encoder.layer.3.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.16.output.dense.weight', 'base_model.encoder.layer.15.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.10.intermediate.dense.weight', 'base_model.encoder.layer.19.attention.self.query.bias', 'base_model.encoder.layer.14.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.14.attention.output.dense.bias', 'base_model.encoder.layer.6.attention.self.query.bias', 'base_model.encoder.layer.7.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.0.attention.self.value.bias', 'base_model.encoder.layer.2.attention.self.value.weight', 'base_model.encoder.layer.17.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.12.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.20.attention.self.query.bias', 'base_model.encoder.layer.4.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.7.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.4.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.19.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.4.attention.output.LayerNorm.bias', 'base_model.encoder.layer.9.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.20.attention.self.key.weight', 'base_model.encoder.layer.15.output.dense.bias', 'base_model.encoder.layer.19.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.0.output.dense.weight', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.4.attention.self.query.bias', 'base_model.encoder.layer.5.output.LayerNorm.weight', 'base_model.encoder.layer.7.attention.output.dense.bias', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.4.attention.self.key.weight', 'base_model.encoder.layer.4.attention.output.dense.weight', 'base_model.encoder.layer.5.attention.self.value.weight', 'base_model.encoder.layer.6.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.9.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.18.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.16.intermediate.dense.weight', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.22.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.4.intermediate.dense.bias', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.20.attention.self.query.weight', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.1.attention.output.dense.bias', 'base_model.encoder.layer.8.attention.output.LayerNorm.weight', 'base_model.encoder.layer.13.output.LayerNorm.bias', 'base_model.encoder.layer.22.attention.self.query.weight', 'base_model.encoder.layer.10.attention.self.query.weight', 'base_model.encoder.layer.23.attention.self.key.weight', 'base_model.encoder.layer.7.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.11.attention.output.LayerNorm.weight', 'base_model.encoder.layer.20.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.21.attention.self.value.bias', 'base_model.embeddings.position_embeddings.weight', 'base_model.encoder.layer.15.attention.output.LayerNorm.weight', 'base_model.encoder.layer.3.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.6.attention.self.value.weight', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.0.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.21.attention.self.key.weight', 'base_model.encoder.layer.14.attention.self.query.weight', 'base_model.encoder.layer.16.output.dense.bias', 'base_model.encoder.layer.16.attention.self.value.bias', 'base_model.encoder.layer.21.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.9.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.7.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.19.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.9.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.3.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.10.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.2.attention.output.dense.bias', 'base_model.encoder.layer.9.attention.self.value.weight', 'base_model.encoder.layer.15.attention.self.value.weight', 'base_model.encoder.layer.13.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.13.output.LayerNorm.weight', 'base_model.encoder.layer.13.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.5.attention.self.query.weight', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.14.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.12.attention.self.key.bias', 'base_model.encoder.layer.8.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.3.output.dense.weight', 'base_model.encoder.layer.10.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.16.attention.output.dense.bias', 'base_model.encoder.layer.17.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.12.attention.self.key.weight', 'base_model.encoder.layer.16.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.21.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.21.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.22.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.14.output.dense.bias', 'base_model.encoder.layer.14.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.18.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.21.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.4.attention.self.key.bias', 'base_model.encoder.layer.3.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.9.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.4.attention.self.value.bias', 'base_model.encoder.layer.21.output.LayerNorm.bias', 'base_model.encoder.layer.8.attention.self.value.weight', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.6.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.3.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.4.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.15.attention.output.dense.weight', 'base_model.encoder.layer.9.output.LayerNorm.bias', 'base_model.encoder.layer.14.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.0.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.4.output.LayerNorm.bias', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.2.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.7.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.1.attention.output.dense.weight', 'base_model.encoder.layer.1.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.13.intermediate.dense.bias', 'base_model.encoder.layer.0.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.21.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.23.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.20.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.2.attention.self.key.weight', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.16.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.17.intermediate.dense.bias', 'base_model.encoder.layer.23.attention.output.dense.bias', 'base_model.encoder.layer.12.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.5.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.15.output.dense.weight', 'base_model.encoder.layer.7.attention.self.query.bias', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.9.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.8.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.4.attention.output.dense.bias', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.6.attention.output.LayerNorm.bias', 'base_model.encoder.layer.15.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.18.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.10.output.dense.bias', 'base_model.encoder.layer.11.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.3.attention.self.value.weight', 'base_model.encoder.layer.12.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.20.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.13.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.10.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.6.attention.self.key.weight', 'base_model.encoder.layer.19.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.0.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.11.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.7.output.dense.weight', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.8.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.20.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.2.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.19.attention.self.value.weight', 'base_model.encoder.layer.0.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.22.attention.self.value.bias', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.15.output.LayerNorm.weight', 'base_model.encoder.layer.3.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.14.attention.output.LayerNorm.weight']
- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of XLMRobertaModel were not initialized from the model checkpoint at /cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//squad/xlm-KG_LR8e-6_EPOCH2.0_maxlen384_batchsize4_gradacc4 and are newly initialized: ['encoder.layer.0.intermediate.dense.weight', 'encoder.layer.15.output.dense.bias', 'encoder.layer.1.attention.self.key.weight', 'encoder.layer.23.output.LayerNorm.weight', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.19.attention.self.value.bias', 'encoder.layer.6.attention.output.LayerNorm.bias', 'encoder.layer.15.attention.self.value.bias', 'encoder.layer.23.attention.output.LayerNorm.bias', 'encoder.layer.5.attention.self.key.bias', 'encoder.layer.10.output.dense.bias', 'encoder.layer.18.output.dense.weight', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.22.attention.self.key.bias', 'encoder.layer.16.intermediate.dense.bias', 'encoder.layer.13.intermediate.dense.bias', 'encoder.layer.19.intermediate.dense.weight', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.8.output.dense.bias', 'encoder.layer.13.attention.output.dense.weight', 'encoder.layer.9.attention.self.key.weight', 'encoder.layer.0.attention.output.dense.weight', 'encoder.layer.6.attention.self.key.bias', 'encoder.layer.23.output.LayerNorm.bias', 'encoder.layer.21.attention.output.LayerNorm.bias', 'encoder.layer.3.attention.self.key.bias', 'encoder.layer.15.attention.self.query.weight', 'encoder.layer.21.attention.self.value.bias', 'encoder.layer.6.attention.output.LayerNorm.weight', 'encoder.layer.1.attention.self.query.weight', 'encoder.layer.14.attention.self.value.weight', 'encoder.layer.17.attention.self.query.weight', 'encoder.layer.23.intermediate.dense.weight', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.12.attention.output.LayerNorm.bias', 'encoder.layer.19.attention.output.dense.weight', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.0.output.dense.weight', 'encoder.layer.16.attention.self.query.weight', 'encoder.layer.12.output.LayerNorm.bias', 'encoder.layer.21.intermediate.dense.bias', 'encoder.layer.9.attention.self.query.bias', 'encoder.layer.20.intermediate.dense.bias', 'encoder.layer.6.attention.self.value.weight', 'encoder.layer.19.attention.self.key.weight', 'encoder.layer.0.attention.self.query.bias', 'encoder.layer.2.attention.output.LayerNorm.bias', 'encoder.layer.14.attention.self.key.bias', 'encoder.layer.0.attention.self.value.weight', 'encoder.layer.19.output.dense.weight', 'encoder.layer.8.attention.self.key.bias', 'encoder.layer.9.output.dense.bias', 'encoder.layer.14.output.LayerNorm.weight', 'encoder.layer.21.intermediate.dense.weight', 'encoder.layer.17.output.LayerNorm.bias', 'encoder.layer.22.output.LayerNorm.bias', 'encoder.layer.13.output.dense.weight', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.4.attention.self.query.weight', 'encoder.layer.11.output.dense.weight', 'encoder.layer.22.attention.output.LayerNorm.bias', 'encoder.layer.2.output.dense.bias', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.0.attention.self.key.weight', 'encoder.layer.18.intermediate.dense.bias', 'encoder.layer.22.attention.output.dense.bias', 'encoder.layer.3.attention.self.value.weight', 'encoder.layer.15.attention.self.value.weight', 'encoder.layer.0.attention.self.value.bias', 'encoder.layer.10.output.dense.weight', 'encoder.layer.7.attention.self.value.bias', 'embeddings.LayerNorm.bias', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.11.attention.self.key.bias', 'encoder.layer.16.output.LayerNorm.bias', 'encoder.layer.7.output.LayerNorm.weight', 'encoder.layer.17.attention.output.dense.bias', 'encoder.layer.16.attention.output.dense.bias', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.16.attention.self.key.bias', 'encoder.layer.7.attention.self.query.weight', 'encoder.layer.0.attention.self.key.bias', 'encoder.layer.19.attention.self.value.weight', 'encoder.layer.7.output.dense.bias', 'encoder.layer.15.attention.output.LayerNorm.bias', 'encoder.layer.12.output.dense.bias', 'embeddings.LayerNorm.weight', 'encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.layer.19.attention.output.LayerNorm.bias', 'encoder.layer.16.attention.self.key.weight', 'encoder.layer.4.attention.output.dense.bias', 'encoder.layer.21.attention.output.dense.bias', 'encoder.layer.9.attention.self.key.bias', 'encoder.layer.23.attention.self.query.weight', 'encoder.layer.21.output.dense.weight', 'encoder.layer.12.intermediate.dense.weight', 'encoder.layer.6.attention.self.key.weight', 'encoder.layer.15.attention.self.query.bias', 'encoder.layer.6.output.dense.bias', 'encoder.layer.10.attention.self.key.bias', 'encoder.layer.15.attention.output.LayerNorm.weight', 'encoder.layer.5.attention.output.LayerNorm.weight', 'encoder.layer.16.attention.output.LayerNorm.weight', 'encoder.layer.19.output.LayerNorm.bias', 'encoder.layer.4.attention.self.key.bias', 'encoder.layer.5.output.dense.bias', 'encoder.layer.22.attention.self.query.bias', 'encoder.layer.21.attention.output.dense.weight', 'encoder.layer.8.attention.self.query.weight', 'encoder.layer.4.attention.self.query.bias', 'encoder.layer.17.intermediate.dense.bias', 'encoder.layer.11.attention.self.query.weight', 'encoder.layer.9.attention.output.LayerNorm.bias', 'encoder.layer.13.attention.output.LayerNorm.bias', 'encoder.layer.14.attention.output.LayerNorm.bias', 'encoder.layer.19.output.dense.bias', 'embeddings.word_embeddings.weight', 'encoder.layer.1.attention.output.dense.weight', 'encoder.layer.11.attention.self.query.bias', 'encoder.layer.23.attention.self.key.weight', 'encoder.layer.15.intermediate.dense.weight', 'encoder.layer.2.attention.self.value.bias', 'encoder.layer.16.attention.output.dense.weight', 'encoder.layer.22.attention.output.dense.weight', 'encoder.layer.5.attention.self.key.weight', 'encoder.layer.15.output.LayerNorm.bias', 'encoder.layer.20.attention.output.dense.weight', 'encoder.layer.23.attention.self.value.weight', 'encoder.layer.9.output.LayerNorm.weight', 'encoder.layer.8.attention.output.LayerNorm.weight', 'encoder.layer.9.output.dense.weight', 'encoder.layer.1.attention.self.key.bias', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.18.output.LayerNorm.weight', 'encoder.layer.21.attention.self.key.weight', 'encoder.layer.10.attention.output.dense.bias', 'encoder.layer.16.attention.output.LayerNorm.bias', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.1.attention.self.query.bias', 'encoder.layer.13.output.LayerNorm.bias', 'encoder.layer.16.intermediate.dense.weight', 'encoder.layer.19.intermediate.dense.bias', 'encoder.layer.19.attention.self.key.bias', 'encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.2.attention.self.value.weight', 'encoder.layer.14.attention.output.dense.weight', 'encoder.layer.12.attention.output.dense.weight', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.20.output.dense.bias', 'encoder.layer.9.attention.output.dense.weight', 'encoder.layer.7.attention.output.dense.bias', 'encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.layer.2.attention.output.dense.bias', 'encoder.layer.7.attention.output.dense.weight', 'encoder.layer.13.attention.self.value.weight', 'encoder.layer.11.attention.self.value.bias', 'encoder.layer.3.output.dense.bias', 'encoder.layer.20.output.LayerNorm.bias', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.8.attention.self.value.weight', 'encoder.layer.18.attention.self.key.weight', 'encoder.layer.8.attention.output.dense.bias', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.1.attention.self.value.weight', 'encoder.layer.12.attention.self.query.bias', 'encoder.layer.11.attention.output.LayerNorm.weight', 'encoder.layer.10.attention.output.dense.weight', 'encoder.layer.15.output.dense.weight', 'encoder.layer.22.intermediate.dense.weight', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.17.attention.output.dense.weight', 'encoder.layer.7.attention.output.LayerNorm.bias', 'encoder.layer.4.attention.output.dense.weight', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.4.attention.self.value.bias', 'encoder.layer.4.output.dense.bias', 'encoder.layer.20.output.dense.weight', 'encoder.layer.13.intermediate.dense.weight', 'encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.layer.21.output.dense.bias', 'encoder.layer.14.intermediate.dense.bias', 'encoder.layer.13.attention.output.dense.bias', 'encoder.layer.9.output.LayerNorm.bias', 'encoder.layer.20.attention.output.LayerNorm.weight', 'encoder.layer.14.attention.output.LayerNorm.weight', 'encoder.layer.10.output.LayerNorm.weight', 'encoder.layer.8.output.LayerNorm.bias', 'encoder.layer.0.output.dense.bias', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.19.attention.self.query.weight', 'encoder.layer.17.attention.self.value.bias', 'encoder.layer.21.attention.self.value.weight', 'encoder.layer.3.attention.output.dense.weight', 'encoder.layer.13.attention.output.LayerNorm.weight', 'encoder.layer.9.attention.output.LayerNorm.weight', 'encoder.layer.19.attention.self.query.bias', 'encoder.layer.13.attention.self.key.weight', 'encoder.layer.11.attention.self.value.weight', 'encoder.layer.5.output.LayerNorm.bias', 'encoder.layer.10.output.LayerNorm.bias', 'encoder.layer.21.attention.output.LayerNorm.weight', 'encoder.layer.0.attention.output.dense.bias', 'encoder.layer.17.attention.self.key.bias', 'encoder.layer.8.output.dense.weight', 'encoder.layer.9.attention.self.query.weight', 'encoder.layer.6.attention.self.value.bias', 'encoder.layer.7.attention.self.key.bias', 'encoder.layer.15.attention.output.dense.weight', 'encoder.layer.5.attention.self.value.bias', 'encoder.layer.22.attention.output.LayerNorm.weight', 'encoder.layer.3.attention.self.value.bias', 'encoder.layer.22.intermediate.dense.bias', 'encoder.layer.18.attention.self.key.bias', 'encoder.layer.1.output.dense.weight', 'encoder.layer.19.attention.output.LayerNorm.weight', 'encoder.layer.20.attention.self.query.weight', 'encoder.layer.12.output.LayerNorm.weight', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.8.attention.output.dense.weight', 'encoder.layer.2.attention.output.dense.weight', 'encoder.layer.10.attention.self.value.bias', 'encoder.layer.10.attention.output.LayerNorm.bias', 'encoder.layer.20.attention.self.value.weight', 'encoder.layer.8.attention.output.LayerNorm.bias', 'encoder.layer.12.attention.self.key.weight', 'encoder.layer.18.attention.self.query.bias', 'encoder.layer.7.attention.self.key.weight', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.7.attention.self.query.bias', 'encoder.layer.15.attention.output.dense.bias', 'encoder.layer.18.attention.self.query.weight', 'encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.layer.18.output.LayerNorm.bias', 'encoder.layer.12.attention.self.value.weight', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.20.attention.self.key.bias', 'encoder.layer.2.attention.self.key.weight', 'pooler.dense.bias', 'encoder.layer.12.output.dense.weight', 'encoder.layer.17.attention.output.LayerNorm.weight', 'encoder.layer.13.attention.self.value.bias', 'encoder.layer.3.attention.self.query.weight', 'encoder.layer.11.attention.self.key.weight', 'encoder.layer.5.attention.output.dense.bias', 'encoder.layer.17.output.dense.bias', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.11.output.LayerNorm.bias', 'encoder.layer.21.output.LayerNorm.bias', 'encoder.layer.8.attention.self.key.weight', 'encoder.layer.23.intermediate.dense.bias', 'encoder.layer.14.output.LayerNorm.bias', 'encoder.layer.4.attention.self.key.weight', 'encoder.layer.23.attention.self.value.bias', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.7.output.dense.weight', 'encoder.layer.23.attention.self.query.bias', 'encoder.layer.8.attention.self.query.bias', 'encoder.layer.8.attention.self.value.bias', 'encoder.layer.7.intermediate.dense.bias', 'encoder.layer.22.output.dense.bias', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.19.attention.output.dense.bias', 'encoder.layer.6.attention.self.query.bias', 'encoder.layer.3.output.dense.weight', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.4.attention.self.value.weight', 'encoder.layer.12.attention.self.query.weight', 'encoder.layer.9.attention.self.value.bias', 'encoder.layer.17.attention.self.key.weight', 'encoder.layer.4.output.dense.weight', 'encoder.layer.12.attention.self.value.bias', 'encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.layer.13.output.LayerNorm.weight', 'encoder.layer.18.attention.output.LayerNorm.bias', 'encoder.layer.23.attention.output.dense.bias', 'encoder.layer.23.attention.output.dense.weight', 'encoder.layer.21.output.LayerNorm.weight', 'encoder.layer.1.output.dense.bias', 'encoder.layer.23.output.dense.weight', 'encoder.layer.14.output.dense.weight', 'encoder.layer.12.attention.output.dense.bias', 'encoder.layer.10.attention.self.value.weight', 'encoder.layer.23.attention.self.key.bias', 'encoder.layer.6.output.dense.weight', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.2.attention.self.key.bias', 'embeddings.position_embeddings.weight', 'encoder.layer.15.intermediate.dense.bias', 'encoder.layer.18.attention.output.dense.weight', 'encoder.layer.0.attention.self.query.weight', 'encoder.layer.9.attention.output.dense.bias', 'encoder.layer.13.output.dense.bias', 'encoder.layer.21.attention.self.query.weight', 'encoder.layer.5.attention.self.query.bias', 'encoder.layer.12.attention.self.key.bias', 'encoder.layer.14.attention.self.key.weight', 'encoder.layer.23.output.dense.bias', 'encoder.layer.18.output.dense.bias', 'encoder.layer.9.attention.self.value.weight', 'encoder.layer.18.attention.output.LayerNorm.weight', 'encoder.layer.3.attention.self.query.bias', 'encoder.layer.15.attention.self.key.bias', 'encoder.layer.3.attention.self.key.weight', 'encoder.layer.4.attention.output.LayerNorm.bias', 'encoder.layer.6.attention.self.query.weight', 'encoder.layer.17.attention.output.LayerNorm.bias', 'encoder.layer.20.output.LayerNorm.weight', 'encoder.layer.23.attention.output.LayerNorm.weight', 'encoder.layer.12.intermediate.dense.bias', 'encoder.layer.16.output.dense.bias', 'encoder.layer.18.intermediate.dense.weight', 'encoder.layer.20.attention.output.dense.bias', 'encoder.layer.6.output.LayerNorm.bias', 'encoder.layer.1.attention.self.value.bias', 'encoder.layer.17.intermediate.dense.weight', 'encoder.layer.18.attention.self.value.bias', 'encoder.layer.20.attention.self.key.weight', 'encoder.layer.11.output.LayerNorm.weight', 'encoder.layer.20.intermediate.dense.weight', 'encoder.layer.22.output.dense.weight', 'encoder.layer.6.attention.output.dense.bias', 'encoder.layer.17.attention.self.value.weight', 'encoder.layer.5.output.dense.weight', 'encoder.layer.7.output.LayerNorm.bias', 'encoder.layer.14.attention.self.value.bias', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.11.output.dense.bias', 'encoder.layer.14.intermediate.dense.weight', 'encoder.layer.2.attention.output.LayerNorm.weight', 'encoder.layer.2.attention.self.query.weight', 'encoder.layer.17.attention.self.query.bias', 'encoder.layer.3.attention.output.dense.bias', 'encoder.layer.20.attention.output.LayerNorm.bias', 'encoder.layer.6.attention.output.dense.weight', 'encoder.layer.17.output.dense.weight', 'encoder.layer.11.attention.output.dense.weight', 'encoder.layer.13.attention.self.key.bias', 'encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.2.output.dense.weight', 'encoder.layer.0.attention.output.LayerNorm.weight', 'encoder.layer.1.attention.output.dense.bias', 'encoder.layer.18.attention.self.value.weight', 'encoder.layer.8.output.LayerNorm.weight', 'encoder.layer.22.output.LayerNorm.weight', 'encoder.layer.14.attention.output.dense.bias', 'encoder.layer.13.attention.self.query.weight', 'encoder.layer.15.output.LayerNorm.weight', 'encoder.layer.17.output.LayerNorm.weight', 'encoder.layer.7.attention.output.LayerNorm.weight', 'encoder.layer.13.attention.self.query.bias', 'encoder.layer.20.attention.self.value.bias', 'encoder.layer.2.attention.self.query.bias', 'encoder.layer.22.attention.self.key.weight', 'encoder.layer.19.output.LayerNorm.weight', 'encoder.layer.11.attention.output.dense.bias', 'encoder.layer.16.attention.self.value.bias', 'encoder.layer.10.attention.output.LayerNorm.weight', 'encoder.layer.10.attention.self.query.weight', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.22.attention.self.query.weight', 'encoder.layer.14.output.dense.bias', 'encoder.layer.22.attention.self.value.weight', 'encoder.layer.22.attention.self.value.bias', 'encoder.layer.5.attention.self.query.weight', 'encoder.layer.10.attention.self.key.weight', 'encoder.layer.16.output.LayerNorm.weight', 'encoder.layer.1.attention.output.LayerNorm.weight', 'pooler.dense.weight', 'embeddings.token_type_embeddings.weight', 'encoder.layer.21.attention.self.key.bias', 'encoder.layer.14.attention.self.query.bias', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.15.attention.self.key.weight', 'encoder.layer.21.attention.self.query.bias', 'encoder.layer.12.attention.output.LayerNorm.weight', 'encoder.layer.20.attention.self.query.bias', 'encoder.layer.4.attention.output.LayerNorm.weight', 'encoder.layer.10.attention.self.query.bias', 'encoder.layer.5.attention.output.dense.weight', 'encoder.layer.16.attention.self.value.weight', 'encoder.layer.14.attention.self.query.weight', 'encoder.layer.18.attention.output.dense.bias', 'encoder.layer.7.attention.self.value.weight', 'encoder.layer.16.output.dense.weight', 'encoder.layer.10.intermediate.dense.weight', 'encoder.layer.16.attention.self.query.bias', 'encoder.layer.5.attention.self.value.weight', 'encoder.layer.9.intermediate.dense.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Overwriting existing adapter 'ep'.
Overwriting existing adapter 'tp'.
Overwriting existing adapter 'es'.
Overwriting existing adapter 'ts'.
Overwriting existing adapter fusion module 'ep,tp,es,ts'
/cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//squad/xlm-KG_LR8e-6_EPOCH2.0_maxlen384_batchsize4_gradacc4
XLMConfig {
  "architectures": [
    "XLMRobertaForMaskedLM"
  ],
  "asm": false,
  "attention_dropout": 0.1,
  "attention_probs_dropout_prob": 0.1,
  "bos_index": 0,
  "bos_token_id": 0,
  "causal": false,
  "dropout": 0.1,
  "emb_dim": 1024,
  "embed_init_std": 0.02209708691207961,
  "end_n_top": 5,
  "eos_index": 1,
  "eos_token_id": 2,
  "gelu_activation": true,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "init_std": 0.02,
  "initializer_range": 0.02,
  "intermediate_size": 4096,
  "is_encoder": true,
  "lang_id": 0,
  "layer_norm_eps": 1e-05,
  "mask_index": 5,
  "mask_token_id": 0,
  "max_position_embeddings": 514,
  "model_type": "xlm",
  "n_heads": 16,
  "n_langs": 1,
  "n_layers": 24,
  "output_past": true,
  "pad_index": 2,
  "pad_token_id": 1,
  "sinusoidal_embeddings": false,
  "start_n_top": 5,
  "summary_activation": null,
  "summary_first_dropout": 0.1,
  "summary_proj_to_labels": true,
  "summary_type": "first",
  "summary_use_proj": true,
  "transformers_version": "4.17.0",
  "type_vocab_size": 1,
  "unk_index": 3,
  "use_lang_emb": false,
  "vocab_size": 250002
}

Traceback (most recent call last):
  File "third_party/run_squad.py", line 958, in <module>
    main()
  File "third_party/run_squad.py", line 941, in main
    load_model(model, os.path.join(args.output_dir, "pytorch_model.bin"))
  File "third_party/run_squad.py", line 98, in load_model
    model.load_state_dict(torch.load(path, map_location='cpu'), strict=False)
  File "/cluster/project/sachan/yifan/softwares/anaconda/anaconda3/envs/xfactr/lib/python3.8/site-packages/torch/serialization.py", line 581, in load
    with _open_file_like(f, 'rb') as opened_file:
  File "/cluster/project/sachan/yifan/softwares/anaconda/anaconda3/envs/xfactr/lib/python3.8/site-packages/torch/serialization.py", line 230, in _open_file_like
    return _open_file(name_or_buffer, mode)
  File "/cluster/project/sachan/yifan/softwares/anaconda/anaconda3/envs/xfactr/lib/python3.8/site-packages/torch/serialization.py", line 211, in __init__
    super(_open_file, self).__init__(open(name, mode))
FileNotFoundError: [Errno 2] No such file or directory: '/cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//squad/xlm-KG_LR8e-6_EPOCH2.0_maxlen384_batchsize4_gradacc4/predictions/mlqa/pytorch_model.bin'
  hi 
2022-05-09 21:40:32.287097: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0
05/09/2022 21:40:35 - WARNING - __main__ -   Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, 16-bits training: False
You are using a model of type xlm-roberta to instantiate a model of type xlm. This is not supported for all configurations of models and can yield errors.
Some weights of the model checkpoint at /cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//squad/xlm-KG_LR8e-6_EPOCH2.0_maxlen384_batchsize4_gradacc4 were not used when initializing XLMRobertaModel: ['base_model.encoder.layer.13.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.10.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.23.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.5.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.8.output.LayerNorm.bias', 'base_model.encoder.layer.18.attention.self.query.weight', 'base_model.encoder.layer.18.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.23.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.14.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.21.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.22.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.21.intermediate.dense.weight', 'base_model.embeddings.position_embeddings.weight', 'base_model.encoder.layer.3.output.LayerNorm.weight', 'base_model.encoder.layer.10.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.16.output.dense.bias', 'base_model.encoder.layer.17.attention.self.value.bias', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.1.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.22.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.1.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.11.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.4.attention.self.key.weight', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.9.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.14.attention.self.value.bias', 'base_model.encoder.layer.2.intermediate.dense.bias', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.6.attention.self.query.bias', 'base_model.encoder.layer.16.intermediate.dense.bias', 'base_model.encoder.layer.16.output.dense.weight', 'base_model.encoder.layer.16.attention.output.LayerNorm.weight', 'base_model.encoder.layer.18.attention.output.dense.weight', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.8.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.22.output.dense.weight', 'base_model.encoder.layer.20.attention.output.dense.bias', 'base_model.encoder.layer.10.attention.self.query.bias', 'base_model.encoder.layer.10.output.dense.weight', 'base_model.encoder.layer.23.output.LayerNorm.bias', 'base_model.encoder.layer.4.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.9.attention.output.LayerNorm.weight', 'base_model.encoder.layer.19.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.20.intermediate.dense.weight', 'base_model.encoder.layer.15.intermediate.dense.weight', 'base_model.encoder.layer.16.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.16.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.14.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.23.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.13.intermediate.dense.weight', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.22.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.11.attention.output.dense.bias', 'base_model.encoder.layer.18.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.14.attention.output.LayerNorm.weight', 'base_model.encoder.layer.16.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.21.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.14.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.23.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.3.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.13.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.9.attention.self.query.weight', 'base_model.encoder.layer.2.attention.self.value.bias', 'base_model.encoder.layer.21.output.dense.weight', 'base_model.encoder.layer.21.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.0.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.0.attention.output.dense.weight', 'base_model.encoder.layer.5.attention.output.dense.bias', 'base_model.encoder.layer.5.attention.self.value.bias', 'base_model.encoder.layer.19.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.13.attention.self.query.bias', 'base_model.encoder.layer.12.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.11.attention.self.query.weight', 'base_model.encoder.layer.4.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.12.attention.self.key.weight', 'base_model.encoder.layer.7.attention.self.value.weight', 'base_model.encoder.layer.18.attention.self.value.bias', 'base_model.encoder.layer.15.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.14.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.9.output.dense.bias', 'base_model.encoder.layer.6.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.15.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.5.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.19.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.8.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.15.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.18.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.19.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.8.attention.output.dense.bias', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.9.attention.self.value.weight', 'base_model.encoder.layer.5.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.18.intermediate.dense.bias', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.4.output.LayerNorm.weight', 'base_model.encoder.layer.23.attention.self.value.weight', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.21.attention.output.dense.bias', 'base_model.encoder.layer.3.attention.self.key.weight', 'base_model.encoder.layer.16.attention.self.key.weight', 'base_model.encoder.layer.20.attention.self.key.weight', 'base_model.encoder.layer.13.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.22.attention.output.LayerNorm.weight', 'base_model.encoder.layer.20.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.22.intermediate.dense.bias', 'base_model.encoder.layer.15.intermediate.dense.bias', 'base_model.encoder.layer.15.output.dense.bias', 'base_model.encoder.layer.2.output.LayerNorm.weight', 'base_model.encoder.layer.4.attention.output.LayerNorm.weight', 'base_model.encoder.layer.13.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.6.output.dense.bias', 'base_model.encoder.layer.23.attention.output.dense.bias', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.7.attention.self.query.bias', 'base_model.encoder.layer.0.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.7.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.10.output.dense.bias', 'base_model.encoder.layer.21.attention.output.LayerNorm.bias', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.17.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.3.attention.output.dense.weight', 'base_model.encoder.layer.10.output.LayerNorm.bias', 'base_model.encoder.layer.11.attention.self.value.weight', 'base_model.encoder.layer.8.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.9.attention.self.value.bias', 'base_model.encoder.layer.14.attention.output.LayerNorm.bias', 'base_model.encoder.layer.18.output.adapters.ep.adapter_down.0.bias', 'base_model.embeddings.LayerNorm.bias', 'base_model.encoder.layer.3.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.17.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.1.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.2.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.21.attention.output.LayerNorm.weight', 'base_model.encoder.layer.18.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.17.attention.output.LayerNorm.weight', 'base_model.encoder.layer.3.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.7.attention.output.dense.bias', 'base_model.encoder.layer.7.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.1.output.LayerNorm.bias', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.16.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.11.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.1.attention.self.query.weight', 'base_model.encoder.layer.16.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.6.attention.self.query.weight', 'base_model.encoder.layer.22.attention.self.value.bias', 'base_model.encoder.layer.9.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.3.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.10.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.14.output.dense.bias', 'base_model.encoder.layer.8.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.12.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.4.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.20.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.1.output.LayerNorm.weight', 'base_model.encoder.layer.13.attention.self.key.weight', 'base_model.encoder.layer.4.attention.output.dense.bias', 'base_model.encoder.layer.13.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.7.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.19.attention.self.query.bias', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.17.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.10.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.7.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.5.attention.self.key.weight', 'base_model.encoder.layer.9.attention.self.key.bias', 'base_model.encoder.layer.8.output.LayerNorm.weight', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.18.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.10.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.9.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.4.attention.output.dense.weight', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.21.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.7.intermediate.dense.weight', 'base_model.encoder.layer.10.attention.output.LayerNorm.bias', 'base_model.encoder.layer.1.attention.output.LayerNorm.weight', 'base_model.encoder.layer.2.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.8.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.7.attention.self.key.weight', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.20.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.1.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.21.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.18.output.LayerNorm.weight', 'base_model.encoder.layer.2.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.19.attention.self.value.weight', 'base_model.encoder.layer.5.attention.output.LayerNorm.bias', 'base_model.encoder.layer.16.attention.output.LayerNorm.bias', 'base_model.encoder.layer.13.attention.self.value.bias', 'base_model.encoder.layer.20.attention.output.LayerNorm.weight', 'base_model.encoder.layer.2.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.23.attention.self.key.weight', 'base_model.encoder.layer.9.intermediate.dense.bias', 'base_model.encoder.layer.3.attention.self.value.bias', 'base_model.encoder.layer.3.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.20.attention.self.query.bias', 'base_model.encoder.layer.22.output.LayerNorm.weight', 'base_model.encoder.layer.11.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.12.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.7.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.6.attention.output.dense.bias', 'base_model.encoder.layer.15.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.21.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.5.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.5.output.LayerNorm.weight', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.18.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.18.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.6.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.15.attention.self.key.bias', 'base_model.encoder.layer.10.attention.self.key.weight', 'base_model.encoder.layer.4.output.LayerNorm.bias', 'base_model.encoder.layer.13.output.dense.bias', 'base_model.encoder.layer.1.intermediate.dense.weight', 'base_model.encoder.layer.17.output.dense.weight', 'base_model.encoder.layer.0.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.1.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.21.output.dense.bias', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.20.intermediate.dense.bias', 'base_model.encoder.layer.17.attention.output.LayerNorm.bias', 'base_model.encoder.layer.22.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.9.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.5.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.7.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.12.attention.self.value.bias', 'base_model.encoder.layer.23.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.16.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.11.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.12.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.1.attention.self.key.bias', 'base_model.encoder.layer.17.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.9.attention.output.dense.weight', 'base_model.encoder.layer.18.attention.output.dense.bias', 'base_model.encoder.layer.15.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.17.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.20.output.LayerNorm.bias', 'base_model.encoder.layer.14.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.11.attention.self.value.bias', 'base_model.encoder.layer.12.output.dense.weight', 'base_model.encoder.layer.9.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.11.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.0.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.19.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.17.output.LayerNorm.bias', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.20.output.adapters.tp.adapter_up.weight', 'base_model.embeddings.LayerNorm.weight', 'base_model.encoder.layer.8.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.7.attention.self.value.bias', 'base_model.encoder.layer.10.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.1.output.dense.bias', 'base_model.encoder.layer.9.intermediate.dense.weight', 'base_model.encoder.layer.17.intermediate.dense.weight', 'base_model.encoder.layer.13.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.18.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.1.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.12.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.18.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.5.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.3.attention.output.LayerNorm.weight', 'base_model.encoder.layer.23.output.LayerNorm.weight', 'base_model.encoder.layer.11.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.10.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.19.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.23.attention.self.key.bias', 'base_model.encoder.layer.0.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.19.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.7.output.LayerNorm.weight', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.1.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.6.attention.self.value.bias', 'base_model.encoder.layer.6.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.11.output.dense.bias', 'base_model.encoder.layer.19.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.embeddings.position_ids', 'base_model.encoder.layer.6.attention.self.value.weight', 'base_model.encoder.layer.23.attention.output.LayerNorm.bias', 'base_model.encoder.layer.3.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.1.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.15.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.11.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.22.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.6.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.6.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.12.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.5.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.8.attention.self.value.bias', 'base_model.encoder.layer.23.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.17.attention.self.key.bias', 'base_model.encoder.layer.12.output.LayerNorm.bias', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.0.output.LayerNorm.weight', 'base_model.encoder.layer.1.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.8.attention.output.LayerNorm.bias', 'base_model.encoder.layer.11.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.22.attention.output.dense.weight', 'base_model.encoder.layer.11.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.9.attention.self.query.bias', 'base_model.encoder.layer.17.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.5.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.3.output.LayerNorm.bias', 'base_model.encoder.layer.12.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.8.attention.self.query.weight', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.10.attention.self.value.bias', 'base_model.encoder.layer.0.attention.self.key.bias', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.14.output.LayerNorm.weight', 'base_model.encoder.layer.14.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.22.intermediate.dense.weight', 'base_model.encoder.layer.22.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.12.attention.output.dense.bias', 'base_model.encoder.layer.10.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.20.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.5.intermediate.dense.weight', 'base_model.encoder.layer.0.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.19.output.dense.weight', 'base_model.encoder.layer.21.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.4.attention.output.LayerNorm.bias', 'base_model.encoder.layer.23.attention.output.LayerNorm.weight', 'base_model.encoder.layer.15.attention.self.value.weight', 'base_model.encoder.layer.20.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.4.attention.self.value.bias', 'base_model.encoder.layer.4.output.dense.bias', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.23.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.7.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.2.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.9.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.11.output.LayerNorm.weight', 'base_model.encoder.layer.15.attention.output.dense.bias', 'base_model.encoder.layer.15.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.13.attention.self.value.weight', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.20.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.23.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.12.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.18.output.dense.bias', 'base_model.encoder.layer.16.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.22.output.adapters.ts.adapter_down.0.weight', 'base_model.embeddings.word_embeddings.weight', 'base_model.encoder.layer.9.attention.self.key.weight', 'base_model.encoder.layer.19.attention.self.key.bias', 'base_model.encoder.layer.6.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.1.attention.self.query.bias', 'base_model.encoder.layer.8.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.3.attention.self.key.bias', 'base_model.encoder.layer.6.attention.output.LayerNorm.weight', 'base_model.encoder.layer.21.output.LayerNorm.bias', 'base_model.encoder.layer.15.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.13.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.22.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.5.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.1.attention.output.dense.bias', 'base_model.encoder.layer.21.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.7.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.16.attention.output.dense.bias', 'base_model.encoder.layer.9.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.1.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.17.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.17.output.dense.bias', 'base_model.encoder.layer.23.output.dense.bias', 'base_model.encoder.layer.9.attention.output.LayerNorm.bias', 'base_model.encoder.layer.2.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.6.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.7.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.19.attention.output.dense.weight', 'base_model.encoder.layer.1.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.17.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.21.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.9.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.3.attention.output.LayerNorm.bias', 'base_model.encoder.layer.13.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.21.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.23.attention.self.query.weight', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.14.attention.self.key.weight', 'base_model.encoder.layer.21.attention.self.value.bias', 'base_model.encoder.layer.1.output.dense.weight', 'base_model.encoder.layer.2.attention.output.dense.bias', 'base_model.encoder.layer.4.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.11.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.21.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.0.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.3.attention.self.query.bias', 'base_model.encoder.layer.22.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.23.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.10.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.18.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.22.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.5.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.8.intermediate.dense.weight', 'base_model.encoder.layer.15.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.22.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.17.output.LayerNorm.weight', 'base_model.encoder.layer.2.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.8.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.11.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.19.attention.self.key.weight', 'base_model.encoder.layer.20.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.13.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.3.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.18.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.13.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.11.output.dense.weight', 'base_model.encoder.layer.5.intermediate.dense.bias', 'base_model.encoder.layer.10.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.12.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.2.output.dense.weight', 'base_model.encoder.layer.15.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.20.output.adapters.tp.adapter_down.0.bias', 'qa_outputs.weight', 'base_model.encoder.layer.4.intermediate.dense.bias', 'base_model.encoder.layer.20.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.21.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.13.attention.output.LayerNorm.bias', 'base_model.encoder.layer.11.attention.output.dense.weight', 'base_model.encoder.layer.22.attention.output.dense.bias', 'base_model.encoder.layer.0.intermediate.dense.weight', 'base_model.encoder.layer.16.attention.output.dense.weight', 'base_model.encoder.layer.19.output.dense.bias', 'base_model.encoder.layer.3.intermediate.dense.weight', 'base_model.encoder.layer.18.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.11.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.12.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.1.attention.self.key.weight', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.14.output.dense.weight', 'base_model.pooler.dense.weight', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.21.attention.self.key.bias', 'base_model.encoder.layer.5.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.4.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.1.attention.self.value.bias', 'base_model.encoder.layer.9.output.dense.weight', 'base_model.encoder.layer.2.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.13.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.2.attention.self.query.bias', 'base_model.encoder.layer.15.output.LayerNorm.bias', 'base_model.encoder.layer.20.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.13.attention.output.dense.bias', 'base_model.encoder.layer.3.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.13.attention.self.query.weight', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.19.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.2.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.5.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.14.intermediate.dense.bias', 'base_model.encoder.layer.0.intermediate.dense.bias', 'base_model.encoder.layer.2.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.10.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.3.output.dense.bias', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.17.attention.output.dense.bias', 'base_model.encoder.layer.6.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.23.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.14.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.6.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.0.attention.output.dense.bias', 'base_model.encoder.layer.18.output.dense.weight', 'base_model.encoder.layer.14.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.23.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.12.attention.self.query.bias', 'base_model.encoder.layer.0.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.15.attention.output.LayerNorm.weight', 'base_model.encoder.layer.16.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.22.attention.self.key.bias', 'base_model.encoder.layer.2.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.2.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.15.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.21.attention.self.key.weight', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.14.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.8.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.16.attention.self.query.weight', 'base_model.encoder.layer.6.attention.self.key.weight', 'base_model.encoder.layer.4.attention.self.query.weight', 'base_model.encoder.layer.0.attention.self.key.weight', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.10.attention.output.LayerNorm.weight', 'base_model.encoder.layer.7.attention.output.dense.weight', 'base_model.encoder.layer.22.output.dense.bias', 'base_model.encoder.layer.6.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.13.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.17.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.12.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.6.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.10.attention.self.query.weight', 'base_model.encoder.layer.8.output.dense.weight', 'base_model.encoder.layer.5.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.17.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.22.output.LayerNorm.bias', 'base_model.encoder.layer.20.attention.self.value.bias', 'base_model.encoder.layer.8.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.23.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.10.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.16.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.18.intermediate.dense.weight', 'base_model.encoder.layer.15.attention.self.query.bias', 'base_model.encoder.layer.0.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.12.intermediate.dense.bias', 'base_model.encoder.layer.18.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.2.attention.output.dense.weight', 'base_model.encoder.layer.0.attention.output.LayerNorm.weight', 'base_model.encoder.layer.2.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.4.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.3.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.4.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.17.attention.self.key.weight', 'base_model.encoder.layer.0.attention.output.LayerNorm.bias', 'base_model.encoder.layer.23.output.dense.weight', 'base_model.encoder.layer.16.attention.self.value.bias', 'base_model.encoder.layer.3.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.19.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.23.attention.self.query.bias', 'base_model.encoder.layer.11.attention.self.key.bias', 'base_model.encoder.layer.12.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.9.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.22.attention.self.value.weight', 'base_model.encoder.layer.8.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.8.attention.output.dense.weight', 'base_model.encoder.layer.13.attention.output.dense.weight', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.23.attention.self.value.bias', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.11.intermediate.dense.bias', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.9.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.19.attention.output.LayerNorm.weight', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.12.attention.self.query.weight', 'base_model.encoder.layer.18.attention.self.key.weight', 'base_model.encoder.layer.16.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.16.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.18.attention.output.LayerNorm.bias', 'base_model.encoder.layer.17.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.17.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.2.output.LayerNorm.bias', 'base_model.encoder.layer.21.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.8.attention.self.key.bias', 'base_model.encoder.layer.17.attention.output.dense.weight', 'base_model.encoder.layer.10.attention.output.dense.weight', 'base_model.encoder.layer.12.attention.output.LayerNorm.bias', 'base_model.encoder.layer.3.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.20.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.13.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.13.intermediate.dense.bias', 'base_model.encoder.layer.14.attention.self.key.bias', 'base_model.encoder.layer.12.attention.self.key.bias', 'base_model.encoder.layer.19.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.10.intermediate.dense.weight', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.1.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.11.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.7.attention.output.LayerNorm.bias', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.22.attention.self.query.bias', 'base_model.encoder.layer.9.output.LayerNorm.bias', 'base_model.encoder.layer.23.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.7.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.1.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.4.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.18.attention.self.key.bias', 'base_model.encoder.layer.0.attention.self.value.weight', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.19.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.12.intermediate.dense.weight', 'base_model.encoder.layer.16.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.7.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.6.attention.output.LayerNorm.bias', 'base_model.encoder.layer.20.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.8.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.4.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.14.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.3.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.11.attention.output.LayerNorm.bias', 'base_model.encoder.layer.11.output.LayerNorm.bias', 'base_model.encoder.layer.0.attention.self.query.bias', 'base_model.encoder.layer.4.output.dense.weight', 'base_model.encoder.layer.9.attention.output.dense.bias', 'base_model.encoder.layer.10.output.LayerNorm.weight', 'base_model.encoder.layer.10.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.19.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.3.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.0.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.3.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.15.attention.self.key.weight', 'base_model.encoder.layer.2.attention.output.LayerNorm.bias', 'base_model.encoder.layer.14.attention.output.dense.bias', 'base_model.encoder.layer.19.intermediate.dense.weight', 'base_model.encoder.layer.19.attention.output.dense.bias', 'base_model.embeddings.token_type_embeddings.weight', 'base_model.encoder.layer.15.output.LayerNorm.weight', 'base_model.encoder.layer.21.intermediate.dense.bias', 'base_model.encoder.layer.23.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.11.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.21.attention.self.value.weight', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.11.attention.self.key.weight', 'base_model.encoder.layer.6.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.19.attention.output.LayerNorm.bias', 'base_model.encoder.layer.12.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.6.output.LayerNorm.bias', 'base_model.encoder.layer.6.attention.output.dense.weight', 'base_model.encoder.layer.10.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.7.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.23.attention.output.dense.weight', 'base_model.encoder.layer.22.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.7.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.13.attention.output.LayerNorm.weight', 'base_model.encoder.layer.22.attention.self.query.weight', 'base_model.encoder.layer.17.attention.self.query.weight', 'base_model.encoder.layer.0.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.5.output.LayerNorm.bias', 'base_model.encoder.layer.10.attention.output.dense.bias', 'base_model.encoder.layer.22.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.4.attention.self.value.weight', 'base_model.encoder.layer.16.output.LayerNorm.bias', 'base_model.encoder.layer.3.attention.self.value.weight', 'base_model.encoder.layer.10.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.12.attention.self.value.weight', 'base_model.encoder.layer.19.output.LayerNorm.bias', 'base_model.encoder.layer.12.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.6.output.dense.weight', 'base_model.encoder.layer.22.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.15.attention.self.query.weight', 'base_model.encoder.layer.7.attention.self.key.bias', 'base_model.encoder.layer.0.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.3.attention.self.query.weight', 'base_model.encoder.layer.4.attention.self.key.bias', 'base_model.encoder.layer.20.output.adapters.ep.adapter_down.0.bias', 'qa_outputs.bias', 'base_model.encoder.layer.20.attention.output.LayerNorm.bias', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.14.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.22.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.9.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.12.output.dense.bias', 'base_model.encoder.layer.10.intermediate.dense.bias', 'base_model.encoder.layer.6.intermediate.dense.bias', 'base_model.encoder.layer.22.attention.output.LayerNorm.bias', 'base_model.encoder.layer.15.output.dense.weight', 'base_model.encoder.layer.20.output.dense.weight', 'base_model.encoder.layer.14.attention.output.dense.weight', 'base_model.encoder.layer.8.attention.self.value.weight', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.8.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.5.attention.output.dense.weight', 'base_model.encoder.layer.19.intermediate.dense.bias', 'base_model.encoder.layer.17.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.3.intermediate.dense.bias', 'base_model.encoder.layer.5.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.1.intermediate.dense.bias', 'base_model.encoder.layer.2.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.4.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.0.attention.self.query.weight', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.19.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.21.output.LayerNorm.weight', 'base_model.encoder.layer.7.output.dense.weight', 'base_model.encoder.layer.2.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.5.output.dense.weight', 'base_model.encoder.layer.0.output.dense.bias', 'base_model.encoder.layer.13.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.20.attention.self.value.weight', 'base_model.encoder.layer.10.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.8.attention.output.LayerNorm.weight', 'base_model.encoder.layer.21.attention.self.query.weight', 'base_model.encoder.layer.15.attention.output.dense.weight', 'base_model.encoder.layer.19.attention.self.value.bias', 'base_model.encoder.layer.4.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.14.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.17.attention.self.value.weight', 'base_model.encoder.layer.2.attention.self.value.weight', 'base_model.encoder.layer.1.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.16.output.LayerNorm.weight', 'base_model.encoder.layer.5.attention.self.query.bias', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.10.attention.self.value.weight', 'base_model.encoder.layer.14.output.LayerNorm.bias', 'base_model.encoder.layer.20.output.dense.bias', 'base_model.encoder.layer.21.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.13.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.20.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.15.attention.output.LayerNorm.bias', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.1.attention.self.value.weight', 'base_model.encoder.layer.17.attention.self.query.bias', 'base_model.encoder.layer.17.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.8.attention.self.key.weight', 'base_model.encoder.layer.5.attention.output.LayerNorm.weight', 'base_model.encoder.layer.2.attention.self.query.weight', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.4.attention.self.query.bias', 'base_model.encoder.layer.7.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.18.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.15.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.14.intermediate.dense.weight', 'base_model.encoder.layer.0.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.0.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.18.output.LayerNorm.bias', 'base_model.encoder.layer.5.output.dense.bias', 'base_model.encoder.layer.8.attention.self.query.bias', 'base_model.encoder.layer.2.attention.self.key.bias', 'base_model.encoder.layer.10.attention.self.key.bias', 'base_model.encoder.layer.12.output.LayerNorm.weight', 'base_model.encoder.layer.0.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.2.intermediate.dense.weight', 'base_model.encoder.layer.8.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.21.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.14.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.4.intermediate.dense.weight', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.2.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.8.output.dense.bias', 'base_model.encoder.layer.12.attention.output.LayerNorm.weight', 'base_model.encoder.layer.6.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.0.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.12.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.8.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.16.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.19.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.7.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.1.attention.output.LayerNorm.bias', 'base_model.encoder.layer.21.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.4.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.9.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.20.attention.self.key.bias', 'base_model.encoder.layer.15.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.20.output.LayerNorm.weight', 'base_model.encoder.layer.3.output.dense.weight', 'base_model.encoder.layer.15.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.20.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.5.attention.self.query.weight', 'base_model.encoder.layer.3.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.14.attention.self.query.weight', 'base_model.encoder.layer.4.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.6.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.7.attention.self.query.weight', 'base_model.encoder.layer.1.attention.output.dense.weight', 'base_model.encoder.layer.1.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.5.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.6.intermediate.dense.weight', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.22.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.0.output.LayerNorm.bias', 'base_model.encoder.layer.4.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.13.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.6.output.adapters.ts.adapter_up.weight', 'base_model.pooler.dense.bias', 'base_model.encoder.layer.2.output.dense.bias', 'base_model.encoder.layer.7.output.LayerNorm.bias', 'base_model.encoder.layer.7.attention.output.LayerNorm.weight', 'base_model.encoder.layer.20.attention.self.query.weight', 'base_model.encoder.layer.7.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.13.output.LayerNorm.bias', 'base_model.encoder.layer.21.attention.self.query.bias', 'base_model.encoder.layer.14.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.19.attention.self.query.weight', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.12.attention.output.dense.weight', 'base_model.encoder.layer.15.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.11.attention.output.LayerNorm.weight', 'base_model.encoder.layer.18.attention.self.value.weight', 'base_model.encoder.layer.5.attention.self.key.bias', 'base_model.encoder.layer.0.output.dense.weight', 'base_model.encoder.layer.23.intermediate.dense.bias', 'base_model.encoder.layer.20.attention.output.dense.weight', 'base_model.encoder.layer.15.attention.self.value.bias', 'base_model.encoder.layer.11.intermediate.dense.weight', 'base_model.encoder.layer.7.intermediate.dense.bias', 'base_model.encoder.layer.16.intermediate.dense.weight', 'base_model.encoder.layer.8.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.9.output.LayerNorm.weight', 'base_model.encoder.layer.23.intermediate.dense.weight', 'base_model.encoder.layer.16.attention.self.value.weight', 'base_model.encoder.layer.23.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.9.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.19.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.17.intermediate.dense.bias', 'base_model.encoder.layer.13.attention.self.key.bias', 'base_model.encoder.layer.14.attention.self.query.bias', 'base_model.encoder.layer.6.attention.self.key.bias', 'base_model.encoder.layer.16.attention.self.query.bias', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.13.output.dense.weight', 'base_model.encoder.layer.11.attention.self.query.bias', 'base_model.encoder.layer.6.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.18.attention.output.LayerNorm.weight', 'base_model.encoder.layer.11.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.16.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.22.attention.self.key.weight', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.9.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.8.intermediate.dense.bias', 'base_model.encoder.layer.16.attention.self.key.bias', 'base_model.encoder.layer.18.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.23.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.5.attention.self.value.weight', 'base_model.encoder.layer.14.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.3.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.5.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.9.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.15.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.4.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.4.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.14.attention.self.value.weight', 'base_model.encoder.layer.13.output.LayerNorm.weight', 'base_model.encoder.layer.11.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.6.output.LayerNorm.weight', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.18.attention.self.query.bias', 'base_model.encoder.layer.0.attention.self.value.bias', 'base_model.encoder.layer.19.output.LayerNorm.weight', 'base_model.encoder.layer.2.attention.output.LayerNorm.weight', 'base_model.encoder.layer.16.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.3.attention.output.dense.bias', 'base_model.encoder.layer.21.attention.output.dense.weight', 'base_model.encoder.layer.7.output.dense.bias', 'base_model.encoder.layer.2.attention.self.key.weight', 'base_model.encoder.layer.17.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.14.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.16.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.17.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.9.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.1.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.12.output.adapters.es.adapter_up.bias']
- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of XLMRobertaModel were not initialized from the model checkpoint at /cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//squad/xlm-KG_LR8e-6_EPOCH2.0_maxlen384_batchsize4_gradacc4 and are newly initialized: ['encoder.layer.5.output.dense.weight', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.5.output.LayerNorm.bias', 'encoder.layer.1.attention.self.key.bias', 'encoder.layer.1.attention.self.value.bias', 'encoder.layer.4.attention.output.dense.bias', 'encoder.layer.10.attention.self.value.weight', 'encoder.layer.16.attention.self.value.bias', 'encoder.layer.15.output.dense.weight', 'encoder.layer.13.attention.output.LayerNorm.weight', 'encoder.layer.2.attention.output.dense.weight', 'encoder.layer.21.attention.output.dense.weight', 'encoder.layer.20.attention.self.query.weight', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.10.attention.self.key.weight', 'encoder.layer.9.output.dense.bias', 'encoder.layer.12.output.dense.bias', 'encoder.layer.18.output.LayerNorm.bias', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.10.output.LayerNorm.bias', 'encoder.layer.21.attention.self.query.weight', 'encoder.layer.21.output.dense.bias', 'encoder.layer.5.attention.self.value.weight', 'encoder.layer.22.intermediate.dense.bias', 'encoder.layer.13.attention.output.LayerNorm.bias', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.19.output.LayerNorm.weight', 'encoder.layer.15.attention.output.dense.bias', 'encoder.layer.5.attention.self.query.bias', 'encoder.layer.16.attention.self.value.weight', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.23.intermediate.dense.bias', 'pooler.dense.bias', 'encoder.layer.10.attention.self.query.weight', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.9.attention.output.dense.weight', 'encoder.layer.17.intermediate.dense.bias', 'encoder.layer.2.attention.self.value.bias', 'encoder.layer.6.attention.self.value.bias', 'encoder.layer.3.attention.self.value.weight', 'encoder.layer.19.attention.output.dense.bias', 'encoder.layer.14.attention.self.key.bias', 'encoder.layer.11.attention.self.key.weight', 'encoder.layer.23.attention.output.LayerNorm.bias', 'encoder.layer.4.attention.output.dense.weight', 'encoder.layer.16.attention.output.dense.weight', 'encoder.layer.16.output.dense.bias', 'encoder.layer.0.attention.self.value.bias', 'encoder.layer.0.attention.self.key.bias', 'encoder.layer.23.output.dense.weight', 'encoder.layer.11.attention.self.key.bias', 'encoder.layer.19.attention.output.LayerNorm.weight', 'encoder.layer.21.output.LayerNorm.bias', 'encoder.layer.22.output.LayerNorm.bias', 'encoder.layer.18.attention.self.value.weight', 'encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.13.attention.self.key.bias', 'encoder.layer.11.attention.self.query.weight', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.17.attention.output.LayerNorm.bias', 'encoder.layer.6.attention.output.dense.bias', 'encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.layer.12.attention.self.key.bias', 'encoder.layer.15.attention.self.key.bias', 'encoder.layer.20.attention.self.key.weight', 'encoder.layer.15.intermediate.dense.weight', 'encoder.layer.23.attention.self.value.bias', 'encoder.layer.12.intermediate.dense.bias', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.8.output.dense.bias', 'encoder.layer.12.attention.output.LayerNorm.weight', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.7.attention.output.LayerNorm.weight', 'encoder.layer.17.output.LayerNorm.weight', 'encoder.layer.8.output.LayerNorm.bias', 'encoder.layer.21.output.dense.weight', 'encoder.layer.0.attention.self.query.bias', 'encoder.layer.6.attention.output.LayerNorm.bias', 'encoder.layer.7.output.dense.bias', 'encoder.layer.17.attention.self.key.bias', 'encoder.layer.5.attention.self.value.bias', 'encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.layer.9.attention.self.value.weight', 'encoder.layer.16.output.LayerNorm.bias', 'encoder.layer.13.attention.output.dense.bias', 'encoder.layer.14.attention.self.value.weight', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.22.attention.self.query.bias', 'encoder.layer.12.attention.self.query.bias', 'encoder.layer.9.attention.output.LayerNorm.weight', 'encoder.layer.8.attention.output.LayerNorm.bias', 'encoder.layer.22.attention.output.LayerNorm.weight', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.15.attention.self.value.bias', 'encoder.layer.7.attention.self.value.weight', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.9.attention.self.query.bias', 'encoder.layer.21.attention.self.key.bias', 'encoder.layer.14.attention.self.query.weight', 'encoder.layer.14.attention.self.key.weight', 'encoder.layer.7.attention.output.dense.bias', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.9.attention.output.dense.bias', 'encoder.layer.16.attention.self.query.weight', 'encoder.layer.22.attention.output.dense.weight', 'encoder.layer.9.output.LayerNorm.bias', 'encoder.layer.3.attention.self.query.weight', 'encoder.layer.2.attention.self.key.bias', 'encoder.layer.15.attention.self.value.weight', 'encoder.layer.8.attention.output.dense.bias', 'encoder.layer.11.attention.output.LayerNorm.weight', 'encoder.layer.7.attention.self.key.bias', 'encoder.layer.23.output.LayerNorm.weight', 'encoder.layer.18.attention.self.key.weight', 'encoder.layer.21.output.LayerNorm.weight', 'encoder.layer.13.attention.self.key.weight', 'encoder.layer.18.attention.output.dense.weight', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.1.attention.output.dense.weight', 'encoder.layer.8.attention.output.dense.weight', 'encoder.layer.11.output.dense.weight', 'encoder.layer.4.attention.self.query.weight', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.22.attention.self.query.weight', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.7.output.dense.weight', 'encoder.layer.22.attention.output.dense.bias', 'encoder.layer.12.output.LayerNorm.weight', 'encoder.layer.20.output.dense.bias', 'encoder.layer.17.attention.self.query.bias', 'encoder.layer.0.attention.output.LayerNorm.weight', 'encoder.layer.3.attention.self.query.bias', 'encoder.layer.18.output.LayerNorm.weight', 'encoder.layer.6.output.dense.weight', 'encoder.layer.5.attention.output.dense.weight', 'encoder.layer.12.attention.output.dense.weight', 'encoder.layer.23.attention.self.query.bias', 'encoder.layer.20.intermediate.dense.weight', 'encoder.layer.6.attention.output.LayerNorm.weight', 'encoder.layer.4.output.dense.weight', 'encoder.layer.17.attention.self.query.weight', 'encoder.layer.22.attention.self.key.weight', 'encoder.layer.2.attention.self.key.weight', 'encoder.layer.15.attention.self.query.bias', 'encoder.layer.1.attention.output.LayerNorm.weight', 'encoder.layer.23.attention.self.key.bias', 'encoder.layer.12.attention.self.query.weight', 'encoder.layer.4.attention.self.query.bias', 'encoder.layer.23.attention.output.dense.weight', 'encoder.layer.7.attention.self.value.bias', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.5.attention.self.key.bias', 'encoder.layer.11.output.LayerNorm.bias', 'encoder.layer.3.attention.output.dense.bias', 'embeddings.position_embeddings.weight', 'encoder.layer.7.output.LayerNorm.bias', 'encoder.layer.1.output.dense.bias', 'encoder.layer.12.intermediate.dense.weight', 'encoder.layer.15.attention.output.LayerNorm.weight', 'encoder.layer.11.attention.output.dense.weight', 'encoder.layer.15.output.LayerNorm.weight', 'encoder.layer.6.attention.self.query.bias', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.3.attention.output.dense.weight', 'encoder.layer.3.attention.self.key.bias', 'encoder.layer.2.attention.output.dense.bias', 'encoder.layer.13.output.LayerNorm.bias', 'pooler.dense.weight', 'encoder.layer.17.output.dense.weight', 'encoder.layer.1.attention.output.dense.bias', 'encoder.layer.6.attention.self.key.weight', 'encoder.layer.19.attention.self.query.bias', 'encoder.layer.14.attention.self.query.bias', 'encoder.layer.11.attention.self.value.bias', 'encoder.layer.21.attention.output.dense.bias', 'embeddings.token_type_embeddings.weight', 'encoder.layer.21.intermediate.dense.weight', 'encoder.layer.14.attention.self.value.bias', 'encoder.layer.11.attention.self.value.weight', 'encoder.layer.17.output.dense.bias', 'encoder.layer.14.attention.output.LayerNorm.weight', 'encoder.layer.10.attention.output.dense.weight', 'encoder.layer.14.attention.output.dense.weight', 'encoder.layer.3.output.dense.weight', 'encoder.layer.18.attention.self.query.bias', 'encoder.layer.15.attention.output.LayerNorm.bias', 'encoder.layer.21.attention.self.key.weight', 'encoder.layer.20.attention.self.key.bias', 'encoder.layer.21.attention.self.value.weight', 'encoder.layer.16.output.LayerNorm.weight', 'encoder.layer.8.output.dense.weight', 'encoder.layer.5.output.dense.bias', 'encoder.layer.8.attention.self.value.bias', 'encoder.layer.16.attention.output.dense.bias', 'encoder.layer.9.attention.output.LayerNorm.bias', 'encoder.layer.10.attention.output.LayerNorm.bias', 'encoder.layer.11.attention.self.query.bias', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.6.attention.self.query.weight', 'encoder.layer.21.attention.output.LayerNorm.weight', 'encoder.layer.16.attention.self.query.bias', 'encoder.layer.20.attention.output.LayerNorm.weight', 'encoder.layer.21.attention.output.LayerNorm.bias', 'encoder.layer.9.output.dense.weight', 'encoder.layer.1.intermediate.dense.bias', 'embeddings.word_embeddings.weight', 'encoder.layer.19.attention.self.query.weight', 'encoder.layer.17.intermediate.dense.weight', 'encoder.layer.8.attention.self.query.weight', 'encoder.layer.10.output.dense.bias', 'encoder.layer.7.output.LayerNorm.weight', 'encoder.layer.19.attention.output.LayerNorm.bias', 'encoder.layer.22.attention.self.key.bias', 'encoder.layer.14.output.LayerNorm.bias', 'encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.18.attention.self.value.bias', 'encoder.layer.10.attention.self.query.bias', 'encoder.layer.4.attention.output.LayerNorm.weight', 'encoder.layer.15.attention.output.dense.weight', 'encoder.layer.20.attention.output.LayerNorm.bias', 'encoder.layer.4.attention.self.key.bias', 'encoder.layer.21.attention.self.query.bias', 'encoder.layer.1.attention.self.value.weight', 'encoder.layer.7.attention.output.dense.weight', 'encoder.layer.15.attention.self.query.weight', 'encoder.layer.13.output.dense.weight', 'encoder.layer.6.output.dense.bias', 'encoder.layer.17.attention.self.key.weight', 'encoder.layer.14.attention.output.LayerNorm.bias', 'encoder.layer.19.output.dense.bias', 'encoder.layer.11.attention.output.dense.bias', 'encoder.layer.1.attention.self.query.bias', 'encoder.layer.3.output.LayerNorm.bias', 'embeddings.LayerNorm.weight', 'encoder.layer.20.output.LayerNorm.weight', 'encoder.layer.13.intermediate.dense.bias', 'encoder.layer.6.attention.self.value.weight', 'encoder.layer.8.attention.self.query.bias', 'encoder.layer.18.attention.output.LayerNorm.weight', 'encoder.layer.0.attention.self.key.weight', 'encoder.layer.21.intermediate.dense.bias', 'encoder.layer.19.attention.self.value.bias', 'encoder.layer.19.attention.self.value.weight', 'encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.layer.6.output.LayerNorm.bias', 'encoder.layer.19.output.dense.weight', 'encoder.layer.4.output.dense.bias', 'encoder.layer.4.attention.self.value.bias', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.12.attention.self.value.weight', 'encoder.layer.8.attention.self.key.bias', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.0.attention.self.query.weight', 'encoder.layer.2.attention.self.query.bias', 'encoder.layer.23.attention.output.LayerNorm.weight', 'encoder.layer.13.attention.self.query.bias', 'encoder.layer.10.output.LayerNorm.weight', 'encoder.layer.16.output.dense.weight', 'encoder.layer.14.attention.output.dense.bias', 'encoder.layer.18.intermediate.dense.bias', 'encoder.layer.2.attention.output.LayerNorm.bias', 'encoder.layer.22.output.dense.bias', 'encoder.layer.20.attention.self.query.bias', 'encoder.layer.0.output.dense.weight', 'encoder.layer.23.output.LayerNorm.bias', 'encoder.layer.17.attention.output.dense.bias', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.11.output.LayerNorm.weight', 'encoder.layer.0.attention.output.dense.bias', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.4.attention.self.key.weight', 'encoder.layer.7.attention.output.LayerNorm.bias', 'encoder.layer.13.intermediate.dense.weight', 'encoder.layer.20.attention.self.value.weight', 'encoder.layer.23.attention.self.key.weight', 'encoder.layer.16.attention.output.LayerNorm.bias', 'encoder.layer.22.output.dense.weight', 'encoder.layer.16.attention.output.LayerNorm.weight', 'encoder.layer.13.output.LayerNorm.weight', 'encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.layer.11.output.dense.bias', 'encoder.layer.18.output.dense.bias', 'encoder.layer.5.attention.output.LayerNorm.weight', 'encoder.layer.18.intermediate.dense.weight', 'encoder.layer.4.attention.output.LayerNorm.bias', 'encoder.layer.17.attention.output.LayerNorm.weight', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.18.attention.self.key.bias', 'embeddings.LayerNorm.bias', 'encoder.layer.14.output.dense.bias', 'encoder.layer.12.attention.self.key.weight', 'encoder.layer.18.attention.output.dense.bias', 'encoder.layer.8.output.LayerNorm.weight', 'encoder.layer.20.attention.output.dense.weight', 'encoder.layer.17.attention.self.value.bias', 'encoder.layer.23.attention.self.query.weight', 'encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.layer.13.attention.self.query.weight', 'encoder.layer.3.output.dense.bias', 'encoder.layer.9.attention.self.key.weight', 'encoder.layer.0.attention.output.dense.weight', 'encoder.layer.8.attention.self.key.weight', 'encoder.layer.5.attention.self.query.weight', 'encoder.layer.3.attention.self.value.bias', 'encoder.layer.2.attention.self.value.weight', 'encoder.layer.1.attention.self.query.weight', 'encoder.layer.2.output.dense.weight', 'encoder.layer.14.intermediate.dense.bias', 'encoder.layer.15.intermediate.dense.bias', 'encoder.layer.17.attention.output.dense.weight', 'encoder.layer.9.attention.self.key.bias', 'encoder.layer.15.output.dense.bias', 'encoder.layer.20.intermediate.dense.bias', 'encoder.layer.7.intermediate.dense.bias', 'encoder.layer.10.intermediate.dense.weight', 'encoder.layer.10.attention.output.dense.bias', 'encoder.layer.22.intermediate.dense.weight', 'encoder.layer.22.attention.output.LayerNorm.bias', 'encoder.layer.6.attention.output.dense.weight', 'encoder.layer.15.output.LayerNorm.bias', 'encoder.layer.5.attention.output.dense.bias', 'encoder.layer.16.attention.self.key.bias', 'encoder.layer.23.output.dense.bias', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.12.attention.output.LayerNorm.bias', 'encoder.layer.15.attention.self.key.weight', 'encoder.layer.19.intermediate.dense.weight', 'encoder.layer.21.attention.self.value.bias', 'encoder.layer.18.attention.self.query.weight', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.7.attention.self.key.weight', 'encoder.layer.19.intermediate.dense.bias', 'encoder.layer.10.attention.output.LayerNorm.weight', 'encoder.layer.10.attention.self.key.bias', 'encoder.layer.23.attention.output.dense.bias', 'encoder.layer.13.attention.self.value.weight', 'encoder.layer.6.attention.self.key.bias', 'encoder.layer.20.attention.output.dense.bias', 'encoder.layer.13.attention.output.dense.weight', 'encoder.layer.5.attention.self.key.weight', 'encoder.layer.23.intermediate.dense.weight', 'encoder.layer.18.attention.output.LayerNorm.bias', 'encoder.layer.8.attention.self.value.weight', 'encoder.layer.10.attention.self.value.bias', 'encoder.layer.1.attention.self.key.weight', 'encoder.layer.13.attention.self.value.bias', 'encoder.layer.23.attention.self.value.weight', 'encoder.layer.14.output.LayerNorm.weight', 'encoder.layer.18.output.dense.weight', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.9.attention.self.value.bias', 'encoder.layer.3.attention.self.key.weight', 'encoder.layer.22.output.LayerNorm.weight', 'encoder.layer.20.output.dense.weight', 'encoder.layer.9.output.LayerNorm.weight', 'encoder.layer.16.intermediate.dense.bias', 'encoder.layer.19.output.LayerNorm.bias', 'encoder.layer.7.attention.self.query.bias', 'encoder.layer.16.intermediate.dense.weight', 'encoder.layer.7.attention.self.query.weight', 'encoder.layer.22.attention.self.value.weight', 'encoder.layer.0.attention.self.value.weight', 'encoder.layer.2.attention.self.query.weight', 'encoder.layer.20.output.LayerNorm.bias', 'encoder.layer.19.attention.self.key.bias', 'encoder.layer.2.output.dense.bias', 'encoder.layer.0.output.dense.bias', 'encoder.layer.20.attention.self.value.bias', 'encoder.layer.12.output.LayerNorm.bias', 'encoder.layer.13.output.dense.bias', 'encoder.layer.4.attention.self.value.weight', 'encoder.layer.2.attention.output.LayerNorm.weight', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.10.output.dense.weight', 'encoder.layer.19.attention.output.dense.weight', 'encoder.layer.14.intermediate.dense.weight', 'encoder.layer.16.attention.self.key.weight', 'encoder.layer.1.output.dense.weight', 'encoder.layer.12.output.dense.weight', 'encoder.layer.9.attention.self.query.weight', 'encoder.layer.14.output.dense.weight', 'encoder.layer.19.attention.self.key.weight', 'encoder.layer.22.attention.self.value.bias', 'encoder.layer.12.attention.output.dense.bias', 'encoder.layer.17.output.LayerNorm.bias', 'encoder.layer.12.attention.self.value.bias', 'encoder.layer.17.attention.self.value.weight', 'encoder.layer.8.attention.output.LayerNorm.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Overwriting existing adapter 'ep'.
Overwriting existing adapter 'tp'.
Overwriting existing adapter 'es'.
Overwriting existing adapter 'ts'.
Overwriting existing adapter fusion module 'ep,tp,es,ts'
05/09/2022 21:40:56 - INFO - __main__ -   lang2id = None
05/09/2022 21:40:59 - INFO - __main__ -   Training/evaluation parameters Namespace(adam_epsilon=1e-08, cache_dir='', config_name='', data_dir=None, device=device(type='cuda'), do_eval=True, do_lower_case=False, do_train=False, doc_stride=128, eval_all_checkpoints=False, eval_lang='hi', evaluate_during_training=False, fp16=False, fp16_opt_level='O1', gradient_accumulation_steps=1, learning_rate=5e-05, local_rank=-1, logging_steps=50, max_answer_length=30, max_grad_norm=1.0, max_query_length=64, max_seq_length=384, max_steps=-1, model_name='xlm-KG', model_name_or_path='/cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//squad/xlm-KG_LR8e-6_EPOCH2.0_maxlen384_batchsize4_gradacc4', model_type='xlm', modelkg_dir='/cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/adapter/xlmr_adapter', n_best_size=20, n_gpu=1, no_cuda=False, null_score_diff_threshold=0.0, num_train_epochs=3.0, output_dir='/cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//squad/xlm-KG_LR8e-6_EPOCH2.0_maxlen384_batchsize4_gradacc4/predictions/mlqa/', overwrite_cache=False, overwrite_output_dir=False, per_gpu_eval_batch_size=8, per_gpu_train_batch_size=8, predict_file='/cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/download//mlqa//MLQA_V1/test/test-context-hi-question-hi.json', save_steps=50, seed=42, server_ip='', server_port='', threads=1, tokenizer_name='', train_file=None, train_lang='en', verbose_logging=False, version_2_with_negative=False, warmup_steps=0, weight_decay=0.0)
05/09/2022 21:40:59 - INFO - __main__ -   Loading checkpoint /cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//squad/xlm-KG_LR8e-6_EPOCH2.0_maxlen384_batchsize4_gradacc4 for evaluation
05/09/2022 21:40:59 - INFO - __main__ -   Evaluate the following checkpoints: ['/cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//squad/xlm-KG_LR8e-6_EPOCH2.0_maxlen384_batchsize4_gradacc4']
Some weights of the model checkpoint at /cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//squad/xlm-KG_LR8e-6_EPOCH2.0_maxlen384_batchsize4_gradacc4 were not used when initializing XLMRobertaModel: ['base_model.encoder.layer.13.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.10.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.23.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.5.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.8.output.LayerNorm.bias', 'base_model.encoder.layer.18.attention.self.query.weight', 'base_model.encoder.layer.18.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.23.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.14.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.21.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.22.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.21.intermediate.dense.weight', 'base_model.embeddings.position_embeddings.weight', 'base_model.encoder.layer.3.output.LayerNorm.weight', 'base_model.encoder.layer.10.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.16.output.dense.bias', 'base_model.encoder.layer.17.attention.self.value.bias', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.1.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.22.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.1.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.11.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.4.attention.self.key.weight', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.9.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.14.attention.self.value.bias', 'base_model.encoder.layer.2.intermediate.dense.bias', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.6.attention.self.query.bias', 'base_model.encoder.layer.16.intermediate.dense.bias', 'base_model.encoder.layer.16.output.dense.weight', 'base_model.encoder.layer.16.attention.output.LayerNorm.weight', 'base_model.encoder.layer.18.attention.output.dense.weight', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.8.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.22.output.dense.weight', 'base_model.encoder.layer.20.attention.output.dense.bias', 'base_model.encoder.layer.10.attention.self.query.bias', 'base_model.encoder.layer.10.output.dense.weight', 'base_model.encoder.layer.23.output.LayerNorm.bias', 'base_model.encoder.layer.4.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.9.attention.output.LayerNorm.weight', 'base_model.encoder.layer.19.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.20.intermediate.dense.weight', 'base_model.encoder.layer.15.intermediate.dense.weight', 'base_model.encoder.layer.16.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.16.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.14.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.23.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.13.intermediate.dense.weight', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.22.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.11.attention.output.dense.bias', 'base_model.encoder.layer.18.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.14.attention.output.LayerNorm.weight', 'base_model.encoder.layer.16.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.21.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.14.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.23.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.3.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.13.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.9.attention.self.query.weight', 'base_model.encoder.layer.2.attention.self.value.bias', 'base_model.encoder.layer.21.output.dense.weight', 'base_model.encoder.layer.21.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.0.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.0.attention.output.dense.weight', 'base_model.encoder.layer.5.attention.output.dense.bias', 'base_model.encoder.layer.5.attention.self.value.bias', 'base_model.encoder.layer.19.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.13.attention.self.query.bias', 'base_model.encoder.layer.12.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.11.attention.self.query.weight', 'base_model.encoder.layer.4.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.12.attention.self.key.weight', 'base_model.encoder.layer.7.attention.self.value.weight', 'base_model.encoder.layer.18.attention.self.value.bias', 'base_model.encoder.layer.15.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.14.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.9.output.dense.bias', 'base_model.encoder.layer.6.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.15.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.5.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.19.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.8.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.15.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.18.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.19.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.8.attention.output.dense.bias', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.9.attention.self.value.weight', 'base_model.encoder.layer.5.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.18.intermediate.dense.bias', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.4.output.LayerNorm.weight', 'base_model.encoder.layer.23.attention.self.value.weight', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.21.attention.output.dense.bias', 'base_model.encoder.layer.3.attention.self.key.weight', 'base_model.encoder.layer.16.attention.self.key.weight', 'base_model.encoder.layer.20.attention.self.key.weight', 'base_model.encoder.layer.13.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.22.attention.output.LayerNorm.weight', 'base_model.encoder.layer.20.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.22.intermediate.dense.bias', 'base_model.encoder.layer.15.intermediate.dense.bias', 'base_model.encoder.layer.15.output.dense.bias', 'base_model.encoder.layer.2.output.LayerNorm.weight', 'base_model.encoder.layer.4.attention.output.LayerNorm.weight', 'base_model.encoder.layer.13.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.6.output.dense.bias', 'base_model.encoder.layer.23.attention.output.dense.bias', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.7.attention.self.query.bias', 'base_model.encoder.layer.0.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.7.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.10.output.dense.bias', 'base_model.encoder.layer.21.attention.output.LayerNorm.bias', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.17.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.3.attention.output.dense.weight', 'base_model.encoder.layer.10.output.LayerNorm.bias', 'base_model.encoder.layer.11.attention.self.value.weight', 'base_model.encoder.layer.8.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.9.attention.self.value.bias', 'base_model.encoder.layer.14.attention.output.LayerNorm.bias', 'base_model.encoder.layer.18.output.adapters.ep.adapter_down.0.bias', 'base_model.embeddings.LayerNorm.bias', 'base_model.encoder.layer.3.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.17.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.1.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.2.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.21.attention.output.LayerNorm.weight', 'base_model.encoder.layer.18.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.17.attention.output.LayerNorm.weight', 'base_model.encoder.layer.3.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.7.attention.output.dense.bias', 'base_model.encoder.layer.7.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.1.output.LayerNorm.bias', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.16.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.11.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.1.attention.self.query.weight', 'base_model.encoder.layer.16.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.6.attention.self.query.weight', 'base_model.encoder.layer.22.attention.self.value.bias', 'base_model.encoder.layer.9.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.3.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.10.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.14.output.dense.bias', 'base_model.encoder.layer.8.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.12.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.4.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.20.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.1.output.LayerNorm.weight', 'base_model.encoder.layer.13.attention.self.key.weight', 'base_model.encoder.layer.4.attention.output.dense.bias', 'base_model.encoder.layer.13.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.7.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.19.attention.self.query.bias', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.17.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.10.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.7.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.5.attention.self.key.weight', 'base_model.encoder.layer.9.attention.self.key.bias', 'base_model.encoder.layer.8.output.LayerNorm.weight', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.18.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.10.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.9.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.4.attention.output.dense.weight', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.21.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.7.intermediate.dense.weight', 'base_model.encoder.layer.10.attention.output.LayerNorm.bias', 'base_model.encoder.layer.1.attention.output.LayerNorm.weight', 'base_model.encoder.layer.2.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.8.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.7.attention.self.key.weight', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.20.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.1.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.21.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.18.output.LayerNorm.weight', 'base_model.encoder.layer.2.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.19.attention.self.value.weight', 'base_model.encoder.layer.5.attention.output.LayerNorm.bias', 'base_model.encoder.layer.16.attention.output.LayerNorm.bias', 'base_model.encoder.layer.13.attention.self.value.bias', 'base_model.encoder.layer.20.attention.output.LayerNorm.weight', 'base_model.encoder.layer.2.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.23.attention.self.key.weight', 'base_model.encoder.layer.9.intermediate.dense.bias', 'base_model.encoder.layer.3.attention.self.value.bias', 'base_model.encoder.layer.3.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.20.attention.self.query.bias', 'base_model.encoder.layer.22.output.LayerNorm.weight', 'base_model.encoder.layer.11.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.12.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.7.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.6.attention.output.dense.bias', 'base_model.encoder.layer.15.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.21.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.5.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.5.output.LayerNorm.weight', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.18.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.18.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.6.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.15.attention.self.key.bias', 'base_model.encoder.layer.10.attention.self.key.weight', 'base_model.encoder.layer.4.output.LayerNorm.bias', 'base_model.encoder.layer.13.output.dense.bias', 'base_model.encoder.layer.1.intermediate.dense.weight', 'base_model.encoder.layer.17.output.dense.weight', 'base_model.encoder.layer.0.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.1.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.21.output.dense.bias', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.20.intermediate.dense.bias', 'base_model.encoder.layer.17.attention.output.LayerNorm.bias', 'base_model.encoder.layer.22.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.9.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.5.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.7.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.12.attention.self.value.bias', 'base_model.encoder.layer.23.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.16.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.11.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.12.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.1.attention.self.key.bias', 'base_model.encoder.layer.17.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.9.attention.output.dense.weight', 'base_model.encoder.layer.18.attention.output.dense.bias', 'base_model.encoder.layer.15.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.17.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.20.output.LayerNorm.bias', 'base_model.encoder.layer.14.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.11.attention.self.value.bias', 'base_model.encoder.layer.12.output.dense.weight', 'base_model.encoder.layer.9.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.11.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.0.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.19.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.17.output.LayerNorm.bias', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.20.output.adapters.tp.adapter_up.weight', 'base_model.embeddings.LayerNorm.weight', 'base_model.encoder.layer.8.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.7.attention.self.value.bias', 'base_model.encoder.layer.10.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.1.output.dense.bias', 'base_model.encoder.layer.9.intermediate.dense.weight', 'base_model.encoder.layer.17.intermediate.dense.weight', 'base_model.encoder.layer.13.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.18.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.1.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.12.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.18.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.5.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.3.attention.output.LayerNorm.weight', 'base_model.encoder.layer.23.output.LayerNorm.weight', 'base_model.encoder.layer.11.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.10.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.19.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.23.attention.self.key.bias', 'base_model.encoder.layer.0.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.19.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.7.output.LayerNorm.weight', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.1.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.6.attention.self.value.bias', 'base_model.encoder.layer.6.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.11.output.dense.bias', 'base_model.encoder.layer.19.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.embeddings.position_ids', 'base_model.encoder.layer.6.attention.self.value.weight', 'base_model.encoder.layer.23.attention.output.LayerNorm.bias', 'base_model.encoder.layer.3.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.1.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.15.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.11.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.22.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.6.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.6.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.12.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.5.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.8.attention.self.value.bias', 'base_model.encoder.layer.23.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.17.attention.self.key.bias', 'base_model.encoder.layer.12.output.LayerNorm.bias', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.0.output.LayerNorm.weight', 'base_model.encoder.layer.1.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.8.attention.output.LayerNorm.bias', 'base_model.encoder.layer.11.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.22.attention.output.dense.weight', 'base_model.encoder.layer.11.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.9.attention.self.query.bias', 'base_model.encoder.layer.17.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.5.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.3.output.LayerNorm.bias', 'base_model.encoder.layer.12.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.8.attention.self.query.weight', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.10.attention.self.value.bias', 'base_model.encoder.layer.0.attention.self.key.bias', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.14.output.LayerNorm.weight', 'base_model.encoder.layer.14.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.22.intermediate.dense.weight', 'base_model.encoder.layer.22.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.12.attention.output.dense.bias', 'base_model.encoder.layer.10.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.20.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.5.intermediate.dense.weight', 'base_model.encoder.layer.0.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.19.output.dense.weight', 'base_model.encoder.layer.21.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.4.attention.output.LayerNorm.bias', 'base_model.encoder.layer.23.attention.output.LayerNorm.weight', 'base_model.encoder.layer.15.attention.self.value.weight', 'base_model.encoder.layer.20.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.4.attention.self.value.bias', 'base_model.encoder.layer.4.output.dense.bias', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.23.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.7.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.2.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.9.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.11.output.LayerNorm.weight', 'base_model.encoder.layer.15.attention.output.dense.bias', 'base_model.encoder.layer.15.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.13.attention.self.value.weight', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.20.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.23.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.12.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.18.output.dense.bias', 'base_model.encoder.layer.16.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.22.output.adapters.ts.adapter_down.0.weight', 'base_model.embeddings.word_embeddings.weight', 'base_model.encoder.layer.9.attention.self.key.weight', 'base_model.encoder.layer.19.attention.self.key.bias', 'base_model.encoder.layer.6.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.1.attention.self.query.bias', 'base_model.encoder.layer.8.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.3.attention.self.key.bias', 'base_model.encoder.layer.6.attention.output.LayerNorm.weight', 'base_model.encoder.layer.21.output.LayerNorm.bias', 'base_model.encoder.layer.15.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.13.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.22.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.5.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.1.attention.output.dense.bias', 'base_model.encoder.layer.21.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.7.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.16.attention.output.dense.bias', 'base_model.encoder.layer.9.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.1.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.17.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.17.output.dense.bias', 'base_model.encoder.layer.23.output.dense.bias', 'base_model.encoder.layer.9.attention.output.LayerNorm.bias', 'base_model.encoder.layer.2.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.6.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.7.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.19.attention.output.dense.weight', 'base_model.encoder.layer.1.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.17.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.21.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.9.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.3.attention.output.LayerNorm.bias', 'base_model.encoder.layer.13.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.21.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.23.attention.self.query.weight', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.14.attention.self.key.weight', 'base_model.encoder.layer.21.attention.self.value.bias', 'base_model.encoder.layer.1.output.dense.weight', 'base_model.encoder.layer.2.attention.output.dense.bias', 'base_model.encoder.layer.4.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.11.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.21.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.0.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.3.attention.self.query.bias', 'base_model.encoder.layer.22.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.23.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.10.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.18.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.22.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.5.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.8.intermediate.dense.weight', 'base_model.encoder.layer.15.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.22.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.17.output.LayerNorm.weight', 'base_model.encoder.layer.2.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.8.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.11.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.19.attention.self.key.weight', 'base_model.encoder.layer.20.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.13.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.3.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.18.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.13.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.11.output.dense.weight', 'base_model.encoder.layer.5.intermediate.dense.bias', 'base_model.encoder.layer.10.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.12.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.2.output.dense.weight', 'base_model.encoder.layer.15.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.20.output.adapters.tp.adapter_down.0.bias', 'qa_outputs.weight', 'base_model.encoder.layer.4.intermediate.dense.bias', 'base_model.encoder.layer.20.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.21.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.13.attention.output.LayerNorm.bias', 'base_model.encoder.layer.11.attention.output.dense.weight', 'base_model.encoder.layer.22.attention.output.dense.bias', 'base_model.encoder.layer.0.intermediate.dense.weight', 'base_model.encoder.layer.16.attention.output.dense.weight', 'base_model.encoder.layer.19.output.dense.bias', 'base_model.encoder.layer.3.intermediate.dense.weight', 'base_model.encoder.layer.18.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.11.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.12.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.1.attention.self.key.weight', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.14.output.dense.weight', 'base_model.pooler.dense.weight', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.21.attention.self.key.bias', 'base_model.encoder.layer.5.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.4.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.1.attention.self.value.bias', 'base_model.encoder.layer.9.output.dense.weight', 'base_model.encoder.layer.2.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.13.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.2.attention.self.query.bias', 'base_model.encoder.layer.15.output.LayerNorm.bias', 'base_model.encoder.layer.20.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.13.attention.output.dense.bias', 'base_model.encoder.layer.3.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.13.attention.self.query.weight', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.19.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.2.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.5.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.14.intermediate.dense.bias', 'base_model.encoder.layer.0.intermediate.dense.bias', 'base_model.encoder.layer.2.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.10.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.3.output.dense.bias', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.17.attention.output.dense.bias', 'base_model.encoder.layer.6.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.23.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.14.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.6.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.0.attention.output.dense.bias', 'base_model.encoder.layer.18.output.dense.weight', 'base_model.encoder.layer.14.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.23.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.12.attention.self.query.bias', 'base_model.encoder.layer.0.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.15.attention.output.LayerNorm.weight', 'base_model.encoder.layer.16.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.22.attention.self.key.bias', 'base_model.encoder.layer.2.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.2.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.15.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.21.attention.self.key.weight', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.14.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.8.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.16.attention.self.query.weight', 'base_model.encoder.layer.6.attention.self.key.weight', 'base_model.encoder.layer.4.attention.self.query.weight', 'base_model.encoder.layer.0.attention.self.key.weight', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.10.attention.output.LayerNorm.weight', 'base_model.encoder.layer.7.attention.output.dense.weight', 'base_model.encoder.layer.22.output.dense.bias', 'base_model.encoder.layer.6.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.13.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.17.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.12.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.6.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.10.attention.self.query.weight', 'base_model.encoder.layer.8.output.dense.weight', 'base_model.encoder.layer.5.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.17.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.22.output.LayerNorm.bias', 'base_model.encoder.layer.20.attention.self.value.bias', 'base_model.encoder.layer.8.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.23.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.10.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.16.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.18.intermediate.dense.weight', 'base_model.encoder.layer.15.attention.self.query.bias', 'base_model.encoder.layer.0.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.12.intermediate.dense.bias', 'base_model.encoder.layer.18.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.2.attention.output.dense.weight', 'base_model.encoder.layer.0.attention.output.LayerNorm.weight', 'base_model.encoder.layer.2.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.4.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.3.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.4.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.17.attention.self.key.weight', 'base_model.encoder.layer.0.attention.output.LayerNorm.bias', 'base_model.encoder.layer.23.output.dense.weight', 'base_model.encoder.layer.16.attention.self.value.bias', 'base_model.encoder.layer.3.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.19.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.23.attention.self.query.bias', 'base_model.encoder.layer.11.attention.self.key.bias', 'base_model.encoder.layer.12.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.9.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.22.attention.self.value.weight', 'base_model.encoder.layer.8.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.8.attention.output.dense.weight', 'base_model.encoder.layer.13.attention.output.dense.weight', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.23.attention.self.value.bias', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.11.intermediate.dense.bias', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.9.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.19.attention.output.LayerNorm.weight', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.12.attention.self.query.weight', 'base_model.encoder.layer.18.attention.self.key.weight', 'base_model.encoder.layer.16.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.16.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.18.attention.output.LayerNorm.bias', 'base_model.encoder.layer.17.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.17.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.2.output.LayerNorm.bias', 'base_model.encoder.layer.21.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.8.attention.self.key.bias', 'base_model.encoder.layer.17.attention.output.dense.weight', 'base_model.encoder.layer.10.attention.output.dense.weight', 'base_model.encoder.layer.12.attention.output.LayerNorm.bias', 'base_model.encoder.layer.3.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.20.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.13.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.13.intermediate.dense.bias', 'base_model.encoder.layer.14.attention.self.key.bias', 'base_model.encoder.layer.12.attention.self.key.bias', 'base_model.encoder.layer.19.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.10.intermediate.dense.weight', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.1.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.11.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.7.attention.output.LayerNorm.bias', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.22.attention.self.query.bias', 'base_model.encoder.layer.9.output.LayerNorm.bias', 'base_model.encoder.layer.23.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.7.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.1.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.4.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.18.attention.self.key.bias', 'base_model.encoder.layer.0.attention.self.value.weight', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.19.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.12.intermediate.dense.weight', 'base_model.encoder.layer.16.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.7.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.6.attention.output.LayerNorm.bias', 'base_model.encoder.layer.20.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.8.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.4.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.14.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.3.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.11.attention.output.LayerNorm.bias', 'base_model.encoder.layer.11.output.LayerNorm.bias', 'base_model.encoder.layer.0.attention.self.query.bias', 'base_model.encoder.layer.4.output.dense.weight', 'base_model.encoder.layer.9.attention.output.dense.bias', 'base_model.encoder.layer.10.output.LayerNorm.weight', 'base_model.encoder.layer.10.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.19.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.3.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.0.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.3.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.15.attention.self.key.weight', 'base_model.encoder.layer.2.attention.output.LayerNorm.bias', 'base_model.encoder.layer.14.attention.output.dense.bias', 'base_model.encoder.layer.19.intermediate.dense.weight', 'base_model.encoder.layer.19.attention.output.dense.bias', 'base_model.embeddings.token_type_embeddings.weight', 'base_model.encoder.layer.15.output.LayerNorm.weight', 'base_model.encoder.layer.21.intermediate.dense.bias', 'base_model.encoder.layer.23.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.11.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.21.attention.self.value.weight', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.11.attention.self.key.weight', 'base_model.encoder.layer.6.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.19.attention.output.LayerNorm.bias', 'base_model.encoder.layer.12.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.6.output.LayerNorm.bias', 'base_model.encoder.layer.6.attention.output.dense.weight', 'base_model.encoder.layer.10.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.7.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.23.attention.output.dense.weight', 'base_model.encoder.layer.22.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.7.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.13.attention.output.LayerNorm.weight', 'base_model.encoder.layer.22.attention.self.query.weight', 'base_model.encoder.layer.17.attention.self.query.weight', 'base_model.encoder.layer.0.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.5.output.LayerNorm.bias', 'base_model.encoder.layer.10.attention.output.dense.bias', 'base_model.encoder.layer.22.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.4.attention.self.value.weight', 'base_model.encoder.layer.16.output.LayerNorm.bias', 'base_model.encoder.layer.3.attention.self.value.weight', 'base_model.encoder.layer.10.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.12.attention.self.value.weight', 'base_model.encoder.layer.19.output.LayerNorm.bias', 'base_model.encoder.layer.12.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.6.output.dense.weight', 'base_model.encoder.layer.22.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.15.attention.self.query.weight', 'base_model.encoder.layer.7.attention.self.key.bias', 'base_model.encoder.layer.0.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.3.attention.self.query.weight', 'base_model.encoder.layer.4.attention.self.key.bias', 'base_model.encoder.layer.20.output.adapters.ep.adapter_down.0.bias', 'qa_outputs.bias', 'base_model.encoder.layer.20.attention.output.LayerNorm.bias', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.14.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.22.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.9.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.12.output.dense.bias', 'base_model.encoder.layer.10.intermediate.dense.bias', 'base_model.encoder.layer.6.intermediate.dense.bias', 'base_model.encoder.layer.22.attention.output.LayerNorm.bias', 'base_model.encoder.layer.15.output.dense.weight', 'base_model.encoder.layer.20.output.dense.weight', 'base_model.encoder.layer.14.attention.output.dense.weight', 'base_model.encoder.layer.8.attention.self.value.weight', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.8.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.5.attention.output.dense.weight', 'base_model.encoder.layer.19.intermediate.dense.bias', 'base_model.encoder.layer.17.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.3.intermediate.dense.bias', 'base_model.encoder.layer.5.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.1.intermediate.dense.bias', 'base_model.encoder.layer.2.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.4.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.0.attention.self.query.weight', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.19.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.21.output.LayerNorm.weight', 'base_model.encoder.layer.7.output.dense.weight', 'base_model.encoder.layer.2.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.5.output.dense.weight', 'base_model.encoder.layer.0.output.dense.bias', 'base_model.encoder.layer.13.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.20.attention.self.value.weight', 'base_model.encoder.layer.10.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.8.attention.output.LayerNorm.weight', 'base_model.encoder.layer.21.attention.self.query.weight', 'base_model.encoder.layer.15.attention.output.dense.weight', 'base_model.encoder.layer.19.attention.self.value.bias', 'base_model.encoder.layer.4.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.14.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.17.attention.self.value.weight', 'base_model.encoder.layer.2.attention.self.value.weight', 'base_model.encoder.layer.1.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.16.output.LayerNorm.weight', 'base_model.encoder.layer.5.attention.self.query.bias', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.10.attention.self.value.weight', 'base_model.encoder.layer.14.output.LayerNorm.bias', 'base_model.encoder.layer.20.output.dense.bias', 'base_model.encoder.layer.21.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.13.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.20.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.15.attention.output.LayerNorm.bias', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.1.attention.self.value.weight', 'base_model.encoder.layer.17.attention.self.query.bias', 'base_model.encoder.layer.17.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.8.attention.self.key.weight', 'base_model.encoder.layer.5.attention.output.LayerNorm.weight', 'base_model.encoder.layer.2.attention.self.query.weight', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.4.attention.self.query.bias', 'base_model.encoder.layer.7.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.18.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.15.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.14.intermediate.dense.weight', 'base_model.encoder.layer.0.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.0.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.18.output.LayerNorm.bias', 'base_model.encoder.layer.5.output.dense.bias', 'base_model.encoder.layer.8.attention.self.query.bias', 'base_model.encoder.layer.2.attention.self.key.bias', 'base_model.encoder.layer.10.attention.self.key.bias', 'base_model.encoder.layer.12.output.LayerNorm.weight', 'base_model.encoder.layer.0.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.2.intermediate.dense.weight', 'base_model.encoder.layer.8.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.21.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.14.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.4.intermediate.dense.weight', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.2.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.8.output.dense.bias', 'base_model.encoder.layer.12.attention.output.LayerNorm.weight', 'base_model.encoder.layer.6.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.0.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.12.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.8.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.16.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.19.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.7.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.1.attention.output.LayerNorm.bias', 'base_model.encoder.layer.21.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.4.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.9.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.20.attention.self.key.bias', 'base_model.encoder.layer.15.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.20.output.LayerNorm.weight', 'base_model.encoder.layer.3.output.dense.weight', 'base_model.encoder.layer.15.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.20.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.5.attention.self.query.weight', 'base_model.encoder.layer.3.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.14.attention.self.query.weight', 'base_model.encoder.layer.4.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.6.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.7.attention.self.query.weight', 'base_model.encoder.layer.1.attention.output.dense.weight', 'base_model.encoder.layer.1.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.5.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.6.intermediate.dense.weight', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.22.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.0.output.LayerNorm.bias', 'base_model.encoder.layer.4.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.13.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.6.output.adapters.ts.adapter_up.weight', 'base_model.pooler.dense.bias', 'base_model.encoder.layer.2.output.dense.bias', 'base_model.encoder.layer.7.output.LayerNorm.bias', 'base_model.encoder.layer.7.attention.output.LayerNorm.weight', 'base_model.encoder.layer.20.attention.self.query.weight', 'base_model.encoder.layer.7.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.13.output.LayerNorm.bias', 'base_model.encoder.layer.21.attention.self.query.bias', 'base_model.encoder.layer.14.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.19.attention.self.query.weight', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.12.attention.output.dense.weight', 'base_model.encoder.layer.15.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.11.attention.output.LayerNorm.weight', 'base_model.encoder.layer.18.attention.self.value.weight', 'base_model.encoder.layer.5.attention.self.key.bias', 'base_model.encoder.layer.0.output.dense.weight', 'base_model.encoder.layer.23.intermediate.dense.bias', 'base_model.encoder.layer.20.attention.output.dense.weight', 'base_model.encoder.layer.15.attention.self.value.bias', 'base_model.encoder.layer.11.intermediate.dense.weight', 'base_model.encoder.layer.7.intermediate.dense.bias', 'base_model.encoder.layer.16.intermediate.dense.weight', 'base_model.encoder.layer.8.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.9.output.LayerNorm.weight', 'base_model.encoder.layer.23.intermediate.dense.weight', 'base_model.encoder.layer.16.attention.self.value.weight', 'base_model.encoder.layer.23.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.9.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.19.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.17.intermediate.dense.bias', 'base_model.encoder.layer.13.attention.self.key.bias', 'base_model.encoder.layer.14.attention.self.query.bias', 'base_model.encoder.layer.6.attention.self.key.bias', 'base_model.encoder.layer.16.attention.self.query.bias', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.13.output.dense.weight', 'base_model.encoder.layer.11.attention.self.query.bias', 'base_model.encoder.layer.6.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.18.attention.output.LayerNorm.weight', 'base_model.encoder.layer.11.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.16.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.22.attention.self.key.weight', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.9.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.8.intermediate.dense.bias', 'base_model.encoder.layer.16.attention.self.key.bias', 'base_model.encoder.layer.18.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.23.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.5.attention.self.value.weight', 'base_model.encoder.layer.14.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.3.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.5.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.9.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.15.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.4.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.4.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.14.attention.self.value.weight', 'base_model.encoder.layer.13.output.LayerNorm.weight', 'base_model.encoder.layer.11.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.6.output.LayerNorm.weight', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.18.attention.self.query.bias', 'base_model.encoder.layer.0.attention.self.value.bias', 'base_model.encoder.layer.19.output.LayerNorm.weight', 'base_model.encoder.layer.2.attention.output.LayerNorm.weight', 'base_model.encoder.layer.16.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.3.attention.output.dense.bias', 'base_model.encoder.layer.21.attention.output.dense.weight', 'base_model.encoder.layer.7.output.dense.bias', 'base_model.encoder.layer.2.attention.self.key.weight', 'base_model.encoder.layer.17.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.14.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.16.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.17.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.9.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.1.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.12.output.adapters.es.adapter_up.bias']
- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of XLMRobertaModel were not initialized from the model checkpoint at /cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//squad/xlm-KG_LR8e-6_EPOCH2.0_maxlen384_batchsize4_gradacc4 and are newly initialized: ['encoder.layer.5.output.dense.weight', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.5.output.LayerNorm.bias', 'encoder.layer.1.attention.self.key.bias', 'encoder.layer.1.attention.self.value.bias', 'encoder.layer.4.attention.output.dense.bias', 'encoder.layer.10.attention.self.value.weight', 'encoder.layer.16.attention.self.value.bias', 'encoder.layer.15.output.dense.weight', 'encoder.layer.13.attention.output.LayerNorm.weight', 'encoder.layer.2.attention.output.dense.weight', 'encoder.layer.21.attention.output.dense.weight', 'encoder.layer.20.attention.self.query.weight', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.10.attention.self.key.weight', 'encoder.layer.9.output.dense.bias', 'encoder.layer.12.output.dense.bias', 'encoder.layer.18.output.LayerNorm.bias', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.10.output.LayerNorm.bias', 'encoder.layer.21.attention.self.query.weight', 'encoder.layer.21.output.dense.bias', 'encoder.layer.5.attention.self.value.weight', 'encoder.layer.22.intermediate.dense.bias', 'encoder.layer.13.attention.output.LayerNorm.bias', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.19.output.LayerNorm.weight', 'encoder.layer.15.attention.output.dense.bias', 'encoder.layer.5.attention.self.query.bias', 'encoder.layer.16.attention.self.value.weight', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.23.intermediate.dense.bias', 'pooler.dense.bias', 'encoder.layer.10.attention.self.query.weight', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.9.attention.output.dense.weight', 'encoder.layer.17.intermediate.dense.bias', 'encoder.layer.2.attention.self.value.bias', 'encoder.layer.6.attention.self.value.bias', 'encoder.layer.3.attention.self.value.weight', 'encoder.layer.19.attention.output.dense.bias', 'encoder.layer.14.attention.self.key.bias', 'encoder.layer.11.attention.self.key.weight', 'encoder.layer.23.attention.output.LayerNorm.bias', 'encoder.layer.4.attention.output.dense.weight', 'encoder.layer.16.attention.output.dense.weight', 'encoder.layer.16.output.dense.bias', 'encoder.layer.0.attention.self.value.bias', 'encoder.layer.0.attention.self.key.bias', 'encoder.layer.23.output.dense.weight', 'encoder.layer.11.attention.self.key.bias', 'encoder.layer.19.attention.output.LayerNorm.weight', 'encoder.layer.21.output.LayerNorm.bias', 'encoder.layer.22.output.LayerNorm.bias', 'encoder.layer.18.attention.self.value.weight', 'encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.13.attention.self.key.bias', 'encoder.layer.11.attention.self.query.weight', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.17.attention.output.LayerNorm.bias', 'encoder.layer.6.attention.output.dense.bias', 'encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.layer.12.attention.self.key.bias', 'encoder.layer.15.attention.self.key.bias', 'encoder.layer.20.attention.self.key.weight', 'encoder.layer.15.intermediate.dense.weight', 'encoder.layer.23.attention.self.value.bias', 'encoder.layer.12.intermediate.dense.bias', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.8.output.dense.bias', 'encoder.layer.12.attention.output.LayerNorm.weight', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.7.attention.output.LayerNorm.weight', 'encoder.layer.17.output.LayerNorm.weight', 'encoder.layer.8.output.LayerNorm.bias', 'encoder.layer.21.output.dense.weight', 'encoder.layer.0.attention.self.query.bias', 'encoder.layer.6.attention.output.LayerNorm.bias', 'encoder.layer.7.output.dense.bias', 'encoder.layer.17.attention.self.key.bias', 'encoder.layer.5.attention.self.value.bias', 'encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.layer.9.attention.self.value.weight', 'encoder.layer.16.output.LayerNorm.bias', 'encoder.layer.13.attention.output.dense.bias', 'encoder.layer.14.attention.self.value.weight', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.22.attention.self.query.bias', 'encoder.layer.12.attention.self.query.bias', 'encoder.layer.9.attention.output.LayerNorm.weight', 'encoder.layer.8.attention.output.LayerNorm.bias', 'encoder.layer.22.attention.output.LayerNorm.weight', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.15.attention.self.value.bias', 'encoder.layer.7.attention.self.value.weight', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.9.attention.self.query.bias', 'encoder.layer.21.attention.self.key.bias', 'encoder.layer.14.attention.self.query.weight', 'encoder.layer.14.attention.self.key.weight', 'encoder.layer.7.attention.output.dense.bias', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.9.attention.output.dense.bias', 'encoder.layer.16.attention.self.query.weight', 'encoder.layer.22.attention.output.dense.weight', 'encoder.layer.9.output.LayerNorm.bias', 'encoder.layer.3.attention.self.query.weight', 'encoder.layer.2.attention.self.key.bias', 'encoder.layer.15.attention.self.value.weight', 'encoder.layer.8.attention.output.dense.bias', 'encoder.layer.11.attention.output.LayerNorm.weight', 'encoder.layer.7.attention.self.key.bias', 'encoder.layer.23.output.LayerNorm.weight', 'encoder.layer.18.attention.self.key.weight', 'encoder.layer.21.output.LayerNorm.weight', 'encoder.layer.13.attention.self.key.weight', 'encoder.layer.18.attention.output.dense.weight', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.1.attention.output.dense.weight', 'encoder.layer.8.attention.output.dense.weight', 'encoder.layer.11.output.dense.weight', 'encoder.layer.4.attention.self.query.weight', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.22.attention.self.query.weight', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.7.output.dense.weight', 'encoder.layer.22.attention.output.dense.bias', 'encoder.layer.12.output.LayerNorm.weight', 'encoder.layer.20.output.dense.bias', 'encoder.layer.17.attention.self.query.bias', 'encoder.layer.0.attention.output.LayerNorm.weight', 'encoder.layer.3.attention.self.query.bias', 'encoder.layer.18.output.LayerNorm.weight', 'encoder.layer.6.output.dense.weight', 'encoder.layer.5.attention.output.dense.weight', 'encoder.layer.12.attention.output.dense.weight', 'encoder.layer.23.attention.self.query.bias', 'encoder.layer.20.intermediate.dense.weight', 'encoder.layer.6.attention.output.LayerNorm.weight', 'encoder.layer.4.output.dense.weight', 'encoder.layer.17.attention.self.query.weight', 'encoder.layer.22.attention.self.key.weight', 'encoder.layer.2.attention.self.key.weight', 'encoder.layer.15.attention.self.query.bias', 'encoder.layer.1.attention.output.LayerNorm.weight', 'encoder.layer.23.attention.self.key.bias', 'encoder.layer.12.attention.self.query.weight', 'encoder.layer.4.attention.self.query.bias', 'encoder.layer.23.attention.output.dense.weight', 'encoder.layer.7.attention.self.value.bias', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.5.attention.self.key.bias', 'encoder.layer.11.output.LayerNorm.bias', 'encoder.layer.3.attention.output.dense.bias', 'embeddings.position_embeddings.weight', 'encoder.layer.7.output.LayerNorm.bias', 'encoder.layer.1.output.dense.bias', 'encoder.layer.12.intermediate.dense.weight', 'encoder.layer.15.attention.output.LayerNorm.weight', 'encoder.layer.11.attention.output.dense.weight', 'encoder.layer.15.output.LayerNorm.weight', 'encoder.layer.6.attention.self.query.bias', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.3.attention.output.dense.weight', 'encoder.layer.3.attention.self.key.bias', 'encoder.layer.2.attention.output.dense.bias', 'encoder.layer.13.output.LayerNorm.bias', 'pooler.dense.weight', 'encoder.layer.17.output.dense.weight', 'encoder.layer.1.attention.output.dense.bias', 'encoder.layer.6.attention.self.key.weight', 'encoder.layer.19.attention.self.query.bias', 'encoder.layer.14.attention.self.query.bias', 'encoder.layer.11.attention.self.value.bias', 'encoder.layer.21.attention.output.dense.bias', 'embeddings.token_type_embeddings.weight', 'encoder.layer.21.intermediate.dense.weight', 'encoder.layer.14.attention.self.value.bias', 'encoder.layer.11.attention.self.value.weight', 'encoder.layer.17.output.dense.bias', 'encoder.layer.14.attention.output.LayerNorm.weight', 'encoder.layer.10.attention.output.dense.weight', 'encoder.layer.14.attention.output.dense.weight', 'encoder.layer.3.output.dense.weight', 'encoder.layer.18.attention.self.query.bias', 'encoder.layer.15.attention.output.LayerNorm.bias', 'encoder.layer.21.attention.self.key.weight', 'encoder.layer.20.attention.self.key.bias', 'encoder.layer.21.attention.self.value.weight', 'encoder.layer.16.output.LayerNorm.weight', 'encoder.layer.8.output.dense.weight', 'encoder.layer.5.output.dense.bias', 'encoder.layer.8.attention.self.value.bias', 'encoder.layer.16.attention.output.dense.bias', 'encoder.layer.9.attention.output.LayerNorm.bias', 'encoder.layer.10.attention.output.LayerNorm.bias', 'encoder.layer.11.attention.self.query.bias', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.6.attention.self.query.weight', 'encoder.layer.21.attention.output.LayerNorm.weight', 'encoder.layer.16.attention.self.query.bias', 'encoder.layer.20.attention.output.LayerNorm.weight', 'encoder.layer.21.attention.output.LayerNorm.bias', 'encoder.layer.9.output.dense.weight', 'encoder.layer.1.intermediate.dense.bias', 'embeddings.word_embeddings.weight', 'encoder.layer.19.attention.self.query.weight', 'encoder.layer.17.intermediate.dense.weight', 'encoder.layer.8.attention.self.query.weight', 'encoder.layer.10.output.dense.bias', 'encoder.layer.7.output.LayerNorm.weight', 'encoder.layer.19.attention.output.LayerNorm.bias', 'encoder.layer.22.attention.self.key.bias', 'encoder.layer.14.output.LayerNorm.bias', 'encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.18.attention.self.value.bias', 'encoder.layer.10.attention.self.query.bias', 'encoder.layer.4.attention.output.LayerNorm.weight', 'encoder.layer.15.attention.output.dense.weight', 'encoder.layer.20.attention.output.LayerNorm.bias', 'encoder.layer.4.attention.self.key.bias', 'encoder.layer.21.attention.self.query.bias', 'encoder.layer.1.attention.self.value.weight', 'encoder.layer.7.attention.output.dense.weight', 'encoder.layer.15.attention.self.query.weight', 'encoder.layer.13.output.dense.weight', 'encoder.layer.6.output.dense.bias', 'encoder.layer.17.attention.self.key.weight', 'encoder.layer.14.attention.output.LayerNorm.bias', 'encoder.layer.19.output.dense.bias', 'encoder.layer.11.attention.output.dense.bias', 'encoder.layer.1.attention.self.query.bias', 'encoder.layer.3.output.LayerNorm.bias', 'embeddings.LayerNorm.weight', 'encoder.layer.20.output.LayerNorm.weight', 'encoder.layer.13.intermediate.dense.bias', 'encoder.layer.6.attention.self.value.weight', 'encoder.layer.8.attention.self.query.bias', 'encoder.layer.18.attention.output.LayerNorm.weight', 'encoder.layer.0.attention.self.key.weight', 'encoder.layer.21.intermediate.dense.bias', 'encoder.layer.19.attention.self.value.bias', 'encoder.layer.19.attention.self.value.weight', 'encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.layer.6.output.LayerNorm.bias', 'encoder.layer.19.output.dense.weight', 'encoder.layer.4.output.dense.bias', 'encoder.layer.4.attention.self.value.bias', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.12.attention.self.value.weight', 'encoder.layer.8.attention.self.key.bias', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.0.attention.self.query.weight', 'encoder.layer.2.attention.self.query.bias', 'encoder.layer.23.attention.output.LayerNorm.weight', 'encoder.layer.13.attention.self.query.bias', 'encoder.layer.10.output.LayerNorm.weight', 'encoder.layer.16.output.dense.weight', 'encoder.layer.14.attention.output.dense.bias', 'encoder.layer.18.intermediate.dense.bias', 'encoder.layer.2.attention.output.LayerNorm.bias', 'encoder.layer.22.output.dense.bias', 'encoder.layer.20.attention.self.query.bias', 'encoder.layer.0.output.dense.weight', 'encoder.layer.23.output.LayerNorm.bias', 'encoder.layer.17.attention.output.dense.bias', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.11.output.LayerNorm.weight', 'encoder.layer.0.attention.output.dense.bias', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.4.attention.self.key.weight', 'encoder.layer.7.attention.output.LayerNorm.bias', 'encoder.layer.13.intermediate.dense.weight', 'encoder.layer.20.attention.self.value.weight', 'encoder.layer.23.attention.self.key.weight', 'encoder.layer.16.attention.output.LayerNorm.bias', 'encoder.layer.22.output.dense.weight', 'encoder.layer.16.attention.output.LayerNorm.weight', 'encoder.layer.13.output.LayerNorm.weight', 'encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.layer.11.output.dense.bias', 'encoder.layer.18.output.dense.bias', 'encoder.layer.5.attention.output.LayerNorm.weight', 'encoder.layer.18.intermediate.dense.weight', 'encoder.layer.4.attention.output.LayerNorm.bias', 'encoder.layer.17.attention.output.LayerNorm.weight', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.18.attention.self.key.bias', 'embeddings.LayerNorm.bias', 'encoder.layer.14.output.dense.bias', 'encoder.layer.12.attention.self.key.weight', 'encoder.layer.18.attention.output.dense.bias', 'encoder.layer.8.output.LayerNorm.weight', 'encoder.layer.20.attention.output.dense.weight', 'encoder.layer.17.attention.self.value.bias', 'encoder.layer.23.attention.self.query.weight', 'encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.layer.13.attention.self.query.weight', 'encoder.layer.3.output.dense.bias', 'encoder.layer.9.attention.self.key.weight', 'encoder.layer.0.attention.output.dense.weight', 'encoder.layer.8.attention.self.key.weight', 'encoder.layer.5.attention.self.query.weight', 'encoder.layer.3.attention.self.value.bias', 'encoder.layer.2.attention.self.value.weight', 'encoder.layer.1.attention.self.query.weight', 'encoder.layer.2.output.dense.weight', 'encoder.layer.14.intermediate.dense.bias', 'encoder.layer.15.intermediate.dense.bias', 'encoder.layer.17.attention.output.dense.weight', 'encoder.layer.9.attention.self.key.bias', 'encoder.layer.15.output.dense.bias', 'encoder.layer.20.intermediate.dense.bias', 'encoder.layer.7.intermediate.dense.bias', 'encoder.layer.10.intermediate.dense.weight', 'encoder.layer.10.attention.output.dense.bias', 'encoder.layer.22.intermediate.dense.weight', 'encoder.layer.22.attention.output.LayerNorm.bias', 'encoder.layer.6.attention.output.dense.weight', 'encoder.layer.15.output.LayerNorm.bias', 'encoder.layer.5.attention.output.dense.bias', 'encoder.layer.16.attention.self.key.bias', 'encoder.layer.23.output.dense.bias', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.12.attention.output.LayerNorm.bias', 'encoder.layer.15.attention.self.key.weight', 'encoder.layer.19.intermediate.dense.weight', 'encoder.layer.21.attention.self.value.bias', 'encoder.layer.18.attention.self.query.weight', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.7.attention.self.key.weight', 'encoder.layer.19.intermediate.dense.bias', 'encoder.layer.10.attention.output.LayerNorm.weight', 'encoder.layer.10.attention.self.key.bias', 'encoder.layer.23.attention.output.dense.bias', 'encoder.layer.13.attention.self.value.weight', 'encoder.layer.6.attention.self.key.bias', 'encoder.layer.20.attention.output.dense.bias', 'encoder.layer.13.attention.output.dense.weight', 'encoder.layer.5.attention.self.key.weight', 'encoder.layer.23.intermediate.dense.weight', 'encoder.layer.18.attention.output.LayerNorm.bias', 'encoder.layer.8.attention.self.value.weight', 'encoder.layer.10.attention.self.value.bias', 'encoder.layer.1.attention.self.key.weight', 'encoder.layer.13.attention.self.value.bias', 'encoder.layer.23.attention.self.value.weight', 'encoder.layer.14.output.LayerNorm.weight', 'encoder.layer.18.output.dense.weight', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.9.attention.self.value.bias', 'encoder.layer.3.attention.self.key.weight', 'encoder.layer.22.output.LayerNorm.weight', 'encoder.layer.20.output.dense.weight', 'encoder.layer.9.output.LayerNorm.weight', 'encoder.layer.16.intermediate.dense.bias', 'encoder.layer.19.output.LayerNorm.bias', 'encoder.layer.7.attention.self.query.bias', 'encoder.layer.16.intermediate.dense.weight', 'encoder.layer.7.attention.self.query.weight', 'encoder.layer.22.attention.self.value.weight', 'encoder.layer.0.attention.self.value.weight', 'encoder.layer.2.attention.self.query.weight', 'encoder.layer.20.output.LayerNorm.bias', 'encoder.layer.19.attention.self.key.bias', 'encoder.layer.2.output.dense.bias', 'encoder.layer.0.output.dense.bias', 'encoder.layer.20.attention.self.value.bias', 'encoder.layer.12.output.LayerNorm.bias', 'encoder.layer.13.output.dense.bias', 'encoder.layer.4.attention.self.value.weight', 'encoder.layer.2.attention.output.LayerNorm.weight', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.10.output.dense.weight', 'encoder.layer.19.attention.output.dense.weight', 'encoder.layer.14.intermediate.dense.weight', 'encoder.layer.16.attention.self.key.weight', 'encoder.layer.1.output.dense.weight', 'encoder.layer.12.output.dense.weight', 'encoder.layer.9.attention.self.query.weight', 'encoder.layer.14.output.dense.weight', 'encoder.layer.19.attention.self.key.weight', 'encoder.layer.22.attention.self.value.bias', 'encoder.layer.12.attention.output.dense.bias', 'encoder.layer.17.output.LayerNorm.bias', 'encoder.layer.12.attention.self.value.bias', 'encoder.layer.17.attention.self.value.weight', 'encoder.layer.8.attention.output.LayerNorm.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Overwriting existing adapter 'ep'.
Overwriting existing adapter 'tp'.
Overwriting existing adapter 'es'.
Overwriting existing adapter 'ts'.
Overwriting existing adapter fusion module 'ep,tp,es,ts'
/cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//squad/xlm-KG_LR8e-6_EPOCH2.0_maxlen384_batchsize4_gradacc4
XLMConfig {
  "architectures": [
    "XLMRobertaForMaskedLM"
  ],
  "asm": false,
  "attention_dropout": 0.1,
  "attention_probs_dropout_prob": 0.1,
  "bos_index": 0,
  "bos_token_id": 0,
  "causal": false,
  "dropout": 0.1,
  "emb_dim": 1024,
  "embed_init_std": 0.02209708691207961,
  "end_n_top": 5,
  "eos_index": 1,
  "eos_token_id": 2,
  "gelu_activation": true,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "init_std": 0.02,
  "initializer_range": 0.02,
  "intermediate_size": 4096,
  "is_encoder": true,
  "lang_id": 0,
  "layer_norm_eps": 1e-05,
  "mask_index": 5,
  "mask_token_id": 0,
  "max_position_embeddings": 514,
  "model_type": "xlm",
  "n_heads": 16,
  "n_langs": 1,
  "n_layers": 24,
  "output_past": true,
  "pad_index": 2,
  "pad_token_id": 1,
  "sinusoidal_embeddings": false,
  "start_n_top": 5,
  "summary_activation": null,
  "summary_first_dropout": 0.1,
  "summary_proj_to_labels": true,
  "summary_type": "first",
  "summary_use_proj": true,
  "transformers_version": "4.17.0",
  "type_vocab_size": 1,
  "unk_index": 3,
  "use_lang_emb": false,
  "vocab_size": 250002
}

Traceback (most recent call last):
  File "third_party/run_squad.py", line 958, in <module>
    main()
  File "third_party/run_squad.py", line 941, in main
    load_model(model, os.path.join(args.output_dir, "pytorch_model.bin"))
  File "third_party/run_squad.py", line 98, in load_model
    model.load_state_dict(torch.load(path, map_location='cpu'), strict=False)
  File "/cluster/project/sachan/yifan/softwares/anaconda/anaconda3/envs/xfactr/lib/python3.8/site-packages/torch/serialization.py", line 581, in load
    with _open_file_like(f, 'rb') as opened_file:
  File "/cluster/project/sachan/yifan/softwares/anaconda/anaconda3/envs/xfactr/lib/python3.8/site-packages/torch/serialization.py", line 230, in _open_file_like
    return _open_file(name_or_buffer, mode)
  File "/cluster/project/sachan/yifan/softwares/anaconda/anaconda3/envs/xfactr/lib/python3.8/site-packages/torch/serialization.py", line 211, in __init__
    super(_open_file, self).__init__(open(name, mode))
FileNotFoundError: [Errno 2] No such file or directory: '/cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//squad/xlm-KG_LR8e-6_EPOCH2.0_maxlen384_batchsize4_gradacc4/predictions/mlqa/pytorch_model.bin'
  vi 
2022-05-09 21:41:23.198866: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0
05/09/2022 21:41:25 - WARNING - __main__ -   Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, 16-bits training: False
You are using a model of type xlm-roberta to instantiate a model of type xlm. This is not supported for all configurations of models and can yield errors.
Some weights of the model checkpoint at /cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//squad/xlm-KG_LR8e-6_EPOCH2.0_maxlen384_batchsize4_gradacc4 were not used when initializing XLMRobertaModel: ['base_model.encoder.layer.6.attention.self.value.weight', 'base_model.encoder.layer.0.output.LayerNorm.weight', 'base_model.encoder.layer.22.attention.output.LayerNorm.bias', 'base_model.encoder.layer.8.attention.self.value.weight', 'base_model.encoder.layer.19.attention.output.dense.bias', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.22.attention.self.key.bias', 'base_model.encoder.layer.17.attention.self.query.bias', 'base_model.encoder.layer.15.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.9.attention.self.key.bias', 'base_model.encoder.layer.8.attention.self.key.weight', 'base_model.encoder.layer.15.attention.self.query.weight', 'base_model.encoder.layer.4.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.11.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.20.output.LayerNorm.weight', 'base_model.encoder.layer.9.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.13.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.8.output.dense.bias', 'base_model.encoder.layer.3.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.15.attention.self.key.bias', 'base_model.encoder.layer.0.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.22.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.16.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.15.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.16.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.10.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.14.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.10.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.4.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.7.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.1.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.3.attention.output.LayerNorm.bias', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.20.attention.self.value.bias', 'base_model.encoder.layer.13.attention.self.key.weight', 'base_model.encoder.layer.10.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.0.intermediate.dense.bias', 'base_model.encoder.layer.21.attention.output.dense.bias', 'base_model.encoder.layer.16.attention.output.dense.bias', 'base_model.encoder.layer.17.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.2.output.LayerNorm.weight', 'base_model.encoder.layer.15.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.6.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.17.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.9.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.13.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.19.output.dense.bias', 'base_model.encoder.layer.19.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.7.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.22.attention.output.dense.bias', 'base_model.encoder.layer.4.intermediate.dense.bias', 'base_model.encoder.layer.3.attention.self.query.bias', 'base_model.encoder.layer.2.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.10.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.21.intermediate.dense.weight', 'base_model.encoder.layer.5.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.8.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.19.attention.output.LayerNorm.bias', 'base_model.encoder.layer.14.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.17.attention.self.value.weight', 'base_model.encoder.layer.15.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.13.output.LayerNorm.weight', 'base_model.encoder.layer.8.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.23.attention.output.dense.bias', 'base_model.encoder.layer.6.attention.output.dense.bias', 'base_model.encoder.layer.8.attention.self.query.bias', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.5.output.LayerNorm.bias', 'base_model.encoder.layer.0.attention.output.LayerNorm.weight', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.12.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.14.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.22.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.23.output.LayerNorm.weight', 'base_model.encoder.layer.22.intermediate.dense.weight', 'base_model.encoder.layer.17.attention.self.key.bias', 'base_model.encoder.layer.2.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.11.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.22.attention.self.value.bias', 'base_model.encoder.layer.7.attention.output.dense.bias', 'base_model.embeddings.position_ids', 'base_model.encoder.layer.2.attention.output.dense.weight', 'base_model.encoder.layer.11.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.14.attention.output.dense.weight', 'base_model.encoder.layer.14.output.dense.weight', 'base_model.encoder.layer.21.output.LayerNorm.weight', 'base_model.encoder.layer.23.output.LayerNorm.bias', 'base_model.encoder.layer.3.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.6.output.LayerNorm.bias', 'base_model.encoder.layer.21.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.23.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.0.output.LayerNorm.bias', 'base_model.encoder.layer.22.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.14.attention.self.key.bias', 'base_model.encoder.layer.15.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.15.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.12.attention.output.LayerNorm.bias', 'base_model.encoder.layer.1.output.dense.weight', 'base_model.encoder.layer.12.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.20.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.15.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.6.intermediate.dense.bias', 'base_model.encoder.layer.21.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.16.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.8.attention.output.LayerNorm.weight', 'base_model.encoder.layer.12.output.LayerNorm.bias', 'base_model.encoder.layer.9.attention.self.key.weight', 'base_model.encoder.layer.20.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.21.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.19.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.20.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.3.attention.self.key.weight', 'base_model.encoder.layer.19.attention.self.query.weight', 'base_model.encoder.layer.23.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.10.attention.self.value.bias', 'base_model.encoder.layer.0.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.4.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.19.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.23.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.22.output.dense.bias', 'base_model.encoder.layer.13.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.2.attention.self.value.bias', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.17.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.2.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.13.output.LayerNorm.bias', 'base_model.encoder.layer.7.attention.self.query.weight', 'base_model.encoder.layer.11.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.19.attention.self.query.bias', 'base_model.encoder.layer.9.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.19.attention.self.value.weight', 'base_model.encoder.layer.7.attention.self.value.bias', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.21.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.2.attention.output.LayerNorm.weight', 'base_model.encoder.layer.1.output.dense.bias', 'base_model.encoder.layer.16.attention.self.value.bias', 'base_model.encoder.layer.18.attention.output.dense.bias', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.19.intermediate.dense.weight', 'base_model.encoder.layer.12.attention.output.dense.bias', 'base_model.encoder.layer.2.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.3.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.12.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.8.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.18.intermediate.dense.bias', 'base_model.encoder.layer.18.attention.output.dense.weight', 'base_model.encoder.layer.21.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.5.attention.self.query.weight', 'base_model.encoder.layer.13.attention.output.LayerNorm.bias', 'base_model.encoder.layer.0.attention.output.dense.bias', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.17.intermediate.dense.weight', 'base_model.encoder.layer.1.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.2.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.4.attention.self.query.bias', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.10.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.14.output.dense.bias', 'base_model.encoder.layer.22.attention.self.query.weight', 'base_model.encoder.layer.18.attention.self.key.bias', 'base_model.encoder.layer.23.intermediate.dense.bias', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.8.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.14.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.17.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.2.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.23.attention.self.query.bias', 'base_model.encoder.layer.2.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.13.attention.self.value.bias', 'base_model.encoder.layer.4.attention.output.LayerNorm.bias', 'base_model.encoder.layer.3.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.10.attention.self.key.weight', 'base_model.encoder.layer.1.attention.self.value.weight', 'base_model.encoder.layer.2.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.1.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.20.attention.self.value.weight', 'base_model.encoder.layer.0.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.22.output.LayerNorm.weight', 'base_model.encoder.layer.9.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.2.attention.output.LayerNorm.bias', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.22.intermediate.dense.bias', 'base_model.encoder.layer.18.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.7.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.0.attention.self.query.bias', 'base_model.encoder.layer.18.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.5.intermediate.dense.weight', 'base_model.encoder.layer.14.attention.self.query.bias', 'base_model.encoder.layer.1.attention.self.value.bias', 'base_model.encoder.layer.11.attention.output.LayerNorm.bias', 'base_model.encoder.layer.6.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.22.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.16.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.3.output.dense.bias', 'base_model.encoder.layer.6.attention.self.query.bias', 'base_model.encoder.layer.10.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.11.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.3.attention.output.dense.bias', 'base_model.encoder.layer.15.attention.self.value.weight', 'base_model.encoder.layer.19.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.9.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.6.attention.output.LayerNorm.bias', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.21.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.5.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.22.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.10.attention.output.LayerNorm.weight', 'base_model.encoder.layer.17.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.14.attention.self.query.weight', 'base_model.encoder.layer.15.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.14.intermediate.dense.bias', 'base_model.encoder.layer.10.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.7.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.4.attention.self.value.bias', 'base_model.encoder.layer.13.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.4.attention.self.query.weight', 'base_model.encoder.layer.1.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.19.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.23.attention.self.value.weight', 'base_model.encoder.layer.7.output.LayerNorm.bias', 'base_model.encoder.layer.9.attention.self.value.bias', 'base_model.encoder.layer.6.output.dense.bias', 'base_model.encoder.layer.7.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.13.attention.self.query.bias', 'base_model.encoder.layer.10.attention.output.LayerNorm.bias', 'base_model.encoder.layer.14.output.LayerNorm.bias', 'base_model.encoder.layer.5.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.20.intermediate.dense.bias', 'base_model.encoder.layer.7.attention.self.key.bias', 'base_model.encoder.layer.20.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.12.attention.output.dense.weight', 'base_model.encoder.layer.14.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.14.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.5.attention.output.dense.bias', 'base_model.encoder.layer.16.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.19.attention.self.value.bias', 'base_model.encoder.layer.20.attention.self.key.bias', 'base_model.encoder.layer.6.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.11.output.dense.bias', 'base_model.encoder.layer.16.output.LayerNorm.bias', 'base_model.encoder.layer.18.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.21.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.21.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.13.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.19.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.15.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.21.output.dense.weight', 'base_model.encoder.layer.3.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.21.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.6.attention.output.dense.weight', 'base_model.encoder.layer.4.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.2.attention.self.key.bias', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.16.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.4.attention.self.value.weight', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.2.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.13.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.18.output.adapters.tp.adapter_down.0.weight', 'base_model.embeddings.token_type_embeddings.weight', 'base_model.encoder.layer.19.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.3.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.16.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.4.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.5.attention.self.value.weight', 'base_model.encoder.layer.8.attention.output.dense.bias', 'base_model.encoder.layer.11.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.18.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.21.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.12.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.0.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.4.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.1.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.9.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.4.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.21.attention.output.dense.weight', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.2.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.15.attention.self.key.weight', 'base_model.encoder.layer.0.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.8.output.LayerNorm.bias', 'base_model.encoder.layer.14.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.21.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.23.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.12.attention.self.value.bias', 'base_model.encoder.layer.23.attention.self.key.weight', 'base_model.encoder.layer.4.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.16.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.14.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.10.output.dense.bias', 'base_model.encoder.layer.23.attention.output.LayerNorm.weight', 'base_model.encoder.layer.10.attention.self.query.bias', 'base_model.encoder.layer.1.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.12.output.LayerNorm.weight', 'base_model.encoder.layer.19.output.dense.weight', 'base_model.encoder.layer.0.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.6.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.6.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.13.attention.self.key.bias', 'base_model.encoder.layer.21.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.7.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.20.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.2.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.3.attention.output.LayerNorm.weight', 'base_model.encoder.layer.11.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.11.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.11.intermediate.dense.bias', 'base_model.encoder.layer.17.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.20.attention.self.key.weight', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.8.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.8.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.2.intermediate.dense.weight', 'base_model.encoder.layer.17.attention.self.query.weight', 'base_model.encoder.layer.19.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.18.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.12.output.dense.weight', 'base_model.encoder.layer.9.output.dense.weight', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.8.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.4.output.dense.bias', 'base_model.encoder.layer.12.output.dense.bias', 'base_model.encoder.layer.14.attention.self.key.weight', 'base_model.encoder.layer.23.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.12.attention.self.query.bias', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.22.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.16.intermediate.dense.bias', 'base_model.encoder.layer.0.attention.self.key.bias', 'base_model.encoder.layer.7.attention.self.key.weight', 'base_model.encoder.layer.0.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.4.attention.output.dense.weight', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.7.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.7.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.17.attention.output.dense.weight', 'base_model.encoder.layer.2.attention.self.value.weight', 'base_model.encoder.layer.12.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.1.output.LayerNorm.bias', 'base_model.encoder.layer.10.attention.self.query.weight', 'base_model.encoder.layer.5.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.16.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.22.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.20.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.23.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.5.attention.output.dense.weight', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.2.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.9.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.16.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.14.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.15.output.dense.bias', 'base_model.encoder.layer.3.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.4.intermediate.dense.weight', 'base_model.encoder.layer.10.output.LayerNorm.bias', 'base_model.pooler.dense.weight', 'base_model.encoder.layer.15.output.LayerNorm.weight', 'base_model.pooler.dense.bias', 'base_model.encoder.layer.2.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.11.attention.self.key.weight', 'base_model.encoder.layer.17.attention.output.dense.bias', 'base_model.encoder.layer.7.output.LayerNorm.weight', 'base_model.encoder.layer.21.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.21.attention.self.key.weight', 'base_model.encoder.layer.21.attention.self.value.weight', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.10.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.0.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.20.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.0.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.20.attention.output.dense.bias', 'base_model.encoder.layer.14.attention.self.value.weight', 'base_model.encoder.layer.16.output.dense.weight', 'base_model.encoder.layer.3.attention.self.query.weight', 'base_model.encoder.layer.3.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.7.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.19.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.2.intermediate.dense.bias', 'base_model.encoder.layer.2.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.15.attention.output.dense.weight', 'base_model.encoder.layer.12.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.10.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.19.output.LayerNorm.bias', 'base_model.encoder.layer.0.attention.self.key.weight', 'base_model.encoder.layer.12.intermediate.dense.weight', 'base_model.encoder.layer.18.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.4.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.5.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.23.attention.self.key.bias', 'base_model.encoder.layer.6.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.18.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.0.attention.self.value.weight', 'base_model.encoder.layer.13.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.12.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.8.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.0.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.16.output.dense.bias', 'base_model.encoder.layer.18.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.19.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.23.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.9.attention.output.LayerNorm.weight', 'base_model.encoder.layer.11.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.23.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.17.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.21.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.14.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.11.attention.self.value.bias', 'base_model.encoder.layer.5.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.15.attention.output.LayerNorm.weight', 'base_model.encoder.layer.22.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.9.output.dense.bias', 'base_model.encoder.layer.11.attention.output.dense.weight', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.7.attention.output.dense.weight', 'base_model.encoder.layer.4.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.23.attention.self.query.weight', 'base_model.encoder.layer.5.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.22.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.13.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.16.attention.self.query.weight', 'base_model.encoder.layer.22.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.2.output.dense.weight', 'base_model.encoder.layer.5.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.21.intermediate.dense.bias', 'base_model.encoder.layer.3.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.19.attention.output.LayerNorm.weight', 'base_model.encoder.layer.3.intermediate.dense.weight', 'base_model.encoder.layer.3.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.1.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.6.attention.output.LayerNorm.weight', 'base_model.encoder.layer.10.intermediate.dense.weight', 'base_model.encoder.layer.8.attention.self.value.bias', 'base_model.encoder.layer.4.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.6.output.LayerNorm.weight', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.3.output.LayerNorm.weight', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.5.attention.self.query.bias', 'base_model.encoder.layer.3.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.1.attention.output.dense.bias', 'base_model.encoder.layer.11.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.5.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.0.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.19.output.LayerNorm.weight', 'base_model.encoder.layer.22.attention.self.key.weight', 'base_model.encoder.layer.13.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.9.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.16.output.LayerNorm.weight', 'base_model.encoder.layer.5.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.15.attention.self.value.bias', 'base_model.encoder.layer.7.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.5.output.dense.weight', 'base_model.encoder.layer.22.attention.self.value.weight', 'base_model.encoder.layer.0.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.5.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.23.output.dense.weight', 'base_model.encoder.layer.14.attention.output.LayerNorm.weight', 'base_model.encoder.layer.7.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.21.output.dense.bias', 'base_model.encoder.layer.15.intermediate.dense.weight', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.1.attention.output.LayerNorm.bias', 'base_model.encoder.layer.10.intermediate.dense.bias', 'base_model.encoder.layer.13.attention.self.value.weight', 'base_model.encoder.layer.13.attention.output.dense.weight', 'base_model.encoder.layer.8.attention.output.LayerNorm.bias', 'base_model.encoder.layer.10.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.3.output.dense.weight', 'base_model.encoder.layer.18.output.LayerNorm.bias', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.5.attention.self.value.bias', 'base_model.encoder.layer.18.output.dense.weight', 'base_model.encoder.layer.23.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.11.attention.self.query.weight', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.13.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.2.attention.output.dense.bias', 'base_model.encoder.layer.18.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.21.attention.self.key.bias', 'base_model.encoder.layer.7.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.9.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.20.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.23.attention.output.dense.weight', 'base_model.encoder.layer.14.output.LayerNorm.weight', 'base_model.encoder.layer.15.attention.output.dense.bias', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.18.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.22.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.9.attention.self.query.bias', 'base_model.encoder.layer.13.attention.output.dense.bias', 'base_model.encoder.layer.11.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.12.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.1.attention.output.dense.weight', 'base_model.encoder.layer.4.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.6.output.dense.weight', 'base_model.encoder.layer.20.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.20.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.9.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.17.attention.self.key.weight', 'base_model.encoder.layer.22.attention.output.LayerNorm.weight', 'base_model.encoder.layer.5.intermediate.dense.bias', 'base_model.encoder.layer.21.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.16.attention.self.value.weight', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.14.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.17.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.17.attention.output.LayerNorm.bias', 'base_model.encoder.layer.7.output.dense.weight', 'base_model.encoder.layer.19.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.9.attention.output.dense.weight', 'base_model.encoder.layer.14.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.17.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.13.output.adapters.es.adapter_down.0.weight', 'base_model.embeddings.LayerNorm.weight', 'base_model.encoder.layer.14.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.9.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.20.attention.output.LayerNorm.bias', 'base_model.encoder.layer.22.output.LayerNorm.bias', 'base_model.encoder.layer.23.attention.output.LayerNorm.bias', 'base_model.encoder.layer.13.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.3.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.15.attention.output.LayerNorm.bias', 'base_model.encoder.layer.8.output.LayerNorm.weight', 'base_model.encoder.layer.3.intermediate.dense.bias', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.12.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.9.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.6.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.7.intermediate.dense.bias', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.21.attention.output.LayerNorm.bias', 'base_model.encoder.layer.0.output.dense.weight', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.16.attention.self.key.weight', 'base_model.encoder.layer.9.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.15.attention.self.query.bias', 'base_model.encoder.layer.18.attention.self.value.weight', 'base_model.encoder.layer.23.attention.self.value.bias', 'base_model.encoder.layer.9.attention.self.query.weight', 'base_model.encoder.layer.18.attention.output.LayerNorm.weight', 'base_model.encoder.layer.17.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.5.attention.output.LayerNorm.bias', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.4.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.8.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.21.attention.self.query.bias', 'base_model.encoder.layer.12.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.17.attention.output.LayerNorm.weight', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.9.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.17.output.LayerNorm.bias', 'base_model.encoder.layer.20.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.1.attention.output.LayerNorm.weight', 'base_model.encoder.layer.21.attention.self.value.bias', 'base_model.encoder.layer.16.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.11.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.4.attention.self.key.bias', 'base_model.encoder.layer.2.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.6.intermediate.dense.weight', 'base_model.encoder.layer.9.intermediate.dense.weight', 'base_model.encoder.layer.0.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.14.intermediate.dense.weight', 'base_model.encoder.layer.8.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.13.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.19.attention.self.key.bias', 'base_model.encoder.layer.18.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.18.attention.self.query.weight', 'base_model.encoder.layer.12.attention.self.key.bias', 'base_model.encoder.layer.6.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.18.attention.self.query.bias', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.11.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.22.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.14.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.4.output.LayerNorm.bias', 'base_model.encoder.layer.7.intermediate.dense.weight', 'base_model.encoder.layer.19.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.8.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.0.attention.self.query.weight', 'base_model.encoder.layer.9.output.LayerNorm.bias', 'base_model.encoder.layer.1.attention.self.query.weight', 'base_model.encoder.layer.5.output.dense.bias', 'base_model.encoder.layer.19.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.17.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.7.output.dense.bias', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.19.intermediate.dense.bias', 'base_model.encoder.layer.5.attention.self.key.bias', 'base_model.encoder.layer.16.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.10.attention.self.value.weight', 'base_model.encoder.layer.23.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.3.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.23.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.19.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.5.output.LayerNorm.weight', 'base_model.encoder.layer.11.attention.output.LayerNorm.weight', 'base_model.encoder.layer.17.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.12.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.6.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.22.output.dense.weight', 'base_model.encoder.layer.20.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.4.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.8.output.dense.weight', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.18.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.2.attention.self.key.weight', 'base_model.encoder.layer.0.attention.output.LayerNorm.bias', 'base_model.encoder.layer.19.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.21.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.9.attention.output.dense.bias', 'base_model.encoder.layer.1.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.7.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.12.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.18.output.LayerNorm.weight', 'base_model.encoder.layer.15.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.16.attention.output.dense.weight', 'base_model.encoder.layer.13.output.dense.weight', 'base_model.encoder.layer.12.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.20.attention.self.query.weight', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.16.attention.output.LayerNorm.weight', 'base_model.encoder.layer.23.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.11.attention.self.key.bias', 'base_model.encoder.layer.19.attention.self.key.weight', 'base_model.encoder.layer.11.output.LayerNorm.weight', 'base_model.encoder.layer.6.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.10.output.dense.weight', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.22.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.20.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.15.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.2.output.LayerNorm.bias', 'base_model.encoder.layer.22.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.17.attention.self.value.bias', 'base_model.encoder.layer.23.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.11.attention.self.value.weight', 'base_model.encoder.layer.16.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.22.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.17.output.dense.bias', 'base_model.encoder.layer.9.attention.self.value.weight', 'base_model.encoder.layer.1.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.5.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.11.output.LayerNorm.bias', 'base_model.encoder.layer.13.intermediate.dense.bias', 'base_model.encoder.layer.15.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.2.output.dense.bias', 'base_model.encoder.layer.18.attention.self.value.bias', 'base_model.encoder.layer.3.attention.self.key.bias', 'base_model.encoder.layer.23.output.dense.bias', 'base_model.encoder.layer.23.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.20.attention.output.LayerNorm.weight', 'base_model.encoder.layer.10.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.1.attention.self.key.bias', 'base_model.encoder.layer.16.attention.output.LayerNorm.bias', 'base_model.encoder.layer.7.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.12.attention.output.LayerNorm.weight', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.10.attention.self.key.bias', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.13.attention.output.LayerNorm.weight', 'base_model.encoder.layer.0.attention.self.value.bias', 'base_model.encoder.layer.13.intermediate.dense.weight', 'base_model.encoder.layer.14.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.21.output.LayerNorm.bias', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.1.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.23.intermediate.dense.weight', 'base_model.encoder.layer.13.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.12.attention.self.query.weight', 'base_model.encoder.layer.8.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.4.output.dense.weight', 'base_model.encoder.layer.18.attention.output.LayerNorm.bias', 'base_model.encoder.layer.0.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.9.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.10.attention.output.dense.bias', 'base_model.encoder.layer.17.output.LayerNorm.weight', 'base_model.encoder.layer.16.attention.self.key.bias', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.6.attention.self.query.weight', 'base_model.encoder.layer.9.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.11.attention.output.dense.bias', 'base_model.encoder.layer.4.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.1.attention.self.query.bias', 'base_model.encoder.layer.20.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.8.attention.self.key.bias', 'base_model.encoder.layer.15.output.dense.weight', 'base_model.encoder.layer.18.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.20.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.20.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.15.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.0.intermediate.dense.weight', 'base_model.encoder.layer.3.attention.self.value.bias', 'qa_outputs.weight', 'base_model.encoder.layer.21.attention.self.query.weight', 'base_model.encoder.layer.8.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.0.attention.output.dense.weight', 'base_model.encoder.layer.3.output.LayerNorm.bias', 'base_model.encoder.layer.8.intermediate.dense.weight', 'base_model.encoder.layer.17.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.3.attention.output.dense.weight', 'base_model.encoder.layer.8.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.6.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.0.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.10.output.adapters.tp.adapter_up.weight', 'base_model.embeddings.word_embeddings.weight', 'base_model.encoder.layer.3.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.22.attention.self.query.bias', 'base_model.encoder.layer.7.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.23.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.20.output.dense.weight', 'base_model.encoder.layer.10.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.6.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.23.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.2.attention.self.query.bias', 'base_model.encoder.layer.10.output.LayerNorm.weight', 'base_model.encoder.layer.9.output.LayerNorm.weight', 'base_model.encoder.layer.1.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.5.attention.self.key.weight', 'base_model.encoder.layer.11.output.dense.weight', 'base_model.encoder.layer.5.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.1.output.LayerNorm.weight', 'base_model.encoder.layer.7.attention.self.query.bias', 'base_model.encoder.layer.3.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.16.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.20.output.dense.bias', 'base_model.encoder.layer.8.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.12.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.4.attention.output.LayerNorm.weight', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.21.attention.output.LayerNorm.weight', 'base_model.encoder.layer.4.output.LayerNorm.weight', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.4.attention.self.key.weight', 'base_model.encoder.layer.4.attention.output.dense.bias', 'base_model.encoder.layer.0.output.dense.bias', 'base_model.encoder.layer.12.attention.self.key.weight', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.7.attention.output.LayerNorm.weight', 'base_model.encoder.layer.11.intermediate.dense.weight', 'base_model.encoder.layer.15.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.5.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.14.attention.output.LayerNorm.bias', 'base_model.encoder.layer.2.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.16.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.7.attention.output.LayerNorm.bias', 'base_model.encoder.layer.17.output.dense.weight', 'base_model.encoder.layer.10.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.15.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.5.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.16.attention.self.query.bias', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.18.attention.self.key.weight', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.1.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.7.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.15.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.1.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.11.attention.self.query.bias', 'base_model.encoder.layer.20.attention.self.query.bias', 'base_model.embeddings.position_embeddings.weight', 'base_model.encoder.layer.6.attention.self.key.bias', 'base_model.encoder.layer.6.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.8.intermediate.dense.bias', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.18.intermediate.dense.weight', 'base_model.encoder.layer.22.attention.output.dense.weight', 'base_model.encoder.layer.1.intermediate.dense.weight', 'base_model.encoder.layer.22.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.12.intermediate.dense.bias', 'base_model.encoder.layer.14.attention.self.value.bias', 'base_model.encoder.layer.7.attention.self.value.weight', 'base_model.embeddings.LayerNorm.bias', 'base_model.encoder.layer.12.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.6.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.5.attention.output.LayerNorm.weight', 'base_model.encoder.layer.19.attention.output.dense.weight', 'base_model.encoder.layer.3.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.14.attention.output.dense.bias', 'base_model.encoder.layer.1.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.13.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.18.output.dense.bias', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.1.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.9.attention.output.LayerNorm.bias', 'base_model.encoder.layer.2.attention.self.query.weight', 'base_model.encoder.layer.13.attention.self.query.weight', 'base_model.encoder.layer.6.attention.self.key.weight', 'base_model.encoder.layer.16.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.8.attention.output.dense.weight', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.8.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.20.attention.output.dense.weight', 'qa_outputs.bias', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.10.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.10.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.14.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.13.output.dense.bias', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.1.intermediate.dense.bias', 'base_model.encoder.layer.12.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.17.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.18.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.16.intermediate.dense.weight', 'base_model.encoder.layer.0.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.11.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.12.attention.self.value.weight', 'base_model.encoder.layer.6.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.19.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.15.intermediate.dense.bias', 'base_model.encoder.layer.11.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.3.attention.self.value.weight', 'base_model.encoder.layer.17.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.5.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.15.output.LayerNorm.bias', 'base_model.encoder.layer.13.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.6.attention.self.value.bias', 'base_model.encoder.layer.6.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.17.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.1.attention.self.key.weight', 'base_model.encoder.layer.20.intermediate.dense.weight', 'base_model.encoder.layer.11.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.20.output.LayerNorm.bias', 'base_model.encoder.layer.18.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.8.attention.self.query.weight', 'base_model.encoder.layer.9.intermediate.dense.bias', 'base_model.encoder.layer.4.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.10.attention.output.dense.weight', 'base_model.encoder.layer.1.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.17.intermediate.dense.bias']
- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of XLMRobertaModel were not initialized from the model checkpoint at /cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//squad/xlm-KG_LR8e-6_EPOCH2.0_maxlen384_batchsize4_gradacc4 and are newly initialized: ['encoder.layer.22.output.dense.weight', 'encoder.layer.3.attention.self.value.weight', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.16.intermediate.dense.weight', 'encoder.layer.14.attention.self.value.bias', 'encoder.layer.5.attention.self.value.bias', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.12.attention.output.dense.bias', 'encoder.layer.23.attention.self.query.bias', 'encoder.layer.3.attention.output.dense.weight', 'encoder.layer.9.output.LayerNorm.bias', 'encoder.layer.14.intermediate.dense.bias', 'encoder.layer.6.output.dense.bias', 'encoder.layer.23.attention.self.key.bias', 'encoder.layer.13.attention.self.value.bias', 'encoder.layer.7.intermediate.dense.bias', 'encoder.layer.23.attention.self.value.bias', 'encoder.layer.23.attention.output.dense.weight', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.14.output.dense.bias', 'encoder.layer.12.output.LayerNorm.weight', 'encoder.layer.23.output.LayerNorm.weight', 'encoder.layer.18.attention.output.LayerNorm.weight', 'encoder.layer.11.attention.self.query.weight', 'encoder.layer.6.output.LayerNorm.bias', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.6.attention.self.value.bias', 'encoder.layer.14.attention.output.dense.bias', 'encoder.layer.17.attention.self.query.bias', 'encoder.layer.10.attention.output.dense.bias', 'encoder.layer.11.attention.self.query.bias', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.23.attention.output.dense.bias', 'encoder.layer.23.attention.self.value.weight', 'encoder.layer.4.output.dense.weight', 'encoder.layer.8.attention.self.query.weight', 'encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.layer.2.attention.self.value.weight', 'encoder.layer.9.output.dense.bias', 'encoder.layer.21.attention.self.query.weight', 'encoder.layer.15.output.dense.bias', 'encoder.layer.14.attention.self.value.weight', 'encoder.layer.12.attention.self.key.bias', 'encoder.layer.13.output.LayerNorm.bias', 'encoder.layer.4.attention.output.dense.bias', 'encoder.layer.17.attention.self.key.bias', 'encoder.layer.4.attention.output.LayerNorm.weight', 'encoder.layer.17.intermediate.dense.bias', 'encoder.layer.10.output.LayerNorm.bias', 'encoder.layer.11.output.dense.weight', 'encoder.layer.9.output.LayerNorm.weight', 'encoder.layer.18.attention.self.key.weight', 'encoder.layer.16.attention.output.LayerNorm.weight', 'encoder.layer.10.output.dense.bias', 'encoder.layer.21.output.dense.bias', 'encoder.layer.2.output.dense.bias', 'encoder.layer.21.attention.output.LayerNorm.weight', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.13.attention.output.LayerNorm.bias', 'encoder.layer.17.attention.output.dense.bias', 'encoder.layer.17.attention.self.value.weight', 'encoder.layer.12.attention.output.dense.weight', 'encoder.layer.17.intermediate.dense.weight', 'encoder.layer.2.attention.self.query.weight', 'encoder.layer.19.attention.self.query.bias', 'encoder.layer.12.attention.self.query.weight', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.12.output.dense.weight', 'encoder.layer.18.attention.self.key.bias', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.14.attention.self.key.weight', 'encoder.layer.18.output.dense.weight', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.10.attention.self.key.weight', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.15.attention.output.dense.bias', 'encoder.layer.2.attention.self.key.weight', 'encoder.layer.23.output.LayerNorm.bias', 'encoder.layer.15.output.LayerNorm.bias', 'encoder.layer.16.output.dense.weight', 'encoder.layer.16.attention.self.query.bias', 'encoder.layer.16.attention.self.query.weight', 'encoder.layer.7.attention.output.dense.weight', 'encoder.layer.16.attention.output.LayerNorm.bias', 'encoder.layer.7.attention.self.value.bias', 'encoder.layer.12.attention.output.LayerNorm.weight', 'encoder.layer.0.intermediate.dense.weight', 'embeddings.position_embeddings.weight', 'encoder.layer.14.output.LayerNorm.weight', 'embeddings.LayerNorm.weight', 'encoder.layer.0.attention.output.LayerNorm.weight', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.1.attention.output.dense.bias', 'encoder.layer.18.attention.output.LayerNorm.bias', 'encoder.layer.12.attention.self.value.weight', 'encoder.layer.22.attention.output.dense.weight', 'encoder.layer.8.attention.output.LayerNorm.bias', 'encoder.layer.21.output.LayerNorm.weight', 'encoder.layer.7.attention.self.key.bias', 'encoder.layer.22.output.LayerNorm.bias', 'encoder.layer.19.output.dense.weight', 'encoder.layer.5.attention.self.query.bias', 'encoder.layer.15.attention.output.LayerNorm.weight', 'encoder.layer.1.output.dense.bias', 'encoder.layer.15.attention.self.value.weight', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.10.attention.self.value.bias', 'encoder.layer.0.output.dense.weight', 'encoder.layer.22.attention.output.LayerNorm.bias', 'encoder.layer.20.attention.self.value.weight', 'encoder.layer.19.attention.output.LayerNorm.bias', 'encoder.layer.3.attention.self.key.bias', 'encoder.layer.12.intermediate.dense.bias', 'encoder.layer.1.attention.self.key.bias', 'encoder.layer.16.output.LayerNorm.weight', 'encoder.layer.13.attention.self.key.bias', 'encoder.layer.6.attention.self.value.weight', 'encoder.layer.4.attention.output.dense.weight', 'encoder.layer.1.attention.output.dense.weight', 'encoder.layer.15.attention.output.dense.weight', 'encoder.layer.20.attention.output.dense.weight', 'encoder.layer.6.attention.self.key.bias', 'encoder.layer.11.attention.self.value.bias', 'encoder.layer.19.output.LayerNorm.weight', 'encoder.layer.23.attention.output.LayerNorm.bias', 'encoder.layer.5.attention.output.dense.weight', 'encoder.layer.13.attention.self.key.weight', 'encoder.layer.10.output.LayerNorm.weight', 'encoder.layer.18.attention.self.query.weight', 'encoder.layer.18.output.LayerNorm.bias', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.22.intermediate.dense.bias', 'encoder.layer.6.attention.output.dense.weight', 'encoder.layer.22.output.dense.bias', 'encoder.layer.2.attention.output.LayerNorm.bias', 'encoder.layer.18.attention.output.dense.weight', 'encoder.layer.23.attention.output.LayerNorm.weight', 'encoder.layer.13.attention.self.query.weight', 'encoder.layer.5.attention.self.key.weight', 'encoder.layer.22.attention.self.key.bias', 'encoder.layer.13.attention.self.value.weight', 'encoder.layer.5.output.dense.weight', 'encoder.layer.13.output.dense.bias', 'encoder.layer.21.attention.self.value.bias', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.19.attention.output.LayerNorm.weight', 'encoder.layer.22.attention.self.key.weight', 'encoder.layer.9.attention.self.key.weight', 'encoder.layer.21.attention.self.key.weight', 'encoder.layer.18.intermediate.dense.bias', 'encoder.layer.23.attention.self.key.weight', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.3.attention.self.query.bias', 'encoder.layer.12.attention.output.LayerNorm.bias', 'encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.6.attention.self.query.weight', 'encoder.layer.9.attention.self.query.bias', 'embeddings.word_embeddings.weight', 'encoder.layer.21.intermediate.dense.bias', 'encoder.layer.3.attention.output.dense.bias', 'encoder.layer.1.attention.output.LayerNorm.weight', 'encoder.layer.20.attention.self.value.bias', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.7.attention.output.LayerNorm.bias', 'encoder.layer.6.attention.output.dense.bias', 'encoder.layer.19.intermediate.dense.bias', 'encoder.layer.12.output.LayerNorm.bias', 'encoder.layer.22.attention.self.value.bias', 'encoder.layer.16.attention.output.dense.weight', 'encoder.layer.20.attention.output.LayerNorm.bias', 'encoder.layer.7.attention.self.query.bias', 'encoder.layer.23.output.dense.bias', 'encoder.layer.14.output.LayerNorm.bias', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.20.output.dense.bias', 'encoder.layer.0.attention.self.query.bias', 'encoder.layer.16.attention.output.dense.bias', 'encoder.layer.10.attention.self.value.weight', 'encoder.layer.15.intermediate.dense.weight', 'encoder.layer.22.attention.self.query.weight', 'encoder.layer.21.attention.self.query.bias', 'encoder.layer.13.attention.self.query.bias', 'encoder.layer.3.attention.self.value.bias', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.0.output.dense.bias', 'encoder.layer.10.attention.output.LayerNorm.bias', 'encoder.layer.4.attention.self.query.bias', 'encoder.layer.8.attention.output.LayerNorm.weight', 'encoder.layer.8.output.LayerNorm.weight', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.19.attention.self.value.bias', 'encoder.layer.18.attention.self.value.weight', 'encoder.layer.9.attention.self.key.bias', 'encoder.layer.20.attention.self.query.weight', 'encoder.layer.15.output.dense.weight', 'encoder.layer.20.output.LayerNorm.weight', 'encoder.layer.0.attention.self.key.weight', 'embeddings.token_type_embeddings.weight', 'encoder.layer.1.output.dense.weight', 'encoder.layer.20.output.LayerNorm.bias', 'encoder.layer.1.attention.self.key.weight', 'encoder.layer.21.attention.self.key.bias', 'encoder.layer.9.attention.output.dense.bias', 'encoder.layer.9.attention.output.dense.weight', 'encoder.layer.16.attention.self.key.weight', 'encoder.layer.5.attention.self.query.weight', 'encoder.layer.21.intermediate.dense.weight', 'encoder.layer.0.attention.self.query.weight', 'encoder.layer.15.attention.self.query.bias', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.0.attention.output.dense.bias', 'encoder.layer.14.intermediate.dense.weight', 'encoder.layer.10.attention.output.LayerNorm.weight', 'encoder.layer.11.output.LayerNorm.bias', 'encoder.layer.5.attention.self.value.weight', 'encoder.layer.19.output.LayerNorm.bias', 'encoder.layer.15.attention.output.LayerNorm.bias', 'encoder.layer.23.output.dense.weight', 'encoder.layer.20.attention.output.LayerNorm.weight', 'encoder.layer.17.attention.output.dense.weight', 'encoder.layer.19.attention.self.query.weight', 'encoder.layer.2.attention.self.value.bias', 'encoder.layer.20.attention.output.dense.bias', 'encoder.layer.8.attention.output.dense.weight', 'encoder.layer.5.attention.output.dense.bias', 'encoder.layer.1.attention.self.value.bias', 'encoder.layer.17.attention.self.query.weight', 'pooler.dense.bias', 'encoder.layer.22.attention.self.query.bias', 'encoder.layer.19.attention.self.key.weight', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.17.attention.output.LayerNorm.weight', 'encoder.layer.6.attention.output.LayerNorm.bias', 'encoder.layer.18.intermediate.dense.weight', 'encoder.layer.13.attention.output.dense.bias', 'encoder.layer.22.attention.output.dense.bias', 'encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.layer.0.attention.self.value.bias', 'encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.layer.11.attention.output.LayerNorm.weight', 'encoder.layer.11.output.dense.bias', 'encoder.layer.9.attention.self.value.weight', 'encoder.layer.9.attention.self.query.weight', 'encoder.layer.2.attention.self.key.bias', 'encoder.layer.23.intermediate.dense.weight', 'encoder.layer.4.attention.self.value.bias', 'encoder.layer.12.attention.self.value.bias', 'encoder.layer.16.intermediate.dense.bias', 'encoder.layer.18.attention.self.query.bias', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.2.output.dense.weight', 'encoder.layer.3.attention.self.key.weight', 'encoder.layer.11.attention.output.dense.bias', 'encoder.layer.4.attention.output.LayerNorm.bias', 'encoder.layer.19.attention.output.dense.weight', 'encoder.layer.8.output.LayerNorm.bias', 'encoder.layer.17.attention.self.key.weight', 'encoder.layer.13.intermediate.dense.weight', 'encoder.layer.15.attention.self.key.bias', 'encoder.layer.10.intermediate.dense.weight', 'encoder.layer.1.attention.self.query.weight', 'encoder.layer.20.output.dense.weight', 'encoder.layer.7.attention.self.value.weight', 'encoder.layer.10.attention.output.dense.weight', 'encoder.layer.20.intermediate.dense.weight', 'encoder.layer.10.output.dense.weight', 'encoder.layer.16.output.dense.bias', 'encoder.layer.17.output.LayerNorm.bias', 'encoder.layer.8.attention.self.key.weight', 'encoder.layer.15.intermediate.dense.bias', 'encoder.layer.8.attention.output.dense.bias', 'encoder.layer.9.attention.output.LayerNorm.weight', 'encoder.layer.21.attention.output.LayerNorm.bias', 'encoder.layer.21.output.dense.weight', 'encoder.layer.7.output.dense.bias', 'encoder.layer.3.attention.self.query.weight', 'encoder.layer.15.attention.self.query.weight', 'encoder.layer.17.output.LayerNorm.weight', 'encoder.layer.20.intermediate.dense.bias', 'encoder.layer.6.attention.self.query.bias', 'encoder.layer.1.attention.self.value.weight', 'encoder.layer.12.intermediate.dense.weight', 'encoder.layer.0.attention.output.dense.weight', 'encoder.layer.13.output.LayerNorm.weight', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.14.attention.self.key.bias', 'encoder.layer.20.attention.self.query.bias', 'encoder.layer.14.attention.self.query.bias', 'encoder.layer.13.output.dense.weight', 'encoder.layer.18.attention.output.dense.bias', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.3.output.dense.bias', 'encoder.layer.13.attention.output.LayerNorm.weight', 'encoder.layer.19.attention.output.dense.bias', 'encoder.layer.5.attention.output.LayerNorm.weight', 'encoder.layer.8.attention.self.value.bias', 'encoder.layer.18.attention.self.value.bias', 'encoder.layer.10.attention.self.key.bias', 'encoder.layer.19.intermediate.dense.weight', 'encoder.layer.2.attention.output.dense.weight', 'encoder.layer.6.output.dense.weight', 'encoder.layer.11.attention.self.value.weight', 'encoder.layer.16.output.LayerNorm.bias', 'encoder.layer.15.output.LayerNorm.weight', 'encoder.layer.6.attention.self.key.weight', 'encoder.layer.12.output.dense.bias', 'encoder.layer.20.attention.self.key.bias', 'encoder.layer.9.output.dense.weight', 'encoder.layer.17.output.dense.bias', 'encoder.layer.4.attention.self.key.weight', 'encoder.layer.17.output.dense.weight', 'encoder.layer.20.attention.self.key.weight', 'encoder.layer.4.attention.self.query.weight', 'embeddings.LayerNorm.bias', 'encoder.layer.11.attention.output.dense.weight', 'encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.22.attention.self.value.weight', 'encoder.layer.13.attention.output.dense.weight', 'encoder.layer.9.attention.output.LayerNorm.bias', 'encoder.layer.0.attention.self.key.bias', 'encoder.layer.12.attention.self.key.weight', 'encoder.layer.23.intermediate.dense.bias', 'encoder.layer.22.attention.output.LayerNorm.weight', 'encoder.layer.19.output.dense.bias', 'encoder.layer.17.attention.output.LayerNorm.bias', 'encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.layer.13.intermediate.dense.bias', 'encoder.layer.14.attention.output.LayerNorm.bias', 'encoder.layer.21.output.LayerNorm.bias', 'encoder.layer.15.attention.self.value.bias', 'encoder.layer.10.attention.self.query.weight', 'encoder.layer.7.output.LayerNorm.bias', 'encoder.layer.23.attention.self.query.weight', 'encoder.layer.0.attention.self.value.weight', 'encoder.layer.7.attention.output.dense.bias', 'encoder.layer.19.attention.self.key.bias', 'encoder.layer.16.attention.self.value.weight', 'encoder.layer.11.output.LayerNorm.weight', 'encoder.layer.21.attention.output.dense.weight', 'encoder.layer.4.attention.self.key.bias', 'encoder.layer.7.attention.self.query.weight', 'encoder.layer.14.output.dense.weight', 'encoder.layer.5.attention.self.key.bias', 'encoder.layer.8.attention.self.query.bias', 'encoder.layer.6.attention.output.LayerNorm.weight', 'encoder.layer.22.output.LayerNorm.weight', 'encoder.layer.4.output.dense.bias', 'encoder.layer.11.attention.self.key.bias', 'encoder.layer.12.attention.self.query.bias', 'encoder.layer.16.attention.self.key.bias', 'encoder.layer.19.attention.self.value.weight', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.14.attention.output.dense.weight', 'encoder.layer.15.attention.self.key.weight', 'encoder.layer.11.attention.self.key.weight', 'pooler.dense.weight', 'encoder.layer.8.output.dense.weight', 'encoder.layer.7.attention.self.key.weight', 'encoder.layer.8.output.dense.bias', 'encoder.layer.7.output.LayerNorm.weight', 'encoder.layer.18.output.LayerNorm.weight', 'encoder.layer.16.attention.self.value.bias', 'encoder.layer.21.attention.output.dense.bias', 'encoder.layer.8.attention.self.key.bias', 'encoder.layer.18.output.dense.bias', 'encoder.layer.2.attention.self.query.bias', 'encoder.layer.7.output.dense.weight', 'encoder.layer.2.attention.output.dense.bias', 'encoder.layer.4.attention.self.value.weight', 'encoder.layer.21.attention.self.value.weight', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.22.intermediate.dense.weight', 'encoder.layer.5.output.LayerNorm.bias', 'encoder.layer.9.attention.self.value.bias', 'encoder.layer.3.output.dense.weight', 'encoder.layer.14.attention.self.query.weight', 'encoder.layer.7.attention.output.LayerNorm.weight', 'encoder.layer.17.attention.self.value.bias', 'encoder.layer.8.attention.self.value.weight', 'encoder.layer.5.output.dense.bias', 'encoder.layer.10.attention.self.query.bias', 'encoder.layer.14.attention.output.LayerNorm.weight', 'encoder.layer.1.attention.self.query.bias', 'encoder.layer.2.attention.output.LayerNorm.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Overwriting existing adapter 'ep'.
Overwriting existing adapter 'tp'.
Overwriting existing adapter 'es'.
Overwriting existing adapter 'ts'.
Overwriting existing adapter fusion module 'ep,tp,es,ts'
05/09/2022 21:41:48 - INFO - __main__ -   lang2id = None
05/09/2022 21:41:52 - INFO - __main__ -   Training/evaluation parameters Namespace(adam_epsilon=1e-08, cache_dir='', config_name='', data_dir=None, device=device(type='cuda'), do_eval=True, do_lower_case=False, do_train=False, doc_stride=128, eval_all_checkpoints=False, eval_lang='vi', evaluate_during_training=False, fp16=False, fp16_opt_level='O1', gradient_accumulation_steps=1, learning_rate=5e-05, local_rank=-1, logging_steps=50, max_answer_length=30, max_grad_norm=1.0, max_query_length=64, max_seq_length=384, max_steps=-1, model_name='xlm-KG', model_name_or_path='/cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//squad/xlm-KG_LR8e-6_EPOCH2.0_maxlen384_batchsize4_gradacc4', model_type='xlm', modelkg_dir='/cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/adapter/xlmr_adapter', n_best_size=20, n_gpu=1, no_cuda=False, null_score_diff_threshold=0.0, num_train_epochs=3.0, output_dir='/cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//squad/xlm-KG_LR8e-6_EPOCH2.0_maxlen384_batchsize4_gradacc4/predictions/mlqa/', overwrite_cache=False, overwrite_output_dir=False, per_gpu_eval_batch_size=8, per_gpu_train_batch_size=8, predict_file='/cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/download//mlqa//MLQA_V1/test/test-context-vi-question-vi.json', save_steps=50, seed=42, server_ip='', server_port='', threads=1, tokenizer_name='', train_file=None, train_lang='en', verbose_logging=False, version_2_with_negative=False, warmup_steps=0, weight_decay=0.0)
05/09/2022 21:41:52 - INFO - __main__ -   Loading checkpoint /cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//squad/xlm-KG_LR8e-6_EPOCH2.0_maxlen384_batchsize4_gradacc4 for evaluation
05/09/2022 21:41:52 - INFO - __main__ -   Evaluate the following checkpoints: ['/cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//squad/xlm-KG_LR8e-6_EPOCH2.0_maxlen384_batchsize4_gradacc4']
Some weights of the model checkpoint at /cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//squad/xlm-KG_LR8e-6_EPOCH2.0_maxlen384_batchsize4_gradacc4 were not used when initializing XLMRobertaModel: ['base_model.encoder.layer.6.attention.self.value.weight', 'base_model.encoder.layer.0.output.LayerNorm.weight', 'base_model.encoder.layer.22.attention.output.LayerNorm.bias', 'base_model.encoder.layer.8.attention.self.value.weight', 'base_model.encoder.layer.19.attention.output.dense.bias', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.22.attention.self.key.bias', 'base_model.encoder.layer.17.attention.self.query.bias', 'base_model.encoder.layer.15.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.9.attention.self.key.bias', 'base_model.encoder.layer.8.attention.self.key.weight', 'base_model.encoder.layer.15.attention.self.query.weight', 'base_model.encoder.layer.4.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.11.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.20.output.LayerNorm.weight', 'base_model.encoder.layer.9.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.13.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.8.output.dense.bias', 'base_model.encoder.layer.3.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.15.attention.self.key.bias', 'base_model.encoder.layer.0.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.22.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.16.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.15.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.16.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.10.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.14.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.10.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.4.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.7.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.1.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.3.attention.output.LayerNorm.bias', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.20.attention.self.value.bias', 'base_model.encoder.layer.13.attention.self.key.weight', 'base_model.encoder.layer.10.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.0.intermediate.dense.bias', 'base_model.encoder.layer.21.attention.output.dense.bias', 'base_model.encoder.layer.16.attention.output.dense.bias', 'base_model.encoder.layer.17.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.2.output.LayerNorm.weight', 'base_model.encoder.layer.15.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.6.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.17.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.9.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.13.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.19.output.dense.bias', 'base_model.encoder.layer.19.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.7.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.22.attention.output.dense.bias', 'base_model.encoder.layer.4.intermediate.dense.bias', 'base_model.encoder.layer.3.attention.self.query.bias', 'base_model.encoder.layer.2.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.10.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.21.intermediate.dense.weight', 'base_model.encoder.layer.5.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.8.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.19.attention.output.LayerNorm.bias', 'base_model.encoder.layer.14.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.17.attention.self.value.weight', 'base_model.encoder.layer.15.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.13.output.LayerNorm.weight', 'base_model.encoder.layer.8.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.23.attention.output.dense.bias', 'base_model.encoder.layer.6.attention.output.dense.bias', 'base_model.encoder.layer.8.attention.self.query.bias', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.5.output.LayerNorm.bias', 'base_model.encoder.layer.0.attention.output.LayerNorm.weight', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.12.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.14.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.22.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.23.output.LayerNorm.weight', 'base_model.encoder.layer.22.intermediate.dense.weight', 'base_model.encoder.layer.17.attention.self.key.bias', 'base_model.encoder.layer.2.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.11.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.22.attention.self.value.bias', 'base_model.encoder.layer.7.attention.output.dense.bias', 'base_model.embeddings.position_ids', 'base_model.encoder.layer.2.attention.output.dense.weight', 'base_model.encoder.layer.11.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.14.attention.output.dense.weight', 'base_model.encoder.layer.14.output.dense.weight', 'base_model.encoder.layer.21.output.LayerNorm.weight', 'base_model.encoder.layer.23.output.LayerNorm.bias', 'base_model.encoder.layer.3.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.6.output.LayerNorm.bias', 'base_model.encoder.layer.21.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.23.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.0.output.LayerNorm.bias', 'base_model.encoder.layer.22.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.14.attention.self.key.bias', 'base_model.encoder.layer.15.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.15.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.12.attention.output.LayerNorm.bias', 'base_model.encoder.layer.1.output.dense.weight', 'base_model.encoder.layer.12.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.20.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.15.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.6.intermediate.dense.bias', 'base_model.encoder.layer.21.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.16.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.8.attention.output.LayerNorm.weight', 'base_model.encoder.layer.12.output.LayerNorm.bias', 'base_model.encoder.layer.9.attention.self.key.weight', 'base_model.encoder.layer.20.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.21.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.19.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.20.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.3.attention.self.key.weight', 'base_model.encoder.layer.19.attention.self.query.weight', 'base_model.encoder.layer.23.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.10.attention.self.value.bias', 'base_model.encoder.layer.0.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.4.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.19.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.23.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.22.output.dense.bias', 'base_model.encoder.layer.13.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.2.attention.self.value.bias', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.17.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.2.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.13.output.LayerNorm.bias', 'base_model.encoder.layer.7.attention.self.query.weight', 'base_model.encoder.layer.11.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.19.attention.self.query.bias', 'base_model.encoder.layer.9.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.19.attention.self.value.weight', 'base_model.encoder.layer.7.attention.self.value.bias', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.21.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.2.attention.output.LayerNorm.weight', 'base_model.encoder.layer.1.output.dense.bias', 'base_model.encoder.layer.16.attention.self.value.bias', 'base_model.encoder.layer.18.attention.output.dense.bias', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.19.intermediate.dense.weight', 'base_model.encoder.layer.12.attention.output.dense.bias', 'base_model.encoder.layer.2.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.3.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.12.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.8.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.18.intermediate.dense.bias', 'base_model.encoder.layer.18.attention.output.dense.weight', 'base_model.encoder.layer.21.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.5.attention.self.query.weight', 'base_model.encoder.layer.13.attention.output.LayerNorm.bias', 'base_model.encoder.layer.0.attention.output.dense.bias', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.17.intermediate.dense.weight', 'base_model.encoder.layer.1.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.2.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.4.attention.self.query.bias', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.10.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.14.output.dense.bias', 'base_model.encoder.layer.22.attention.self.query.weight', 'base_model.encoder.layer.18.attention.self.key.bias', 'base_model.encoder.layer.23.intermediate.dense.bias', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.8.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.14.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.17.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.2.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.23.attention.self.query.bias', 'base_model.encoder.layer.2.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.13.attention.self.value.bias', 'base_model.encoder.layer.4.attention.output.LayerNorm.bias', 'base_model.encoder.layer.3.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.10.attention.self.key.weight', 'base_model.encoder.layer.1.attention.self.value.weight', 'base_model.encoder.layer.2.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.1.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.20.attention.self.value.weight', 'base_model.encoder.layer.0.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.22.output.LayerNorm.weight', 'base_model.encoder.layer.9.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.2.attention.output.LayerNorm.bias', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.22.intermediate.dense.bias', 'base_model.encoder.layer.18.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.7.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.0.attention.self.query.bias', 'base_model.encoder.layer.18.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.5.intermediate.dense.weight', 'base_model.encoder.layer.14.attention.self.query.bias', 'base_model.encoder.layer.1.attention.self.value.bias', 'base_model.encoder.layer.11.attention.output.LayerNorm.bias', 'base_model.encoder.layer.6.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.22.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.16.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.3.output.dense.bias', 'base_model.encoder.layer.6.attention.self.query.bias', 'base_model.encoder.layer.10.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.11.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.3.attention.output.dense.bias', 'base_model.encoder.layer.15.attention.self.value.weight', 'base_model.encoder.layer.19.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.9.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.6.attention.output.LayerNorm.bias', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.21.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.5.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.22.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.10.attention.output.LayerNorm.weight', 'base_model.encoder.layer.17.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.14.attention.self.query.weight', 'base_model.encoder.layer.15.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.14.intermediate.dense.bias', 'base_model.encoder.layer.10.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.7.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.4.attention.self.value.bias', 'base_model.encoder.layer.13.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.4.attention.self.query.weight', 'base_model.encoder.layer.1.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.19.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.23.attention.self.value.weight', 'base_model.encoder.layer.7.output.LayerNorm.bias', 'base_model.encoder.layer.9.attention.self.value.bias', 'base_model.encoder.layer.6.output.dense.bias', 'base_model.encoder.layer.7.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.13.attention.self.query.bias', 'base_model.encoder.layer.10.attention.output.LayerNorm.bias', 'base_model.encoder.layer.14.output.LayerNorm.bias', 'base_model.encoder.layer.5.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.20.intermediate.dense.bias', 'base_model.encoder.layer.7.attention.self.key.bias', 'base_model.encoder.layer.20.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.12.attention.output.dense.weight', 'base_model.encoder.layer.14.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.14.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.5.attention.output.dense.bias', 'base_model.encoder.layer.16.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.19.attention.self.value.bias', 'base_model.encoder.layer.20.attention.self.key.bias', 'base_model.encoder.layer.6.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.11.output.dense.bias', 'base_model.encoder.layer.16.output.LayerNorm.bias', 'base_model.encoder.layer.18.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.21.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.21.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.13.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.19.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.15.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.21.output.dense.weight', 'base_model.encoder.layer.3.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.21.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.6.attention.output.dense.weight', 'base_model.encoder.layer.4.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.2.attention.self.key.bias', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.16.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.4.attention.self.value.weight', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.2.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.13.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.18.output.adapters.tp.adapter_down.0.weight', 'base_model.embeddings.token_type_embeddings.weight', 'base_model.encoder.layer.19.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.3.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.16.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.4.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.5.attention.self.value.weight', 'base_model.encoder.layer.8.attention.output.dense.bias', 'base_model.encoder.layer.11.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.18.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.21.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.12.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.0.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.4.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.1.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.9.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.4.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.21.attention.output.dense.weight', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.2.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.15.attention.self.key.weight', 'base_model.encoder.layer.0.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.8.output.LayerNorm.bias', 'base_model.encoder.layer.14.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.21.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.23.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.12.attention.self.value.bias', 'base_model.encoder.layer.23.attention.self.key.weight', 'base_model.encoder.layer.4.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.16.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.14.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.10.output.dense.bias', 'base_model.encoder.layer.23.attention.output.LayerNorm.weight', 'base_model.encoder.layer.10.attention.self.query.bias', 'base_model.encoder.layer.1.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.12.output.LayerNorm.weight', 'base_model.encoder.layer.19.output.dense.weight', 'base_model.encoder.layer.0.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.6.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.6.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.13.attention.self.key.bias', 'base_model.encoder.layer.21.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.7.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.20.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.2.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.3.attention.output.LayerNorm.weight', 'base_model.encoder.layer.11.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.11.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.11.intermediate.dense.bias', 'base_model.encoder.layer.17.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.20.attention.self.key.weight', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.8.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.8.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.2.intermediate.dense.weight', 'base_model.encoder.layer.17.attention.self.query.weight', 'base_model.encoder.layer.19.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.18.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.12.output.dense.weight', 'base_model.encoder.layer.9.output.dense.weight', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.8.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.4.output.dense.bias', 'base_model.encoder.layer.12.output.dense.bias', 'base_model.encoder.layer.14.attention.self.key.weight', 'base_model.encoder.layer.23.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.12.attention.self.query.bias', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.22.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.16.intermediate.dense.bias', 'base_model.encoder.layer.0.attention.self.key.bias', 'base_model.encoder.layer.7.attention.self.key.weight', 'base_model.encoder.layer.0.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.4.attention.output.dense.weight', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.7.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.7.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.17.attention.output.dense.weight', 'base_model.encoder.layer.2.attention.self.value.weight', 'base_model.encoder.layer.12.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.1.output.LayerNorm.bias', 'base_model.encoder.layer.10.attention.self.query.weight', 'base_model.encoder.layer.5.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.16.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.22.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.20.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.23.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.5.attention.output.dense.weight', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.2.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.9.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.16.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.14.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.15.output.dense.bias', 'base_model.encoder.layer.3.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.4.intermediate.dense.weight', 'base_model.encoder.layer.10.output.LayerNorm.bias', 'base_model.pooler.dense.weight', 'base_model.encoder.layer.15.output.LayerNorm.weight', 'base_model.pooler.dense.bias', 'base_model.encoder.layer.2.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.11.attention.self.key.weight', 'base_model.encoder.layer.17.attention.output.dense.bias', 'base_model.encoder.layer.7.output.LayerNorm.weight', 'base_model.encoder.layer.21.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.21.attention.self.key.weight', 'base_model.encoder.layer.21.attention.self.value.weight', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.10.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.0.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.20.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.0.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.20.attention.output.dense.bias', 'base_model.encoder.layer.14.attention.self.value.weight', 'base_model.encoder.layer.16.output.dense.weight', 'base_model.encoder.layer.3.attention.self.query.weight', 'base_model.encoder.layer.3.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.7.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.19.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.2.intermediate.dense.bias', 'base_model.encoder.layer.2.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.15.attention.output.dense.weight', 'base_model.encoder.layer.12.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.10.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.19.output.LayerNorm.bias', 'base_model.encoder.layer.0.attention.self.key.weight', 'base_model.encoder.layer.12.intermediate.dense.weight', 'base_model.encoder.layer.18.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.4.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.5.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.23.attention.self.key.bias', 'base_model.encoder.layer.6.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.18.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.0.attention.self.value.weight', 'base_model.encoder.layer.13.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.12.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.8.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.0.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.16.output.dense.bias', 'base_model.encoder.layer.18.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.19.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.23.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.9.attention.output.LayerNorm.weight', 'base_model.encoder.layer.11.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.23.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.17.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.21.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.14.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.11.attention.self.value.bias', 'base_model.encoder.layer.5.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.15.attention.output.LayerNorm.weight', 'base_model.encoder.layer.22.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.9.output.dense.bias', 'base_model.encoder.layer.11.attention.output.dense.weight', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.7.attention.output.dense.weight', 'base_model.encoder.layer.4.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.23.attention.self.query.weight', 'base_model.encoder.layer.5.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.22.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.13.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.16.attention.self.query.weight', 'base_model.encoder.layer.22.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.2.output.dense.weight', 'base_model.encoder.layer.5.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.21.intermediate.dense.bias', 'base_model.encoder.layer.3.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.19.attention.output.LayerNorm.weight', 'base_model.encoder.layer.3.intermediate.dense.weight', 'base_model.encoder.layer.3.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.1.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.6.attention.output.LayerNorm.weight', 'base_model.encoder.layer.10.intermediate.dense.weight', 'base_model.encoder.layer.8.attention.self.value.bias', 'base_model.encoder.layer.4.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.6.output.LayerNorm.weight', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.3.output.LayerNorm.weight', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.5.attention.self.query.bias', 'base_model.encoder.layer.3.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.1.attention.output.dense.bias', 'base_model.encoder.layer.11.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.5.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.0.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.19.output.LayerNorm.weight', 'base_model.encoder.layer.22.attention.self.key.weight', 'base_model.encoder.layer.13.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.9.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.16.output.LayerNorm.weight', 'base_model.encoder.layer.5.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.15.attention.self.value.bias', 'base_model.encoder.layer.7.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.5.output.dense.weight', 'base_model.encoder.layer.22.attention.self.value.weight', 'base_model.encoder.layer.0.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.5.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.23.output.dense.weight', 'base_model.encoder.layer.14.attention.output.LayerNorm.weight', 'base_model.encoder.layer.7.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.21.output.dense.bias', 'base_model.encoder.layer.15.intermediate.dense.weight', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.1.attention.output.LayerNorm.bias', 'base_model.encoder.layer.10.intermediate.dense.bias', 'base_model.encoder.layer.13.attention.self.value.weight', 'base_model.encoder.layer.13.attention.output.dense.weight', 'base_model.encoder.layer.8.attention.output.LayerNorm.bias', 'base_model.encoder.layer.10.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.3.output.dense.weight', 'base_model.encoder.layer.18.output.LayerNorm.bias', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.5.attention.self.value.bias', 'base_model.encoder.layer.18.output.dense.weight', 'base_model.encoder.layer.23.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.11.attention.self.query.weight', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.13.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.2.attention.output.dense.bias', 'base_model.encoder.layer.18.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.21.attention.self.key.bias', 'base_model.encoder.layer.7.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.9.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.20.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.23.attention.output.dense.weight', 'base_model.encoder.layer.14.output.LayerNorm.weight', 'base_model.encoder.layer.15.attention.output.dense.bias', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.18.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.22.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.9.attention.self.query.bias', 'base_model.encoder.layer.13.attention.output.dense.bias', 'base_model.encoder.layer.11.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.12.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.1.attention.output.dense.weight', 'base_model.encoder.layer.4.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.6.output.dense.weight', 'base_model.encoder.layer.20.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.20.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.9.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.17.attention.self.key.weight', 'base_model.encoder.layer.22.attention.output.LayerNorm.weight', 'base_model.encoder.layer.5.intermediate.dense.bias', 'base_model.encoder.layer.21.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.16.attention.self.value.weight', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.14.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.17.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.17.attention.output.LayerNorm.bias', 'base_model.encoder.layer.7.output.dense.weight', 'base_model.encoder.layer.19.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.9.attention.output.dense.weight', 'base_model.encoder.layer.14.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.17.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.13.output.adapters.es.adapter_down.0.weight', 'base_model.embeddings.LayerNorm.weight', 'base_model.encoder.layer.14.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.9.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.20.attention.output.LayerNorm.bias', 'base_model.encoder.layer.22.output.LayerNorm.bias', 'base_model.encoder.layer.23.attention.output.LayerNorm.bias', 'base_model.encoder.layer.13.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.3.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.15.attention.output.LayerNorm.bias', 'base_model.encoder.layer.8.output.LayerNorm.weight', 'base_model.encoder.layer.3.intermediate.dense.bias', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.12.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.9.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.6.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.7.intermediate.dense.bias', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.21.attention.output.LayerNorm.bias', 'base_model.encoder.layer.0.output.dense.weight', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.16.attention.self.key.weight', 'base_model.encoder.layer.9.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.15.attention.self.query.bias', 'base_model.encoder.layer.18.attention.self.value.weight', 'base_model.encoder.layer.23.attention.self.value.bias', 'base_model.encoder.layer.9.attention.self.query.weight', 'base_model.encoder.layer.18.attention.output.LayerNorm.weight', 'base_model.encoder.layer.17.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.5.attention.output.LayerNorm.bias', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.4.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.8.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.21.attention.self.query.bias', 'base_model.encoder.layer.12.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.17.attention.output.LayerNorm.weight', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.9.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.17.output.LayerNorm.bias', 'base_model.encoder.layer.20.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.1.attention.output.LayerNorm.weight', 'base_model.encoder.layer.21.attention.self.value.bias', 'base_model.encoder.layer.16.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.11.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.4.attention.self.key.bias', 'base_model.encoder.layer.2.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.6.intermediate.dense.weight', 'base_model.encoder.layer.9.intermediate.dense.weight', 'base_model.encoder.layer.0.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.14.intermediate.dense.weight', 'base_model.encoder.layer.8.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.13.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.19.attention.self.key.bias', 'base_model.encoder.layer.18.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.18.attention.self.query.weight', 'base_model.encoder.layer.12.attention.self.key.bias', 'base_model.encoder.layer.6.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.18.attention.self.query.bias', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.11.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.22.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.14.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.4.output.LayerNorm.bias', 'base_model.encoder.layer.7.intermediate.dense.weight', 'base_model.encoder.layer.19.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.8.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.0.attention.self.query.weight', 'base_model.encoder.layer.9.output.LayerNorm.bias', 'base_model.encoder.layer.1.attention.self.query.weight', 'base_model.encoder.layer.5.output.dense.bias', 'base_model.encoder.layer.19.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.17.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.7.output.dense.bias', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.19.intermediate.dense.bias', 'base_model.encoder.layer.5.attention.self.key.bias', 'base_model.encoder.layer.16.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.10.attention.self.value.weight', 'base_model.encoder.layer.23.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.3.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.23.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.19.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.5.output.LayerNorm.weight', 'base_model.encoder.layer.11.attention.output.LayerNorm.weight', 'base_model.encoder.layer.17.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.12.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.6.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.22.output.dense.weight', 'base_model.encoder.layer.20.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.4.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.8.output.dense.weight', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.18.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.2.attention.self.key.weight', 'base_model.encoder.layer.0.attention.output.LayerNorm.bias', 'base_model.encoder.layer.19.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.21.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.9.attention.output.dense.bias', 'base_model.encoder.layer.1.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.7.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.12.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.18.output.LayerNorm.weight', 'base_model.encoder.layer.15.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.16.attention.output.dense.weight', 'base_model.encoder.layer.13.output.dense.weight', 'base_model.encoder.layer.12.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.20.attention.self.query.weight', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.16.attention.output.LayerNorm.weight', 'base_model.encoder.layer.23.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.11.attention.self.key.bias', 'base_model.encoder.layer.19.attention.self.key.weight', 'base_model.encoder.layer.11.output.LayerNorm.weight', 'base_model.encoder.layer.6.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.10.output.dense.weight', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.22.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.20.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.15.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.2.output.LayerNorm.bias', 'base_model.encoder.layer.22.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.17.attention.self.value.bias', 'base_model.encoder.layer.23.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.11.attention.self.value.weight', 'base_model.encoder.layer.16.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.22.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.17.output.dense.bias', 'base_model.encoder.layer.9.attention.self.value.weight', 'base_model.encoder.layer.1.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.5.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.11.output.LayerNorm.bias', 'base_model.encoder.layer.13.intermediate.dense.bias', 'base_model.encoder.layer.15.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.2.output.dense.bias', 'base_model.encoder.layer.18.attention.self.value.bias', 'base_model.encoder.layer.3.attention.self.key.bias', 'base_model.encoder.layer.23.output.dense.bias', 'base_model.encoder.layer.23.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.20.attention.output.LayerNorm.weight', 'base_model.encoder.layer.10.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.1.attention.self.key.bias', 'base_model.encoder.layer.16.attention.output.LayerNorm.bias', 'base_model.encoder.layer.7.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.12.attention.output.LayerNorm.weight', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.10.attention.self.key.bias', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.13.attention.output.LayerNorm.weight', 'base_model.encoder.layer.0.attention.self.value.bias', 'base_model.encoder.layer.13.intermediate.dense.weight', 'base_model.encoder.layer.14.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.21.output.LayerNorm.bias', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.1.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.23.intermediate.dense.weight', 'base_model.encoder.layer.13.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.12.attention.self.query.weight', 'base_model.encoder.layer.8.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.4.output.dense.weight', 'base_model.encoder.layer.18.attention.output.LayerNorm.bias', 'base_model.encoder.layer.0.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.9.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.10.attention.output.dense.bias', 'base_model.encoder.layer.17.output.LayerNorm.weight', 'base_model.encoder.layer.16.attention.self.key.bias', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.6.attention.self.query.weight', 'base_model.encoder.layer.9.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.11.attention.output.dense.bias', 'base_model.encoder.layer.4.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.1.attention.self.query.bias', 'base_model.encoder.layer.20.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.8.attention.self.key.bias', 'base_model.encoder.layer.15.output.dense.weight', 'base_model.encoder.layer.18.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.20.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.20.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.15.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.0.intermediate.dense.weight', 'base_model.encoder.layer.3.attention.self.value.bias', 'qa_outputs.weight', 'base_model.encoder.layer.21.attention.self.query.weight', 'base_model.encoder.layer.8.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.0.attention.output.dense.weight', 'base_model.encoder.layer.3.output.LayerNorm.bias', 'base_model.encoder.layer.8.intermediate.dense.weight', 'base_model.encoder.layer.17.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.3.attention.output.dense.weight', 'base_model.encoder.layer.8.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.6.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.0.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.10.output.adapters.tp.adapter_up.weight', 'base_model.embeddings.word_embeddings.weight', 'base_model.encoder.layer.3.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.22.attention.self.query.bias', 'base_model.encoder.layer.7.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.23.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.20.output.dense.weight', 'base_model.encoder.layer.10.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.6.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.23.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.2.attention.self.query.bias', 'base_model.encoder.layer.10.output.LayerNorm.weight', 'base_model.encoder.layer.9.output.LayerNorm.weight', 'base_model.encoder.layer.1.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.5.attention.self.key.weight', 'base_model.encoder.layer.11.output.dense.weight', 'base_model.encoder.layer.5.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.1.output.LayerNorm.weight', 'base_model.encoder.layer.7.attention.self.query.bias', 'base_model.encoder.layer.3.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.16.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.20.output.dense.bias', 'base_model.encoder.layer.8.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.12.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.4.attention.output.LayerNorm.weight', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.21.attention.output.LayerNorm.weight', 'base_model.encoder.layer.4.output.LayerNorm.weight', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.4.attention.self.key.weight', 'base_model.encoder.layer.4.attention.output.dense.bias', 'base_model.encoder.layer.0.output.dense.bias', 'base_model.encoder.layer.12.attention.self.key.weight', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.7.attention.output.LayerNorm.weight', 'base_model.encoder.layer.11.intermediate.dense.weight', 'base_model.encoder.layer.15.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.5.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.14.attention.output.LayerNorm.bias', 'base_model.encoder.layer.2.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.16.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.7.attention.output.LayerNorm.bias', 'base_model.encoder.layer.17.output.dense.weight', 'base_model.encoder.layer.10.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.15.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.5.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.16.attention.self.query.bias', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.18.attention.self.key.weight', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.1.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.7.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.15.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.1.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.11.attention.self.query.bias', 'base_model.encoder.layer.20.attention.self.query.bias', 'base_model.embeddings.position_embeddings.weight', 'base_model.encoder.layer.6.attention.self.key.bias', 'base_model.encoder.layer.6.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.8.intermediate.dense.bias', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.18.intermediate.dense.weight', 'base_model.encoder.layer.22.attention.output.dense.weight', 'base_model.encoder.layer.1.intermediate.dense.weight', 'base_model.encoder.layer.22.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.12.intermediate.dense.bias', 'base_model.encoder.layer.14.attention.self.value.bias', 'base_model.encoder.layer.7.attention.self.value.weight', 'base_model.embeddings.LayerNorm.bias', 'base_model.encoder.layer.12.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.6.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.5.attention.output.LayerNorm.weight', 'base_model.encoder.layer.19.attention.output.dense.weight', 'base_model.encoder.layer.3.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.14.attention.output.dense.bias', 'base_model.encoder.layer.1.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.13.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.18.output.dense.bias', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.1.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.9.attention.output.LayerNorm.bias', 'base_model.encoder.layer.2.attention.self.query.weight', 'base_model.encoder.layer.13.attention.self.query.weight', 'base_model.encoder.layer.6.attention.self.key.weight', 'base_model.encoder.layer.16.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.8.attention.output.dense.weight', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.8.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.20.attention.output.dense.weight', 'qa_outputs.bias', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.10.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.10.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.14.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.13.output.dense.bias', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.1.intermediate.dense.bias', 'base_model.encoder.layer.12.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.17.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.18.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.16.intermediate.dense.weight', 'base_model.encoder.layer.0.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.11.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.12.attention.self.value.weight', 'base_model.encoder.layer.6.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.19.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.15.intermediate.dense.bias', 'base_model.encoder.layer.11.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.3.attention.self.value.weight', 'base_model.encoder.layer.17.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.5.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.15.output.LayerNorm.bias', 'base_model.encoder.layer.13.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.6.attention.self.value.bias', 'base_model.encoder.layer.6.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.17.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.1.attention.self.key.weight', 'base_model.encoder.layer.20.intermediate.dense.weight', 'base_model.encoder.layer.11.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.20.output.LayerNorm.bias', 'base_model.encoder.layer.18.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.8.attention.self.query.weight', 'base_model.encoder.layer.9.intermediate.dense.bias', 'base_model.encoder.layer.4.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.10.attention.output.dense.weight', 'base_model.encoder.layer.1.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.17.intermediate.dense.bias']
- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of XLMRobertaModel were not initialized from the model checkpoint at /cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//squad/xlm-KG_LR8e-6_EPOCH2.0_maxlen384_batchsize4_gradacc4 and are newly initialized: ['encoder.layer.22.output.dense.weight', 'encoder.layer.3.attention.self.value.weight', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.16.intermediate.dense.weight', 'encoder.layer.14.attention.self.value.bias', 'encoder.layer.5.attention.self.value.bias', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.12.attention.output.dense.bias', 'encoder.layer.23.attention.self.query.bias', 'encoder.layer.3.attention.output.dense.weight', 'encoder.layer.9.output.LayerNorm.bias', 'encoder.layer.14.intermediate.dense.bias', 'encoder.layer.6.output.dense.bias', 'encoder.layer.23.attention.self.key.bias', 'encoder.layer.13.attention.self.value.bias', 'encoder.layer.7.intermediate.dense.bias', 'encoder.layer.23.attention.self.value.bias', 'encoder.layer.23.attention.output.dense.weight', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.14.output.dense.bias', 'encoder.layer.12.output.LayerNorm.weight', 'encoder.layer.23.output.LayerNorm.weight', 'encoder.layer.18.attention.output.LayerNorm.weight', 'encoder.layer.11.attention.self.query.weight', 'encoder.layer.6.output.LayerNorm.bias', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.6.attention.self.value.bias', 'encoder.layer.14.attention.output.dense.bias', 'encoder.layer.17.attention.self.query.bias', 'encoder.layer.10.attention.output.dense.bias', 'encoder.layer.11.attention.self.query.bias', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.23.attention.output.dense.bias', 'encoder.layer.23.attention.self.value.weight', 'encoder.layer.4.output.dense.weight', 'encoder.layer.8.attention.self.query.weight', 'encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.layer.2.attention.self.value.weight', 'encoder.layer.9.output.dense.bias', 'encoder.layer.21.attention.self.query.weight', 'encoder.layer.15.output.dense.bias', 'encoder.layer.14.attention.self.value.weight', 'encoder.layer.12.attention.self.key.bias', 'encoder.layer.13.output.LayerNorm.bias', 'encoder.layer.4.attention.output.dense.bias', 'encoder.layer.17.attention.self.key.bias', 'encoder.layer.4.attention.output.LayerNorm.weight', 'encoder.layer.17.intermediate.dense.bias', 'encoder.layer.10.output.LayerNorm.bias', 'encoder.layer.11.output.dense.weight', 'encoder.layer.9.output.LayerNorm.weight', 'encoder.layer.18.attention.self.key.weight', 'encoder.layer.16.attention.output.LayerNorm.weight', 'encoder.layer.10.output.dense.bias', 'encoder.layer.21.output.dense.bias', 'encoder.layer.2.output.dense.bias', 'encoder.layer.21.attention.output.LayerNorm.weight', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.13.attention.output.LayerNorm.bias', 'encoder.layer.17.attention.output.dense.bias', 'encoder.layer.17.attention.self.value.weight', 'encoder.layer.12.attention.output.dense.weight', 'encoder.layer.17.intermediate.dense.weight', 'encoder.layer.2.attention.self.query.weight', 'encoder.layer.19.attention.self.query.bias', 'encoder.layer.12.attention.self.query.weight', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.12.output.dense.weight', 'encoder.layer.18.attention.self.key.bias', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.14.attention.self.key.weight', 'encoder.layer.18.output.dense.weight', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.10.attention.self.key.weight', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.15.attention.output.dense.bias', 'encoder.layer.2.attention.self.key.weight', 'encoder.layer.23.output.LayerNorm.bias', 'encoder.layer.15.output.LayerNorm.bias', 'encoder.layer.16.output.dense.weight', 'encoder.layer.16.attention.self.query.bias', 'encoder.layer.16.attention.self.query.weight', 'encoder.layer.7.attention.output.dense.weight', 'encoder.layer.16.attention.output.LayerNorm.bias', 'encoder.layer.7.attention.self.value.bias', 'encoder.layer.12.attention.output.LayerNorm.weight', 'encoder.layer.0.intermediate.dense.weight', 'embeddings.position_embeddings.weight', 'encoder.layer.14.output.LayerNorm.weight', 'embeddings.LayerNorm.weight', 'encoder.layer.0.attention.output.LayerNorm.weight', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.1.attention.output.dense.bias', 'encoder.layer.18.attention.output.LayerNorm.bias', 'encoder.layer.12.attention.self.value.weight', 'encoder.layer.22.attention.output.dense.weight', 'encoder.layer.8.attention.output.LayerNorm.bias', 'encoder.layer.21.output.LayerNorm.weight', 'encoder.layer.7.attention.self.key.bias', 'encoder.layer.22.output.LayerNorm.bias', 'encoder.layer.19.output.dense.weight', 'encoder.layer.5.attention.self.query.bias', 'encoder.layer.15.attention.output.LayerNorm.weight', 'encoder.layer.1.output.dense.bias', 'encoder.layer.15.attention.self.value.weight', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.10.attention.self.value.bias', 'encoder.layer.0.output.dense.weight', 'encoder.layer.22.attention.output.LayerNorm.bias', 'encoder.layer.20.attention.self.value.weight', 'encoder.layer.19.attention.output.LayerNorm.bias', 'encoder.layer.3.attention.self.key.bias', 'encoder.layer.12.intermediate.dense.bias', 'encoder.layer.1.attention.self.key.bias', 'encoder.layer.16.output.LayerNorm.weight', 'encoder.layer.13.attention.self.key.bias', 'encoder.layer.6.attention.self.value.weight', 'encoder.layer.4.attention.output.dense.weight', 'encoder.layer.1.attention.output.dense.weight', 'encoder.layer.15.attention.output.dense.weight', 'encoder.layer.20.attention.output.dense.weight', 'encoder.layer.6.attention.self.key.bias', 'encoder.layer.11.attention.self.value.bias', 'encoder.layer.19.output.LayerNorm.weight', 'encoder.layer.23.attention.output.LayerNorm.bias', 'encoder.layer.5.attention.output.dense.weight', 'encoder.layer.13.attention.self.key.weight', 'encoder.layer.10.output.LayerNorm.weight', 'encoder.layer.18.attention.self.query.weight', 'encoder.layer.18.output.LayerNorm.bias', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.22.intermediate.dense.bias', 'encoder.layer.6.attention.output.dense.weight', 'encoder.layer.22.output.dense.bias', 'encoder.layer.2.attention.output.LayerNorm.bias', 'encoder.layer.18.attention.output.dense.weight', 'encoder.layer.23.attention.output.LayerNorm.weight', 'encoder.layer.13.attention.self.query.weight', 'encoder.layer.5.attention.self.key.weight', 'encoder.layer.22.attention.self.key.bias', 'encoder.layer.13.attention.self.value.weight', 'encoder.layer.5.output.dense.weight', 'encoder.layer.13.output.dense.bias', 'encoder.layer.21.attention.self.value.bias', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.19.attention.output.LayerNorm.weight', 'encoder.layer.22.attention.self.key.weight', 'encoder.layer.9.attention.self.key.weight', 'encoder.layer.21.attention.self.key.weight', 'encoder.layer.18.intermediate.dense.bias', 'encoder.layer.23.attention.self.key.weight', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.3.attention.self.query.bias', 'encoder.layer.12.attention.output.LayerNorm.bias', 'encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.6.attention.self.query.weight', 'encoder.layer.9.attention.self.query.bias', 'embeddings.word_embeddings.weight', 'encoder.layer.21.intermediate.dense.bias', 'encoder.layer.3.attention.output.dense.bias', 'encoder.layer.1.attention.output.LayerNorm.weight', 'encoder.layer.20.attention.self.value.bias', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.7.attention.output.LayerNorm.bias', 'encoder.layer.6.attention.output.dense.bias', 'encoder.layer.19.intermediate.dense.bias', 'encoder.layer.12.output.LayerNorm.bias', 'encoder.layer.22.attention.self.value.bias', 'encoder.layer.16.attention.output.dense.weight', 'encoder.layer.20.attention.output.LayerNorm.bias', 'encoder.layer.7.attention.self.query.bias', 'encoder.layer.23.output.dense.bias', 'encoder.layer.14.output.LayerNorm.bias', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.20.output.dense.bias', 'encoder.layer.0.attention.self.query.bias', 'encoder.layer.16.attention.output.dense.bias', 'encoder.layer.10.attention.self.value.weight', 'encoder.layer.15.intermediate.dense.weight', 'encoder.layer.22.attention.self.query.weight', 'encoder.layer.21.attention.self.query.bias', 'encoder.layer.13.attention.self.query.bias', 'encoder.layer.3.attention.self.value.bias', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.0.output.dense.bias', 'encoder.layer.10.attention.output.LayerNorm.bias', 'encoder.layer.4.attention.self.query.bias', 'encoder.layer.8.attention.output.LayerNorm.weight', 'encoder.layer.8.output.LayerNorm.weight', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.19.attention.self.value.bias', 'encoder.layer.18.attention.self.value.weight', 'encoder.layer.9.attention.self.key.bias', 'encoder.layer.20.attention.self.query.weight', 'encoder.layer.15.output.dense.weight', 'encoder.layer.20.output.LayerNorm.weight', 'encoder.layer.0.attention.self.key.weight', 'embeddings.token_type_embeddings.weight', 'encoder.layer.1.output.dense.weight', 'encoder.layer.20.output.LayerNorm.bias', 'encoder.layer.1.attention.self.key.weight', 'encoder.layer.21.attention.self.key.bias', 'encoder.layer.9.attention.output.dense.bias', 'encoder.layer.9.attention.output.dense.weight', 'encoder.layer.16.attention.self.key.weight', 'encoder.layer.5.attention.self.query.weight', 'encoder.layer.21.intermediate.dense.weight', 'encoder.layer.0.attention.self.query.weight', 'encoder.layer.15.attention.self.query.bias', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.0.attention.output.dense.bias', 'encoder.layer.14.intermediate.dense.weight', 'encoder.layer.10.attention.output.LayerNorm.weight', 'encoder.layer.11.output.LayerNorm.bias', 'encoder.layer.5.attention.self.value.weight', 'encoder.layer.19.output.LayerNorm.bias', 'encoder.layer.15.attention.output.LayerNorm.bias', 'encoder.layer.23.output.dense.weight', 'encoder.layer.20.attention.output.LayerNorm.weight', 'encoder.layer.17.attention.output.dense.weight', 'encoder.layer.19.attention.self.query.weight', 'encoder.layer.2.attention.self.value.bias', 'encoder.layer.20.attention.output.dense.bias', 'encoder.layer.8.attention.output.dense.weight', 'encoder.layer.5.attention.output.dense.bias', 'encoder.layer.1.attention.self.value.bias', 'encoder.layer.17.attention.self.query.weight', 'pooler.dense.bias', 'encoder.layer.22.attention.self.query.bias', 'encoder.layer.19.attention.self.key.weight', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.17.attention.output.LayerNorm.weight', 'encoder.layer.6.attention.output.LayerNorm.bias', 'encoder.layer.18.intermediate.dense.weight', 'encoder.layer.13.attention.output.dense.bias', 'encoder.layer.22.attention.output.dense.bias', 'encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.layer.0.attention.self.value.bias', 'encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.layer.11.attention.output.LayerNorm.weight', 'encoder.layer.11.output.dense.bias', 'encoder.layer.9.attention.self.value.weight', 'encoder.layer.9.attention.self.query.weight', 'encoder.layer.2.attention.self.key.bias', 'encoder.layer.23.intermediate.dense.weight', 'encoder.layer.4.attention.self.value.bias', 'encoder.layer.12.attention.self.value.bias', 'encoder.layer.16.intermediate.dense.bias', 'encoder.layer.18.attention.self.query.bias', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.2.output.dense.weight', 'encoder.layer.3.attention.self.key.weight', 'encoder.layer.11.attention.output.dense.bias', 'encoder.layer.4.attention.output.LayerNorm.bias', 'encoder.layer.19.attention.output.dense.weight', 'encoder.layer.8.output.LayerNorm.bias', 'encoder.layer.17.attention.self.key.weight', 'encoder.layer.13.intermediate.dense.weight', 'encoder.layer.15.attention.self.key.bias', 'encoder.layer.10.intermediate.dense.weight', 'encoder.layer.1.attention.self.query.weight', 'encoder.layer.20.output.dense.weight', 'encoder.layer.7.attention.self.value.weight', 'encoder.layer.10.attention.output.dense.weight', 'encoder.layer.20.intermediate.dense.weight', 'encoder.layer.10.output.dense.weight', 'encoder.layer.16.output.dense.bias', 'encoder.layer.17.output.LayerNorm.bias', 'encoder.layer.8.attention.self.key.weight', 'encoder.layer.15.intermediate.dense.bias', 'encoder.layer.8.attention.output.dense.bias', 'encoder.layer.9.attention.output.LayerNorm.weight', 'encoder.layer.21.attention.output.LayerNorm.bias', 'encoder.layer.21.output.dense.weight', 'encoder.layer.7.output.dense.bias', 'encoder.layer.3.attention.self.query.weight', 'encoder.layer.15.attention.self.query.weight', 'encoder.layer.17.output.LayerNorm.weight', 'encoder.layer.20.intermediate.dense.bias', 'encoder.layer.6.attention.self.query.bias', 'encoder.layer.1.attention.self.value.weight', 'encoder.layer.12.intermediate.dense.weight', 'encoder.layer.0.attention.output.dense.weight', 'encoder.layer.13.output.LayerNorm.weight', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.14.attention.self.key.bias', 'encoder.layer.20.attention.self.query.bias', 'encoder.layer.14.attention.self.query.bias', 'encoder.layer.13.output.dense.weight', 'encoder.layer.18.attention.output.dense.bias', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.3.output.dense.bias', 'encoder.layer.13.attention.output.LayerNorm.weight', 'encoder.layer.19.attention.output.dense.bias', 'encoder.layer.5.attention.output.LayerNorm.weight', 'encoder.layer.8.attention.self.value.bias', 'encoder.layer.18.attention.self.value.bias', 'encoder.layer.10.attention.self.key.bias', 'encoder.layer.19.intermediate.dense.weight', 'encoder.layer.2.attention.output.dense.weight', 'encoder.layer.6.output.dense.weight', 'encoder.layer.11.attention.self.value.weight', 'encoder.layer.16.output.LayerNorm.bias', 'encoder.layer.15.output.LayerNorm.weight', 'encoder.layer.6.attention.self.key.weight', 'encoder.layer.12.output.dense.bias', 'encoder.layer.20.attention.self.key.bias', 'encoder.layer.9.output.dense.weight', 'encoder.layer.17.output.dense.bias', 'encoder.layer.4.attention.self.key.weight', 'encoder.layer.17.output.dense.weight', 'encoder.layer.20.attention.self.key.weight', 'encoder.layer.4.attention.self.query.weight', 'embeddings.LayerNorm.bias', 'encoder.layer.11.attention.output.dense.weight', 'encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.22.attention.self.value.weight', 'encoder.layer.13.attention.output.dense.weight', 'encoder.layer.9.attention.output.LayerNorm.bias', 'encoder.layer.0.attention.self.key.bias', 'encoder.layer.12.attention.self.key.weight', 'encoder.layer.23.intermediate.dense.bias', 'encoder.layer.22.attention.output.LayerNorm.weight', 'encoder.layer.19.output.dense.bias', 'encoder.layer.17.attention.output.LayerNorm.bias', 'encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.layer.13.intermediate.dense.bias', 'encoder.layer.14.attention.output.LayerNorm.bias', 'encoder.layer.21.output.LayerNorm.bias', 'encoder.layer.15.attention.self.value.bias', 'encoder.layer.10.attention.self.query.weight', 'encoder.layer.7.output.LayerNorm.bias', 'encoder.layer.23.attention.self.query.weight', 'encoder.layer.0.attention.self.value.weight', 'encoder.layer.7.attention.output.dense.bias', 'encoder.layer.19.attention.self.key.bias', 'encoder.layer.16.attention.self.value.weight', 'encoder.layer.11.output.LayerNorm.weight', 'encoder.layer.21.attention.output.dense.weight', 'encoder.layer.4.attention.self.key.bias', 'encoder.layer.7.attention.self.query.weight', 'encoder.layer.14.output.dense.weight', 'encoder.layer.5.attention.self.key.bias', 'encoder.layer.8.attention.self.query.bias', 'encoder.layer.6.attention.output.LayerNorm.weight', 'encoder.layer.22.output.LayerNorm.weight', 'encoder.layer.4.output.dense.bias', 'encoder.layer.11.attention.self.key.bias', 'encoder.layer.12.attention.self.query.bias', 'encoder.layer.16.attention.self.key.bias', 'encoder.layer.19.attention.self.value.weight', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.14.attention.output.dense.weight', 'encoder.layer.15.attention.self.key.weight', 'encoder.layer.11.attention.self.key.weight', 'pooler.dense.weight', 'encoder.layer.8.output.dense.weight', 'encoder.layer.7.attention.self.key.weight', 'encoder.layer.8.output.dense.bias', 'encoder.layer.7.output.LayerNorm.weight', 'encoder.layer.18.output.LayerNorm.weight', 'encoder.layer.16.attention.self.value.bias', 'encoder.layer.21.attention.output.dense.bias', 'encoder.layer.8.attention.self.key.bias', 'encoder.layer.18.output.dense.bias', 'encoder.layer.2.attention.self.query.bias', 'encoder.layer.7.output.dense.weight', 'encoder.layer.2.attention.output.dense.bias', 'encoder.layer.4.attention.self.value.weight', 'encoder.layer.21.attention.self.value.weight', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.22.intermediate.dense.weight', 'encoder.layer.5.output.LayerNorm.bias', 'encoder.layer.9.attention.self.value.bias', 'encoder.layer.3.output.dense.weight', 'encoder.layer.14.attention.self.query.weight', 'encoder.layer.7.attention.output.LayerNorm.weight', 'encoder.layer.17.attention.self.value.bias', 'encoder.layer.8.attention.self.value.weight', 'encoder.layer.5.output.dense.bias', 'encoder.layer.10.attention.self.query.bias', 'encoder.layer.14.attention.output.LayerNorm.weight', 'encoder.layer.1.attention.self.query.bias', 'encoder.layer.2.attention.output.LayerNorm.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Overwriting existing adapter 'ep'.
Overwriting existing adapter 'tp'.
Overwriting existing adapter 'es'.
Overwriting existing adapter 'ts'.
Overwriting existing adapter fusion module 'ep,tp,es,ts'
/cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//squad/xlm-KG_LR8e-6_EPOCH2.0_maxlen384_batchsize4_gradacc4
XLMConfig {
  "architectures": [
    "XLMRobertaForMaskedLM"
  ],
  "asm": false,
  "attention_dropout": 0.1,
  "attention_probs_dropout_prob": 0.1,
  "bos_index": 0,
  "bos_token_id": 0,
  "causal": false,
  "dropout": 0.1,
  "emb_dim": 1024,
  "embed_init_std": 0.02209708691207961,
  "end_n_top": 5,
  "eos_index": 1,
  "eos_token_id": 2,
  "gelu_activation": true,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "init_std": 0.02,
  "initializer_range": 0.02,
  "intermediate_size": 4096,
  "is_encoder": true,
  "lang_id": 0,
  "layer_norm_eps": 1e-05,
  "mask_index": 5,
  "mask_token_id": 0,
  "max_position_embeddings": 514,
  "model_type": "xlm",
  "n_heads": 16,
  "n_langs": 1,
  "n_layers": 24,
  "output_past": true,
  "pad_index": 2,
  "pad_token_id": 1,
  "sinusoidal_embeddings": false,
  "start_n_top": 5,
  "summary_activation": null,
  "summary_first_dropout": 0.1,
  "summary_proj_to_labels": true,
  "summary_type": "first",
  "summary_use_proj": true,
  "transformers_version": "4.17.0",
  "type_vocab_size": 1,
  "unk_index": 3,
  "use_lang_emb": false,
  "vocab_size": 250002
}

Traceback (most recent call last):
  File "third_party/run_squad.py", line 958, in <module>
    main()
  File "third_party/run_squad.py", line 941, in main
    load_model(model, os.path.join(args.output_dir, "pytorch_model.bin"))
  File "third_party/run_squad.py", line 98, in load_model
    model.load_state_dict(torch.load(path, map_location='cpu'), strict=False)
  File "/cluster/project/sachan/yifan/softwares/anaconda/anaconda3/envs/xfactr/lib/python3.8/site-packages/torch/serialization.py", line 581, in load
    with _open_file_like(f, 'rb') as opened_file:
  File "/cluster/project/sachan/yifan/softwares/anaconda/anaconda3/envs/xfactr/lib/python3.8/site-packages/torch/serialization.py", line 230, in _open_file_like
    return _open_file(name_or_buffer, mode)
  File "/cluster/project/sachan/yifan/softwares/anaconda/anaconda3/envs/xfactr/lib/python3.8/site-packages/torch/serialization.py", line 211, in __init__
    super(_open_file, self).__init__(open(name, mode))
FileNotFoundError: [Errno 2] No such file or directory: '/cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//squad/xlm-KG_LR8e-6_EPOCH2.0_maxlen384_batchsize4_gradacc4/predictions/mlqa/pytorch_model.bin'
  zh 
2022-05-09 21:42:19.852961: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0
05/09/2022 21:42:23 - WARNING - __main__ -   Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, 16-bits training: False
You are using a model of type xlm-roberta to instantiate a model of type xlm. This is not supported for all configurations of models and can yield errors.
Some weights of the model checkpoint at /cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//squad/xlm-KG_LR8e-6_EPOCH2.0_maxlen384_batchsize4_gradacc4 were not used when initializing XLMRobertaModel: ['base_model.encoder.layer.6.output.LayerNorm.bias', 'base_model.encoder.layer.17.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.6.output.dense.weight', 'base_model.encoder.layer.17.attention.self.value.weight', 'base_model.encoder.layer.7.attention.self.query.bias', 'base_model.encoder.layer.20.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.3.attention.self.query.bias', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.21.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.14.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.22.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.16.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.23.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.13.intermediate.dense.weight', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.10.output.dense.bias', 'base_model.encoder.layer.1.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.23.attention.output.dense.weight', 'base_model.encoder.layer.18.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.20.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.22.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.16.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.2.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.5.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.19.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.9.intermediate.dense.bias', 'base_model.encoder.layer.21.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.0.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.6.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.12.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.1.output.LayerNorm.weight', 'base_model.encoder.layer.9.attention.output.dense.weight', 'base_model.encoder.layer.9.attention.output.dense.bias', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.11.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.10.attention.self.value.weight', 'base_model.encoder.layer.21.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.23.intermediate.dense.bias', 'base_model.encoder.layer.8.attention.output.LayerNorm.bias', 'base_model.encoder.layer.4.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.19.attention.output.LayerNorm.bias', 'base_model.encoder.layer.2.attention.output.dense.weight', 'base_model.encoder.layer.5.attention.output.dense.bias', 'base_model.encoder.layer.3.attention.output.dense.weight', 'base_model.encoder.layer.2.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.5.output.LayerNorm.weight', 'base_model.encoder.layer.17.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.6.attention.self.key.bias', 'base_model.encoder.layer.1.attention.self.key.bias', 'base_model.encoder.layer.1.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.20.attention.self.query.bias', 'base_model.encoder.layer.12.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.20.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.8.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.8.intermediate.dense.bias', 'base_model.encoder.layer.12.attention.self.query.bias', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.10.attention.self.key.weight', 'base_model.encoder.layer.7.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.10.attention.self.query.weight', 'base_model.encoder.layer.5.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.1.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.2.attention.self.query.weight', 'base_model.encoder.layer.5.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.8.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.22.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.6.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.6.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.20.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.16.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.10.attention.output.dense.bias', 'base_model.encoder.layer.5.attention.self.query.weight', 'base_model.encoder.layer.3.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.18.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.14.attention.self.key.bias', 'base_model.encoder.layer.20.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.14.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.13.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.19.intermediate.dense.bias', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.12.output.LayerNorm.weight', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.22.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.18.output.dense.weight', 'base_model.encoder.layer.20.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.10.attention.output.dense.weight', 'base_model.encoder.layer.15.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.10.output.LayerNorm.bias', 'base_model.encoder.layer.9.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.22.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.13.attention.output.dense.bias', 'base_model.encoder.layer.5.output.dense.bias', 'base_model.encoder.layer.5.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.10.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.3.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.0.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.5.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.11.intermediate.dense.weight', 'base_model.encoder.layer.0.attention.output.dense.weight', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.2.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.21.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.14.output.dense.weight', 'base_model.encoder.layer.0.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.3.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.19.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.15.output.dense.weight', 'base_model.encoder.layer.19.attention.self.value.weight', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.2.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.8.attention.output.LayerNorm.weight', 'base_model.encoder.layer.10.attention.output.LayerNorm.weight', 'base_model.encoder.layer.10.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.13.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.1.output.LayerNorm.bias', 'base_model.encoder.layer.1.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.6.attention.self.query.weight', 'base_model.encoder.layer.16.attention.self.key.weight', 'base_model.encoder.layer.1.attention.output.dense.weight', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.16.attention.output.dense.bias', 'base_model.encoder.layer.3.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.11.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.1.attention.output.dense.bias', 'base_model.encoder.layer.16.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.18.attention.output.dense.weight', 'base_model.encoder.layer.23.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.9.attention.output.LayerNorm.bias', 'base_model.encoder.layer.8.attention.self.query.weight', 'base_model.encoder.layer.9.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.11.attention.self.value.weight', 'base_model.encoder.layer.8.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.11.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.7.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.6.attention.self.key.weight', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.14.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.8.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.19.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.11.output.LayerNorm.bias', 'base_model.encoder.layer.4.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.5.attention.self.value.weight', 'base_model.encoder.layer.16.attention.output.LayerNorm.bias', 'base_model.encoder.layer.9.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.11.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.4.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.22.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.13.attention.output.LayerNorm.weight', 'base_model.encoder.layer.17.attention.self.key.bias', 'base_model.encoder.layer.12.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.2.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.15.attention.output.dense.bias', 'base_model.encoder.layer.6.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.21.output.dense.weight', 'base_model.encoder.layer.23.output.LayerNorm.weight', 'base_model.encoder.layer.0.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.8.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.11.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.21.attention.output.LayerNorm.bias', 'base_model.encoder.layer.2.intermediate.dense.weight', 'base_model.encoder.layer.23.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.11.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.1.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.12.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.5.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.0.intermediate.dense.bias', 'base_model.encoder.layer.8.attention.self.value.bias', 'base_model.encoder.layer.8.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.1.attention.output.LayerNorm.weight', 'base_model.encoder.layer.3.output.dense.weight', 'base_model.encoder.layer.14.output.dense.bias', 'base_model.encoder.layer.18.output.LayerNorm.bias', 'base_model.encoder.layer.23.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.0.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.1.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.12.attention.self.key.bias', 'base_model.encoder.layer.16.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.16.output.LayerNorm.weight', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.6.attention.output.LayerNorm.bias', 'base_model.encoder.layer.9.attention.self.key.bias', 'base_model.encoder.layer.10.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.21.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.17.output.dense.weight', 'base_model.encoder.layer.23.attention.self.key.weight', 'base_model.encoder.layer.0.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.8.attention.self.key.bias', 'base_model.encoder.layer.11.output.dense.bias', 'base_model.encoder.layer.23.intermediate.dense.weight', 'base_model.encoder.layer.23.output.dense.weight', 'base_model.encoder.layer.6.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.23.attention.self.value.bias', 'base_model.encoder.layer.6.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.19.output.LayerNorm.bias', 'base_model.encoder.layer.9.attention.self.key.weight', 'base_model.encoder.layer.22.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.15.attention.output.LayerNorm.bias', 'base_model.encoder.layer.2.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.17.attention.output.LayerNorm.bias', 'base_model.encoder.layer.10.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.16.attention.self.key.bias', 'base_model.encoder.layer.11.attention.self.query.bias', 'base_model.encoder.layer.8.output.dense.weight', 'base_model.encoder.layer.22.attention.output.LayerNorm.bias', 'base_model.encoder.layer.14.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.4.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.16.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.23.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.14.attention.self.query.weight', 'base_model.encoder.layer.7.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.5.attention.output.LayerNorm.bias', 'base_model.encoder.layer.10.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.6.intermediate.dense.weight', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.9.attention.output.LayerNorm.weight', 'base_model.encoder.layer.22.attention.output.dense.weight', 'base_model.encoder.layer.15.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.2.attention.output.dense.bias', 'base_model.encoder.layer.13.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.18.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.18.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.13.output.dense.bias', 'base_model.encoder.layer.17.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.14.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.20.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.10.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.21.output.dense.bias', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.15.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.4.attention.output.dense.weight', 'base_model.encoder.layer.21.attention.self.query.bias', 'base_model.encoder.layer.15.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.11.intermediate.dense.bias', 'base_model.encoder.layer.14.attention.self.value.weight', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.10.output.dense.weight', 'base_model.encoder.layer.19.attention.output.dense.weight', 'base_model.encoder.layer.5.output.dense.weight', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.17.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.23.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.5.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.4.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.6.output.dense.bias', 'base_model.encoder.layer.13.intermediate.dense.bias', 'base_model.encoder.layer.11.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.3.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.9.attention.self.query.bias', 'base_model.encoder.layer.11.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.13.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.16.output.dense.bias', 'base_model.encoder.layer.13.attention.self.query.weight', 'base_model.encoder.layer.16.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.14.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.20.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.3.output.LayerNorm.bias', 'base_model.encoder.layer.15.attention.self.value.weight', 'base_model.encoder.layer.16.intermediate.dense.weight', 'base_model.encoder.layer.19.attention.output.dense.bias', 'base_model.encoder.layer.23.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.0.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.13.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.20.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.4.attention.output.LayerNorm.bias', 'base_model.encoder.layer.7.attention.self.value.weight', 'base_model.encoder.layer.23.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.14.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.2.intermediate.dense.bias', 'base_model.encoder.layer.22.attention.self.key.weight', 'base_model.encoder.layer.5.attention.output.dense.weight', 'base_model.encoder.layer.8.attention.self.query.bias', 'base_model.encoder.layer.21.attention.self.value.weight', 'base_model.encoder.layer.11.attention.output.LayerNorm.bias', 'base_model.encoder.layer.0.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.8.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.2.attention.self.value.weight', 'base_model.encoder.layer.21.attention.output.dense.bias', 'base_model.encoder.layer.7.attention.self.query.weight', 'base_model.encoder.layer.0.attention.self.value.weight', 'base_model.encoder.layer.13.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.7.output.LayerNorm.weight', 'base_model.encoder.layer.5.intermediate.dense.bias', 'base_model.encoder.layer.7.attention.self.key.bias', 'base_model.encoder.layer.2.attention.self.query.bias', 'base_model.encoder.layer.22.attention.self.value.bias', 'base_model.encoder.layer.20.attention.self.key.weight', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.15.attention.output.dense.weight', 'base_model.encoder.layer.6.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.20.intermediate.dense.weight', 'base_model.encoder.layer.19.intermediate.dense.weight', 'base_model.encoder.layer.5.attention.output.LayerNorm.weight', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.12.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.12.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.14.output.LayerNorm.bias', 'base_model.encoder.layer.3.attention.self.query.weight', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.4.attention.self.value.bias', 'base_model.encoder.layer.12.output.dense.weight', 'base_model.encoder.layer.18.intermediate.dense.bias', 'base_model.encoder.layer.20.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.21.output.adapters.ts.adapter_up.bias', 'qa_outputs.bias', 'base_model.encoder.layer.9.attention.self.query.weight', 'base_model.encoder.layer.8.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.7.attention.self.value.bias', 'base_model.encoder.layer.5.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.19.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.23.output.LayerNorm.bias', 'base_model.encoder.layer.0.output.LayerNorm.weight', 'base_model.embeddings.token_type_embeddings.weight', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.12.intermediate.dense.weight', 'base_model.encoder.layer.1.attention.self.query.bias', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.13.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.21.attention.output.dense.weight', 'base_model.encoder.layer.15.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.0.output.adapters.tp.adapter_down.0.bias', 'base_model.embeddings.position_ids', 'base_model.encoder.layer.0.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.8.attention.output.dense.weight', 'base_model.encoder.layer.7.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.14.attention.output.dense.bias', 'base_model.encoder.layer.9.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.10.intermediate.dense.weight', 'base_model.encoder.layer.9.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.21.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.6.attention.output.dense.weight', 'base_model.encoder.layer.11.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.11.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.22.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.14.attention.output.LayerNorm.bias', 'base_model.encoder.layer.9.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.15.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.2.attention.output.LayerNorm.bias', 'base_model.encoder.layer.20.attention.output.dense.bias', 'base_model.encoder.layer.9.output.dense.weight', 'base_model.encoder.layer.16.attention.self.query.bias', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.7.intermediate.dense.weight', 'base_model.encoder.layer.15.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.15.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.11.attention.self.key.bias', 'base_model.encoder.layer.3.attention.output.dense.bias', 'base_model.encoder.layer.5.attention.self.value.bias', 'base_model.encoder.layer.18.attention.output.LayerNorm.weight', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.23.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.19.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.20.attention.self.value.weight', 'base_model.encoder.layer.7.output.dense.bias', 'base_model.encoder.layer.13.attention.self.value.bias', 'base_model.encoder.layer.22.intermediate.dense.weight', 'base_model.encoder.layer.6.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.23.output.dense.bias', 'base_model.encoder.layer.2.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.10.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.17.output.LayerNorm.weight', 'base_model.encoder.layer.18.attention.output.LayerNorm.bias', 'base_model.encoder.layer.15.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.4.output.LayerNorm.bias', 'base_model.encoder.layer.3.output.dense.bias', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.11.attention.self.query.weight', 'base_model.encoder.layer.8.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.15.intermediate.dense.bias', 'base_model.encoder.layer.3.attention.output.LayerNorm.weight', 'base_model.encoder.layer.7.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.18.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.5.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.15.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.22.intermediate.dense.bias', 'base_model.encoder.layer.20.attention.output.LayerNorm.bias', 'base_model.encoder.layer.6.attention.self.value.bias', 'base_model.encoder.layer.8.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.12.attention.output.LayerNorm.bias', 'base_model.encoder.layer.13.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.17.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.5.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.14.intermediate.dense.weight', 'base_model.encoder.layer.18.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.2.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.12.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.21.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.14.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.16.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.21.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.19.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.21.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.14.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.12.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.14.attention.self.value.bias', 'base_model.encoder.layer.16.attention.output.dense.weight', 'base_model.encoder.layer.20.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.4.output.LayerNorm.weight', 'base_model.encoder.layer.7.output.dense.weight', 'base_model.encoder.layer.22.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.12.output.dense.bias', 'base_model.encoder.layer.16.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.18.output.dense.bias', 'base_model.encoder.layer.14.attention.self.query.bias', 'base_model.encoder.layer.13.attention.self.value.weight', 'base_model.encoder.layer.9.output.LayerNorm.bias', 'base_model.encoder.layer.9.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.4.attention.self.query.bias', 'base_model.encoder.layer.10.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.18.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.16.output.dense.weight', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.11.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.4.intermediate.dense.weight', 'base_model.encoder.layer.7.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.17.attention.self.query.weight', 'base_model.encoder.layer.22.output.LayerNorm.bias', 'base_model.encoder.layer.22.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.3.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.11.attention.output.dense.weight', 'base_model.encoder.layer.21.intermediate.dense.weight', 'base_model.encoder.layer.20.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.2.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.12.attention.output.LayerNorm.weight', 'base_model.encoder.layer.16.attention.self.query.weight', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.6.attention.self.value.weight', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.17.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.18.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.23.attention.self.key.bias', 'base_model.encoder.layer.12.output.LayerNorm.bias', 'base_model.encoder.layer.19.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.13.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.7.attention.output.dense.bias', 'base_model.encoder.layer.9.output.LayerNorm.weight', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.10.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.12.attention.self.key.weight', 'base_model.encoder.layer.11.output.dense.weight', 'base_model.encoder.layer.7.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.12.attention.output.dense.bias', 'base_model.encoder.layer.19.attention.self.key.weight', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.16.output.LayerNorm.bias', 'base_model.encoder.layer.17.attention.output.LayerNorm.weight', 'base_model.encoder.layer.8.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.1.output.dense.bias', 'base_model.encoder.layer.5.output.LayerNorm.bias', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.3.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.4.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.0.attention.self.key.weight', 'base_model.encoder.layer.18.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.17.output.LayerNorm.bias', 'base_model.encoder.layer.1.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.18.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.15.attention.self.key.bias', 'base_model.encoder.layer.21.attention.output.LayerNorm.weight', 'base_model.encoder.layer.21.attention.self.query.weight', 'base_model.encoder.layer.20.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.1.attention.output.LayerNorm.bias', 'base_model.encoder.layer.9.attention.self.value.bias', 'base_model.encoder.layer.16.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.16.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.11.attention.output.LayerNorm.weight', 'base_model.encoder.layer.15.output.LayerNorm.bias', 'base_model.encoder.layer.20.output.dense.bias', 'base_model.encoder.layer.0.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.13.attention.output.dense.weight', 'base_model.encoder.layer.16.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.18.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.13.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.4.attention.output.LayerNorm.weight', 'base_model.encoder.layer.14.intermediate.dense.bias', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.6.attention.output.dense.bias', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.13.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.1.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.8.attention.output.dense.bias', 'base_model.encoder.layer.9.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.14.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.23.attention.output.LayerNorm.weight', 'base_model.encoder.layer.20.attention.self.value.bias', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.18.attention.self.query.bias', 'base_model.encoder.layer.17.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.20.output.LayerNorm.weight', 'base_model.encoder.layer.4.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.5.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.0.attention.self.key.bias', 'base_model.encoder.layer.2.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.2.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.5.attention.self.query.bias', 'base_model.encoder.layer.3.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.3.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.1.intermediate.dense.bias', 'base_model.encoder.layer.9.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.20.attention.self.key.bias', 'base_model.encoder.layer.23.output.adapters.ep.adapter_up.bias', 'base_model.pooler.dense.weight', 'base_model.encoder.layer.19.attention.self.query.bias', 'base_model.encoder.layer.4.intermediate.dense.bias', 'base_model.encoder.layer.6.attention.output.LayerNorm.weight', 'base_model.encoder.layer.20.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.4.attention.self.key.weight', 'base_model.encoder.layer.7.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.18.attention.self.key.bias', 'base_model.encoder.layer.17.attention.output.dense.bias', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.14.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.10.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.21.output.adapters.ep.adapter_down.0.bias', 'base_model.embeddings.position_embeddings.weight', 'base_model.encoder.layer.14.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.22.attention.self.value.weight', 'base_model.encoder.layer.13.output.LayerNorm.bias', 'base_model.encoder.layer.20.output.LayerNorm.bias', 'base_model.encoder.layer.9.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.2.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.16.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.11.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.4.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.6.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.11.output.LayerNorm.weight', 'base_model.encoder.layer.10.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.15.output.dense.bias', 'base_model.encoder.layer.10.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.17.attention.output.dense.weight', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.13.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.3.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.1.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.4.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.11.attention.self.value.bias', 'base_model.encoder.layer.17.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.2.attention.self.key.bias', 'base_model.encoder.layer.22.attention.self.key.bias', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.12.intermediate.dense.bias', 'base_model.encoder.layer.16.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.2.output.dense.bias', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.3.attention.self.key.bias', 'base_model.encoder.layer.4.attention.self.query.weight', 'base_model.encoder.layer.7.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.13.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.0.attention.self.query.bias', 'base_model.pooler.dense.bias', 'base_model.encoder.layer.2.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.13.attention.self.query.bias', 'base_model.encoder.layer.3.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.17.attention.self.value.bias', 'base_model.encoder.layer.10.attention.self.key.bias', 'base_model.encoder.layer.14.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.4.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.17.attention.self.key.weight', 'base_model.encoder.layer.3.intermediate.dense.weight', 'base_model.encoder.layer.4.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.18.attention.self.value.bias', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.0.attention.output.dense.bias', 'base_model.encoder.layer.15.attention.output.LayerNorm.weight', 'base_model.encoder.layer.13.output.LayerNorm.weight', 'base_model.encoder.layer.6.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.15.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.18.attention.self.key.weight', 'base_model.encoder.layer.12.attention.output.dense.weight', 'base_model.encoder.layer.0.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.8.attention.self.value.weight', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.12.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.12.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.21.output.LayerNorm.bias', 'base_model.encoder.layer.18.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.23.attention.self.query.weight', 'base_model.encoder.layer.12.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.18.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.22.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.15.intermediate.dense.weight', 'base_model.encoder.layer.6.intermediate.dense.bias', 'base_model.encoder.layer.9.output.dense.bias', 'base_model.encoder.layer.22.output.LayerNorm.weight', 'base_model.encoder.layer.7.attention.output.dense.weight', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.4.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.0.attention.output.LayerNorm.bias', 'base_model.encoder.layer.13.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.10.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.12.attention.self.query.weight', 'base_model.encoder.layer.6.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.3.attention.self.value.weight', 'base_model.encoder.layer.12.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.22.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.20.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.9.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.15.attention.self.query.weight', 'base_model.encoder.layer.2.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.18.output.LayerNorm.weight', 'base_model.encoder.layer.8.attention.self.key.weight', 'base_model.encoder.layer.0.attention.output.LayerNorm.weight', 'base_model.encoder.layer.10.attention.output.LayerNorm.bias', 'base_model.encoder.layer.0.intermediate.dense.weight', 'base_model.encoder.layer.13.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.20.output.dense.weight', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.10.attention.self.query.bias', 'base_model.encoder.layer.0.output.dense.weight', 'base_model.encoder.layer.3.attention.self.key.weight', 'base_model.encoder.layer.6.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.22.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.1.attention.self.value.weight', 'base_model.encoder.layer.14.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.1.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.12.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.12.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.19.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.18.attention.output.dense.bias', 'base_model.encoder.layer.1.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.11.attention.self.key.weight', 'base_model.encoder.layer.7.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.22.output.dense.bias', 'base_model.encoder.layer.22.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.3.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.10.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.7.attention.output.LayerNorm.bias', 'base_model.encoder.layer.7.attention.output.LayerNorm.weight', 'base_model.encoder.layer.6.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.9.intermediate.dense.weight', 'base_model.encoder.layer.17.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.17.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.10.intermediate.dense.bias', 'base_model.encoder.layer.17.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.15.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.4.output.dense.weight', 'base_model.encoder.layer.5.attention.self.key.weight', 'base_model.encoder.layer.8.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.14.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.4.attention.self.key.bias', 'base_model.encoder.layer.0.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.2.output.LayerNorm.bias', 'base_model.encoder.layer.7.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.15.attention.self.value.bias', 'base_model.encoder.layer.22.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.19.output.LayerNorm.weight', 'base_model.encoder.layer.12.attention.self.value.weight', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.6.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.8.output.dense.bias', 'base_model.encoder.layer.7.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.8.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.2.output.LayerNorm.weight', 'base_model.encoder.layer.9.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.9.attention.self.value.weight', 'base_model.encoder.layer.10.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.20.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.6.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.8.output.LayerNorm.bias', 'base_model.encoder.layer.16.attention.self.value.weight', 'base_model.encoder.layer.7.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.21.attention.self.value.bias', 'base_model.encoder.layer.20.intermediate.dense.bias', 'base_model.encoder.layer.23.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.15.attention.self.key.weight', 'base_model.encoder.layer.3.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.13.output.dense.weight', 'base_model.encoder.layer.10.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.23.attention.output.LayerNorm.bias', 'base_model.encoder.layer.21.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.15.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.21.attention.self.key.bias', 'base_model.encoder.layer.3.intermediate.dense.bias', 'base_model.encoder.layer.8.intermediate.dense.weight', 'base_model.encoder.layer.19.attention.self.key.bias', 'base_model.encoder.layer.22.attention.output.LayerNorm.weight', 'base_model.encoder.layer.0.output.LayerNorm.bias', 'base_model.encoder.layer.16.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.8.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.5.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.23.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.4.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.2.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.19.attention.self.query.weight', 'base_model.encoder.layer.7.output.LayerNorm.bias', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.1.attention.self.query.weight', 'base_model.encoder.layer.17.output.dense.bias', 'base_model.encoder.layer.5.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.18.intermediate.dense.weight', 'base_model.encoder.layer.21.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.19.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.14.attention.output.LayerNorm.weight', 'base_model.encoder.layer.9.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.17.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.12.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.13.attention.output.LayerNorm.bias', 'base_model.encoder.layer.2.output.dense.weight', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.2.attention.output.LayerNorm.weight', 'base_model.encoder.layer.4.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.14.attention.output.dense.weight', 'base_model.encoder.layer.21.attention.self.key.weight', 'base_model.encoder.layer.9.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.1.attention.self.key.weight', 'base_model.encoder.layer.1.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.23.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.3.attention.self.value.bias', 'base_model.encoder.layer.21.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.3.output.LayerNorm.weight', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.18.attention.self.value.weight', 'base_model.encoder.layer.7.intermediate.dense.bias', 'base_model.encoder.layer.14.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.0.attention.self.value.bias', 'base_model.encoder.layer.13.attention.self.key.bias', 'base_model.encoder.layer.22.attention.output.dense.bias', 'base_model.encoder.layer.9.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.5.attention.self.key.bias', 'base_model.encoder.layer.5.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.8.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.7.attention.self.key.weight', 'base_model.encoder.layer.11.attention.output.dense.bias', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.16.intermediate.dense.bias', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.4.output.dense.bias', 'base_model.encoder.layer.23.attention.self.value.weight', 'base_model.encoder.layer.18.attention.self.query.weight', 'base_model.encoder.layer.0.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.1.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.7.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.0.output.dense.bias', 'base_model.encoder.layer.22.attention.self.query.weight', 'base_model.encoder.layer.19.output.dense.weight', 'base_model.embeddings.word_embeddings.weight', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.12.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.20.attention.output.dense.weight', 'base_model.encoder.layer.5.intermediate.dense.weight', 'base_model.encoder.layer.15.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.21.output.LayerNorm.weight', 'base_model.encoder.layer.22.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.23.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.7.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.8.output.LayerNorm.weight', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.1.attention.self.value.bias', 'base_model.encoder.layer.4.attention.output.dense.bias', 'base_model.encoder.layer.3.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.12.attention.self.value.bias', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.1.output.adapters.ts.adapter_down.0.weight', 'qa_outputs.weight', 'base_model.encoder.layer.15.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.11.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.2.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.16.attention.self.value.bias', 'base_model.encoder.layer.2.attention.self.value.bias', 'base_model.encoder.layer.22.output.dense.weight', 'base_model.encoder.layer.14.output.LayerNorm.weight', 'base_model.encoder.layer.17.attention.self.query.bias', 'base_model.embeddings.LayerNorm.bias', 'base_model.encoder.layer.17.intermediate.dense.weight', 'base_model.encoder.layer.3.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.19.attention.self.value.bias', 'base_model.encoder.layer.6.attention.self.query.bias', 'base_model.encoder.layer.3.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.1.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.19.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.14.attention.self.key.weight', 'base_model.encoder.layer.19.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.9.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.17.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.4.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.8.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.15.output.LayerNorm.weight', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.20.attention.self.query.weight', 'base_model.encoder.layer.10.output.LayerNorm.weight', 'base_model.encoder.layer.23.attention.output.dense.bias', 'base_model.encoder.layer.18.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.21.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.15.attention.self.query.bias', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.16.attention.output.LayerNorm.weight', 'base_model.encoder.layer.4.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.17.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.7.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.23.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.15.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.0.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.23.attention.self.query.bias', 'base_model.encoder.layer.17.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.17.intermediate.dense.bias', 'base_model.encoder.layer.10.attention.self.value.bias', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.22.attention.self.query.bias', 'base_model.encoder.layer.1.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.11.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.20.attention.output.LayerNorm.weight', 'base_model.encoder.layer.19.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.3.attention.output.LayerNorm.bias', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.21.intermediate.dense.bias', 'base_model.encoder.layer.0.attention.self.query.weight', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.1.intermediate.dense.weight', 'base_model.embeddings.LayerNorm.weight', 'base_model.encoder.layer.17.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.19.attention.output.LayerNorm.weight', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.4.attention.self.value.weight', 'base_model.encoder.layer.0.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.5.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.18.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.6.output.LayerNorm.weight', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.23.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.11.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.6.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.13.attention.self.key.weight', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.11.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.19.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.19.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.2.attention.self.key.weight', 'base_model.encoder.layer.5.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.13.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.18.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.19.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.19.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.21.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.16.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.1.output.dense.weight', 'base_model.encoder.layer.19.output.dense.bias']
- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of XLMRobertaModel were not initialized from the model checkpoint at /cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//squad/xlm-KG_LR8e-6_EPOCH2.0_maxlen384_batchsize4_gradacc4 and are newly initialized: ['encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.15.attention.self.key.bias', 'encoder.layer.11.attention.output.dense.weight', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.8.output.dense.bias', 'encoder.layer.3.attention.output.dense.weight', 'encoder.layer.20.attention.output.dense.bias', 'encoder.layer.12.attention.output.LayerNorm.bias', 'encoder.layer.12.output.dense.bias', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.17.output.LayerNorm.bias', 'encoder.layer.13.attention.self.key.bias', 'encoder.layer.23.attention.self.query.weight', 'encoder.layer.8.attention.output.dense.weight', 'encoder.layer.13.output.LayerNorm.bias', 'encoder.layer.10.attention.output.LayerNorm.weight', 'encoder.layer.18.attention.self.key.weight', 'encoder.layer.20.attention.self.query.bias', 'encoder.layer.21.output.LayerNorm.bias', 'encoder.layer.7.attention.self.query.bias', 'encoder.layer.14.attention.output.dense.bias', 'encoder.layer.9.attention.output.dense.weight', 'encoder.layer.23.output.dense.weight', 'encoder.layer.8.output.LayerNorm.weight', 'encoder.layer.20.intermediate.dense.weight', 'encoder.layer.14.output.dense.bias', 'encoder.layer.0.attention.self.query.bias', 'encoder.layer.7.output.dense.bias', 'encoder.layer.19.output.LayerNorm.bias', 'encoder.layer.13.attention.self.key.weight', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.6.attention.output.dense.bias', 'encoder.layer.7.output.dense.weight', 'encoder.layer.17.attention.self.key.weight', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.10.attention.output.dense.bias', 'pooler.dense.weight', 'encoder.layer.11.attention.self.query.bias', 'encoder.layer.12.attention.self.query.bias', 'encoder.layer.18.attention.output.LayerNorm.bias', 'encoder.layer.19.output.dense.weight', 'encoder.layer.13.attention.output.LayerNorm.bias', 'encoder.layer.6.attention.self.value.bias', 'encoder.layer.17.attention.output.LayerNorm.weight', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.8.attention.self.value.bias', 'encoder.layer.19.output.dense.bias', 'encoder.layer.5.attention.self.key.weight', 'encoder.layer.13.attention.output.LayerNorm.weight', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.12.attention.self.key.weight', 'encoder.layer.14.output.LayerNorm.weight', 'encoder.layer.8.attention.output.LayerNorm.bias', 'encoder.layer.8.attention.self.value.weight', 'encoder.layer.2.attention.output.LayerNorm.bias', 'encoder.layer.14.output.LayerNorm.bias', 'encoder.layer.11.output.LayerNorm.weight', 'encoder.layer.22.attention.self.value.weight', 'encoder.layer.19.attention.output.LayerNorm.bias', 'encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.layer.10.output.dense.bias', 'encoder.layer.10.output.LayerNorm.weight', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.18.attention.self.value.bias', 'encoder.layer.21.intermediate.dense.weight', 'encoder.layer.2.attention.self.query.weight', 'encoder.layer.19.intermediate.dense.weight', 'encoder.layer.20.output.dense.weight', 'encoder.layer.7.attention.self.value.bias', 'encoder.layer.13.attention.output.dense.bias', 'encoder.layer.13.output.dense.bias', 'encoder.layer.20.attention.output.dense.weight', 'encoder.layer.1.output.dense.weight', 'encoder.layer.3.attention.self.query.bias', 'encoder.layer.15.attention.output.LayerNorm.bias', 'encoder.layer.7.attention.self.query.weight', 'encoder.layer.22.attention.output.LayerNorm.weight', 'embeddings.LayerNorm.weight', 'encoder.layer.15.attention.self.value.bias', 'encoder.layer.7.output.LayerNorm.bias', 'encoder.layer.3.attention.self.key.weight', 'encoder.layer.8.attention.self.key.bias', 'encoder.layer.15.attention.self.value.weight', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.16.attention.output.LayerNorm.weight', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.17.output.dense.bias', 'encoder.layer.21.attention.output.dense.weight', 'encoder.layer.4.attention.output.dense.bias', 'encoder.layer.6.attention.output.LayerNorm.weight', 'encoder.layer.9.attention.output.LayerNorm.bias', 'encoder.layer.23.attention.output.dense.bias', 'encoder.layer.14.attention.self.key.weight', 'encoder.layer.4.attention.self.query.weight', 'encoder.layer.3.attention.self.value.weight', 'encoder.layer.15.intermediate.dense.weight', 'encoder.layer.9.output.dense.weight', 'encoder.layer.2.attention.output.dense.weight', 'encoder.layer.18.attention.output.dense.weight', 'encoder.layer.21.attention.output.dense.bias', 'encoder.layer.3.attention.output.dense.bias', 'encoder.layer.10.attention.self.key.weight', 'encoder.layer.16.attention.output.LayerNorm.bias', 'encoder.layer.18.attention.output.dense.bias', 'encoder.layer.4.output.dense.weight', 'encoder.layer.3.output.dense.bias', 'encoder.layer.19.attention.self.query.bias', 'encoder.layer.7.attention.output.LayerNorm.bias', 'encoder.layer.16.attention.self.key.bias', 'encoder.layer.13.intermediate.dense.weight', 'encoder.layer.5.attention.self.value.weight', 'encoder.layer.6.attention.output.dense.weight', 'encoder.layer.11.output.dense.weight', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.20.attention.output.LayerNorm.weight', 'encoder.layer.3.attention.self.value.bias', 'encoder.layer.1.attention.self.query.bias', 'encoder.layer.2.attention.output.LayerNorm.weight', 'encoder.layer.8.attention.self.key.weight', 'encoder.layer.16.attention.self.query.bias', 'encoder.layer.21.attention.self.value.weight', 'encoder.layer.0.attention.self.value.weight', 'encoder.layer.3.output.dense.weight', 'encoder.layer.2.attention.self.key.weight', 'encoder.layer.22.attention.self.query.bias', 'encoder.layer.21.output.dense.weight', 'encoder.layer.23.attention.self.key.bias', 'encoder.layer.20.attention.self.query.weight', 'encoder.layer.1.output.dense.bias', 'encoder.layer.8.attention.output.LayerNorm.weight', 'encoder.layer.5.attention.output.dense.weight', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.19.attention.self.key.weight', 'encoder.layer.23.attention.output.LayerNorm.bias', 'encoder.layer.17.attention.self.query.bias', 'encoder.layer.17.attention.output.dense.bias', 'encoder.layer.1.attention.self.key.bias', 'encoder.layer.15.attention.output.LayerNorm.weight', 'encoder.layer.11.attention.self.query.weight', 'encoder.layer.13.intermediate.dense.bias', 'encoder.layer.14.attention.output.LayerNorm.bias', 'encoder.layer.19.attention.self.value.bias', 'encoder.layer.18.attention.self.query.weight', 'encoder.layer.12.attention.self.query.weight', 'encoder.layer.22.attention.self.query.weight', 'encoder.layer.5.output.LayerNorm.bias', 'encoder.layer.9.attention.self.key.bias', 'encoder.layer.21.intermediate.dense.bias', 'encoder.layer.20.attention.self.key.weight', 'encoder.layer.7.attention.output.dense.weight', 'encoder.layer.6.attention.self.query.weight', 'encoder.layer.13.attention.self.query.bias', 'encoder.layer.0.attention.self.value.bias', 'encoder.layer.18.attention.self.value.weight', 'encoder.layer.16.attention.output.dense.bias', 'encoder.layer.13.attention.self.value.bias', 'encoder.layer.22.attention.self.value.bias', 'encoder.layer.5.attention.self.query.weight', 'encoder.layer.7.attention.output.dense.bias', 'encoder.layer.22.output.dense.weight', 'encoder.layer.1.attention.self.query.weight', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.18.attention.output.LayerNorm.weight', 'encoder.layer.16.intermediate.dense.weight', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.17.attention.output.dense.weight', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.20.attention.self.value.weight', 'encoder.layer.19.intermediate.dense.bias', 'encoder.layer.6.output.dense.bias', 'encoder.layer.17.attention.output.LayerNorm.bias', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.4.attention.output.LayerNorm.bias', 'encoder.layer.7.attention.output.LayerNorm.weight', 'encoder.layer.12.attention.self.key.bias', 'encoder.layer.5.attention.output.LayerNorm.weight', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.10.output.LayerNorm.bias', 'encoder.layer.23.attention.self.value.bias', 'encoder.layer.21.output.dense.bias', 'encoder.layer.15.attention.self.key.weight', 'encoder.layer.19.output.LayerNorm.weight', 'encoder.layer.15.intermediate.dense.bias', 'encoder.layer.9.attention.self.query.weight', 'encoder.layer.17.intermediate.dense.bias', 'encoder.layer.22.output.LayerNorm.bias', 'encoder.layer.4.attention.self.value.weight', 'encoder.layer.2.output.dense.weight', 'encoder.layer.20.output.LayerNorm.bias', 'encoder.layer.13.attention.self.value.weight', 'encoder.layer.2.attention.self.key.bias', 'encoder.layer.20.attention.self.key.bias', 'encoder.layer.15.attention.output.dense.weight', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.23.attention.self.key.weight', 'encoder.layer.18.output.dense.weight', 'encoder.layer.2.attention.self.query.bias', 'encoder.layer.8.attention.self.query.weight', 'encoder.layer.20.output.LayerNorm.weight', 'encoder.layer.6.attention.self.key.bias', 'encoder.layer.12.output.LayerNorm.bias', 'encoder.layer.4.attention.self.query.bias', 'encoder.layer.18.intermediate.dense.weight', 'encoder.layer.7.attention.self.key.weight', 'encoder.layer.12.attention.self.value.weight', 'encoder.layer.3.attention.self.key.bias', 'encoder.layer.17.attention.self.query.weight', 'encoder.layer.6.attention.output.LayerNorm.bias', 'encoder.layer.17.intermediate.dense.weight', 'encoder.layer.0.attention.output.dense.bias', 'encoder.layer.3.attention.self.query.weight', 'encoder.layer.13.output.LayerNorm.weight', 'encoder.layer.14.attention.self.query.bias', 'encoder.layer.22.attention.output.dense.bias', 'encoder.layer.11.attention.self.value.bias', 'encoder.layer.8.attention.output.dense.bias', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.17.output.LayerNorm.weight', 'encoder.layer.21.attention.self.key.weight', 'encoder.layer.12.attention.output.dense.weight', 'encoder.layer.22.intermediate.dense.bias', 'encoder.layer.13.attention.self.query.weight', 'encoder.layer.13.output.dense.weight', 'encoder.layer.10.attention.self.value.bias', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.10.intermediate.dense.weight', 'encoder.layer.12.output.LayerNorm.weight', 'encoder.layer.7.intermediate.dense.bias', 'encoder.layer.23.attention.output.LayerNorm.weight', 'encoder.layer.11.attention.self.key.weight', 'encoder.layer.16.attention.self.query.weight', 'encoder.layer.0.attention.self.query.weight', 'encoder.layer.12.intermediate.dense.weight', 'encoder.layer.22.attention.self.key.bias', 'encoder.layer.12.attention.output.dense.bias', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.15.output.dense.bias', 'encoder.layer.23.intermediate.dense.weight', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.19.attention.self.query.weight', 'encoder.layer.16.output.LayerNorm.weight', 'encoder.layer.21.attention.output.LayerNorm.weight', 'encoder.layer.5.attention.self.value.bias', 'encoder.layer.14.attention.output.LayerNorm.weight', 'encoder.layer.21.output.LayerNorm.weight', 'encoder.layer.9.attention.output.dense.bias', 'encoder.layer.2.attention.output.dense.bias', 'encoder.layer.18.intermediate.dense.bias', 'encoder.layer.12.intermediate.dense.bias', 'encoder.layer.5.output.dense.weight', 'encoder.layer.17.attention.self.value.weight', 'encoder.layer.1.attention.output.LayerNorm.weight', 'encoder.layer.9.output.LayerNorm.weight', 'encoder.layer.10.output.dense.weight', 'encoder.layer.15.attention.output.dense.bias', 'encoder.layer.6.output.LayerNorm.bias', 'encoder.layer.11.attention.output.dense.bias', 'encoder.layer.23.output.dense.bias', 'encoder.layer.5.output.dense.bias', 'encoder.layer.23.intermediate.dense.bias', 'encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.layer.9.output.LayerNorm.bias', 'encoder.layer.15.output.LayerNorm.weight', 'encoder.layer.22.attention.output.LayerNorm.bias', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.4.attention.self.value.bias', 'encoder.layer.16.output.dense.weight', 'encoder.layer.8.attention.self.query.bias', 'encoder.layer.6.attention.self.value.weight', 'encoder.layer.2.attention.self.value.bias', 'encoder.layer.1.attention.self.value.weight', 'encoder.layer.1.attention.output.dense.weight', 'encoder.layer.14.attention.self.value.bias', 'encoder.layer.9.attention.output.LayerNorm.weight', 'encoder.layer.9.attention.self.key.weight', 'embeddings.word_embeddings.weight', 'encoder.layer.22.output.LayerNorm.weight', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.14.attention.output.dense.weight', 'encoder.layer.2.output.dense.bias', 'encoder.layer.19.attention.output.LayerNorm.weight', 'encoder.layer.10.attention.output.dense.weight', 'encoder.layer.0.attention.self.key.bias', 'encoder.layer.19.attention.output.dense.weight', 'encoder.layer.7.attention.self.key.bias', 'encoder.layer.17.attention.self.key.bias', 'encoder.layer.20.attention.output.LayerNorm.bias', 'encoder.layer.16.attention.self.key.weight', 'encoder.layer.9.attention.self.value.bias', 'encoder.layer.5.attention.output.dense.bias', 'encoder.layer.22.attention.self.key.weight', 'encoder.layer.15.attention.self.query.weight', 'encoder.layer.16.attention.self.value.bias', 'encoder.layer.10.attention.self.value.weight', 'encoder.layer.0.attention.output.dense.weight', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.18.attention.self.key.bias', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.16.attention.self.value.weight', 'encoder.layer.7.attention.self.value.weight', 'encoder.layer.23.attention.self.query.bias', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.19.attention.output.dense.bias', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.16.attention.output.dense.weight', 'encoder.layer.11.output.dense.bias', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.21.attention.output.LayerNorm.bias', 'encoder.layer.14.intermediate.dense.weight', 'encoder.layer.15.output.LayerNorm.bias', 'encoder.layer.20.attention.self.value.bias', 'encoder.layer.22.output.dense.bias', 'encoder.layer.6.output.dense.weight', 'encoder.layer.14.output.dense.weight', 'pooler.dense.bias', 'encoder.layer.21.attention.self.key.bias', 'encoder.layer.6.attention.self.query.bias', 'encoder.layer.4.attention.self.key.bias', 'encoder.layer.21.attention.self.query.weight', 'encoder.layer.14.intermediate.dense.bias', 'embeddings.LayerNorm.bias', 'encoder.layer.11.attention.output.LayerNorm.weight', 'encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.layer.10.attention.self.query.weight', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.10.attention.self.key.bias', 'encoder.layer.1.attention.self.key.weight', 'encoder.layer.12.output.dense.weight', 'encoder.layer.21.attention.self.query.bias', 'encoder.layer.10.attention.self.query.bias', 'encoder.layer.11.output.LayerNorm.bias', 'encoder.layer.0.output.dense.bias', 'encoder.layer.14.attention.self.value.weight', 'encoder.layer.18.output.LayerNorm.bias', 'encoder.layer.18.output.dense.bias', 'encoder.layer.23.output.LayerNorm.bias', 'embeddings.token_type_embeddings.weight', 'encoder.layer.8.output.dense.weight', 'encoder.layer.13.attention.output.dense.weight', 'encoder.layer.14.attention.self.query.weight', 'encoder.layer.4.attention.output.dense.weight', 'encoder.layer.5.attention.self.query.bias', 'encoder.layer.2.attention.self.value.weight', 'encoder.layer.14.attention.self.key.bias', 'encoder.layer.22.intermediate.dense.weight', 'encoder.layer.16.intermediate.dense.bias', 'encoder.layer.23.attention.output.dense.weight', 'encoder.layer.21.attention.self.value.bias', 'encoder.layer.9.attention.self.query.bias', 'encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.layer.8.output.LayerNorm.bias', 'encoder.layer.9.attention.self.value.weight', 'encoder.layer.9.output.dense.bias', 'encoder.layer.1.attention.self.value.bias', 'encoder.layer.0.attention.self.key.weight', 'encoder.layer.6.attention.self.key.weight', 'encoder.layer.4.attention.self.key.weight', 'encoder.layer.16.output.dense.bias', 'encoder.layer.18.output.LayerNorm.weight', 'encoder.layer.1.attention.output.dense.bias', 'encoder.layer.19.attention.self.key.bias', 'encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.layer.0.attention.output.LayerNorm.weight', 'encoder.layer.4.attention.output.LayerNorm.weight', 'encoder.layer.11.attention.self.value.weight', 'encoder.layer.19.attention.self.value.weight', 'encoder.layer.18.attention.self.query.bias', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.22.attention.output.dense.weight', 'encoder.layer.5.attention.self.key.bias', 'encoder.layer.7.output.LayerNorm.weight', 'encoder.layer.0.output.dense.weight', 'encoder.layer.15.attention.self.query.bias', 'encoder.layer.20.output.dense.bias', 'encoder.layer.12.attention.self.value.bias', 'encoder.layer.4.output.dense.bias', 'encoder.layer.23.output.LayerNorm.weight', 'encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.23.attention.self.value.weight', 'encoder.layer.17.output.dense.weight', 'encoder.layer.11.attention.self.key.bias', 'encoder.layer.17.attention.self.value.bias', 'embeddings.position_embeddings.weight', 'encoder.layer.15.output.dense.weight', 'encoder.layer.20.intermediate.dense.bias', 'encoder.layer.16.output.LayerNorm.bias', 'encoder.layer.12.attention.output.LayerNorm.weight', 'encoder.layer.10.attention.output.LayerNorm.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Overwriting existing adapter 'ep'.
Overwriting existing adapter 'tp'.
Overwriting existing adapter 'es'.
Overwriting existing adapter 'ts'.
Overwriting existing adapter fusion module 'ep,tp,es,ts'
05/09/2022 21:42:43 - INFO - __main__ -   lang2id = None
05/09/2022 21:42:47 - INFO - __main__ -   Training/evaluation parameters Namespace(adam_epsilon=1e-08, cache_dir='', config_name='', data_dir=None, device=device(type='cuda'), do_eval=True, do_lower_case=False, do_train=False, doc_stride=128, eval_all_checkpoints=False, eval_lang='zh', evaluate_during_training=False, fp16=False, fp16_opt_level='O1', gradient_accumulation_steps=1, learning_rate=5e-05, local_rank=-1, logging_steps=50, max_answer_length=30, max_grad_norm=1.0, max_query_length=64, max_seq_length=384, max_steps=-1, model_name='xlm-KG', model_name_or_path='/cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//squad/xlm-KG_LR8e-6_EPOCH2.0_maxlen384_batchsize4_gradacc4', model_type='xlm', modelkg_dir='/cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/adapter/xlmr_adapter', n_best_size=20, n_gpu=1, no_cuda=False, null_score_diff_threshold=0.0, num_train_epochs=3.0, output_dir='/cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//squad/xlm-KG_LR8e-6_EPOCH2.0_maxlen384_batchsize4_gradacc4/predictions/mlqa/', overwrite_cache=False, overwrite_output_dir=False, per_gpu_eval_batch_size=8, per_gpu_train_batch_size=8, predict_file='/cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/download//mlqa//MLQA_V1/test/test-context-zh-question-zh.json', save_steps=50, seed=42, server_ip='', server_port='', threads=1, tokenizer_name='', train_file=None, train_lang='en', verbose_logging=False, version_2_with_negative=False, warmup_steps=0, weight_decay=0.0)
05/09/2022 21:42:47 - INFO - __main__ -   Loading checkpoint /cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//squad/xlm-KG_LR8e-6_EPOCH2.0_maxlen384_batchsize4_gradacc4 for evaluation
05/09/2022 21:42:47 - INFO - __main__ -   Evaluate the following checkpoints: ['/cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//squad/xlm-KG_LR8e-6_EPOCH2.0_maxlen384_batchsize4_gradacc4']
Some weights of the model checkpoint at /cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//squad/xlm-KG_LR8e-6_EPOCH2.0_maxlen384_batchsize4_gradacc4 were not used when initializing XLMRobertaModel: ['base_model.encoder.layer.6.output.LayerNorm.bias', 'base_model.encoder.layer.17.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.6.output.dense.weight', 'base_model.encoder.layer.17.attention.self.value.weight', 'base_model.encoder.layer.7.attention.self.query.bias', 'base_model.encoder.layer.20.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.3.attention.self.query.bias', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.21.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.14.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.22.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.16.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.23.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.13.intermediate.dense.weight', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.10.output.dense.bias', 'base_model.encoder.layer.1.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.23.attention.output.dense.weight', 'base_model.encoder.layer.18.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.20.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.22.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.16.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.2.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.5.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.19.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.9.intermediate.dense.bias', 'base_model.encoder.layer.21.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.0.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.6.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.12.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.1.output.LayerNorm.weight', 'base_model.encoder.layer.9.attention.output.dense.weight', 'base_model.encoder.layer.9.attention.output.dense.bias', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.11.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.10.attention.self.value.weight', 'base_model.encoder.layer.21.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.23.intermediate.dense.bias', 'base_model.encoder.layer.8.attention.output.LayerNorm.bias', 'base_model.encoder.layer.4.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.19.attention.output.LayerNorm.bias', 'base_model.encoder.layer.2.attention.output.dense.weight', 'base_model.encoder.layer.5.attention.output.dense.bias', 'base_model.encoder.layer.3.attention.output.dense.weight', 'base_model.encoder.layer.2.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.5.output.LayerNorm.weight', 'base_model.encoder.layer.17.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.6.attention.self.key.bias', 'base_model.encoder.layer.1.attention.self.key.bias', 'base_model.encoder.layer.1.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.20.attention.self.query.bias', 'base_model.encoder.layer.12.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.20.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.8.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.8.intermediate.dense.bias', 'base_model.encoder.layer.12.attention.self.query.bias', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.10.attention.self.key.weight', 'base_model.encoder.layer.7.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.10.attention.self.query.weight', 'base_model.encoder.layer.5.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.1.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.2.attention.self.query.weight', 'base_model.encoder.layer.5.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.8.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.22.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.6.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.6.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.20.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.16.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.10.attention.output.dense.bias', 'base_model.encoder.layer.5.attention.self.query.weight', 'base_model.encoder.layer.3.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.18.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.14.attention.self.key.bias', 'base_model.encoder.layer.20.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.14.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.13.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.19.intermediate.dense.bias', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.12.output.LayerNorm.weight', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.22.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.18.output.dense.weight', 'base_model.encoder.layer.20.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.10.attention.output.dense.weight', 'base_model.encoder.layer.15.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.10.output.LayerNorm.bias', 'base_model.encoder.layer.9.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.22.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.13.attention.output.dense.bias', 'base_model.encoder.layer.5.output.dense.bias', 'base_model.encoder.layer.5.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.10.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.3.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.0.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.5.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.11.intermediate.dense.weight', 'base_model.encoder.layer.0.attention.output.dense.weight', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.2.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.21.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.14.output.dense.weight', 'base_model.encoder.layer.0.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.3.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.19.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.15.output.dense.weight', 'base_model.encoder.layer.19.attention.self.value.weight', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.2.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.8.attention.output.LayerNorm.weight', 'base_model.encoder.layer.10.attention.output.LayerNorm.weight', 'base_model.encoder.layer.10.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.13.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.1.output.LayerNorm.bias', 'base_model.encoder.layer.1.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.6.attention.self.query.weight', 'base_model.encoder.layer.16.attention.self.key.weight', 'base_model.encoder.layer.1.attention.output.dense.weight', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.16.attention.output.dense.bias', 'base_model.encoder.layer.3.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.11.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.1.attention.output.dense.bias', 'base_model.encoder.layer.16.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.18.attention.output.dense.weight', 'base_model.encoder.layer.23.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.9.attention.output.LayerNorm.bias', 'base_model.encoder.layer.8.attention.self.query.weight', 'base_model.encoder.layer.9.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.11.attention.self.value.weight', 'base_model.encoder.layer.8.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.11.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.7.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.6.attention.self.key.weight', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.14.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.8.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.19.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.11.output.LayerNorm.bias', 'base_model.encoder.layer.4.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.5.attention.self.value.weight', 'base_model.encoder.layer.16.attention.output.LayerNorm.bias', 'base_model.encoder.layer.9.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.11.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.4.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.22.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.13.attention.output.LayerNorm.weight', 'base_model.encoder.layer.17.attention.self.key.bias', 'base_model.encoder.layer.12.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.2.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.15.attention.output.dense.bias', 'base_model.encoder.layer.6.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.21.output.dense.weight', 'base_model.encoder.layer.23.output.LayerNorm.weight', 'base_model.encoder.layer.0.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.8.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.11.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.21.attention.output.LayerNorm.bias', 'base_model.encoder.layer.2.intermediate.dense.weight', 'base_model.encoder.layer.23.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.11.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.1.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.12.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.5.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.0.intermediate.dense.bias', 'base_model.encoder.layer.8.attention.self.value.bias', 'base_model.encoder.layer.8.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.1.attention.output.LayerNorm.weight', 'base_model.encoder.layer.3.output.dense.weight', 'base_model.encoder.layer.14.output.dense.bias', 'base_model.encoder.layer.18.output.LayerNorm.bias', 'base_model.encoder.layer.23.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.0.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.1.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.12.attention.self.key.bias', 'base_model.encoder.layer.16.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.16.output.LayerNorm.weight', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.6.attention.output.LayerNorm.bias', 'base_model.encoder.layer.9.attention.self.key.bias', 'base_model.encoder.layer.10.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.21.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.17.output.dense.weight', 'base_model.encoder.layer.23.attention.self.key.weight', 'base_model.encoder.layer.0.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.8.attention.self.key.bias', 'base_model.encoder.layer.11.output.dense.bias', 'base_model.encoder.layer.23.intermediate.dense.weight', 'base_model.encoder.layer.23.output.dense.weight', 'base_model.encoder.layer.6.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.23.attention.self.value.bias', 'base_model.encoder.layer.6.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.19.output.LayerNorm.bias', 'base_model.encoder.layer.9.attention.self.key.weight', 'base_model.encoder.layer.22.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.15.attention.output.LayerNorm.bias', 'base_model.encoder.layer.2.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.17.attention.output.LayerNorm.bias', 'base_model.encoder.layer.10.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.16.attention.self.key.bias', 'base_model.encoder.layer.11.attention.self.query.bias', 'base_model.encoder.layer.8.output.dense.weight', 'base_model.encoder.layer.22.attention.output.LayerNorm.bias', 'base_model.encoder.layer.14.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.4.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.16.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.23.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.14.attention.self.query.weight', 'base_model.encoder.layer.7.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.5.attention.output.LayerNorm.bias', 'base_model.encoder.layer.10.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.6.intermediate.dense.weight', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.9.attention.output.LayerNorm.weight', 'base_model.encoder.layer.22.attention.output.dense.weight', 'base_model.encoder.layer.15.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.2.attention.output.dense.bias', 'base_model.encoder.layer.13.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.18.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.18.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.13.output.dense.bias', 'base_model.encoder.layer.17.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.14.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.20.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.10.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.21.output.dense.bias', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.15.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.4.attention.output.dense.weight', 'base_model.encoder.layer.21.attention.self.query.bias', 'base_model.encoder.layer.15.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.11.intermediate.dense.bias', 'base_model.encoder.layer.14.attention.self.value.weight', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.10.output.dense.weight', 'base_model.encoder.layer.19.attention.output.dense.weight', 'base_model.encoder.layer.5.output.dense.weight', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.17.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.23.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.5.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.4.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.6.output.dense.bias', 'base_model.encoder.layer.13.intermediate.dense.bias', 'base_model.encoder.layer.11.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.3.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.9.attention.self.query.bias', 'base_model.encoder.layer.11.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.13.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.16.output.dense.bias', 'base_model.encoder.layer.13.attention.self.query.weight', 'base_model.encoder.layer.16.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.14.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.20.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.3.output.LayerNorm.bias', 'base_model.encoder.layer.15.attention.self.value.weight', 'base_model.encoder.layer.16.intermediate.dense.weight', 'base_model.encoder.layer.19.attention.output.dense.bias', 'base_model.encoder.layer.23.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.0.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.13.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.20.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.4.attention.output.LayerNorm.bias', 'base_model.encoder.layer.7.attention.self.value.weight', 'base_model.encoder.layer.23.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.14.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.2.intermediate.dense.bias', 'base_model.encoder.layer.22.attention.self.key.weight', 'base_model.encoder.layer.5.attention.output.dense.weight', 'base_model.encoder.layer.8.attention.self.query.bias', 'base_model.encoder.layer.21.attention.self.value.weight', 'base_model.encoder.layer.11.attention.output.LayerNorm.bias', 'base_model.encoder.layer.0.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.8.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.2.attention.self.value.weight', 'base_model.encoder.layer.21.attention.output.dense.bias', 'base_model.encoder.layer.7.attention.self.query.weight', 'base_model.encoder.layer.0.attention.self.value.weight', 'base_model.encoder.layer.13.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.7.output.LayerNorm.weight', 'base_model.encoder.layer.5.intermediate.dense.bias', 'base_model.encoder.layer.7.attention.self.key.bias', 'base_model.encoder.layer.2.attention.self.query.bias', 'base_model.encoder.layer.22.attention.self.value.bias', 'base_model.encoder.layer.20.attention.self.key.weight', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.15.attention.output.dense.weight', 'base_model.encoder.layer.6.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.20.intermediate.dense.weight', 'base_model.encoder.layer.19.intermediate.dense.weight', 'base_model.encoder.layer.5.attention.output.LayerNorm.weight', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.12.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.12.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.14.output.LayerNorm.bias', 'base_model.encoder.layer.3.attention.self.query.weight', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.4.attention.self.value.bias', 'base_model.encoder.layer.12.output.dense.weight', 'base_model.encoder.layer.18.intermediate.dense.bias', 'base_model.encoder.layer.20.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.21.output.adapters.ts.adapter_up.bias', 'qa_outputs.bias', 'base_model.encoder.layer.9.attention.self.query.weight', 'base_model.encoder.layer.8.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.7.attention.self.value.bias', 'base_model.encoder.layer.5.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.19.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.23.output.LayerNorm.bias', 'base_model.encoder.layer.0.output.LayerNorm.weight', 'base_model.embeddings.token_type_embeddings.weight', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.12.intermediate.dense.weight', 'base_model.encoder.layer.1.attention.self.query.bias', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.13.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.21.attention.output.dense.weight', 'base_model.encoder.layer.15.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.0.output.adapters.tp.adapter_down.0.bias', 'base_model.embeddings.position_ids', 'base_model.encoder.layer.0.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.8.attention.output.dense.weight', 'base_model.encoder.layer.7.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.14.attention.output.dense.bias', 'base_model.encoder.layer.9.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.10.intermediate.dense.weight', 'base_model.encoder.layer.9.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.21.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.6.attention.output.dense.weight', 'base_model.encoder.layer.11.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.11.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.22.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.14.attention.output.LayerNorm.bias', 'base_model.encoder.layer.9.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.15.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.2.attention.output.LayerNorm.bias', 'base_model.encoder.layer.20.attention.output.dense.bias', 'base_model.encoder.layer.9.output.dense.weight', 'base_model.encoder.layer.16.attention.self.query.bias', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.7.intermediate.dense.weight', 'base_model.encoder.layer.15.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.15.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.11.attention.self.key.bias', 'base_model.encoder.layer.3.attention.output.dense.bias', 'base_model.encoder.layer.5.attention.self.value.bias', 'base_model.encoder.layer.18.attention.output.LayerNorm.weight', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.23.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.19.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.20.attention.self.value.weight', 'base_model.encoder.layer.7.output.dense.bias', 'base_model.encoder.layer.13.attention.self.value.bias', 'base_model.encoder.layer.22.intermediate.dense.weight', 'base_model.encoder.layer.6.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.23.output.dense.bias', 'base_model.encoder.layer.2.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.10.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.17.output.LayerNorm.weight', 'base_model.encoder.layer.18.attention.output.LayerNorm.bias', 'base_model.encoder.layer.15.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.4.output.LayerNorm.bias', 'base_model.encoder.layer.3.output.dense.bias', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.11.attention.self.query.weight', 'base_model.encoder.layer.8.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.15.intermediate.dense.bias', 'base_model.encoder.layer.3.attention.output.LayerNorm.weight', 'base_model.encoder.layer.7.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.18.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.5.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.15.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.22.intermediate.dense.bias', 'base_model.encoder.layer.20.attention.output.LayerNorm.bias', 'base_model.encoder.layer.6.attention.self.value.bias', 'base_model.encoder.layer.8.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.12.attention.output.LayerNorm.bias', 'base_model.encoder.layer.13.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.17.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.5.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.14.intermediate.dense.weight', 'base_model.encoder.layer.18.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.2.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.12.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.21.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.14.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.16.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.21.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.19.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.21.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.14.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.12.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.14.attention.self.value.bias', 'base_model.encoder.layer.16.attention.output.dense.weight', 'base_model.encoder.layer.20.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.4.output.LayerNorm.weight', 'base_model.encoder.layer.7.output.dense.weight', 'base_model.encoder.layer.22.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.12.output.dense.bias', 'base_model.encoder.layer.16.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.18.output.dense.bias', 'base_model.encoder.layer.14.attention.self.query.bias', 'base_model.encoder.layer.13.attention.self.value.weight', 'base_model.encoder.layer.9.output.LayerNorm.bias', 'base_model.encoder.layer.9.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.4.attention.self.query.bias', 'base_model.encoder.layer.10.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.18.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.16.output.dense.weight', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.11.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.4.intermediate.dense.weight', 'base_model.encoder.layer.7.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.17.attention.self.query.weight', 'base_model.encoder.layer.22.output.LayerNorm.bias', 'base_model.encoder.layer.22.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.3.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.11.attention.output.dense.weight', 'base_model.encoder.layer.21.intermediate.dense.weight', 'base_model.encoder.layer.20.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.2.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.12.attention.output.LayerNorm.weight', 'base_model.encoder.layer.16.attention.self.query.weight', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.6.attention.self.value.weight', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.17.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.18.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.23.attention.self.key.bias', 'base_model.encoder.layer.12.output.LayerNorm.bias', 'base_model.encoder.layer.19.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.13.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.7.attention.output.dense.bias', 'base_model.encoder.layer.9.output.LayerNorm.weight', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.10.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.12.attention.self.key.weight', 'base_model.encoder.layer.11.output.dense.weight', 'base_model.encoder.layer.7.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.12.attention.output.dense.bias', 'base_model.encoder.layer.19.attention.self.key.weight', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.16.output.LayerNorm.bias', 'base_model.encoder.layer.17.attention.output.LayerNorm.weight', 'base_model.encoder.layer.8.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.1.output.dense.bias', 'base_model.encoder.layer.5.output.LayerNorm.bias', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.3.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.4.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.0.attention.self.key.weight', 'base_model.encoder.layer.18.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.17.output.LayerNorm.bias', 'base_model.encoder.layer.1.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.18.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.15.attention.self.key.bias', 'base_model.encoder.layer.21.attention.output.LayerNorm.weight', 'base_model.encoder.layer.21.attention.self.query.weight', 'base_model.encoder.layer.20.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.1.attention.output.LayerNorm.bias', 'base_model.encoder.layer.9.attention.self.value.bias', 'base_model.encoder.layer.16.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.16.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.11.attention.output.LayerNorm.weight', 'base_model.encoder.layer.15.output.LayerNorm.bias', 'base_model.encoder.layer.20.output.dense.bias', 'base_model.encoder.layer.0.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.13.attention.output.dense.weight', 'base_model.encoder.layer.16.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.18.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.13.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.4.attention.output.LayerNorm.weight', 'base_model.encoder.layer.14.intermediate.dense.bias', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.6.attention.output.dense.bias', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.13.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.1.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.8.attention.output.dense.bias', 'base_model.encoder.layer.9.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.14.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.23.attention.output.LayerNorm.weight', 'base_model.encoder.layer.20.attention.self.value.bias', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.18.attention.self.query.bias', 'base_model.encoder.layer.17.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.20.output.LayerNorm.weight', 'base_model.encoder.layer.4.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.5.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.0.attention.self.key.bias', 'base_model.encoder.layer.2.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.2.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.5.attention.self.query.bias', 'base_model.encoder.layer.3.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.3.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.1.intermediate.dense.bias', 'base_model.encoder.layer.9.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.20.attention.self.key.bias', 'base_model.encoder.layer.23.output.adapters.ep.adapter_up.bias', 'base_model.pooler.dense.weight', 'base_model.encoder.layer.19.attention.self.query.bias', 'base_model.encoder.layer.4.intermediate.dense.bias', 'base_model.encoder.layer.6.attention.output.LayerNorm.weight', 'base_model.encoder.layer.20.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.4.attention.self.key.weight', 'base_model.encoder.layer.7.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.18.attention.self.key.bias', 'base_model.encoder.layer.17.attention.output.dense.bias', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.14.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.10.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.21.output.adapters.ep.adapter_down.0.bias', 'base_model.embeddings.position_embeddings.weight', 'base_model.encoder.layer.14.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.22.attention.self.value.weight', 'base_model.encoder.layer.13.output.LayerNorm.bias', 'base_model.encoder.layer.20.output.LayerNorm.bias', 'base_model.encoder.layer.9.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.2.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.16.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.11.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.4.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.6.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.11.output.LayerNorm.weight', 'base_model.encoder.layer.10.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.15.output.dense.bias', 'base_model.encoder.layer.10.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.17.attention.output.dense.weight', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.13.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.3.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.1.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.4.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.11.attention.self.value.bias', 'base_model.encoder.layer.17.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.2.attention.self.key.bias', 'base_model.encoder.layer.22.attention.self.key.bias', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.12.intermediate.dense.bias', 'base_model.encoder.layer.16.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.2.output.dense.bias', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.3.attention.self.key.bias', 'base_model.encoder.layer.4.attention.self.query.weight', 'base_model.encoder.layer.7.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.13.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.0.attention.self.query.bias', 'base_model.pooler.dense.bias', 'base_model.encoder.layer.2.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.13.attention.self.query.bias', 'base_model.encoder.layer.3.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.17.attention.self.value.bias', 'base_model.encoder.layer.10.attention.self.key.bias', 'base_model.encoder.layer.14.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.4.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.17.attention.self.key.weight', 'base_model.encoder.layer.3.intermediate.dense.weight', 'base_model.encoder.layer.4.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.18.attention.self.value.bias', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.0.attention.output.dense.bias', 'base_model.encoder.layer.15.attention.output.LayerNorm.weight', 'base_model.encoder.layer.13.output.LayerNorm.weight', 'base_model.encoder.layer.6.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.15.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.18.attention.self.key.weight', 'base_model.encoder.layer.12.attention.output.dense.weight', 'base_model.encoder.layer.0.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.8.attention.self.value.weight', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.12.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.12.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.21.output.LayerNorm.bias', 'base_model.encoder.layer.18.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.23.attention.self.query.weight', 'base_model.encoder.layer.12.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.18.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.22.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.15.intermediate.dense.weight', 'base_model.encoder.layer.6.intermediate.dense.bias', 'base_model.encoder.layer.9.output.dense.bias', 'base_model.encoder.layer.22.output.LayerNorm.weight', 'base_model.encoder.layer.7.attention.output.dense.weight', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.4.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.0.attention.output.LayerNorm.bias', 'base_model.encoder.layer.13.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.10.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.12.attention.self.query.weight', 'base_model.encoder.layer.6.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.3.attention.self.value.weight', 'base_model.encoder.layer.12.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.22.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.20.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.9.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.15.attention.self.query.weight', 'base_model.encoder.layer.2.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.18.output.LayerNorm.weight', 'base_model.encoder.layer.8.attention.self.key.weight', 'base_model.encoder.layer.0.attention.output.LayerNorm.weight', 'base_model.encoder.layer.10.attention.output.LayerNorm.bias', 'base_model.encoder.layer.0.intermediate.dense.weight', 'base_model.encoder.layer.13.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.20.output.dense.weight', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.10.attention.self.query.bias', 'base_model.encoder.layer.0.output.dense.weight', 'base_model.encoder.layer.3.attention.self.key.weight', 'base_model.encoder.layer.6.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.22.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.1.attention.self.value.weight', 'base_model.encoder.layer.14.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.1.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.12.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.12.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.19.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.18.attention.output.dense.bias', 'base_model.encoder.layer.1.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.11.attention.self.key.weight', 'base_model.encoder.layer.7.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.22.output.dense.bias', 'base_model.encoder.layer.22.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.3.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.10.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.7.attention.output.LayerNorm.bias', 'base_model.encoder.layer.7.attention.output.LayerNorm.weight', 'base_model.encoder.layer.6.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.9.intermediate.dense.weight', 'base_model.encoder.layer.17.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.17.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.10.intermediate.dense.bias', 'base_model.encoder.layer.17.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.15.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.4.output.dense.weight', 'base_model.encoder.layer.5.attention.self.key.weight', 'base_model.encoder.layer.8.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.14.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.4.attention.self.key.bias', 'base_model.encoder.layer.0.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.2.output.LayerNorm.bias', 'base_model.encoder.layer.7.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.15.attention.self.value.bias', 'base_model.encoder.layer.22.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.19.output.LayerNorm.weight', 'base_model.encoder.layer.12.attention.self.value.weight', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.6.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.8.output.dense.bias', 'base_model.encoder.layer.7.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.8.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.2.output.LayerNorm.weight', 'base_model.encoder.layer.9.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.9.attention.self.value.weight', 'base_model.encoder.layer.10.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.20.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.6.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.8.output.LayerNorm.bias', 'base_model.encoder.layer.16.attention.self.value.weight', 'base_model.encoder.layer.7.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.21.attention.self.value.bias', 'base_model.encoder.layer.20.intermediate.dense.bias', 'base_model.encoder.layer.23.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.15.attention.self.key.weight', 'base_model.encoder.layer.3.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.13.output.dense.weight', 'base_model.encoder.layer.10.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.23.attention.output.LayerNorm.bias', 'base_model.encoder.layer.21.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.15.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.21.attention.self.key.bias', 'base_model.encoder.layer.3.intermediate.dense.bias', 'base_model.encoder.layer.8.intermediate.dense.weight', 'base_model.encoder.layer.19.attention.self.key.bias', 'base_model.encoder.layer.22.attention.output.LayerNorm.weight', 'base_model.encoder.layer.0.output.LayerNorm.bias', 'base_model.encoder.layer.16.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.8.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.5.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.23.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.4.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.2.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.19.attention.self.query.weight', 'base_model.encoder.layer.7.output.LayerNorm.bias', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.1.attention.self.query.weight', 'base_model.encoder.layer.17.output.dense.bias', 'base_model.encoder.layer.5.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.18.intermediate.dense.weight', 'base_model.encoder.layer.21.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.19.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.14.attention.output.LayerNorm.weight', 'base_model.encoder.layer.9.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.17.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.12.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.13.attention.output.LayerNorm.bias', 'base_model.encoder.layer.2.output.dense.weight', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.2.attention.output.LayerNorm.weight', 'base_model.encoder.layer.4.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.14.attention.output.dense.weight', 'base_model.encoder.layer.21.attention.self.key.weight', 'base_model.encoder.layer.9.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.1.attention.self.key.weight', 'base_model.encoder.layer.1.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.23.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.3.attention.self.value.bias', 'base_model.encoder.layer.21.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.3.output.LayerNorm.weight', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.18.attention.self.value.weight', 'base_model.encoder.layer.7.intermediate.dense.bias', 'base_model.encoder.layer.14.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.0.attention.self.value.bias', 'base_model.encoder.layer.13.attention.self.key.bias', 'base_model.encoder.layer.22.attention.output.dense.bias', 'base_model.encoder.layer.9.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.5.attention.self.key.bias', 'base_model.encoder.layer.5.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.8.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.7.attention.self.key.weight', 'base_model.encoder.layer.11.attention.output.dense.bias', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.16.intermediate.dense.bias', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.4.output.dense.bias', 'base_model.encoder.layer.23.attention.self.value.weight', 'base_model.encoder.layer.18.attention.self.query.weight', 'base_model.encoder.layer.0.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.1.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.7.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.0.output.dense.bias', 'base_model.encoder.layer.22.attention.self.query.weight', 'base_model.encoder.layer.19.output.dense.weight', 'base_model.embeddings.word_embeddings.weight', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.12.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.20.attention.output.dense.weight', 'base_model.encoder.layer.5.intermediate.dense.weight', 'base_model.encoder.layer.15.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.21.output.LayerNorm.weight', 'base_model.encoder.layer.22.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.23.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.7.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.8.output.LayerNorm.weight', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.1.attention.self.value.bias', 'base_model.encoder.layer.4.attention.output.dense.bias', 'base_model.encoder.layer.3.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.12.attention.self.value.bias', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.1.output.adapters.ts.adapter_down.0.weight', 'qa_outputs.weight', 'base_model.encoder.layer.15.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.11.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.2.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.16.attention.self.value.bias', 'base_model.encoder.layer.2.attention.self.value.bias', 'base_model.encoder.layer.22.output.dense.weight', 'base_model.encoder.layer.14.output.LayerNorm.weight', 'base_model.encoder.layer.17.attention.self.query.bias', 'base_model.embeddings.LayerNorm.bias', 'base_model.encoder.layer.17.intermediate.dense.weight', 'base_model.encoder.layer.3.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.19.attention.self.value.bias', 'base_model.encoder.layer.6.attention.self.query.bias', 'base_model.encoder.layer.3.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.1.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.19.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.14.attention.self.key.weight', 'base_model.encoder.layer.19.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.9.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.17.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.4.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.8.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.15.output.LayerNorm.weight', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.20.attention.self.query.weight', 'base_model.encoder.layer.10.output.LayerNorm.weight', 'base_model.encoder.layer.23.attention.output.dense.bias', 'base_model.encoder.layer.18.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.21.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.15.attention.self.query.bias', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.16.attention.output.LayerNorm.weight', 'base_model.encoder.layer.4.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.17.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.7.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.23.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.15.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.0.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.23.attention.self.query.bias', 'base_model.encoder.layer.17.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.17.intermediate.dense.bias', 'base_model.encoder.layer.10.attention.self.value.bias', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.22.attention.self.query.bias', 'base_model.encoder.layer.1.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.11.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.20.attention.output.LayerNorm.weight', 'base_model.encoder.layer.19.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.3.attention.output.LayerNorm.bias', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.21.intermediate.dense.bias', 'base_model.encoder.layer.0.attention.self.query.weight', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.1.intermediate.dense.weight', 'base_model.embeddings.LayerNorm.weight', 'base_model.encoder.layer.17.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.19.attention.output.LayerNorm.weight', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.4.attention.self.value.weight', 'base_model.encoder.layer.0.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.5.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.18.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.6.output.LayerNorm.weight', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.23.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.11.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.6.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.13.attention.self.key.weight', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.11.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.19.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.19.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.2.attention.self.key.weight', 'base_model.encoder.layer.5.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.13.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.18.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.19.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.19.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.21.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.16.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.1.output.dense.weight', 'base_model.encoder.layer.19.output.dense.bias']
- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of XLMRobertaModel were not initialized from the model checkpoint at /cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//squad/xlm-KG_LR8e-6_EPOCH2.0_maxlen384_batchsize4_gradacc4 and are newly initialized: ['encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.15.attention.self.key.bias', 'encoder.layer.11.attention.output.dense.weight', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.8.output.dense.bias', 'encoder.layer.3.attention.output.dense.weight', 'encoder.layer.20.attention.output.dense.bias', 'encoder.layer.12.attention.output.LayerNorm.bias', 'encoder.layer.12.output.dense.bias', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.17.output.LayerNorm.bias', 'encoder.layer.13.attention.self.key.bias', 'encoder.layer.23.attention.self.query.weight', 'encoder.layer.8.attention.output.dense.weight', 'encoder.layer.13.output.LayerNorm.bias', 'encoder.layer.10.attention.output.LayerNorm.weight', 'encoder.layer.18.attention.self.key.weight', 'encoder.layer.20.attention.self.query.bias', 'encoder.layer.21.output.LayerNorm.bias', 'encoder.layer.7.attention.self.query.bias', 'encoder.layer.14.attention.output.dense.bias', 'encoder.layer.9.attention.output.dense.weight', 'encoder.layer.23.output.dense.weight', 'encoder.layer.8.output.LayerNorm.weight', 'encoder.layer.20.intermediate.dense.weight', 'encoder.layer.14.output.dense.bias', 'encoder.layer.0.attention.self.query.bias', 'encoder.layer.7.output.dense.bias', 'encoder.layer.19.output.LayerNorm.bias', 'encoder.layer.13.attention.self.key.weight', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.6.attention.output.dense.bias', 'encoder.layer.7.output.dense.weight', 'encoder.layer.17.attention.self.key.weight', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.10.attention.output.dense.bias', 'pooler.dense.weight', 'encoder.layer.11.attention.self.query.bias', 'encoder.layer.12.attention.self.query.bias', 'encoder.layer.18.attention.output.LayerNorm.bias', 'encoder.layer.19.output.dense.weight', 'encoder.layer.13.attention.output.LayerNorm.bias', 'encoder.layer.6.attention.self.value.bias', 'encoder.layer.17.attention.output.LayerNorm.weight', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.8.attention.self.value.bias', 'encoder.layer.19.output.dense.bias', 'encoder.layer.5.attention.self.key.weight', 'encoder.layer.13.attention.output.LayerNorm.weight', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.12.attention.self.key.weight', 'encoder.layer.14.output.LayerNorm.weight', 'encoder.layer.8.attention.output.LayerNorm.bias', 'encoder.layer.8.attention.self.value.weight', 'encoder.layer.2.attention.output.LayerNorm.bias', 'encoder.layer.14.output.LayerNorm.bias', 'encoder.layer.11.output.LayerNorm.weight', 'encoder.layer.22.attention.self.value.weight', 'encoder.layer.19.attention.output.LayerNorm.bias', 'encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.layer.10.output.dense.bias', 'encoder.layer.10.output.LayerNorm.weight', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.18.attention.self.value.bias', 'encoder.layer.21.intermediate.dense.weight', 'encoder.layer.2.attention.self.query.weight', 'encoder.layer.19.intermediate.dense.weight', 'encoder.layer.20.output.dense.weight', 'encoder.layer.7.attention.self.value.bias', 'encoder.layer.13.attention.output.dense.bias', 'encoder.layer.13.output.dense.bias', 'encoder.layer.20.attention.output.dense.weight', 'encoder.layer.1.output.dense.weight', 'encoder.layer.3.attention.self.query.bias', 'encoder.layer.15.attention.output.LayerNorm.bias', 'encoder.layer.7.attention.self.query.weight', 'encoder.layer.22.attention.output.LayerNorm.weight', 'embeddings.LayerNorm.weight', 'encoder.layer.15.attention.self.value.bias', 'encoder.layer.7.output.LayerNorm.bias', 'encoder.layer.3.attention.self.key.weight', 'encoder.layer.8.attention.self.key.bias', 'encoder.layer.15.attention.self.value.weight', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.16.attention.output.LayerNorm.weight', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.17.output.dense.bias', 'encoder.layer.21.attention.output.dense.weight', 'encoder.layer.4.attention.output.dense.bias', 'encoder.layer.6.attention.output.LayerNorm.weight', 'encoder.layer.9.attention.output.LayerNorm.bias', 'encoder.layer.23.attention.output.dense.bias', 'encoder.layer.14.attention.self.key.weight', 'encoder.layer.4.attention.self.query.weight', 'encoder.layer.3.attention.self.value.weight', 'encoder.layer.15.intermediate.dense.weight', 'encoder.layer.9.output.dense.weight', 'encoder.layer.2.attention.output.dense.weight', 'encoder.layer.18.attention.output.dense.weight', 'encoder.layer.21.attention.output.dense.bias', 'encoder.layer.3.attention.output.dense.bias', 'encoder.layer.10.attention.self.key.weight', 'encoder.layer.16.attention.output.LayerNorm.bias', 'encoder.layer.18.attention.output.dense.bias', 'encoder.layer.4.output.dense.weight', 'encoder.layer.3.output.dense.bias', 'encoder.layer.19.attention.self.query.bias', 'encoder.layer.7.attention.output.LayerNorm.bias', 'encoder.layer.16.attention.self.key.bias', 'encoder.layer.13.intermediate.dense.weight', 'encoder.layer.5.attention.self.value.weight', 'encoder.layer.6.attention.output.dense.weight', 'encoder.layer.11.output.dense.weight', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.20.attention.output.LayerNorm.weight', 'encoder.layer.3.attention.self.value.bias', 'encoder.layer.1.attention.self.query.bias', 'encoder.layer.2.attention.output.LayerNorm.weight', 'encoder.layer.8.attention.self.key.weight', 'encoder.layer.16.attention.self.query.bias', 'encoder.layer.21.attention.self.value.weight', 'encoder.layer.0.attention.self.value.weight', 'encoder.layer.3.output.dense.weight', 'encoder.layer.2.attention.self.key.weight', 'encoder.layer.22.attention.self.query.bias', 'encoder.layer.21.output.dense.weight', 'encoder.layer.23.attention.self.key.bias', 'encoder.layer.20.attention.self.query.weight', 'encoder.layer.1.output.dense.bias', 'encoder.layer.8.attention.output.LayerNorm.weight', 'encoder.layer.5.attention.output.dense.weight', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.19.attention.self.key.weight', 'encoder.layer.23.attention.output.LayerNorm.bias', 'encoder.layer.17.attention.self.query.bias', 'encoder.layer.17.attention.output.dense.bias', 'encoder.layer.1.attention.self.key.bias', 'encoder.layer.15.attention.output.LayerNorm.weight', 'encoder.layer.11.attention.self.query.weight', 'encoder.layer.13.intermediate.dense.bias', 'encoder.layer.14.attention.output.LayerNorm.bias', 'encoder.layer.19.attention.self.value.bias', 'encoder.layer.18.attention.self.query.weight', 'encoder.layer.12.attention.self.query.weight', 'encoder.layer.22.attention.self.query.weight', 'encoder.layer.5.output.LayerNorm.bias', 'encoder.layer.9.attention.self.key.bias', 'encoder.layer.21.intermediate.dense.bias', 'encoder.layer.20.attention.self.key.weight', 'encoder.layer.7.attention.output.dense.weight', 'encoder.layer.6.attention.self.query.weight', 'encoder.layer.13.attention.self.query.bias', 'encoder.layer.0.attention.self.value.bias', 'encoder.layer.18.attention.self.value.weight', 'encoder.layer.16.attention.output.dense.bias', 'encoder.layer.13.attention.self.value.bias', 'encoder.layer.22.attention.self.value.bias', 'encoder.layer.5.attention.self.query.weight', 'encoder.layer.7.attention.output.dense.bias', 'encoder.layer.22.output.dense.weight', 'encoder.layer.1.attention.self.query.weight', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.18.attention.output.LayerNorm.weight', 'encoder.layer.16.intermediate.dense.weight', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.17.attention.output.dense.weight', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.20.attention.self.value.weight', 'encoder.layer.19.intermediate.dense.bias', 'encoder.layer.6.output.dense.bias', 'encoder.layer.17.attention.output.LayerNorm.bias', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.4.attention.output.LayerNorm.bias', 'encoder.layer.7.attention.output.LayerNorm.weight', 'encoder.layer.12.attention.self.key.bias', 'encoder.layer.5.attention.output.LayerNorm.weight', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.10.output.LayerNorm.bias', 'encoder.layer.23.attention.self.value.bias', 'encoder.layer.21.output.dense.bias', 'encoder.layer.15.attention.self.key.weight', 'encoder.layer.19.output.LayerNorm.weight', 'encoder.layer.15.intermediate.dense.bias', 'encoder.layer.9.attention.self.query.weight', 'encoder.layer.17.intermediate.dense.bias', 'encoder.layer.22.output.LayerNorm.bias', 'encoder.layer.4.attention.self.value.weight', 'encoder.layer.2.output.dense.weight', 'encoder.layer.20.output.LayerNorm.bias', 'encoder.layer.13.attention.self.value.weight', 'encoder.layer.2.attention.self.key.bias', 'encoder.layer.20.attention.self.key.bias', 'encoder.layer.15.attention.output.dense.weight', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.23.attention.self.key.weight', 'encoder.layer.18.output.dense.weight', 'encoder.layer.2.attention.self.query.bias', 'encoder.layer.8.attention.self.query.weight', 'encoder.layer.20.output.LayerNorm.weight', 'encoder.layer.6.attention.self.key.bias', 'encoder.layer.12.output.LayerNorm.bias', 'encoder.layer.4.attention.self.query.bias', 'encoder.layer.18.intermediate.dense.weight', 'encoder.layer.7.attention.self.key.weight', 'encoder.layer.12.attention.self.value.weight', 'encoder.layer.3.attention.self.key.bias', 'encoder.layer.17.attention.self.query.weight', 'encoder.layer.6.attention.output.LayerNorm.bias', 'encoder.layer.17.intermediate.dense.weight', 'encoder.layer.0.attention.output.dense.bias', 'encoder.layer.3.attention.self.query.weight', 'encoder.layer.13.output.LayerNorm.weight', 'encoder.layer.14.attention.self.query.bias', 'encoder.layer.22.attention.output.dense.bias', 'encoder.layer.11.attention.self.value.bias', 'encoder.layer.8.attention.output.dense.bias', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.17.output.LayerNorm.weight', 'encoder.layer.21.attention.self.key.weight', 'encoder.layer.12.attention.output.dense.weight', 'encoder.layer.22.intermediate.dense.bias', 'encoder.layer.13.attention.self.query.weight', 'encoder.layer.13.output.dense.weight', 'encoder.layer.10.attention.self.value.bias', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.10.intermediate.dense.weight', 'encoder.layer.12.output.LayerNorm.weight', 'encoder.layer.7.intermediate.dense.bias', 'encoder.layer.23.attention.output.LayerNorm.weight', 'encoder.layer.11.attention.self.key.weight', 'encoder.layer.16.attention.self.query.weight', 'encoder.layer.0.attention.self.query.weight', 'encoder.layer.12.intermediate.dense.weight', 'encoder.layer.22.attention.self.key.bias', 'encoder.layer.12.attention.output.dense.bias', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.15.output.dense.bias', 'encoder.layer.23.intermediate.dense.weight', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.19.attention.self.query.weight', 'encoder.layer.16.output.LayerNorm.weight', 'encoder.layer.21.attention.output.LayerNorm.weight', 'encoder.layer.5.attention.self.value.bias', 'encoder.layer.14.attention.output.LayerNorm.weight', 'encoder.layer.21.output.LayerNorm.weight', 'encoder.layer.9.attention.output.dense.bias', 'encoder.layer.2.attention.output.dense.bias', 'encoder.layer.18.intermediate.dense.bias', 'encoder.layer.12.intermediate.dense.bias', 'encoder.layer.5.output.dense.weight', 'encoder.layer.17.attention.self.value.weight', 'encoder.layer.1.attention.output.LayerNorm.weight', 'encoder.layer.9.output.LayerNorm.weight', 'encoder.layer.10.output.dense.weight', 'encoder.layer.15.attention.output.dense.bias', 'encoder.layer.6.output.LayerNorm.bias', 'encoder.layer.11.attention.output.dense.bias', 'encoder.layer.23.output.dense.bias', 'encoder.layer.5.output.dense.bias', 'encoder.layer.23.intermediate.dense.bias', 'encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.layer.9.output.LayerNorm.bias', 'encoder.layer.15.output.LayerNorm.weight', 'encoder.layer.22.attention.output.LayerNorm.bias', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.4.attention.self.value.bias', 'encoder.layer.16.output.dense.weight', 'encoder.layer.8.attention.self.query.bias', 'encoder.layer.6.attention.self.value.weight', 'encoder.layer.2.attention.self.value.bias', 'encoder.layer.1.attention.self.value.weight', 'encoder.layer.1.attention.output.dense.weight', 'encoder.layer.14.attention.self.value.bias', 'encoder.layer.9.attention.output.LayerNorm.weight', 'encoder.layer.9.attention.self.key.weight', 'embeddings.word_embeddings.weight', 'encoder.layer.22.output.LayerNorm.weight', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.14.attention.output.dense.weight', 'encoder.layer.2.output.dense.bias', 'encoder.layer.19.attention.output.LayerNorm.weight', 'encoder.layer.10.attention.output.dense.weight', 'encoder.layer.0.attention.self.key.bias', 'encoder.layer.19.attention.output.dense.weight', 'encoder.layer.7.attention.self.key.bias', 'encoder.layer.17.attention.self.key.bias', 'encoder.layer.20.attention.output.LayerNorm.bias', 'encoder.layer.16.attention.self.key.weight', 'encoder.layer.9.attention.self.value.bias', 'encoder.layer.5.attention.output.dense.bias', 'encoder.layer.22.attention.self.key.weight', 'encoder.layer.15.attention.self.query.weight', 'encoder.layer.16.attention.self.value.bias', 'encoder.layer.10.attention.self.value.weight', 'encoder.layer.0.attention.output.dense.weight', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.18.attention.self.key.bias', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.16.attention.self.value.weight', 'encoder.layer.7.attention.self.value.weight', 'encoder.layer.23.attention.self.query.bias', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.19.attention.output.dense.bias', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.16.attention.output.dense.weight', 'encoder.layer.11.output.dense.bias', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.21.attention.output.LayerNorm.bias', 'encoder.layer.14.intermediate.dense.weight', 'encoder.layer.15.output.LayerNorm.bias', 'encoder.layer.20.attention.self.value.bias', 'encoder.layer.22.output.dense.bias', 'encoder.layer.6.output.dense.weight', 'encoder.layer.14.output.dense.weight', 'pooler.dense.bias', 'encoder.layer.21.attention.self.key.bias', 'encoder.layer.6.attention.self.query.bias', 'encoder.layer.4.attention.self.key.bias', 'encoder.layer.21.attention.self.query.weight', 'encoder.layer.14.intermediate.dense.bias', 'embeddings.LayerNorm.bias', 'encoder.layer.11.attention.output.LayerNorm.weight', 'encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.layer.10.attention.self.query.weight', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.10.attention.self.key.bias', 'encoder.layer.1.attention.self.key.weight', 'encoder.layer.12.output.dense.weight', 'encoder.layer.21.attention.self.query.bias', 'encoder.layer.10.attention.self.query.bias', 'encoder.layer.11.output.LayerNorm.bias', 'encoder.layer.0.output.dense.bias', 'encoder.layer.14.attention.self.value.weight', 'encoder.layer.18.output.LayerNorm.bias', 'encoder.layer.18.output.dense.bias', 'encoder.layer.23.output.LayerNorm.bias', 'embeddings.token_type_embeddings.weight', 'encoder.layer.8.output.dense.weight', 'encoder.layer.13.attention.output.dense.weight', 'encoder.layer.14.attention.self.query.weight', 'encoder.layer.4.attention.output.dense.weight', 'encoder.layer.5.attention.self.query.bias', 'encoder.layer.2.attention.self.value.weight', 'encoder.layer.14.attention.self.key.bias', 'encoder.layer.22.intermediate.dense.weight', 'encoder.layer.16.intermediate.dense.bias', 'encoder.layer.23.attention.output.dense.weight', 'encoder.layer.21.attention.self.value.bias', 'encoder.layer.9.attention.self.query.bias', 'encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.layer.8.output.LayerNorm.bias', 'encoder.layer.9.attention.self.value.weight', 'encoder.layer.9.output.dense.bias', 'encoder.layer.1.attention.self.value.bias', 'encoder.layer.0.attention.self.key.weight', 'encoder.layer.6.attention.self.key.weight', 'encoder.layer.4.attention.self.key.weight', 'encoder.layer.16.output.dense.bias', 'encoder.layer.18.output.LayerNorm.weight', 'encoder.layer.1.attention.output.dense.bias', 'encoder.layer.19.attention.self.key.bias', 'encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.layer.0.attention.output.LayerNorm.weight', 'encoder.layer.4.attention.output.LayerNorm.weight', 'encoder.layer.11.attention.self.value.weight', 'encoder.layer.19.attention.self.value.weight', 'encoder.layer.18.attention.self.query.bias', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.22.attention.output.dense.weight', 'encoder.layer.5.attention.self.key.bias', 'encoder.layer.7.output.LayerNorm.weight', 'encoder.layer.0.output.dense.weight', 'encoder.layer.15.attention.self.query.bias', 'encoder.layer.20.output.dense.bias', 'encoder.layer.12.attention.self.value.bias', 'encoder.layer.4.output.dense.bias', 'encoder.layer.23.output.LayerNorm.weight', 'encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.23.attention.self.value.weight', 'encoder.layer.17.output.dense.weight', 'encoder.layer.11.attention.self.key.bias', 'encoder.layer.17.attention.self.value.bias', 'embeddings.position_embeddings.weight', 'encoder.layer.15.output.dense.weight', 'encoder.layer.20.intermediate.dense.bias', 'encoder.layer.16.output.LayerNorm.bias', 'encoder.layer.12.attention.output.LayerNorm.weight', 'encoder.layer.10.attention.output.LayerNorm.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Overwriting existing adapter 'ep'.
Overwriting existing adapter 'tp'.
Overwriting existing adapter 'es'.
Overwriting existing adapter 'ts'.
Overwriting existing adapter fusion module 'ep,tp,es,ts'
/cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//squad/xlm-KG_LR8e-6_EPOCH2.0_maxlen384_batchsize4_gradacc4
XLMConfig {
  "architectures": [
    "XLMRobertaForMaskedLM"
  ],
  "asm": false,
  "attention_dropout": 0.1,
  "attention_probs_dropout_prob": 0.1,
  "bos_index": 0,
  "bos_token_id": 0,
  "causal": false,
  "dropout": 0.1,
  "emb_dim": 1024,
  "embed_init_std": 0.02209708691207961,
  "end_n_top": 5,
  "eos_index": 1,
  "eos_token_id": 2,
  "gelu_activation": true,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "init_std": 0.02,
  "initializer_range": 0.02,
  "intermediate_size": 4096,
  "is_encoder": true,
  "lang_id": 0,
  "layer_norm_eps": 1e-05,
  "mask_index": 5,
  "mask_token_id": 0,
  "max_position_embeddings": 514,
  "model_type": "xlm",
  "n_heads": 16,
  "n_langs": 1,
  "n_layers": 24,
  "output_past": true,
  "pad_index": 2,
  "pad_token_id": 1,
  "sinusoidal_embeddings": false,
  "start_n_top": 5,
  "summary_activation": null,
  "summary_first_dropout": 0.1,
  "summary_proj_to_labels": true,
  "summary_type": "first",
  "summary_use_proj": true,
  "transformers_version": "4.17.0",
  "type_vocab_size": 1,
  "unk_index": 3,
  "use_lang_emb": false,
  "vocab_size": 250002
}

Traceback (most recent call last):
  File "third_party/run_squad.py", line 958, in <module>
    main()
  File "third_party/run_squad.py", line 941, in main
    load_model(model, os.path.join(args.output_dir, "pytorch_model.bin"))
  File "third_party/run_squad.py", line 98, in load_model
    model.load_state_dict(torch.load(path, map_location='cpu'), strict=False)
  File "/cluster/project/sachan/yifan/softwares/anaconda/anaconda3/envs/xfactr/lib/python3.8/site-packages/torch/serialization.py", line 581, in load
    with _open_file_like(f, 'rb') as opened_file:
  File "/cluster/project/sachan/yifan/softwares/anaconda/anaconda3/envs/xfactr/lib/python3.8/site-packages/torch/serialization.py", line 230, in _open_file_like
    return _open_file(name_or_buffer, mode)
  File "/cluster/project/sachan/yifan/softwares/anaconda/anaconda3/envs/xfactr/lib/python3.8/site-packages/torch/serialization.py", line 211, in __init__
    super(_open_file, self).__init__(open(name, mode))
FileNotFoundError: [Errno 2] No such file or directory: '/cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//squad/xlm-KG_LR8e-6_EPOCH2.0_maxlen384_batchsize4_gradacc4/predictions/mlqa/pytorch_model.bin'
mv: cannot stat ‘/cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//squad/xlm-KG_LR8e-6_EPOCH2.0_maxlen384_batchsize4_gradacc4/predictions/mlqa//predictions_en_.json’: No such file or directory
mv: cannot stat ‘/cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//squad/xlm-KG_LR8e-6_EPOCH2.0_maxlen384_batchsize4_gradacc4/predictions/mlqa//predictions_es_.json’: No such file or directory
mv: cannot stat ‘/cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//squad/xlm-KG_LR8e-6_EPOCH2.0_maxlen384_batchsize4_gradacc4/predictions/mlqa//predictions_de_.json’: No such file or directory
mv: cannot stat ‘/cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//squad/xlm-KG_LR8e-6_EPOCH2.0_maxlen384_batchsize4_gradacc4/predictions/mlqa//predictions_ar_.json’: No such file or directory
mv: cannot stat ‘/cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//squad/xlm-KG_LR8e-6_EPOCH2.0_maxlen384_batchsize4_gradacc4/predictions/mlqa//predictions_hi_.json’: No such file or directory
mv: cannot stat ‘/cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//squad/xlm-KG_LR8e-6_EPOCH2.0_maxlen384_batchsize4_gradacc4/predictions/mlqa//predictions_vi_.json’: No such file or directory
mv: cannot stat ‘/cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//squad/xlm-KG_LR8e-6_EPOCH2.0_maxlen384_batchsize4_gradacc4/predictions/mlqa//predictions_zh_.json’: No such file or directory
