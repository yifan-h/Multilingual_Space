Fine-tuning /cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/xlm-roberta-large on xquad using GPU 0
Load data from /cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/download/, and save models to /cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter/
************************
/cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/xlm-roberta-large
************************

Predictions on xquad
  en 
2022-05-09 08:55:41.377633: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0
05/09/2022 08:55:45 - WARNING - __main__ -   Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, 16-bits training: False
You are using a model of type xlm-roberta to instantiate a model of type xlm. This is not supported for all configurations of models and can yield errors.
Some weights of the model checkpoint at /cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//squad/xlm-KG_LR3e-5_EPOCH2.0_maxlen384_batchsize4_gradacc4 were not used when initializing XLMRobertaModel: ['base_model.encoder.layer.21.attention.self.value.weight', 'base_model.encoder.layer.5.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.12.attention.output.LayerNorm.weight', 'base_model.encoder.layer.15.output.dense.weight', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.9.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.7.attention.self.value.weight', 'base_model.encoder.layer.17.attention.self.query.bias', 'base_model.encoder.layer.3.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.15.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.20.attention.self.key.weight', 'base_model.encoder.layer.15.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.10.output.LayerNorm.weight', 'base_model.encoder.layer.18.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.0.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.6.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.14.output.dense.bias', 'base_model.encoder.layer.16.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.9.attention.self.query.weight', 'base_model.encoder.layer.5.attention.self.value.weight', 'base_model.encoder.layer.3.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.21.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.11.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.18.attention.output.dense.bias', 'base_model.encoder.layer.5.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.6.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.10.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.11.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.21.output.dense.weight', 'base_model.encoder.layer.9.intermediate.dense.bias', 'base_model.encoder.layer.6.output.dense.bias', 'base_model.encoder.layer.14.output.LayerNorm.weight', 'base_model.encoder.layer.11.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.12.attention.self.value.bias', 'base_model.encoder.layer.2.intermediate.dense.weight', 'base_model.encoder.layer.14.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.16.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.15.attention.output.dense.weight', 'base_model.encoder.layer.3.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.3.output.dense.bias', 'base_model.encoder.layer.4.attention.output.dense.weight', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.12.attention.self.query.bias', 'base_model.encoder.layer.3.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.3.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.5.attention.output.LayerNorm.bias', 'base_model.encoder.layer.15.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.0.attention.self.query.bias', 'base_model.encoder.layer.9.attention.output.dense.bias', 'base_model.encoder.layer.4.attention.self.query.bias', 'base_model.encoder.layer.1.attention.self.query.bias', 'base_model.encoder.layer.19.attention.self.query.bias', 'base_model.encoder.layer.7.attention.output.LayerNorm.bias', 'base_model.encoder.layer.1.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.9.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.18.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.6.output.LayerNorm.weight', 'base_model.encoder.layer.11.attention.self.query.weight', 'base_model.encoder.layer.11.attention.output.dense.weight', 'base_model.encoder.layer.0.attention.self.query.weight', 'base_model.encoder.layer.0.attention.self.value.weight', 'base_model.encoder.layer.0.attention.self.value.bias', 'base_model.encoder.layer.19.output.LayerNorm.bias', 'base_model.encoder.layer.5.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.15.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.9.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.15.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.21.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.0.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.2.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.5.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.3.attention.self.value.bias', 'base_model.encoder.layer.21.attention.output.dense.weight', 'base_model.encoder.layer.4.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.20.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.17.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.9.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.22.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.9.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.7.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.5.attention.self.key.weight', 'base_model.encoder.layer.5.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.11.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.0.output.dense.weight', 'base_model.encoder.layer.15.output.LayerNorm.bias', 'base_model.encoder.layer.21.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.21.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.3.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.11.attention.self.value.bias', 'base_model.encoder.layer.6.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.20.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.6.attention.self.query.weight', 'base_model.encoder.layer.13.attention.self.query.weight', 'base_model.encoder.layer.18.attention.output.LayerNorm.weight', 'base_model.encoder.layer.5.output.dense.bias', 'base_model.encoder.layer.1.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.22.intermediate.dense.weight', 'base_model.encoder.layer.13.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.18.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.4.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.7.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.18.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.11.output.LayerNorm.bias', 'base_model.encoder.layer.5.attention.output.dense.bias', 'base_model.encoder.layer.9.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.16.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.5.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.13.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.23.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.16.attention.self.key.weight', 'base_model.encoder.layer.22.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.0.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.16.output.dense.weight', 'base_model.encoder.layer.8.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.14.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.9.output.LayerNorm.weight', 'base_model.encoder.layer.3.output.LayerNorm.weight', 'base_model.encoder.layer.18.intermediate.dense.weight', 'base_model.encoder.layer.19.attention.output.dense.bias', 'base_model.encoder.layer.9.output.LayerNorm.bias', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.7.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.1.attention.self.key.weight', 'base_model.encoder.layer.1.output.dense.bias', 'base_model.encoder.layer.11.output.dense.weight', 'base_model.encoder.layer.1.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.7.attention.output.LayerNorm.weight', 'base_model.embeddings.token_type_embeddings.weight', 'base_model.encoder.layer.17.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.23.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.9.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.6.attention.output.LayerNorm.weight', 'base_model.encoder.layer.8.attention.self.query.bias', 'base_model.encoder.layer.9.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.14.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.4.attention.output.LayerNorm.weight', 'base_model.encoder.layer.10.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.23.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.13.output.LayerNorm.bias', 'base_model.encoder.layer.23.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.8.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.12.output.dense.weight', 'base_model.encoder.layer.10.attention.self.query.bias', 'base_model.encoder.layer.0.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.6.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.14.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.6.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.3.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.12.intermediate.dense.bias', 'base_model.encoder.layer.17.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.12.attention.output.dense.bias', 'base_model.encoder.layer.12.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.4.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.11.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.7.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.4.attention.self.query.weight', 'base_model.encoder.layer.11.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.15.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.16.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.4.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.21.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.8.attention.output.dense.weight', 'base_model.encoder.layer.19.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.20.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.7.attention.self.key.bias', 'base_model.encoder.layer.10.attention.self.value.bias', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.16.attention.output.dense.bias', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.17.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.8.attention.self.query.weight', 'base_model.encoder.layer.6.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.1.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.13.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.3.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.19.attention.self.query.weight', 'base_model.encoder.layer.11.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.1.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.5.output.LayerNorm.bias', 'base_model.encoder.layer.14.attention.output.LayerNorm.weight', 'base_model.encoder.layer.8.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.12.attention.output.LayerNorm.bias', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.23.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.9.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.16.output.adapters.es.adapter_up.weight', 'base_model.embeddings.LayerNorm.bias', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.17.attention.self.value.weight', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.15.attention.self.value.weight', 'base_model.encoder.layer.10.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.22.attention.output.LayerNorm.bias', 'base_model.encoder.layer.10.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.10.output.LayerNorm.bias', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.0.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.20.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.18.attention.self.value.bias', 'base_model.encoder.layer.16.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.18.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.22.intermediate.dense.bias', 'base_model.encoder.layer.23.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.5.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.0.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.14.attention.output.dense.weight', 'base_model.encoder.layer.16.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.23.output.LayerNorm.weight', 'base_model.encoder.layer.12.attention.self.value.weight', 'base_model.encoder.layer.3.attention.output.LayerNorm.weight', 'base_model.encoder.layer.16.output.dense.bias', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.22.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.11.output.LayerNorm.weight', 'base_model.encoder.layer.19.intermediate.dense.bias', 'base_model.encoder.layer.7.output.dense.bias', 'base_model.encoder.layer.12.attention.self.key.bias', 'base_model.encoder.layer.16.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.23.attention.output.dense.bias', 'base_model.encoder.layer.20.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.7.attention.self.value.bias', 'base_model.encoder.layer.20.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.8.attention.self.key.bias', 'base_model.encoder.layer.1.attention.output.dense.bias', 'base_model.encoder.layer.15.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.0.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.4.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.8.output.LayerNorm.weight', 'base_model.encoder.layer.7.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.20.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.19.attention.self.value.bias', 'base_model.encoder.layer.18.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.1.attention.output.dense.weight', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.0.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.1.attention.self.key.bias', 'base_model.encoder.layer.2.attention.self.query.weight', 'base_model.encoder.layer.14.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.12.output.dense.bias', 'base_model.encoder.layer.13.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.3.output.dense.weight', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.12.attention.self.key.weight', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.17.attention.self.key.weight', 'base_model.encoder.layer.0.output.dense.bias', 'base_model.encoder.layer.17.attention.output.LayerNorm.bias', 'base_model.encoder.layer.20.attention.output.LayerNorm.weight', 'base_model.encoder.layer.15.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.13.attention.self.query.bias', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.3.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.19.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.0.attention.output.dense.bias', 'base_model.encoder.layer.14.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.0.intermediate.dense.weight', 'base_model.encoder.layer.0.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.14.attention.output.LayerNorm.bias', 'base_model.encoder.layer.4.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.9.attention.output.dense.weight', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.0.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.16.attention.output.LayerNorm.bias', 'base_model.encoder.layer.19.attention.self.key.weight', 'base_model.encoder.layer.4.output.LayerNorm.bias', 'base_model.encoder.layer.22.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.22.attention.self.value.bias', 'base_model.encoder.layer.8.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.17.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.8.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.4.intermediate.dense.weight', 'base_model.encoder.layer.13.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.15.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.7.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.22.output.dense.weight', 'base_model.encoder.layer.22.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.embeddings.word_embeddings.weight', 'base_model.encoder.layer.1.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.15.attention.self.query.bias', 'base_model.encoder.layer.8.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.9.attention.output.LayerNorm.bias', 'base_model.encoder.layer.19.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.13.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.9.attention.self.key.bias', 'base_model.encoder.layer.2.attention.self.value.bias', 'base_model.encoder.layer.17.attention.output.dense.weight', 'base_model.encoder.layer.11.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.18.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.8.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.19.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.10.attention.self.key.weight', 'base_model.encoder.layer.4.output.LayerNorm.weight', 'base_model.encoder.layer.8.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.8.attention.output.LayerNorm.bias', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.6.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.13.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.16.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.21.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.12.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.2.output.dense.weight', 'base_model.encoder.layer.23.output.dense.weight', 'base_model.encoder.layer.0.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.22.attention.output.dense.weight', 'base_model.encoder.layer.0.output.adapters.tp.adapter_up.bias', 'base_model.embeddings.position_ids', 'base_model.encoder.layer.7.intermediate.dense.weight', 'base_model.encoder.layer.23.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.1.attention.output.LayerNorm.bias', 'base_model.encoder.layer.2.attention.self.key.weight', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.4.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.2.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.21.attention.output.LayerNorm.weight', 'base_model.encoder.layer.20.output.dense.weight', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.11.intermediate.dense.weight', 'base_model.encoder.layer.13.attention.output.dense.bias', 'base_model.encoder.layer.18.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.8.attention.self.value.weight', 'base_model.encoder.layer.18.attention.self.key.bias', 'base_model.encoder.layer.12.output.LayerNorm.weight', 'base_model.encoder.layer.21.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.22.attention.output.dense.bias', 'base_model.encoder.layer.0.output.LayerNorm.weight', 'base_model.encoder.layer.7.output.LayerNorm.bias', 'base_model.encoder.layer.4.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.18.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.0.attention.output.dense.weight', 'base_model.encoder.layer.14.intermediate.dense.bias', 'base_model.encoder.layer.23.attention.self.value.bias', 'base_model.encoder.layer.17.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.2.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.13.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.22.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.2.output.dense.bias', 'base_model.encoder.layer.9.output.dense.bias', 'base_model.encoder.layer.19.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.2.intermediate.dense.bias', 'base_model.encoder.layer.8.output.dense.bias', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.3.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.15.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.11.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.7.attention.output.dense.bias', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.20.attention.self.value.weight', 'base_model.encoder.layer.6.attention.output.LayerNorm.bias', 'base_model.encoder.layer.5.intermediate.dense.weight', 'base_model.encoder.layer.4.attention.output.LayerNorm.bias', 'base_model.encoder.layer.8.intermediate.dense.bias', 'base_model.encoder.layer.20.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.5.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.13.attention.self.value.weight', 'base_model.encoder.layer.18.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.21.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.5.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.18.attention.self.query.bias', 'base_model.encoder.layer.1.intermediate.dense.weight', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.19.attention.self.key.bias', 'base_model.encoder.layer.2.output.LayerNorm.bias', 'base_model.encoder.layer.13.attention.output.LayerNorm.bias', 'base_model.encoder.layer.20.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.5.intermediate.dense.bias', 'base_model.encoder.layer.7.attention.self.key.weight', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.17.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.15.attention.self.query.weight', 'base_model.encoder.layer.19.attention.self.value.weight', 'base_model.encoder.layer.10.attention.self.query.weight', 'base_model.encoder.layer.15.output.LayerNorm.weight', 'base_model.encoder.layer.19.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.16.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.10.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.7.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.23.attention.output.LayerNorm.weight', 'base_model.encoder.layer.17.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.3.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.6.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.6.attention.self.query.bias', 'base_model.pooler.dense.bias', 'base_model.encoder.layer.5.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.11.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.10.attention.output.dense.bias', 'base_model.encoder.layer.5.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.11.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.16.attention.output.dense.weight', 'base_model.encoder.layer.0.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.6.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.18.attention.self.query.weight', 'base_model.encoder.layer.19.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.22.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.2.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.11.attention.output.dense.bias', 'base_model.encoder.layer.4.attention.self.value.bias', 'base_model.encoder.layer.18.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.12.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.23.attention.self.query.bias', 'base_model.encoder.layer.4.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.23.intermediate.dense.bias', 'base_model.encoder.layer.19.intermediate.dense.weight', 'base_model.encoder.layer.21.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.1.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.7.output.LayerNorm.weight', 'base_model.encoder.layer.13.attention.self.key.bias', 'base_model.encoder.layer.1.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.23.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.0.output.LayerNorm.bias', 'base_model.encoder.layer.16.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.21.attention.self.key.bias', 'base_model.encoder.layer.22.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.2.attention.output.LayerNorm.bias', 'base_model.encoder.layer.3.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.21.attention.self.value.bias', 'base_model.encoder.layer.17.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.23.attention.output.dense.weight', 'base_model.encoder.layer.4.intermediate.dense.bias', 'base_model.encoder.layer.6.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.4.output.dense.bias', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.6.attention.output.dense.weight', 'base_model.encoder.layer.1.output.LayerNorm.bias', 'base_model.encoder.layer.2.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.17.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.1.output.dense.weight', 'base_model.encoder.layer.9.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.13.output.LayerNorm.weight', 'base_model.encoder.layer.17.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.15.attention.output.LayerNorm.bias', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.12.attention.output.dense.weight', 'base_model.encoder.layer.19.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.18.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.22.attention.self.value.weight', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.9.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.13.attention.output.LayerNorm.weight', 'base_model.encoder.layer.2.attention.self.key.bias', 'base_model.encoder.layer.15.attention.output.dense.bias', 'base_model.encoder.layer.12.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.15.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.8.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.1.attention.self.value.weight', 'base_model.encoder.layer.14.intermediate.dense.weight', 'base_model.encoder.layer.11.intermediate.dense.bias', 'base_model.encoder.layer.12.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.17.output.dense.weight', 'base_model.encoder.layer.3.attention.self.value.weight', 'base_model.encoder.layer.15.attention.output.LayerNorm.weight', 'base_model.encoder.layer.18.attention.self.value.weight', 'base_model.encoder.layer.9.attention.self.value.bias', 'base_model.encoder.layer.17.output.LayerNorm.weight', 'base_model.encoder.layer.10.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.23.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.0.intermediate.dense.bias', 'base_model.encoder.layer.8.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.14.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.7.attention.output.dense.weight', 'base_model.encoder.layer.13.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.16.attention.self.query.weight', 'base_model.encoder.layer.10.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.18.output.LayerNorm.bias', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.18.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.11.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.10.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.1.attention.self.query.weight', 'base_model.encoder.layer.1.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.20.attention.self.value.bias', 'base_model.encoder.layer.22.attention.output.LayerNorm.weight', 'base_model.encoder.layer.16.attention.self.value.weight', 'base_model.encoder.layer.5.attention.output.dense.weight', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.17.attention.output.LayerNorm.weight', 'base_model.encoder.layer.2.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.6.attention.self.value.weight', 'base_model.encoder.layer.21.output.LayerNorm.weight', 'base_model.encoder.layer.13.attention.self.key.weight', 'base_model.encoder.layer.23.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.12.attention.self.query.weight', 'base_model.encoder.layer.0.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.19.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.1.output.LayerNorm.weight', 'base_model.encoder.layer.3.attention.output.dense.bias', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.10.attention.output.LayerNorm.bias', 'base_model.encoder.layer.11.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.13.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.23.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.19.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.9.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.4.attention.self.value.weight', 'base_model.encoder.layer.9.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.12.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.12.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.22.attention.self.query.bias', 'base_model.encoder.layer.6.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.0.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.7.intermediate.dense.bias', 'base_model.encoder.layer.7.attention.self.query.bias', 'base_model.encoder.layer.9.attention.output.LayerNorm.weight', 'base_model.encoder.layer.2.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.3.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.10.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.21.attention.output.LayerNorm.bias', 'base_model.encoder.layer.2.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.embeddings.position_embeddings.weight', 'base_model.encoder.layer.8.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.embeddings.LayerNorm.weight', 'base_model.encoder.layer.3.attention.output.dense.weight', 'base_model.encoder.layer.10.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.11.attention.self.key.bias', 'base_model.encoder.layer.11.output.dense.bias', 'base_model.encoder.layer.13.output.dense.weight', 'base_model.encoder.layer.12.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.20.attention.self.query.bias', 'base_model.encoder.layer.23.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.17.intermediate.dense.bias', 'base_model.encoder.layer.4.attention.self.key.weight', 'base_model.encoder.layer.12.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.7.output.dense.weight', 'base_model.encoder.layer.21.attention.self.query.bias', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.15.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.14.output.LayerNorm.bias', 'base_model.encoder.layer.18.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.19.output.dense.weight', 'base_model.encoder.layer.3.attention.self.key.bias', 'base_model.encoder.layer.3.output.LayerNorm.bias', 'base_model.encoder.layer.18.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.2.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.13.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.10.attention.self.key.bias', 'base_model.encoder.layer.13.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.22.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.20.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.17.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.5.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.19.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.16.output.LayerNorm.bias', 'base_model.encoder.layer.10.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.23.attention.self.query.weight', 'base_model.encoder.layer.20.attention.output.dense.weight', 'base_model.encoder.layer.23.output.LayerNorm.bias', 'base_model.encoder.layer.6.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.14.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.11.attention.output.LayerNorm.weight', 'base_model.encoder.layer.17.attention.self.value.bias', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.11.attention.self.value.weight', 'base_model.encoder.layer.19.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.20.output.dense.bias', 'base_model.encoder.layer.5.attention.self.query.weight', 'base_model.encoder.layer.4.output.dense.weight', 'base_model.encoder.layer.2.output.LayerNorm.weight', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.14.output.dense.weight', 'base_model.encoder.layer.6.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.15.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.13.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.9.attention.self.value.weight', 'base_model.encoder.layer.1.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.22.output.dense.bias', 'base_model.encoder.layer.20.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.21.intermediate.dense.weight', 'base_model.encoder.layer.4.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.20.intermediate.dense.bias', 'base_model.encoder.layer.2.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.9.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.10.attention.output.LayerNorm.weight', 'base_model.encoder.layer.17.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.15.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.1.intermediate.dense.bias', 'base_model.encoder.layer.14.attention.self.key.bias', 'base_model.encoder.layer.20.output.adapters.tp.adapter_down.0.bias', 'qa_outputs.bias', 'base_model.encoder.layer.12.output.LayerNorm.bias', 'base_model.encoder.layer.22.output.LayerNorm.weight', 'base_model.encoder.layer.7.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.13.attention.output.dense.weight', 'base_model.encoder.layer.2.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.11.attention.output.LayerNorm.bias', 'base_model.encoder.layer.19.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.21.attention.self.key.weight', 'base_model.encoder.layer.14.attention.output.dense.bias', 'base_model.encoder.layer.15.attention.self.value.bias', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.16.attention.self.query.bias', 'base_model.encoder.layer.7.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.13.intermediate.dense.weight', 'base_model.encoder.layer.22.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.17.attention.output.dense.bias', 'base_model.encoder.layer.15.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.6.output.dense.weight', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.1.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.7.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.11.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.20.attention.self.key.bias', 'base_model.encoder.layer.21.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.10.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.5.output.LayerNorm.weight', 'base_model.encoder.layer.3.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.3.intermediate.dense.bias', 'base_model.encoder.layer.20.output.LayerNorm.bias', 'base_model.encoder.layer.22.attention.self.key.bias', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.4.attention.output.dense.bias', 'base_model.encoder.layer.2.attention.output.LayerNorm.weight', 'base_model.encoder.layer.10.output.dense.bias', 'base_model.encoder.layer.2.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.0.attention.output.LayerNorm.weight', 'base_model.encoder.layer.17.output.dense.bias', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.2.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.21.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.23.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.20.attention.output.LayerNorm.bias', 'base_model.encoder.layer.22.output.LayerNorm.bias', 'base_model.encoder.layer.16.attention.output.LayerNorm.weight', 'base_model.encoder.layer.20.output.LayerNorm.weight', 'base_model.encoder.layer.10.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.12.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.9.attention.self.key.weight', 'base_model.encoder.layer.6.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.21.output.LayerNorm.bias', 'base_model.encoder.layer.23.attention.output.LayerNorm.bias', 'base_model.encoder.layer.5.attention.self.value.bias', 'base_model.encoder.layer.13.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.4.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.18.attention.output.dense.weight', 'base_model.encoder.layer.11.attention.self.query.bias', 'base_model.encoder.layer.5.attention.self.query.bias', 'base_model.encoder.layer.1.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.16.intermediate.dense.weight', 'base_model.encoder.layer.14.attention.self.query.weight', 'base_model.encoder.layer.17.output.LayerNorm.bias', 'base_model.encoder.layer.18.output.dense.bias', 'base_model.encoder.layer.22.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.19.attention.output.dense.weight', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.22.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.6.attention.self.value.bias', 'base_model.encoder.layer.9.attention.self.query.bias', 'base_model.encoder.layer.9.output.dense.weight', 'base_model.encoder.layer.12.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.5.output.dense.weight', 'base_model.encoder.layer.4.attention.self.key.bias', 'base_model.encoder.layer.23.attention.self.key.bias', 'base_model.encoder.layer.20.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.11.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.15.attention.self.key.weight', 'base_model.encoder.layer.17.attention.self.query.weight', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.8.attention.output.dense.bias', 'base_model.encoder.layer.10.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.15.intermediate.dense.weight', 'base_model.encoder.layer.10.intermediate.dense.bias', 'base_model.encoder.layer.16.attention.self.key.bias', 'base_model.encoder.layer.9.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.14.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.0.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.8.attention.self.key.weight', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.7.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.9.intermediate.dense.weight', 'base_model.encoder.layer.10.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.13.attention.self.value.bias', 'base_model.encoder.layer.17.intermediate.dense.weight', 'base_model.encoder.layer.22.attention.self.query.weight', 'base_model.encoder.layer.17.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.15.attention.self.key.bias', 'base_model.encoder.layer.22.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.14.attention.self.value.bias', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.12.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.1.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.14.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.19.attention.output.LayerNorm.bias', 'base_model.encoder.layer.0.attention.self.key.weight', 'base_model.encoder.layer.6.intermediate.dense.bias', 'base_model.encoder.layer.17.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.4.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.1.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.13.intermediate.dense.bias', 'base_model.encoder.layer.2.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.10.output.dense.weight', 'base_model.encoder.layer.21.output.dense.bias', 'base_model.encoder.layer.13.output.dense.bias', 'base_model.encoder.layer.20.attention.output.dense.bias', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.18.output.dense.weight', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.23.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.2.attention.output.dense.bias', 'base_model.encoder.layer.5.attention.self.key.bias', 'base_model.encoder.layer.15.intermediate.dense.bias', 'base_model.encoder.layer.7.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.14.attention.self.query.bias', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.2.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.9.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.1.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.13.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.2.attention.self.value.weight', 'base_model.encoder.layer.20.intermediate.dense.weight', 'base_model.encoder.layer.21.intermediate.dense.bias', 'base_model.encoder.layer.11.output.adapters.ts.adapter_up.bias', 'qa_outputs.weight', 'base_model.encoder.layer.21.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.8.output.dense.weight', 'base_model.encoder.layer.16.output.LayerNorm.weight', 'base_model.encoder.layer.3.attention.self.query.bias', 'base_model.encoder.layer.6.attention.self.key.weight', 'base_model.encoder.layer.12.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.14.attention.self.key.weight', 'base_model.encoder.layer.3.attention.output.LayerNorm.bias', 'base_model.encoder.layer.22.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.12.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.1.attention.output.LayerNorm.weight', 'base_model.encoder.layer.5.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.23.intermediate.dense.weight', 'base_model.encoder.layer.23.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.7.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.14.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.18.attention.output.LayerNorm.bias', 'base_model.encoder.layer.6.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.3.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.4.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.17.attention.self.key.bias', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.7.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.17.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.20.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.21.attention.output.dense.bias', 'base_model.encoder.layer.4.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.5.attention.output.LayerNorm.weight', 'base_model.encoder.layer.3.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.15.output.dense.bias', 'base_model.encoder.layer.19.output.dense.bias', 'base_model.encoder.layer.2.attention.output.dense.weight', 'base_model.encoder.layer.8.attention.self.value.bias', 'base_model.encoder.layer.0.attention.output.LayerNorm.bias', 'base_model.encoder.layer.11.attention.self.key.weight', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.19.attention.output.LayerNorm.weight', 'base_model.encoder.layer.22.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.5.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.10.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.16.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.14.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.22.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.23.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.21.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.14.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.1.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.5.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.16.intermediate.dense.bias', 'base_model.encoder.layer.8.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.14.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.14.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.6.attention.output.dense.bias', 'base_model.encoder.layer.18.output.LayerNorm.weight', 'base_model.encoder.layer.8.output.LayerNorm.bias', 'base_model.encoder.layer.5.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.18.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.16.attention.self.value.bias', 'base_model.encoder.layer.8.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.10.intermediate.dense.weight', 'base_model.encoder.layer.16.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.7.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.10.attention.self.value.weight', 'base_model.encoder.layer.8.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.8.intermediate.dense.weight', 'base_model.encoder.layer.18.intermediate.dense.bias', 'base_model.encoder.layer.20.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.1.attention.self.value.bias', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.3.attention.self.key.weight', 'base_model.encoder.layer.21.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.14.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.3.attention.self.query.weight', 'base_model.encoder.layer.19.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.21.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.21.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.21.attention.self.query.weight', 'base_model.encoder.layer.19.output.LayerNorm.weight', 'base_model.encoder.layer.0.attention.self.key.bias', 'base_model.encoder.layer.19.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.7.attention.self.query.weight', 'base_model.encoder.layer.12.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.4.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.2.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.16.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.6.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.16.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.18.attention.self.key.weight', 'base_model.encoder.layer.4.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.3.intermediate.dense.weight', 'base_model.encoder.layer.12.intermediate.dense.weight', 'base_model.encoder.layer.12.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.2.attention.self.query.bias', 'base_model.pooler.dense.weight', 'base_model.encoder.layer.23.attention.self.key.weight', 'base_model.encoder.layer.8.attention.output.LayerNorm.weight', 'base_model.encoder.layer.6.output.LayerNorm.bias', 'base_model.encoder.layer.16.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.20.attention.self.query.weight', 'base_model.encoder.layer.20.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.15.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.7.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.6.intermediate.dense.weight', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.8.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.8.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.10.attention.output.dense.weight', 'base_model.encoder.layer.22.attention.self.key.weight', 'base_model.encoder.layer.19.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.23.attention.self.value.weight', 'base_model.encoder.layer.14.attention.self.value.weight', 'base_model.encoder.layer.23.output.dense.bias', 'base_model.encoder.layer.6.attention.self.key.bias', 'base_model.encoder.layer.13.output.adapters.ts.adapter_down.0.bias']
- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of XLMRobertaModel were not initialized from the model checkpoint at /cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//squad/xlm-KG_LR3e-5_EPOCH2.0_maxlen384_batchsize4_gradacc4 and are newly initialized: ['encoder.layer.18.attention.output.LayerNorm.weight', 'encoder.layer.15.attention.self.value.weight', 'encoder.layer.4.attention.self.key.weight', 'encoder.layer.20.attention.self.value.bias', 'encoder.layer.23.attention.self.value.bias', 'encoder.layer.11.attention.output.LayerNorm.weight', 'encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.layer.1.attention.self.key.bias', 'encoder.layer.7.output.LayerNorm.weight', 'encoder.layer.5.output.LayerNorm.bias', 'encoder.layer.22.attention.self.key.weight', 'encoder.layer.12.attention.output.dense.bias', 'encoder.layer.8.attention.self.value.weight', 'embeddings.LayerNorm.bias', 'encoder.layer.2.attention.output.LayerNorm.bias', 'encoder.layer.20.attention.self.key.weight', 'encoder.layer.22.attention.self.query.weight', 'encoder.layer.9.attention.output.dense.weight', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.0.attention.output.dense.weight', 'encoder.layer.4.attention.output.LayerNorm.weight', 'encoder.layer.12.output.dense.bias', 'encoder.layer.3.attention.self.value.weight', 'encoder.layer.10.attention.output.LayerNorm.bias', 'embeddings.word_embeddings.weight', 'encoder.layer.22.attention.output.LayerNorm.bias', 'encoder.layer.9.attention.self.value.weight', 'encoder.layer.9.output.LayerNorm.bias', 'encoder.layer.3.output.dense.bias', 'encoder.layer.2.attention.self.query.weight', 'encoder.layer.3.attention.self.key.weight', 'encoder.layer.16.attention.output.dense.bias', 'embeddings.LayerNorm.weight', 'encoder.layer.5.attention.self.key.weight', 'encoder.layer.6.output.dense.weight', 'encoder.layer.21.attention.self.query.bias', 'encoder.layer.10.attention.self.value.weight', 'encoder.layer.12.attention.self.key.weight', 'encoder.layer.15.output.LayerNorm.bias', 'encoder.layer.15.output.LayerNorm.weight', 'encoder.layer.13.attention.self.key.weight', 'encoder.layer.11.attention.self.query.bias', 'encoder.layer.11.attention.output.dense.weight', 'encoder.layer.1.attention.self.value.weight', 'encoder.layer.21.attention.output.dense.weight', 'encoder.layer.18.attention.output.dense.weight', 'encoder.layer.2.attention.self.value.bias', 'encoder.layer.2.output.dense.bias', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.1.output.dense.weight', 'encoder.layer.10.attention.self.key.bias', 'encoder.layer.20.attention.output.LayerNorm.bias', 'encoder.layer.0.attention.self.value.weight', 'encoder.layer.15.intermediate.dense.bias', 'encoder.layer.19.output.LayerNorm.weight', 'encoder.layer.6.output.dense.bias', 'encoder.layer.14.intermediate.dense.bias', 'encoder.layer.16.attention.self.query.weight', 'encoder.layer.17.attention.self.query.weight', 'encoder.layer.12.output.LayerNorm.bias', 'encoder.layer.11.attention.self.key.bias', 'encoder.layer.10.attention.self.query.bias', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.16.attention.self.value.bias', 'encoder.layer.13.output.LayerNorm.bias', 'encoder.layer.21.attention.output.dense.bias', 'encoder.layer.8.output.LayerNorm.bias', 'encoder.layer.10.output.dense.weight', 'encoder.layer.3.attention.self.value.bias', 'encoder.layer.17.attention.self.key.weight', 'encoder.layer.8.attention.output.LayerNorm.bias', 'encoder.layer.12.attention.self.value.weight', 'encoder.layer.19.output.LayerNorm.bias', 'encoder.layer.20.output.LayerNorm.bias', 'encoder.layer.12.attention.output.dense.weight', 'encoder.layer.14.attention.self.key.bias', 'encoder.layer.13.attention.self.query.bias', 'encoder.layer.17.output.LayerNorm.weight', 'encoder.layer.1.attention.self.query.weight', 'encoder.layer.6.attention.output.dense.bias', 'encoder.layer.9.attention.self.key.bias', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.16.attention.self.key.weight', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.2.attention.output.LayerNorm.weight', 'encoder.layer.15.attention.self.key.bias', 'encoder.layer.23.attention.output.dense.bias', 'encoder.layer.14.attention.self.value.weight', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.22.attention.self.value.weight', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.15.output.dense.bias', 'encoder.layer.7.attention.output.dense.weight', 'encoder.layer.9.attention.output.dense.bias', 'encoder.layer.17.output.dense.bias', 'encoder.layer.15.output.dense.weight', 'encoder.layer.9.attention.self.key.weight', 'encoder.layer.19.attention.self.query.weight', 'encoder.layer.14.attention.output.LayerNorm.bias', 'encoder.layer.16.attention.output.LayerNorm.weight', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.6.attention.output.dense.weight', 'encoder.layer.13.attention.self.query.weight', 'encoder.layer.23.attention.output.LayerNorm.weight', 'encoder.layer.2.attention.output.dense.weight', 'encoder.layer.18.output.dense.bias', 'encoder.layer.22.attention.self.query.bias', 'encoder.layer.16.attention.output.LayerNorm.bias', 'encoder.layer.22.output.dense.weight', 'encoder.layer.12.output.dense.weight', 'encoder.layer.12.intermediate.dense.bias', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.11.output.dense.weight', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.15.attention.self.query.bias', 'encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.layer.5.attention.output.dense.weight', 'encoder.layer.6.output.LayerNorm.bias', 'encoder.layer.23.intermediate.dense.bias', 'encoder.layer.18.attention.self.query.bias', 'encoder.layer.1.attention.self.key.weight', 'encoder.layer.7.attention.output.LayerNorm.weight', 'encoder.layer.2.attention.self.key.bias', 'encoder.layer.20.attention.self.key.bias', 'encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.layer.23.attention.self.key.bias', 'encoder.layer.8.attention.output.LayerNorm.weight', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.7.attention.self.key.bias', 'encoder.layer.11.output.LayerNorm.weight', 'encoder.layer.7.attention.self.query.weight', 'encoder.layer.2.attention.output.dense.bias', 'encoder.layer.20.output.dense.weight', 'encoder.layer.17.attention.self.query.bias', 'encoder.layer.14.attention.self.key.weight', 'encoder.layer.11.attention.self.key.weight', 'encoder.layer.11.output.dense.bias', 'encoder.layer.8.output.LayerNorm.weight', 'encoder.layer.23.attention.self.value.weight', 'encoder.layer.22.attention.self.key.bias', 'encoder.layer.18.attention.self.key.weight', 'encoder.layer.18.output.LayerNorm.bias', 'encoder.layer.2.attention.self.query.bias', 'encoder.layer.15.attention.output.LayerNorm.weight', 'encoder.layer.20.intermediate.dense.weight', 'encoder.layer.10.intermediate.dense.bias', 'embeddings.position_embeddings.weight', 'encoder.layer.11.attention.output.dense.bias', 'encoder.layer.17.attention.output.dense.weight', 'encoder.layer.10.attention.output.dense.bias', 'encoder.layer.22.attention.output.dense.bias', 'encoder.layer.3.attention.output.dense.weight', 'encoder.layer.4.output.dense.bias', 'encoder.layer.0.attention.self.query.bias', 'encoder.layer.11.attention.self.query.weight', 'encoder.layer.10.attention.self.key.weight', 'encoder.layer.13.output.LayerNorm.weight', 'encoder.layer.18.output.LayerNorm.weight', 'encoder.layer.23.output.dense.weight', 'encoder.layer.16.attention.self.query.bias', 'encoder.layer.19.attention.self.key.weight', 'encoder.layer.23.attention.self.query.bias', 'encoder.layer.14.output.LayerNorm.bias', 'encoder.layer.21.attention.self.value.bias', 'encoder.layer.13.attention.output.dense.bias', 'encoder.layer.18.output.dense.weight', 'encoder.layer.19.output.dense.bias', 'encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.layer.4.attention.self.query.weight', 'encoder.layer.0.output.dense.weight', 'encoder.layer.17.attention.output.LayerNorm.weight', 'encoder.layer.17.output.dense.weight', 'encoder.layer.1.attention.self.query.bias', 'encoder.layer.22.attention.output.LayerNorm.weight', 'encoder.layer.8.attention.self.key.weight', 'encoder.layer.23.output.LayerNorm.weight', 'encoder.layer.10.output.dense.bias', 'encoder.layer.0.output.dense.bias', 'encoder.layer.2.attention.self.value.weight', 'encoder.layer.2.output.dense.weight', 'encoder.layer.12.attention.self.key.bias', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.12.attention.self.value.bias', 'encoder.layer.8.attention.output.dense.weight', 'encoder.layer.20.output.LayerNorm.weight', 'encoder.layer.13.attention.self.value.bias', 'encoder.layer.10.output.LayerNorm.bias', 'encoder.layer.8.attention.self.key.bias', 'encoder.layer.16.intermediate.dense.weight', 'encoder.layer.0.attention.output.dense.bias', 'encoder.layer.19.attention.output.LayerNorm.bias', 'encoder.layer.16.output.LayerNorm.bias', 'encoder.layer.1.attention.output.dense.bias', 'encoder.layer.4.attention.output.dense.bias', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.5.attention.self.query.weight', 'encoder.layer.22.output.LayerNorm.bias', 'encoder.layer.19.attention.self.value.bias', 'encoder.layer.11.output.LayerNorm.bias', 'encoder.layer.16.attention.output.dense.weight', 'encoder.layer.21.attention.self.key.bias', 'encoder.layer.23.attention.self.key.weight', 'encoder.layer.7.output.dense.bias', 'encoder.layer.23.intermediate.dense.weight', 'encoder.layer.20.attention.output.dense.weight', 'encoder.layer.19.attention.output.LayerNorm.weight', 'encoder.layer.12.attention.self.query.bias', 'encoder.layer.19.attention.output.dense.bias', 'encoder.layer.16.output.dense.weight', 'encoder.layer.16.intermediate.dense.bias', 'encoder.layer.7.output.LayerNorm.bias', 'encoder.layer.13.attention.output.LayerNorm.bias', 'pooler.dense.weight', 'encoder.layer.20.output.dense.bias', 'encoder.layer.3.output.dense.weight', 'encoder.layer.1.attention.output.LayerNorm.weight', 'encoder.layer.23.output.LayerNorm.bias', 'encoder.layer.13.attention.output.LayerNorm.weight', 'encoder.layer.13.output.dense.weight', 'encoder.layer.17.intermediate.dense.weight', 'encoder.layer.5.output.dense.weight', 'encoder.layer.4.output.dense.weight', 'encoder.layer.18.attention.output.dense.bias', 'encoder.layer.17.output.LayerNorm.bias', 'encoder.layer.5.attention.self.value.bias', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.10.intermediate.dense.weight', 'encoder.layer.0.attention.self.value.bias', 'encoder.layer.15.attention.self.query.weight', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.10.attention.output.dense.weight', 'encoder.layer.14.intermediate.dense.weight', 'encoder.layer.13.intermediate.dense.bias', 'encoder.layer.15.attention.self.key.weight', 'encoder.layer.19.intermediate.dense.weight', 'encoder.layer.13.output.dense.bias', 'encoder.layer.7.attention.output.dense.bias', 'encoder.layer.17.attention.output.LayerNorm.bias', 'encoder.layer.7.attention.self.value.bias', 'encoder.layer.15.attention.output.LayerNorm.bias', 'encoder.layer.7.attention.self.query.bias', 'encoder.layer.7.intermediate.dense.bias', 'encoder.layer.23.output.dense.bias', 'encoder.layer.1.attention.output.dense.weight', 'encoder.layer.20.intermediate.dense.bias', 'encoder.layer.19.intermediate.dense.bias', 'encoder.layer.8.attention.self.value.bias', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.20.attention.output.dense.bias', 'encoder.layer.7.output.dense.weight', 'encoder.layer.21.attention.output.LayerNorm.bias', 'encoder.layer.18.attention.self.query.weight', 'encoder.layer.4.attention.self.key.bias', 'encoder.layer.8.output.dense.bias', 'encoder.layer.3.attention.output.dense.bias', 'encoder.layer.18.attention.self.key.bias', 'encoder.layer.19.attention.self.value.weight', 'encoder.layer.7.attention.self.value.weight', 'encoder.layer.10.output.LayerNorm.weight', 'encoder.layer.22.output.dense.bias', 'encoder.layer.21.attention.self.key.weight', 'encoder.layer.2.attention.self.key.weight', 'encoder.layer.1.output.dense.bias', 'encoder.layer.14.attention.output.dense.bias', 'encoder.layer.5.attention.output.LayerNorm.weight', 'encoder.layer.5.intermediate.dense.weight', 'pooler.dense.bias', 'encoder.layer.15.intermediate.dense.weight', 'encoder.layer.4.attention.output.dense.weight', 'encoder.layer.3.attention.self.key.bias', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.6.attention.self.key.weight', 'encoder.layer.8.attention.self.query.bias', 'encoder.layer.6.attention.self.key.bias', 'encoder.layer.0.attention.self.key.bias', 'encoder.layer.21.output.LayerNorm.weight', 'encoder.layer.6.attention.self.query.bias', 'encoder.layer.23.attention.self.query.weight', 'encoder.layer.12.intermediate.dense.weight', 'encoder.layer.4.attention.self.value.bias', 'encoder.layer.14.attention.self.query.weight', 'encoder.layer.13.attention.self.key.bias', 'encoder.layer.21.attention.output.LayerNorm.weight', 'encoder.layer.18.attention.output.LayerNorm.bias', 'encoder.layer.14.attention.self.value.bias', 'encoder.layer.8.attention.self.query.weight', 'encoder.layer.1.attention.self.value.bias', 'encoder.layer.16.output.LayerNorm.weight', 'encoder.layer.14.output.LayerNorm.weight', 'encoder.layer.15.attention.output.dense.weight', 'encoder.layer.9.attention.self.query.weight', 'encoder.layer.21.attention.self.query.weight', 'encoder.layer.5.attention.self.query.bias', 'encoder.layer.17.attention.self.key.bias', 'encoder.layer.9.output.dense.bias', 'encoder.layer.4.attention.output.LayerNorm.bias', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.22.output.LayerNorm.weight', 'encoder.layer.18.attention.self.value.bias', 'encoder.layer.6.attention.self.query.weight', 'encoder.layer.20.attention.self.value.weight', 'encoder.layer.22.attention.output.dense.weight', 'encoder.layer.10.attention.self.value.bias', 'encoder.layer.15.attention.output.dense.bias', 'encoder.layer.22.intermediate.dense.bias', 'encoder.layer.18.attention.self.value.weight', 'encoder.layer.22.attention.self.value.bias', 'encoder.layer.16.attention.self.key.bias', 'encoder.layer.17.attention.self.value.bias', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.9.output.LayerNorm.weight', 'encoder.layer.7.attention.self.key.weight', 'encoder.layer.9.output.dense.weight', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.20.attention.self.query.bias', 'encoder.layer.5.attention.self.key.bias', 'encoder.layer.14.output.dense.weight', 'encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.layer.15.attention.self.value.bias', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.21.intermediate.dense.bias', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.5.attention.output.dense.bias', 'encoder.layer.18.intermediate.dense.weight', 'encoder.layer.21.output.dense.weight', 'encoder.layer.6.attention.output.LayerNorm.weight', 'encoder.layer.6.attention.output.LayerNorm.bias', 'encoder.layer.3.attention.self.query.bias', 'encoder.layer.10.attention.output.LayerNorm.weight', 'encoder.layer.21.attention.self.value.weight', 'encoder.layer.18.intermediate.dense.bias', 'encoder.layer.6.attention.self.value.weight', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.14.output.dense.bias', 'encoder.layer.11.attention.self.value.bias', 'encoder.layer.9.attention.self.query.bias', 'encoder.layer.21.intermediate.dense.weight', 'encoder.layer.12.output.LayerNorm.weight', 'encoder.layer.6.attention.self.value.bias', 'encoder.layer.19.attention.self.query.bias', 'encoder.layer.5.output.dense.bias', 'encoder.layer.22.intermediate.dense.weight', 'encoder.layer.11.attention.self.value.weight', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.8.output.dense.weight', 'encoder.layer.9.attention.output.LayerNorm.bias', 'encoder.layer.14.attention.output.dense.weight', 'encoder.layer.14.attention.self.query.bias', 'encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.23.attention.output.LayerNorm.bias', 'encoder.layer.16.output.dense.bias', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.9.attention.output.LayerNorm.weight', 'encoder.layer.17.attention.output.dense.bias', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.9.attention.self.value.bias', 'encoder.layer.13.attention.output.dense.weight', 'encoder.layer.5.attention.self.value.weight', 'encoder.layer.17.intermediate.dense.bias', 'encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.layer.3.attention.self.query.weight', 'encoder.layer.16.attention.self.value.weight', 'encoder.layer.14.attention.output.LayerNorm.weight', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.20.attention.self.query.weight', 'encoder.layer.4.attention.self.query.bias', 'encoder.layer.7.attention.output.LayerNorm.bias', 'encoder.layer.12.attention.output.LayerNorm.weight', 'encoder.layer.8.attention.output.dense.bias', 'encoder.layer.0.attention.self.query.weight', 'encoder.layer.17.attention.self.value.weight', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.19.attention.self.key.bias', 'encoder.layer.12.attention.self.query.weight', 'encoder.layer.20.attention.output.LayerNorm.weight', 'encoder.layer.13.intermediate.dense.weight', 'encoder.layer.19.output.dense.weight', 'encoder.layer.13.attention.self.value.weight', 'encoder.layer.10.attention.self.query.weight', 'encoder.layer.19.attention.output.dense.weight', 'encoder.layer.4.attention.self.value.weight', 'encoder.layer.23.attention.output.dense.weight', 'encoder.layer.0.attention.output.LayerNorm.weight', 'embeddings.token_type_embeddings.weight', 'encoder.layer.0.attention.self.key.weight', 'encoder.layer.21.output.dense.bias', 'encoder.layer.12.attention.output.LayerNorm.bias', 'encoder.layer.21.output.LayerNorm.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Overwriting existing adapter 'ep'.
Overwriting existing adapter 'tp'.
Overwriting existing adapter 'es'.
Overwriting existing adapter 'ts'.
Overwriting existing adapter fusion module 'ep,tp,es,ts'
05/09/2022 08:56:13 - INFO - __main__ -   lang2id = None
05/09/2022 08:56:18 - INFO - __main__ -   Training/evaluation parameters Namespace(adam_epsilon=1e-08, cache_dir='', config_name='', data_dir=None, device=device(type='cuda'), do_eval=True, do_lower_case=False, do_train=False, doc_stride=128, eval_all_checkpoints=False, eval_lang='en', evaluate_during_training=False, fp16=False, fp16_opt_level='O1', gradient_accumulation_steps=1, learning_rate=5e-05, local_rank=-1, logging_steps=50, max_answer_length=30, max_grad_norm=1.0, max_query_length=64, max_seq_length=384, max_steps=-1, model_name='xlm-KG', model_name_or_path='/cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//squad/xlm-KG_LR3e-5_EPOCH2.0_maxlen384_batchsize4_gradacc4', model_type='xlm', modelkg_dir='/cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/adapter/xlmr_adapter', n_best_size=20, n_gpu=1, no_cuda=False, null_score_diff_threshold=0.0, num_train_epochs=3.0, output_dir='/cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//squad/xlm-KG_LR3e-5_EPOCH2.0_maxlen384_batchsize4_gradacc4/predictions/xquad/', overwrite_cache=False, overwrite_output_dir=False, per_gpu_eval_batch_size=8, per_gpu_train_batch_size=8, predict_file='/cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/download//xquad//xquad.en.json', save_steps=50, seed=42, server_ip='', server_port='', threads=1, tokenizer_name='', train_file=None, train_lang='en', verbose_logging=False, version_2_with_negative=False, warmup_steps=0, weight_decay=0.0)
05/09/2022 08:56:18 - INFO - __main__ -   Loading checkpoint /cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//squad/xlm-KG_LR3e-5_EPOCH2.0_maxlen384_batchsize4_gradacc4 for evaluation
05/09/2022 08:56:18 - INFO - __main__ -   Evaluate the following checkpoints: ['/cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//squad/xlm-KG_LR3e-5_EPOCH2.0_maxlen384_batchsize4_gradacc4']
Some weights of the model checkpoint at /cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//squad/xlm-KG_LR3e-5_EPOCH2.0_maxlen384_batchsize4_gradacc4 were not used when initializing XLMRobertaModel: ['base_model.encoder.layer.21.attention.self.value.weight', 'base_model.encoder.layer.5.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.12.attention.output.LayerNorm.weight', 'base_model.encoder.layer.15.output.dense.weight', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.9.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.7.attention.self.value.weight', 'base_model.encoder.layer.17.attention.self.query.bias', 'base_model.encoder.layer.3.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.15.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.20.attention.self.key.weight', 'base_model.encoder.layer.15.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.10.output.LayerNorm.weight', 'base_model.encoder.layer.18.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.0.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.6.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.14.output.dense.bias', 'base_model.encoder.layer.16.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.9.attention.self.query.weight', 'base_model.encoder.layer.5.attention.self.value.weight', 'base_model.encoder.layer.3.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.21.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.11.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.18.attention.output.dense.bias', 'base_model.encoder.layer.5.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.6.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.10.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.11.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.21.output.dense.weight', 'base_model.encoder.layer.9.intermediate.dense.bias', 'base_model.encoder.layer.6.output.dense.bias', 'base_model.encoder.layer.14.output.LayerNorm.weight', 'base_model.encoder.layer.11.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.12.attention.self.value.bias', 'base_model.encoder.layer.2.intermediate.dense.weight', 'base_model.encoder.layer.14.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.16.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.15.attention.output.dense.weight', 'base_model.encoder.layer.3.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.3.output.dense.bias', 'base_model.encoder.layer.4.attention.output.dense.weight', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.12.attention.self.query.bias', 'base_model.encoder.layer.3.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.3.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.5.attention.output.LayerNorm.bias', 'base_model.encoder.layer.15.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.0.attention.self.query.bias', 'base_model.encoder.layer.9.attention.output.dense.bias', 'base_model.encoder.layer.4.attention.self.query.bias', 'base_model.encoder.layer.1.attention.self.query.bias', 'base_model.encoder.layer.19.attention.self.query.bias', 'base_model.encoder.layer.7.attention.output.LayerNorm.bias', 'base_model.encoder.layer.1.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.9.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.18.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.6.output.LayerNorm.weight', 'base_model.encoder.layer.11.attention.self.query.weight', 'base_model.encoder.layer.11.attention.output.dense.weight', 'base_model.encoder.layer.0.attention.self.query.weight', 'base_model.encoder.layer.0.attention.self.value.weight', 'base_model.encoder.layer.0.attention.self.value.bias', 'base_model.encoder.layer.19.output.LayerNorm.bias', 'base_model.encoder.layer.5.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.15.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.9.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.15.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.21.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.0.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.2.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.5.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.3.attention.self.value.bias', 'base_model.encoder.layer.21.attention.output.dense.weight', 'base_model.encoder.layer.4.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.20.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.17.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.9.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.22.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.9.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.7.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.5.attention.self.key.weight', 'base_model.encoder.layer.5.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.11.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.0.output.dense.weight', 'base_model.encoder.layer.15.output.LayerNorm.bias', 'base_model.encoder.layer.21.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.21.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.3.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.11.attention.self.value.bias', 'base_model.encoder.layer.6.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.20.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.6.attention.self.query.weight', 'base_model.encoder.layer.13.attention.self.query.weight', 'base_model.encoder.layer.18.attention.output.LayerNorm.weight', 'base_model.encoder.layer.5.output.dense.bias', 'base_model.encoder.layer.1.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.22.intermediate.dense.weight', 'base_model.encoder.layer.13.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.18.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.4.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.7.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.18.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.11.output.LayerNorm.bias', 'base_model.encoder.layer.5.attention.output.dense.bias', 'base_model.encoder.layer.9.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.16.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.5.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.13.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.23.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.16.attention.self.key.weight', 'base_model.encoder.layer.22.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.0.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.16.output.dense.weight', 'base_model.encoder.layer.8.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.14.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.9.output.LayerNorm.weight', 'base_model.encoder.layer.3.output.LayerNorm.weight', 'base_model.encoder.layer.18.intermediate.dense.weight', 'base_model.encoder.layer.19.attention.output.dense.bias', 'base_model.encoder.layer.9.output.LayerNorm.bias', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.7.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.1.attention.self.key.weight', 'base_model.encoder.layer.1.output.dense.bias', 'base_model.encoder.layer.11.output.dense.weight', 'base_model.encoder.layer.1.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.7.attention.output.LayerNorm.weight', 'base_model.embeddings.token_type_embeddings.weight', 'base_model.encoder.layer.17.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.23.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.9.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.6.attention.output.LayerNorm.weight', 'base_model.encoder.layer.8.attention.self.query.bias', 'base_model.encoder.layer.9.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.14.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.4.attention.output.LayerNorm.weight', 'base_model.encoder.layer.10.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.23.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.13.output.LayerNorm.bias', 'base_model.encoder.layer.23.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.8.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.12.output.dense.weight', 'base_model.encoder.layer.10.attention.self.query.bias', 'base_model.encoder.layer.0.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.6.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.14.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.6.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.3.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.12.intermediate.dense.bias', 'base_model.encoder.layer.17.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.12.attention.output.dense.bias', 'base_model.encoder.layer.12.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.4.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.11.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.7.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.4.attention.self.query.weight', 'base_model.encoder.layer.11.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.15.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.16.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.4.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.21.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.8.attention.output.dense.weight', 'base_model.encoder.layer.19.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.20.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.7.attention.self.key.bias', 'base_model.encoder.layer.10.attention.self.value.bias', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.16.attention.output.dense.bias', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.17.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.8.attention.self.query.weight', 'base_model.encoder.layer.6.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.1.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.13.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.3.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.19.attention.self.query.weight', 'base_model.encoder.layer.11.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.1.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.5.output.LayerNorm.bias', 'base_model.encoder.layer.14.attention.output.LayerNorm.weight', 'base_model.encoder.layer.8.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.12.attention.output.LayerNorm.bias', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.23.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.9.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.16.output.adapters.es.adapter_up.weight', 'base_model.embeddings.LayerNorm.bias', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.17.attention.self.value.weight', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.15.attention.self.value.weight', 'base_model.encoder.layer.10.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.22.attention.output.LayerNorm.bias', 'base_model.encoder.layer.10.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.10.output.LayerNorm.bias', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.0.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.20.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.18.attention.self.value.bias', 'base_model.encoder.layer.16.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.18.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.22.intermediate.dense.bias', 'base_model.encoder.layer.23.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.5.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.0.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.14.attention.output.dense.weight', 'base_model.encoder.layer.16.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.23.output.LayerNorm.weight', 'base_model.encoder.layer.12.attention.self.value.weight', 'base_model.encoder.layer.3.attention.output.LayerNorm.weight', 'base_model.encoder.layer.16.output.dense.bias', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.22.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.11.output.LayerNorm.weight', 'base_model.encoder.layer.19.intermediate.dense.bias', 'base_model.encoder.layer.7.output.dense.bias', 'base_model.encoder.layer.12.attention.self.key.bias', 'base_model.encoder.layer.16.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.23.attention.output.dense.bias', 'base_model.encoder.layer.20.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.7.attention.self.value.bias', 'base_model.encoder.layer.20.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.8.attention.self.key.bias', 'base_model.encoder.layer.1.attention.output.dense.bias', 'base_model.encoder.layer.15.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.0.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.4.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.8.output.LayerNorm.weight', 'base_model.encoder.layer.7.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.20.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.19.attention.self.value.bias', 'base_model.encoder.layer.18.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.1.attention.output.dense.weight', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.0.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.1.attention.self.key.bias', 'base_model.encoder.layer.2.attention.self.query.weight', 'base_model.encoder.layer.14.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.12.output.dense.bias', 'base_model.encoder.layer.13.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.3.output.dense.weight', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.12.attention.self.key.weight', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.17.attention.self.key.weight', 'base_model.encoder.layer.0.output.dense.bias', 'base_model.encoder.layer.17.attention.output.LayerNorm.bias', 'base_model.encoder.layer.20.attention.output.LayerNorm.weight', 'base_model.encoder.layer.15.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.13.attention.self.query.bias', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.3.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.19.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.0.attention.output.dense.bias', 'base_model.encoder.layer.14.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.0.intermediate.dense.weight', 'base_model.encoder.layer.0.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.14.attention.output.LayerNorm.bias', 'base_model.encoder.layer.4.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.9.attention.output.dense.weight', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.0.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.16.attention.output.LayerNorm.bias', 'base_model.encoder.layer.19.attention.self.key.weight', 'base_model.encoder.layer.4.output.LayerNorm.bias', 'base_model.encoder.layer.22.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.22.attention.self.value.bias', 'base_model.encoder.layer.8.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.17.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.8.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.4.intermediate.dense.weight', 'base_model.encoder.layer.13.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.15.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.7.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.22.output.dense.weight', 'base_model.encoder.layer.22.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.embeddings.word_embeddings.weight', 'base_model.encoder.layer.1.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.15.attention.self.query.bias', 'base_model.encoder.layer.8.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.9.attention.output.LayerNorm.bias', 'base_model.encoder.layer.19.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.13.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.9.attention.self.key.bias', 'base_model.encoder.layer.2.attention.self.value.bias', 'base_model.encoder.layer.17.attention.output.dense.weight', 'base_model.encoder.layer.11.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.18.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.8.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.19.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.10.attention.self.key.weight', 'base_model.encoder.layer.4.output.LayerNorm.weight', 'base_model.encoder.layer.8.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.8.attention.output.LayerNorm.bias', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.6.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.13.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.16.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.21.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.12.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.2.output.dense.weight', 'base_model.encoder.layer.23.output.dense.weight', 'base_model.encoder.layer.0.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.22.attention.output.dense.weight', 'base_model.encoder.layer.0.output.adapters.tp.adapter_up.bias', 'base_model.embeddings.position_ids', 'base_model.encoder.layer.7.intermediate.dense.weight', 'base_model.encoder.layer.23.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.1.attention.output.LayerNorm.bias', 'base_model.encoder.layer.2.attention.self.key.weight', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.4.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.2.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.21.attention.output.LayerNorm.weight', 'base_model.encoder.layer.20.output.dense.weight', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.11.intermediate.dense.weight', 'base_model.encoder.layer.13.attention.output.dense.bias', 'base_model.encoder.layer.18.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.8.attention.self.value.weight', 'base_model.encoder.layer.18.attention.self.key.bias', 'base_model.encoder.layer.12.output.LayerNorm.weight', 'base_model.encoder.layer.21.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.22.attention.output.dense.bias', 'base_model.encoder.layer.0.output.LayerNorm.weight', 'base_model.encoder.layer.7.output.LayerNorm.bias', 'base_model.encoder.layer.4.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.18.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.0.attention.output.dense.weight', 'base_model.encoder.layer.14.intermediate.dense.bias', 'base_model.encoder.layer.23.attention.self.value.bias', 'base_model.encoder.layer.17.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.2.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.13.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.22.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.2.output.dense.bias', 'base_model.encoder.layer.9.output.dense.bias', 'base_model.encoder.layer.19.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.2.intermediate.dense.bias', 'base_model.encoder.layer.8.output.dense.bias', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.3.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.15.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.11.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.7.attention.output.dense.bias', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.20.attention.self.value.weight', 'base_model.encoder.layer.6.attention.output.LayerNorm.bias', 'base_model.encoder.layer.5.intermediate.dense.weight', 'base_model.encoder.layer.4.attention.output.LayerNorm.bias', 'base_model.encoder.layer.8.intermediate.dense.bias', 'base_model.encoder.layer.20.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.5.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.13.attention.self.value.weight', 'base_model.encoder.layer.18.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.21.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.5.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.18.attention.self.query.bias', 'base_model.encoder.layer.1.intermediate.dense.weight', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.19.attention.self.key.bias', 'base_model.encoder.layer.2.output.LayerNorm.bias', 'base_model.encoder.layer.13.attention.output.LayerNorm.bias', 'base_model.encoder.layer.20.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.5.intermediate.dense.bias', 'base_model.encoder.layer.7.attention.self.key.weight', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.17.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.15.attention.self.query.weight', 'base_model.encoder.layer.19.attention.self.value.weight', 'base_model.encoder.layer.10.attention.self.query.weight', 'base_model.encoder.layer.15.output.LayerNorm.weight', 'base_model.encoder.layer.19.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.16.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.10.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.7.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.23.attention.output.LayerNorm.weight', 'base_model.encoder.layer.17.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.3.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.6.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.6.attention.self.query.bias', 'base_model.pooler.dense.bias', 'base_model.encoder.layer.5.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.11.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.10.attention.output.dense.bias', 'base_model.encoder.layer.5.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.11.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.16.attention.output.dense.weight', 'base_model.encoder.layer.0.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.6.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.18.attention.self.query.weight', 'base_model.encoder.layer.19.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.22.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.2.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.11.attention.output.dense.bias', 'base_model.encoder.layer.4.attention.self.value.bias', 'base_model.encoder.layer.18.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.12.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.23.attention.self.query.bias', 'base_model.encoder.layer.4.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.23.intermediate.dense.bias', 'base_model.encoder.layer.19.intermediate.dense.weight', 'base_model.encoder.layer.21.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.1.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.7.output.LayerNorm.weight', 'base_model.encoder.layer.13.attention.self.key.bias', 'base_model.encoder.layer.1.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.23.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.0.output.LayerNorm.bias', 'base_model.encoder.layer.16.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.21.attention.self.key.bias', 'base_model.encoder.layer.22.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.2.attention.output.LayerNorm.bias', 'base_model.encoder.layer.3.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.21.attention.self.value.bias', 'base_model.encoder.layer.17.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.23.attention.output.dense.weight', 'base_model.encoder.layer.4.intermediate.dense.bias', 'base_model.encoder.layer.6.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.4.output.dense.bias', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.6.attention.output.dense.weight', 'base_model.encoder.layer.1.output.LayerNorm.bias', 'base_model.encoder.layer.2.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.17.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.1.output.dense.weight', 'base_model.encoder.layer.9.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.13.output.LayerNorm.weight', 'base_model.encoder.layer.17.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.15.attention.output.LayerNorm.bias', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.12.attention.output.dense.weight', 'base_model.encoder.layer.19.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.18.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.22.attention.self.value.weight', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.9.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.13.attention.output.LayerNorm.weight', 'base_model.encoder.layer.2.attention.self.key.bias', 'base_model.encoder.layer.15.attention.output.dense.bias', 'base_model.encoder.layer.12.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.15.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.8.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.1.attention.self.value.weight', 'base_model.encoder.layer.14.intermediate.dense.weight', 'base_model.encoder.layer.11.intermediate.dense.bias', 'base_model.encoder.layer.12.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.17.output.dense.weight', 'base_model.encoder.layer.3.attention.self.value.weight', 'base_model.encoder.layer.15.attention.output.LayerNorm.weight', 'base_model.encoder.layer.18.attention.self.value.weight', 'base_model.encoder.layer.9.attention.self.value.bias', 'base_model.encoder.layer.17.output.LayerNorm.weight', 'base_model.encoder.layer.10.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.23.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.0.intermediate.dense.bias', 'base_model.encoder.layer.8.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.14.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.7.attention.output.dense.weight', 'base_model.encoder.layer.13.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.16.attention.self.query.weight', 'base_model.encoder.layer.10.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.18.output.LayerNorm.bias', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.18.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.11.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.10.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.1.attention.self.query.weight', 'base_model.encoder.layer.1.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.20.attention.self.value.bias', 'base_model.encoder.layer.22.attention.output.LayerNorm.weight', 'base_model.encoder.layer.16.attention.self.value.weight', 'base_model.encoder.layer.5.attention.output.dense.weight', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.17.attention.output.LayerNorm.weight', 'base_model.encoder.layer.2.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.6.attention.self.value.weight', 'base_model.encoder.layer.21.output.LayerNorm.weight', 'base_model.encoder.layer.13.attention.self.key.weight', 'base_model.encoder.layer.23.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.12.attention.self.query.weight', 'base_model.encoder.layer.0.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.19.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.1.output.LayerNorm.weight', 'base_model.encoder.layer.3.attention.output.dense.bias', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.10.attention.output.LayerNorm.bias', 'base_model.encoder.layer.11.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.13.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.23.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.19.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.9.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.4.attention.self.value.weight', 'base_model.encoder.layer.9.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.12.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.12.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.22.attention.self.query.bias', 'base_model.encoder.layer.6.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.0.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.7.intermediate.dense.bias', 'base_model.encoder.layer.7.attention.self.query.bias', 'base_model.encoder.layer.9.attention.output.LayerNorm.weight', 'base_model.encoder.layer.2.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.3.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.10.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.21.attention.output.LayerNorm.bias', 'base_model.encoder.layer.2.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.embeddings.position_embeddings.weight', 'base_model.encoder.layer.8.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.embeddings.LayerNorm.weight', 'base_model.encoder.layer.3.attention.output.dense.weight', 'base_model.encoder.layer.10.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.11.attention.self.key.bias', 'base_model.encoder.layer.11.output.dense.bias', 'base_model.encoder.layer.13.output.dense.weight', 'base_model.encoder.layer.12.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.20.attention.self.query.bias', 'base_model.encoder.layer.23.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.17.intermediate.dense.bias', 'base_model.encoder.layer.4.attention.self.key.weight', 'base_model.encoder.layer.12.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.7.output.dense.weight', 'base_model.encoder.layer.21.attention.self.query.bias', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.15.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.14.output.LayerNorm.bias', 'base_model.encoder.layer.18.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.19.output.dense.weight', 'base_model.encoder.layer.3.attention.self.key.bias', 'base_model.encoder.layer.3.output.LayerNorm.bias', 'base_model.encoder.layer.18.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.2.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.13.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.10.attention.self.key.bias', 'base_model.encoder.layer.13.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.22.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.20.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.17.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.5.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.19.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.16.output.LayerNorm.bias', 'base_model.encoder.layer.10.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.23.attention.self.query.weight', 'base_model.encoder.layer.20.attention.output.dense.weight', 'base_model.encoder.layer.23.output.LayerNorm.bias', 'base_model.encoder.layer.6.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.14.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.11.attention.output.LayerNorm.weight', 'base_model.encoder.layer.17.attention.self.value.bias', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.11.attention.self.value.weight', 'base_model.encoder.layer.19.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.20.output.dense.bias', 'base_model.encoder.layer.5.attention.self.query.weight', 'base_model.encoder.layer.4.output.dense.weight', 'base_model.encoder.layer.2.output.LayerNorm.weight', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.14.output.dense.weight', 'base_model.encoder.layer.6.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.15.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.13.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.9.attention.self.value.weight', 'base_model.encoder.layer.1.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.22.output.dense.bias', 'base_model.encoder.layer.20.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.21.intermediate.dense.weight', 'base_model.encoder.layer.4.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.20.intermediate.dense.bias', 'base_model.encoder.layer.2.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.9.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.10.attention.output.LayerNorm.weight', 'base_model.encoder.layer.17.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.15.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.1.intermediate.dense.bias', 'base_model.encoder.layer.14.attention.self.key.bias', 'base_model.encoder.layer.20.output.adapters.tp.adapter_down.0.bias', 'qa_outputs.bias', 'base_model.encoder.layer.12.output.LayerNorm.bias', 'base_model.encoder.layer.22.output.LayerNorm.weight', 'base_model.encoder.layer.7.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.13.attention.output.dense.weight', 'base_model.encoder.layer.2.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.11.attention.output.LayerNorm.bias', 'base_model.encoder.layer.19.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.21.attention.self.key.weight', 'base_model.encoder.layer.14.attention.output.dense.bias', 'base_model.encoder.layer.15.attention.self.value.bias', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.16.attention.self.query.bias', 'base_model.encoder.layer.7.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.13.intermediate.dense.weight', 'base_model.encoder.layer.22.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.17.attention.output.dense.bias', 'base_model.encoder.layer.15.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.6.output.dense.weight', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.1.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.7.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.11.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.20.attention.self.key.bias', 'base_model.encoder.layer.21.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.10.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.5.output.LayerNorm.weight', 'base_model.encoder.layer.3.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.3.intermediate.dense.bias', 'base_model.encoder.layer.20.output.LayerNorm.bias', 'base_model.encoder.layer.22.attention.self.key.bias', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.4.attention.output.dense.bias', 'base_model.encoder.layer.2.attention.output.LayerNorm.weight', 'base_model.encoder.layer.10.output.dense.bias', 'base_model.encoder.layer.2.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.0.attention.output.LayerNorm.weight', 'base_model.encoder.layer.17.output.dense.bias', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.2.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.21.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.23.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.20.attention.output.LayerNorm.bias', 'base_model.encoder.layer.22.output.LayerNorm.bias', 'base_model.encoder.layer.16.attention.output.LayerNorm.weight', 'base_model.encoder.layer.20.output.LayerNorm.weight', 'base_model.encoder.layer.10.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.12.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.9.attention.self.key.weight', 'base_model.encoder.layer.6.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.21.output.LayerNorm.bias', 'base_model.encoder.layer.23.attention.output.LayerNorm.bias', 'base_model.encoder.layer.5.attention.self.value.bias', 'base_model.encoder.layer.13.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.4.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.18.attention.output.dense.weight', 'base_model.encoder.layer.11.attention.self.query.bias', 'base_model.encoder.layer.5.attention.self.query.bias', 'base_model.encoder.layer.1.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.16.intermediate.dense.weight', 'base_model.encoder.layer.14.attention.self.query.weight', 'base_model.encoder.layer.17.output.LayerNorm.bias', 'base_model.encoder.layer.18.output.dense.bias', 'base_model.encoder.layer.22.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.19.attention.output.dense.weight', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.22.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.6.attention.self.value.bias', 'base_model.encoder.layer.9.attention.self.query.bias', 'base_model.encoder.layer.9.output.dense.weight', 'base_model.encoder.layer.12.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.5.output.dense.weight', 'base_model.encoder.layer.4.attention.self.key.bias', 'base_model.encoder.layer.23.attention.self.key.bias', 'base_model.encoder.layer.20.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.11.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.15.attention.self.key.weight', 'base_model.encoder.layer.17.attention.self.query.weight', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.8.attention.output.dense.bias', 'base_model.encoder.layer.10.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.15.intermediate.dense.weight', 'base_model.encoder.layer.10.intermediate.dense.bias', 'base_model.encoder.layer.16.attention.self.key.bias', 'base_model.encoder.layer.9.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.14.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.0.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.8.attention.self.key.weight', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.7.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.9.intermediate.dense.weight', 'base_model.encoder.layer.10.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.13.attention.self.value.bias', 'base_model.encoder.layer.17.intermediate.dense.weight', 'base_model.encoder.layer.22.attention.self.query.weight', 'base_model.encoder.layer.17.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.15.attention.self.key.bias', 'base_model.encoder.layer.22.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.14.attention.self.value.bias', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.12.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.1.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.14.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.19.attention.output.LayerNorm.bias', 'base_model.encoder.layer.0.attention.self.key.weight', 'base_model.encoder.layer.6.intermediate.dense.bias', 'base_model.encoder.layer.17.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.4.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.1.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.13.intermediate.dense.bias', 'base_model.encoder.layer.2.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.10.output.dense.weight', 'base_model.encoder.layer.21.output.dense.bias', 'base_model.encoder.layer.13.output.dense.bias', 'base_model.encoder.layer.20.attention.output.dense.bias', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.18.output.dense.weight', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.23.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.2.attention.output.dense.bias', 'base_model.encoder.layer.5.attention.self.key.bias', 'base_model.encoder.layer.15.intermediate.dense.bias', 'base_model.encoder.layer.7.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.14.attention.self.query.bias', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.2.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.9.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.1.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.13.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.2.attention.self.value.weight', 'base_model.encoder.layer.20.intermediate.dense.weight', 'base_model.encoder.layer.21.intermediate.dense.bias', 'base_model.encoder.layer.11.output.adapters.ts.adapter_up.bias', 'qa_outputs.weight', 'base_model.encoder.layer.21.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.8.output.dense.weight', 'base_model.encoder.layer.16.output.LayerNorm.weight', 'base_model.encoder.layer.3.attention.self.query.bias', 'base_model.encoder.layer.6.attention.self.key.weight', 'base_model.encoder.layer.12.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.14.attention.self.key.weight', 'base_model.encoder.layer.3.attention.output.LayerNorm.bias', 'base_model.encoder.layer.22.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.12.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.1.attention.output.LayerNorm.weight', 'base_model.encoder.layer.5.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.23.intermediate.dense.weight', 'base_model.encoder.layer.23.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.7.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.14.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.18.attention.output.LayerNorm.bias', 'base_model.encoder.layer.6.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.3.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.4.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.17.attention.self.key.bias', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.7.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.17.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.20.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.21.attention.output.dense.bias', 'base_model.encoder.layer.4.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.5.attention.output.LayerNorm.weight', 'base_model.encoder.layer.3.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.15.output.dense.bias', 'base_model.encoder.layer.19.output.dense.bias', 'base_model.encoder.layer.2.attention.output.dense.weight', 'base_model.encoder.layer.8.attention.self.value.bias', 'base_model.encoder.layer.0.attention.output.LayerNorm.bias', 'base_model.encoder.layer.11.attention.self.key.weight', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.19.attention.output.LayerNorm.weight', 'base_model.encoder.layer.22.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.5.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.10.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.16.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.14.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.22.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.23.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.21.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.14.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.1.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.5.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.16.intermediate.dense.bias', 'base_model.encoder.layer.8.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.14.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.14.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.6.attention.output.dense.bias', 'base_model.encoder.layer.18.output.LayerNorm.weight', 'base_model.encoder.layer.8.output.LayerNorm.bias', 'base_model.encoder.layer.5.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.18.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.16.attention.self.value.bias', 'base_model.encoder.layer.8.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.10.intermediate.dense.weight', 'base_model.encoder.layer.16.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.7.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.10.attention.self.value.weight', 'base_model.encoder.layer.8.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.8.intermediate.dense.weight', 'base_model.encoder.layer.18.intermediate.dense.bias', 'base_model.encoder.layer.20.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.1.attention.self.value.bias', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.3.attention.self.key.weight', 'base_model.encoder.layer.21.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.14.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.3.attention.self.query.weight', 'base_model.encoder.layer.19.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.21.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.21.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.21.attention.self.query.weight', 'base_model.encoder.layer.19.output.LayerNorm.weight', 'base_model.encoder.layer.0.attention.self.key.bias', 'base_model.encoder.layer.19.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.7.attention.self.query.weight', 'base_model.encoder.layer.12.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.4.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.2.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.16.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.6.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.16.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.18.attention.self.key.weight', 'base_model.encoder.layer.4.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.3.intermediate.dense.weight', 'base_model.encoder.layer.12.intermediate.dense.weight', 'base_model.encoder.layer.12.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.2.attention.self.query.bias', 'base_model.pooler.dense.weight', 'base_model.encoder.layer.23.attention.self.key.weight', 'base_model.encoder.layer.8.attention.output.LayerNorm.weight', 'base_model.encoder.layer.6.output.LayerNorm.bias', 'base_model.encoder.layer.16.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.20.attention.self.query.weight', 'base_model.encoder.layer.20.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.15.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.7.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.6.intermediate.dense.weight', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.8.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.8.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.10.attention.output.dense.weight', 'base_model.encoder.layer.22.attention.self.key.weight', 'base_model.encoder.layer.19.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.23.attention.self.value.weight', 'base_model.encoder.layer.14.attention.self.value.weight', 'base_model.encoder.layer.23.output.dense.bias', 'base_model.encoder.layer.6.attention.self.key.bias', 'base_model.encoder.layer.13.output.adapters.ts.adapter_down.0.bias']
- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of XLMRobertaModel were not initialized from the model checkpoint at /cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//squad/xlm-KG_LR3e-5_EPOCH2.0_maxlen384_batchsize4_gradacc4 and are newly initialized: ['encoder.layer.18.attention.output.LayerNorm.weight', 'encoder.layer.15.attention.self.value.weight', 'encoder.layer.4.attention.self.key.weight', 'encoder.layer.20.attention.self.value.bias', 'encoder.layer.23.attention.self.value.bias', 'encoder.layer.11.attention.output.LayerNorm.weight', 'encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.layer.1.attention.self.key.bias', 'encoder.layer.7.output.LayerNorm.weight', 'encoder.layer.5.output.LayerNorm.bias', 'encoder.layer.22.attention.self.key.weight', 'encoder.layer.12.attention.output.dense.bias', 'encoder.layer.8.attention.self.value.weight', 'embeddings.LayerNorm.bias', 'encoder.layer.2.attention.output.LayerNorm.bias', 'encoder.layer.20.attention.self.key.weight', 'encoder.layer.22.attention.self.query.weight', 'encoder.layer.9.attention.output.dense.weight', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.0.attention.output.dense.weight', 'encoder.layer.4.attention.output.LayerNorm.weight', 'encoder.layer.12.output.dense.bias', 'encoder.layer.3.attention.self.value.weight', 'encoder.layer.10.attention.output.LayerNorm.bias', 'embeddings.word_embeddings.weight', 'encoder.layer.22.attention.output.LayerNorm.bias', 'encoder.layer.9.attention.self.value.weight', 'encoder.layer.9.output.LayerNorm.bias', 'encoder.layer.3.output.dense.bias', 'encoder.layer.2.attention.self.query.weight', 'encoder.layer.3.attention.self.key.weight', 'encoder.layer.16.attention.output.dense.bias', 'embeddings.LayerNorm.weight', 'encoder.layer.5.attention.self.key.weight', 'encoder.layer.6.output.dense.weight', 'encoder.layer.21.attention.self.query.bias', 'encoder.layer.10.attention.self.value.weight', 'encoder.layer.12.attention.self.key.weight', 'encoder.layer.15.output.LayerNorm.bias', 'encoder.layer.15.output.LayerNorm.weight', 'encoder.layer.13.attention.self.key.weight', 'encoder.layer.11.attention.self.query.bias', 'encoder.layer.11.attention.output.dense.weight', 'encoder.layer.1.attention.self.value.weight', 'encoder.layer.21.attention.output.dense.weight', 'encoder.layer.18.attention.output.dense.weight', 'encoder.layer.2.attention.self.value.bias', 'encoder.layer.2.output.dense.bias', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.1.output.dense.weight', 'encoder.layer.10.attention.self.key.bias', 'encoder.layer.20.attention.output.LayerNorm.bias', 'encoder.layer.0.attention.self.value.weight', 'encoder.layer.15.intermediate.dense.bias', 'encoder.layer.19.output.LayerNorm.weight', 'encoder.layer.6.output.dense.bias', 'encoder.layer.14.intermediate.dense.bias', 'encoder.layer.16.attention.self.query.weight', 'encoder.layer.17.attention.self.query.weight', 'encoder.layer.12.output.LayerNorm.bias', 'encoder.layer.11.attention.self.key.bias', 'encoder.layer.10.attention.self.query.bias', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.16.attention.self.value.bias', 'encoder.layer.13.output.LayerNorm.bias', 'encoder.layer.21.attention.output.dense.bias', 'encoder.layer.8.output.LayerNorm.bias', 'encoder.layer.10.output.dense.weight', 'encoder.layer.3.attention.self.value.bias', 'encoder.layer.17.attention.self.key.weight', 'encoder.layer.8.attention.output.LayerNorm.bias', 'encoder.layer.12.attention.self.value.weight', 'encoder.layer.19.output.LayerNorm.bias', 'encoder.layer.20.output.LayerNorm.bias', 'encoder.layer.12.attention.output.dense.weight', 'encoder.layer.14.attention.self.key.bias', 'encoder.layer.13.attention.self.query.bias', 'encoder.layer.17.output.LayerNorm.weight', 'encoder.layer.1.attention.self.query.weight', 'encoder.layer.6.attention.output.dense.bias', 'encoder.layer.9.attention.self.key.bias', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.16.attention.self.key.weight', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.2.attention.output.LayerNorm.weight', 'encoder.layer.15.attention.self.key.bias', 'encoder.layer.23.attention.output.dense.bias', 'encoder.layer.14.attention.self.value.weight', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.22.attention.self.value.weight', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.15.output.dense.bias', 'encoder.layer.7.attention.output.dense.weight', 'encoder.layer.9.attention.output.dense.bias', 'encoder.layer.17.output.dense.bias', 'encoder.layer.15.output.dense.weight', 'encoder.layer.9.attention.self.key.weight', 'encoder.layer.19.attention.self.query.weight', 'encoder.layer.14.attention.output.LayerNorm.bias', 'encoder.layer.16.attention.output.LayerNorm.weight', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.6.attention.output.dense.weight', 'encoder.layer.13.attention.self.query.weight', 'encoder.layer.23.attention.output.LayerNorm.weight', 'encoder.layer.2.attention.output.dense.weight', 'encoder.layer.18.output.dense.bias', 'encoder.layer.22.attention.self.query.bias', 'encoder.layer.16.attention.output.LayerNorm.bias', 'encoder.layer.22.output.dense.weight', 'encoder.layer.12.output.dense.weight', 'encoder.layer.12.intermediate.dense.bias', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.11.output.dense.weight', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.15.attention.self.query.bias', 'encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.layer.5.attention.output.dense.weight', 'encoder.layer.6.output.LayerNorm.bias', 'encoder.layer.23.intermediate.dense.bias', 'encoder.layer.18.attention.self.query.bias', 'encoder.layer.1.attention.self.key.weight', 'encoder.layer.7.attention.output.LayerNorm.weight', 'encoder.layer.2.attention.self.key.bias', 'encoder.layer.20.attention.self.key.bias', 'encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.layer.23.attention.self.key.bias', 'encoder.layer.8.attention.output.LayerNorm.weight', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.7.attention.self.key.bias', 'encoder.layer.11.output.LayerNorm.weight', 'encoder.layer.7.attention.self.query.weight', 'encoder.layer.2.attention.output.dense.bias', 'encoder.layer.20.output.dense.weight', 'encoder.layer.17.attention.self.query.bias', 'encoder.layer.14.attention.self.key.weight', 'encoder.layer.11.attention.self.key.weight', 'encoder.layer.11.output.dense.bias', 'encoder.layer.8.output.LayerNorm.weight', 'encoder.layer.23.attention.self.value.weight', 'encoder.layer.22.attention.self.key.bias', 'encoder.layer.18.attention.self.key.weight', 'encoder.layer.18.output.LayerNorm.bias', 'encoder.layer.2.attention.self.query.bias', 'encoder.layer.15.attention.output.LayerNorm.weight', 'encoder.layer.20.intermediate.dense.weight', 'encoder.layer.10.intermediate.dense.bias', 'embeddings.position_embeddings.weight', 'encoder.layer.11.attention.output.dense.bias', 'encoder.layer.17.attention.output.dense.weight', 'encoder.layer.10.attention.output.dense.bias', 'encoder.layer.22.attention.output.dense.bias', 'encoder.layer.3.attention.output.dense.weight', 'encoder.layer.4.output.dense.bias', 'encoder.layer.0.attention.self.query.bias', 'encoder.layer.11.attention.self.query.weight', 'encoder.layer.10.attention.self.key.weight', 'encoder.layer.13.output.LayerNorm.weight', 'encoder.layer.18.output.LayerNorm.weight', 'encoder.layer.23.output.dense.weight', 'encoder.layer.16.attention.self.query.bias', 'encoder.layer.19.attention.self.key.weight', 'encoder.layer.23.attention.self.query.bias', 'encoder.layer.14.output.LayerNorm.bias', 'encoder.layer.21.attention.self.value.bias', 'encoder.layer.13.attention.output.dense.bias', 'encoder.layer.18.output.dense.weight', 'encoder.layer.19.output.dense.bias', 'encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.layer.4.attention.self.query.weight', 'encoder.layer.0.output.dense.weight', 'encoder.layer.17.attention.output.LayerNorm.weight', 'encoder.layer.17.output.dense.weight', 'encoder.layer.1.attention.self.query.bias', 'encoder.layer.22.attention.output.LayerNorm.weight', 'encoder.layer.8.attention.self.key.weight', 'encoder.layer.23.output.LayerNorm.weight', 'encoder.layer.10.output.dense.bias', 'encoder.layer.0.output.dense.bias', 'encoder.layer.2.attention.self.value.weight', 'encoder.layer.2.output.dense.weight', 'encoder.layer.12.attention.self.key.bias', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.12.attention.self.value.bias', 'encoder.layer.8.attention.output.dense.weight', 'encoder.layer.20.output.LayerNorm.weight', 'encoder.layer.13.attention.self.value.bias', 'encoder.layer.10.output.LayerNorm.bias', 'encoder.layer.8.attention.self.key.bias', 'encoder.layer.16.intermediate.dense.weight', 'encoder.layer.0.attention.output.dense.bias', 'encoder.layer.19.attention.output.LayerNorm.bias', 'encoder.layer.16.output.LayerNorm.bias', 'encoder.layer.1.attention.output.dense.bias', 'encoder.layer.4.attention.output.dense.bias', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.5.attention.self.query.weight', 'encoder.layer.22.output.LayerNorm.bias', 'encoder.layer.19.attention.self.value.bias', 'encoder.layer.11.output.LayerNorm.bias', 'encoder.layer.16.attention.output.dense.weight', 'encoder.layer.21.attention.self.key.bias', 'encoder.layer.23.attention.self.key.weight', 'encoder.layer.7.output.dense.bias', 'encoder.layer.23.intermediate.dense.weight', 'encoder.layer.20.attention.output.dense.weight', 'encoder.layer.19.attention.output.LayerNorm.weight', 'encoder.layer.12.attention.self.query.bias', 'encoder.layer.19.attention.output.dense.bias', 'encoder.layer.16.output.dense.weight', 'encoder.layer.16.intermediate.dense.bias', 'encoder.layer.7.output.LayerNorm.bias', 'encoder.layer.13.attention.output.LayerNorm.bias', 'pooler.dense.weight', 'encoder.layer.20.output.dense.bias', 'encoder.layer.3.output.dense.weight', 'encoder.layer.1.attention.output.LayerNorm.weight', 'encoder.layer.23.output.LayerNorm.bias', 'encoder.layer.13.attention.output.LayerNorm.weight', 'encoder.layer.13.output.dense.weight', 'encoder.layer.17.intermediate.dense.weight', 'encoder.layer.5.output.dense.weight', 'encoder.layer.4.output.dense.weight', 'encoder.layer.18.attention.output.dense.bias', 'encoder.layer.17.output.LayerNorm.bias', 'encoder.layer.5.attention.self.value.bias', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.10.intermediate.dense.weight', 'encoder.layer.0.attention.self.value.bias', 'encoder.layer.15.attention.self.query.weight', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.10.attention.output.dense.weight', 'encoder.layer.14.intermediate.dense.weight', 'encoder.layer.13.intermediate.dense.bias', 'encoder.layer.15.attention.self.key.weight', 'encoder.layer.19.intermediate.dense.weight', 'encoder.layer.13.output.dense.bias', 'encoder.layer.7.attention.output.dense.bias', 'encoder.layer.17.attention.output.LayerNorm.bias', 'encoder.layer.7.attention.self.value.bias', 'encoder.layer.15.attention.output.LayerNorm.bias', 'encoder.layer.7.attention.self.query.bias', 'encoder.layer.7.intermediate.dense.bias', 'encoder.layer.23.output.dense.bias', 'encoder.layer.1.attention.output.dense.weight', 'encoder.layer.20.intermediate.dense.bias', 'encoder.layer.19.intermediate.dense.bias', 'encoder.layer.8.attention.self.value.bias', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.20.attention.output.dense.bias', 'encoder.layer.7.output.dense.weight', 'encoder.layer.21.attention.output.LayerNorm.bias', 'encoder.layer.18.attention.self.query.weight', 'encoder.layer.4.attention.self.key.bias', 'encoder.layer.8.output.dense.bias', 'encoder.layer.3.attention.output.dense.bias', 'encoder.layer.18.attention.self.key.bias', 'encoder.layer.19.attention.self.value.weight', 'encoder.layer.7.attention.self.value.weight', 'encoder.layer.10.output.LayerNorm.weight', 'encoder.layer.22.output.dense.bias', 'encoder.layer.21.attention.self.key.weight', 'encoder.layer.2.attention.self.key.weight', 'encoder.layer.1.output.dense.bias', 'encoder.layer.14.attention.output.dense.bias', 'encoder.layer.5.attention.output.LayerNorm.weight', 'encoder.layer.5.intermediate.dense.weight', 'pooler.dense.bias', 'encoder.layer.15.intermediate.dense.weight', 'encoder.layer.4.attention.output.dense.weight', 'encoder.layer.3.attention.self.key.bias', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.6.attention.self.key.weight', 'encoder.layer.8.attention.self.query.bias', 'encoder.layer.6.attention.self.key.bias', 'encoder.layer.0.attention.self.key.bias', 'encoder.layer.21.output.LayerNorm.weight', 'encoder.layer.6.attention.self.query.bias', 'encoder.layer.23.attention.self.query.weight', 'encoder.layer.12.intermediate.dense.weight', 'encoder.layer.4.attention.self.value.bias', 'encoder.layer.14.attention.self.query.weight', 'encoder.layer.13.attention.self.key.bias', 'encoder.layer.21.attention.output.LayerNorm.weight', 'encoder.layer.18.attention.output.LayerNorm.bias', 'encoder.layer.14.attention.self.value.bias', 'encoder.layer.8.attention.self.query.weight', 'encoder.layer.1.attention.self.value.bias', 'encoder.layer.16.output.LayerNorm.weight', 'encoder.layer.14.output.LayerNorm.weight', 'encoder.layer.15.attention.output.dense.weight', 'encoder.layer.9.attention.self.query.weight', 'encoder.layer.21.attention.self.query.weight', 'encoder.layer.5.attention.self.query.bias', 'encoder.layer.17.attention.self.key.bias', 'encoder.layer.9.output.dense.bias', 'encoder.layer.4.attention.output.LayerNorm.bias', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.22.output.LayerNorm.weight', 'encoder.layer.18.attention.self.value.bias', 'encoder.layer.6.attention.self.query.weight', 'encoder.layer.20.attention.self.value.weight', 'encoder.layer.22.attention.output.dense.weight', 'encoder.layer.10.attention.self.value.bias', 'encoder.layer.15.attention.output.dense.bias', 'encoder.layer.22.intermediate.dense.bias', 'encoder.layer.18.attention.self.value.weight', 'encoder.layer.22.attention.self.value.bias', 'encoder.layer.16.attention.self.key.bias', 'encoder.layer.17.attention.self.value.bias', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.9.output.LayerNorm.weight', 'encoder.layer.7.attention.self.key.weight', 'encoder.layer.9.output.dense.weight', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.20.attention.self.query.bias', 'encoder.layer.5.attention.self.key.bias', 'encoder.layer.14.output.dense.weight', 'encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.layer.15.attention.self.value.bias', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.21.intermediate.dense.bias', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.5.attention.output.dense.bias', 'encoder.layer.18.intermediate.dense.weight', 'encoder.layer.21.output.dense.weight', 'encoder.layer.6.attention.output.LayerNorm.weight', 'encoder.layer.6.attention.output.LayerNorm.bias', 'encoder.layer.3.attention.self.query.bias', 'encoder.layer.10.attention.output.LayerNorm.weight', 'encoder.layer.21.attention.self.value.weight', 'encoder.layer.18.intermediate.dense.bias', 'encoder.layer.6.attention.self.value.weight', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.14.output.dense.bias', 'encoder.layer.11.attention.self.value.bias', 'encoder.layer.9.attention.self.query.bias', 'encoder.layer.21.intermediate.dense.weight', 'encoder.layer.12.output.LayerNorm.weight', 'encoder.layer.6.attention.self.value.bias', 'encoder.layer.19.attention.self.query.bias', 'encoder.layer.5.output.dense.bias', 'encoder.layer.22.intermediate.dense.weight', 'encoder.layer.11.attention.self.value.weight', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.8.output.dense.weight', 'encoder.layer.9.attention.output.LayerNorm.bias', 'encoder.layer.14.attention.output.dense.weight', 'encoder.layer.14.attention.self.query.bias', 'encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.23.attention.output.LayerNorm.bias', 'encoder.layer.16.output.dense.bias', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.9.attention.output.LayerNorm.weight', 'encoder.layer.17.attention.output.dense.bias', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.9.attention.self.value.bias', 'encoder.layer.13.attention.output.dense.weight', 'encoder.layer.5.attention.self.value.weight', 'encoder.layer.17.intermediate.dense.bias', 'encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.layer.3.attention.self.query.weight', 'encoder.layer.16.attention.self.value.weight', 'encoder.layer.14.attention.output.LayerNorm.weight', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.20.attention.self.query.weight', 'encoder.layer.4.attention.self.query.bias', 'encoder.layer.7.attention.output.LayerNorm.bias', 'encoder.layer.12.attention.output.LayerNorm.weight', 'encoder.layer.8.attention.output.dense.bias', 'encoder.layer.0.attention.self.query.weight', 'encoder.layer.17.attention.self.value.weight', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.19.attention.self.key.bias', 'encoder.layer.12.attention.self.query.weight', 'encoder.layer.20.attention.output.LayerNorm.weight', 'encoder.layer.13.intermediate.dense.weight', 'encoder.layer.19.output.dense.weight', 'encoder.layer.13.attention.self.value.weight', 'encoder.layer.10.attention.self.query.weight', 'encoder.layer.19.attention.output.dense.weight', 'encoder.layer.4.attention.self.value.weight', 'encoder.layer.23.attention.output.dense.weight', 'encoder.layer.0.attention.output.LayerNorm.weight', 'embeddings.token_type_embeddings.weight', 'encoder.layer.0.attention.self.key.weight', 'encoder.layer.21.output.dense.bias', 'encoder.layer.12.attention.output.LayerNorm.bias', 'encoder.layer.21.output.LayerNorm.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Overwriting existing adapter 'ep'.
Overwriting existing adapter 'tp'.
Overwriting existing adapter 'es'.
Overwriting existing adapter 'ts'.
Overwriting existing adapter fusion module 'ep,tp,es,ts'
05/09/2022 08:56:50 - INFO - __main__ -   Creating features from dataset file at .
/cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//squad/xlm-KG_LR3e-5_EPOCH2.0_maxlen384_batchsize4_gradacc4
XLMConfig {
  "architectures": [
    "XLMRobertaForMaskedLM"
  ],
  "asm": false,
  "attention_dropout": 0.1,
  "attention_probs_dropout_prob": 0.1,
  "bos_index": 0,
  "bos_token_id": 0,
  "causal": false,
  "dropout": 0.1,
  "emb_dim": 1024,
  "embed_init_std": 0.02209708691207961,
  "end_n_top": 5,
  "eos_index": 1,
  "eos_token_id": 2,
  "gelu_activation": true,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "init_std": 0.02,
  "initializer_range": 0.02,
  "intermediate_size": 4096,
  "is_encoder": true,
  "lang_id": 0,
  "layer_norm_eps": 1e-05,
  "mask_index": 5,
  "mask_token_id": 0,
  "max_position_embeddings": 514,
  "model_type": "xlm",
  "n_heads": 16,
  "n_langs": 1,
  "n_layers": 24,
  "output_past": true,
  "pad_index": 2,
  "pad_token_id": 1,
  "sinusoidal_embeddings": false,
  "start_n_top": 5,
  "summary_activation": null,
  "summary_first_dropout": 0.1,
  "summary_proj_to_labels": true,
  "summary_type": "first",
  "summary_use_proj": true,
  "transformers_version": "4.17.0",
  "type_vocab_size": 1,
  "unk_index": 3,
  "use_lang_emb": false,
  "vocab_size": 250002
}

  0%|          | 0/48 [00:00<?, ?it/s] 21%|██        | 10/48 [00:00<00:00, 97.49it/s] 42%|████▏     | 20/48 [00:00<00:00, 66.32it/s] 58%|█████▊    | 28/48 [00:00<00:00, 68.28it/s] 75%|███████▌  | 36/48 [00:00<00:00, 69.02it/s] 94%|█████████▍| 45/48 [00:00<00:00, 75.28it/s]100%|██████████| 48/48 [00:00<00:00, 74.67it/s]
convert squad examples to features:   0%|          | 0/1190 [00:00<?, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.
convert squad examples to features:   0%|          | 1/1190 [00:00<04:17,  4.62it/s]convert squad examples to features:   3%|▎         | 33/1190 [00:00<00:10, 115.59it/s]convert squad examples to features:   5%|▌         | 65/1190 [00:00<00:07, 146.44it/s]convert squad examples to features:   8%|▊         | 97/1190 [00:00<00:07, 152.03it/s]convert squad examples to features:  11%|█         | 129/1190 [00:00<00:06, 164.55it/s]convert squad examples to features:  14%|█▎        | 161/1190 [00:01<00:05, 195.32it/s]convert squad examples to features:  19%|█▉        | 225/1190 [00:01<00:04, 238.27it/s]convert squad examples to features:  22%|██▏       | 257/1190 [00:01<00:03, 246.90it/s]convert squad examples to features:  24%|██▍       | 289/1190 [00:01<00:04, 221.78it/s]convert squad examples to features:  27%|██▋       | 321/1190 [00:01<00:04, 193.16it/s]convert squad examples to features:  30%|██▉       | 353/1190 [00:01<00:04, 194.40it/s]convert squad examples to features:  32%|███▏      | 385/1190 [00:02<00:08, 100.02it/s]convert squad examples to features:  35%|███▌      | 417/1190 [00:02<00:07, 106.13it/s]convert squad examples to features:  38%|███▊      | 449/1190 [00:03<00:06, 119.35it/s]convert squad examples to features:  40%|████      | 481/1190 [00:03<00:05, 122.25it/s]convert squad examples to features:  43%|████▎     | 513/1190 [00:03<00:05, 128.55it/s]convert squad examples to features:  46%|████▌     | 545/1190 [00:03<00:05, 128.96it/s]convert squad examples to features:  48%|████▊     | 577/1190 [00:03<00:04, 139.74it/s]convert squad examples to features:  51%|█████     | 609/1190 [00:04<00:04, 140.00it/s]convert squad examples to features:  54%|█████▍    | 641/1190 [00:04<00:04, 137.14it/s]convert squad examples to features:  57%|█████▋    | 673/1190 [00:04<00:03, 132.94it/s]convert squad examples to features:  59%|█████▉    | 705/1190 [00:04<00:03, 137.41it/s]convert squad examples to features:  62%|██████▏   | 737/1190 [00:05<00:03, 141.42it/s]convert squad examples to features:  65%|██████▍   | 769/1190 [00:05<00:02, 154.72it/s]convert squad examples to features:  67%|██████▋   | 801/1190 [00:05<00:02, 159.26it/s]convert squad examples to features:  70%|███████   | 833/1190 [00:05<00:02, 147.48it/s]convert squad examples to features:  73%|███████▎  | 865/1190 [00:05<00:02, 147.80it/s]convert squad examples to features:  75%|███████▌  | 897/1190 [00:06<00:02, 140.06it/s]convert squad examples to features:  78%|███████▊  | 929/1190 [00:06<00:01, 136.91it/s]convert squad examples to features:  81%|████████  | 961/1190 [00:06<00:01, 138.32it/s]convert squad examples to features:  83%|████████▎ | 993/1190 [00:06<00:01, 146.77it/s]convert squad examples to features:  86%|████████▌ | 1025/1190 [00:07<00:01, 152.75it/s]convert squad examples to features:  89%|████████▉ | 1057/1190 [00:07<00:00, 163.03it/s]convert squad examples to features:  92%|█████████▏| 1089/1190 [00:07<00:00, 167.59it/s]convert squad examples to features:  94%|█████████▍| 1121/1190 [00:07<00:00, 169.45it/s]convert squad examples to features:  97%|█████████▋| 1153/1190 [00:07<00:00, 155.52it/s]convert squad examples to features: 100%|██████████| 1190/1190 [00:07<00:00, 152.19it/s]/cluster/project/sachan/yifan/softwares/anaconda/anaconda3/envs/xfactr/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2272: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

add example index and unique id:   0%|          | 0/1190 [00:00<?, ?it/s]add example index and unique id: 100%|██████████| 1190/1190 [00:00<00:00, 405033.01it/s]
05/09/2022 08:56:59 - INFO - __main__ -   Saving features into cached file ./cached_xquad.en.json_xlm-KG_LR3e-5_EPOCH2.0_maxlen384_batchsize4_gradacc4_384_en
05/09/2022 08:57:00 - INFO - __main__ -   ***** Running evaluation  *****
05/09/2022 08:57:00 - INFO - __main__ -     Num examples = 1270
05/09/2022 08:57:00 - INFO - __main__ -     Batch size = 8
Evaluating:   0%|          | 0/159 [00:00<?, ?it/s]Evaluating:   1%|          | 1/159 [00:00<02:20,  1.12it/s]Evaluating:   1%|▏         | 2/159 [00:01<01:29,  1.76it/s]Evaluating:   2%|▏         | 3/159 [00:01<01:12,  2.15it/s]Evaluating:   3%|▎         | 4/159 [00:01<01:04,  2.40it/s]Evaluating:   3%|▎         | 5/159 [00:02<01:00,  2.56it/s]Evaluating:   4%|▍         | 6/159 [00:02<00:57,  2.67it/s]Evaluating:   4%|▍         | 7/159 [00:02<00:55,  2.74it/s]Evaluating:   5%|▌         | 8/159 [00:03<00:54,  2.79it/s]Evaluating:   6%|▌         | 9/159 [00:03<00:52,  2.83it/s]Evaluating:   6%|▋         | 10/159 [00:03<00:52,  2.85it/s]Evaluating:   7%|▋         | 11/159 [00:04<00:51,  2.87it/s]Evaluating:   8%|▊         | 12/159 [00:04<00:50,  2.89it/s]Evaluating:   8%|▊         | 13/159 [00:05<00:50,  2.90it/s]Evaluating:   9%|▉         | 14/159 [00:05<00:49,  2.90it/s]Evaluating:   9%|▉         | 15/159 [00:05<00:49,  2.91it/s]Evaluating:  10%|█         | 16/159 [00:06<00:49,  2.91it/s]Evaluating:  11%|█         | 17/159 [00:06<00:48,  2.90it/s]Evaluating:  11%|█▏        | 18/159 [00:06<00:48,  2.90it/s]Evaluating:  12%|█▏        | 19/159 [00:07<00:48,  2.90it/s]Evaluating:  13%|█▎        | 20/159 [00:07<00:48,  2.90it/s]Evaluating:  13%|█▎        | 21/159 [00:07<00:47,  2.89it/s]Evaluating:  14%|█▍        | 22/159 [00:08<00:47,  2.88it/s]Evaluating:  14%|█▍        | 23/159 [00:08<00:47,  2.89it/s]Evaluating:  15%|█▌        | 24/159 [00:08<00:46,  2.89it/s]Evaluating:  16%|█▌        | 25/159 [00:09<00:46,  2.90it/s]Evaluating:  16%|█▋        | 26/159 [00:09<00:45,  2.91it/s]Evaluating:  17%|█▋        | 27/159 [00:09<00:45,  2.92it/s]Evaluating:  18%|█▊        | 28/159 [00:10<00:44,  2.92it/s]Evaluating:  18%|█▊        | 29/159 [00:10<00:44,  2.92it/s]Evaluating:  19%|█▉        | 30/159 [00:10<00:44,  2.92it/s]Evaluating:  19%|█▉        | 31/159 [00:11<00:43,  2.92it/s]Evaluating:  20%|██        | 32/159 [00:11<00:43,  2.92it/s]Evaluating:  21%|██        | 33/159 [00:11<00:43,  2.92it/s]Evaluating:  21%|██▏       | 34/159 [00:12<00:42,  2.92it/s]Evaluating:  22%|██▏       | 35/159 [00:12<00:42,  2.92it/s]Evaluating:  23%|██▎       | 36/159 [00:12<00:42,  2.93it/s]Evaluating:  23%|██▎       | 37/159 [00:13<00:41,  2.93it/s]Evaluating:  24%|██▍       | 38/159 [00:13<00:41,  2.92it/s]Evaluating:  25%|██▍       | 39/159 [00:13<00:41,  2.92it/s]Evaluating:  25%|██▌       | 40/159 [00:14<00:40,  2.92it/s]Evaluating:  26%|██▌       | 41/159 [00:14<00:40,  2.91it/s]Evaluating:  26%|██▋       | 42/159 [00:14<00:40,  2.91it/s]Evaluating:  27%|██▋       | 43/159 [00:15<00:39,  2.90it/s]Evaluating:  28%|██▊       | 44/159 [00:15<00:39,  2.90it/s]Evaluating:  28%|██▊       | 45/159 [00:16<00:39,  2.91it/s]Evaluating:  29%|██▉       | 46/159 [00:16<00:38,  2.91it/s]Evaluating:  30%|██▉       | 47/159 [00:16<00:38,  2.92it/s]Evaluating:  30%|███       | 48/159 [00:17<00:37,  2.92it/s]Evaluating:  31%|███       | 49/159 [00:17<00:37,  2.92it/s]Evaluating:  31%|███▏      | 50/159 [00:17<00:37,  2.92it/s]Evaluating:  32%|███▏      | 51/159 [00:18<00:36,  2.92it/s]Evaluating:  33%|███▎      | 52/159 [00:18<00:36,  2.91it/s]Evaluating:  33%|███▎      | 53/159 [00:18<00:36,  2.90it/s]Evaluating:  34%|███▍      | 54/159 [00:19<00:36,  2.90it/s]Evaluating:  35%|███▍      | 55/159 [00:19<00:35,  2.89it/s]Evaluating:  35%|███▌      | 56/159 [00:19<00:35,  2.88it/s]Evaluating:  36%|███▌      | 57/159 [00:20<00:35,  2.89it/s]Evaluating:  36%|███▋      | 58/159 [00:20<00:34,  2.89it/s]Evaluating:  37%|███▋      | 59/159 [00:20<00:34,  2.90it/s]Evaluating:  38%|███▊      | 60/159 [00:21<00:34,  2.91it/s]Evaluating:  38%|███▊      | 61/159 [00:21<00:33,  2.91it/s]Evaluating:  39%|███▉      | 62/159 [00:21<00:33,  2.91it/s]Evaluating:  40%|███▉      | 63/159 [00:22<00:32,  2.92it/s]Evaluating:  40%|████      | 64/159 [00:22<00:32,  2.92it/s]Evaluating:  41%|████      | 65/159 [00:22<00:32,  2.91it/s]Evaluating:  42%|████▏     | 66/159 [00:23<00:31,  2.91it/s]Evaluating:  42%|████▏     | 67/159 [00:23<00:31,  2.90it/s]Evaluating:  43%|████▎     | 68/159 [00:23<00:31,  2.90it/s]Evaluating:  43%|████▎     | 69/159 [00:24<00:30,  2.91it/s]Evaluating:  44%|████▍     | 70/159 [00:24<00:30,  2.90it/s]Evaluating:  45%|████▍     | 71/159 [00:24<00:30,  2.91it/s]Evaluating:  45%|████▌     | 72/159 [00:25<00:30,  2.90it/s]Evaluating:  46%|████▌     | 73/159 [00:25<00:29,  2.90it/s]Evaluating:  47%|████▋     | 74/159 [00:25<00:29,  2.90it/s]Evaluating:  47%|████▋     | 75/159 [00:26<00:28,  2.90it/s]Evaluating:  48%|████▊     | 76/159 [00:26<00:28,  2.90it/s]Evaluating:  48%|████▊     | 77/159 [00:27<00:28,  2.91it/s]Evaluating:  49%|████▉     | 78/159 [00:27<00:27,  2.91it/s]Evaluating:  50%|████▉     | 79/159 [00:27<00:27,  2.91it/s]Evaluating:  50%|█████     | 80/159 [00:28<00:27,  2.91it/s]Evaluating:  51%|█████     | 81/159 [00:28<00:26,  2.91it/s]Evaluating:  52%|█████▏    | 82/159 [00:28<00:26,  2.91it/s]Evaluating:  52%|█████▏    | 83/159 [00:29<00:26,  2.91it/s]Evaluating:  53%|█████▎    | 84/159 [00:29<00:25,  2.90it/s]Evaluating:  53%|█████▎    | 85/159 [00:29<00:25,  2.91it/s]Evaluating:  54%|█████▍    | 86/159 [00:30<00:25,  2.91it/s]Evaluating:  55%|█████▍    | 87/159 [00:30<00:24,  2.91it/s]Evaluating:  55%|█████▌    | 88/159 [00:30<00:24,  2.92it/s]Evaluating:  56%|█████▌    | 89/159 [00:31<00:24,  2.92it/s]Evaluating:  57%|█████▋    | 90/159 [00:31<00:23,  2.92it/s]Evaluating:  57%|█████▋    | 91/159 [00:31<00:23,  2.92it/s]Evaluating:  58%|█████▊    | 92/159 [00:32<00:22,  2.92it/s]Evaluating:  58%|█████▊    | 93/159 [00:32<00:22,  2.92it/s]Evaluating:  59%|█████▉    | 94/159 [00:32<00:22,  2.92it/s]Evaluating:  60%|█████▉    | 95/159 [00:33<00:21,  2.91it/s]Evaluating:  60%|██████    | 96/159 [00:33<00:21,  2.91it/s]Evaluating:  61%|██████    | 97/159 [00:33<00:21,  2.91it/s]Evaluating:  62%|██████▏   | 98/159 [00:34<00:20,  2.91it/s]Evaluating:  62%|██████▏   | 99/159 [00:34<00:20,  2.90it/s]Evaluating:  63%|██████▎   | 100/159 [00:34<00:20,  2.91it/s]Evaluating:  64%|██████▎   | 101/159 [00:35<00:19,  2.91it/s]Evaluating:  64%|██████▍   | 102/159 [00:35<00:19,  2.90it/s]Evaluating:  65%|██████▍   | 103/159 [00:35<00:19,  2.90it/s]Evaluating:  65%|██████▌   | 104/159 [00:36<00:18,  2.91it/s]Evaluating:  66%|██████▌   | 105/159 [00:36<00:18,  2.90it/s]Evaluating:  67%|██████▋   | 106/159 [00:36<00:18,  2.89it/s]Evaluating:  67%|██████▋   | 107/159 [00:37<00:17,  2.90it/s]Evaluating:  68%|██████▊   | 108/159 [00:37<00:17,  2.91it/s]Evaluating:  69%|██████▊   | 109/159 [00:38<00:17,  2.90it/s]Evaluating:  69%|██████▉   | 110/159 [00:38<00:16,  2.91it/s]Evaluating:  70%|██████▉   | 111/159 [00:38<00:16,  2.89it/s]Evaluating:  70%|███████   | 112/159 [00:39<00:16,  2.90it/s]Evaluating:  71%|███████   | 113/159 [00:39<00:15,  2.91it/s]Evaluating:  72%|███████▏  | 114/159 [00:39<00:15,  2.90it/s]Evaluating:  72%|███████▏  | 115/159 [00:40<00:15,  2.89it/s]Evaluating:  73%|███████▎  | 116/159 [00:40<00:14,  2.90it/s]Evaluating:  74%|███████▎  | 117/159 [00:40<00:14,  2.91it/s]Evaluating:  74%|███████▍  | 118/159 [00:41<00:14,  2.92it/s]Evaluating:  75%|███████▍  | 119/159 [00:41<00:13,  2.92it/s]Evaluating:  75%|███████▌  | 120/159 [00:41<00:13,  2.92it/s]Evaluating:  76%|███████▌  | 121/159 [00:42<00:13,  2.92it/s]Evaluating:  77%|███████▋  | 122/159 [00:42<00:12,  2.92it/s]Evaluating:  77%|███████▋  | 123/159 [00:42<00:12,  2.92it/s]Evaluating:  78%|███████▊  | 124/159 [00:43<00:12,  2.92it/s]Evaluating:  79%|███████▊  | 125/159 [00:43<00:11,  2.91it/s]Evaluating:  79%|███████▉  | 126/159 [00:43<00:11,  2.91it/s]Evaluating:  80%|███████▉  | 127/159 [00:44<00:11,  2.91it/s]Evaluating:  81%|████████  | 128/159 [00:44<00:10,  2.91it/s]Evaluating:  81%|████████  | 129/159 [00:44<00:10,  2.90it/s]Evaluating:  82%|████████▏ | 130/159 [00:45<00:10,  2.84it/s]Evaluating:  82%|████████▏ | 131/159 [00:45<00:09,  2.86it/s]Evaluating:  83%|████████▎ | 132/159 [00:45<00:09,  2.88it/s]Evaluating:  84%|████████▎ | 133/159 [00:46<00:09,  2.88it/s]Evaluating:  84%|████████▍ | 134/159 [00:46<00:08,  2.88it/s]Evaluating:  85%|████████▍ | 135/159 [00:46<00:08,  2.88it/s]Evaluating:  86%|████████▌ | 136/159 [00:47<00:07,  2.88it/s]Evaluating:  86%|████████▌ | 137/159 [00:47<00:07,  2.88it/s]Evaluating:  87%|████████▋ | 138/159 [00:48<00:07,  2.89it/s]Evaluating:  87%|████████▋ | 139/159 [00:48<00:06,  2.89it/s]Evaluating:  88%|████████▊ | 140/159 [00:48<00:06,  2.90it/s]Evaluating:  89%|████████▊ | 141/159 [00:49<00:06,  2.91it/s]Evaluating:  89%|████████▉ | 142/159 [00:49<00:05,  2.90it/s]Evaluating:  90%|████████▉ | 143/159 [00:49<00:05,  2.91it/s]Evaluating:  91%|█████████ | 144/159 [00:50<00:05,  2.91it/s]Evaluating:  91%|█████████ | 145/159 [00:50<00:04,  2.91it/s]Evaluating:  92%|█████████▏| 146/159 [00:50<00:04,  2.92it/s]Evaluating:  92%|█████████▏| 147/159 [00:51<00:04,  2.91it/s]Evaluating:  93%|█████████▎| 148/159 [00:51<00:03,  2.91it/s]Evaluating:  94%|█████████▎| 149/159 [00:51<00:03,  2.90it/s]Evaluating:  94%|█████████▍| 150/159 [00:52<00:03,  2.91it/s]Evaluating:  95%|█████████▍| 151/159 [00:52<00:02,  2.91it/s]Evaluating:  96%|█████████▌| 152/159 [00:52<00:02,  2.91it/s]Evaluating:  96%|█████████▌| 153/159 [00:53<00:02,  2.91it/s]Evaluating:  97%|█████████▋| 154/159 [00:53<00:01,  2.92it/s]Evaluating:  97%|█████████▋| 155/159 [00:53<00:01,  2.91it/s]Evaluating:  98%|█████████▊| 156/159 [00:54<00:01,  2.91it/s]Evaluating:  99%|█████████▊| 157/159 [00:54<00:00,  2.91it/s]Evaluating:  99%|█████████▉| 158/159 [00:54<00:00,  2.89it/s]Evaluating: 100%|██████████| 159/159 [00:55<00:00,  3.10it/s]Evaluating: 100%|██████████| 159/159 [00:55<00:00,  2.88it/s]
05/09/2022 08:57:55 - INFO - __main__ -     Evaluation done in total 55.171847 secs (0.043442 sec per example)
05/09/2022 08:58:02 - INFO - __main__ -   Results: {'exact': 76.63865546218487, 'f1': 87.55974375934419, 'total': 1190, 'HasAns_exact': 76.63865546218487, 'HasAns_f1': 87.55974375934419, 'HasAns_total': 1190, 'best_exact': 76.63865546218487, 'best_exact_thresh': 0.0, 'best_f1': 87.55974375934419, 'best_f1_thresh': 0.0}
  es 
2022-05-09 08:58:05.667776: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0
05/09/2022 08:58:09 - WARNING - __main__ -   Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, 16-bits training: False
You are using a model of type xlm-roberta to instantiate a model of type xlm. This is not supported for all configurations of models and can yield errors.
Some weights of the model checkpoint at /cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//squad/xlm-KG_LR3e-5_EPOCH2.0_maxlen384_batchsize4_gradacc4 were not used when initializing XLMRobertaModel: ['base_model.encoder.layer.15.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.19.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.9.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.8.attention.output.dense.weight', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.6.attention.output.dense.weight', 'base_model.encoder.layer.8.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.16.attention.self.query.weight', 'base_model.encoder.layer.22.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.14.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.17.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.11.attention.output.dense.bias', 'base_model.encoder.layer.21.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.5.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.6.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.1.output.LayerNorm.bias', 'base_model.encoder.layer.14.attention.self.query.weight', 'base_model.encoder.layer.4.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.16.attention.output.dense.bias', 'base_model.encoder.layer.19.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.0.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.10.attention.output.dense.weight', 'base_model.encoder.layer.15.output.LayerNorm.bias', 'base_model.encoder.layer.2.attention.self.query.weight', 'base_model.encoder.layer.14.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.8.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.15.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.15.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.21.output.dense.bias', 'base_model.encoder.layer.2.intermediate.dense.bias', 'base_model.pooler.dense.weight', 'base_model.encoder.layer.11.attention.output.LayerNorm.bias', 'base_model.encoder.layer.11.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.20.attention.output.dense.weight', 'base_model.encoder.layer.18.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.7.attention.self.value.bias', 'base_model.encoder.layer.1.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.20.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.17.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.10.attention.output.dense.bias', 'base_model.encoder.layer.16.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.18.intermediate.dense.weight', 'base_model.encoder.layer.19.attention.output.dense.bias', 'base_model.encoder.layer.21.output.adapters.tp.adapter_down.0.weight', 'qa_outputs.bias', 'base_model.encoder.layer.16.attention.output.LayerNorm.bias', 'base_model.encoder.layer.18.attention.self.query.weight', 'base_model.embeddings.token_type_embeddings.weight', 'base_model.encoder.layer.0.attention.output.LayerNorm.bias', 'base_model.encoder.layer.5.attention.self.query.bias', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.21.output.LayerNorm.bias', 'base_model.encoder.layer.0.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.5.attention.self.value.weight', 'base_model.encoder.layer.23.output.LayerNorm.weight', 'base_model.encoder.layer.13.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.15.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.17.intermediate.dense.bias', 'base_model.encoder.layer.14.intermediate.dense.bias', 'base_model.encoder.layer.9.attention.self.key.bias', 'base_model.encoder.layer.17.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.10.attention.output.LayerNorm.weight', 'base_model.encoder.layer.22.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.22.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.1.attention.self.query.weight', 'base_model.encoder.layer.5.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.0.attention.self.key.bias', 'base_model.encoder.layer.15.attention.self.key.bias', 'base_model.encoder.layer.3.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.6.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.9.attention.output.dense.weight', 'base_model.encoder.layer.1.output.dense.weight', 'base_model.encoder.layer.1.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.5.attention.output.LayerNorm.weight', 'base_model.encoder.layer.13.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.16.output.dense.weight', 'base_model.encoder.layer.18.attention.output.dense.weight', 'base_model.encoder.layer.21.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.21.intermediate.dense.weight', 'base_model.encoder.layer.21.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.6.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.15.attention.output.LayerNorm.weight', 'base_model.encoder.layer.1.intermediate.dense.weight', 'base_model.encoder.layer.9.attention.self.query.bias', 'base_model.encoder.layer.19.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.8.attention.output.LayerNorm.weight', 'base_model.encoder.layer.2.intermediate.dense.weight', 'base_model.encoder.layer.10.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.17.attention.output.LayerNorm.weight', 'base_model.encoder.layer.21.attention.self.value.weight', 'base_model.encoder.layer.5.output.LayerNorm.bias', 'base_model.encoder.layer.22.intermediate.dense.weight', 'base_model.encoder.layer.19.attention.output.LayerNorm.bias', 'base_model.encoder.layer.3.attention.output.LayerNorm.bias', 'base_model.encoder.layer.6.attention.output.dense.bias', 'base_model.encoder.layer.5.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.7.output.dense.weight', 'base_model.encoder.layer.0.intermediate.dense.bias', 'base_model.encoder.layer.8.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.20.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.4.output.LayerNorm.weight', 'base_model.encoder.layer.0.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.12.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.21.attention.self.key.weight', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.0.attention.self.value.bias', 'base_model.encoder.layer.13.attention.self.value.weight', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.22.output.LayerNorm.weight', 'base_model.encoder.layer.9.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.19.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.12.attention.self.key.weight', 'base_model.encoder.layer.23.output.dense.bias', 'base_model.encoder.layer.18.output.dense.bias', 'base_model.encoder.layer.8.intermediate.dense.weight', 'base_model.encoder.layer.17.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.2.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.6.attention.self.value.bias', 'base_model.encoder.layer.7.output.LayerNorm.bias', 'base_model.encoder.layer.18.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.10.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.5.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.1.attention.self.value.bias', 'base_model.encoder.layer.19.attention.output.LayerNorm.weight', 'base_model.encoder.layer.7.attention.output.LayerNorm.weight', 'base_model.encoder.layer.14.intermediate.dense.weight', 'base_model.encoder.layer.8.attention.output.dense.bias', 'base_model.encoder.layer.5.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.19.attention.self.key.bias', 'base_model.encoder.layer.11.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.5.output.dense.bias', 'base_model.encoder.layer.0.output.LayerNorm.weight', 'base_model.encoder.layer.19.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.0.output.dense.bias', 'base_model.encoder.layer.14.attention.output.dense.weight', 'base_model.encoder.layer.20.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.8.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.10.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.7.output.LayerNorm.weight', 'base_model.encoder.layer.13.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.0.intermediate.dense.weight', 'base_model.encoder.layer.9.attention.output.LayerNorm.weight', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.16.attention.self.key.weight', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.20.attention.self.query.weight', 'base_model.encoder.layer.19.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.0.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.16.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.14.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.0.attention.self.query.weight', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.2.attention.self.key.bias', 'base_model.encoder.layer.15.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.12.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.10.intermediate.dense.bias', 'base_model.encoder.layer.20.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.1.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.2.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.9.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.13.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.18.attention.self.value.bias', 'base_model.encoder.layer.19.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.4.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.7.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.6.output.LayerNorm.weight', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.17.attention.self.value.weight', 'base_model.encoder.layer.17.output.LayerNorm.bias', 'base_model.encoder.layer.17.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.6.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.10.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.21.attention.self.key.bias', 'base_model.encoder.layer.19.intermediate.dense.bias', 'base_model.encoder.layer.8.attention.self.value.bias', 'base_model.encoder.layer.7.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.4.attention.output.dense.bias', 'base_model.encoder.layer.11.intermediate.dense.bias', 'base_model.encoder.layer.19.output.dense.bias', 'base_model.encoder.layer.1.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.4.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.0.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.6.output.LayerNorm.bias', 'base_model.encoder.layer.17.attention.output.LayerNorm.bias', 'base_model.pooler.dense.bias', 'base_model.encoder.layer.11.output.dense.weight', 'base_model.encoder.layer.9.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.15.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.19.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.9.intermediate.dense.bias', 'base_model.encoder.layer.8.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.6.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.19.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.7.attention.self.query.bias', 'base_model.encoder.layer.22.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.6.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.10.intermediate.dense.weight', 'base_model.encoder.layer.13.attention.output.dense.weight', 'base_model.encoder.layer.7.intermediate.dense.weight', 'base_model.encoder.layer.12.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.17.output.dense.bias', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.10.attention.self.query.bias', 'base_model.encoder.layer.14.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.0.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.8.intermediate.dense.bias', 'base_model.encoder.layer.12.attention.output.LayerNorm.bias', 'base_model.encoder.layer.4.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.6.attention.self.value.weight', 'base_model.encoder.layer.15.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.16.attention.self.value.bias', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.8.attention.self.key.weight', 'base_model.encoder.layer.7.attention.self.value.weight', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.21.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.18.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.16.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.11.intermediate.dense.weight', 'base_model.encoder.layer.15.attention.self.value.weight', 'base_model.encoder.layer.6.attention.output.LayerNorm.weight', 'base_model.encoder.layer.14.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.3.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.10.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.23.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.1.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.16.attention.output.LayerNorm.weight', 'base_model.encoder.layer.6.attention.self.key.weight', 'base_model.encoder.layer.9.output.dense.bias', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.13.attention.output.LayerNorm.bias', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.3.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.10.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.10.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.21.output.dense.weight', 'base_model.encoder.layer.16.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.9.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.2.attention.self.value.bias', 'base_model.encoder.layer.22.intermediate.dense.bias', 'base_model.encoder.layer.14.attention.self.key.weight', 'base_model.encoder.layer.14.attention.self.key.bias', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.3.attention.self.key.bias', 'base_model.encoder.layer.13.intermediate.dense.bias', 'base_model.encoder.layer.21.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.18.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.0.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.6.attention.self.key.bias', 'base_model.encoder.layer.22.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.13.attention.self.query.weight', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.8.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.7.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.2.attention.output.dense.bias', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.18.output.LayerNorm.weight', 'base_model.encoder.layer.2.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.12.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.6.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.3.attention.self.value.weight', 'base_model.encoder.layer.5.intermediate.dense.weight', 'base_model.encoder.layer.1.attention.output.LayerNorm.bias', 'base_model.encoder.layer.0.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.9.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.11.output.LayerNorm.bias', 'base_model.encoder.layer.18.attention.self.key.weight', 'base_model.encoder.layer.6.attention.self.query.weight', 'base_model.encoder.layer.18.attention.output.dense.bias', 'base_model.encoder.layer.8.output.dense.weight', 'base_model.encoder.layer.15.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.15.attention.output.LayerNorm.bias', 'base_model.encoder.layer.16.output.LayerNorm.weight', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.1.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.12.attention.self.key.bias', 'base_model.encoder.layer.13.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.3.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.10.output.LayerNorm.bias', 'base_model.encoder.layer.13.attention.self.value.bias', 'base_model.encoder.layer.14.output.dense.weight', 'base_model.encoder.layer.17.attention.self.query.bias', 'base_model.encoder.layer.19.attention.self.query.bias', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.23.intermediate.dense.bias', 'base_model.encoder.layer.22.attention.output.LayerNorm.bias', 'base_model.encoder.layer.11.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.20.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.23.attention.output.dense.weight', 'base_model.encoder.layer.5.output.dense.weight', 'base_model.encoder.layer.9.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.15.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.22.attention.output.LayerNorm.weight', 'base_model.encoder.layer.22.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.3.attention.output.LayerNorm.weight', 'base_model.encoder.layer.22.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.7.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.2.output.LayerNorm.weight', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.17.attention.self.key.bias', 'base_model.encoder.layer.4.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.3.intermediate.dense.weight', 'base_model.encoder.layer.13.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.18.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.10.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.6.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.11.attention.self.query.bias', 'base_model.encoder.layer.19.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.19.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.22.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.23.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.18.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.1.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.11.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.7.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.3.output.adapters.es.adapter_down.0.bias', 'base_model.embeddings.LayerNorm.bias', 'base_model.encoder.layer.11.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.23.attention.output.LayerNorm.bias', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.3.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.4.attention.self.key.bias', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.17.attention.self.query.weight', 'base_model.encoder.layer.7.intermediate.dense.bias', 'base_model.encoder.layer.5.attention.output.LayerNorm.bias', 'base_model.encoder.layer.9.attention.self.value.weight', 'base_model.encoder.layer.13.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.22.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.3.attention.output.dense.weight', 'base_model.encoder.layer.22.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.3.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.13.attention.output.LayerNorm.weight', 'base_model.encoder.layer.11.attention.self.key.weight', 'base_model.encoder.layer.3.output.LayerNorm.weight', 'base_model.encoder.layer.7.attention.output.dense.bias', 'base_model.encoder.layer.15.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.16.intermediate.dense.bias', 'base_model.encoder.layer.18.attention.self.key.bias', 'base_model.encoder.layer.20.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.15.output.dense.bias', 'base_model.encoder.layer.23.attention.self.value.weight', 'base_model.encoder.layer.9.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.14.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.10.attention.self.value.bias', 'base_model.encoder.layer.20.output.LayerNorm.bias', 'base_model.encoder.layer.0.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.18.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.20.attention.self.query.bias', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.12.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.20.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.0.attention.self.value.weight', 'base_model.encoder.layer.4.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.19.output.LayerNorm.weight', 'base_model.encoder.layer.14.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.7.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.12.attention.self.value.bias', 'base_model.encoder.layer.13.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.19.intermediate.dense.weight', 'base_model.embeddings.word_embeddings.weight', 'base_model.encoder.layer.6.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.1.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.22.attention.self.value.bias', 'base_model.encoder.layer.16.intermediate.dense.weight', 'base_model.encoder.layer.13.output.LayerNorm.bias', 'base_model.encoder.layer.20.output.dense.bias', 'base_model.encoder.layer.3.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.14.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.21.attention.output.LayerNorm.weight', 'base_model.encoder.layer.5.attention.output.dense.weight', 'base_model.encoder.layer.18.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.23.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.17.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.10.output.LayerNorm.weight', 'base_model.encoder.layer.13.output.dense.weight', 'base_model.encoder.layer.15.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.6.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.10.output.dense.weight', 'base_model.encoder.layer.0.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.22.output.dense.weight', 'base_model.encoder.layer.12.intermediate.dense.bias', 'base_model.encoder.layer.23.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.1.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.0.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.23.intermediate.dense.weight', 'base_model.embeddings.position_embeddings.weight', 'base_model.encoder.layer.21.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.22.attention.self.key.weight', 'base_model.encoder.layer.14.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.5.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.10.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.16.attention.self.query.bias', 'base_model.encoder.layer.8.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.1.output.LayerNorm.weight', 'base_model.encoder.layer.12.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.23.attention.self.key.bias', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.20.output.dense.weight', 'base_model.encoder.layer.18.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.17.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.4.attention.output.LayerNorm.bias', 'base_model.encoder.layer.11.output.LayerNorm.weight', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.19.attention.self.key.weight', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.21.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.21.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.3.attention.self.value.bias', 'base_model.encoder.layer.23.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.14.output.LayerNorm.weight', 'base_model.encoder.layer.22.output.LayerNorm.bias', 'base_model.encoder.layer.20.attention.self.value.bias', 'base_model.encoder.layer.4.attention.self.key.weight', 'base_model.encoder.layer.7.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.20.output.LayerNorm.weight', 'base_model.encoder.layer.14.attention.self.query.bias', 'base_model.encoder.layer.16.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.6.output.dense.weight', 'base_model.encoder.layer.15.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.0.attention.output.dense.weight', 'base_model.encoder.layer.19.output.LayerNorm.bias', 'base_model.encoder.layer.5.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.21.attention.self.value.bias', 'base_model.encoder.layer.10.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.20.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.1.attention.self.value.weight', 'base_model.encoder.layer.9.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.0.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.23.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.8.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.5.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.5.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.17.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.17.intermediate.dense.weight', 'base_model.encoder.layer.3.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.13.attention.self.key.bias', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.2.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.18.output.dense.weight', 'base_model.encoder.layer.19.attention.self.query.weight', 'base_model.encoder.layer.22.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.2.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.9.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.16.output.LayerNorm.bias', 'base_model.encoder.layer.12.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.13.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.7.attention.output.dense.weight', 'base_model.encoder.layer.11.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.14.output.adapters.tp.adapter_down.0.bias', 'qa_outputs.weight', 'base_model.encoder.layer.5.attention.self.query.weight', 'base_model.encoder.layer.5.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.10.attention.output.LayerNorm.bias', 'base_model.encoder.layer.6.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.7.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.20.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.19.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.23.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.11.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.12.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.7.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.12.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.9.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.9.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.2.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.12.attention.output.dense.weight', 'base_model.encoder.layer.2.attention.output.dense.weight', 'base_model.encoder.layer.14.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.16.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.22.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.13.attention.self.query.bias', 'base_model.encoder.layer.14.attention.output.LayerNorm.bias', 'base_model.encoder.layer.5.attention.output.dense.bias', 'base_model.encoder.layer.11.output.dense.bias', 'base_model.encoder.layer.16.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.9.output.dense.weight', 'base_model.encoder.layer.21.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.11.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.3.attention.self.query.bias', 'base_model.encoder.layer.5.intermediate.dense.bias', 'base_model.encoder.layer.8.output.LayerNorm.weight', 'base_model.encoder.layer.23.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.7.attention.self.query.weight', 'base_model.encoder.layer.1.intermediate.dense.bias', 'base_model.encoder.layer.12.output.LayerNorm.bias', 'base_model.encoder.layer.18.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.9.attention.output.dense.bias', 'base_model.encoder.layer.8.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.2.attention.self.key.weight', 'base_model.embeddings.LayerNorm.weight', 'base_model.encoder.layer.4.attention.output.LayerNorm.weight', 'base_model.encoder.layer.7.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.9.intermediate.dense.weight', 'base_model.encoder.layer.11.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.21.attention.output.LayerNorm.bias', 'base_model.encoder.layer.6.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.8.attention.self.query.weight', 'base_model.encoder.layer.12.attention.self.query.weight', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.7.attention.self.key.bias', 'base_model.encoder.layer.13.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.8.output.dense.bias', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.11.attention.output.LayerNorm.weight', 'base_model.encoder.layer.4.attention.self.value.bias', 'base_model.encoder.layer.4.intermediate.dense.weight', 'base_model.encoder.layer.12.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.12.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.4.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.13.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.21.attention.self.query.bias', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.20.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.16.output.dense.bias', 'base_model.encoder.layer.2.attention.output.LayerNorm.bias', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.23.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.0.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.8.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.5.attention.self.value.bias', 'base_model.encoder.layer.2.attention.output.LayerNorm.weight', 'base_model.encoder.layer.3.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.17.attention.output.dense.bias', 'base_model.encoder.layer.13.intermediate.dense.weight', 'base_model.encoder.layer.14.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.4.intermediate.dense.bias', 'base_model.encoder.layer.7.attention.self.key.weight', 'base_model.encoder.layer.17.attention.self.key.weight', 'base_model.encoder.layer.20.attention.output.LayerNorm.weight', 'base_model.embeddings.position_ids', 'base_model.encoder.layer.4.attention.self.value.weight', 'base_model.encoder.layer.11.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.15.attention.self.key.weight', 'base_model.encoder.layer.5.output.LayerNorm.weight', 'base_model.encoder.layer.1.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.15.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.20.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.5.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.13.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.14.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.15.attention.self.query.weight', 'base_model.encoder.layer.21.intermediate.dense.bias', 'base_model.encoder.layer.4.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.10.attention.self.key.bias', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.11.attention.self.key.bias', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.6.attention.output.LayerNorm.bias', 'base_model.encoder.layer.15.attention.output.dense.weight', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.1.attention.self.query.bias', 'base_model.encoder.layer.10.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.15.attention.self.query.bias', 'base_model.encoder.layer.13.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.12.attention.self.query.bias', 'base_model.encoder.layer.15.intermediate.dense.bias', 'base_model.encoder.layer.14.attention.self.value.bias', 'base_model.encoder.layer.11.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.3.attention.self.query.weight', 'base_model.encoder.layer.18.output.LayerNorm.bias', 'base_model.encoder.layer.20.attention.output.dense.bias', 'base_model.encoder.layer.18.attention.output.LayerNorm.bias', 'base_model.encoder.layer.12.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.23.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.8.attention.output.LayerNorm.bias', 'base_model.encoder.layer.2.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.13.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.22.output.dense.bias', 'base_model.encoder.layer.2.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.23.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.4.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.1.attention.output.LayerNorm.weight', 'base_model.encoder.layer.4.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.0.attention.output.dense.bias', 'base_model.encoder.layer.1.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.5.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.2.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.1.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.16.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.17.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.21.output.LayerNorm.weight', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.3.output.dense.weight', 'base_model.encoder.layer.16.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.4.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.9.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.2.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.23.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.10.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.21.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.6.attention.self.query.bias', 'base_model.encoder.layer.8.attention.self.key.bias', 'base_model.encoder.layer.11.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.9.output.LayerNorm.bias', 'base_model.encoder.layer.1.attention.output.dense.bias', 'base_model.encoder.layer.4.attention.self.query.weight', 'base_model.encoder.layer.5.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.19.attention.output.dense.weight', 'base_model.encoder.layer.8.output.LayerNorm.bias', 'base_model.encoder.layer.16.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.21.attention.self.query.weight', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.3.attention.self.key.weight', 'base_model.encoder.layer.6.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.10.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.17.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.19.attention.self.value.weight', 'base_model.encoder.layer.17.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.5.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.23.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.13.attention.self.key.weight', 'base_model.encoder.layer.23.attention.self.key.weight', 'base_model.encoder.layer.8.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.20.attention.self.key.bias', 'base_model.encoder.layer.3.output.LayerNorm.bias', 'base_model.encoder.layer.0.attention.self.query.bias', 'base_model.encoder.layer.0.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.11.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.2.output.LayerNorm.bias', 'base_model.encoder.layer.22.attention.self.query.weight', 'base_model.encoder.layer.2.output.dense.bias', 'base_model.encoder.layer.16.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.14.attention.self.value.weight', 'base_model.encoder.layer.5.attention.self.key.weight', 'base_model.encoder.layer.20.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.9.attention.output.LayerNorm.bias', 'base_model.encoder.layer.11.attention.self.value.bias', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.22.attention.self.key.bias', 'base_model.encoder.layer.10.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.6.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.18.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.9.attention.self.query.weight', 'base_model.encoder.layer.7.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.8.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.20.attention.output.LayerNorm.bias', 'base_model.encoder.layer.18.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.20.intermediate.dense.weight', 'base_model.encoder.layer.12.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.20.attention.self.value.weight', 'base_model.encoder.layer.2.attention.self.value.weight', 'base_model.encoder.layer.7.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.7.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.21.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.12.attention.output.LayerNorm.weight', 'base_model.encoder.layer.11.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.3.intermediate.dense.bias', 'base_model.encoder.layer.1.output.dense.bias', 'base_model.encoder.layer.2.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.11.attention.self.value.weight', 'base_model.encoder.layer.1.attention.self.key.bias', 'base_model.encoder.layer.6.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.23.attention.self.query.weight', 'base_model.encoder.layer.17.output.dense.weight', 'base_model.encoder.layer.13.output.dense.bias', 'base_model.encoder.layer.6.output.dense.bias', 'base_model.encoder.layer.17.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.15.output.dense.weight', 'base_model.encoder.layer.12.attention.self.value.weight', 'base_model.encoder.layer.9.output.LayerNorm.weight', 'base_model.encoder.layer.10.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.19.output.dense.weight', 'base_model.encoder.layer.22.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.23.attention.self.query.bias', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.9.attention.self.key.weight', 'base_model.encoder.layer.16.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.1.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.3.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.23.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.3.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.5.attention.self.key.bias', 'base_model.encoder.layer.11.attention.output.dense.weight', 'base_model.encoder.layer.0.attention.self.key.weight', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.13.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.20.intermediate.dense.bias', 'base_model.encoder.layer.3.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.16.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.18.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.22.attention.output.dense.weight', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.18.attention.self.query.bias', 'base_model.encoder.layer.0.attention.output.LayerNorm.weight', 'base_model.encoder.layer.23.attention.output.LayerNorm.weight', 'base_model.encoder.layer.14.output.LayerNorm.bias', 'base_model.encoder.layer.9.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.20.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.13.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.22.attention.self.query.bias', 'base_model.encoder.layer.15.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.4.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.7.output.dense.bias', 'base_model.encoder.layer.10.attention.self.query.weight', 'base_model.encoder.layer.10.output.dense.bias', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.19.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.20.attention.self.key.weight', 'base_model.encoder.layer.21.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.15.intermediate.dense.weight', 'base_model.encoder.layer.4.attention.output.dense.weight', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.4.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.16.attention.self.key.bias', 'base_model.encoder.layer.5.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.22.attention.self.value.weight', 'base_model.encoder.layer.13.attention.output.dense.bias', 'base_model.encoder.layer.8.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.10.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.1.attention.self.key.weight', 'base_model.encoder.layer.2.attention.self.query.bias', 'base_model.encoder.layer.3.attention.output.dense.bias', 'base_model.encoder.layer.11.attention.self.query.weight', 'base_model.encoder.layer.14.output.dense.bias', 'base_model.encoder.layer.14.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.1.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.12.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.2.output.dense.weight', 'base_model.encoder.layer.22.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.19.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.0.output.dense.weight', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.8.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.12.output.LayerNorm.weight', 'base_model.encoder.layer.0.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.7.attention.output.LayerNorm.bias', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.19.attention.self.value.bias', 'base_model.encoder.layer.6.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.14.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.12.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.14.attention.output.LayerNorm.weight', 'base_model.encoder.layer.18.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.23.output.dense.weight', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.0.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.2.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.9.attention.self.value.bias', 'base_model.encoder.layer.15.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.20.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.3.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.16.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.4.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.10.attention.self.value.weight', 'base_model.encoder.layer.15.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.16.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.20.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.18.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.9.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.16.attention.self.value.weight', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.8.attention.self.query.bias', 'base_model.encoder.layer.23.attention.output.dense.bias', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.1.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.3.output.dense.bias', 'base_model.encoder.layer.4.output.dense.weight', 'base_model.encoder.layer.2.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.15.attention.output.dense.bias', 'base_model.encoder.layer.12.attention.output.dense.bias', 'base_model.encoder.layer.8.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.18.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.4.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.7.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.15.attention.self.value.bias', 'base_model.encoder.layer.8.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.10.attention.self.key.weight', 'base_model.encoder.layer.17.attention.output.dense.weight', 'base_model.encoder.layer.22.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.1.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.3.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.17.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.23.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.17.output.LayerNorm.weight', 'base_model.encoder.layer.2.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.12.output.dense.bias', 'base_model.encoder.layer.15.output.LayerNorm.weight', 'base_model.encoder.layer.18.attention.self.value.weight', 'base_model.encoder.layer.17.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.21.attention.output.dense.weight', 'base_model.encoder.layer.16.attention.output.dense.weight', 'base_model.encoder.layer.4.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.4.output.LayerNorm.bias', 'base_model.encoder.layer.23.attention.self.value.bias', 'base_model.encoder.layer.23.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.9.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.17.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.11.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.12.intermediate.dense.weight', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.0.output.LayerNorm.bias', 'base_model.encoder.layer.6.intermediate.dense.bias', 'base_model.encoder.layer.7.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.13.output.LayerNorm.weight', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.14.attention.output.dense.bias', 'base_model.encoder.layer.17.attention.self.value.bias', 'base_model.encoder.layer.20.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.16.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.8.attention.self.value.weight', 'base_model.encoder.layer.18.attention.output.LayerNorm.weight', 'base_model.encoder.layer.1.attention.output.dense.weight', 'base_model.encoder.layer.2.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.22.attention.output.dense.bias', 'base_model.encoder.layer.2.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.14.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.21.attention.output.dense.bias', 'base_model.encoder.layer.19.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.17.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.22.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.18.intermediate.dense.bias', 'base_model.encoder.layer.5.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.4.attention.self.query.bias', 'base_model.encoder.layer.11.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.23.output.LayerNorm.bias', 'base_model.encoder.layer.7.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.4.output.dense.bias', 'base_model.encoder.layer.12.output.dense.weight', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.3.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.21.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.12.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.21.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.19.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.21.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.6.intermediate.dense.weight', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.query.weight']
- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of XLMRobertaModel were not initialized from the model checkpoint at /cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//squad/xlm-KG_LR3e-5_EPOCH2.0_maxlen384_batchsize4_gradacc4 and are newly initialized: ['encoder.layer.16.attention.self.key.weight', 'encoder.layer.15.attention.self.key.bias', 'encoder.layer.19.output.dense.weight', 'encoder.layer.14.attention.output.dense.weight', 'encoder.layer.17.attention.output.LayerNorm.weight', 'encoder.layer.3.attention.self.value.weight', 'embeddings.LayerNorm.weight', 'encoder.layer.12.attention.self.query.weight', 'encoder.layer.17.attention.output.dense.weight', 'encoder.layer.20.attention.output.LayerNorm.bias', 'pooler.dense.bias', 'encoder.layer.21.output.LayerNorm.bias', 'encoder.layer.21.attention.output.dense.bias', 'encoder.layer.12.attention.self.key.bias', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.22.attention.self.key.weight', 'encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.layer.20.attention.self.value.bias', 'embeddings.position_embeddings.weight', 'encoder.layer.7.attention.self.key.weight', 'encoder.layer.0.attention.self.key.bias', 'encoder.layer.19.attention.output.LayerNorm.weight', 'encoder.layer.7.intermediate.dense.bias', 'encoder.layer.9.attention.output.LayerNorm.weight', 'encoder.layer.3.attention.self.value.bias', 'encoder.layer.18.intermediate.dense.bias', 'encoder.layer.15.intermediate.dense.bias', 'encoder.layer.9.attention.self.value.bias', 'encoder.layer.20.attention.self.key.weight', 'encoder.layer.9.output.dense.weight', 'encoder.layer.6.output.LayerNorm.bias', 'encoder.layer.13.attention.output.LayerNorm.weight', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.5.attention.self.value.weight', 'encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.layer.13.output.dense.bias', 'encoder.layer.22.output.LayerNorm.bias', 'encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.layer.6.attention.self.value.bias', 'encoder.layer.22.attention.self.key.bias', 'encoder.layer.7.attention.output.dense.bias', 'encoder.layer.19.attention.output.dense.weight', 'encoder.layer.19.output.LayerNorm.bias', 'encoder.layer.10.output.LayerNorm.bias', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.14.attention.self.query.weight', 'encoder.layer.1.output.dense.bias', 'encoder.layer.21.attention.self.key.weight', 'encoder.layer.21.attention.output.dense.weight', 'encoder.layer.8.attention.self.key.bias', 'embeddings.LayerNorm.bias', 'encoder.layer.21.attention.self.key.bias', 'encoder.layer.16.output.LayerNorm.weight', 'encoder.layer.3.attention.self.key.weight', 'encoder.layer.8.attention.self.query.bias', 'encoder.layer.18.attention.self.value.bias', 'encoder.layer.19.intermediate.dense.weight', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.0.attention.output.LayerNorm.weight', 'encoder.layer.1.attention.output.LayerNorm.weight', 'encoder.layer.22.output.LayerNorm.weight', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.4.attention.self.query.weight', 'encoder.layer.16.attention.self.query.weight', 'encoder.layer.8.attention.self.query.weight', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.17.attention.self.query.bias', 'encoder.layer.23.attention.output.LayerNorm.weight', 'encoder.layer.2.output.dense.weight', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.9.attention.self.query.weight', 'encoder.layer.0.attention.self.query.bias', 'encoder.layer.4.output.dense.weight', 'encoder.layer.3.attention.self.query.bias', 'encoder.layer.15.attention.self.value.weight', 'encoder.layer.11.output.dense.bias', 'encoder.layer.0.attention.self.query.weight', 'encoder.layer.11.attention.self.value.weight', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.14.attention.self.query.bias', 'encoder.layer.3.attention.output.dense.bias', 'encoder.layer.3.attention.self.query.weight', 'encoder.layer.10.attention.self.value.bias', 'encoder.layer.4.attention.output.dense.weight', 'encoder.layer.16.output.dense.bias', 'encoder.layer.7.attention.output.dense.weight', 'encoder.layer.1.attention.self.value.bias', 'encoder.layer.5.output.dense.bias', 'encoder.layer.17.output.dense.weight', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.2.output.dense.bias', 'encoder.layer.7.output.LayerNorm.bias', 'encoder.layer.13.output.LayerNorm.weight', 'encoder.layer.8.attention.output.LayerNorm.bias', 'encoder.layer.23.attention.output.LayerNorm.bias', 'encoder.layer.14.output.dense.bias', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.13.output.dense.weight', 'encoder.layer.4.attention.self.key.bias', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.6.attention.output.LayerNorm.weight', 'encoder.layer.5.attention.self.key.bias', 'encoder.layer.8.output.dense.weight', 'encoder.layer.16.attention.self.value.weight', 'encoder.layer.12.attention.self.key.weight', 'encoder.layer.23.attention.output.dense.bias', 'encoder.layer.23.output.dense.bias', 'encoder.layer.7.attention.self.key.bias', 'encoder.layer.18.attention.self.query.bias', 'encoder.layer.4.attention.output.LayerNorm.bias', 'encoder.layer.14.intermediate.dense.weight', 'encoder.layer.19.attention.self.query.bias', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.10.attention.self.key.weight', 'encoder.layer.19.attention.output.dense.bias', 'encoder.layer.16.attention.self.query.bias', 'encoder.layer.7.output.LayerNorm.weight', 'encoder.layer.6.attention.self.query.bias', 'encoder.layer.11.attention.self.key.weight', 'encoder.layer.17.attention.self.key.bias', 'encoder.layer.13.attention.output.LayerNorm.bias', 'encoder.layer.2.attention.output.dense.weight', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.2.attention.output.LayerNorm.weight', 'encoder.layer.9.output.LayerNorm.bias', 'encoder.layer.14.attention.self.key.bias', 'encoder.layer.15.attention.output.dense.weight', 'encoder.layer.10.intermediate.dense.weight', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.20.attention.output.dense.weight', 'encoder.layer.19.attention.output.LayerNorm.bias', 'encoder.layer.9.output.dense.bias', 'encoder.layer.18.attention.self.key.weight', 'encoder.layer.15.output.LayerNorm.weight', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.13.intermediate.dense.weight', 'encoder.layer.7.attention.self.query.bias', 'encoder.layer.14.intermediate.dense.bias', 'encoder.layer.23.output.LayerNorm.bias', 'encoder.layer.19.attention.self.value.weight', 'encoder.layer.2.attention.self.key.bias', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.22.attention.self.value.weight', 'encoder.layer.12.intermediate.dense.weight', 'encoder.layer.10.attention.self.key.bias', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.18.attention.output.dense.bias', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.7.attention.self.query.weight', 'encoder.layer.2.attention.self.value.bias', 'encoder.layer.21.output.dense.bias', 'encoder.layer.20.attention.self.value.weight', 'encoder.layer.5.attention.output.dense.bias', 'encoder.layer.5.output.LayerNorm.bias', 'encoder.layer.0.output.dense.bias', 'encoder.layer.4.attention.self.query.bias', 'encoder.layer.23.intermediate.dense.bias', 'encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.layer.15.attention.self.query.bias', 'encoder.layer.0.output.dense.weight', 'encoder.layer.0.attention.output.dense.bias', 'encoder.layer.12.attention.output.dense.bias', 'encoder.layer.20.output.LayerNorm.bias', 'encoder.layer.15.output.LayerNorm.bias', 'embeddings.word_embeddings.weight', 'encoder.layer.8.attention.self.key.weight', 'encoder.layer.14.attention.output.dense.bias', 'encoder.layer.22.attention.self.value.bias', 'encoder.layer.5.attention.self.query.bias', 'encoder.layer.14.output.LayerNorm.weight', 'encoder.layer.8.output.LayerNorm.weight', 'encoder.layer.17.output.LayerNorm.weight', 'encoder.layer.3.attention.self.key.bias', 'encoder.layer.15.output.dense.weight', 'encoder.layer.13.attention.self.value.weight', 'encoder.layer.7.attention.self.value.weight', 'encoder.layer.4.attention.self.value.bias', 'encoder.layer.15.attention.output.LayerNorm.bias', 'encoder.layer.9.attention.output.dense.bias', 'encoder.layer.6.output.dense.weight', 'encoder.layer.11.output.LayerNorm.weight', 'encoder.layer.2.attention.self.value.weight', 'encoder.layer.13.attention.output.dense.weight', 'encoder.layer.6.attention.output.LayerNorm.bias', 'encoder.layer.5.output.dense.weight', 'encoder.layer.1.attention.output.dense.weight', 'encoder.layer.3.output.dense.weight', 'encoder.layer.0.attention.output.dense.weight', 'encoder.layer.12.attention.output.LayerNorm.bias', 'encoder.layer.9.attention.self.value.weight', 'encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.layer.13.output.LayerNorm.bias', 'encoder.layer.17.attention.output.LayerNorm.bias', 'encoder.layer.15.attention.self.value.bias', 'encoder.layer.20.output.dense.bias', 'encoder.layer.18.output.dense.bias', 'encoder.layer.7.output.dense.bias', 'encoder.layer.15.attention.self.key.weight', 'encoder.layer.13.attention.output.dense.bias', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.11.output.dense.weight', 'encoder.layer.13.attention.self.key.bias', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.5.attention.output.dense.weight', 'encoder.layer.14.output.LayerNorm.bias', 'encoder.layer.23.output.dense.weight', 'encoder.layer.19.attention.self.query.weight', 'encoder.layer.7.output.dense.weight', 'encoder.layer.13.attention.self.value.bias', 'encoder.layer.10.attention.output.dense.bias', 'encoder.layer.21.output.LayerNorm.weight', 'encoder.layer.15.output.dense.bias', 'encoder.layer.4.attention.self.value.weight', 'encoder.layer.22.intermediate.dense.bias', 'encoder.layer.8.attention.output.LayerNorm.weight', 'encoder.layer.7.attention.output.LayerNorm.weight', 'encoder.layer.17.attention.self.value.bias', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.18.attention.self.value.weight', 'encoder.layer.22.attention.output.dense.weight', 'encoder.layer.12.output.LayerNorm.weight', 'encoder.layer.8.attention.output.dense.weight', 'encoder.layer.8.attention.self.value.weight', 'encoder.layer.9.attention.self.key.weight', 'encoder.layer.19.output.dense.bias', 'encoder.layer.21.attention.self.query.weight', 'encoder.layer.23.attention.output.dense.weight', 'encoder.layer.20.intermediate.dense.weight', 'encoder.layer.23.attention.self.key.bias', 'encoder.layer.12.output.dense.bias', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.14.attention.output.LayerNorm.bias', 'encoder.layer.5.attention.output.LayerNorm.weight', 'encoder.layer.16.intermediate.dense.weight', 'encoder.layer.1.attention.self.value.weight', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.13.attention.self.query.bias', 'encoder.layer.9.output.LayerNorm.weight', 'encoder.layer.15.attention.self.query.weight', 'encoder.layer.16.intermediate.dense.bias', 'encoder.layer.11.output.LayerNorm.bias', 'encoder.layer.1.attention.self.query.bias', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.17.attention.self.value.weight', 'encoder.layer.23.output.LayerNorm.weight', 'encoder.layer.4.output.dense.bias', 'encoder.layer.8.output.LayerNorm.bias', 'encoder.layer.21.attention.self.query.bias', 'encoder.layer.10.attention.output.dense.weight', 'encoder.layer.14.attention.output.LayerNorm.weight', 'encoder.layer.6.attention.self.key.bias', 'encoder.layer.23.attention.self.query.bias', 'encoder.layer.20.attention.output.LayerNorm.weight', 'encoder.layer.14.attention.self.value.bias', 'encoder.layer.10.attention.self.query.weight', 'encoder.layer.12.attention.self.value.weight', 'encoder.layer.13.attention.self.query.weight', 'encoder.layer.9.attention.self.key.bias', 'encoder.layer.23.attention.self.key.weight', 'encoder.layer.9.attention.output.LayerNorm.bias', 'encoder.layer.11.attention.output.LayerNorm.weight', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.4.attention.self.key.weight', 'encoder.layer.1.attention.self.query.weight', 'encoder.layer.22.attention.output.LayerNorm.weight', 'encoder.layer.22.attention.output.dense.bias', 'encoder.layer.12.intermediate.dense.bias', 'encoder.layer.12.attention.self.value.bias', 'encoder.layer.18.output.LayerNorm.weight', 'encoder.layer.19.attention.self.key.weight', 'encoder.layer.16.attention.output.dense.bias', 'encoder.layer.23.attention.self.query.weight', 'encoder.layer.6.attention.self.value.weight', 'encoder.layer.0.attention.self.value.bias', 'encoder.layer.21.output.dense.weight', 'encoder.layer.23.attention.self.value.bias', 'encoder.layer.12.attention.output.LayerNorm.weight', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.17.attention.self.key.weight', 'encoder.layer.2.attention.output.LayerNorm.bias', 'encoder.layer.15.intermediate.dense.weight', 'encoder.layer.17.attention.output.dense.bias', 'encoder.layer.20.output.dense.weight', 'encoder.layer.17.attention.self.query.weight', 'encoder.layer.21.attention.output.LayerNorm.weight', 'encoder.layer.21.attention.self.value.weight', 'encoder.layer.21.intermediate.dense.bias', 'encoder.layer.18.output.dense.weight', 'encoder.layer.19.intermediate.dense.bias', 'encoder.layer.10.attention.output.LayerNorm.bias', 'encoder.layer.8.attention.self.value.bias', 'encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.layer.13.intermediate.dense.bias', 'encoder.layer.22.attention.self.query.bias', 'encoder.layer.11.attention.self.query.bias', 'encoder.layer.21.attention.output.LayerNorm.bias', 'encoder.layer.7.attention.output.LayerNorm.bias', 'encoder.layer.22.attention.self.query.weight', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.16.attention.output.LayerNorm.weight', 'encoder.layer.10.attention.self.value.weight', 'encoder.layer.7.attention.self.value.bias', 'encoder.layer.0.attention.self.value.weight', 'encoder.layer.16.output.dense.weight', 'encoder.layer.16.attention.output.dense.weight', 'encoder.layer.20.attention.self.query.weight', 'encoder.layer.1.attention.output.dense.bias', 'encoder.layer.11.attention.self.value.bias', 'encoder.layer.21.intermediate.dense.weight', 'encoder.layer.11.attention.output.dense.bias', 'encoder.layer.22.attention.output.LayerNorm.bias', 'encoder.layer.2.attention.self.query.weight', 'encoder.layer.10.attention.self.query.bias', 'encoder.layer.22.intermediate.dense.weight', 'encoder.layer.18.attention.self.key.bias', 'encoder.layer.9.attention.output.dense.weight', 'encoder.layer.12.attention.self.query.bias', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.19.output.LayerNorm.weight', 'encoder.layer.20.attention.output.dense.bias', 'encoder.layer.0.attention.self.key.weight', 'encoder.layer.3.output.dense.bias', 'encoder.layer.17.output.dense.bias', 'encoder.layer.8.attention.output.dense.bias', 'encoder.layer.4.attention.output.LayerNorm.weight', 'encoder.layer.18.attention.output.dense.weight', 'encoder.layer.20.intermediate.dense.bias', 'encoder.layer.20.attention.self.query.bias', 'encoder.layer.10.output.LayerNorm.weight', 'encoder.layer.22.output.dense.bias', 'encoder.layer.15.attention.output.LayerNorm.weight', 'encoder.layer.9.attention.self.query.bias', 'encoder.layer.11.attention.self.key.bias', 'encoder.layer.6.attention.output.dense.bias', 'encoder.layer.11.attention.output.dense.weight', 'encoder.layer.20.output.LayerNorm.weight', 'encoder.layer.23.attention.self.value.weight', 'encoder.layer.12.output.dense.weight', 'encoder.layer.10.attention.output.LayerNorm.weight', 'encoder.layer.6.attention.self.key.weight', 'encoder.layer.11.attention.self.query.weight', 'encoder.layer.5.attention.self.value.bias', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.18.attention.output.LayerNorm.weight', 'encoder.layer.5.attention.self.query.weight', 'encoder.layer.21.attention.self.value.bias', 'encoder.layer.17.intermediate.dense.weight', 'encoder.layer.15.attention.output.dense.bias', 'encoder.layer.19.attention.self.value.bias', 'encoder.layer.16.attention.self.value.bias', 'encoder.layer.4.attention.output.dense.bias', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.16.output.LayerNorm.bias', 'encoder.layer.2.attention.self.query.bias', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.16.attention.output.LayerNorm.bias', 'encoder.layer.3.attention.output.dense.weight', 'encoder.layer.18.attention.output.LayerNorm.bias', 'pooler.dense.weight', 'encoder.layer.18.output.LayerNorm.bias', 'encoder.layer.10.output.dense.weight', 'encoder.layer.13.attention.self.key.weight', 'encoder.layer.18.attention.self.query.weight', 'encoder.layer.1.attention.self.key.weight', 'encoder.layer.17.output.LayerNorm.bias', 'embeddings.token_type_embeddings.weight', 'encoder.layer.14.output.dense.weight', 'encoder.layer.23.intermediate.dense.weight', 'encoder.layer.1.output.dense.weight', 'encoder.layer.17.intermediate.dense.bias', 'encoder.layer.14.attention.self.key.weight', 'encoder.layer.22.output.dense.weight', 'encoder.layer.1.attention.self.key.bias', 'encoder.layer.16.attention.self.key.bias', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.12.attention.output.dense.weight', 'encoder.layer.8.output.dense.bias', 'encoder.layer.20.attention.self.key.bias', 'encoder.layer.19.attention.self.key.bias', 'encoder.layer.6.attention.self.query.weight', 'encoder.layer.10.output.dense.bias', 'encoder.layer.12.output.LayerNorm.bias', 'encoder.layer.5.attention.self.key.weight', 'encoder.layer.2.attention.output.dense.bias', 'encoder.layer.6.output.dense.bias', 'encoder.layer.18.intermediate.dense.weight', 'encoder.layer.14.attention.self.value.weight', 'encoder.layer.6.attention.output.dense.weight', 'encoder.layer.2.attention.self.key.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Overwriting existing adapter 'ep'.
Overwriting existing adapter 'tp'.
Overwriting existing adapter 'es'.
Overwriting existing adapter 'ts'.
Overwriting existing adapter fusion module 'ep,tp,es,ts'
05/09/2022 08:58:36 - INFO - __main__ -   lang2id = None
05/09/2022 08:58:43 - INFO - __main__ -   Training/evaluation parameters Namespace(adam_epsilon=1e-08, cache_dir='', config_name='', data_dir=None, device=device(type='cuda'), do_eval=True, do_lower_case=False, do_train=False, doc_stride=128, eval_all_checkpoints=False, eval_lang='es', evaluate_during_training=False, fp16=False, fp16_opt_level='O1', gradient_accumulation_steps=1, learning_rate=5e-05, local_rank=-1, logging_steps=50, max_answer_length=30, max_grad_norm=1.0, max_query_length=64, max_seq_length=384, max_steps=-1, model_name='xlm-KG', model_name_or_path='/cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//squad/xlm-KG_LR3e-5_EPOCH2.0_maxlen384_batchsize4_gradacc4', model_type='xlm', modelkg_dir='/cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/adapter/xlmr_adapter', n_best_size=20, n_gpu=1, no_cuda=False, null_score_diff_threshold=0.0, num_train_epochs=3.0, output_dir='/cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//squad/xlm-KG_LR3e-5_EPOCH2.0_maxlen384_batchsize4_gradacc4/predictions/xquad/', overwrite_cache=False, overwrite_output_dir=False, per_gpu_eval_batch_size=8, per_gpu_train_batch_size=8, predict_file='/cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/download//xquad//xquad.es.json', save_steps=50, seed=42, server_ip='', server_port='', threads=1, tokenizer_name='', train_file=None, train_lang='en', verbose_logging=False, version_2_with_negative=False, warmup_steps=0, weight_decay=0.0)
05/09/2022 08:58:43 - INFO - __main__ -   Loading checkpoint /cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//squad/xlm-KG_LR3e-5_EPOCH2.0_maxlen384_batchsize4_gradacc4 for evaluation
05/09/2022 08:58:43 - INFO - __main__ -   Evaluate the following checkpoints: ['/cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//squad/xlm-KG_LR3e-5_EPOCH2.0_maxlen384_batchsize4_gradacc4']
Some weights of the model checkpoint at /cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//squad/xlm-KG_LR3e-5_EPOCH2.0_maxlen384_batchsize4_gradacc4 were not used when initializing XLMRobertaModel: ['base_model.encoder.layer.15.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.19.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.9.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.8.attention.output.dense.weight', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.6.attention.output.dense.weight', 'base_model.encoder.layer.8.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.16.attention.self.query.weight', 'base_model.encoder.layer.22.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.14.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.17.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.11.attention.output.dense.bias', 'base_model.encoder.layer.21.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.5.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.6.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.1.output.LayerNorm.bias', 'base_model.encoder.layer.14.attention.self.query.weight', 'base_model.encoder.layer.4.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.16.attention.output.dense.bias', 'base_model.encoder.layer.19.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.0.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.10.attention.output.dense.weight', 'base_model.encoder.layer.15.output.LayerNorm.bias', 'base_model.encoder.layer.2.attention.self.query.weight', 'base_model.encoder.layer.14.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.8.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.15.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.15.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.21.output.dense.bias', 'base_model.encoder.layer.2.intermediate.dense.bias', 'base_model.pooler.dense.weight', 'base_model.encoder.layer.11.attention.output.LayerNorm.bias', 'base_model.encoder.layer.11.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.20.attention.output.dense.weight', 'base_model.encoder.layer.18.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.7.attention.self.value.bias', 'base_model.encoder.layer.1.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.20.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.17.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.10.attention.output.dense.bias', 'base_model.encoder.layer.16.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.18.intermediate.dense.weight', 'base_model.encoder.layer.19.attention.output.dense.bias', 'base_model.encoder.layer.21.output.adapters.tp.adapter_down.0.weight', 'qa_outputs.bias', 'base_model.encoder.layer.16.attention.output.LayerNorm.bias', 'base_model.encoder.layer.18.attention.self.query.weight', 'base_model.embeddings.token_type_embeddings.weight', 'base_model.encoder.layer.0.attention.output.LayerNorm.bias', 'base_model.encoder.layer.5.attention.self.query.bias', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.21.output.LayerNorm.bias', 'base_model.encoder.layer.0.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.5.attention.self.value.weight', 'base_model.encoder.layer.23.output.LayerNorm.weight', 'base_model.encoder.layer.13.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.15.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.17.intermediate.dense.bias', 'base_model.encoder.layer.14.intermediate.dense.bias', 'base_model.encoder.layer.9.attention.self.key.bias', 'base_model.encoder.layer.17.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.10.attention.output.LayerNorm.weight', 'base_model.encoder.layer.22.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.22.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.1.attention.self.query.weight', 'base_model.encoder.layer.5.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.0.attention.self.key.bias', 'base_model.encoder.layer.15.attention.self.key.bias', 'base_model.encoder.layer.3.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.6.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.9.attention.output.dense.weight', 'base_model.encoder.layer.1.output.dense.weight', 'base_model.encoder.layer.1.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.5.attention.output.LayerNorm.weight', 'base_model.encoder.layer.13.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.16.output.dense.weight', 'base_model.encoder.layer.18.attention.output.dense.weight', 'base_model.encoder.layer.21.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.21.intermediate.dense.weight', 'base_model.encoder.layer.21.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.6.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.15.attention.output.LayerNorm.weight', 'base_model.encoder.layer.1.intermediate.dense.weight', 'base_model.encoder.layer.9.attention.self.query.bias', 'base_model.encoder.layer.19.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.8.attention.output.LayerNorm.weight', 'base_model.encoder.layer.2.intermediate.dense.weight', 'base_model.encoder.layer.10.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.17.attention.output.LayerNorm.weight', 'base_model.encoder.layer.21.attention.self.value.weight', 'base_model.encoder.layer.5.output.LayerNorm.bias', 'base_model.encoder.layer.22.intermediate.dense.weight', 'base_model.encoder.layer.19.attention.output.LayerNorm.bias', 'base_model.encoder.layer.3.attention.output.LayerNorm.bias', 'base_model.encoder.layer.6.attention.output.dense.bias', 'base_model.encoder.layer.5.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.7.output.dense.weight', 'base_model.encoder.layer.0.intermediate.dense.bias', 'base_model.encoder.layer.8.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.20.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.4.output.LayerNorm.weight', 'base_model.encoder.layer.0.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.12.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.21.attention.self.key.weight', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.0.attention.self.value.bias', 'base_model.encoder.layer.13.attention.self.value.weight', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.22.output.LayerNorm.weight', 'base_model.encoder.layer.9.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.19.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.12.attention.self.key.weight', 'base_model.encoder.layer.23.output.dense.bias', 'base_model.encoder.layer.18.output.dense.bias', 'base_model.encoder.layer.8.intermediate.dense.weight', 'base_model.encoder.layer.17.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.2.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.6.attention.self.value.bias', 'base_model.encoder.layer.7.output.LayerNorm.bias', 'base_model.encoder.layer.18.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.10.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.5.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.1.attention.self.value.bias', 'base_model.encoder.layer.19.attention.output.LayerNorm.weight', 'base_model.encoder.layer.7.attention.output.LayerNorm.weight', 'base_model.encoder.layer.14.intermediate.dense.weight', 'base_model.encoder.layer.8.attention.output.dense.bias', 'base_model.encoder.layer.5.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.19.attention.self.key.bias', 'base_model.encoder.layer.11.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.5.output.dense.bias', 'base_model.encoder.layer.0.output.LayerNorm.weight', 'base_model.encoder.layer.19.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.0.output.dense.bias', 'base_model.encoder.layer.14.attention.output.dense.weight', 'base_model.encoder.layer.20.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.8.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.10.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.7.output.LayerNorm.weight', 'base_model.encoder.layer.13.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.0.intermediate.dense.weight', 'base_model.encoder.layer.9.attention.output.LayerNorm.weight', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.16.attention.self.key.weight', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.20.attention.self.query.weight', 'base_model.encoder.layer.19.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.0.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.16.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.14.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.0.attention.self.query.weight', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.2.attention.self.key.bias', 'base_model.encoder.layer.15.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.12.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.10.intermediate.dense.bias', 'base_model.encoder.layer.20.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.1.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.2.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.9.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.13.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.18.attention.self.value.bias', 'base_model.encoder.layer.19.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.4.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.7.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.6.output.LayerNorm.weight', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.17.attention.self.value.weight', 'base_model.encoder.layer.17.output.LayerNorm.bias', 'base_model.encoder.layer.17.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.6.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.10.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.21.attention.self.key.bias', 'base_model.encoder.layer.19.intermediate.dense.bias', 'base_model.encoder.layer.8.attention.self.value.bias', 'base_model.encoder.layer.7.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.4.attention.output.dense.bias', 'base_model.encoder.layer.11.intermediate.dense.bias', 'base_model.encoder.layer.19.output.dense.bias', 'base_model.encoder.layer.1.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.4.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.0.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.6.output.LayerNorm.bias', 'base_model.encoder.layer.17.attention.output.LayerNorm.bias', 'base_model.pooler.dense.bias', 'base_model.encoder.layer.11.output.dense.weight', 'base_model.encoder.layer.9.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.15.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.19.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.9.intermediate.dense.bias', 'base_model.encoder.layer.8.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.6.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.19.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.7.attention.self.query.bias', 'base_model.encoder.layer.22.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.6.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.10.intermediate.dense.weight', 'base_model.encoder.layer.13.attention.output.dense.weight', 'base_model.encoder.layer.7.intermediate.dense.weight', 'base_model.encoder.layer.12.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.17.output.dense.bias', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.10.attention.self.query.bias', 'base_model.encoder.layer.14.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.0.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.8.intermediate.dense.bias', 'base_model.encoder.layer.12.attention.output.LayerNorm.bias', 'base_model.encoder.layer.4.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.6.attention.self.value.weight', 'base_model.encoder.layer.15.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.16.attention.self.value.bias', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.8.attention.self.key.weight', 'base_model.encoder.layer.7.attention.self.value.weight', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.21.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.18.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.16.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.11.intermediate.dense.weight', 'base_model.encoder.layer.15.attention.self.value.weight', 'base_model.encoder.layer.6.attention.output.LayerNorm.weight', 'base_model.encoder.layer.14.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.3.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.10.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.23.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.1.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.16.attention.output.LayerNorm.weight', 'base_model.encoder.layer.6.attention.self.key.weight', 'base_model.encoder.layer.9.output.dense.bias', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.13.attention.output.LayerNorm.bias', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.3.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.10.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.10.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.21.output.dense.weight', 'base_model.encoder.layer.16.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.9.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.2.attention.self.value.bias', 'base_model.encoder.layer.22.intermediate.dense.bias', 'base_model.encoder.layer.14.attention.self.key.weight', 'base_model.encoder.layer.14.attention.self.key.bias', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.3.attention.self.key.bias', 'base_model.encoder.layer.13.intermediate.dense.bias', 'base_model.encoder.layer.21.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.18.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.0.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.6.attention.self.key.bias', 'base_model.encoder.layer.22.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.13.attention.self.query.weight', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.8.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.7.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.2.attention.output.dense.bias', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.18.output.LayerNorm.weight', 'base_model.encoder.layer.2.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.12.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.6.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.3.attention.self.value.weight', 'base_model.encoder.layer.5.intermediate.dense.weight', 'base_model.encoder.layer.1.attention.output.LayerNorm.bias', 'base_model.encoder.layer.0.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.9.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.11.output.LayerNorm.bias', 'base_model.encoder.layer.18.attention.self.key.weight', 'base_model.encoder.layer.6.attention.self.query.weight', 'base_model.encoder.layer.18.attention.output.dense.bias', 'base_model.encoder.layer.8.output.dense.weight', 'base_model.encoder.layer.15.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.15.attention.output.LayerNorm.bias', 'base_model.encoder.layer.16.output.LayerNorm.weight', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.1.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.12.attention.self.key.bias', 'base_model.encoder.layer.13.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.3.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.10.output.LayerNorm.bias', 'base_model.encoder.layer.13.attention.self.value.bias', 'base_model.encoder.layer.14.output.dense.weight', 'base_model.encoder.layer.17.attention.self.query.bias', 'base_model.encoder.layer.19.attention.self.query.bias', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.23.intermediate.dense.bias', 'base_model.encoder.layer.22.attention.output.LayerNorm.bias', 'base_model.encoder.layer.11.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.20.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.23.attention.output.dense.weight', 'base_model.encoder.layer.5.output.dense.weight', 'base_model.encoder.layer.9.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.15.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.22.attention.output.LayerNorm.weight', 'base_model.encoder.layer.22.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.3.attention.output.LayerNorm.weight', 'base_model.encoder.layer.22.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.7.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.2.output.LayerNorm.weight', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.17.attention.self.key.bias', 'base_model.encoder.layer.4.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.3.intermediate.dense.weight', 'base_model.encoder.layer.13.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.18.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.10.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.6.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.11.attention.self.query.bias', 'base_model.encoder.layer.19.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.19.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.22.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.23.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.18.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.1.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.11.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.7.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.3.output.adapters.es.adapter_down.0.bias', 'base_model.embeddings.LayerNorm.bias', 'base_model.encoder.layer.11.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.23.attention.output.LayerNorm.bias', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.3.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.4.attention.self.key.bias', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.17.attention.self.query.weight', 'base_model.encoder.layer.7.intermediate.dense.bias', 'base_model.encoder.layer.5.attention.output.LayerNorm.bias', 'base_model.encoder.layer.9.attention.self.value.weight', 'base_model.encoder.layer.13.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.22.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.3.attention.output.dense.weight', 'base_model.encoder.layer.22.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.3.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.13.attention.output.LayerNorm.weight', 'base_model.encoder.layer.11.attention.self.key.weight', 'base_model.encoder.layer.3.output.LayerNorm.weight', 'base_model.encoder.layer.7.attention.output.dense.bias', 'base_model.encoder.layer.15.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.16.intermediate.dense.bias', 'base_model.encoder.layer.18.attention.self.key.bias', 'base_model.encoder.layer.20.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.15.output.dense.bias', 'base_model.encoder.layer.23.attention.self.value.weight', 'base_model.encoder.layer.9.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.14.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.10.attention.self.value.bias', 'base_model.encoder.layer.20.output.LayerNorm.bias', 'base_model.encoder.layer.0.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.18.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.20.attention.self.query.bias', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.12.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.20.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.0.attention.self.value.weight', 'base_model.encoder.layer.4.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.19.output.LayerNorm.weight', 'base_model.encoder.layer.14.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.7.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.12.attention.self.value.bias', 'base_model.encoder.layer.13.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.19.intermediate.dense.weight', 'base_model.embeddings.word_embeddings.weight', 'base_model.encoder.layer.6.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.1.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.22.attention.self.value.bias', 'base_model.encoder.layer.16.intermediate.dense.weight', 'base_model.encoder.layer.13.output.LayerNorm.bias', 'base_model.encoder.layer.20.output.dense.bias', 'base_model.encoder.layer.3.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.14.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.21.attention.output.LayerNorm.weight', 'base_model.encoder.layer.5.attention.output.dense.weight', 'base_model.encoder.layer.18.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.23.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.17.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.10.output.LayerNorm.weight', 'base_model.encoder.layer.13.output.dense.weight', 'base_model.encoder.layer.15.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.6.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.10.output.dense.weight', 'base_model.encoder.layer.0.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.22.output.dense.weight', 'base_model.encoder.layer.12.intermediate.dense.bias', 'base_model.encoder.layer.23.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.1.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.0.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.23.intermediate.dense.weight', 'base_model.embeddings.position_embeddings.weight', 'base_model.encoder.layer.21.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.22.attention.self.key.weight', 'base_model.encoder.layer.14.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.5.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.10.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.16.attention.self.query.bias', 'base_model.encoder.layer.8.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.1.output.LayerNorm.weight', 'base_model.encoder.layer.12.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.23.attention.self.key.bias', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.20.output.dense.weight', 'base_model.encoder.layer.18.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.17.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.4.attention.output.LayerNorm.bias', 'base_model.encoder.layer.11.output.LayerNorm.weight', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.19.attention.self.key.weight', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.21.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.21.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.3.attention.self.value.bias', 'base_model.encoder.layer.23.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.14.output.LayerNorm.weight', 'base_model.encoder.layer.22.output.LayerNorm.bias', 'base_model.encoder.layer.20.attention.self.value.bias', 'base_model.encoder.layer.4.attention.self.key.weight', 'base_model.encoder.layer.7.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.20.output.LayerNorm.weight', 'base_model.encoder.layer.14.attention.self.query.bias', 'base_model.encoder.layer.16.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.6.output.dense.weight', 'base_model.encoder.layer.15.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.0.attention.output.dense.weight', 'base_model.encoder.layer.19.output.LayerNorm.bias', 'base_model.encoder.layer.5.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.21.attention.self.value.bias', 'base_model.encoder.layer.10.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.20.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.1.attention.self.value.weight', 'base_model.encoder.layer.9.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.0.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.23.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.8.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.5.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.5.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.17.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.17.intermediate.dense.weight', 'base_model.encoder.layer.3.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.13.attention.self.key.bias', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.2.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.18.output.dense.weight', 'base_model.encoder.layer.19.attention.self.query.weight', 'base_model.encoder.layer.22.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.2.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.9.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.16.output.LayerNorm.bias', 'base_model.encoder.layer.12.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.13.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.7.attention.output.dense.weight', 'base_model.encoder.layer.11.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.14.output.adapters.tp.adapter_down.0.bias', 'qa_outputs.weight', 'base_model.encoder.layer.5.attention.self.query.weight', 'base_model.encoder.layer.5.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.10.attention.output.LayerNorm.bias', 'base_model.encoder.layer.6.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.7.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.20.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.19.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.23.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.11.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.12.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.7.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.12.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.9.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.9.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.2.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.12.attention.output.dense.weight', 'base_model.encoder.layer.2.attention.output.dense.weight', 'base_model.encoder.layer.14.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.16.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.22.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.13.attention.self.query.bias', 'base_model.encoder.layer.14.attention.output.LayerNorm.bias', 'base_model.encoder.layer.5.attention.output.dense.bias', 'base_model.encoder.layer.11.output.dense.bias', 'base_model.encoder.layer.16.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.9.output.dense.weight', 'base_model.encoder.layer.21.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.11.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.3.attention.self.query.bias', 'base_model.encoder.layer.5.intermediate.dense.bias', 'base_model.encoder.layer.8.output.LayerNorm.weight', 'base_model.encoder.layer.23.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.7.attention.self.query.weight', 'base_model.encoder.layer.1.intermediate.dense.bias', 'base_model.encoder.layer.12.output.LayerNorm.bias', 'base_model.encoder.layer.18.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.9.attention.output.dense.bias', 'base_model.encoder.layer.8.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.2.attention.self.key.weight', 'base_model.embeddings.LayerNorm.weight', 'base_model.encoder.layer.4.attention.output.LayerNorm.weight', 'base_model.encoder.layer.7.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.9.intermediate.dense.weight', 'base_model.encoder.layer.11.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.21.attention.output.LayerNorm.bias', 'base_model.encoder.layer.6.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.8.attention.self.query.weight', 'base_model.encoder.layer.12.attention.self.query.weight', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.7.attention.self.key.bias', 'base_model.encoder.layer.13.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.8.output.dense.bias', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.11.attention.output.LayerNorm.weight', 'base_model.encoder.layer.4.attention.self.value.bias', 'base_model.encoder.layer.4.intermediate.dense.weight', 'base_model.encoder.layer.12.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.12.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.4.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.13.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.21.attention.self.query.bias', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.20.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.16.output.dense.bias', 'base_model.encoder.layer.2.attention.output.LayerNorm.bias', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.23.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.0.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.8.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.5.attention.self.value.bias', 'base_model.encoder.layer.2.attention.output.LayerNorm.weight', 'base_model.encoder.layer.3.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.17.attention.output.dense.bias', 'base_model.encoder.layer.13.intermediate.dense.weight', 'base_model.encoder.layer.14.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.4.intermediate.dense.bias', 'base_model.encoder.layer.7.attention.self.key.weight', 'base_model.encoder.layer.17.attention.self.key.weight', 'base_model.encoder.layer.20.attention.output.LayerNorm.weight', 'base_model.embeddings.position_ids', 'base_model.encoder.layer.4.attention.self.value.weight', 'base_model.encoder.layer.11.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.15.attention.self.key.weight', 'base_model.encoder.layer.5.output.LayerNorm.weight', 'base_model.encoder.layer.1.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.15.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.20.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.5.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.13.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.14.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.15.attention.self.query.weight', 'base_model.encoder.layer.21.intermediate.dense.bias', 'base_model.encoder.layer.4.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.10.attention.self.key.bias', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.11.attention.self.key.bias', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.6.attention.output.LayerNorm.bias', 'base_model.encoder.layer.15.attention.output.dense.weight', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.1.attention.self.query.bias', 'base_model.encoder.layer.10.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.15.attention.self.query.bias', 'base_model.encoder.layer.13.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.12.attention.self.query.bias', 'base_model.encoder.layer.15.intermediate.dense.bias', 'base_model.encoder.layer.14.attention.self.value.bias', 'base_model.encoder.layer.11.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.3.attention.self.query.weight', 'base_model.encoder.layer.18.output.LayerNorm.bias', 'base_model.encoder.layer.20.attention.output.dense.bias', 'base_model.encoder.layer.18.attention.output.LayerNorm.bias', 'base_model.encoder.layer.12.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.23.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.8.attention.output.LayerNorm.bias', 'base_model.encoder.layer.2.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.13.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.22.output.dense.bias', 'base_model.encoder.layer.2.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.23.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.4.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.1.attention.output.LayerNorm.weight', 'base_model.encoder.layer.4.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.0.attention.output.dense.bias', 'base_model.encoder.layer.1.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.5.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.2.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.1.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.16.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.17.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.21.output.LayerNorm.weight', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.3.output.dense.weight', 'base_model.encoder.layer.16.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.4.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.9.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.2.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.23.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.10.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.21.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.6.attention.self.query.bias', 'base_model.encoder.layer.8.attention.self.key.bias', 'base_model.encoder.layer.11.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.9.output.LayerNorm.bias', 'base_model.encoder.layer.1.attention.output.dense.bias', 'base_model.encoder.layer.4.attention.self.query.weight', 'base_model.encoder.layer.5.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.19.attention.output.dense.weight', 'base_model.encoder.layer.8.output.LayerNorm.bias', 'base_model.encoder.layer.16.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.21.attention.self.query.weight', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.3.attention.self.key.weight', 'base_model.encoder.layer.6.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.10.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.17.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.19.attention.self.value.weight', 'base_model.encoder.layer.17.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.5.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.23.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.13.attention.self.key.weight', 'base_model.encoder.layer.23.attention.self.key.weight', 'base_model.encoder.layer.8.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.20.attention.self.key.bias', 'base_model.encoder.layer.3.output.LayerNorm.bias', 'base_model.encoder.layer.0.attention.self.query.bias', 'base_model.encoder.layer.0.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.11.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.2.output.LayerNorm.bias', 'base_model.encoder.layer.22.attention.self.query.weight', 'base_model.encoder.layer.2.output.dense.bias', 'base_model.encoder.layer.16.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.14.attention.self.value.weight', 'base_model.encoder.layer.5.attention.self.key.weight', 'base_model.encoder.layer.20.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.9.attention.output.LayerNorm.bias', 'base_model.encoder.layer.11.attention.self.value.bias', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.22.attention.self.key.bias', 'base_model.encoder.layer.10.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.6.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.18.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.9.attention.self.query.weight', 'base_model.encoder.layer.7.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.8.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.20.attention.output.LayerNorm.bias', 'base_model.encoder.layer.18.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.20.intermediate.dense.weight', 'base_model.encoder.layer.12.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.20.attention.self.value.weight', 'base_model.encoder.layer.2.attention.self.value.weight', 'base_model.encoder.layer.7.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.7.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.21.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.12.attention.output.LayerNorm.weight', 'base_model.encoder.layer.11.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.3.intermediate.dense.bias', 'base_model.encoder.layer.1.output.dense.bias', 'base_model.encoder.layer.2.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.11.attention.self.value.weight', 'base_model.encoder.layer.1.attention.self.key.bias', 'base_model.encoder.layer.6.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.23.attention.self.query.weight', 'base_model.encoder.layer.17.output.dense.weight', 'base_model.encoder.layer.13.output.dense.bias', 'base_model.encoder.layer.6.output.dense.bias', 'base_model.encoder.layer.17.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.15.output.dense.weight', 'base_model.encoder.layer.12.attention.self.value.weight', 'base_model.encoder.layer.9.output.LayerNorm.weight', 'base_model.encoder.layer.10.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.19.output.dense.weight', 'base_model.encoder.layer.22.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.23.attention.self.query.bias', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.9.attention.self.key.weight', 'base_model.encoder.layer.16.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.1.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.3.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.23.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.3.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.5.attention.self.key.bias', 'base_model.encoder.layer.11.attention.output.dense.weight', 'base_model.encoder.layer.0.attention.self.key.weight', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.13.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.20.intermediate.dense.bias', 'base_model.encoder.layer.3.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.16.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.18.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.22.attention.output.dense.weight', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.18.attention.self.query.bias', 'base_model.encoder.layer.0.attention.output.LayerNorm.weight', 'base_model.encoder.layer.23.attention.output.LayerNorm.weight', 'base_model.encoder.layer.14.output.LayerNorm.bias', 'base_model.encoder.layer.9.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.20.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.13.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.22.attention.self.query.bias', 'base_model.encoder.layer.15.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.4.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.7.output.dense.bias', 'base_model.encoder.layer.10.attention.self.query.weight', 'base_model.encoder.layer.10.output.dense.bias', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.19.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.20.attention.self.key.weight', 'base_model.encoder.layer.21.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.15.intermediate.dense.weight', 'base_model.encoder.layer.4.attention.output.dense.weight', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.4.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.16.attention.self.key.bias', 'base_model.encoder.layer.5.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.22.attention.self.value.weight', 'base_model.encoder.layer.13.attention.output.dense.bias', 'base_model.encoder.layer.8.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.10.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.1.attention.self.key.weight', 'base_model.encoder.layer.2.attention.self.query.bias', 'base_model.encoder.layer.3.attention.output.dense.bias', 'base_model.encoder.layer.11.attention.self.query.weight', 'base_model.encoder.layer.14.output.dense.bias', 'base_model.encoder.layer.14.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.1.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.12.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.2.output.dense.weight', 'base_model.encoder.layer.22.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.19.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.0.output.dense.weight', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.8.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.12.output.LayerNorm.weight', 'base_model.encoder.layer.0.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.7.attention.output.LayerNorm.bias', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.19.attention.self.value.bias', 'base_model.encoder.layer.6.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.14.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.12.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.14.attention.output.LayerNorm.weight', 'base_model.encoder.layer.18.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.23.output.dense.weight', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.0.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.2.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.9.attention.self.value.bias', 'base_model.encoder.layer.15.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.20.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.3.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.16.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.4.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.10.attention.self.value.weight', 'base_model.encoder.layer.15.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.16.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.20.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.18.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.9.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.16.attention.self.value.weight', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.8.attention.self.query.bias', 'base_model.encoder.layer.23.attention.output.dense.bias', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.1.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.3.output.dense.bias', 'base_model.encoder.layer.4.output.dense.weight', 'base_model.encoder.layer.2.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.15.attention.output.dense.bias', 'base_model.encoder.layer.12.attention.output.dense.bias', 'base_model.encoder.layer.8.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.18.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.4.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.7.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.15.attention.self.value.bias', 'base_model.encoder.layer.8.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.10.attention.self.key.weight', 'base_model.encoder.layer.17.attention.output.dense.weight', 'base_model.encoder.layer.22.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.1.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.3.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.17.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.23.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.17.output.LayerNorm.weight', 'base_model.encoder.layer.2.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.12.output.dense.bias', 'base_model.encoder.layer.15.output.LayerNorm.weight', 'base_model.encoder.layer.18.attention.self.value.weight', 'base_model.encoder.layer.17.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.21.attention.output.dense.weight', 'base_model.encoder.layer.16.attention.output.dense.weight', 'base_model.encoder.layer.4.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.4.output.LayerNorm.bias', 'base_model.encoder.layer.23.attention.self.value.bias', 'base_model.encoder.layer.23.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.9.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.17.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.11.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.12.intermediate.dense.weight', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.0.output.LayerNorm.bias', 'base_model.encoder.layer.6.intermediate.dense.bias', 'base_model.encoder.layer.7.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.13.output.LayerNorm.weight', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.14.attention.output.dense.bias', 'base_model.encoder.layer.17.attention.self.value.bias', 'base_model.encoder.layer.20.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.16.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.8.attention.self.value.weight', 'base_model.encoder.layer.18.attention.output.LayerNorm.weight', 'base_model.encoder.layer.1.attention.output.dense.weight', 'base_model.encoder.layer.2.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.22.attention.output.dense.bias', 'base_model.encoder.layer.2.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.14.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.21.attention.output.dense.bias', 'base_model.encoder.layer.19.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.17.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.22.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.18.intermediate.dense.bias', 'base_model.encoder.layer.5.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.4.attention.self.query.bias', 'base_model.encoder.layer.11.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.23.output.LayerNorm.bias', 'base_model.encoder.layer.7.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.4.output.dense.bias', 'base_model.encoder.layer.12.output.dense.weight', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.3.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.21.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.12.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.21.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.19.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.21.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.6.intermediate.dense.weight', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.query.weight']
- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of XLMRobertaModel were not initialized from the model checkpoint at /cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//squad/xlm-KG_LR3e-5_EPOCH2.0_maxlen384_batchsize4_gradacc4 and are newly initialized: ['encoder.layer.16.attention.self.key.weight', 'encoder.layer.15.attention.self.key.bias', 'encoder.layer.19.output.dense.weight', 'encoder.layer.14.attention.output.dense.weight', 'encoder.layer.17.attention.output.LayerNorm.weight', 'encoder.layer.3.attention.self.value.weight', 'embeddings.LayerNorm.weight', 'encoder.layer.12.attention.self.query.weight', 'encoder.layer.17.attention.output.dense.weight', 'encoder.layer.20.attention.output.LayerNorm.bias', 'pooler.dense.bias', 'encoder.layer.21.output.LayerNorm.bias', 'encoder.layer.21.attention.output.dense.bias', 'encoder.layer.12.attention.self.key.bias', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.22.attention.self.key.weight', 'encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.layer.20.attention.self.value.bias', 'embeddings.position_embeddings.weight', 'encoder.layer.7.attention.self.key.weight', 'encoder.layer.0.attention.self.key.bias', 'encoder.layer.19.attention.output.LayerNorm.weight', 'encoder.layer.7.intermediate.dense.bias', 'encoder.layer.9.attention.output.LayerNorm.weight', 'encoder.layer.3.attention.self.value.bias', 'encoder.layer.18.intermediate.dense.bias', 'encoder.layer.15.intermediate.dense.bias', 'encoder.layer.9.attention.self.value.bias', 'encoder.layer.20.attention.self.key.weight', 'encoder.layer.9.output.dense.weight', 'encoder.layer.6.output.LayerNorm.bias', 'encoder.layer.13.attention.output.LayerNorm.weight', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.5.attention.self.value.weight', 'encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.layer.13.output.dense.bias', 'encoder.layer.22.output.LayerNorm.bias', 'encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.layer.6.attention.self.value.bias', 'encoder.layer.22.attention.self.key.bias', 'encoder.layer.7.attention.output.dense.bias', 'encoder.layer.19.attention.output.dense.weight', 'encoder.layer.19.output.LayerNorm.bias', 'encoder.layer.10.output.LayerNorm.bias', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.14.attention.self.query.weight', 'encoder.layer.1.output.dense.bias', 'encoder.layer.21.attention.self.key.weight', 'encoder.layer.21.attention.output.dense.weight', 'encoder.layer.8.attention.self.key.bias', 'embeddings.LayerNorm.bias', 'encoder.layer.21.attention.self.key.bias', 'encoder.layer.16.output.LayerNorm.weight', 'encoder.layer.3.attention.self.key.weight', 'encoder.layer.8.attention.self.query.bias', 'encoder.layer.18.attention.self.value.bias', 'encoder.layer.19.intermediate.dense.weight', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.0.attention.output.LayerNorm.weight', 'encoder.layer.1.attention.output.LayerNorm.weight', 'encoder.layer.22.output.LayerNorm.weight', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.4.attention.self.query.weight', 'encoder.layer.16.attention.self.query.weight', 'encoder.layer.8.attention.self.query.weight', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.17.attention.self.query.bias', 'encoder.layer.23.attention.output.LayerNorm.weight', 'encoder.layer.2.output.dense.weight', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.9.attention.self.query.weight', 'encoder.layer.0.attention.self.query.bias', 'encoder.layer.4.output.dense.weight', 'encoder.layer.3.attention.self.query.bias', 'encoder.layer.15.attention.self.value.weight', 'encoder.layer.11.output.dense.bias', 'encoder.layer.0.attention.self.query.weight', 'encoder.layer.11.attention.self.value.weight', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.14.attention.self.query.bias', 'encoder.layer.3.attention.output.dense.bias', 'encoder.layer.3.attention.self.query.weight', 'encoder.layer.10.attention.self.value.bias', 'encoder.layer.4.attention.output.dense.weight', 'encoder.layer.16.output.dense.bias', 'encoder.layer.7.attention.output.dense.weight', 'encoder.layer.1.attention.self.value.bias', 'encoder.layer.5.output.dense.bias', 'encoder.layer.17.output.dense.weight', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.2.output.dense.bias', 'encoder.layer.7.output.LayerNorm.bias', 'encoder.layer.13.output.LayerNorm.weight', 'encoder.layer.8.attention.output.LayerNorm.bias', 'encoder.layer.23.attention.output.LayerNorm.bias', 'encoder.layer.14.output.dense.bias', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.13.output.dense.weight', 'encoder.layer.4.attention.self.key.bias', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.6.attention.output.LayerNorm.weight', 'encoder.layer.5.attention.self.key.bias', 'encoder.layer.8.output.dense.weight', 'encoder.layer.16.attention.self.value.weight', 'encoder.layer.12.attention.self.key.weight', 'encoder.layer.23.attention.output.dense.bias', 'encoder.layer.23.output.dense.bias', 'encoder.layer.7.attention.self.key.bias', 'encoder.layer.18.attention.self.query.bias', 'encoder.layer.4.attention.output.LayerNorm.bias', 'encoder.layer.14.intermediate.dense.weight', 'encoder.layer.19.attention.self.query.bias', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.10.attention.self.key.weight', 'encoder.layer.19.attention.output.dense.bias', 'encoder.layer.16.attention.self.query.bias', 'encoder.layer.7.output.LayerNorm.weight', 'encoder.layer.6.attention.self.query.bias', 'encoder.layer.11.attention.self.key.weight', 'encoder.layer.17.attention.self.key.bias', 'encoder.layer.13.attention.output.LayerNorm.bias', 'encoder.layer.2.attention.output.dense.weight', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.2.attention.output.LayerNorm.weight', 'encoder.layer.9.output.LayerNorm.bias', 'encoder.layer.14.attention.self.key.bias', 'encoder.layer.15.attention.output.dense.weight', 'encoder.layer.10.intermediate.dense.weight', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.20.attention.output.dense.weight', 'encoder.layer.19.attention.output.LayerNorm.bias', 'encoder.layer.9.output.dense.bias', 'encoder.layer.18.attention.self.key.weight', 'encoder.layer.15.output.LayerNorm.weight', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.13.intermediate.dense.weight', 'encoder.layer.7.attention.self.query.bias', 'encoder.layer.14.intermediate.dense.bias', 'encoder.layer.23.output.LayerNorm.bias', 'encoder.layer.19.attention.self.value.weight', 'encoder.layer.2.attention.self.key.bias', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.22.attention.self.value.weight', 'encoder.layer.12.intermediate.dense.weight', 'encoder.layer.10.attention.self.key.bias', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.18.attention.output.dense.bias', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.7.attention.self.query.weight', 'encoder.layer.2.attention.self.value.bias', 'encoder.layer.21.output.dense.bias', 'encoder.layer.20.attention.self.value.weight', 'encoder.layer.5.attention.output.dense.bias', 'encoder.layer.5.output.LayerNorm.bias', 'encoder.layer.0.output.dense.bias', 'encoder.layer.4.attention.self.query.bias', 'encoder.layer.23.intermediate.dense.bias', 'encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.layer.15.attention.self.query.bias', 'encoder.layer.0.output.dense.weight', 'encoder.layer.0.attention.output.dense.bias', 'encoder.layer.12.attention.output.dense.bias', 'encoder.layer.20.output.LayerNorm.bias', 'encoder.layer.15.output.LayerNorm.bias', 'embeddings.word_embeddings.weight', 'encoder.layer.8.attention.self.key.weight', 'encoder.layer.14.attention.output.dense.bias', 'encoder.layer.22.attention.self.value.bias', 'encoder.layer.5.attention.self.query.bias', 'encoder.layer.14.output.LayerNorm.weight', 'encoder.layer.8.output.LayerNorm.weight', 'encoder.layer.17.output.LayerNorm.weight', 'encoder.layer.3.attention.self.key.bias', 'encoder.layer.15.output.dense.weight', 'encoder.layer.13.attention.self.value.weight', 'encoder.layer.7.attention.self.value.weight', 'encoder.layer.4.attention.self.value.bias', 'encoder.layer.15.attention.output.LayerNorm.bias', 'encoder.layer.9.attention.output.dense.bias', 'encoder.layer.6.output.dense.weight', 'encoder.layer.11.output.LayerNorm.weight', 'encoder.layer.2.attention.self.value.weight', 'encoder.layer.13.attention.output.dense.weight', 'encoder.layer.6.attention.output.LayerNorm.bias', 'encoder.layer.5.output.dense.weight', 'encoder.layer.1.attention.output.dense.weight', 'encoder.layer.3.output.dense.weight', 'encoder.layer.0.attention.output.dense.weight', 'encoder.layer.12.attention.output.LayerNorm.bias', 'encoder.layer.9.attention.self.value.weight', 'encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.layer.13.output.LayerNorm.bias', 'encoder.layer.17.attention.output.LayerNorm.bias', 'encoder.layer.15.attention.self.value.bias', 'encoder.layer.20.output.dense.bias', 'encoder.layer.18.output.dense.bias', 'encoder.layer.7.output.dense.bias', 'encoder.layer.15.attention.self.key.weight', 'encoder.layer.13.attention.output.dense.bias', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.11.output.dense.weight', 'encoder.layer.13.attention.self.key.bias', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.5.attention.output.dense.weight', 'encoder.layer.14.output.LayerNorm.bias', 'encoder.layer.23.output.dense.weight', 'encoder.layer.19.attention.self.query.weight', 'encoder.layer.7.output.dense.weight', 'encoder.layer.13.attention.self.value.bias', 'encoder.layer.10.attention.output.dense.bias', 'encoder.layer.21.output.LayerNorm.weight', 'encoder.layer.15.output.dense.bias', 'encoder.layer.4.attention.self.value.weight', 'encoder.layer.22.intermediate.dense.bias', 'encoder.layer.8.attention.output.LayerNorm.weight', 'encoder.layer.7.attention.output.LayerNorm.weight', 'encoder.layer.17.attention.self.value.bias', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.18.attention.self.value.weight', 'encoder.layer.22.attention.output.dense.weight', 'encoder.layer.12.output.LayerNorm.weight', 'encoder.layer.8.attention.output.dense.weight', 'encoder.layer.8.attention.self.value.weight', 'encoder.layer.9.attention.self.key.weight', 'encoder.layer.19.output.dense.bias', 'encoder.layer.21.attention.self.query.weight', 'encoder.layer.23.attention.output.dense.weight', 'encoder.layer.20.intermediate.dense.weight', 'encoder.layer.23.attention.self.key.bias', 'encoder.layer.12.output.dense.bias', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.14.attention.output.LayerNorm.bias', 'encoder.layer.5.attention.output.LayerNorm.weight', 'encoder.layer.16.intermediate.dense.weight', 'encoder.layer.1.attention.self.value.weight', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.13.attention.self.query.bias', 'encoder.layer.9.output.LayerNorm.weight', 'encoder.layer.15.attention.self.query.weight', 'encoder.layer.16.intermediate.dense.bias', 'encoder.layer.11.output.LayerNorm.bias', 'encoder.layer.1.attention.self.query.bias', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.17.attention.self.value.weight', 'encoder.layer.23.output.LayerNorm.weight', 'encoder.layer.4.output.dense.bias', 'encoder.layer.8.output.LayerNorm.bias', 'encoder.layer.21.attention.self.query.bias', 'encoder.layer.10.attention.output.dense.weight', 'encoder.layer.14.attention.output.LayerNorm.weight', 'encoder.layer.6.attention.self.key.bias', 'encoder.layer.23.attention.self.query.bias', 'encoder.layer.20.attention.output.LayerNorm.weight', 'encoder.layer.14.attention.self.value.bias', 'encoder.layer.10.attention.self.query.weight', 'encoder.layer.12.attention.self.value.weight', 'encoder.layer.13.attention.self.query.weight', 'encoder.layer.9.attention.self.key.bias', 'encoder.layer.23.attention.self.key.weight', 'encoder.layer.9.attention.output.LayerNorm.bias', 'encoder.layer.11.attention.output.LayerNorm.weight', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.4.attention.self.key.weight', 'encoder.layer.1.attention.self.query.weight', 'encoder.layer.22.attention.output.LayerNorm.weight', 'encoder.layer.22.attention.output.dense.bias', 'encoder.layer.12.intermediate.dense.bias', 'encoder.layer.12.attention.self.value.bias', 'encoder.layer.18.output.LayerNorm.weight', 'encoder.layer.19.attention.self.key.weight', 'encoder.layer.16.attention.output.dense.bias', 'encoder.layer.23.attention.self.query.weight', 'encoder.layer.6.attention.self.value.weight', 'encoder.layer.0.attention.self.value.bias', 'encoder.layer.21.output.dense.weight', 'encoder.layer.23.attention.self.value.bias', 'encoder.layer.12.attention.output.LayerNorm.weight', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.17.attention.self.key.weight', 'encoder.layer.2.attention.output.LayerNorm.bias', 'encoder.layer.15.intermediate.dense.weight', 'encoder.layer.17.attention.output.dense.bias', 'encoder.layer.20.output.dense.weight', 'encoder.layer.17.attention.self.query.weight', 'encoder.layer.21.attention.output.LayerNorm.weight', 'encoder.layer.21.attention.self.value.weight', 'encoder.layer.21.intermediate.dense.bias', 'encoder.layer.18.output.dense.weight', 'encoder.layer.19.intermediate.dense.bias', 'encoder.layer.10.attention.output.LayerNorm.bias', 'encoder.layer.8.attention.self.value.bias', 'encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.layer.13.intermediate.dense.bias', 'encoder.layer.22.attention.self.query.bias', 'encoder.layer.11.attention.self.query.bias', 'encoder.layer.21.attention.output.LayerNorm.bias', 'encoder.layer.7.attention.output.LayerNorm.bias', 'encoder.layer.22.attention.self.query.weight', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.16.attention.output.LayerNorm.weight', 'encoder.layer.10.attention.self.value.weight', 'encoder.layer.7.attention.self.value.bias', 'encoder.layer.0.attention.self.value.weight', 'encoder.layer.16.output.dense.weight', 'encoder.layer.16.attention.output.dense.weight', 'encoder.layer.20.attention.self.query.weight', 'encoder.layer.1.attention.output.dense.bias', 'encoder.layer.11.attention.self.value.bias', 'encoder.layer.21.intermediate.dense.weight', 'encoder.layer.11.attention.output.dense.bias', 'encoder.layer.22.attention.output.LayerNorm.bias', 'encoder.layer.2.attention.self.query.weight', 'encoder.layer.10.attention.self.query.bias', 'encoder.layer.22.intermediate.dense.weight', 'encoder.layer.18.attention.self.key.bias', 'encoder.layer.9.attention.output.dense.weight', 'encoder.layer.12.attention.self.query.bias', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.19.output.LayerNorm.weight', 'encoder.layer.20.attention.output.dense.bias', 'encoder.layer.0.attention.self.key.weight', 'encoder.layer.3.output.dense.bias', 'encoder.layer.17.output.dense.bias', 'encoder.layer.8.attention.output.dense.bias', 'encoder.layer.4.attention.output.LayerNorm.weight', 'encoder.layer.18.attention.output.dense.weight', 'encoder.layer.20.intermediate.dense.bias', 'encoder.layer.20.attention.self.query.bias', 'encoder.layer.10.output.LayerNorm.weight', 'encoder.layer.22.output.dense.bias', 'encoder.layer.15.attention.output.LayerNorm.weight', 'encoder.layer.9.attention.self.query.bias', 'encoder.layer.11.attention.self.key.bias', 'encoder.layer.6.attention.output.dense.bias', 'encoder.layer.11.attention.output.dense.weight', 'encoder.layer.20.output.LayerNorm.weight', 'encoder.layer.23.attention.self.value.weight', 'encoder.layer.12.output.dense.weight', 'encoder.layer.10.attention.output.LayerNorm.weight', 'encoder.layer.6.attention.self.key.weight', 'encoder.layer.11.attention.self.query.weight', 'encoder.layer.5.attention.self.value.bias', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.18.attention.output.LayerNorm.weight', 'encoder.layer.5.attention.self.query.weight', 'encoder.layer.21.attention.self.value.bias', 'encoder.layer.17.intermediate.dense.weight', 'encoder.layer.15.attention.output.dense.bias', 'encoder.layer.19.attention.self.value.bias', 'encoder.layer.16.attention.self.value.bias', 'encoder.layer.4.attention.output.dense.bias', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.16.output.LayerNorm.bias', 'encoder.layer.2.attention.self.query.bias', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.16.attention.output.LayerNorm.bias', 'encoder.layer.3.attention.output.dense.weight', 'encoder.layer.18.attention.output.LayerNorm.bias', 'pooler.dense.weight', 'encoder.layer.18.output.LayerNorm.bias', 'encoder.layer.10.output.dense.weight', 'encoder.layer.13.attention.self.key.weight', 'encoder.layer.18.attention.self.query.weight', 'encoder.layer.1.attention.self.key.weight', 'encoder.layer.17.output.LayerNorm.bias', 'embeddings.token_type_embeddings.weight', 'encoder.layer.14.output.dense.weight', 'encoder.layer.23.intermediate.dense.weight', 'encoder.layer.1.output.dense.weight', 'encoder.layer.17.intermediate.dense.bias', 'encoder.layer.14.attention.self.key.weight', 'encoder.layer.22.output.dense.weight', 'encoder.layer.1.attention.self.key.bias', 'encoder.layer.16.attention.self.key.bias', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.12.attention.output.dense.weight', 'encoder.layer.8.output.dense.bias', 'encoder.layer.20.attention.self.key.bias', 'encoder.layer.19.attention.self.key.bias', 'encoder.layer.6.attention.self.query.weight', 'encoder.layer.10.output.dense.bias', 'encoder.layer.12.output.LayerNorm.bias', 'encoder.layer.5.attention.self.key.weight', 'encoder.layer.2.attention.output.dense.bias', 'encoder.layer.6.output.dense.bias', 'encoder.layer.18.intermediate.dense.weight', 'encoder.layer.14.attention.self.value.weight', 'encoder.layer.6.attention.output.dense.weight', 'encoder.layer.2.attention.self.key.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Overwriting existing adapter 'ep'.
Overwriting existing adapter 'tp'.
Overwriting existing adapter 'es'.
Overwriting existing adapter 'ts'.
Overwriting existing adapter fusion module 'ep,tp,es,ts'
05/09/2022 08:59:14 - INFO - __main__ -   Creating features from dataset file at .
/cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//squad/xlm-KG_LR3e-5_EPOCH2.0_maxlen384_batchsize4_gradacc4
XLMConfig {
  "architectures": [
    "XLMRobertaForMaskedLM"
  ],
  "asm": false,
  "attention_dropout": 0.1,
  "attention_probs_dropout_prob": 0.1,
  "bos_index": 0,
  "bos_token_id": 0,
  "causal": false,
  "dropout": 0.1,
  "emb_dim": 1024,
  "embed_init_std": 0.02209708691207961,
  "end_n_top": 5,
  "eos_index": 1,
  "eos_token_id": 2,
  "gelu_activation": true,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "init_std": 0.02,
  "initializer_range": 0.02,
  "intermediate_size": 4096,
  "is_encoder": true,
  "lang_id": 0,
  "layer_norm_eps": 1e-05,
  "mask_index": 5,
  "mask_token_id": 0,
  "max_position_embeddings": 514,
  "model_type": "xlm",
  "n_heads": 16,
  "n_langs": 1,
  "n_layers": 24,
  "output_past": true,
  "pad_index": 2,
  "pad_token_id": 1,
  "sinusoidal_embeddings": false,
  "start_n_top": 5,
  "summary_activation": null,
  "summary_first_dropout": 0.1,
  "summary_proj_to_labels": true,
  "summary_type": "first",
  "summary_use_proj": true,
  "transformers_version": "4.17.0",
  "type_vocab_size": 1,
  "unk_index": 3,
  "use_lang_emb": false,
  "vocab_size": 250002
}

  0%|          | 0/48 [00:00<?, ?it/s] 17%|█▋        | 8/48 [00:00<00:00, 79.37it/s] 33%|███▎      | 16/48 [00:00<00:00, 69.46it/s] 50%|█████     | 24/48 [00:00<00:00, 63.75it/s] 65%|██████▍   | 31/48 [00:00<00:00, 60.83it/s] 79%|███████▉  | 38/48 [00:00<00:00, 61.23it/s]100%|██████████| 48/48 [00:00<00:00, 72.52it/s]100%|██████████| 48/48 [00:00<00:00, 68.31it/s]
convert squad examples to features:   0%|          | 0/1190 [00:00<?, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.
convert squad examples to features:   0%|          | 1/1190 [00:00<06:01,  3.29it/s]convert squad examples to features:   3%|▎         | 33/1190 [00:00<00:12, 93.05it/s]convert squad examples to features:   5%|▌         | 65/1190 [00:00<00:09, 120.18it/s]convert squad examples to features:   8%|▊         | 97/1190 [00:00<00:07, 142.18it/s]convert squad examples to features:  11%|█         | 129/1190 [00:00<00:06, 168.75it/s]convert squad examples to features:  14%|█▎        | 161/1190 [00:01<00:05, 182.08it/s]convert squad examples to features:  16%|█▌        | 193/1190 [00:01<00:05, 183.51it/s]convert squad examples to features:  19%|█▉        | 225/1190 [00:01<00:05, 182.02it/s]convert squad examples to features:  22%|██▏       | 257/1190 [00:01<00:05, 156.12it/s]convert squad examples to features:  24%|██▍       | 289/1190 [00:01<00:05, 158.20it/s]convert squad examples to features:  27%|██▋       | 321/1190 [00:02<00:06, 140.91it/s]convert squad examples to features:  30%|██▉       | 353/1190 [00:02<00:05, 150.11it/s]convert squad examples to features:  32%|███▏      | 385/1190 [00:03<00:10, 78.54it/s] convert squad examples to features:  35%|███▌      | 417/1190 [00:03<00:08, 88.63it/s]convert squad examples to features:  38%|███▊      | 449/1190 [00:03<00:07, 95.71it/s]convert squad examples to features:  40%|████      | 481/1190 [00:04<00:07, 98.56it/s]convert squad examples to features:  43%|████▎     | 513/1190 [00:04<00:06, 106.98it/s]convert squad examples to features:  46%|████▌     | 545/1190 [00:04<00:05, 108.15it/s]convert squad examples to features:  48%|████▊     | 577/1190 [00:04<00:05, 112.58it/s]convert squad examples to features:  51%|█████     | 609/1190 [00:05<00:05, 115.04it/s]convert squad examples to features:  54%|█████▍    | 641/1190 [00:05<00:04, 113.59it/s]convert squad examples to features:  57%|█████▋    | 673/1190 [00:05<00:04, 106.59it/s]convert squad examples to features:  59%|█████▉    | 705/1190 [00:05<00:04, 116.65it/s]convert squad examples to features:  62%|██████▏   | 737/1190 [00:06<00:03, 124.05it/s]convert squad examples to features:  65%|██████▍   | 769/1190 [00:06<00:03, 132.28it/s]convert squad examples to features:  67%|██████▋   | 801/1190 [00:06<00:02, 144.28it/s]convert squad examples to features:  70%|███████   | 833/1190 [00:06<00:02, 131.12it/s]convert squad examples to features:  73%|███████▎  | 865/1190 [00:07<00:02, 136.45it/s]convert squad examples to features:  75%|███████▌  | 897/1190 [00:07<00:02, 130.12it/s]convert squad examples to features:  78%|███████▊  | 929/1190 [00:07<00:02, 126.15it/s]convert squad examples to features:  81%|████████  | 961/1190 [00:07<00:01, 129.08it/s]convert squad examples to features:  83%|████████▎ | 993/1190 [00:08<00:01, 141.81it/s]convert squad examples to features:  86%|████████▌ | 1025/1190 [00:08<00:01, 148.40it/s]convert squad examples to features:  89%|████████▉ | 1057/1190 [00:08<00:00, 159.86it/s]convert squad examples to features:  92%|█████████▏| 1089/1190 [00:08<00:00, 162.57it/s]convert squad examples to features:  94%|█████████▍| 1121/1190 [00:08<00:00, 151.99it/s]convert squad examples to features:  97%|█████████▋| 1153/1190 [00:09<00:00, 140.66it/s]convert squad examples to features: 100%|██████████| 1190/1190 [00:09<00:00, 130.63it/s]/cluster/project/sachan/yifan/softwares/anaconda/anaconda3/envs/xfactr/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2272: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

add example index and unique id:   0%|          | 0/1190 [00:00<?, ?it/s]add example index and unique id: 100%|██████████| 1190/1190 [00:00<00:00, 428026.91it/s]
05/09/2022 08:59:24 - INFO - __main__ -   Saving features into cached file ./cached_xquad.es.json_xlm-KG_LR3e-5_EPOCH2.0_maxlen384_batchsize4_gradacc4_384_es
05/09/2022 08:59:26 - INFO - __main__ -   ***** Running evaluation  *****
05/09/2022 08:59:26 - INFO - __main__ -     Num examples = 1304
05/09/2022 08:59:26 - INFO - __main__ -     Batch size = 8
Evaluating:   0%|          | 0/163 [00:00<?, ?it/s]Evaluating:   1%|          | 1/163 [00:00<02:29,  1.08it/s]Evaluating:   1%|          | 2/163 [00:01<01:33,  1.72it/s]Evaluating:   2%|▏         | 3/163 [00:01<01:15,  2.11it/s]Evaluating:   2%|▏         | 4/163 [00:01<01:07,  2.36it/s]Evaluating:   3%|▎         | 5/163 [00:02<01:02,  2.54it/s]Evaluating:   4%|▎         | 6/163 [00:02<00:59,  2.66it/s]Evaluating:   4%|▍         | 7/163 [00:02<00:56,  2.74it/s]Evaluating:   5%|▍         | 8/163 [00:03<00:55,  2.79it/s]Evaluating:   6%|▌         | 9/163 [00:03<00:54,  2.83it/s]Evaluating:   6%|▌         | 10/163 [00:04<00:53,  2.85it/s]Evaluating:   7%|▋         | 11/163 [00:04<00:53,  2.87it/s]Evaluating:   7%|▋         | 12/163 [00:04<00:52,  2.87it/s]Evaluating:   8%|▊         | 13/163 [00:05<00:52,  2.88it/s]Evaluating:   9%|▊         | 14/163 [00:05<00:51,  2.89it/s]Evaluating:   9%|▉         | 15/163 [00:05<00:51,  2.90it/s]Evaluating:  10%|▉         | 16/163 [00:06<00:50,  2.90it/s]Evaluating:  10%|█         | 17/163 [00:06<00:50,  2.91it/s]Evaluating:  11%|█         | 18/163 [00:06<00:49,  2.91it/s]Evaluating:  12%|█▏        | 19/163 [00:07<00:49,  2.90it/s]Evaluating:  12%|█▏        | 20/163 [00:07<00:49,  2.91it/s]Evaluating:  13%|█▎        | 21/163 [00:07<00:48,  2.91it/s]Evaluating:  13%|█▎        | 22/163 [00:08<00:48,  2.90it/s]Evaluating:  14%|█▍        | 23/163 [00:08<00:48,  2.89it/s]Evaluating:  15%|█▍        | 24/163 [00:08<00:47,  2.90it/s]Evaluating:  15%|█▌        | 25/163 [00:09<00:47,  2.91it/s]Evaluating:  16%|█▌        | 26/163 [00:09<00:47,  2.91it/s]Evaluating:  17%|█▋        | 27/163 [00:09<00:46,  2.92it/s]Evaluating:  17%|█▋        | 28/163 [00:10<00:46,  2.90it/s]Evaluating:  18%|█▊        | 29/163 [00:10<00:46,  2.91it/s]Evaluating:  18%|█▊        | 30/163 [00:10<00:45,  2.91it/s]Evaluating:  19%|█▉        | 31/163 [00:11<00:45,  2.91it/s]Evaluating:  20%|█▉        | 32/163 [00:11<00:45,  2.91it/s]Evaluating:  20%|██        | 33/163 [00:11<00:44,  2.91it/s]Evaluating:  21%|██        | 34/163 [00:12<00:44,  2.91it/s]Evaluating:  21%|██▏       | 35/163 [00:12<00:44,  2.91it/s]Evaluating:  22%|██▏       | 36/163 [00:12<00:43,  2.91it/s]Evaluating:  23%|██▎       | 37/163 [00:13<00:43,  2.91it/s]Evaluating:  23%|██▎       | 38/163 [00:13<00:43,  2.90it/s]Evaluating:  24%|██▍       | 39/163 [00:13<00:42,  2.89it/s]Evaluating:  25%|██▍       | 40/163 [00:14<00:42,  2.89it/s]Evaluating:  25%|██▌       | 41/163 [00:14<00:42,  2.90it/s]Evaluating:  26%|██▌       | 42/163 [00:15<00:41,  2.91it/s]Evaluating:  26%|██▋       | 43/163 [00:15<00:41,  2.91it/s]Evaluating:  27%|██▋       | 44/163 [00:15<00:40,  2.91it/s]Evaluating:  28%|██▊       | 45/163 [00:16<00:40,  2.91it/s]Evaluating:  28%|██▊       | 46/163 [00:16<00:40,  2.91it/s]Evaluating:  29%|██▉       | 47/163 [00:16<00:39,  2.90it/s]Evaluating:  29%|██▉       | 48/163 [00:17<00:39,  2.91it/s]Evaluating:  30%|███       | 49/163 [00:17<00:39,  2.91it/s]Evaluating:  31%|███       | 50/163 [00:17<00:38,  2.91it/s]Evaluating:  31%|███▏      | 51/163 [00:18<00:38,  2.91it/s]Evaluating:  32%|███▏      | 52/163 [00:18<00:38,  2.91it/s]Evaluating:  33%|███▎      | 53/163 [00:18<00:37,  2.90it/s]Evaluating:  33%|███▎      | 54/163 [00:19<00:37,  2.90it/s]Evaluating:  34%|███▎      | 55/163 [00:19<00:37,  2.89it/s]Evaluating:  34%|███▍      | 56/163 [00:19<00:36,  2.89it/s]Evaluating:  35%|███▍      | 57/163 [00:20<00:36,  2.88it/s]Evaluating:  36%|███▌      | 58/163 [00:20<00:36,  2.88it/s]Evaluating:  36%|███▌      | 59/163 [00:20<00:36,  2.88it/s]Evaluating:  37%|███▋      | 60/163 [00:21<00:35,  2.88it/s]Evaluating:  37%|███▋      | 61/163 [00:21<00:35,  2.88it/s]Evaluating:  38%|███▊      | 62/163 [00:21<00:35,  2.88it/s]Evaluating:  39%|███▊      | 63/163 [00:22<00:34,  2.88it/s]Evaluating:  39%|███▉      | 64/163 [00:22<00:34,  2.90it/s]Evaluating:  40%|███▉      | 65/163 [00:22<00:33,  2.90it/s]Evaluating:  40%|████      | 66/163 [00:23<00:33,  2.91it/s]Evaluating:  41%|████      | 67/163 [00:23<00:33,  2.88it/s]Evaluating:  42%|████▏     | 68/163 [00:24<00:32,  2.88it/s]Evaluating:  42%|████▏     | 69/163 [00:24<00:32,  2.88it/s]Evaluating:  43%|████▎     | 70/163 [00:24<00:32,  2.88it/s]Evaluating:  44%|████▎     | 71/163 [00:25<00:31,  2.89it/s]Evaluating:  44%|████▍     | 72/163 [00:25<00:31,  2.88it/s]Evaluating:  45%|████▍     | 73/163 [00:25<00:31,  2.90it/s]Evaluating:  45%|████▌     | 74/163 [00:26<00:30,  2.89it/s]Evaluating:  46%|████▌     | 75/163 [00:26<00:30,  2.88it/s]Evaluating:  47%|████▋     | 76/163 [00:26<00:30,  2.89it/s]Evaluating:  47%|████▋     | 77/163 [00:27<00:29,  2.90it/s]Evaluating:  48%|████▊     | 78/163 [00:27<00:29,  2.90it/s]Evaluating:  48%|████▊     | 79/163 [00:27<00:29,  2.89it/s]Evaluating:  49%|████▉     | 80/163 [00:28<00:28,  2.88it/s]Evaluating:  50%|████▉     | 81/163 [00:28<00:28,  2.89it/s]Evaluating:  50%|█████     | 82/163 [00:28<00:27,  2.90it/s]Evaluating:  51%|█████     | 83/163 [00:29<00:27,  2.89it/s]Evaluating:  52%|█████▏    | 84/163 [00:29<00:27,  2.88it/s]Evaluating:  52%|█████▏    | 85/163 [00:29<00:27,  2.89it/s]Evaluating:  53%|█████▎    | 86/163 [00:30<00:26,  2.90it/s]Evaluating:  53%|█████▎    | 87/163 [00:30<00:26,  2.90it/s]Evaluating:  54%|█████▍    | 88/163 [00:30<00:25,  2.90it/s]Evaluating:  55%|█████▍    | 89/163 [00:31<00:25,  2.89it/s]Evaluating:  55%|█████▌    | 90/163 [00:31<00:25,  2.90it/s]Evaluating:  56%|█████▌    | 91/163 [00:31<00:24,  2.90it/s]Evaluating:  56%|█████▋    | 92/163 [00:32<00:24,  2.90it/s]Evaluating:  57%|█████▋    | 93/163 [00:32<00:24,  2.89it/s]Evaluating:  58%|█████▊    | 94/163 [00:33<00:23,  2.88it/s]Evaluating:  58%|█████▊    | 95/163 [00:33<00:23,  2.89it/s]Evaluating:  59%|█████▉    | 96/163 [00:33<00:23,  2.89it/s]Evaluating:  60%|█████▉    | 97/163 [00:34<00:22,  2.89it/s]Evaluating:  60%|██████    | 98/163 [00:34<00:22,  2.90it/s]Evaluating:  61%|██████    | 99/163 [00:34<00:22,  2.90it/s]Evaluating:  61%|██████▏   | 100/163 [00:35<00:21,  2.91it/s]Evaluating:  62%|██████▏   | 101/163 [00:35<00:21,  2.91it/s]Evaluating:  63%|██████▎   | 102/163 [00:35<00:20,  2.91it/s]Evaluating:  63%|██████▎   | 103/163 [00:36<00:20,  2.91it/s]Evaluating:  64%|██████▍   | 104/163 [00:36<00:20,  2.91it/s]Evaluating:  64%|██████▍   | 105/163 [00:36<00:19,  2.90it/s]Evaluating:  65%|██████▌   | 106/163 [00:37<00:19,  2.91it/s]Evaluating:  66%|██████▌   | 107/163 [00:37<00:19,  2.91it/s]Evaluating:  66%|██████▋   | 108/163 [00:37<00:18,  2.91it/s]Evaluating:  67%|██████▋   | 109/163 [00:38<00:18,  2.91it/s]Evaluating:  67%|██████▋   | 110/163 [00:38<00:18,  2.91it/s]Evaluating:  68%|██████▊   | 111/163 [00:38<00:17,  2.91it/s]Evaluating:  69%|██████▊   | 112/163 [00:39<00:17,  2.90it/s]Evaluating:  69%|██████▉   | 113/163 [00:39<00:17,  2.91it/s]Evaluating:  70%|██████▉   | 114/163 [00:39<00:16,  2.92it/s]Evaluating:  71%|███████   | 115/163 [00:40<00:16,  2.91it/s]Evaluating:  71%|███████   | 116/163 [00:40<00:16,  2.92it/s]Evaluating:  72%|███████▏  | 117/163 [00:40<00:15,  2.91it/s]Evaluating:  72%|███████▏  | 118/163 [00:41<00:15,  2.92it/s]Evaluating:  73%|███████▎  | 119/163 [00:41<00:15,  2.92it/s]Evaluating:  74%|███████▎  | 120/163 [00:41<00:14,  2.91it/s]Evaluating:  74%|███████▍  | 121/163 [00:42<00:14,  2.91it/s]Evaluating:  75%|███████▍  | 122/163 [00:42<00:14,  2.91it/s]Evaluating:  75%|███████▌  | 123/163 [00:42<00:13,  2.91it/s]Evaluating:  76%|███████▌  | 124/163 [00:43<00:13,  2.90it/s]Evaluating:  77%|███████▋  | 125/163 [00:43<00:13,  2.91it/s]Evaluating:  77%|███████▋  | 126/163 [00:44<00:12,  2.91it/s]Evaluating:  78%|███████▊  | 127/163 [00:44<00:12,  2.90it/s]Evaluating:  79%|███████▊  | 128/163 [00:44<00:12,  2.90it/s]Evaluating:  79%|███████▉  | 129/163 [00:45<00:11,  2.90it/s]Evaluating:  80%|███████▉  | 130/163 [00:45<00:11,  2.83it/s]Evaluating:  80%|████████  | 131/163 [00:45<00:11,  2.86it/s]Evaluating:  81%|████████  | 132/163 [00:46<00:10,  2.87it/s]Evaluating:  82%|████████▏ | 133/163 [00:46<00:10,  2.89it/s]Evaluating:  82%|████████▏ | 134/163 [00:46<00:09,  2.90it/s]Evaluating:  83%|████████▎ | 135/163 [00:47<00:09,  2.88it/s]Evaluating:  83%|████████▎ | 136/163 [00:47<00:09,  2.89it/s]Evaluating:  84%|████████▍ | 137/163 [00:47<00:08,  2.90it/s]Evaluating:  85%|████████▍ | 138/163 [00:48<00:08,  2.91it/s]Evaluating:  85%|████████▌ | 139/163 [00:48<00:08,  2.92it/s]Evaluating:  86%|████████▌ | 140/163 [00:48<00:07,  2.92it/s]Evaluating:  87%|████████▋ | 141/163 [00:49<00:07,  2.92it/s]Evaluating:  87%|████████▋ | 142/163 [00:49<00:07,  2.92it/s]Evaluating:  88%|████████▊ | 143/163 [00:49<00:06,  2.92it/s]Evaluating:  88%|████████▊ | 144/163 [00:50<00:06,  2.90it/s]Evaluating:  89%|████████▉ | 145/163 [00:50<00:06,  2.90it/s]Evaluating:  90%|████████▉ | 146/163 [00:50<00:05,  2.91it/s]Evaluating:  90%|█████████ | 147/163 [00:51<00:05,  2.91it/s]Evaluating:  91%|█████████ | 148/163 [00:51<00:05,  2.92it/s]Evaluating:  91%|█████████▏| 149/163 [00:51<00:04,  2.92it/s]Evaluating:  92%|█████████▏| 150/163 [00:52<00:04,  2.92it/s]Evaluating:  93%|█████████▎| 151/163 [00:52<00:04,  2.92it/s]Evaluating:  93%|█████████▎| 152/163 [00:52<00:03,  2.90it/s]Evaluating:  94%|█████████▍| 153/163 [00:53<00:03,  2.91it/s]Evaluating:  94%|█████████▍| 154/163 [00:53<00:03,  2.90it/s]Evaluating:  95%|█████████▌| 155/163 [00:54<00:02,  2.90it/s]Evaluating:  96%|█████████▌| 156/163 [00:54<00:02,  2.89it/s]Evaluating:  96%|█████████▋| 157/163 [00:54<00:02,  2.89it/s]Evaluating:  97%|█████████▋| 158/163 [00:55<00:01,  2.90it/s]Evaluating:  98%|█████████▊| 159/163 [00:55<00:01,  2.90it/s]Evaluating:  98%|█████████▊| 160/163 [00:55<00:01,  2.91it/s]Evaluating:  99%|█████████▉| 161/163 [00:56<00:00,  2.91it/s]Evaluating:  99%|█████████▉| 162/163 [00:56<00:00,  2.91it/s]Evaluating: 100%|██████████| 163/163 [00:56<00:00,  2.90it/s]Evaluating: 100%|██████████| 163/163 [00:56<00:00,  2.87it/s]
05/09/2022 09:00:23 - INFO - __main__ -     Evaluation done in total 56.760197 secs (0.043528 sec per example)
05/09/2022 09:00:29 - INFO - __main__ -   Results: {'exact': 62.6890756302521, 'f1': 81.1010957882802, 'total': 1190, 'HasAns_exact': 62.6890756302521, 'HasAns_f1': 81.1010957882802, 'HasAns_total': 1190, 'best_exact': 62.6890756302521, 'best_exact_thresh': 0.0, 'best_f1': 81.1010957882802, 'best_f1_thresh': 0.0}
  de 
2022-05-09 09:00:33.492394: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0
05/09/2022 09:00:37 - WARNING - __main__ -   Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, 16-bits training: False
You are using a model of type xlm-roberta to instantiate a model of type xlm. This is not supported for all configurations of models and can yield errors.
Some weights of the model checkpoint at /cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//squad/xlm-KG_LR3e-5_EPOCH2.0_maxlen384_batchsize4_gradacc4 were not used when initializing XLMRobertaModel: ['base_model.encoder.layer.0.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.19.attention.output.dense.bias', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.5.attention.self.key.weight', 'base_model.encoder.layer.15.attention.output.dense.weight', 'base_model.encoder.layer.18.intermediate.dense.weight', 'base_model.encoder.layer.15.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.21.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.12.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.10.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.9.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.7.attention.output.LayerNorm.weight', 'base_model.encoder.layer.13.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.19.attention.output.LayerNorm.weight', 'base_model.encoder.layer.3.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.9.attention.self.key.weight', 'base_model.encoder.layer.23.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.2.output.dense.bias', 'base_model.encoder.layer.21.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.13.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.3.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.7.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.3.attention.self.value.weight', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.7.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.21.attention.self.key.bias', 'base_model.encoder.layer.17.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.0.intermediate.dense.weight', 'qa_outputs.weight', 'base_model.encoder.layer.16.output.LayerNorm.weight', 'base_model.encoder.layer.4.attention.self.value.weight', 'base_model.encoder.layer.15.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.8.intermediate.dense.weight', 'base_model.encoder.layer.2.intermediate.dense.weight', 'base_model.encoder.layer.23.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.11.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.16.attention.output.LayerNorm.weight', 'base_model.encoder.layer.14.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.11.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.20.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.23.output.dense.bias', 'base_model.encoder.layer.12.attention.self.key.bias', 'base_model.encoder.layer.0.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.14.attention.self.key.bias', 'base_model.encoder.layer.14.attention.self.value.weight', 'base_model.encoder.layer.21.attention.self.query.bias', 'base_model.encoder.layer.11.attention.self.value.weight', 'base_model.encoder.layer.15.attention.self.key.bias', 'base_model.encoder.layer.4.attention.self.query.weight', 'base_model.encoder.layer.16.attention.self.query.bias', 'base_model.encoder.layer.20.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.11.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.3.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.8.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.3.output.LayerNorm.bias', 'base_model.encoder.layer.7.attention.self.value.weight', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.9.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.7.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.18.intermediate.dense.bias', 'base_model.encoder.layer.18.attention.output.dense.weight', 'base_model.encoder.layer.20.attention.self.key.bias', 'base_model.encoder.layer.13.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.16.output.dense.bias', 'base_model.encoder.layer.7.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.20.output.dense.weight', 'base_model.encoder.layer.2.attention.self.value.bias', 'base_model.encoder.layer.23.attention.self.key.weight', 'base_model.encoder.layer.17.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.11.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.12.attention.output.dense.bias', 'base_model.encoder.layer.10.attention.output.dense.bias', 'base_model.encoder.layer.0.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.1.attention.output.dense.bias', 'base_model.encoder.layer.19.attention.output.LayerNorm.bias', 'base_model.encoder.layer.23.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.21.attention.output.dense.bias', 'base_model.encoder.layer.3.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.21.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.0.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.23.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.9.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.6.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.8.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.1.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.16.output.LayerNorm.bias', 'base_model.encoder.layer.2.attention.self.value.weight', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.6.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.3.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.23.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.2.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.13.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.0.output.dense.weight', 'base_model.encoder.layer.22.attention.self.key.bias', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.8.output.LayerNorm.weight', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.1.attention.self.value.bias', 'base_model.encoder.layer.23.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.14.attention.self.value.bias', 'base_model.encoder.layer.16.attention.self.query.weight', 'base_model.encoder.layer.18.attention.self.query.weight', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.17.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.2.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.14.intermediate.dense.weight', 'base_model.encoder.layer.4.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.19.attention.self.key.weight', 'base_model.encoder.layer.5.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.9.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.3.attention.self.query.weight', 'base_model.encoder.layer.19.attention.self.value.weight', 'base_model.encoder.layer.21.attention.output.dense.weight', 'base_model.encoder.layer.23.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.17.attention.self.value.weight', 'base_model.encoder.layer.9.output.dense.bias', 'base_model.encoder.layer.19.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.16.attention.self.key.weight', 'base_model.encoder.layer.2.attention.output.dense.weight', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.17.output.LayerNorm.weight', 'base_model.encoder.layer.3.attention.output.LayerNorm.bias', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.21.intermediate.dense.weight', 'base_model.encoder.layer.10.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.11.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.11.attention.output.LayerNorm.bias', 'base_model.encoder.layer.19.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.18.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.22.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.3.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.21.output.LayerNorm.bias', 'base_model.encoder.layer.0.attention.output.dense.weight', 'base_model.encoder.layer.13.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.17.intermediate.dense.bias', 'base_model.encoder.layer.21.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.3.attention.output.dense.bias', 'base_model.encoder.layer.23.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.15.output.LayerNorm.bias', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.15.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.16.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.22.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.3.attention.self.key.bias', 'base_model.encoder.layer.14.attention.output.dense.weight', 'base_model.encoder.layer.18.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.19.attention.self.query.weight', 'base_model.encoder.layer.23.attention.self.query.bias', 'base_model.encoder.layer.3.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.6.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.14.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.19.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.6.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.7.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.14.output.LayerNorm.weight', 'base_model.encoder.layer.14.attention.self.query.weight', 'base_model.encoder.layer.11.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.16.attention.output.LayerNorm.bias', 'base_model.encoder.layer.10.intermediate.dense.bias', 'base_model.encoder.layer.16.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.19.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.4.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.5.output.LayerNorm.bias', 'base_model.encoder.layer.10.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.0.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.7.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.8.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.7.attention.output.dense.weight', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.13.intermediate.dense.weight', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.22.attention.output.dense.bias', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.12.attention.self.query.weight', 'base_model.encoder.layer.6.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.19.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.6.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.2.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.5.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.6.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.5.output.dense.bias', 'base_model.encoder.layer.16.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.20.attention.output.dense.bias', 'base_model.encoder.layer.15.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.9.attention.self.query.bias', 'base_model.embeddings.word_embeddings.weight', 'base_model.encoder.layer.2.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.6.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.13.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.14.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.17.attention.self.query.weight', 'base_model.encoder.layer.14.intermediate.dense.bias', 'base_model.encoder.layer.11.attention.output.LayerNorm.weight', 'base_model.encoder.layer.23.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.0.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.12.output.dense.weight', 'base_model.encoder.layer.15.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.18.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.15.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.5.output.LayerNorm.weight', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.22.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.12.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.13.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.20.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.8.attention.self.query.bias', 'base_model.encoder.layer.16.intermediate.dense.bias', 'base_model.encoder.layer.4.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.4.attention.output.LayerNorm.weight', 'base_model.encoder.layer.21.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.17.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.22.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.20.attention.self.value.weight', 'base_model.encoder.layer.8.attention.self.key.weight', 'base_model.encoder.layer.7.output.LayerNorm.bias', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.12.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.10.attention.output.LayerNorm.weight', 'base_model.encoder.layer.10.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.14.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.7.output.dense.bias', 'base_model.encoder.layer.16.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.2.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.17.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.20.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.10.output.dense.weight', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.16.intermediate.dense.weight', 'base_model.encoder.layer.17.attention.self.query.bias', 'base_model.encoder.layer.1.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.0.output.dense.bias', 'base_model.encoder.layer.12.attention.self.query.bias', 'base_model.encoder.layer.0.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.7.attention.self.key.weight', 'base_model.encoder.layer.2.attention.self.key.bias', 'base_model.encoder.layer.0.attention.output.dense.bias', 'base_model.encoder.layer.11.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.10.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.18.attention.output.LayerNorm.bias', 'base_model.encoder.layer.20.attention.output.LayerNorm.weight', 'base_model.encoder.layer.17.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.11.attention.output.dense.bias', 'base_model.encoder.layer.0.attention.self.key.weight', 'base_model.encoder.layer.10.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.18.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.14.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.3.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.5.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.5.attention.output.dense.weight', 'base_model.encoder.layer.6.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.16.attention.output.dense.weight', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.4.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.4.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.19.output.dense.weight', 'base_model.encoder.layer.21.attention.self.value.weight', 'base_model.encoder.layer.23.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.8.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.0.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.11.attention.self.query.bias', 'base_model.encoder.layer.19.intermediate.dense.weight', 'base_model.encoder.layer.12.output.LayerNorm.weight', 'base_model.encoder.layer.22.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.10.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.11.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.5.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.18.output.dense.weight', 'base_model.encoder.layer.17.output.adapters.ts.adapter_up.bias', 'base_model.embeddings.token_type_embeddings.weight', 'base_model.encoder.layer.7.attention.output.dense.bias', 'base_model.encoder.layer.17.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.1.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.10.intermediate.dense.weight', 'base_model.encoder.layer.11.output.LayerNorm.weight', 'base_model.encoder.layer.22.attention.self.value.weight', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.13.attention.output.LayerNorm.weight', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.4.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.23.attention.output.LayerNorm.weight', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.3.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.5.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.13.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.19.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.17.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.22.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.22.attention.output.dense.weight', 'base_model.encoder.layer.8.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.1.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.9.attention.output.LayerNorm.bias', 'base_model.encoder.layer.8.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.17.attention.output.LayerNorm.weight', 'base_model.encoder.layer.7.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.20.output.LayerNorm.weight', 'base_model.encoder.layer.20.attention.output.dense.weight', 'base_model.encoder.layer.6.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.21.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.8.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.3.output.dense.weight', 'base_model.encoder.layer.15.attention.self.value.bias', 'base_model.encoder.layer.1.attention.output.LayerNorm.bias', 'base_model.encoder.layer.9.attention.output.LayerNorm.weight', 'base_model.encoder.layer.12.output.LayerNorm.bias', 'base_model.encoder.layer.0.attention.self.key.bias', 'base_model.encoder.layer.17.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.0.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.3.output.dense.bias', 'base_model.embeddings.LayerNorm.weight', 'base_model.encoder.layer.5.attention.self.key.bias', 'base_model.encoder.layer.9.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.4.attention.output.dense.bias', 'base_model.encoder.layer.18.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.20.attention.output.LayerNorm.bias', 'base_model.encoder.layer.1.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.4.output.dense.bias', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.16.attention.self.key.bias', 'base_model.encoder.layer.20.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.0.attention.self.query.bias', 'base_model.encoder.layer.12.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.19.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.4.output.LayerNorm.bias', 'base_model.encoder.layer.10.output.dense.bias', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.19.output.LayerNorm.weight', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.1.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.8.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.21.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.23.attention.self.value.bias', 'base_model.encoder.layer.4.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.3.intermediate.dense.weight', 'base_model.encoder.layer.13.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.20.attention.self.query.bias', 'base_model.encoder.layer.9.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.15.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.22.intermediate.dense.bias', 'base_model.encoder.layer.22.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.12.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.15.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.11.intermediate.dense.weight', 'base_model.encoder.layer.22.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.10.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.20.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.1.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.3.attention.self.value.bias', 'base_model.encoder.layer.23.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.1.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.20.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.15.attention.self.value.weight', 'base_model.encoder.layer.12.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.7.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.23.attention.output.dense.bias', 'base_model.encoder.layer.7.attention.self.value.bias', 'base_model.encoder.layer.9.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.17.output.dense.weight', 'base_model.encoder.layer.7.attention.self.key.bias', 'base_model.encoder.layer.4.output.dense.weight', 'base_model.encoder.layer.17.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.18.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.0.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.6.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.5.attention.output.dense.bias', 'base_model.encoder.layer.5.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.6.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.5.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.2.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.11.attention.self.key.weight', 'base_model.encoder.layer.17.attention.self.value.bias', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.21.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.14.attention.self.key.weight', 'base_model.encoder.layer.19.attention.self.value.bias', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.20.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.9.intermediate.dense.bias', 'base_model.encoder.layer.0.attention.output.LayerNorm.weight', 'base_model.encoder.layer.6.output.dense.weight', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.23.attention.output.LayerNorm.bias', 'base_model.encoder.layer.3.attention.self.key.weight', 'base_model.encoder.layer.17.attention.output.dense.weight', 'base_model.encoder.layer.4.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.6.output.dense.bias', 'base_model.encoder.layer.15.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.8.output.LayerNorm.bias', 'base_model.encoder.layer.14.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.21.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.14.output.dense.bias', 'base_model.encoder.layer.20.attention.self.key.weight', 'base_model.encoder.layer.3.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.19.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.12.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.2.output.LayerNorm.weight', 'base_model.encoder.layer.21.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.15.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.5.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.18.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.19.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.0.attention.self.value.weight', 'base_model.encoder.layer.8.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.22.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.15.output.LayerNorm.weight', 'base_model.encoder.layer.9.attention.self.query.weight', 'base_model.encoder.layer.18.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.18.attention.output.LayerNorm.weight', 'base_model.encoder.layer.20.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.10.attention.self.key.weight', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.8.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.21.attention.self.key.weight', 'base_model.encoder.layer.7.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.8.attention.output.dense.bias', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.22.output.LayerNorm.bias', 'base_model.encoder.layer.10.attention.self.value.bias', 'base_model.encoder.layer.22.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.7.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.8.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.10.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.9.attention.self.value.bias', 'base_model.encoder.layer.10.attention.self.query.bias', 'base_model.encoder.layer.17.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.0.attention.self.query.weight', 'base_model.encoder.layer.12.attention.output.LayerNorm.bias', 'base_model.encoder.layer.11.intermediate.dense.bias', 'base_model.encoder.layer.6.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.11.output.LayerNorm.bias', 'base_model.encoder.layer.1.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.13.attention.self.query.weight', 'base_model.encoder.layer.4.attention.output.dense.weight', 'base_model.encoder.layer.14.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.15.output.dense.bias', 'base_model.encoder.layer.2.attention.output.dense.bias', 'base_model.encoder.layer.14.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.15.output.dense.weight', 'base_model.encoder.layer.2.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.0.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.8.attention.output.LayerNorm.bias', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.1.output.LayerNorm.weight', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.14.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.13.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.2.attention.output.LayerNorm.weight', 'base_model.encoder.layer.16.attention.output.dense.bias', 'base_model.encoder.layer.3.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.0.output.LayerNorm.weight', 'base_model.encoder.layer.3.attention.output.LayerNorm.weight', 'base_model.encoder.layer.4.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.10.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.12.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.22.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.1.attention.output.dense.weight', 'base_model.encoder.layer.6.intermediate.dense.bias', 'base_model.encoder.layer.18.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.18.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.16.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.2.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.18.output.LayerNorm.bias', 'base_model.encoder.layer.8.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.8.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.4.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.0.output.LayerNorm.bias', 'base_model.encoder.layer.1.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.5.attention.self.query.weight', 'base_model.encoder.layer.9.attention.self.key.bias', 'base_model.encoder.layer.14.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.3.attention.output.dense.weight', 'base_model.encoder.layer.13.attention.self.key.weight', 'base_model.encoder.layer.17.attention.self.key.bias', 'base_model.encoder.layer.8.attention.self.query.weight', 'base_model.encoder.layer.18.attention.self.key.weight', 'base_model.encoder.layer.19.output.LayerNorm.bias', 'base_model.encoder.layer.5.attention.self.value.bias', 'base_model.encoder.layer.2.attention.self.key.weight', 'base_model.encoder.layer.22.attention.self.query.weight', 'base_model.encoder.layer.2.intermediate.dense.bias', 'base_model.encoder.layer.5.attention.self.value.weight', 'base_model.encoder.layer.14.output.dense.weight', 'base_model.encoder.layer.19.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.21.output.LayerNorm.weight', 'base_model.encoder.layer.22.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.0.attention.output.LayerNorm.bias', 'base_model.encoder.layer.8.intermediate.dense.bias', 'base_model.encoder.layer.5.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.15.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.6.attention.output.dense.weight', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.19.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.21.attention.self.value.bias', 'base_model.encoder.layer.16.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.13.attention.output.dense.bias', 'base_model.encoder.layer.22.attention.output.LayerNorm.weight', 'base_model.encoder.layer.14.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.10.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.14.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.18.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.4.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.22.intermediate.dense.weight', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.13.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.22.attention.self.key.weight', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.11.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.0.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.18.output.adapters.tp.adapter_up.bias', 'base_model.pooler.dense.bias', 'base_model.encoder.layer.17.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.12.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.16.attention.self.value.weight', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.4.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.11.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.23.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.9.output.dense.weight', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.embeddings.LayerNorm.bias', 'base_model.encoder.layer.16.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.5.intermediate.dense.bias', 'base_model.encoder.layer.9.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.11.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.22.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.7.attention.self.query.bias', 'base_model.encoder.layer.12.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.18.attention.self.value.bias', 'base_model.encoder.layer.12.attention.output.LayerNorm.weight', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.17.attention.self.key.weight', 'base_model.encoder.layer.7.attention.output.LayerNorm.bias', 'base_model.encoder.layer.2.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.9.attention.output.dense.bias', 'base_model.encoder.layer.0.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.13.intermediate.dense.bias', 'base_model.encoder.layer.15.intermediate.dense.bias', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.9.attention.output.dense.weight', 'base_model.encoder.layer.1.output.dense.weight', 'base_model.encoder.layer.9.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.14.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.4.output.LayerNorm.weight', 'base_model.encoder.layer.8.attention.self.value.weight', 'base_model.encoder.layer.19.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.13.attention.self.query.bias', 'base_model.encoder.layer.13.output.dense.bias', 'base_model.encoder.layer.8.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.13.attention.output.LayerNorm.bias', 'base_model.encoder.layer.21.output.dense.bias', 'base_model.encoder.layer.1.output.dense.bias', 'base_model.encoder.layer.1.output.LayerNorm.bias', 'base_model.encoder.layer.18.attention.self.query.bias', 'base_model.encoder.layer.14.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.22.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.9.attention.self.value.weight', 'base_model.encoder.layer.21.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.0.intermediate.dense.bias', 'base_model.encoder.layer.11.attention.self.query.weight', 'base_model.encoder.layer.6.attention.self.query.bias', 'base_model.encoder.layer.8.attention.output.LayerNorm.weight', 'base_model.encoder.layer.11.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.7.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.23.output.dense.weight', 'base_model.encoder.layer.13.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.16.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.5.attention.self.query.bias', 'base_model.encoder.layer.13.output.dense.weight', 'base_model.encoder.layer.6.attention.output.dense.bias', 'base_model.encoder.layer.9.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.14.attention.output.LayerNorm.bias', 'base_model.encoder.layer.9.output.LayerNorm.weight', 'base_model.encoder.layer.12.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.6.attention.self.value.bias', 'base_model.encoder.layer.9.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.22.attention.output.LayerNorm.bias', 'base_model.encoder.layer.12.output.dense.bias', 'base_model.encoder.layer.21.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.1.attention.self.key.bias', 'base_model.encoder.layer.0.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.8.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.13.attention.self.value.bias', 'base_model.encoder.layer.17.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.21.intermediate.dense.bias', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.16.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.7.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.18.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.7.output.dense.weight', 'base_model.encoder.layer.2.attention.self.query.bias', 'base_model.encoder.layer.20.intermediate.dense.bias', 'base_model.encoder.layer.12.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.10.attention.output.LayerNorm.bias', 'base_model.encoder.layer.9.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.11.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.11.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.20.output.dense.bias', 'base_model.encoder.layer.0.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.7.intermediate.dense.weight', 'base_model.encoder.layer.20.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.6.output.LayerNorm.bias', 'base_model.encoder.layer.9.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.23.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.11.output.adapters.ep.adapter_up.weight', 'base_model.pooler.dense.weight', 'base_model.encoder.layer.10.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.2.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.6.attention.output.LayerNorm.weight', 'base_model.encoder.layer.10.output.LayerNorm.bias', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.11.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.13.attention.self.value.weight', 'base_model.encoder.layer.17.intermediate.dense.weight', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.21.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.4.attention.output.LayerNorm.bias', 'base_model.encoder.layer.10.output.LayerNorm.weight', 'base_model.encoder.layer.20.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.18.output.LayerNorm.weight', 'base_model.encoder.layer.5.output.dense.weight', 'base_model.encoder.layer.14.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.5.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.12.attention.output.dense.weight', 'base_model.encoder.layer.1.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.18.attention.output.dense.bias', 'base_model.encoder.layer.3.output.LayerNorm.weight', 'base_model.encoder.layer.3.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.23.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.2.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.0.attention.self.value.bias', 'base_model.encoder.layer.17.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.18.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.19.output.dense.bias', 'base_model.encoder.layer.2.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.8.attention.self.value.bias', 'base_model.encoder.layer.12.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.18.attention.self.value.weight', 'base_model.encoder.layer.3.attention.self.query.bias', 'base_model.encoder.layer.20.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.23.attention.self.value.weight', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.7.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.1.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.15.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.15.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.15.attention.self.query.bias', 'base_model.encoder.layer.6.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.15.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.22.attention.self.value.bias', 'base_model.encoder.layer.5.intermediate.dense.weight', 'base_model.encoder.layer.8.output.dense.bias', 'base_model.encoder.layer.23.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.4.intermediate.dense.bias', 'base_model.encoder.layer.6.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.4.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.6.attention.self.query.weight', 'base_model.encoder.layer.11.output.dense.bias', 'base_model.encoder.layer.6.intermediate.dense.weight', 'base_model.encoder.layer.5.attention.output.LayerNorm.weight', 'base_model.encoder.layer.18.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.12.intermediate.dense.weight', 'base_model.encoder.layer.10.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.6.attention.output.LayerNorm.bias', 'base_model.encoder.layer.21.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.15.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.20.intermediate.dense.weight', 'base_model.encoder.layer.4.attention.self.query.bias', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.21.attention.self.query.weight', 'base_model.encoder.layer.1.attention.self.value.weight', 'base_model.embeddings.position_embeddings.weight', 'base_model.encoder.layer.10.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.19.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.20.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.12.output.adapters.ts.adapter_down.0.bias', 'qa_outputs.bias', 'base_model.encoder.layer.21.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.6.attention.self.key.bias', 'base_model.encoder.layer.13.output.LayerNorm.weight', 'base_model.encoder.layer.8.output.dense.weight', 'base_model.encoder.layer.12.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.20.attention.self.value.bias', 'base_model.encoder.layer.20.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.8.attention.output.dense.weight', 'base_model.encoder.layer.16.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.22.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.17.output.LayerNorm.bias', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.3.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.13.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.13.attention.self.key.bias', 'base_model.encoder.layer.19.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.21.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.1.intermediate.dense.bias', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.5.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.4.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.16.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.14.output.LayerNorm.bias', 'base_model.encoder.layer.16.attention.self.value.bias', 'base_model.encoder.layer.19.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.16.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.1.attention.self.key.weight', 'base_model.encoder.layer.10.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.20.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.9.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.17.attention.output.dense.bias', 'base_model.encoder.layer.19.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.3.intermediate.dense.bias', 'base_model.encoder.layer.18.attention.self.key.bias', 'base_model.encoder.layer.15.intermediate.dense.weight', 'base_model.encoder.layer.1.attention.self.query.weight', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.13.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.22.output.dense.weight', 'base_model.encoder.layer.3.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.5.attention.output.LayerNorm.bias', 'base_model.encoder.layer.22.output.LayerNorm.weight', 'base_model.encoder.layer.18.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.11.attention.output.dense.weight', 'base_model.encoder.layer.5.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.3.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.2.output.LayerNorm.bias', 'base_model.encoder.layer.5.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.6.output.LayerNorm.weight', 'base_model.encoder.layer.15.attention.output.LayerNorm.weight', 'base_model.encoder.layer.14.attention.output.dense.bias', 'base_model.encoder.layer.13.output.LayerNorm.bias', 'base_model.encoder.layer.13.attention.output.dense.weight', 'base_model.encoder.layer.17.output.dense.bias', 'base_model.encoder.layer.4.attention.self.key.weight', 'base_model.encoder.layer.7.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.12.attention.self.key.weight', 'base_model.encoder.layer.20.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.7.attention.self.query.weight', 'base_model.encoder.layer.8.attention.self.key.bias', 'base_model.encoder.layer.19.attention.output.dense.weight', 'base_model.encoder.layer.23.output.LayerNorm.bias', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.1.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.6.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.15.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.23.intermediate.dense.bias', 'base_model.encoder.layer.14.attention.self.query.bias', 'base_model.encoder.layer.1.attention.output.LayerNorm.weight', 'base_model.encoder.layer.13.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.16.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.20.output.LayerNorm.bias', 'base_model.encoder.layer.1.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.2.attention.output.LayerNorm.bias', 'base_model.encoder.layer.6.attention.self.value.weight', 'base_model.encoder.layer.10.attention.self.query.weight', 'base_model.encoder.layer.1.intermediate.dense.weight', 'base_model.encoder.layer.7.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.13.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.15.attention.output.LayerNorm.bias', 'base_model.encoder.layer.23.attention.output.dense.weight', 'base_model.encoder.layer.23.attention.self.key.bias', 'base_model.encoder.layer.19.attention.self.key.bias', 'base_model.encoder.layer.0.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.1.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.15.attention.self.query.weight', 'base_model.encoder.layer.17.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.4.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.2.attention.self.query.weight', 'base_model.encoder.layer.15.attention.output.dense.bias', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.22.attention.self.query.bias', 'base_model.encoder.layer.21.output.dense.weight', 'base_model.encoder.layer.12.attention.self.value.weight', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.7.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.4.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.5.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.1.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.23.output.LayerNorm.weight', 'base_model.encoder.layer.12.attention.self.value.bias', 'base_model.encoder.layer.21.attention.output.LayerNorm.bias', 'base_model.encoder.layer.6.attention.self.key.weight', 'base_model.encoder.layer.10.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.10.attention.self.key.bias', 'base_model.encoder.layer.23.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.8.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.2.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.1.attention.self.query.bias', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.9.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.16.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.10.attention.self.value.weight', 'base_model.encoder.layer.12.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.4.attention.self.key.bias', 'base_model.encoder.layer.12.intermediate.dense.bias', 'base_model.encoder.layer.2.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.11.attention.self.value.bias', 'base_model.encoder.layer.18.output.dense.bias', 'base_model.encoder.layer.10.attention.output.dense.weight', 'base_model.encoder.layer.7.output.LayerNorm.weight', 'base_model.encoder.layer.5.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.21.attention.output.LayerNorm.weight', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.9.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.22.output.dense.bias', 'base_model.encoder.layer.23.intermediate.dense.weight', 'base_model.encoder.layer.19.attention.self.query.bias', 'base_model.embeddings.position_ids', 'base_model.encoder.layer.3.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.11.output.dense.weight', 'base_model.encoder.layer.4.attention.self.value.bias', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.16.output.dense.weight', 'base_model.encoder.layer.2.output.dense.weight', 'base_model.encoder.layer.19.intermediate.dense.bias', 'base_model.encoder.layer.20.attention.self.query.weight', 'base_model.encoder.layer.23.attention.self.query.weight', 'base_model.encoder.layer.11.attention.self.key.bias', 'base_model.encoder.layer.16.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.2.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.4.intermediate.dense.weight', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.17.attention.output.LayerNorm.bias', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.2.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.9.output.LayerNorm.bias', 'base_model.encoder.layer.22.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.16.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.15.attention.self.key.weight', 'base_model.encoder.layer.7.intermediate.dense.bias', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.14.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.14.attention.output.LayerNorm.weight', 'base_model.encoder.layer.9.intermediate.dense.weight', 'base_model.encoder.layer.5.output.adapters.tp.adapter_up.bias']
- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of XLMRobertaModel were not initialized from the model checkpoint at /cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//squad/xlm-KG_LR3e-5_EPOCH2.0_maxlen384_batchsize4_gradacc4 and are newly initialized: ['encoder.layer.10.attention.self.value.weight', 'encoder.layer.7.attention.output.dense.bias', 'encoder.layer.9.attention.self.key.weight', 'encoder.layer.20.attention.output.LayerNorm.bias', 'encoder.layer.22.attention.self.query.weight', 'encoder.layer.18.attention.self.value.weight', 'encoder.layer.23.attention.output.dense.weight', 'encoder.layer.11.attention.output.dense.weight', 'encoder.layer.11.attention.self.key.weight', 'encoder.layer.2.attention.self.query.weight', 'encoder.layer.2.attention.self.query.bias', 'encoder.layer.11.attention.self.key.bias', 'encoder.layer.7.output.dense.weight', 'encoder.layer.1.attention.output.LayerNorm.weight', 'encoder.layer.5.attention.self.query.bias', 'encoder.layer.8.output.LayerNorm.bias', 'encoder.layer.15.attention.output.LayerNorm.bias', 'encoder.layer.4.attention.self.key.bias', 'encoder.layer.0.attention.self.query.weight', 'encoder.layer.22.attention.output.dense.bias', 'encoder.layer.5.attention.self.value.weight', 'encoder.layer.22.attention.output.LayerNorm.weight', 'encoder.layer.20.attention.output.dense.bias', 'encoder.layer.19.attention.output.dense.weight', 'encoder.layer.21.attention.self.value.bias', 'encoder.layer.0.attention.output.dense.bias', 'encoder.layer.7.output.dense.bias', 'encoder.layer.10.output.dense.bias', 'encoder.layer.14.output.dense.bias', 'encoder.layer.14.attention.self.value.weight', 'encoder.layer.11.output.LayerNorm.bias', 'encoder.layer.0.attention.output.dense.weight', 'encoder.layer.2.output.LayerNorm.bias', 'embeddings.LayerNorm.weight', 'encoder.layer.13.output.dense.bias', 'encoder.layer.15.output.LayerNorm.bias', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.9.attention.self.query.bias', 'encoder.layer.9.attention.self.value.weight', 'encoder.layer.4.attention.self.key.weight', 'encoder.layer.10.output.LayerNorm.weight', 'encoder.layer.2.output.dense.bias', 'encoder.layer.11.attention.self.query.bias', 'encoder.layer.21.output.LayerNorm.weight', 'encoder.layer.16.attention.self.key.bias', 'encoder.layer.22.attention.self.key.bias', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.3.attention.self.key.weight', 'encoder.layer.1.attention.self.key.bias', 'encoder.layer.12.output.dense.bias', 'encoder.layer.22.output.dense.bias', 'encoder.layer.22.output.dense.weight', 'encoder.layer.9.attention.self.key.bias', 'encoder.layer.13.attention.output.LayerNorm.weight', 'encoder.layer.22.output.LayerNorm.weight', 'encoder.layer.19.intermediate.dense.bias', 'encoder.layer.22.attention.self.query.bias', 'encoder.layer.10.attention.self.query.weight', 'encoder.layer.4.attention.output.dense.bias', 'encoder.layer.22.attention.output.dense.weight', 'encoder.layer.2.attention.output.dense.weight', 'encoder.layer.21.attention.output.dense.weight', 'encoder.layer.11.output.dense.weight', 'encoder.layer.21.attention.self.key.bias', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.9.attention.self.value.bias', 'encoder.layer.20.output.dense.bias', 'encoder.layer.0.attention.self.value.weight', 'encoder.layer.6.attention.self.query.bias', 'encoder.layer.16.output.dense.weight', 'encoder.layer.15.attention.output.LayerNorm.weight', 'encoder.layer.3.attention.self.query.bias', 'encoder.layer.16.output.dense.bias', 'encoder.layer.19.attention.self.key.weight', 'encoder.layer.1.attention.output.dense.weight', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.16.intermediate.dense.weight', 'encoder.layer.20.attention.self.value.bias', 'encoder.layer.17.output.LayerNorm.weight', 'encoder.layer.13.attention.self.value.weight', 'encoder.layer.13.attention.output.dense.bias', 'encoder.layer.3.output.dense.bias', 'encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.10.attention.output.dense.bias', 'encoder.layer.0.output.dense.weight', 'encoder.layer.7.output.LayerNorm.bias', 'encoder.layer.2.attention.self.key.bias', 'encoder.layer.23.output.LayerNorm.bias', 'encoder.layer.16.intermediate.dense.bias', 'encoder.layer.0.attention.self.key.bias', 'encoder.layer.5.attention.output.dense.bias', 'encoder.layer.12.output.LayerNorm.bias', 'encoder.layer.3.attention.self.query.weight', 'encoder.layer.7.attention.self.key.bias', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.18.attention.output.LayerNorm.bias', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.21.attention.self.query.weight', 'encoder.layer.9.attention.output.dense.bias', 'encoder.layer.10.attention.self.query.bias', 'encoder.layer.14.intermediate.dense.weight', 'encoder.layer.16.attention.self.key.weight', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.7.attention.self.key.weight', 'encoder.layer.9.attention.self.query.weight', 'encoder.layer.12.attention.output.dense.bias', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.5.output.dense.weight', 'encoder.layer.16.output.LayerNorm.bias', 'encoder.layer.18.attention.output.dense.bias', 'encoder.layer.19.intermediate.dense.weight', 'encoder.layer.14.output.dense.weight', 'encoder.layer.21.attention.self.key.weight', 'encoder.layer.19.attention.self.value.bias', 'encoder.layer.14.attention.output.LayerNorm.bias', 'encoder.layer.9.attention.output.LayerNorm.bias', 'encoder.layer.16.output.LayerNorm.weight', 'encoder.layer.14.attention.output.LayerNorm.weight', 'encoder.layer.9.output.LayerNorm.weight', 'encoder.layer.13.intermediate.dense.bias', 'encoder.layer.1.attention.self.value.weight', 'encoder.layer.10.output.dense.weight', 'encoder.layer.16.attention.output.LayerNorm.bias', 'encoder.layer.16.attention.output.dense.weight', 'encoder.layer.9.output.LayerNorm.bias', 'encoder.layer.18.attention.self.key.weight', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.15.output.LayerNorm.weight', 'encoder.layer.12.output.LayerNorm.weight', 'encoder.layer.18.attention.output.dense.weight', 'encoder.layer.23.attention.self.key.weight', 'encoder.layer.12.intermediate.dense.bias', 'encoder.layer.8.attention.self.query.weight', 'encoder.layer.1.attention.output.dense.bias', 'encoder.layer.19.attention.self.key.bias', 'encoder.layer.1.attention.self.value.bias', 'encoder.layer.21.attention.output.LayerNorm.weight', 'encoder.layer.3.output.dense.weight', 'encoder.layer.7.attention.self.value.weight', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.18.attention.self.key.bias', 'encoder.layer.6.output.LayerNorm.bias', 'encoder.layer.8.output.LayerNorm.weight', 'encoder.layer.0.attention.self.key.weight', 'encoder.layer.7.output.LayerNorm.weight', 'encoder.layer.22.intermediate.dense.weight', 'encoder.layer.15.intermediate.dense.bias', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.6.attention.output.LayerNorm.bias', 'encoder.layer.4.attention.output.LayerNorm.bias', 'encoder.layer.1.output.dense.weight', 'encoder.layer.18.attention.output.LayerNorm.weight', 'encoder.layer.1.attention.self.query.weight', 'encoder.layer.6.attention.self.value.weight', 'embeddings.position_embeddings.weight', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.23.output.LayerNorm.weight', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.14.attention.self.key.bias', 'encoder.layer.4.output.dense.bias', 'encoder.layer.18.attention.self.query.bias', 'encoder.layer.13.intermediate.dense.weight', 'encoder.layer.7.attention.self.query.weight', 'encoder.layer.14.attention.self.query.bias', 'encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.layer.18.intermediate.dense.bias', 'encoder.layer.1.attention.self.key.weight', 'encoder.layer.19.attention.self.query.bias', 'encoder.layer.15.output.dense.bias', 'encoder.layer.23.attention.self.key.bias', 'encoder.layer.4.output.dense.weight', 'encoder.layer.17.attention.self.key.bias', 'encoder.layer.3.attention.self.value.bias', 'encoder.layer.6.attention.self.query.weight', 'encoder.layer.12.attention.self.query.weight', 'encoder.layer.2.output.dense.weight', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.21.attention.self.value.weight', 'encoder.layer.20.output.LayerNorm.bias', 'encoder.layer.17.attention.self.query.bias', 'encoder.layer.12.attention.self.key.weight', 'encoder.layer.13.attention.self.key.weight', 'encoder.layer.15.attention.output.dense.bias', 'encoder.layer.17.intermediate.dense.weight', 'encoder.layer.8.attention.output.dense.weight', 'encoder.layer.20.attention.self.key.bias', 'encoder.layer.14.output.LayerNorm.bias', 'encoder.layer.10.attention.output.LayerNorm.weight', 'encoder.layer.20.attention.output.dense.weight', 'encoder.layer.16.attention.self.value.weight', 'encoder.layer.23.attention.self.value.weight', 'encoder.layer.8.attention.output.LayerNorm.bias', 'encoder.layer.14.attention.output.dense.weight', 'encoder.layer.14.attention.output.dense.bias', 'encoder.layer.1.output.dense.bias', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.12.attention.self.query.bias', 'encoder.layer.15.attention.output.dense.weight', 'encoder.layer.4.attention.output.LayerNorm.weight', 'encoder.layer.19.output.LayerNorm.bias', 'encoder.layer.4.attention.self.query.bias', 'encoder.layer.10.intermediate.dense.weight', 'encoder.layer.4.attention.self.value.weight', 'encoder.layer.8.output.dense.weight', 'encoder.layer.11.output.dense.bias', 'encoder.layer.20.output.LayerNorm.weight', 'encoder.layer.7.attention.output.LayerNorm.bias', 'encoder.layer.13.attention.output.dense.weight', 'encoder.layer.17.attention.output.LayerNorm.weight', 'encoder.layer.12.attention.self.value.bias', 'encoder.layer.7.attention.output.dense.weight', 'encoder.layer.4.attention.output.dense.weight', 'encoder.layer.9.attention.output.LayerNorm.weight', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.23.output.dense.weight', 'encoder.layer.5.attention.self.key.bias', 'encoder.layer.12.attention.self.value.weight', 'encoder.layer.11.attention.self.value.weight', 'encoder.layer.23.intermediate.dense.weight', 'encoder.layer.18.intermediate.dense.weight', 'encoder.layer.0.attention.output.LayerNorm.weight', 'encoder.layer.8.attention.output.dense.bias', 'encoder.layer.12.attention.self.key.bias', 'encoder.layer.18.output.dense.bias', 'encoder.layer.20.attention.output.LayerNorm.weight', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.23.attention.self.query.bias', 'encoder.layer.21.output.dense.weight', 'encoder.layer.13.output.LayerNorm.weight', 'encoder.layer.14.intermediate.dense.bias', 'encoder.layer.19.attention.self.query.weight', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.22.attention.self.value.weight', 'encoder.layer.15.attention.self.value.bias', 'encoder.layer.8.output.dense.bias', 'encoder.layer.20.attention.self.query.bias', 'encoder.layer.6.attention.self.value.bias', 'encoder.layer.10.attention.self.key.bias', 'pooler.dense.bias', 'encoder.layer.7.attention.output.LayerNorm.weight', 'encoder.layer.21.attention.self.query.bias', 'encoder.layer.6.attention.output.LayerNorm.weight', 'encoder.layer.23.attention.output.dense.bias', 'encoder.layer.2.attention.output.dense.bias', 'encoder.layer.23.attention.output.LayerNorm.weight', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.5.attention.output.dense.weight', 'encoder.layer.18.output.LayerNorm.bias', 'encoder.layer.16.attention.self.query.bias', 'encoder.layer.3.attention.self.value.weight', 'encoder.layer.10.attention.self.key.weight', 'encoder.layer.17.output.LayerNorm.bias', 'encoder.layer.8.attention.self.key.weight', 'encoder.layer.8.attention.self.query.bias', 'encoder.layer.23.intermediate.dense.bias', 'encoder.layer.20.intermediate.dense.weight', 'encoder.layer.12.attention.output.LayerNorm.weight', 'encoder.layer.8.attention.output.LayerNorm.weight', 'embeddings.token_type_embeddings.weight', 'encoder.layer.17.attention.self.value.bias', 'encoder.layer.2.attention.self.value.weight', 'encoder.layer.22.attention.output.LayerNorm.bias', 'encoder.layer.13.output.dense.weight', 'embeddings.word_embeddings.weight', 'encoder.layer.18.attention.self.query.weight', 'encoder.layer.15.attention.self.key.bias', 'encoder.layer.6.attention.output.dense.bias', 'encoder.layer.19.output.dense.bias', 'encoder.layer.9.output.dense.weight', 'encoder.layer.9.output.dense.bias', 'encoder.layer.11.attention.self.value.bias', 'encoder.layer.20.attention.self.query.weight', 'encoder.layer.23.output.dense.bias', 'encoder.layer.21.output.dense.bias', 'encoder.layer.14.attention.self.value.bias', 'encoder.layer.4.attention.self.value.bias', 'encoder.layer.18.output.LayerNorm.weight', 'encoder.layer.19.attention.output.LayerNorm.weight', 'encoder.layer.11.output.LayerNorm.weight', 'encoder.layer.23.attention.output.LayerNorm.bias', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.17.output.dense.bias', 'encoder.layer.12.attention.output.dense.weight', 'encoder.layer.10.output.LayerNorm.bias', 'encoder.layer.17.attention.output.dense.weight', 'encoder.layer.3.attention.self.key.bias', 'encoder.layer.0.attention.self.value.bias', 'encoder.layer.17.attention.self.value.weight', 'encoder.layer.7.attention.self.value.bias', 'encoder.layer.2.attention.self.key.weight', 'embeddings.LayerNorm.bias', 'encoder.layer.10.attention.output.LayerNorm.bias', 'encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.layer.4.attention.self.query.weight', 'encoder.layer.20.output.dense.weight', 'encoder.layer.17.attention.self.key.weight', 'encoder.layer.21.output.LayerNorm.bias', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.22.intermediate.dense.bias', 'encoder.layer.17.attention.output.LayerNorm.bias', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.23.attention.self.query.weight', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.layer.10.attention.self.value.bias', 'encoder.layer.20.attention.self.key.weight', 'encoder.layer.21.attention.output.dense.bias', 'encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.layer.18.attention.self.value.bias', 'encoder.layer.20.attention.self.value.weight', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.16.attention.output.LayerNorm.weight', 'encoder.layer.12.attention.output.LayerNorm.bias', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.14.attention.self.query.weight', 'encoder.layer.7.intermediate.dense.bias', 'encoder.layer.10.attention.output.dense.weight', 'encoder.layer.5.attention.self.value.bias', 'encoder.layer.11.attention.self.query.weight', 'encoder.layer.22.output.LayerNorm.bias', 'encoder.layer.17.attention.self.query.weight', 'encoder.layer.15.intermediate.dense.weight', 'encoder.layer.6.output.dense.weight', 'encoder.layer.13.attention.self.query.bias', 'encoder.layer.3.attention.output.dense.weight', 'encoder.layer.5.attention.self.query.weight', 'encoder.layer.5.output.LayerNorm.bias', 'encoder.layer.3.attention.output.dense.bias', 'encoder.layer.22.attention.self.value.bias', 'encoder.layer.22.attention.self.key.weight', 'encoder.layer.1.attention.self.query.bias', 'encoder.layer.19.attention.self.value.weight', 'encoder.layer.21.attention.output.LayerNorm.bias', 'encoder.layer.0.attention.self.query.bias', 'encoder.layer.14.output.LayerNorm.weight', 'encoder.layer.19.attention.output.LayerNorm.bias', 'encoder.layer.12.output.dense.weight', 'encoder.layer.15.attention.self.query.weight', 'encoder.layer.13.output.LayerNorm.bias', 'encoder.layer.15.attention.self.value.weight', 'encoder.layer.8.attention.self.value.bias', 'encoder.layer.19.output.dense.weight', 'encoder.layer.21.intermediate.dense.weight', 'encoder.layer.13.attention.output.LayerNorm.bias', 'encoder.layer.17.intermediate.dense.bias', 'encoder.layer.14.attention.self.key.weight', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.21.intermediate.dense.bias', 'encoder.layer.16.attention.output.dense.bias', 'encoder.layer.9.attention.output.dense.weight', 'encoder.layer.15.output.dense.weight', 'encoder.layer.2.attention.self.value.bias', 'encoder.layer.15.attention.self.key.weight', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.18.output.dense.weight', 'encoder.layer.11.attention.output.LayerNorm.weight', 'encoder.layer.17.output.dense.weight', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.11.attention.output.dense.bias', 'encoder.layer.2.attention.output.LayerNorm.weight', 'encoder.layer.20.intermediate.dense.bias', 'encoder.layer.16.attention.self.query.weight', 'encoder.layer.6.output.dense.bias', 'encoder.layer.0.output.dense.bias', 'encoder.layer.2.attention.output.LayerNorm.bias', 'encoder.layer.15.attention.self.query.bias', 'encoder.layer.23.attention.self.value.bias', 'encoder.layer.5.output.dense.bias', 'encoder.layer.13.attention.self.query.weight', 'encoder.layer.12.intermediate.dense.weight', 'encoder.layer.6.attention.output.dense.weight', 'encoder.layer.17.attention.output.dense.bias', 'encoder.layer.5.attention.self.key.weight', 'encoder.layer.6.attention.self.key.weight', 'encoder.layer.13.attention.self.value.bias', 'pooler.dense.weight', 'encoder.layer.6.attention.self.key.bias', 'encoder.layer.8.attention.self.key.bias', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.5.attention.output.LayerNorm.weight', 'encoder.layer.8.attention.self.value.weight', 'encoder.layer.19.output.LayerNorm.weight', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.19.attention.output.dense.bias', 'encoder.layer.7.attention.self.query.bias', 'encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.16.attention.self.value.bias', 'encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.layer.13.attention.self.key.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Overwriting existing adapter 'ep'.
Overwriting existing adapter 'tp'.
Overwriting existing adapter 'es'.
Overwriting existing adapter 'ts'.
Overwriting existing adapter fusion module 'ep,tp,es,ts'
05/09/2022 09:01:04 - INFO - __main__ -   lang2id = None
05/09/2022 09:01:09 - INFO - __main__ -   Training/evaluation parameters Namespace(adam_epsilon=1e-08, cache_dir='', config_name='', data_dir=None, device=device(type='cuda'), do_eval=True, do_lower_case=False, do_train=False, doc_stride=128, eval_all_checkpoints=False, eval_lang='de', evaluate_during_training=False, fp16=False, fp16_opt_level='O1', gradient_accumulation_steps=1, learning_rate=5e-05, local_rank=-1, logging_steps=50, max_answer_length=30, max_grad_norm=1.0, max_query_length=64, max_seq_length=384, max_steps=-1, model_name='xlm-KG', model_name_or_path='/cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//squad/xlm-KG_LR3e-5_EPOCH2.0_maxlen384_batchsize4_gradacc4', model_type='xlm', modelkg_dir='/cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/adapter/xlmr_adapter', n_best_size=20, n_gpu=1, no_cuda=False, null_score_diff_threshold=0.0, num_train_epochs=3.0, output_dir='/cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//squad/xlm-KG_LR3e-5_EPOCH2.0_maxlen384_batchsize4_gradacc4/predictions/xquad/', overwrite_cache=False, overwrite_output_dir=False, per_gpu_eval_batch_size=8, per_gpu_train_batch_size=8, predict_file='/cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/download//xquad//xquad.de.json', save_steps=50, seed=42, server_ip='', server_port='', threads=1, tokenizer_name='', train_file=None, train_lang='en', verbose_logging=False, version_2_with_negative=False, warmup_steps=0, weight_decay=0.0)
05/09/2022 09:01:09 - INFO - __main__ -   Loading checkpoint /cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//squad/xlm-KG_LR3e-5_EPOCH2.0_maxlen384_batchsize4_gradacc4 for evaluation
05/09/2022 09:01:09 - INFO - __main__ -   Evaluate the following checkpoints: ['/cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//squad/xlm-KG_LR3e-5_EPOCH2.0_maxlen384_batchsize4_gradacc4']
Some weights of the model checkpoint at /cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//squad/xlm-KG_LR3e-5_EPOCH2.0_maxlen384_batchsize4_gradacc4 were not used when initializing XLMRobertaModel: ['base_model.encoder.layer.0.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.19.attention.output.dense.bias', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.5.attention.self.key.weight', 'base_model.encoder.layer.15.attention.output.dense.weight', 'base_model.encoder.layer.18.intermediate.dense.weight', 'base_model.encoder.layer.15.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.21.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.12.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.10.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.9.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.7.attention.output.LayerNorm.weight', 'base_model.encoder.layer.13.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.19.attention.output.LayerNorm.weight', 'base_model.encoder.layer.3.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.9.attention.self.key.weight', 'base_model.encoder.layer.23.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.2.output.dense.bias', 'base_model.encoder.layer.21.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.13.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.3.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.7.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.3.attention.self.value.weight', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.7.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.21.attention.self.key.bias', 'base_model.encoder.layer.17.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.0.intermediate.dense.weight', 'qa_outputs.weight', 'base_model.encoder.layer.16.output.LayerNorm.weight', 'base_model.encoder.layer.4.attention.self.value.weight', 'base_model.encoder.layer.15.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.8.intermediate.dense.weight', 'base_model.encoder.layer.2.intermediate.dense.weight', 'base_model.encoder.layer.23.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.11.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.16.attention.output.LayerNorm.weight', 'base_model.encoder.layer.14.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.11.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.20.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.23.output.dense.bias', 'base_model.encoder.layer.12.attention.self.key.bias', 'base_model.encoder.layer.0.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.14.attention.self.key.bias', 'base_model.encoder.layer.14.attention.self.value.weight', 'base_model.encoder.layer.21.attention.self.query.bias', 'base_model.encoder.layer.11.attention.self.value.weight', 'base_model.encoder.layer.15.attention.self.key.bias', 'base_model.encoder.layer.4.attention.self.query.weight', 'base_model.encoder.layer.16.attention.self.query.bias', 'base_model.encoder.layer.20.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.11.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.3.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.8.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.3.output.LayerNorm.bias', 'base_model.encoder.layer.7.attention.self.value.weight', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.9.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.7.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.18.intermediate.dense.bias', 'base_model.encoder.layer.18.attention.output.dense.weight', 'base_model.encoder.layer.20.attention.self.key.bias', 'base_model.encoder.layer.13.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.16.output.dense.bias', 'base_model.encoder.layer.7.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.20.output.dense.weight', 'base_model.encoder.layer.2.attention.self.value.bias', 'base_model.encoder.layer.23.attention.self.key.weight', 'base_model.encoder.layer.17.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.11.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.12.attention.output.dense.bias', 'base_model.encoder.layer.10.attention.output.dense.bias', 'base_model.encoder.layer.0.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.1.attention.output.dense.bias', 'base_model.encoder.layer.19.attention.output.LayerNorm.bias', 'base_model.encoder.layer.23.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.21.attention.output.dense.bias', 'base_model.encoder.layer.3.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.21.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.0.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.23.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.9.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.6.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.8.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.1.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.16.output.LayerNorm.bias', 'base_model.encoder.layer.2.attention.self.value.weight', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.6.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.3.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.23.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.2.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.13.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.0.output.dense.weight', 'base_model.encoder.layer.22.attention.self.key.bias', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.8.output.LayerNorm.weight', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.1.attention.self.value.bias', 'base_model.encoder.layer.23.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.14.attention.self.value.bias', 'base_model.encoder.layer.16.attention.self.query.weight', 'base_model.encoder.layer.18.attention.self.query.weight', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.17.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.2.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.14.intermediate.dense.weight', 'base_model.encoder.layer.4.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.19.attention.self.key.weight', 'base_model.encoder.layer.5.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.9.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.3.attention.self.query.weight', 'base_model.encoder.layer.19.attention.self.value.weight', 'base_model.encoder.layer.21.attention.output.dense.weight', 'base_model.encoder.layer.23.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.17.attention.self.value.weight', 'base_model.encoder.layer.9.output.dense.bias', 'base_model.encoder.layer.19.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.16.attention.self.key.weight', 'base_model.encoder.layer.2.attention.output.dense.weight', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.17.output.LayerNorm.weight', 'base_model.encoder.layer.3.attention.output.LayerNorm.bias', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.21.intermediate.dense.weight', 'base_model.encoder.layer.10.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.11.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.11.attention.output.LayerNorm.bias', 'base_model.encoder.layer.19.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.18.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.22.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.3.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.21.output.LayerNorm.bias', 'base_model.encoder.layer.0.attention.output.dense.weight', 'base_model.encoder.layer.13.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.17.intermediate.dense.bias', 'base_model.encoder.layer.21.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.3.attention.output.dense.bias', 'base_model.encoder.layer.23.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.15.output.LayerNorm.bias', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.15.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.16.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.22.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.3.attention.self.key.bias', 'base_model.encoder.layer.14.attention.output.dense.weight', 'base_model.encoder.layer.18.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.19.attention.self.query.weight', 'base_model.encoder.layer.23.attention.self.query.bias', 'base_model.encoder.layer.3.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.6.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.14.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.19.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.6.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.7.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.14.output.LayerNorm.weight', 'base_model.encoder.layer.14.attention.self.query.weight', 'base_model.encoder.layer.11.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.16.attention.output.LayerNorm.bias', 'base_model.encoder.layer.10.intermediate.dense.bias', 'base_model.encoder.layer.16.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.19.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.4.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.5.output.LayerNorm.bias', 'base_model.encoder.layer.10.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.0.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.7.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.8.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.7.attention.output.dense.weight', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.13.intermediate.dense.weight', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.22.attention.output.dense.bias', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.12.attention.self.query.weight', 'base_model.encoder.layer.6.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.19.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.6.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.2.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.5.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.6.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.5.output.dense.bias', 'base_model.encoder.layer.16.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.20.attention.output.dense.bias', 'base_model.encoder.layer.15.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.9.attention.self.query.bias', 'base_model.embeddings.word_embeddings.weight', 'base_model.encoder.layer.2.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.6.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.13.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.14.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.17.attention.self.query.weight', 'base_model.encoder.layer.14.intermediate.dense.bias', 'base_model.encoder.layer.11.attention.output.LayerNorm.weight', 'base_model.encoder.layer.23.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.0.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.12.output.dense.weight', 'base_model.encoder.layer.15.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.18.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.15.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.5.output.LayerNorm.weight', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.22.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.12.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.13.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.20.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.8.attention.self.query.bias', 'base_model.encoder.layer.16.intermediate.dense.bias', 'base_model.encoder.layer.4.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.4.attention.output.LayerNorm.weight', 'base_model.encoder.layer.21.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.17.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.22.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.20.attention.self.value.weight', 'base_model.encoder.layer.8.attention.self.key.weight', 'base_model.encoder.layer.7.output.LayerNorm.bias', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.12.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.10.attention.output.LayerNorm.weight', 'base_model.encoder.layer.10.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.14.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.7.output.dense.bias', 'base_model.encoder.layer.16.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.2.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.17.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.20.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.10.output.dense.weight', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.16.intermediate.dense.weight', 'base_model.encoder.layer.17.attention.self.query.bias', 'base_model.encoder.layer.1.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.0.output.dense.bias', 'base_model.encoder.layer.12.attention.self.query.bias', 'base_model.encoder.layer.0.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.7.attention.self.key.weight', 'base_model.encoder.layer.2.attention.self.key.bias', 'base_model.encoder.layer.0.attention.output.dense.bias', 'base_model.encoder.layer.11.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.10.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.18.attention.output.LayerNorm.bias', 'base_model.encoder.layer.20.attention.output.LayerNorm.weight', 'base_model.encoder.layer.17.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.11.attention.output.dense.bias', 'base_model.encoder.layer.0.attention.self.key.weight', 'base_model.encoder.layer.10.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.18.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.14.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.3.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.5.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.5.attention.output.dense.weight', 'base_model.encoder.layer.6.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.16.attention.output.dense.weight', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.4.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.4.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.19.output.dense.weight', 'base_model.encoder.layer.21.attention.self.value.weight', 'base_model.encoder.layer.23.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.8.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.0.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.11.attention.self.query.bias', 'base_model.encoder.layer.19.intermediate.dense.weight', 'base_model.encoder.layer.12.output.LayerNorm.weight', 'base_model.encoder.layer.22.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.10.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.11.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.5.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.18.output.dense.weight', 'base_model.encoder.layer.17.output.adapters.ts.adapter_up.bias', 'base_model.embeddings.token_type_embeddings.weight', 'base_model.encoder.layer.7.attention.output.dense.bias', 'base_model.encoder.layer.17.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.1.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.10.intermediate.dense.weight', 'base_model.encoder.layer.11.output.LayerNorm.weight', 'base_model.encoder.layer.22.attention.self.value.weight', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.13.attention.output.LayerNorm.weight', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.4.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.23.attention.output.LayerNorm.weight', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.3.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.5.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.13.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.19.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.17.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.22.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.22.attention.output.dense.weight', 'base_model.encoder.layer.8.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.1.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.9.attention.output.LayerNorm.bias', 'base_model.encoder.layer.8.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.17.attention.output.LayerNorm.weight', 'base_model.encoder.layer.7.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.20.output.LayerNorm.weight', 'base_model.encoder.layer.20.attention.output.dense.weight', 'base_model.encoder.layer.6.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.21.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.8.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.3.output.dense.weight', 'base_model.encoder.layer.15.attention.self.value.bias', 'base_model.encoder.layer.1.attention.output.LayerNorm.bias', 'base_model.encoder.layer.9.attention.output.LayerNorm.weight', 'base_model.encoder.layer.12.output.LayerNorm.bias', 'base_model.encoder.layer.0.attention.self.key.bias', 'base_model.encoder.layer.17.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.0.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.3.output.dense.bias', 'base_model.embeddings.LayerNorm.weight', 'base_model.encoder.layer.5.attention.self.key.bias', 'base_model.encoder.layer.9.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.4.attention.output.dense.bias', 'base_model.encoder.layer.18.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.20.attention.output.LayerNorm.bias', 'base_model.encoder.layer.1.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.4.output.dense.bias', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.16.attention.self.key.bias', 'base_model.encoder.layer.20.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.0.attention.self.query.bias', 'base_model.encoder.layer.12.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.19.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.4.output.LayerNorm.bias', 'base_model.encoder.layer.10.output.dense.bias', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.19.output.LayerNorm.weight', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.1.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.8.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.21.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.23.attention.self.value.bias', 'base_model.encoder.layer.4.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.3.intermediate.dense.weight', 'base_model.encoder.layer.13.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.20.attention.self.query.bias', 'base_model.encoder.layer.9.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.15.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.22.intermediate.dense.bias', 'base_model.encoder.layer.22.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.12.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.15.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.11.intermediate.dense.weight', 'base_model.encoder.layer.22.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.10.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.20.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.1.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.3.attention.self.value.bias', 'base_model.encoder.layer.23.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.1.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.20.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.15.attention.self.value.weight', 'base_model.encoder.layer.12.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.7.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.23.attention.output.dense.bias', 'base_model.encoder.layer.7.attention.self.value.bias', 'base_model.encoder.layer.9.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.17.output.dense.weight', 'base_model.encoder.layer.7.attention.self.key.bias', 'base_model.encoder.layer.4.output.dense.weight', 'base_model.encoder.layer.17.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.18.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.0.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.6.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.5.attention.output.dense.bias', 'base_model.encoder.layer.5.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.6.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.5.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.2.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.11.attention.self.key.weight', 'base_model.encoder.layer.17.attention.self.value.bias', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.21.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.14.attention.self.key.weight', 'base_model.encoder.layer.19.attention.self.value.bias', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.20.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.9.intermediate.dense.bias', 'base_model.encoder.layer.0.attention.output.LayerNorm.weight', 'base_model.encoder.layer.6.output.dense.weight', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.23.attention.output.LayerNorm.bias', 'base_model.encoder.layer.3.attention.self.key.weight', 'base_model.encoder.layer.17.attention.output.dense.weight', 'base_model.encoder.layer.4.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.6.output.dense.bias', 'base_model.encoder.layer.15.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.8.output.LayerNorm.bias', 'base_model.encoder.layer.14.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.21.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.14.output.dense.bias', 'base_model.encoder.layer.20.attention.self.key.weight', 'base_model.encoder.layer.3.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.19.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.12.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.2.output.LayerNorm.weight', 'base_model.encoder.layer.21.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.15.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.5.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.18.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.19.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.0.attention.self.value.weight', 'base_model.encoder.layer.8.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.22.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.15.output.LayerNorm.weight', 'base_model.encoder.layer.9.attention.self.query.weight', 'base_model.encoder.layer.18.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.18.attention.output.LayerNorm.weight', 'base_model.encoder.layer.20.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.10.attention.self.key.weight', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.8.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.21.attention.self.key.weight', 'base_model.encoder.layer.7.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.8.attention.output.dense.bias', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.22.output.LayerNorm.bias', 'base_model.encoder.layer.10.attention.self.value.bias', 'base_model.encoder.layer.22.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.7.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.8.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.10.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.9.attention.self.value.bias', 'base_model.encoder.layer.10.attention.self.query.bias', 'base_model.encoder.layer.17.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.0.attention.self.query.weight', 'base_model.encoder.layer.12.attention.output.LayerNorm.bias', 'base_model.encoder.layer.11.intermediate.dense.bias', 'base_model.encoder.layer.6.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.11.output.LayerNorm.bias', 'base_model.encoder.layer.1.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.13.attention.self.query.weight', 'base_model.encoder.layer.4.attention.output.dense.weight', 'base_model.encoder.layer.14.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.15.output.dense.bias', 'base_model.encoder.layer.2.attention.output.dense.bias', 'base_model.encoder.layer.14.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.15.output.dense.weight', 'base_model.encoder.layer.2.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.0.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.8.attention.output.LayerNorm.bias', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.1.output.LayerNorm.weight', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.14.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.13.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.2.attention.output.LayerNorm.weight', 'base_model.encoder.layer.16.attention.output.dense.bias', 'base_model.encoder.layer.3.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.0.output.LayerNorm.weight', 'base_model.encoder.layer.3.attention.output.LayerNorm.weight', 'base_model.encoder.layer.4.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.10.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.12.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.22.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.1.attention.output.dense.weight', 'base_model.encoder.layer.6.intermediate.dense.bias', 'base_model.encoder.layer.18.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.18.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.16.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.2.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.18.output.LayerNorm.bias', 'base_model.encoder.layer.8.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.8.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.4.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.0.output.LayerNorm.bias', 'base_model.encoder.layer.1.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.5.attention.self.query.weight', 'base_model.encoder.layer.9.attention.self.key.bias', 'base_model.encoder.layer.14.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.3.attention.output.dense.weight', 'base_model.encoder.layer.13.attention.self.key.weight', 'base_model.encoder.layer.17.attention.self.key.bias', 'base_model.encoder.layer.8.attention.self.query.weight', 'base_model.encoder.layer.18.attention.self.key.weight', 'base_model.encoder.layer.19.output.LayerNorm.bias', 'base_model.encoder.layer.5.attention.self.value.bias', 'base_model.encoder.layer.2.attention.self.key.weight', 'base_model.encoder.layer.22.attention.self.query.weight', 'base_model.encoder.layer.2.intermediate.dense.bias', 'base_model.encoder.layer.5.attention.self.value.weight', 'base_model.encoder.layer.14.output.dense.weight', 'base_model.encoder.layer.19.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.21.output.LayerNorm.weight', 'base_model.encoder.layer.22.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.0.attention.output.LayerNorm.bias', 'base_model.encoder.layer.8.intermediate.dense.bias', 'base_model.encoder.layer.5.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.15.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.6.attention.output.dense.weight', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.19.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.21.attention.self.value.bias', 'base_model.encoder.layer.16.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.13.attention.output.dense.bias', 'base_model.encoder.layer.22.attention.output.LayerNorm.weight', 'base_model.encoder.layer.14.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.10.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.14.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.18.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.4.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.22.intermediate.dense.weight', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.13.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.22.attention.self.key.weight', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.11.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.0.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.18.output.adapters.tp.adapter_up.bias', 'base_model.pooler.dense.bias', 'base_model.encoder.layer.17.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.12.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.16.attention.self.value.weight', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.4.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.11.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.23.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.9.output.dense.weight', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.embeddings.LayerNorm.bias', 'base_model.encoder.layer.16.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.5.intermediate.dense.bias', 'base_model.encoder.layer.9.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.11.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.22.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.7.attention.self.query.bias', 'base_model.encoder.layer.12.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.18.attention.self.value.bias', 'base_model.encoder.layer.12.attention.output.LayerNorm.weight', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.17.attention.self.key.weight', 'base_model.encoder.layer.7.attention.output.LayerNorm.bias', 'base_model.encoder.layer.2.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.9.attention.output.dense.bias', 'base_model.encoder.layer.0.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.13.intermediate.dense.bias', 'base_model.encoder.layer.15.intermediate.dense.bias', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.9.attention.output.dense.weight', 'base_model.encoder.layer.1.output.dense.weight', 'base_model.encoder.layer.9.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.14.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.4.output.LayerNorm.weight', 'base_model.encoder.layer.8.attention.self.value.weight', 'base_model.encoder.layer.19.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.13.attention.self.query.bias', 'base_model.encoder.layer.13.output.dense.bias', 'base_model.encoder.layer.8.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.13.attention.output.LayerNorm.bias', 'base_model.encoder.layer.21.output.dense.bias', 'base_model.encoder.layer.1.output.dense.bias', 'base_model.encoder.layer.1.output.LayerNorm.bias', 'base_model.encoder.layer.18.attention.self.query.bias', 'base_model.encoder.layer.14.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.22.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.9.attention.self.value.weight', 'base_model.encoder.layer.21.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.0.intermediate.dense.bias', 'base_model.encoder.layer.11.attention.self.query.weight', 'base_model.encoder.layer.6.attention.self.query.bias', 'base_model.encoder.layer.8.attention.output.LayerNorm.weight', 'base_model.encoder.layer.11.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.7.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.23.output.dense.weight', 'base_model.encoder.layer.13.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.16.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.5.attention.self.query.bias', 'base_model.encoder.layer.13.output.dense.weight', 'base_model.encoder.layer.6.attention.output.dense.bias', 'base_model.encoder.layer.9.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.14.attention.output.LayerNorm.bias', 'base_model.encoder.layer.9.output.LayerNorm.weight', 'base_model.encoder.layer.12.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.6.attention.self.value.bias', 'base_model.encoder.layer.9.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.22.attention.output.LayerNorm.bias', 'base_model.encoder.layer.12.output.dense.bias', 'base_model.encoder.layer.21.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.1.attention.self.key.bias', 'base_model.encoder.layer.0.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.8.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.13.attention.self.value.bias', 'base_model.encoder.layer.17.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.21.intermediate.dense.bias', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.16.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.7.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.18.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.7.output.dense.weight', 'base_model.encoder.layer.2.attention.self.query.bias', 'base_model.encoder.layer.20.intermediate.dense.bias', 'base_model.encoder.layer.12.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.10.attention.output.LayerNorm.bias', 'base_model.encoder.layer.9.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.11.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.11.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.20.output.dense.bias', 'base_model.encoder.layer.0.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.7.intermediate.dense.weight', 'base_model.encoder.layer.20.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.6.output.LayerNorm.bias', 'base_model.encoder.layer.9.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.23.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.11.output.adapters.ep.adapter_up.weight', 'base_model.pooler.dense.weight', 'base_model.encoder.layer.10.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.2.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.6.attention.output.LayerNorm.weight', 'base_model.encoder.layer.10.output.LayerNorm.bias', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.11.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.13.attention.self.value.weight', 'base_model.encoder.layer.17.intermediate.dense.weight', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.21.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.4.attention.output.LayerNorm.bias', 'base_model.encoder.layer.10.output.LayerNorm.weight', 'base_model.encoder.layer.20.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.18.output.LayerNorm.weight', 'base_model.encoder.layer.5.output.dense.weight', 'base_model.encoder.layer.14.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.5.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.12.attention.output.dense.weight', 'base_model.encoder.layer.1.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.18.attention.output.dense.bias', 'base_model.encoder.layer.3.output.LayerNorm.weight', 'base_model.encoder.layer.3.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.23.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.2.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.0.attention.self.value.bias', 'base_model.encoder.layer.17.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.18.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.19.output.dense.bias', 'base_model.encoder.layer.2.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.8.attention.self.value.bias', 'base_model.encoder.layer.12.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.18.attention.self.value.weight', 'base_model.encoder.layer.3.attention.self.query.bias', 'base_model.encoder.layer.20.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.23.attention.self.value.weight', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.7.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.1.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.15.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.15.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.15.attention.self.query.bias', 'base_model.encoder.layer.6.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.15.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.22.attention.self.value.bias', 'base_model.encoder.layer.5.intermediate.dense.weight', 'base_model.encoder.layer.8.output.dense.bias', 'base_model.encoder.layer.23.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.4.intermediate.dense.bias', 'base_model.encoder.layer.6.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.4.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.6.attention.self.query.weight', 'base_model.encoder.layer.11.output.dense.bias', 'base_model.encoder.layer.6.intermediate.dense.weight', 'base_model.encoder.layer.5.attention.output.LayerNorm.weight', 'base_model.encoder.layer.18.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.12.intermediate.dense.weight', 'base_model.encoder.layer.10.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.6.attention.output.LayerNorm.bias', 'base_model.encoder.layer.21.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.15.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.20.intermediate.dense.weight', 'base_model.encoder.layer.4.attention.self.query.bias', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.21.attention.self.query.weight', 'base_model.encoder.layer.1.attention.self.value.weight', 'base_model.embeddings.position_embeddings.weight', 'base_model.encoder.layer.10.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.19.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.20.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.12.output.adapters.ts.adapter_down.0.bias', 'qa_outputs.bias', 'base_model.encoder.layer.21.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.6.attention.self.key.bias', 'base_model.encoder.layer.13.output.LayerNorm.weight', 'base_model.encoder.layer.8.output.dense.weight', 'base_model.encoder.layer.12.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.20.attention.self.value.bias', 'base_model.encoder.layer.20.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.8.attention.output.dense.weight', 'base_model.encoder.layer.16.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.22.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.17.output.LayerNorm.bias', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.3.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.13.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.13.attention.self.key.bias', 'base_model.encoder.layer.19.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.21.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.1.intermediate.dense.bias', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.5.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.4.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.16.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.14.output.LayerNorm.bias', 'base_model.encoder.layer.16.attention.self.value.bias', 'base_model.encoder.layer.19.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.16.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.1.attention.self.key.weight', 'base_model.encoder.layer.10.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.20.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.9.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.17.attention.output.dense.bias', 'base_model.encoder.layer.19.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.3.intermediate.dense.bias', 'base_model.encoder.layer.18.attention.self.key.bias', 'base_model.encoder.layer.15.intermediate.dense.weight', 'base_model.encoder.layer.1.attention.self.query.weight', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.13.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.22.output.dense.weight', 'base_model.encoder.layer.3.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.5.attention.output.LayerNorm.bias', 'base_model.encoder.layer.22.output.LayerNorm.weight', 'base_model.encoder.layer.18.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.11.attention.output.dense.weight', 'base_model.encoder.layer.5.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.3.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.2.output.LayerNorm.bias', 'base_model.encoder.layer.5.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.6.output.LayerNorm.weight', 'base_model.encoder.layer.15.attention.output.LayerNorm.weight', 'base_model.encoder.layer.14.attention.output.dense.bias', 'base_model.encoder.layer.13.output.LayerNorm.bias', 'base_model.encoder.layer.13.attention.output.dense.weight', 'base_model.encoder.layer.17.output.dense.bias', 'base_model.encoder.layer.4.attention.self.key.weight', 'base_model.encoder.layer.7.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.12.attention.self.key.weight', 'base_model.encoder.layer.20.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.7.attention.self.query.weight', 'base_model.encoder.layer.8.attention.self.key.bias', 'base_model.encoder.layer.19.attention.output.dense.weight', 'base_model.encoder.layer.23.output.LayerNorm.bias', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.1.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.6.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.15.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.23.intermediate.dense.bias', 'base_model.encoder.layer.14.attention.self.query.bias', 'base_model.encoder.layer.1.attention.output.LayerNorm.weight', 'base_model.encoder.layer.13.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.16.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.20.output.LayerNorm.bias', 'base_model.encoder.layer.1.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.2.attention.output.LayerNorm.bias', 'base_model.encoder.layer.6.attention.self.value.weight', 'base_model.encoder.layer.10.attention.self.query.weight', 'base_model.encoder.layer.1.intermediate.dense.weight', 'base_model.encoder.layer.7.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.13.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.15.attention.output.LayerNorm.bias', 'base_model.encoder.layer.23.attention.output.dense.weight', 'base_model.encoder.layer.23.attention.self.key.bias', 'base_model.encoder.layer.19.attention.self.key.bias', 'base_model.encoder.layer.0.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.1.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.15.attention.self.query.weight', 'base_model.encoder.layer.17.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.4.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.2.attention.self.query.weight', 'base_model.encoder.layer.15.attention.output.dense.bias', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.22.attention.self.query.bias', 'base_model.encoder.layer.21.output.dense.weight', 'base_model.encoder.layer.12.attention.self.value.weight', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.7.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.4.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.5.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.1.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.23.output.LayerNorm.weight', 'base_model.encoder.layer.12.attention.self.value.bias', 'base_model.encoder.layer.21.attention.output.LayerNorm.bias', 'base_model.encoder.layer.6.attention.self.key.weight', 'base_model.encoder.layer.10.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.10.attention.self.key.bias', 'base_model.encoder.layer.23.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.8.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.2.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.1.attention.self.query.bias', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.9.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.16.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.10.attention.self.value.weight', 'base_model.encoder.layer.12.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.4.attention.self.key.bias', 'base_model.encoder.layer.12.intermediate.dense.bias', 'base_model.encoder.layer.2.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.11.attention.self.value.bias', 'base_model.encoder.layer.18.output.dense.bias', 'base_model.encoder.layer.10.attention.output.dense.weight', 'base_model.encoder.layer.7.output.LayerNorm.weight', 'base_model.encoder.layer.5.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.21.attention.output.LayerNorm.weight', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.9.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.22.output.dense.bias', 'base_model.encoder.layer.23.intermediate.dense.weight', 'base_model.encoder.layer.19.attention.self.query.bias', 'base_model.embeddings.position_ids', 'base_model.encoder.layer.3.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.11.output.dense.weight', 'base_model.encoder.layer.4.attention.self.value.bias', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.16.output.dense.weight', 'base_model.encoder.layer.2.output.dense.weight', 'base_model.encoder.layer.19.intermediate.dense.bias', 'base_model.encoder.layer.20.attention.self.query.weight', 'base_model.encoder.layer.23.attention.self.query.weight', 'base_model.encoder.layer.11.attention.self.key.bias', 'base_model.encoder.layer.16.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.2.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.4.intermediate.dense.weight', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.17.attention.output.LayerNorm.bias', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.2.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.9.output.LayerNorm.bias', 'base_model.encoder.layer.22.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.16.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.15.attention.self.key.weight', 'base_model.encoder.layer.7.intermediate.dense.bias', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.14.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.14.attention.output.LayerNorm.weight', 'base_model.encoder.layer.9.intermediate.dense.weight', 'base_model.encoder.layer.5.output.adapters.tp.adapter_up.bias']
- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of XLMRobertaModel were not initialized from the model checkpoint at /cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//squad/xlm-KG_LR3e-5_EPOCH2.0_maxlen384_batchsize4_gradacc4 and are newly initialized: ['encoder.layer.10.attention.self.value.weight', 'encoder.layer.7.attention.output.dense.bias', 'encoder.layer.9.attention.self.key.weight', 'encoder.layer.20.attention.output.LayerNorm.bias', 'encoder.layer.22.attention.self.query.weight', 'encoder.layer.18.attention.self.value.weight', 'encoder.layer.23.attention.output.dense.weight', 'encoder.layer.11.attention.output.dense.weight', 'encoder.layer.11.attention.self.key.weight', 'encoder.layer.2.attention.self.query.weight', 'encoder.layer.2.attention.self.query.bias', 'encoder.layer.11.attention.self.key.bias', 'encoder.layer.7.output.dense.weight', 'encoder.layer.1.attention.output.LayerNorm.weight', 'encoder.layer.5.attention.self.query.bias', 'encoder.layer.8.output.LayerNorm.bias', 'encoder.layer.15.attention.output.LayerNorm.bias', 'encoder.layer.4.attention.self.key.bias', 'encoder.layer.0.attention.self.query.weight', 'encoder.layer.22.attention.output.dense.bias', 'encoder.layer.5.attention.self.value.weight', 'encoder.layer.22.attention.output.LayerNorm.weight', 'encoder.layer.20.attention.output.dense.bias', 'encoder.layer.19.attention.output.dense.weight', 'encoder.layer.21.attention.self.value.bias', 'encoder.layer.0.attention.output.dense.bias', 'encoder.layer.7.output.dense.bias', 'encoder.layer.10.output.dense.bias', 'encoder.layer.14.output.dense.bias', 'encoder.layer.14.attention.self.value.weight', 'encoder.layer.11.output.LayerNorm.bias', 'encoder.layer.0.attention.output.dense.weight', 'encoder.layer.2.output.LayerNorm.bias', 'embeddings.LayerNorm.weight', 'encoder.layer.13.output.dense.bias', 'encoder.layer.15.output.LayerNorm.bias', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.9.attention.self.query.bias', 'encoder.layer.9.attention.self.value.weight', 'encoder.layer.4.attention.self.key.weight', 'encoder.layer.10.output.LayerNorm.weight', 'encoder.layer.2.output.dense.bias', 'encoder.layer.11.attention.self.query.bias', 'encoder.layer.21.output.LayerNorm.weight', 'encoder.layer.16.attention.self.key.bias', 'encoder.layer.22.attention.self.key.bias', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.3.attention.self.key.weight', 'encoder.layer.1.attention.self.key.bias', 'encoder.layer.12.output.dense.bias', 'encoder.layer.22.output.dense.bias', 'encoder.layer.22.output.dense.weight', 'encoder.layer.9.attention.self.key.bias', 'encoder.layer.13.attention.output.LayerNorm.weight', 'encoder.layer.22.output.LayerNorm.weight', 'encoder.layer.19.intermediate.dense.bias', 'encoder.layer.22.attention.self.query.bias', 'encoder.layer.10.attention.self.query.weight', 'encoder.layer.4.attention.output.dense.bias', 'encoder.layer.22.attention.output.dense.weight', 'encoder.layer.2.attention.output.dense.weight', 'encoder.layer.21.attention.output.dense.weight', 'encoder.layer.11.output.dense.weight', 'encoder.layer.21.attention.self.key.bias', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.9.attention.self.value.bias', 'encoder.layer.20.output.dense.bias', 'encoder.layer.0.attention.self.value.weight', 'encoder.layer.6.attention.self.query.bias', 'encoder.layer.16.output.dense.weight', 'encoder.layer.15.attention.output.LayerNorm.weight', 'encoder.layer.3.attention.self.query.bias', 'encoder.layer.16.output.dense.bias', 'encoder.layer.19.attention.self.key.weight', 'encoder.layer.1.attention.output.dense.weight', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.16.intermediate.dense.weight', 'encoder.layer.20.attention.self.value.bias', 'encoder.layer.17.output.LayerNorm.weight', 'encoder.layer.13.attention.self.value.weight', 'encoder.layer.13.attention.output.dense.bias', 'encoder.layer.3.output.dense.bias', 'encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.10.attention.output.dense.bias', 'encoder.layer.0.output.dense.weight', 'encoder.layer.7.output.LayerNorm.bias', 'encoder.layer.2.attention.self.key.bias', 'encoder.layer.23.output.LayerNorm.bias', 'encoder.layer.16.intermediate.dense.bias', 'encoder.layer.0.attention.self.key.bias', 'encoder.layer.5.attention.output.dense.bias', 'encoder.layer.12.output.LayerNorm.bias', 'encoder.layer.3.attention.self.query.weight', 'encoder.layer.7.attention.self.key.bias', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.18.attention.output.LayerNorm.bias', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.21.attention.self.query.weight', 'encoder.layer.9.attention.output.dense.bias', 'encoder.layer.10.attention.self.query.bias', 'encoder.layer.14.intermediate.dense.weight', 'encoder.layer.16.attention.self.key.weight', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.7.attention.self.key.weight', 'encoder.layer.9.attention.self.query.weight', 'encoder.layer.12.attention.output.dense.bias', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.5.output.dense.weight', 'encoder.layer.16.output.LayerNorm.bias', 'encoder.layer.18.attention.output.dense.bias', 'encoder.layer.19.intermediate.dense.weight', 'encoder.layer.14.output.dense.weight', 'encoder.layer.21.attention.self.key.weight', 'encoder.layer.19.attention.self.value.bias', 'encoder.layer.14.attention.output.LayerNorm.bias', 'encoder.layer.9.attention.output.LayerNorm.bias', 'encoder.layer.16.output.LayerNorm.weight', 'encoder.layer.14.attention.output.LayerNorm.weight', 'encoder.layer.9.output.LayerNorm.weight', 'encoder.layer.13.intermediate.dense.bias', 'encoder.layer.1.attention.self.value.weight', 'encoder.layer.10.output.dense.weight', 'encoder.layer.16.attention.output.LayerNorm.bias', 'encoder.layer.16.attention.output.dense.weight', 'encoder.layer.9.output.LayerNorm.bias', 'encoder.layer.18.attention.self.key.weight', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.15.output.LayerNorm.weight', 'encoder.layer.12.output.LayerNorm.weight', 'encoder.layer.18.attention.output.dense.weight', 'encoder.layer.23.attention.self.key.weight', 'encoder.layer.12.intermediate.dense.bias', 'encoder.layer.8.attention.self.query.weight', 'encoder.layer.1.attention.output.dense.bias', 'encoder.layer.19.attention.self.key.bias', 'encoder.layer.1.attention.self.value.bias', 'encoder.layer.21.attention.output.LayerNorm.weight', 'encoder.layer.3.output.dense.weight', 'encoder.layer.7.attention.self.value.weight', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.18.attention.self.key.bias', 'encoder.layer.6.output.LayerNorm.bias', 'encoder.layer.8.output.LayerNorm.weight', 'encoder.layer.0.attention.self.key.weight', 'encoder.layer.7.output.LayerNorm.weight', 'encoder.layer.22.intermediate.dense.weight', 'encoder.layer.15.intermediate.dense.bias', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.6.attention.output.LayerNorm.bias', 'encoder.layer.4.attention.output.LayerNorm.bias', 'encoder.layer.1.output.dense.weight', 'encoder.layer.18.attention.output.LayerNorm.weight', 'encoder.layer.1.attention.self.query.weight', 'encoder.layer.6.attention.self.value.weight', 'embeddings.position_embeddings.weight', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.23.output.LayerNorm.weight', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.14.attention.self.key.bias', 'encoder.layer.4.output.dense.bias', 'encoder.layer.18.attention.self.query.bias', 'encoder.layer.13.intermediate.dense.weight', 'encoder.layer.7.attention.self.query.weight', 'encoder.layer.14.attention.self.query.bias', 'encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.layer.18.intermediate.dense.bias', 'encoder.layer.1.attention.self.key.weight', 'encoder.layer.19.attention.self.query.bias', 'encoder.layer.15.output.dense.bias', 'encoder.layer.23.attention.self.key.bias', 'encoder.layer.4.output.dense.weight', 'encoder.layer.17.attention.self.key.bias', 'encoder.layer.3.attention.self.value.bias', 'encoder.layer.6.attention.self.query.weight', 'encoder.layer.12.attention.self.query.weight', 'encoder.layer.2.output.dense.weight', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.21.attention.self.value.weight', 'encoder.layer.20.output.LayerNorm.bias', 'encoder.layer.17.attention.self.query.bias', 'encoder.layer.12.attention.self.key.weight', 'encoder.layer.13.attention.self.key.weight', 'encoder.layer.15.attention.output.dense.bias', 'encoder.layer.17.intermediate.dense.weight', 'encoder.layer.8.attention.output.dense.weight', 'encoder.layer.20.attention.self.key.bias', 'encoder.layer.14.output.LayerNorm.bias', 'encoder.layer.10.attention.output.LayerNorm.weight', 'encoder.layer.20.attention.output.dense.weight', 'encoder.layer.16.attention.self.value.weight', 'encoder.layer.23.attention.self.value.weight', 'encoder.layer.8.attention.output.LayerNorm.bias', 'encoder.layer.14.attention.output.dense.weight', 'encoder.layer.14.attention.output.dense.bias', 'encoder.layer.1.output.dense.bias', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.12.attention.self.query.bias', 'encoder.layer.15.attention.output.dense.weight', 'encoder.layer.4.attention.output.LayerNorm.weight', 'encoder.layer.19.output.LayerNorm.bias', 'encoder.layer.4.attention.self.query.bias', 'encoder.layer.10.intermediate.dense.weight', 'encoder.layer.4.attention.self.value.weight', 'encoder.layer.8.output.dense.weight', 'encoder.layer.11.output.dense.bias', 'encoder.layer.20.output.LayerNorm.weight', 'encoder.layer.7.attention.output.LayerNorm.bias', 'encoder.layer.13.attention.output.dense.weight', 'encoder.layer.17.attention.output.LayerNorm.weight', 'encoder.layer.12.attention.self.value.bias', 'encoder.layer.7.attention.output.dense.weight', 'encoder.layer.4.attention.output.dense.weight', 'encoder.layer.9.attention.output.LayerNorm.weight', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.23.output.dense.weight', 'encoder.layer.5.attention.self.key.bias', 'encoder.layer.12.attention.self.value.weight', 'encoder.layer.11.attention.self.value.weight', 'encoder.layer.23.intermediate.dense.weight', 'encoder.layer.18.intermediate.dense.weight', 'encoder.layer.0.attention.output.LayerNorm.weight', 'encoder.layer.8.attention.output.dense.bias', 'encoder.layer.12.attention.self.key.bias', 'encoder.layer.18.output.dense.bias', 'encoder.layer.20.attention.output.LayerNorm.weight', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.23.attention.self.query.bias', 'encoder.layer.21.output.dense.weight', 'encoder.layer.13.output.LayerNorm.weight', 'encoder.layer.14.intermediate.dense.bias', 'encoder.layer.19.attention.self.query.weight', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.22.attention.self.value.weight', 'encoder.layer.15.attention.self.value.bias', 'encoder.layer.8.output.dense.bias', 'encoder.layer.20.attention.self.query.bias', 'encoder.layer.6.attention.self.value.bias', 'encoder.layer.10.attention.self.key.bias', 'pooler.dense.bias', 'encoder.layer.7.attention.output.LayerNorm.weight', 'encoder.layer.21.attention.self.query.bias', 'encoder.layer.6.attention.output.LayerNorm.weight', 'encoder.layer.23.attention.output.dense.bias', 'encoder.layer.2.attention.output.dense.bias', 'encoder.layer.23.attention.output.LayerNorm.weight', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.5.attention.output.dense.weight', 'encoder.layer.18.output.LayerNorm.bias', 'encoder.layer.16.attention.self.query.bias', 'encoder.layer.3.attention.self.value.weight', 'encoder.layer.10.attention.self.key.weight', 'encoder.layer.17.output.LayerNorm.bias', 'encoder.layer.8.attention.self.key.weight', 'encoder.layer.8.attention.self.query.bias', 'encoder.layer.23.intermediate.dense.bias', 'encoder.layer.20.intermediate.dense.weight', 'encoder.layer.12.attention.output.LayerNorm.weight', 'encoder.layer.8.attention.output.LayerNorm.weight', 'embeddings.token_type_embeddings.weight', 'encoder.layer.17.attention.self.value.bias', 'encoder.layer.2.attention.self.value.weight', 'encoder.layer.22.attention.output.LayerNorm.bias', 'encoder.layer.13.output.dense.weight', 'embeddings.word_embeddings.weight', 'encoder.layer.18.attention.self.query.weight', 'encoder.layer.15.attention.self.key.bias', 'encoder.layer.6.attention.output.dense.bias', 'encoder.layer.19.output.dense.bias', 'encoder.layer.9.output.dense.weight', 'encoder.layer.9.output.dense.bias', 'encoder.layer.11.attention.self.value.bias', 'encoder.layer.20.attention.self.query.weight', 'encoder.layer.23.output.dense.bias', 'encoder.layer.21.output.dense.bias', 'encoder.layer.14.attention.self.value.bias', 'encoder.layer.4.attention.self.value.bias', 'encoder.layer.18.output.LayerNorm.weight', 'encoder.layer.19.attention.output.LayerNorm.weight', 'encoder.layer.11.output.LayerNorm.weight', 'encoder.layer.23.attention.output.LayerNorm.bias', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.17.output.dense.bias', 'encoder.layer.12.attention.output.dense.weight', 'encoder.layer.10.output.LayerNorm.bias', 'encoder.layer.17.attention.output.dense.weight', 'encoder.layer.3.attention.self.key.bias', 'encoder.layer.0.attention.self.value.bias', 'encoder.layer.17.attention.self.value.weight', 'encoder.layer.7.attention.self.value.bias', 'encoder.layer.2.attention.self.key.weight', 'embeddings.LayerNorm.bias', 'encoder.layer.10.attention.output.LayerNorm.bias', 'encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.layer.4.attention.self.query.weight', 'encoder.layer.20.output.dense.weight', 'encoder.layer.17.attention.self.key.weight', 'encoder.layer.21.output.LayerNorm.bias', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.22.intermediate.dense.bias', 'encoder.layer.17.attention.output.LayerNorm.bias', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.23.attention.self.query.weight', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.layer.10.attention.self.value.bias', 'encoder.layer.20.attention.self.key.weight', 'encoder.layer.21.attention.output.dense.bias', 'encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.layer.18.attention.self.value.bias', 'encoder.layer.20.attention.self.value.weight', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.16.attention.output.LayerNorm.weight', 'encoder.layer.12.attention.output.LayerNorm.bias', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.14.attention.self.query.weight', 'encoder.layer.7.intermediate.dense.bias', 'encoder.layer.10.attention.output.dense.weight', 'encoder.layer.5.attention.self.value.bias', 'encoder.layer.11.attention.self.query.weight', 'encoder.layer.22.output.LayerNorm.bias', 'encoder.layer.17.attention.self.query.weight', 'encoder.layer.15.intermediate.dense.weight', 'encoder.layer.6.output.dense.weight', 'encoder.layer.13.attention.self.query.bias', 'encoder.layer.3.attention.output.dense.weight', 'encoder.layer.5.attention.self.query.weight', 'encoder.layer.5.output.LayerNorm.bias', 'encoder.layer.3.attention.output.dense.bias', 'encoder.layer.22.attention.self.value.bias', 'encoder.layer.22.attention.self.key.weight', 'encoder.layer.1.attention.self.query.bias', 'encoder.layer.19.attention.self.value.weight', 'encoder.layer.21.attention.output.LayerNorm.bias', 'encoder.layer.0.attention.self.query.bias', 'encoder.layer.14.output.LayerNorm.weight', 'encoder.layer.19.attention.output.LayerNorm.bias', 'encoder.layer.12.output.dense.weight', 'encoder.layer.15.attention.self.query.weight', 'encoder.layer.13.output.LayerNorm.bias', 'encoder.layer.15.attention.self.value.weight', 'encoder.layer.8.attention.self.value.bias', 'encoder.layer.19.output.dense.weight', 'encoder.layer.21.intermediate.dense.weight', 'encoder.layer.13.attention.output.LayerNorm.bias', 'encoder.layer.17.intermediate.dense.bias', 'encoder.layer.14.attention.self.key.weight', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.21.intermediate.dense.bias', 'encoder.layer.16.attention.output.dense.bias', 'encoder.layer.9.attention.output.dense.weight', 'encoder.layer.15.output.dense.weight', 'encoder.layer.2.attention.self.value.bias', 'encoder.layer.15.attention.self.key.weight', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.18.output.dense.weight', 'encoder.layer.11.attention.output.LayerNorm.weight', 'encoder.layer.17.output.dense.weight', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.11.attention.output.dense.bias', 'encoder.layer.2.attention.output.LayerNorm.weight', 'encoder.layer.20.intermediate.dense.bias', 'encoder.layer.16.attention.self.query.weight', 'encoder.layer.6.output.dense.bias', 'encoder.layer.0.output.dense.bias', 'encoder.layer.2.attention.output.LayerNorm.bias', 'encoder.layer.15.attention.self.query.bias', 'encoder.layer.23.attention.self.value.bias', 'encoder.layer.5.output.dense.bias', 'encoder.layer.13.attention.self.query.weight', 'encoder.layer.12.intermediate.dense.weight', 'encoder.layer.6.attention.output.dense.weight', 'encoder.layer.17.attention.output.dense.bias', 'encoder.layer.5.attention.self.key.weight', 'encoder.layer.6.attention.self.key.weight', 'encoder.layer.13.attention.self.value.bias', 'pooler.dense.weight', 'encoder.layer.6.attention.self.key.bias', 'encoder.layer.8.attention.self.key.bias', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.5.attention.output.LayerNorm.weight', 'encoder.layer.8.attention.self.value.weight', 'encoder.layer.19.output.LayerNorm.weight', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.19.attention.output.dense.bias', 'encoder.layer.7.attention.self.query.bias', 'encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.16.attention.self.value.bias', 'encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.layer.13.attention.self.key.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Overwriting existing adapter 'ep'.
Overwriting existing adapter 'tp'.
Overwriting existing adapter 'es'.
Overwriting existing adapter 'ts'.
Overwriting existing adapter fusion module 'ep,tp,es,ts'
05/09/2022 09:01:41 - INFO - __main__ -   Creating features from dataset file at .
/cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//squad/xlm-KG_LR3e-5_EPOCH2.0_maxlen384_batchsize4_gradacc4
XLMConfig {
  "architectures": [
    "XLMRobertaForMaskedLM"
  ],
  "asm": false,
  "attention_dropout": 0.1,
  "attention_probs_dropout_prob": 0.1,
  "bos_index": 0,
  "bos_token_id": 0,
  "causal": false,
  "dropout": 0.1,
  "emb_dim": 1024,
  "embed_init_std": 0.02209708691207961,
  "end_n_top": 5,
  "eos_index": 1,
  "eos_token_id": 2,
  "gelu_activation": true,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "init_std": 0.02,
  "initializer_range": 0.02,
  "intermediate_size": 4096,
  "is_encoder": true,
  "lang_id": 0,
  "layer_norm_eps": 1e-05,
  "mask_index": 5,
  "mask_token_id": 0,
  "max_position_embeddings": 514,
  "model_type": "xlm",
  "n_heads": 16,
  "n_langs": 1,
  "n_layers": 24,
  "output_past": true,
  "pad_index": 2,
  "pad_token_id": 1,
  "sinusoidal_embeddings": false,
  "start_n_top": 5,
  "summary_activation": null,
  "summary_first_dropout": 0.1,
  "summary_proj_to_labels": true,
  "summary_type": "first",
  "summary_use_proj": true,
  "transformers_version": "4.17.0",
  "type_vocab_size": 1,
  "unk_index": 3,
  "use_lang_emb": false,
  "vocab_size": 250002
}

  0%|          | 0/48 [00:00<?, ?it/s] 15%|█▍        | 7/48 [00:00<00:00, 66.97it/s] 33%|███▎      | 16/48 [00:00<00:00, 62.61it/s] 48%|████▊     | 23/48 [00:00<00:00, 60.32it/s] 62%|██████▎   | 30/48 [00:00<00:00, 60.99it/s] 77%|███████▋  | 37/48 [00:00<00:00, 59.32it/s] 94%|█████████▍| 45/48 [00:00<00:00, 64.41it/s]100%|██████████| 48/48 [00:00<00:00, 64.11it/s]
convert squad examples to features:   0%|          | 0/1190 [00:00<?, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.
convert squad examples to features:   0%|          | 1/1190 [00:00<04:22,  4.53it/s]convert squad examples to features:   3%|▎         | 33/1190 [00:00<00:10, 106.09it/s]convert squad examples to features:   5%|▌         | 65/1190 [00:00<00:09, 123.57it/s]convert squad examples to features:   8%|▊         | 97/1190 [00:00<00:07, 139.98it/s]convert squad examples to features:  11%|█         | 129/1190 [00:00<00:06, 169.11it/s]convert squad examples to features:  14%|█▎        | 161/1190 [00:01<00:05, 189.60it/s]convert squad examples to features:  16%|█▌        | 193/1190 [00:01<00:05, 198.12it/s]convert squad examples to features:  19%|█▉        | 225/1190 [00:01<00:05, 192.69it/s]convert squad examples to features:  22%|██▏       | 257/1190 [00:01<00:04, 213.89it/s]convert squad examples to features:  24%|██▍       | 289/1190 [00:01<00:04, 196.39it/s]convert squad examples to features:  27%|██▋       | 321/1190 [00:01<00:04, 190.16it/s]convert squad examples to features:  30%|██▉       | 353/1190 [00:02<00:04, 188.92it/s]convert squad examples to features:  32%|███▏      | 385/1190 [00:02<00:08, 93.25it/s] convert squad examples to features:  35%|███▌      | 417/1190 [00:02<00:07, 108.37it/s]convert squad examples to features:  38%|███▊      | 449/1190 [00:03<00:06, 120.57it/s]convert squad examples to features:  40%|████      | 481/1190 [00:03<00:05, 130.35it/s]convert squad examples to features:  43%|████▎     | 513/1190 [00:03<00:05, 134.60it/s]convert squad examples to features:  46%|████▌     | 545/1190 [00:03<00:04, 131.25it/s]convert squad examples to features:  48%|████▊     | 577/1190 [00:04<00:04, 133.58it/s]convert squad examples to features:  51%|█████     | 609/1190 [00:04<00:04, 144.74it/s]convert squad examples to features:  54%|█████▍    | 641/1190 [00:04<00:03, 146.97it/s]convert squad examples to features:  57%|█████▋    | 673/1190 [00:04<00:03, 130.68it/s]convert squad examples to features:  59%|█████▉    | 705/1190 [00:04<00:03, 145.26it/s]convert squad examples to features:  62%|██████▏   | 737/1190 [00:05<00:02, 152.91it/s]convert squad examples to features:  65%|██████▍   | 769/1190 [00:05<00:02, 157.16it/s]convert squad examples to features:  67%|██████▋   | 801/1190 [00:05<00:02, 174.79it/s]convert squad examples to features:  70%|███████   | 833/1190 [00:05<00:02, 154.96it/s]convert squad examples to features:  73%|███████▎  | 865/1190 [00:05<00:02, 151.05it/s]convert squad examples to features:  75%|███████▌  | 897/1190 [00:06<00:02, 135.68it/s]convert squad examples to features:  78%|███████▊  | 929/1190 [00:06<00:01, 135.13it/s]convert squad examples to features:  81%|████████  | 961/1190 [00:06<00:01, 147.04it/s]convert squad examples to features:  83%|████████▎ | 993/1190 [00:06<00:01, 153.67it/s]convert squad examples to features:  86%|████████▌ | 1025/1190 [00:06<00:01, 164.63it/s]convert squad examples to features:  89%|████████▉ | 1057/1190 [00:07<00:00, 177.40it/s]convert squad examples to features:  92%|█████████▏| 1089/1190 [00:07<00:00, 196.56it/s]convert squad examples to features:  94%|█████████▍| 1121/1190 [00:07<00:00, 190.87it/s]convert squad examples to features:  97%|█████████▋| 1153/1190 [00:07<00:00, 171.58it/s]convert squad examples to features: 100%|██████████| 1190/1190 [00:07<00:00, 155.23it/s]
add example index and unique id:   0%|          | 0/1190 [00:00<?, ?it/s]add example index and unique id: 100%|██████████| 1190/1190 [00:00<00:00, 406219.72it/s]
05/09/2022 09:01:49 - INFO - __main__ -   Saving features into cached file ./cached_xquad.de.json_xlm-KG_LR3e-5_EPOCH2.0_maxlen384_batchsize4_gradacc4_384_de
05/09/2022 09:01:51 - INFO - __main__ -   ***** Running evaluation  *****
05/09/2022 09:01:51 - INFO - __main__ -     Num examples = 1303
05/09/2022 09:01:51 - INFO - __main__ -     Batch size = 8
Evaluating:   0%|          | 0/163 [00:00<?, ?it/s]Evaluating:   1%|          | 1/163 [00:00<02:37,  1.03it/s]Evaluating:   1%|          | 2/163 [00:01<01:36,  1.66it/s]Evaluating:   2%|▏         | 3/163 [00:01<01:17,  2.07it/s]Evaluating:   2%|▏         | 4/163 [00:01<01:08,  2.34it/s]Evaluating:   3%|▎         | 5/163 [00:02<01:02,  2.52it/s]Evaluating:   4%|▎         | 6/163 [00:02<00:59,  2.65it/s]Evaluating:   4%|▍         | 7/163 [00:03<00:57,  2.73it/s]Evaluating:   5%|▍         | 8/163 [00:03<00:55,  2.78it/s]Evaluating:   6%|▌         | 9/163 [00:03<00:54,  2.81it/s]Evaluating:   6%|▌         | 10/163 [00:04<00:53,  2.84it/s]Evaluating:   7%|▋         | 11/163 [00:04<00:53,  2.86it/s]Evaluating:   7%|▋         | 12/163 [00:04<00:52,  2.88it/s]Evaluating:   8%|▊         | 13/163 [00:05<00:51,  2.89it/s]Evaluating:   9%|▊         | 14/163 [00:05<00:51,  2.90it/s]Evaluating:   9%|▉         | 15/163 [00:05<00:50,  2.91it/s]Evaluating:  10%|▉         | 16/163 [00:06<00:50,  2.91it/s]Evaluating:  10%|█         | 17/163 [00:06<00:50,  2.92it/s]Evaluating:  11%|█         | 18/163 [00:06<00:49,  2.92it/s]Evaluating:  12%|█▏        | 19/163 [00:07<00:49,  2.91it/s]Evaluating:  12%|█▏        | 20/163 [00:07<00:49,  2.91it/s]Evaluating:  13%|█▎        | 21/163 [00:07<00:48,  2.91it/s]Evaluating:  13%|█▎        | 22/163 [00:08<00:48,  2.91it/s]Evaluating:  14%|█▍        | 23/163 [00:08<00:48,  2.90it/s]Evaluating:  15%|█▍        | 24/163 [00:08<00:47,  2.91it/s]Evaluating:  15%|█▌        | 25/163 [00:09<00:47,  2.90it/s]Evaluating:  16%|█▌        | 26/163 [00:09<00:47,  2.91it/s]Evaluating:  17%|█▋        | 27/163 [00:09<00:46,  2.91it/s]Evaluating:  17%|█▋        | 28/163 [00:10<00:46,  2.91it/s]Evaluating:  18%|█▊        | 29/163 [00:10<00:46,  2.91it/s]Evaluating:  18%|█▊        | 30/163 [00:10<00:45,  2.92it/s]Evaluating:  19%|█▉        | 31/163 [00:11<00:45,  2.92it/s]Evaluating:  20%|█▉        | 32/163 [00:11<00:44,  2.92it/s]Evaluating:  20%|██        | 33/163 [00:11<00:44,  2.92it/s]Evaluating:  21%|██        | 34/163 [00:12<00:44,  2.92it/s]Evaluating:  21%|██▏       | 35/163 [00:12<00:43,  2.92it/s]Evaluating:  22%|██▏       | 36/163 [00:12<00:43,  2.92it/s]Evaluating:  23%|██▎       | 37/163 [00:13<00:43,  2.92it/s]Evaluating:  23%|██▎       | 38/163 [00:13<00:42,  2.92it/s]Evaluating:  24%|██▍       | 39/163 [00:14<00:42,  2.91it/s]Evaluating:  25%|██▍       | 40/163 [00:14<00:42,  2.91it/s]Evaluating:  25%|██▌       | 41/163 [00:14<00:41,  2.92it/s]Evaluating:  26%|██▌       | 42/163 [00:15<00:41,  2.92it/s]Evaluating:  26%|██▋       | 43/163 [00:15<00:41,  2.92it/s]Evaluating:  27%|██▋       | 44/163 [00:15<00:40,  2.91it/s]Evaluating:  28%|██▊       | 45/163 [00:16<00:40,  2.90it/s]Evaluating:  28%|██▊       | 46/163 [00:16<00:40,  2.90it/s]Evaluating:  29%|██▉       | 47/163 [00:16<00:39,  2.91it/s]Evaluating:  29%|██▉       | 48/163 [00:17<00:39,  2.91it/s]Evaluating:  30%|███       | 49/163 [00:17<00:39,  2.91it/s]Evaluating:  31%|███       | 50/163 [00:17<00:38,  2.91it/s]Evaluating:  31%|███▏      | 51/163 [00:18<00:38,  2.90it/s]Evaluating:  32%|███▏      | 52/163 [00:18<00:38,  2.89it/s]Evaluating:  33%|███▎      | 53/163 [00:18<00:38,  2.88it/s]Evaluating:  33%|███▎      | 54/163 [00:19<00:37,  2.88it/s]Evaluating:  34%|███▎      | 55/163 [00:19<00:37,  2.86it/s]Evaluating:  34%|███▍      | 56/163 [00:19<00:37,  2.87it/s]Evaluating:  35%|███▍      | 57/163 [00:20<00:36,  2.88it/s]Evaluating:  36%|███▌      | 58/163 [00:20<00:36,  2.87it/s]Evaluating:  36%|███▌      | 59/163 [00:20<00:36,  2.87it/s]Evaluating:  37%|███▋      | 60/163 [00:21<00:35,  2.88it/s]Evaluating:  37%|███▋      | 61/163 [00:21<00:35,  2.89it/s]Evaluating:  38%|███▊      | 62/163 [00:21<00:34,  2.89it/s]Evaluating:  39%|███▊      | 63/163 [00:22<00:34,  2.90it/s]Evaluating:  39%|███▉      | 64/163 [00:22<00:34,  2.91it/s]Evaluating:  40%|███▉      | 65/163 [00:22<00:33,  2.92it/s]Evaluating:  40%|████      | 66/163 [00:23<00:33,  2.91it/s]Evaluating:  41%|████      | 67/163 [00:23<00:33,  2.90it/s]Evaluating:  42%|████▏     | 68/163 [00:24<00:32,  2.89it/s]Evaluating:  42%|████▏     | 69/163 [00:24<00:32,  2.89it/s]Evaluating:  43%|████▎     | 70/163 [00:24<00:32,  2.89it/s]Evaluating:  44%|████▎     | 71/163 [00:25<00:31,  2.90it/s]Evaluating:  44%|████▍     | 72/163 [00:25<00:31,  2.91it/s]Evaluating:  45%|████▍     | 73/163 [00:25<00:31,  2.90it/s]Evaluating:  45%|████▌     | 74/163 [00:26<00:30,  2.91it/s]Evaluating:  46%|████▌     | 75/163 [00:26<00:30,  2.91it/s]Evaluating:  47%|████▋     | 76/163 [00:26<00:29,  2.92it/s]Evaluating:  47%|████▋     | 77/163 [00:27<00:29,  2.91it/s]Evaluating:  48%|████▊     | 78/163 [00:27<00:29,  2.90it/s]Evaluating:  48%|████▊     | 79/163 [00:27<00:29,  2.89it/s]Evaluating:  49%|████▉     | 80/163 [00:28<00:28,  2.89it/s]Evaluating:  50%|████▉     | 81/163 [00:28<00:28,  2.90it/s]Evaluating:  50%|█████     | 82/163 [00:28<00:27,  2.91it/s]Evaluating:  51%|█████     | 83/163 [00:29<00:27,  2.91it/s]Evaluating:  52%|█████▏    | 84/163 [00:29<00:27,  2.91it/s]Evaluating:  52%|█████▏    | 85/163 [00:29<00:26,  2.91it/s]Evaluating:  53%|█████▎    | 86/163 [00:30<00:26,  2.91it/s]Evaluating:  53%|█████▎    | 87/163 [00:30<00:26,  2.89it/s]Evaluating:  54%|█████▍    | 88/163 [00:30<00:25,  2.90it/s]Evaluating:  55%|█████▍    | 89/163 [00:31<00:25,  2.90it/s]Evaluating:  55%|█████▌    | 90/163 [00:31<00:25,  2.90it/s]Evaluating:  56%|█████▌    | 91/163 [00:31<00:24,  2.90it/s]Evaluating:  56%|█████▋    | 92/163 [00:32<00:24,  2.91it/s]Evaluating:  57%|█████▋    | 93/163 [00:32<00:24,  2.91it/s]Evaluating:  58%|█████▊    | 94/163 [00:32<00:23,  2.91it/s]Evaluating:  58%|█████▊    | 95/163 [00:33<00:23,  2.90it/s]Evaluating:  59%|█████▉    | 96/163 [00:33<00:23,  2.90it/s]Evaluating:  60%|█████▉    | 97/163 [00:34<00:22,  2.91it/s]Evaluating:  60%|██████    | 98/163 [00:34<00:22,  2.91it/s]Evaluating:  61%|██████    | 99/163 [00:34<00:21,  2.91it/s]Evaluating:  61%|██████▏   | 100/163 [00:35<00:21,  2.91it/s]Evaluating:  62%|██████▏   | 101/163 [00:35<00:21,  2.91it/s]Evaluating:  63%|██████▎   | 102/163 [00:35<00:21,  2.90it/s]Evaluating:  63%|██████▎   | 103/163 [00:36<00:20,  2.91it/s]Evaluating:  64%|██████▍   | 104/163 [00:36<00:20,  2.91it/s]Evaluating:  64%|██████▍   | 105/163 [00:36<00:19,  2.91it/s]Evaluating:  65%|██████▌   | 106/163 [00:37<00:19,  2.91it/s]Evaluating:  66%|██████▌   | 107/163 [00:37<00:19,  2.91it/s]Evaluating:  66%|██████▋   | 108/163 [00:37<00:18,  2.91it/s]Evaluating:  67%|██████▋   | 109/163 [00:38<00:18,  2.92it/s]Evaluating:  67%|██████▋   | 110/163 [00:38<00:18,  2.91it/s]Evaluating:  68%|██████▊   | 111/163 [00:38<00:17,  2.91it/s]Evaluating:  69%|██████▊   | 112/163 [00:39<00:17,  2.92it/s]Evaluating:  69%|██████▉   | 113/163 [00:39<00:17,  2.91it/s]Evaluating:  70%|██████▉   | 114/163 [00:39<00:16,  2.91it/s]Evaluating:  71%|███████   | 115/163 [00:40<00:16,  2.90it/s]Evaluating:  71%|███████   | 116/163 [00:40<00:16,  2.90it/s]Evaluating:  72%|███████▏  | 117/163 [00:40<00:15,  2.90it/s]Evaluating:  72%|███████▏  | 118/163 [00:41<00:15,  2.91it/s]Evaluating:  73%|███████▎  | 119/163 [00:41<00:15,  2.90it/s]Evaluating:  74%|███████▎  | 120/163 [00:41<00:14,  2.91it/s]Evaluating:  74%|███████▍  | 121/163 [00:42<00:14,  2.90it/s]Evaluating:  75%|███████▍  | 122/163 [00:42<00:14,  2.90it/s]Evaluating:  75%|███████▌  | 123/163 [00:42<00:13,  2.90it/s]Evaluating:  76%|███████▌  | 124/163 [00:43<00:13,  2.90it/s]Evaluating:  77%|███████▋  | 125/163 [00:43<00:13,  2.91it/s]Evaluating:  77%|███████▋  | 126/163 [00:43<00:12,  2.91it/s]Evaluating:  78%|███████▊  | 127/163 [00:44<00:12,  2.91it/s]Evaluating:  79%|███████▊  | 128/163 [00:44<00:12,  2.90it/s]Evaluating:  79%|███████▉  | 129/163 [00:45<00:11,  2.90it/s]Evaluating:  80%|███████▉  | 130/163 [00:45<00:11,  2.81it/s]Evaluating:  80%|████████  | 131/163 [00:45<00:11,  2.83it/s]Evaluating:  81%|████████  | 132/163 [00:46<00:10,  2.86it/s]Evaluating:  82%|████████▏ | 133/163 [00:46<00:10,  2.88it/s]Evaluating:  82%|████████▏ | 134/163 [00:46<00:10,  2.89it/s]Evaluating:  83%|████████▎ | 135/163 [00:47<00:09,  2.89it/s]Evaluating:  83%|████████▎ | 136/163 [00:47<00:09,  2.89it/s]Evaluating:  84%|████████▍ | 137/163 [00:47<00:08,  2.90it/s]Evaluating:  85%|████████▍ | 138/163 [00:48<00:08,  2.90it/s]Evaluating:  85%|████████▌ | 139/163 [00:48<00:08,  2.91it/s]Evaluating:  86%|████████▌ | 140/163 [00:48<00:07,  2.91it/s]Evaluating:  87%|████████▋ | 141/163 [00:49<00:07,  2.89it/s]Evaluating:  87%|████████▋ | 142/163 [00:49<00:07,  2.90it/s]Evaluating:  88%|████████▊ | 143/163 [00:49<00:06,  2.90it/s]Evaluating:  88%|████████▊ | 144/163 [00:50<00:06,  2.91it/s]Evaluating:  89%|████████▉ | 145/163 [00:50<00:06,  2.91it/s]Evaluating:  90%|████████▉ | 146/163 [00:50<00:05,  2.92it/s]Evaluating:  90%|█████████ | 147/163 [00:51<00:05,  2.93it/s]Evaluating:  91%|█████████ | 148/163 [00:51<00:05,  2.93it/s]Evaluating:  91%|█████████▏| 149/163 [00:51<00:04,  2.92it/s]Evaluating:  92%|█████████▏| 150/163 [00:52<00:04,  2.92it/s]Evaluating:  93%|█████████▎| 151/163 [00:52<00:04,  2.92it/s]Evaluating:  93%|█████████▎| 152/163 [00:52<00:03,  2.92it/s]Evaluating:  94%|█████████▍| 153/163 [00:53<00:03,  2.92it/s]Evaluating:  94%|█████████▍| 154/163 [00:53<00:03,  2.91it/s]Evaluating:  95%|█████████▌| 155/163 [00:53<00:02,  2.91it/s]Evaluating:  96%|█████████▌| 156/163 [00:54<00:02,  2.90it/s]Evaluating:  96%|█████████▋| 157/163 [00:54<00:02,  2.90it/s]Evaluating:  97%|█████████▋| 158/163 [00:55<00:01,  2.91it/s]Evaluating:  98%|█████████▊| 159/163 [00:55<00:01,  2.91it/s]Evaluating:  98%|█████████▊| 160/163 [00:55<00:01,  2.90it/s]Evaluating:  99%|█████████▉| 161/163 [00:56<00:00,  2.90it/s]Evaluating:  99%|█████████▉| 162/163 [00:56<00:00,  2.89it/s]Evaluating: 100%|██████████| 163/163 [00:56<00:00,  2.93it/s]Evaluating: 100%|██████████| 163/163 [00:56<00:00,  2.87it/s]
05/09/2022 09:02:48 - INFO - __main__ -     Evaluation done in total 56.745279 secs (0.043550 sec per example)
05/09/2022 09:02:54 - INFO - __main__ -   Results: {'exact': 64.53781512605042, 'f1': 81.2684497031278, 'total': 1190, 'HasAns_exact': 64.53781512605042, 'HasAns_f1': 81.2684497031278, 'HasAns_total': 1190, 'best_exact': 64.53781512605042, 'best_exact_thresh': 0.0, 'best_f1': 81.2684497031278, 'best_f1_thresh': 0.0}
  el 
2022-05-09 09:02:58.250709: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0
05/09/2022 09:03:02 - WARNING - __main__ -   Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, 16-bits training: False
You are using a model of type xlm-roberta to instantiate a model of type xlm. This is not supported for all configurations of models and can yield errors.
Some weights of the model checkpoint at /cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//squad/xlm-KG_LR3e-5_EPOCH2.0_maxlen384_batchsize4_gradacc4 were not used when initializing XLMRobertaModel: ['base_model.encoder.layer.23.attention.self.key.weight', 'base_model.encoder.layer.0.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.3.output.LayerNorm.bias', 'base_model.encoder.layer.10.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.1.intermediate.dense.weight', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.19.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.22.attention.self.key.weight', 'base_model.encoder.layer.19.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.1.attention.self.query.bias', 'base_model.encoder.layer.4.attention.self.key.bias', 'base_model.encoder.layer.7.intermediate.dense.weight', 'base_model.encoder.layer.2.intermediate.dense.bias', 'base_model.encoder.layer.7.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.4.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.12.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.11.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.2.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.5.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.13.output.LayerNorm.weight', 'base_model.encoder.layer.0.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.10.attention.self.key.weight', 'base_model.encoder.layer.15.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.21.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.4.output.LayerNorm.weight', 'base_model.encoder.layer.0.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.14.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.22.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.21.attention.output.dense.bias', 'base_model.encoder.layer.14.attention.self.query.weight', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.1.attention.self.key.weight', 'base_model.encoder.layer.23.output.dense.weight', 'base_model.encoder.layer.13.attention.self.value.bias', 'base_model.encoder.layer.7.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.10.attention.output.dense.weight', 'base_model.encoder.layer.14.attention.self.key.bias', 'base_model.encoder.layer.10.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.10.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.14.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.6.attention.self.key.weight', 'base_model.encoder.layer.11.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.12.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.16.attention.output.dense.weight', 'base_model.encoder.layer.17.output.LayerNorm.bias', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.9.attention.self.query.weight', 'base_model.encoder.layer.23.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.9.attention.output.LayerNorm.weight', 'base_model.encoder.layer.20.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.0.attention.self.key.bias', 'base_model.encoder.layer.12.intermediate.dense.weight', 'base_model.embeddings.token_type_embeddings.weight', 'base_model.encoder.layer.13.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.16.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.6.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.6.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.12.attention.output.dense.bias', 'base_model.encoder.layer.1.attention.self.key.bias', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.22.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.10.output.dense.bias', 'base_model.encoder.layer.10.attention.self.value.bias', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.2.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.23.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.1.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.12.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.3.attention.output.dense.bias', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.1.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.17.attention.output.dense.bias', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.19.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.4.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.16.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.11.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.19.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.19.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.5.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.7.output.LayerNorm.weight', 'base_model.encoder.layer.15.attention.self.key.weight', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.22.intermediate.dense.weight', 'base_model.encoder.layer.13.output.dense.bias', 'base_model.encoder.layer.16.attention.output.LayerNorm.weight', 'base_model.encoder.layer.0.intermediate.dense.weight', 'base_model.encoder.layer.12.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.0.intermediate.dense.bias', 'base_model.encoder.layer.8.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.11.intermediate.dense.bias', 'base_model.embeddings.LayerNorm.weight', 'base_model.encoder.layer.3.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.8.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.9.attention.self.key.bias', 'base_model.encoder.layer.12.attention.self.key.bias', 'base_model.encoder.layer.13.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.2.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.8.attention.self.query.bias', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.18.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.19.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.21.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.4.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.18.output.dense.weight', 'base_model.encoder.layer.5.intermediate.dense.bias', 'base_model.encoder.layer.1.attention.self.value.weight', 'base_model.encoder.layer.15.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.0.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.12.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.22.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.15.output.dense.bias', 'base_model.encoder.layer.4.attention.self.value.bias', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.13.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.21.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.19.intermediate.dense.weight', 'base_model.encoder.layer.20.output.dense.weight', 'base_model.encoder.layer.4.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.17.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.10.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.19.attention.self.key.weight', 'base_model.encoder.layer.16.intermediate.dense.weight', 'base_model.encoder.layer.14.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.2.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.0.output.LayerNorm.weight', 'base_model.encoder.layer.20.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.5.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.11.attention.output.LayerNorm.weight', 'base_model.encoder.layer.15.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.17.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.8.intermediate.dense.weight', 'base_model.encoder.layer.11.attention.output.LayerNorm.bias', 'base_model.encoder.layer.5.attention.self.query.weight', 'base_model.encoder.layer.12.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.13.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.17.attention.output.LayerNorm.weight', 'base_model.encoder.layer.9.output.LayerNorm.weight', 'base_model.encoder.layer.22.output.LayerNorm.weight', 'base_model.encoder.layer.22.output.LayerNorm.bias', 'base_model.encoder.layer.11.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.9.attention.self.query.bias', 'base_model.encoder.layer.7.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.18.attention.output.LayerNorm.weight', 'base_model.encoder.layer.22.attention.self.value.bias', 'base_model.encoder.layer.16.attention.self.value.bias', 'base_model.encoder.layer.7.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.2.attention.output.dense.bias', 'base_model.encoder.layer.10.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.12.output.dense.weight', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.23.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.4.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.20.attention.output.dense.bias', 'base_model.encoder.layer.4.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.3.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.14.attention.output.dense.bias', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.13.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.20.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.2.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.14.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.9.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.14.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.15.intermediate.dense.weight', 'base_model.encoder.layer.16.attention.self.query.weight', 'base_model.encoder.layer.1.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.6.attention.self.key.bias', 'base_model.encoder.layer.3.attention.self.value.bias', 'base_model.encoder.layer.16.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.18.output.LayerNorm.bias', 'base_model.encoder.layer.8.attention.self.key.weight', 'base_model.encoder.layer.4.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.5.attention.self.key.weight', 'base_model.encoder.layer.19.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.20.attention.output.LayerNorm.bias', 'base_model.encoder.layer.13.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.7.attention.self.value.bias', 'base_model.encoder.layer.19.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.1.output.dense.bias', 'base_model.encoder.layer.14.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.15.attention.output.LayerNorm.weight', 'base_model.encoder.layer.5.attention.self.value.bias', 'base_model.encoder.layer.14.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.23.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.9.intermediate.dense.bias', 'base_model.encoder.layer.14.output.LayerNorm.bias', 'base_model.encoder.layer.0.attention.self.key.weight', 'base_model.encoder.layer.15.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.22.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.7.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.11.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.6.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.4.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.8.output.dense.weight', 'base_model.encoder.layer.8.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.0.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.12.attention.output.dense.weight', 'base_model.encoder.layer.11.output.dense.bias', 'base_model.encoder.layer.8.attention.output.dense.bias', 'base_model.encoder.layer.7.attention.self.key.bias', 'base_model.encoder.layer.7.output.LayerNorm.bias', 'base_model.encoder.layer.10.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.12.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.0.output.dense.weight', 'base_model.encoder.layer.5.attention.output.LayerNorm.bias', 'base_model.encoder.layer.1.attention.self.value.bias', 'base_model.encoder.layer.6.attention.output.dense.bias', 'base_model.encoder.layer.18.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.16.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.12.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.5.intermediate.dense.weight', 'base_model.encoder.layer.0.output.dense.bias', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.8.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.23.attention.output.LayerNorm.weight', 'base_model.encoder.layer.2.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.0.attention.output.dense.weight', 'base_model.encoder.layer.0.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.14.attention.output.dense.weight', 'base_model.encoder.layer.4.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.17.output.dense.weight', 'base_model.encoder.layer.8.output.dense.bias', 'base_model.encoder.layer.17.intermediate.dense.bias', 'base_model.encoder.layer.13.attention.self.query.weight', 'base_model.encoder.layer.16.output.LayerNorm.bias', 'base_model.encoder.layer.6.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.1.output.dense.weight', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.17.attention.self.value.weight', 'base_model.encoder.layer.5.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.18.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.10.output.dense.weight', 'base_model.encoder.layer.15.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.4.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.20.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.18.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.8.attention.self.key.bias', 'base_model.encoder.layer.22.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.11.attention.self.value.weight', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.9.attention.output.dense.weight', 'base_model.encoder.layer.16.output.dense.weight', 'base_model.encoder.layer.17.attention.self.key.weight', 'base_model.encoder.layer.16.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.11.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.4.intermediate.dense.weight', 'base_model.encoder.layer.21.output.LayerNorm.weight', 'base_model.encoder.layer.19.intermediate.dense.bias', 'base_model.encoder.layer.6.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.10.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.22.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.23.attention.output.LayerNorm.bias', 'base_model.encoder.layer.6.attention.output.LayerNorm.bias', 'base_model.encoder.layer.2.attention.self.query.weight', 'base_model.encoder.layer.9.output.LayerNorm.bias', 'base_model.encoder.layer.23.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.19.attention.self.value.bias', 'base_model.encoder.layer.4.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.23.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.16.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.9.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.2.output.dense.bias', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.14.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.5.attention.self.key.bias', 'base_model.encoder.layer.14.intermediate.dense.bias', 'base_model.encoder.layer.21.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.9.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.3.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.3.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.11.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.12.attention.self.query.weight', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.21.attention.output.dense.weight', 'base_model.encoder.layer.18.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.7.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.2.attention.self.value.bias', 'base_model.encoder.layer.4.attention.self.key.weight', 'base_model.encoder.layer.8.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.22.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.23.attention.self.query.weight', 'base_model.encoder.layer.14.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.21.intermediate.dense.bias', 'base_model.encoder.layer.13.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.1.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.9.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.5.output.LayerNorm.weight', 'base_model.encoder.layer.13.attention.output.dense.weight', 'base_model.encoder.layer.20.attention.self.value.weight', 'base_model.encoder.layer.6.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.11.attention.self.value.bias', 'base_model.encoder.layer.22.attention.self.key.bias', 'base_model.encoder.layer.0.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.4.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.16.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.20.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.8.output.LayerNorm.bias', 'base_model.encoder.layer.12.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.4.attention.self.query.bias', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.1.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.8.attention.output.dense.weight', 'base_model.encoder.layer.21.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.13.intermediate.dense.bias', 'base_model.encoder.layer.7.attention.self.query.weight', 'base_model.encoder.layer.21.output.dense.weight', 'base_model.encoder.layer.7.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.8.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.20.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.16.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.10.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.19.attention.self.query.bias', 'base_model.encoder.layer.14.output.LayerNorm.weight', 'base_model.encoder.layer.19.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.22.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.5.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.15.attention.output.dense.bias', 'base_model.encoder.layer.3.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.0.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.21.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.3.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.12.attention.output.LayerNorm.weight', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.6.intermediate.dense.weight', 'base_model.encoder.layer.17.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.16.output.dense.bias', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.6.output.dense.weight', 'base_model.encoder.layer.15.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.21.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.20.attention.self.query.bias', 'base_model.encoder.layer.3.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.3.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.23.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.15.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.16.attention.self.key.bias', 'base_model.encoder.layer.9.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.12.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.10.attention.output.LayerNorm.bias', 'base_model.encoder.layer.15.attention.output.dense.weight', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.6.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.5.attention.output.dense.bias', 'base_model.encoder.layer.7.attention.self.value.weight', 'base_model.encoder.layer.8.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.12.attention.self.value.bias', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.23.attention.self.value.bias', 'base_model.encoder.layer.4.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.12.attention.output.LayerNorm.bias', 'base_model.encoder.layer.22.attention.self.value.weight', 'base_model.encoder.layer.6.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.7.attention.output.LayerNorm.weight', 'base_model.embeddings.position_ids', 'base_model.encoder.layer.22.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.2.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.6.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.8.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.1.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.8.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.5.output.LayerNorm.bias', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.7.attention.output.dense.weight', 'base_model.encoder.layer.10.attention.output.LayerNorm.weight', 'base_model.encoder.layer.10.attention.self.query.weight', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.4.attention.output.dense.bias', 'base_model.encoder.layer.5.attention.self.query.bias', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.6.attention.output.LayerNorm.weight', 'base_model.encoder.layer.7.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.9.output.dense.bias', 'base_model.encoder.layer.13.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.16.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.19.attention.output.dense.bias', 'base_model.encoder.layer.22.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.5.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.9.attention.output.dense.bias', 'base_model.encoder.layer.21.attention.output.LayerNorm.bias', 'base_model.encoder.layer.22.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.18.attention.self.query.weight', 'base_model.encoder.layer.16.intermediate.dense.bias', 'base_model.encoder.layer.15.output.LayerNorm.bias', 'base_model.encoder.layer.0.output.LayerNorm.bias', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.18.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.3.attention.self.query.weight', 'base_model.encoder.layer.13.attention.self.value.weight', 'base_model.encoder.layer.18.attention.self.value.weight', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.17.attention.self.query.bias', 'base_model.encoder.layer.19.output.dense.weight', 'base_model.encoder.layer.20.output.dense.bias', 'base_model.encoder.layer.2.attention.output.dense.weight', 'base_model.encoder.layer.20.attention.self.value.bias', 'base_model.encoder.layer.21.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.22.attention.output.LayerNorm.bias', 'base_model.encoder.layer.14.attention.output.LayerNorm.bias', 'base_model.encoder.layer.19.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.12.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.18.intermediate.dense.bias', 'base_model.encoder.layer.7.attention.output.dense.bias', 'base_model.encoder.layer.21.intermediate.dense.weight', 'base_model.encoder.layer.8.output.LayerNorm.weight', 'base_model.encoder.layer.23.attention.self.query.bias', 'base_model.encoder.layer.8.intermediate.dense.bias', 'base_model.encoder.layer.2.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.7.attention.output.LayerNorm.bias', 'base_model.encoder.layer.22.intermediate.dense.bias', 'base_model.encoder.layer.2.attention.output.LayerNorm.weight', 'base_model.encoder.layer.15.intermediate.dense.bias', 'base_model.encoder.layer.23.attention.self.value.weight', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.17.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.23.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.15.output.LayerNorm.weight', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.10.attention.self.key.bias', 'base_model.encoder.layer.10.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.18.attention.self.value.bias', 'base_model.encoder.layer.0.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.2.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.4.output.LayerNorm.bias', 'base_model.encoder.layer.6.output.dense.bias', 'base_model.encoder.layer.8.attention.output.LayerNorm.bias', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.6.output.LayerNorm.bias', 'base_model.encoder.layer.16.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.8.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.14.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.19.output.LayerNorm.weight', 'base_model.encoder.layer.12.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.3.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.21.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.17.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.2.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.5.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.23.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.1.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.22.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.14.attention.self.value.bias', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.17.attention.self.query.weight', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.12.attention.self.value.weight', 'base_model.encoder.layer.21.attention.output.LayerNorm.weight', 'base_model.embeddings.word_embeddings.weight', 'base_model.encoder.layer.2.intermediate.dense.weight', 'base_model.encoder.layer.11.output.dense.weight', 'base_model.encoder.layer.17.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.11.attention.self.key.weight', 'base_model.encoder.layer.22.output.dense.bias', 'base_model.encoder.layer.13.attention.self.key.bias', 'base_model.encoder.layer.2.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.19.attention.self.query.weight', 'base_model.encoder.layer.6.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.6.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.10.attention.self.query.bias', 'base_model.encoder.layer.1.intermediate.dense.bias', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.4.output.dense.bias', 'base_model.encoder.layer.18.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.23.attention.self.key.bias', 'base_model.encoder.layer.14.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.15.output.dense.weight', 'base_model.encoder.layer.4.intermediate.dense.bias', 'base_model.encoder.layer.0.attention.self.query.weight', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.17.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.3.output.LayerNorm.weight', 'base_model.encoder.layer.16.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.20.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.14.attention.output.LayerNorm.weight', 'base_model.encoder.layer.11.attention.self.key.bias', 'base_model.encoder.layer.11.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.2.output.dense.weight', 'base_model.encoder.layer.9.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.18.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.17.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.20.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.10.output.LayerNorm.weight', 'base_model.encoder.layer.14.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.13.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.17.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.7.attention.self.key.weight', 'base_model.encoder.layer.17.attention.output.dense.weight', 'base_model.encoder.layer.16.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.4.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.12.output.dense.bias', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.10.output.LayerNorm.bias', 'base_model.encoder.layer.1.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.1.output.LayerNorm.bias', 'base_model.encoder.layer.15.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.1.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.1.attention.output.LayerNorm.bias', 'base_model.encoder.layer.7.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.0.attention.output.dense.bias', 'base_model.encoder.layer.13.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.17.output.LayerNorm.weight', 'base_model.encoder.layer.20.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.13.attention.self.key.weight', 'base_model.encoder.layer.18.attention.self.key.bias', 'base_model.encoder.layer.3.attention.output.LayerNorm.bias', 'base_model.encoder.layer.21.output.LayerNorm.bias', 'base_model.encoder.layer.13.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.13.attention.output.dense.bias', 'base_model.encoder.layer.13.attention.self.query.bias', 'base_model.encoder.layer.20.intermediate.dense.weight', 'base_model.encoder.layer.10.attention.self.value.weight', 'base_model.encoder.layer.19.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.23.output.dense.bias', 'base_model.encoder.layer.9.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.16.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.11.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.1.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.8.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.13.output.LayerNorm.bias', 'base_model.encoder.layer.23.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.21.attention.self.value.weight', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.15.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.10.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.10.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.19.attention.self.key.bias', 'base_model.encoder.layer.20.intermediate.dense.bias', 'base_model.encoder.layer.6.attention.self.value.weight', 'base_model.encoder.layer.2.output.LayerNorm.weight', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.12.output.LayerNorm.weight', 'base_model.encoder.layer.13.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.19.attention.self.value.weight', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.12.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.6.attention.output.dense.weight', 'base_model.encoder.layer.19.output.LayerNorm.bias', 'base_model.encoder.layer.9.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.5.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.12.attention.self.query.bias', 'base_model.encoder.layer.15.attention.output.LayerNorm.bias', 'base_model.encoder.layer.6.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.7.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.21.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.10.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.20.output.LayerNorm.bias', 'base_model.encoder.layer.9.attention.self.key.weight', 'base_model.encoder.layer.13.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.15.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.5.output.dense.bias', 'base_model.encoder.layer.8.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.6.intermediate.dense.bias', 'base_model.encoder.layer.9.attention.self.value.bias', 'base_model.encoder.layer.8.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.18.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.6.attention.self.query.weight', 'base_model.encoder.layer.7.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.7.output.dense.bias', 'base_model.encoder.layer.23.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.22.output.dense.weight', 'base_model.encoder.layer.12.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.2.attention.self.key.weight', 'base_model.encoder.layer.15.attention.self.query.bias', 'base_model.encoder.layer.16.attention.output.LayerNorm.bias', 'base_model.encoder.layer.19.attention.output.dense.weight', 'base_model.encoder.layer.5.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.15.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.23.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.15.attention.self.value.bias', 'base_model.encoder.layer.18.attention.output.LayerNorm.bias', 'base_model.encoder.layer.22.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.0.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.19.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.3.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.6.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.16.attention.output.dense.bias', 'base_model.encoder.layer.2.attention.output.LayerNorm.bias', 'base_model.encoder.layer.1.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.9.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.14.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.17.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.20.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.16.attention.self.key.weight', 'base_model.encoder.layer.7.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.10.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.16.attention.self.value.weight', 'base_model.encoder.layer.17.intermediate.dense.weight', 'base_model.encoder.layer.18.output.dense.bias', 'base_model.encoder.layer.1.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.10.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.9.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.11.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.3.output.dense.weight', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.18.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.3.attention.output.LayerNorm.weight', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.5.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.11.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.0.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.6.attention.self.value.bias', 'base_model.encoder.layer.2.output.LayerNorm.bias', 'base_model.encoder.layer.6.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.21.output.dense.bias', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.3.intermediate.dense.bias', 'base_model.encoder.layer.3.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.10.intermediate.dense.bias', 'base_model.encoder.layer.19.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.18.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.14.attention.self.query.bias', 'base_model.encoder.layer.15.attention.self.value.weight', 'base_model.encoder.layer.19.output.dense.bias', 'base_model.encoder.layer.17.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.20.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.5.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.3.attention.self.value.weight', 'base_model.encoder.layer.14.output.dense.bias', 'base_model.encoder.layer.1.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.6.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.7.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.3.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.2.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.21.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.3.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.4.attention.self.query.weight', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.0.attention.self.query.bias', 'base_model.encoder.layer.17.attention.output.LayerNorm.bias', 'base_model.encoder.layer.13.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.5.attention.self.value.weight', 'base_model.encoder.layer.8.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.1.attention.output.LayerNorm.weight', 'base_model.encoder.layer.15.attention.self.key.bias', 'base_model.encoder.layer.18.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.22.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.11.output.LayerNorm.bias', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.21.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.15.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.23.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.12.output.LayerNorm.bias', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.15.attention.self.query.weight', 'base_model.encoder.layer.7.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.7.intermediate.dense.bias', 'base_model.encoder.layer.4.attention.self.value.weight', 'base_model.pooler.dense.bias', 'base_model.encoder.layer.4.attention.output.dense.weight', 'base_model.encoder.layer.8.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.15.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.9.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.17.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.7.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.8.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.7.attention.self.query.bias', 'base_model.encoder.layer.18.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.9.output.dense.weight', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.13.intermediate.dense.weight', 'base_model.encoder.layer.11.intermediate.dense.weight', 'base_model.encoder.layer.19.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.17.attention.self.key.bias', 'base_model.encoder.layer.21.attention.self.query.weight', 'base_model.encoder.layer.17.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.5.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.16.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.2.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.2.attention.self.query.bias', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.7.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.3.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.3.attention.output.dense.weight', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.embeddings.position_embeddings.weight', 'base_model.encoder.layer.18.attention.output.dense.weight', 'base_model.encoder.layer.12.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.14.output.adapters.es.adapter_up.bias', 'qa_outputs.weight', 'base_model.encoder.layer.3.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.0.attention.self.value.weight', 'base_model.encoder.layer.20.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.15.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.9.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.13.attention.output.LayerNorm.weight', 'base_model.encoder.layer.0.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.5.output.dense.weight', 'base_model.encoder.layer.9.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.10.attention.output.dense.bias', 'base_model.encoder.layer.18.attention.self.key.weight', 'base_model.encoder.layer.20.attention.self.key.bias', 'base_model.encoder.layer.3.output.dense.bias', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.23.output.LayerNorm.weight', 'base_model.encoder.layer.1.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.14.intermediate.dense.weight', 'base_model.encoder.layer.1.attention.output.dense.bias', 'base_model.encoder.layer.3.intermediate.dense.weight', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.0.attention.output.LayerNorm.weight', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.23.attention.output.dense.weight', 'base_model.encoder.layer.18.attention.self.query.bias', 'base_model.encoder.layer.16.output.LayerNorm.weight', 'base_model.encoder.layer.21.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.19.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.21.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.20.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.20.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.3.attention.self.key.weight', 'base_model.encoder.layer.1.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.4.output.dense.weight', 'base_model.encoder.layer.11.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.17.attention.self.value.bias', 'base_model.encoder.layer.3.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.18.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.11.attention.self.query.weight', 'base_model.encoder.layer.21.attention.self.key.weight', 'base_model.encoder.layer.2.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.5.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.14.attention.self.key.weight', 'base_model.encoder.layer.23.intermediate.dense.bias', 'base_model.encoder.layer.13.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.18.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.13.output.dense.weight', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.1.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.23.attention.output.dense.bias', 'base_model.encoder.layer.8.attention.output.LayerNorm.weight', 'base_model.encoder.layer.11.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.21.attention.self.key.bias', 'base_model.encoder.layer.23.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.12.attention.self.key.weight', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.23.output.LayerNorm.bias', 'base_model.encoder.layer.14.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.18.attention.output.dense.bias', 'base_model.encoder.layer.23.intermediate.dense.weight', 'base_model.encoder.layer.19.attention.output.LayerNorm.weight', 'base_model.encoder.layer.5.attention.output.LayerNorm.weight', 'base_model.encoder.layer.8.attention.self.value.bias', 'base_model.encoder.layer.12.intermediate.dense.bias', 'base_model.encoder.layer.0.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.20.attention.output.LayerNorm.weight', 'base_model.encoder.layer.17.output.dense.bias', 'base_model.encoder.layer.19.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.3.attention.self.key.bias', 'base_model.encoder.layer.9.attention.output.LayerNorm.bias', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.4.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.1.attention.output.dense.weight', 'base_model.encoder.layer.14.attention.self.value.weight', 'base_model.encoder.layer.14.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.16.attention.self.query.bias', 'base_model.encoder.layer.18.intermediate.dense.weight', 'base_model.encoder.layer.21.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.13.attention.output.LayerNorm.bias', 'base_model.encoder.layer.0.attention.self.value.bias', 'base_model.encoder.layer.17.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.5.attention.output.dense.weight', 'base_model.encoder.layer.11.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.11.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.10.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.21.attention.self.value.bias', 'base_model.encoder.layer.20.attention.self.query.weight', 'base_model.encoder.layer.5.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.17.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.0.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.2.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.11.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.8.attention.self.query.weight', 'base_model.encoder.layer.4.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.9.attention.self.value.weight', 'base_model.encoder.layer.13.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.22.attention.output.LayerNorm.weight', 'base_model.encoder.layer.2.attention.self.key.bias', 'base_model.encoder.layer.3.attention.self.query.bias', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.9.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.11.attention.output.dense.bias', 'base_model.encoder.layer.21.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.22.attention.output.dense.weight', 'base_model.encoder.layer.23.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.6.attention.self.query.bias', 'base_model.encoder.layer.22.attention.output.dense.bias', 'base_model.encoder.layer.8.attention.self.value.weight', 'base_model.encoder.layer.16.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.22.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.2.attention.self.value.weight', 'base_model.encoder.layer.20.attention.output.dense.weight', 'base_model.encoder.layer.6.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.11.output.LayerNorm.weight', 'base_model.encoder.layer.21.attention.self.query.bias', 'base_model.encoder.layer.1.attention.self.query.weight', 'base_model.encoder.layer.10.intermediate.dense.weight', 'base_model.encoder.layer.20.attention.self.key.weight', 'base_model.encoder.layer.6.output.LayerNorm.weight', 'base_model.encoder.layer.0.attention.output.LayerNorm.bias', 'base_model.encoder.layer.17.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.22.attention.self.query.weight', 'base_model.encoder.layer.9.intermediate.dense.weight', 'base_model.encoder.layer.20.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.7.output.dense.weight', 'base_model.encoder.layer.5.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.16.output.adapters.ts.adapter_up.bias', 'base_model.embeddings.LayerNorm.bias', 'base_model.encoder.layer.1.output.LayerNorm.weight', 'base_model.encoder.layer.11.attention.self.query.bias', 'base_model.encoder.layer.19.attention.output.LayerNorm.bias', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.22.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.4.attention.output.LayerNorm.bias', 'base_model.encoder.layer.20.output.LayerNorm.weight', 'base_model.encoder.layer.4.attention.output.LayerNorm.weight', 'base_model.encoder.layer.0.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.14.output.dense.weight', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.9.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.11.attention.output.dense.weight', 'base_model.encoder.layer.0.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.15.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.22.attention.self.query.bias', 'base_model.encoder.layer.18.output.LayerNorm.weight', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.5.output.adapters.tp.adapter_up.bias', 'qa_outputs.bias', 'base_model.encoder.layer.12.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.23.output.adapters.tp.adapter_up.bias', 'base_model.pooler.dense.weight', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.10.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.15.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.2.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.18.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.20.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.9.output.adapters.ts.adapter_down.0.bias']
- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of XLMRobertaModel were not initialized from the model checkpoint at /cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//squad/xlm-KG_LR3e-5_EPOCH2.0_maxlen384_batchsize4_gradacc4 and are newly initialized: ['encoder.layer.8.attention.self.query.bias', 'encoder.layer.5.attention.output.dense.bias', 'encoder.layer.20.attention.self.value.bias', 'encoder.layer.11.attention.self.query.weight', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.16.output.LayerNorm.weight', 'encoder.layer.20.intermediate.dense.weight', 'encoder.layer.21.intermediate.dense.bias', 'encoder.layer.12.attention.self.query.bias', 'encoder.layer.3.attention.output.dense.weight', 'encoder.layer.12.attention.self.key.bias', 'encoder.layer.16.output.LayerNorm.bias', 'encoder.layer.22.output.LayerNorm.bias', 'encoder.layer.9.attention.self.value.bias', 'encoder.layer.10.attention.self.key.weight', 'encoder.layer.0.output.dense.weight', 'encoder.layer.20.output.LayerNorm.bias', 'encoder.layer.10.attention.output.dense.weight', 'encoder.layer.13.attention.self.query.weight', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.4.attention.self.query.bias', 'encoder.layer.17.attention.output.dense.weight', 'encoder.layer.20.output.LayerNorm.weight', 'encoder.layer.23.attention.output.LayerNorm.weight', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.19.output.LayerNorm.bias', 'encoder.layer.0.attention.output.dense.bias', 'encoder.layer.15.output.LayerNorm.bias', 'encoder.layer.0.attention.self.query.weight', 'encoder.layer.20.attention.self.key.bias', 'encoder.layer.11.attention.self.value.bias', 'encoder.layer.3.attention.self.key.bias', 'encoder.layer.5.attention.self.query.weight', 'encoder.layer.22.intermediate.dense.bias', 'encoder.layer.8.output.LayerNorm.weight', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.6.output.LayerNorm.bias', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.3.attention.self.value.bias', 'encoder.layer.8.attention.self.value.bias', 'encoder.layer.19.attention.self.key.weight', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.21.attention.self.value.bias', 'encoder.layer.2.attention.self.key.bias', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.10.attention.output.LayerNorm.bias', 'encoder.layer.5.attention.self.value.weight', 'encoder.layer.4.attention.self.query.weight', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.layer.21.attention.output.LayerNorm.weight', 'encoder.layer.20.output.dense.bias', 'encoder.layer.18.attention.self.value.weight', 'encoder.layer.10.intermediate.dense.weight', 'encoder.layer.20.attention.self.key.weight', 'encoder.layer.18.attention.self.key.bias', 'encoder.layer.23.output.LayerNorm.bias', 'encoder.layer.22.attention.self.query.weight', 'encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.layer.23.attention.output.dense.bias', 'encoder.layer.4.attention.self.key.bias', 'encoder.layer.15.output.LayerNorm.weight', 'encoder.layer.23.attention.self.query.weight', 'encoder.layer.20.attention.self.query.weight', 'encoder.layer.7.attention.self.value.bias', 'encoder.layer.17.output.dense.weight', 'encoder.layer.10.output.dense.bias', 'encoder.layer.6.attention.self.value.weight', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.18.intermediate.dense.bias', 'encoder.layer.20.attention.output.LayerNorm.bias', 'encoder.layer.21.output.dense.weight', 'encoder.layer.22.attention.output.dense.weight', 'encoder.layer.8.output.LayerNorm.bias', 'encoder.layer.13.attention.output.dense.weight', 'encoder.layer.6.attention.self.value.bias', 'encoder.layer.17.output.LayerNorm.weight', 'encoder.layer.7.attention.self.query.bias', 'encoder.layer.20.attention.output.dense.weight', 'encoder.layer.21.output.dense.bias', 'encoder.layer.9.attention.output.LayerNorm.weight', 'encoder.layer.19.output.LayerNorm.weight', 'encoder.layer.19.attention.self.value.weight', 'encoder.layer.16.attention.output.LayerNorm.weight', 'encoder.layer.12.attention.self.key.weight', 'encoder.layer.5.intermediate.dense.weight', 'embeddings.LayerNorm.bias', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.13.intermediate.dense.bias', 'encoder.layer.14.output.dense.bias', 'encoder.layer.14.attention.output.dense.weight', 'encoder.layer.16.attention.output.dense.weight', 'encoder.layer.0.attention.self.key.bias', 'encoder.layer.15.attention.self.key.bias', 'encoder.layer.10.attention.self.key.bias', 'encoder.layer.22.output.LayerNorm.weight', 'encoder.layer.16.attention.self.query.weight', 'encoder.layer.22.attention.output.LayerNorm.weight', 'encoder.layer.23.intermediate.dense.weight', 'encoder.layer.1.output.dense.weight', 'encoder.layer.14.intermediate.dense.bias', 'encoder.layer.11.output.LayerNorm.bias', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.21.intermediate.dense.weight', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.16.attention.self.value.weight', 'encoder.layer.2.output.dense.weight', 'encoder.layer.20.attention.self.value.weight', 'encoder.layer.10.attention.output.dense.bias', 'encoder.layer.5.output.dense.bias', 'encoder.layer.7.attention.output.dense.weight', 'encoder.layer.17.attention.self.query.weight', 'encoder.layer.1.attention.self.value.bias', 'encoder.layer.15.attention.self.query.weight', 'encoder.layer.6.attention.self.key.weight', 'encoder.layer.11.attention.self.value.weight', 'encoder.layer.3.attention.self.key.weight', 'encoder.layer.17.attention.self.value.weight', 'encoder.layer.13.output.dense.weight', 'encoder.layer.15.attention.self.value.bias', 'encoder.layer.23.attention.output.dense.weight', 'encoder.layer.23.output.dense.weight', 'encoder.layer.17.attention.output.LayerNorm.weight', 'encoder.layer.23.attention.self.value.bias', 'encoder.layer.12.output.dense.bias', 'encoder.layer.15.output.dense.weight', 'encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.layer.18.intermediate.dense.weight', 'encoder.layer.4.attention.self.key.weight', 'encoder.layer.19.attention.self.key.bias', 'encoder.layer.20.attention.self.query.bias', 'encoder.layer.8.output.dense.bias', 'encoder.layer.19.attention.output.dense.bias', 'encoder.layer.1.attention.self.key.weight', 'encoder.layer.6.attention.output.LayerNorm.bias', 'encoder.layer.0.attention.output.dense.weight', 'encoder.layer.13.output.LayerNorm.bias', 'encoder.layer.12.attention.self.value.weight', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.layer.17.attention.self.key.weight', 'encoder.layer.4.attention.output.LayerNorm.bias', 'encoder.layer.5.attention.self.key.bias', 'encoder.layer.18.attention.self.key.weight', 'pooler.dense.weight', 'encoder.layer.18.attention.self.value.bias', 'encoder.layer.19.attention.self.query.weight', 'encoder.layer.3.attention.self.value.weight', 'encoder.layer.18.output.LayerNorm.bias', 'encoder.layer.12.attention.output.dense.weight', 'encoder.layer.15.intermediate.dense.bias', 'encoder.layer.11.attention.self.key.bias', 'encoder.layer.16.attention.output.dense.bias', 'encoder.layer.12.output.dense.weight', 'encoder.layer.14.attention.self.query.bias', 'encoder.layer.21.attention.self.query.bias', 'encoder.layer.9.output.dense.bias', 'encoder.layer.11.attention.output.dense.bias', 'encoder.layer.14.attention.output.LayerNorm.weight', 'encoder.layer.21.attention.self.query.weight', 'encoder.layer.0.attention.self.query.bias', 'encoder.layer.0.attention.self.value.bias', 'encoder.layer.8.attention.self.value.weight', 'encoder.layer.6.attention.output.LayerNorm.weight', 'encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.layer.3.attention.self.query.weight', 'encoder.layer.14.output.dense.weight', 'encoder.layer.13.attention.self.key.weight', 'encoder.layer.16.attention.self.key.weight', 'encoder.layer.9.attention.self.value.weight', 'encoder.layer.11.attention.self.query.bias', 'encoder.layer.13.intermediate.dense.weight', 'encoder.layer.1.attention.self.query.bias', 'encoder.layer.21.attention.output.dense.weight', 'encoder.layer.17.attention.self.value.bias', 'encoder.layer.13.output.dense.bias', 'encoder.layer.10.attention.self.query.weight', 'encoder.layer.6.output.dense.bias', 'encoder.layer.21.attention.output.dense.bias', 'encoder.layer.19.attention.self.query.bias', 'encoder.layer.20.attention.output.dense.bias', 'encoder.layer.23.output.LayerNorm.weight', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.2.attention.self.value.weight', 'encoder.layer.15.attention.self.key.weight', 'encoder.layer.15.attention.self.query.bias', 'encoder.layer.8.attention.self.query.weight', 'encoder.layer.13.attention.output.LayerNorm.weight', 'encoder.layer.14.intermediate.dense.weight', 'encoder.layer.16.attention.self.key.bias', 'encoder.layer.5.attention.output.LayerNorm.weight', 'encoder.layer.22.attention.self.key.weight', 'encoder.layer.13.attention.self.value.bias', 'encoder.layer.18.attention.self.query.bias', 'encoder.layer.23.attention.self.value.weight', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.19.intermediate.dense.weight', 'encoder.layer.9.attention.self.key.bias', 'encoder.layer.14.attention.output.dense.bias', 'encoder.layer.1.attention.self.value.weight', 'encoder.layer.1.attention.output.dense.bias', 'encoder.layer.10.attention.self.value.bias', 'encoder.layer.12.attention.output.dense.bias', 'encoder.layer.7.output.dense.weight', 'encoder.layer.19.output.dense.weight', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.8.attention.self.key.bias', 'encoder.layer.2.attention.output.LayerNorm.weight', 'encoder.layer.3.output.dense.weight', 'encoder.layer.23.attention.self.key.bias', 'encoder.layer.12.attention.output.LayerNorm.weight', 'encoder.layer.0.attention.self.key.weight', 'encoder.layer.18.attention.output.dense.bias', 'encoder.layer.5.attention.output.dense.weight', 'encoder.layer.18.output.dense.weight', 'encoder.layer.11.attention.output.dense.weight', 'encoder.layer.15.attention.output.LayerNorm.bias', 'encoder.layer.15.attention.output.LayerNorm.weight', 'encoder.layer.13.attention.self.query.bias', 'encoder.layer.23.attention.output.LayerNorm.bias', 'encoder.layer.8.attention.self.key.weight', 'encoder.layer.7.intermediate.dense.bias', 'encoder.layer.0.output.dense.bias', 'encoder.layer.10.output.LayerNorm.bias', 'encoder.layer.19.attention.self.value.bias', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.4.attention.self.value.weight', 'encoder.layer.13.attention.output.dense.bias', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.9.attention.output.LayerNorm.bias', 'encoder.layer.5.output.dense.weight', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.7.output.dense.bias', 'encoder.layer.7.attention.self.key.bias', 'encoder.layer.23.attention.self.query.bias', 'encoder.layer.2.attention.self.query.weight', 'encoder.layer.18.attention.self.query.weight', 'encoder.layer.8.attention.output.dense.weight', 'encoder.layer.0.intermediate.dense.bias', 'pooler.dense.bias', 'encoder.layer.22.intermediate.dense.weight', 'encoder.layer.4.attention.output.LayerNorm.weight', 'encoder.layer.10.output.dense.weight', 'encoder.layer.19.attention.output.LayerNorm.weight', 'encoder.layer.6.attention.output.dense.bias', 'encoder.layer.5.output.LayerNorm.bias', 'embeddings.token_type_embeddings.weight', 'encoder.layer.22.output.dense.weight', 'encoder.layer.9.output.LayerNorm.weight', 'encoder.layer.6.output.dense.weight', 'encoder.layer.18.output.dense.bias', 'encoder.layer.22.attention.output.dense.bias', 'encoder.layer.16.output.dense.bias', 'encoder.layer.2.output.dense.bias', 'encoder.layer.4.output.dense.weight', 'encoder.layer.13.attention.output.LayerNorm.bias', 'encoder.layer.9.attention.output.dense.bias', 'encoder.layer.7.attention.self.value.weight', 'embeddings.position_embeddings.weight', 'encoder.layer.7.attention.output.dense.bias', 'encoder.layer.23.attention.self.key.weight', 'encoder.layer.2.attention.output.dense.weight', 'encoder.layer.17.intermediate.dense.weight', 'encoder.layer.11.attention.output.LayerNorm.weight', 'encoder.layer.1.attention.output.LayerNorm.weight', 'encoder.layer.5.attention.self.query.bias', 'encoder.layer.4.attention.self.value.bias', 'encoder.layer.7.attention.self.query.weight', 'encoder.layer.14.attention.self.query.weight', 'encoder.layer.4.attention.output.dense.bias', 'encoder.layer.18.attention.output.LayerNorm.weight', 'encoder.layer.7.attention.output.LayerNorm.bias', 'encoder.layer.9.attention.self.query.bias', 'encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.layer.12.output.LayerNorm.weight', 'encoder.layer.16.attention.self.value.bias', 'encoder.layer.17.output.LayerNorm.bias', 'encoder.layer.11.output.dense.bias', 'encoder.layer.6.attention.self.query.weight', 'encoder.layer.22.attention.self.value.bias', 'encoder.layer.14.attention.output.LayerNorm.bias', 'encoder.layer.23.output.dense.bias', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.14.attention.self.key.bias', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.22.attention.self.query.bias', 'encoder.layer.20.output.dense.weight', 'encoder.layer.1.attention.output.dense.weight', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.6.attention.self.key.bias', 'encoder.layer.11.output.LayerNorm.weight', 'encoder.layer.6.attention.output.dense.weight', 'encoder.layer.21.attention.self.value.weight', 'encoder.layer.17.output.dense.bias', 'encoder.layer.14.attention.self.value.bias', 'encoder.layer.17.attention.output.dense.bias', 'encoder.layer.9.attention.self.key.weight', 'encoder.layer.4.attention.output.dense.weight', 'encoder.layer.15.output.dense.bias', 'encoder.layer.10.attention.self.query.bias', 'encoder.layer.12.attention.self.value.bias', 'encoder.layer.10.attention.output.LayerNorm.weight', 'encoder.layer.12.attention.self.query.weight', 'encoder.layer.0.attention.self.value.weight', 'encoder.layer.11.attention.self.key.weight', 'encoder.layer.19.attention.output.LayerNorm.bias', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.21.attention.output.LayerNorm.bias', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.14.output.LayerNorm.bias', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.12.output.LayerNorm.bias', 'embeddings.word_embeddings.weight', 'encoder.layer.18.attention.output.LayerNorm.bias', 'encoder.layer.7.output.LayerNorm.bias', 'encoder.layer.20.intermediate.dense.bias', 'encoder.layer.5.attention.self.key.weight', 'encoder.layer.16.attention.self.query.bias', 'encoder.layer.21.output.LayerNorm.weight', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.13.attention.self.value.weight', 'encoder.layer.21.attention.self.key.weight', 'encoder.layer.2.attention.self.query.bias', 'encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.9.attention.output.dense.weight', 'encoder.layer.22.attention.output.LayerNorm.bias', 'encoder.layer.12.intermediate.dense.weight', 'encoder.layer.20.attention.output.LayerNorm.weight', 'encoder.layer.8.attention.output.LayerNorm.weight', 'encoder.layer.2.attention.output.dense.bias', 'encoder.layer.9.attention.self.query.weight', 'encoder.layer.3.output.dense.bias', 'encoder.layer.22.attention.self.key.bias', 'encoder.layer.7.attention.output.LayerNorm.weight', 'encoder.layer.10.output.LayerNorm.weight', 'encoder.layer.7.output.LayerNorm.weight', 'encoder.layer.14.attention.self.value.weight', 'encoder.layer.7.attention.self.key.weight', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.16.intermediate.dense.weight', 'encoder.layer.16.output.dense.weight', 'encoder.layer.5.attention.self.value.bias', 'encoder.layer.9.output.LayerNorm.bias', 'encoder.layer.15.attention.self.value.weight', 'encoder.layer.2.attention.output.LayerNorm.bias', 'encoder.layer.13.output.LayerNorm.weight', 'encoder.layer.8.attention.output.dense.bias', 'encoder.layer.16.attention.output.LayerNorm.bias', 'encoder.layer.8.attention.output.LayerNorm.bias', 'encoder.layer.17.intermediate.dense.bias', 'encoder.layer.1.attention.self.query.weight', 'encoder.layer.16.intermediate.dense.bias', 'encoder.layer.1.attention.self.key.bias', 'embeddings.LayerNorm.weight', 'encoder.layer.21.attention.self.key.bias', 'encoder.layer.14.attention.self.key.weight', 'encoder.layer.8.output.dense.weight', 'encoder.layer.1.output.dense.bias', 'encoder.layer.21.output.LayerNorm.bias', 'encoder.layer.15.attention.output.dense.bias', 'encoder.layer.3.attention.output.dense.bias', 'encoder.layer.12.intermediate.dense.bias', 'encoder.layer.0.attention.output.LayerNorm.weight', 'encoder.layer.17.attention.self.query.bias', 'encoder.layer.6.attention.self.query.bias', 'encoder.layer.2.attention.self.key.weight', 'encoder.layer.2.attention.self.value.bias', 'encoder.layer.10.attention.self.value.weight', 'encoder.layer.15.intermediate.dense.weight', 'encoder.layer.12.attention.output.LayerNorm.bias', 'encoder.layer.19.intermediate.dense.bias', 'encoder.layer.19.attention.output.dense.weight', 'encoder.layer.22.output.dense.bias', 'encoder.layer.23.intermediate.dense.bias', 'encoder.layer.4.output.dense.bias', 'encoder.layer.13.attention.self.key.bias', 'encoder.layer.22.attention.self.value.weight', 'encoder.layer.14.output.LayerNorm.weight', 'encoder.layer.11.output.dense.weight', 'encoder.layer.9.output.dense.weight', 'encoder.layer.3.attention.self.query.bias', 'encoder.layer.19.output.dense.bias', 'encoder.layer.17.attention.self.key.bias', 'encoder.layer.17.attention.output.LayerNorm.bias', 'encoder.layer.18.output.LayerNorm.weight', 'encoder.layer.18.attention.output.dense.weight', 'encoder.layer.15.attention.output.dense.weight', 'encoder.layer.6.intermediate.dense.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Overwriting existing adapter 'ep'.
Overwriting existing adapter 'tp'.
Overwriting existing adapter 'es'.
Overwriting existing adapter 'ts'.
Overwriting existing adapter fusion module 'ep,tp,es,ts'
05/09/2022 09:03:28 - INFO - __main__ -   lang2id = None
05/09/2022 09:03:34 - INFO - __main__ -   Training/evaluation parameters Namespace(adam_epsilon=1e-08, cache_dir='', config_name='', data_dir=None, device=device(type='cuda'), do_eval=True, do_lower_case=False, do_train=False, doc_stride=128, eval_all_checkpoints=False, eval_lang='el', evaluate_during_training=False, fp16=False, fp16_opt_level='O1', gradient_accumulation_steps=1, learning_rate=5e-05, local_rank=-1, logging_steps=50, max_answer_length=30, max_grad_norm=1.0, max_query_length=64, max_seq_length=384, max_steps=-1, model_name='xlm-KG', model_name_or_path='/cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//squad/xlm-KG_LR3e-5_EPOCH2.0_maxlen384_batchsize4_gradacc4', model_type='xlm', modelkg_dir='/cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/adapter/xlmr_adapter', n_best_size=20, n_gpu=1, no_cuda=False, null_score_diff_threshold=0.0, num_train_epochs=3.0, output_dir='/cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//squad/xlm-KG_LR3e-5_EPOCH2.0_maxlen384_batchsize4_gradacc4/predictions/xquad/', overwrite_cache=False, overwrite_output_dir=False, per_gpu_eval_batch_size=8, per_gpu_train_batch_size=8, predict_file='/cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/download//xquad//xquad.el.json', save_steps=50, seed=42, server_ip='', server_port='', threads=1, tokenizer_name='', train_file=None, train_lang='en', verbose_logging=False, version_2_with_negative=False, warmup_steps=0, weight_decay=0.0)
05/09/2022 09:03:34 - INFO - __main__ -   Loading checkpoint /cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//squad/xlm-KG_LR3e-5_EPOCH2.0_maxlen384_batchsize4_gradacc4 for evaluation
05/09/2022 09:03:34 - INFO - __main__ -   Evaluate the following checkpoints: ['/cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//squad/xlm-KG_LR3e-5_EPOCH2.0_maxlen384_batchsize4_gradacc4']
Some weights of the model checkpoint at /cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//squad/xlm-KG_LR3e-5_EPOCH2.0_maxlen384_batchsize4_gradacc4 were not used when initializing XLMRobertaModel: ['base_model.encoder.layer.23.attention.self.key.weight', 'base_model.encoder.layer.0.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.3.output.LayerNorm.bias', 'base_model.encoder.layer.10.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.1.intermediate.dense.weight', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.19.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.22.attention.self.key.weight', 'base_model.encoder.layer.19.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.1.attention.self.query.bias', 'base_model.encoder.layer.4.attention.self.key.bias', 'base_model.encoder.layer.7.intermediate.dense.weight', 'base_model.encoder.layer.2.intermediate.dense.bias', 'base_model.encoder.layer.7.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.4.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.12.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.11.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.2.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.5.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.13.output.LayerNorm.weight', 'base_model.encoder.layer.0.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.10.attention.self.key.weight', 'base_model.encoder.layer.15.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.21.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.4.output.LayerNorm.weight', 'base_model.encoder.layer.0.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.14.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.22.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.21.attention.output.dense.bias', 'base_model.encoder.layer.14.attention.self.query.weight', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.1.attention.self.key.weight', 'base_model.encoder.layer.23.output.dense.weight', 'base_model.encoder.layer.13.attention.self.value.bias', 'base_model.encoder.layer.7.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.10.attention.output.dense.weight', 'base_model.encoder.layer.14.attention.self.key.bias', 'base_model.encoder.layer.10.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.10.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.14.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.6.attention.self.key.weight', 'base_model.encoder.layer.11.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.12.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.16.attention.output.dense.weight', 'base_model.encoder.layer.17.output.LayerNorm.bias', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.9.attention.self.query.weight', 'base_model.encoder.layer.23.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.9.attention.output.LayerNorm.weight', 'base_model.encoder.layer.20.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.0.attention.self.key.bias', 'base_model.encoder.layer.12.intermediate.dense.weight', 'base_model.embeddings.token_type_embeddings.weight', 'base_model.encoder.layer.13.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.16.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.6.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.6.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.12.attention.output.dense.bias', 'base_model.encoder.layer.1.attention.self.key.bias', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.22.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.10.output.dense.bias', 'base_model.encoder.layer.10.attention.self.value.bias', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.2.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.23.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.1.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.12.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.3.attention.output.dense.bias', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.1.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.17.attention.output.dense.bias', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.19.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.4.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.16.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.11.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.19.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.19.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.5.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.7.output.LayerNorm.weight', 'base_model.encoder.layer.15.attention.self.key.weight', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.22.intermediate.dense.weight', 'base_model.encoder.layer.13.output.dense.bias', 'base_model.encoder.layer.16.attention.output.LayerNorm.weight', 'base_model.encoder.layer.0.intermediate.dense.weight', 'base_model.encoder.layer.12.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.0.intermediate.dense.bias', 'base_model.encoder.layer.8.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.11.intermediate.dense.bias', 'base_model.embeddings.LayerNorm.weight', 'base_model.encoder.layer.3.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.8.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.9.attention.self.key.bias', 'base_model.encoder.layer.12.attention.self.key.bias', 'base_model.encoder.layer.13.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.2.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.8.attention.self.query.bias', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.18.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.19.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.21.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.4.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.18.output.dense.weight', 'base_model.encoder.layer.5.intermediate.dense.bias', 'base_model.encoder.layer.1.attention.self.value.weight', 'base_model.encoder.layer.15.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.0.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.12.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.22.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.15.output.dense.bias', 'base_model.encoder.layer.4.attention.self.value.bias', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.13.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.21.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.19.intermediate.dense.weight', 'base_model.encoder.layer.20.output.dense.weight', 'base_model.encoder.layer.4.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.17.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.10.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.19.attention.self.key.weight', 'base_model.encoder.layer.16.intermediate.dense.weight', 'base_model.encoder.layer.14.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.2.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.0.output.LayerNorm.weight', 'base_model.encoder.layer.20.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.5.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.11.attention.output.LayerNorm.weight', 'base_model.encoder.layer.15.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.17.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.8.intermediate.dense.weight', 'base_model.encoder.layer.11.attention.output.LayerNorm.bias', 'base_model.encoder.layer.5.attention.self.query.weight', 'base_model.encoder.layer.12.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.13.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.17.attention.output.LayerNorm.weight', 'base_model.encoder.layer.9.output.LayerNorm.weight', 'base_model.encoder.layer.22.output.LayerNorm.weight', 'base_model.encoder.layer.22.output.LayerNorm.bias', 'base_model.encoder.layer.11.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.9.attention.self.query.bias', 'base_model.encoder.layer.7.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.18.attention.output.LayerNorm.weight', 'base_model.encoder.layer.22.attention.self.value.bias', 'base_model.encoder.layer.16.attention.self.value.bias', 'base_model.encoder.layer.7.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.2.attention.output.dense.bias', 'base_model.encoder.layer.10.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.12.output.dense.weight', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.23.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.4.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.20.attention.output.dense.bias', 'base_model.encoder.layer.4.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.3.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.14.attention.output.dense.bias', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.13.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.20.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.2.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.14.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.9.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.14.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.15.intermediate.dense.weight', 'base_model.encoder.layer.16.attention.self.query.weight', 'base_model.encoder.layer.1.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.6.attention.self.key.bias', 'base_model.encoder.layer.3.attention.self.value.bias', 'base_model.encoder.layer.16.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.18.output.LayerNorm.bias', 'base_model.encoder.layer.8.attention.self.key.weight', 'base_model.encoder.layer.4.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.5.attention.self.key.weight', 'base_model.encoder.layer.19.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.20.attention.output.LayerNorm.bias', 'base_model.encoder.layer.13.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.7.attention.self.value.bias', 'base_model.encoder.layer.19.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.1.output.dense.bias', 'base_model.encoder.layer.14.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.15.attention.output.LayerNorm.weight', 'base_model.encoder.layer.5.attention.self.value.bias', 'base_model.encoder.layer.14.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.23.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.9.intermediate.dense.bias', 'base_model.encoder.layer.14.output.LayerNorm.bias', 'base_model.encoder.layer.0.attention.self.key.weight', 'base_model.encoder.layer.15.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.22.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.7.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.11.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.6.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.4.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.8.output.dense.weight', 'base_model.encoder.layer.8.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.0.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.12.attention.output.dense.weight', 'base_model.encoder.layer.11.output.dense.bias', 'base_model.encoder.layer.8.attention.output.dense.bias', 'base_model.encoder.layer.7.attention.self.key.bias', 'base_model.encoder.layer.7.output.LayerNorm.bias', 'base_model.encoder.layer.10.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.12.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.0.output.dense.weight', 'base_model.encoder.layer.5.attention.output.LayerNorm.bias', 'base_model.encoder.layer.1.attention.self.value.bias', 'base_model.encoder.layer.6.attention.output.dense.bias', 'base_model.encoder.layer.18.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.16.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.12.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.5.intermediate.dense.weight', 'base_model.encoder.layer.0.output.dense.bias', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.8.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.23.attention.output.LayerNorm.weight', 'base_model.encoder.layer.2.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.0.attention.output.dense.weight', 'base_model.encoder.layer.0.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.14.attention.output.dense.weight', 'base_model.encoder.layer.4.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.17.output.dense.weight', 'base_model.encoder.layer.8.output.dense.bias', 'base_model.encoder.layer.17.intermediate.dense.bias', 'base_model.encoder.layer.13.attention.self.query.weight', 'base_model.encoder.layer.16.output.LayerNorm.bias', 'base_model.encoder.layer.6.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.1.output.dense.weight', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.17.attention.self.value.weight', 'base_model.encoder.layer.5.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.18.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.10.output.dense.weight', 'base_model.encoder.layer.15.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.4.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.20.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.18.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.8.attention.self.key.bias', 'base_model.encoder.layer.22.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.11.attention.self.value.weight', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.9.attention.output.dense.weight', 'base_model.encoder.layer.16.output.dense.weight', 'base_model.encoder.layer.17.attention.self.key.weight', 'base_model.encoder.layer.16.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.11.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.4.intermediate.dense.weight', 'base_model.encoder.layer.21.output.LayerNorm.weight', 'base_model.encoder.layer.19.intermediate.dense.bias', 'base_model.encoder.layer.6.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.10.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.22.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.23.attention.output.LayerNorm.bias', 'base_model.encoder.layer.6.attention.output.LayerNorm.bias', 'base_model.encoder.layer.2.attention.self.query.weight', 'base_model.encoder.layer.9.output.LayerNorm.bias', 'base_model.encoder.layer.23.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.19.attention.self.value.bias', 'base_model.encoder.layer.4.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.23.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.16.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.9.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.2.output.dense.bias', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.14.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.5.attention.self.key.bias', 'base_model.encoder.layer.14.intermediate.dense.bias', 'base_model.encoder.layer.21.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.9.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.3.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.3.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.11.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.12.attention.self.query.weight', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.21.attention.output.dense.weight', 'base_model.encoder.layer.18.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.7.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.2.attention.self.value.bias', 'base_model.encoder.layer.4.attention.self.key.weight', 'base_model.encoder.layer.8.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.22.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.23.attention.self.query.weight', 'base_model.encoder.layer.14.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.21.intermediate.dense.bias', 'base_model.encoder.layer.13.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.1.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.9.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.5.output.LayerNorm.weight', 'base_model.encoder.layer.13.attention.output.dense.weight', 'base_model.encoder.layer.20.attention.self.value.weight', 'base_model.encoder.layer.6.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.11.attention.self.value.bias', 'base_model.encoder.layer.22.attention.self.key.bias', 'base_model.encoder.layer.0.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.4.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.16.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.20.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.8.output.LayerNorm.bias', 'base_model.encoder.layer.12.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.4.attention.self.query.bias', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.1.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.8.attention.output.dense.weight', 'base_model.encoder.layer.21.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.13.intermediate.dense.bias', 'base_model.encoder.layer.7.attention.self.query.weight', 'base_model.encoder.layer.21.output.dense.weight', 'base_model.encoder.layer.7.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.8.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.20.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.16.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.10.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.19.attention.self.query.bias', 'base_model.encoder.layer.14.output.LayerNorm.weight', 'base_model.encoder.layer.19.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.22.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.5.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.15.attention.output.dense.bias', 'base_model.encoder.layer.3.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.0.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.21.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.3.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.12.attention.output.LayerNorm.weight', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.6.intermediate.dense.weight', 'base_model.encoder.layer.17.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.16.output.dense.bias', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.6.output.dense.weight', 'base_model.encoder.layer.15.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.21.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.20.attention.self.query.bias', 'base_model.encoder.layer.3.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.3.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.23.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.15.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.16.attention.self.key.bias', 'base_model.encoder.layer.9.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.12.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.10.attention.output.LayerNorm.bias', 'base_model.encoder.layer.15.attention.output.dense.weight', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.6.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.5.attention.output.dense.bias', 'base_model.encoder.layer.7.attention.self.value.weight', 'base_model.encoder.layer.8.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.12.attention.self.value.bias', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.23.attention.self.value.bias', 'base_model.encoder.layer.4.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.12.attention.output.LayerNorm.bias', 'base_model.encoder.layer.22.attention.self.value.weight', 'base_model.encoder.layer.6.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.7.attention.output.LayerNorm.weight', 'base_model.embeddings.position_ids', 'base_model.encoder.layer.22.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.2.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.6.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.8.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.1.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.8.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.5.output.LayerNorm.bias', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.7.attention.output.dense.weight', 'base_model.encoder.layer.10.attention.output.LayerNorm.weight', 'base_model.encoder.layer.10.attention.self.query.weight', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.4.attention.output.dense.bias', 'base_model.encoder.layer.5.attention.self.query.bias', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.6.attention.output.LayerNorm.weight', 'base_model.encoder.layer.7.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.9.output.dense.bias', 'base_model.encoder.layer.13.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.16.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.19.attention.output.dense.bias', 'base_model.encoder.layer.22.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.5.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.9.attention.output.dense.bias', 'base_model.encoder.layer.21.attention.output.LayerNorm.bias', 'base_model.encoder.layer.22.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.18.attention.self.query.weight', 'base_model.encoder.layer.16.intermediate.dense.bias', 'base_model.encoder.layer.15.output.LayerNorm.bias', 'base_model.encoder.layer.0.output.LayerNorm.bias', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.18.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.3.attention.self.query.weight', 'base_model.encoder.layer.13.attention.self.value.weight', 'base_model.encoder.layer.18.attention.self.value.weight', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.17.attention.self.query.bias', 'base_model.encoder.layer.19.output.dense.weight', 'base_model.encoder.layer.20.output.dense.bias', 'base_model.encoder.layer.2.attention.output.dense.weight', 'base_model.encoder.layer.20.attention.self.value.bias', 'base_model.encoder.layer.21.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.22.attention.output.LayerNorm.bias', 'base_model.encoder.layer.14.attention.output.LayerNorm.bias', 'base_model.encoder.layer.19.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.12.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.18.intermediate.dense.bias', 'base_model.encoder.layer.7.attention.output.dense.bias', 'base_model.encoder.layer.21.intermediate.dense.weight', 'base_model.encoder.layer.8.output.LayerNorm.weight', 'base_model.encoder.layer.23.attention.self.query.bias', 'base_model.encoder.layer.8.intermediate.dense.bias', 'base_model.encoder.layer.2.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.7.attention.output.LayerNorm.bias', 'base_model.encoder.layer.22.intermediate.dense.bias', 'base_model.encoder.layer.2.attention.output.LayerNorm.weight', 'base_model.encoder.layer.15.intermediate.dense.bias', 'base_model.encoder.layer.23.attention.self.value.weight', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.17.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.23.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.15.output.LayerNorm.weight', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.10.attention.self.key.bias', 'base_model.encoder.layer.10.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.18.attention.self.value.bias', 'base_model.encoder.layer.0.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.2.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.4.output.LayerNorm.bias', 'base_model.encoder.layer.6.output.dense.bias', 'base_model.encoder.layer.8.attention.output.LayerNorm.bias', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.6.output.LayerNorm.bias', 'base_model.encoder.layer.16.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.8.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.14.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.19.output.LayerNorm.weight', 'base_model.encoder.layer.12.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.3.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.21.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.17.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.2.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.5.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.23.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.1.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.22.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.14.attention.self.value.bias', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.17.attention.self.query.weight', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.12.attention.self.value.weight', 'base_model.encoder.layer.21.attention.output.LayerNorm.weight', 'base_model.embeddings.word_embeddings.weight', 'base_model.encoder.layer.2.intermediate.dense.weight', 'base_model.encoder.layer.11.output.dense.weight', 'base_model.encoder.layer.17.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.11.attention.self.key.weight', 'base_model.encoder.layer.22.output.dense.bias', 'base_model.encoder.layer.13.attention.self.key.bias', 'base_model.encoder.layer.2.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.19.attention.self.query.weight', 'base_model.encoder.layer.6.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.6.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.10.attention.self.query.bias', 'base_model.encoder.layer.1.intermediate.dense.bias', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.4.output.dense.bias', 'base_model.encoder.layer.18.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.23.attention.self.key.bias', 'base_model.encoder.layer.14.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.15.output.dense.weight', 'base_model.encoder.layer.4.intermediate.dense.bias', 'base_model.encoder.layer.0.attention.self.query.weight', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.17.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.3.output.LayerNorm.weight', 'base_model.encoder.layer.16.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.20.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.14.attention.output.LayerNorm.weight', 'base_model.encoder.layer.11.attention.self.key.bias', 'base_model.encoder.layer.11.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.2.output.dense.weight', 'base_model.encoder.layer.9.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.18.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.17.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.20.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.10.output.LayerNorm.weight', 'base_model.encoder.layer.14.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.13.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.17.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.7.attention.self.key.weight', 'base_model.encoder.layer.17.attention.output.dense.weight', 'base_model.encoder.layer.16.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.4.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.12.output.dense.bias', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.10.output.LayerNorm.bias', 'base_model.encoder.layer.1.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.1.output.LayerNorm.bias', 'base_model.encoder.layer.15.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.1.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.1.attention.output.LayerNorm.bias', 'base_model.encoder.layer.7.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.0.attention.output.dense.bias', 'base_model.encoder.layer.13.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.17.output.LayerNorm.weight', 'base_model.encoder.layer.20.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.13.attention.self.key.weight', 'base_model.encoder.layer.18.attention.self.key.bias', 'base_model.encoder.layer.3.attention.output.LayerNorm.bias', 'base_model.encoder.layer.21.output.LayerNorm.bias', 'base_model.encoder.layer.13.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.13.attention.output.dense.bias', 'base_model.encoder.layer.13.attention.self.query.bias', 'base_model.encoder.layer.20.intermediate.dense.weight', 'base_model.encoder.layer.10.attention.self.value.weight', 'base_model.encoder.layer.19.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.23.output.dense.bias', 'base_model.encoder.layer.9.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.16.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.11.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.1.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.8.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.13.output.LayerNorm.bias', 'base_model.encoder.layer.23.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.21.attention.self.value.weight', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.15.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.10.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.10.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.19.attention.self.key.bias', 'base_model.encoder.layer.20.intermediate.dense.bias', 'base_model.encoder.layer.6.attention.self.value.weight', 'base_model.encoder.layer.2.output.LayerNorm.weight', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.12.output.LayerNorm.weight', 'base_model.encoder.layer.13.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.19.attention.self.value.weight', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.12.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.6.attention.output.dense.weight', 'base_model.encoder.layer.19.output.LayerNorm.bias', 'base_model.encoder.layer.9.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.5.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.12.attention.self.query.bias', 'base_model.encoder.layer.15.attention.output.LayerNorm.bias', 'base_model.encoder.layer.6.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.7.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.21.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.10.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.20.output.LayerNorm.bias', 'base_model.encoder.layer.9.attention.self.key.weight', 'base_model.encoder.layer.13.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.15.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.5.output.dense.bias', 'base_model.encoder.layer.8.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.6.intermediate.dense.bias', 'base_model.encoder.layer.9.attention.self.value.bias', 'base_model.encoder.layer.8.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.18.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.6.attention.self.query.weight', 'base_model.encoder.layer.7.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.7.output.dense.bias', 'base_model.encoder.layer.23.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.22.output.dense.weight', 'base_model.encoder.layer.12.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.2.attention.self.key.weight', 'base_model.encoder.layer.15.attention.self.query.bias', 'base_model.encoder.layer.16.attention.output.LayerNorm.bias', 'base_model.encoder.layer.19.attention.output.dense.weight', 'base_model.encoder.layer.5.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.15.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.23.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.15.attention.self.value.bias', 'base_model.encoder.layer.18.attention.output.LayerNorm.bias', 'base_model.encoder.layer.22.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.0.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.19.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.3.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.6.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.16.attention.output.dense.bias', 'base_model.encoder.layer.2.attention.output.LayerNorm.bias', 'base_model.encoder.layer.1.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.9.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.14.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.17.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.20.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.16.attention.self.key.weight', 'base_model.encoder.layer.7.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.10.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.16.attention.self.value.weight', 'base_model.encoder.layer.17.intermediate.dense.weight', 'base_model.encoder.layer.18.output.dense.bias', 'base_model.encoder.layer.1.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.10.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.9.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.11.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.3.output.dense.weight', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.18.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.3.attention.output.LayerNorm.weight', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.5.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.11.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.0.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.6.attention.self.value.bias', 'base_model.encoder.layer.2.output.LayerNorm.bias', 'base_model.encoder.layer.6.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.21.output.dense.bias', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.3.intermediate.dense.bias', 'base_model.encoder.layer.3.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.10.intermediate.dense.bias', 'base_model.encoder.layer.19.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.18.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.14.attention.self.query.bias', 'base_model.encoder.layer.15.attention.self.value.weight', 'base_model.encoder.layer.19.output.dense.bias', 'base_model.encoder.layer.17.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.20.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.5.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.3.attention.self.value.weight', 'base_model.encoder.layer.14.output.dense.bias', 'base_model.encoder.layer.1.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.6.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.7.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.3.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.2.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.21.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.3.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.4.attention.self.query.weight', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.0.attention.self.query.bias', 'base_model.encoder.layer.17.attention.output.LayerNorm.bias', 'base_model.encoder.layer.13.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.5.attention.self.value.weight', 'base_model.encoder.layer.8.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.1.attention.output.LayerNorm.weight', 'base_model.encoder.layer.15.attention.self.key.bias', 'base_model.encoder.layer.18.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.22.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.11.output.LayerNorm.bias', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.21.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.15.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.23.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.12.output.LayerNorm.bias', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.15.attention.self.query.weight', 'base_model.encoder.layer.7.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.7.intermediate.dense.bias', 'base_model.encoder.layer.4.attention.self.value.weight', 'base_model.pooler.dense.bias', 'base_model.encoder.layer.4.attention.output.dense.weight', 'base_model.encoder.layer.8.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.15.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.9.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.17.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.7.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.8.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.7.attention.self.query.bias', 'base_model.encoder.layer.18.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.9.output.dense.weight', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.13.intermediate.dense.weight', 'base_model.encoder.layer.11.intermediate.dense.weight', 'base_model.encoder.layer.19.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.17.attention.self.key.bias', 'base_model.encoder.layer.21.attention.self.query.weight', 'base_model.encoder.layer.17.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.5.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.16.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.2.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.2.attention.self.query.bias', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.7.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.3.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.3.attention.output.dense.weight', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.embeddings.position_embeddings.weight', 'base_model.encoder.layer.18.attention.output.dense.weight', 'base_model.encoder.layer.12.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.14.output.adapters.es.adapter_up.bias', 'qa_outputs.weight', 'base_model.encoder.layer.3.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.0.attention.self.value.weight', 'base_model.encoder.layer.20.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.15.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.9.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.13.attention.output.LayerNorm.weight', 'base_model.encoder.layer.0.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.5.output.dense.weight', 'base_model.encoder.layer.9.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.10.attention.output.dense.bias', 'base_model.encoder.layer.18.attention.self.key.weight', 'base_model.encoder.layer.20.attention.self.key.bias', 'base_model.encoder.layer.3.output.dense.bias', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.23.output.LayerNorm.weight', 'base_model.encoder.layer.1.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.14.intermediate.dense.weight', 'base_model.encoder.layer.1.attention.output.dense.bias', 'base_model.encoder.layer.3.intermediate.dense.weight', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.0.attention.output.LayerNorm.weight', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.23.attention.output.dense.weight', 'base_model.encoder.layer.18.attention.self.query.bias', 'base_model.encoder.layer.16.output.LayerNorm.weight', 'base_model.encoder.layer.21.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.19.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.21.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.20.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.20.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.3.attention.self.key.weight', 'base_model.encoder.layer.1.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.4.output.dense.weight', 'base_model.encoder.layer.11.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.17.attention.self.value.bias', 'base_model.encoder.layer.3.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.18.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.11.attention.self.query.weight', 'base_model.encoder.layer.21.attention.self.key.weight', 'base_model.encoder.layer.2.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.5.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.14.attention.self.key.weight', 'base_model.encoder.layer.23.intermediate.dense.bias', 'base_model.encoder.layer.13.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.18.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.13.output.dense.weight', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.1.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.23.attention.output.dense.bias', 'base_model.encoder.layer.8.attention.output.LayerNorm.weight', 'base_model.encoder.layer.11.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.21.attention.self.key.bias', 'base_model.encoder.layer.23.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.12.attention.self.key.weight', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.23.output.LayerNorm.bias', 'base_model.encoder.layer.14.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.18.attention.output.dense.bias', 'base_model.encoder.layer.23.intermediate.dense.weight', 'base_model.encoder.layer.19.attention.output.LayerNorm.weight', 'base_model.encoder.layer.5.attention.output.LayerNorm.weight', 'base_model.encoder.layer.8.attention.self.value.bias', 'base_model.encoder.layer.12.intermediate.dense.bias', 'base_model.encoder.layer.0.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.20.attention.output.LayerNorm.weight', 'base_model.encoder.layer.17.output.dense.bias', 'base_model.encoder.layer.19.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.3.attention.self.key.bias', 'base_model.encoder.layer.9.attention.output.LayerNorm.bias', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.4.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.1.attention.output.dense.weight', 'base_model.encoder.layer.14.attention.self.value.weight', 'base_model.encoder.layer.14.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.16.attention.self.query.bias', 'base_model.encoder.layer.18.intermediate.dense.weight', 'base_model.encoder.layer.21.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.13.attention.output.LayerNorm.bias', 'base_model.encoder.layer.0.attention.self.value.bias', 'base_model.encoder.layer.17.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.5.attention.output.dense.weight', 'base_model.encoder.layer.11.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.11.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.10.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.21.attention.self.value.bias', 'base_model.encoder.layer.20.attention.self.query.weight', 'base_model.encoder.layer.5.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.17.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.0.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.2.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.11.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.8.attention.self.query.weight', 'base_model.encoder.layer.4.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.9.attention.self.value.weight', 'base_model.encoder.layer.13.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.22.attention.output.LayerNorm.weight', 'base_model.encoder.layer.2.attention.self.key.bias', 'base_model.encoder.layer.3.attention.self.query.bias', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.9.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.11.attention.output.dense.bias', 'base_model.encoder.layer.21.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.22.attention.output.dense.weight', 'base_model.encoder.layer.23.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.6.attention.self.query.bias', 'base_model.encoder.layer.22.attention.output.dense.bias', 'base_model.encoder.layer.8.attention.self.value.weight', 'base_model.encoder.layer.16.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.22.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.2.attention.self.value.weight', 'base_model.encoder.layer.20.attention.output.dense.weight', 'base_model.encoder.layer.6.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.11.output.LayerNorm.weight', 'base_model.encoder.layer.21.attention.self.query.bias', 'base_model.encoder.layer.1.attention.self.query.weight', 'base_model.encoder.layer.10.intermediate.dense.weight', 'base_model.encoder.layer.20.attention.self.key.weight', 'base_model.encoder.layer.6.output.LayerNorm.weight', 'base_model.encoder.layer.0.attention.output.LayerNorm.bias', 'base_model.encoder.layer.17.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.22.attention.self.query.weight', 'base_model.encoder.layer.9.intermediate.dense.weight', 'base_model.encoder.layer.20.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.7.output.dense.weight', 'base_model.encoder.layer.5.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.16.output.adapters.ts.adapter_up.bias', 'base_model.embeddings.LayerNorm.bias', 'base_model.encoder.layer.1.output.LayerNorm.weight', 'base_model.encoder.layer.11.attention.self.query.bias', 'base_model.encoder.layer.19.attention.output.LayerNorm.bias', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.22.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.4.attention.output.LayerNorm.bias', 'base_model.encoder.layer.20.output.LayerNorm.weight', 'base_model.encoder.layer.4.attention.output.LayerNorm.weight', 'base_model.encoder.layer.0.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.14.output.dense.weight', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.9.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.11.attention.output.dense.weight', 'base_model.encoder.layer.0.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.15.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.22.attention.self.query.bias', 'base_model.encoder.layer.18.output.LayerNorm.weight', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.5.output.adapters.tp.adapter_up.bias', 'qa_outputs.bias', 'base_model.encoder.layer.12.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.23.output.adapters.tp.adapter_up.bias', 'base_model.pooler.dense.weight', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.10.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.15.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.2.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.18.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.20.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.9.output.adapters.ts.adapter_down.0.bias']
- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of XLMRobertaModel were not initialized from the model checkpoint at /cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//squad/xlm-KG_LR3e-5_EPOCH2.0_maxlen384_batchsize4_gradacc4 and are newly initialized: ['encoder.layer.8.attention.self.query.bias', 'encoder.layer.5.attention.output.dense.bias', 'encoder.layer.20.attention.self.value.bias', 'encoder.layer.11.attention.self.query.weight', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.16.output.LayerNorm.weight', 'encoder.layer.20.intermediate.dense.weight', 'encoder.layer.21.intermediate.dense.bias', 'encoder.layer.12.attention.self.query.bias', 'encoder.layer.3.attention.output.dense.weight', 'encoder.layer.12.attention.self.key.bias', 'encoder.layer.16.output.LayerNorm.bias', 'encoder.layer.22.output.LayerNorm.bias', 'encoder.layer.9.attention.self.value.bias', 'encoder.layer.10.attention.self.key.weight', 'encoder.layer.0.output.dense.weight', 'encoder.layer.20.output.LayerNorm.bias', 'encoder.layer.10.attention.output.dense.weight', 'encoder.layer.13.attention.self.query.weight', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.4.attention.self.query.bias', 'encoder.layer.17.attention.output.dense.weight', 'encoder.layer.20.output.LayerNorm.weight', 'encoder.layer.23.attention.output.LayerNorm.weight', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.19.output.LayerNorm.bias', 'encoder.layer.0.attention.output.dense.bias', 'encoder.layer.15.output.LayerNorm.bias', 'encoder.layer.0.attention.self.query.weight', 'encoder.layer.20.attention.self.key.bias', 'encoder.layer.11.attention.self.value.bias', 'encoder.layer.3.attention.self.key.bias', 'encoder.layer.5.attention.self.query.weight', 'encoder.layer.22.intermediate.dense.bias', 'encoder.layer.8.output.LayerNorm.weight', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.6.output.LayerNorm.bias', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.3.attention.self.value.bias', 'encoder.layer.8.attention.self.value.bias', 'encoder.layer.19.attention.self.key.weight', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.21.attention.self.value.bias', 'encoder.layer.2.attention.self.key.bias', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.10.attention.output.LayerNorm.bias', 'encoder.layer.5.attention.self.value.weight', 'encoder.layer.4.attention.self.query.weight', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.layer.21.attention.output.LayerNorm.weight', 'encoder.layer.20.output.dense.bias', 'encoder.layer.18.attention.self.value.weight', 'encoder.layer.10.intermediate.dense.weight', 'encoder.layer.20.attention.self.key.weight', 'encoder.layer.18.attention.self.key.bias', 'encoder.layer.23.output.LayerNorm.bias', 'encoder.layer.22.attention.self.query.weight', 'encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.layer.23.attention.output.dense.bias', 'encoder.layer.4.attention.self.key.bias', 'encoder.layer.15.output.LayerNorm.weight', 'encoder.layer.23.attention.self.query.weight', 'encoder.layer.20.attention.self.query.weight', 'encoder.layer.7.attention.self.value.bias', 'encoder.layer.17.output.dense.weight', 'encoder.layer.10.output.dense.bias', 'encoder.layer.6.attention.self.value.weight', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.18.intermediate.dense.bias', 'encoder.layer.20.attention.output.LayerNorm.bias', 'encoder.layer.21.output.dense.weight', 'encoder.layer.22.attention.output.dense.weight', 'encoder.layer.8.output.LayerNorm.bias', 'encoder.layer.13.attention.output.dense.weight', 'encoder.layer.6.attention.self.value.bias', 'encoder.layer.17.output.LayerNorm.weight', 'encoder.layer.7.attention.self.query.bias', 'encoder.layer.20.attention.output.dense.weight', 'encoder.layer.21.output.dense.bias', 'encoder.layer.9.attention.output.LayerNorm.weight', 'encoder.layer.19.output.LayerNorm.weight', 'encoder.layer.19.attention.self.value.weight', 'encoder.layer.16.attention.output.LayerNorm.weight', 'encoder.layer.12.attention.self.key.weight', 'encoder.layer.5.intermediate.dense.weight', 'embeddings.LayerNorm.bias', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.13.intermediate.dense.bias', 'encoder.layer.14.output.dense.bias', 'encoder.layer.14.attention.output.dense.weight', 'encoder.layer.16.attention.output.dense.weight', 'encoder.layer.0.attention.self.key.bias', 'encoder.layer.15.attention.self.key.bias', 'encoder.layer.10.attention.self.key.bias', 'encoder.layer.22.output.LayerNorm.weight', 'encoder.layer.16.attention.self.query.weight', 'encoder.layer.22.attention.output.LayerNorm.weight', 'encoder.layer.23.intermediate.dense.weight', 'encoder.layer.1.output.dense.weight', 'encoder.layer.14.intermediate.dense.bias', 'encoder.layer.11.output.LayerNorm.bias', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.21.intermediate.dense.weight', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.16.attention.self.value.weight', 'encoder.layer.2.output.dense.weight', 'encoder.layer.20.attention.self.value.weight', 'encoder.layer.10.attention.output.dense.bias', 'encoder.layer.5.output.dense.bias', 'encoder.layer.7.attention.output.dense.weight', 'encoder.layer.17.attention.self.query.weight', 'encoder.layer.1.attention.self.value.bias', 'encoder.layer.15.attention.self.query.weight', 'encoder.layer.6.attention.self.key.weight', 'encoder.layer.11.attention.self.value.weight', 'encoder.layer.3.attention.self.key.weight', 'encoder.layer.17.attention.self.value.weight', 'encoder.layer.13.output.dense.weight', 'encoder.layer.15.attention.self.value.bias', 'encoder.layer.23.attention.output.dense.weight', 'encoder.layer.23.output.dense.weight', 'encoder.layer.17.attention.output.LayerNorm.weight', 'encoder.layer.23.attention.self.value.bias', 'encoder.layer.12.output.dense.bias', 'encoder.layer.15.output.dense.weight', 'encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.layer.18.intermediate.dense.weight', 'encoder.layer.4.attention.self.key.weight', 'encoder.layer.19.attention.self.key.bias', 'encoder.layer.20.attention.self.query.bias', 'encoder.layer.8.output.dense.bias', 'encoder.layer.19.attention.output.dense.bias', 'encoder.layer.1.attention.self.key.weight', 'encoder.layer.6.attention.output.LayerNorm.bias', 'encoder.layer.0.attention.output.dense.weight', 'encoder.layer.13.output.LayerNorm.bias', 'encoder.layer.12.attention.self.value.weight', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.layer.17.attention.self.key.weight', 'encoder.layer.4.attention.output.LayerNorm.bias', 'encoder.layer.5.attention.self.key.bias', 'encoder.layer.18.attention.self.key.weight', 'pooler.dense.weight', 'encoder.layer.18.attention.self.value.bias', 'encoder.layer.19.attention.self.query.weight', 'encoder.layer.3.attention.self.value.weight', 'encoder.layer.18.output.LayerNorm.bias', 'encoder.layer.12.attention.output.dense.weight', 'encoder.layer.15.intermediate.dense.bias', 'encoder.layer.11.attention.self.key.bias', 'encoder.layer.16.attention.output.dense.bias', 'encoder.layer.12.output.dense.weight', 'encoder.layer.14.attention.self.query.bias', 'encoder.layer.21.attention.self.query.bias', 'encoder.layer.9.output.dense.bias', 'encoder.layer.11.attention.output.dense.bias', 'encoder.layer.14.attention.output.LayerNorm.weight', 'encoder.layer.21.attention.self.query.weight', 'encoder.layer.0.attention.self.query.bias', 'encoder.layer.0.attention.self.value.bias', 'encoder.layer.8.attention.self.value.weight', 'encoder.layer.6.attention.output.LayerNorm.weight', 'encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.layer.3.attention.self.query.weight', 'encoder.layer.14.output.dense.weight', 'encoder.layer.13.attention.self.key.weight', 'encoder.layer.16.attention.self.key.weight', 'encoder.layer.9.attention.self.value.weight', 'encoder.layer.11.attention.self.query.bias', 'encoder.layer.13.intermediate.dense.weight', 'encoder.layer.1.attention.self.query.bias', 'encoder.layer.21.attention.output.dense.weight', 'encoder.layer.17.attention.self.value.bias', 'encoder.layer.13.output.dense.bias', 'encoder.layer.10.attention.self.query.weight', 'encoder.layer.6.output.dense.bias', 'encoder.layer.21.attention.output.dense.bias', 'encoder.layer.19.attention.self.query.bias', 'encoder.layer.20.attention.output.dense.bias', 'encoder.layer.23.output.LayerNorm.weight', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.2.attention.self.value.weight', 'encoder.layer.15.attention.self.key.weight', 'encoder.layer.15.attention.self.query.bias', 'encoder.layer.8.attention.self.query.weight', 'encoder.layer.13.attention.output.LayerNorm.weight', 'encoder.layer.14.intermediate.dense.weight', 'encoder.layer.16.attention.self.key.bias', 'encoder.layer.5.attention.output.LayerNorm.weight', 'encoder.layer.22.attention.self.key.weight', 'encoder.layer.13.attention.self.value.bias', 'encoder.layer.18.attention.self.query.bias', 'encoder.layer.23.attention.self.value.weight', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.19.intermediate.dense.weight', 'encoder.layer.9.attention.self.key.bias', 'encoder.layer.14.attention.output.dense.bias', 'encoder.layer.1.attention.self.value.weight', 'encoder.layer.1.attention.output.dense.bias', 'encoder.layer.10.attention.self.value.bias', 'encoder.layer.12.attention.output.dense.bias', 'encoder.layer.7.output.dense.weight', 'encoder.layer.19.output.dense.weight', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.8.attention.self.key.bias', 'encoder.layer.2.attention.output.LayerNorm.weight', 'encoder.layer.3.output.dense.weight', 'encoder.layer.23.attention.self.key.bias', 'encoder.layer.12.attention.output.LayerNorm.weight', 'encoder.layer.0.attention.self.key.weight', 'encoder.layer.18.attention.output.dense.bias', 'encoder.layer.5.attention.output.dense.weight', 'encoder.layer.18.output.dense.weight', 'encoder.layer.11.attention.output.dense.weight', 'encoder.layer.15.attention.output.LayerNorm.bias', 'encoder.layer.15.attention.output.LayerNorm.weight', 'encoder.layer.13.attention.self.query.bias', 'encoder.layer.23.attention.output.LayerNorm.bias', 'encoder.layer.8.attention.self.key.weight', 'encoder.layer.7.intermediate.dense.bias', 'encoder.layer.0.output.dense.bias', 'encoder.layer.10.output.LayerNorm.bias', 'encoder.layer.19.attention.self.value.bias', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.4.attention.self.value.weight', 'encoder.layer.13.attention.output.dense.bias', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.9.attention.output.LayerNorm.bias', 'encoder.layer.5.output.dense.weight', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.7.output.dense.bias', 'encoder.layer.7.attention.self.key.bias', 'encoder.layer.23.attention.self.query.bias', 'encoder.layer.2.attention.self.query.weight', 'encoder.layer.18.attention.self.query.weight', 'encoder.layer.8.attention.output.dense.weight', 'encoder.layer.0.intermediate.dense.bias', 'pooler.dense.bias', 'encoder.layer.22.intermediate.dense.weight', 'encoder.layer.4.attention.output.LayerNorm.weight', 'encoder.layer.10.output.dense.weight', 'encoder.layer.19.attention.output.LayerNorm.weight', 'encoder.layer.6.attention.output.dense.bias', 'encoder.layer.5.output.LayerNorm.bias', 'embeddings.token_type_embeddings.weight', 'encoder.layer.22.output.dense.weight', 'encoder.layer.9.output.LayerNorm.weight', 'encoder.layer.6.output.dense.weight', 'encoder.layer.18.output.dense.bias', 'encoder.layer.22.attention.output.dense.bias', 'encoder.layer.16.output.dense.bias', 'encoder.layer.2.output.dense.bias', 'encoder.layer.4.output.dense.weight', 'encoder.layer.13.attention.output.LayerNorm.bias', 'encoder.layer.9.attention.output.dense.bias', 'encoder.layer.7.attention.self.value.weight', 'embeddings.position_embeddings.weight', 'encoder.layer.7.attention.output.dense.bias', 'encoder.layer.23.attention.self.key.weight', 'encoder.layer.2.attention.output.dense.weight', 'encoder.layer.17.intermediate.dense.weight', 'encoder.layer.11.attention.output.LayerNorm.weight', 'encoder.layer.1.attention.output.LayerNorm.weight', 'encoder.layer.5.attention.self.query.bias', 'encoder.layer.4.attention.self.value.bias', 'encoder.layer.7.attention.self.query.weight', 'encoder.layer.14.attention.self.query.weight', 'encoder.layer.4.attention.output.dense.bias', 'encoder.layer.18.attention.output.LayerNorm.weight', 'encoder.layer.7.attention.output.LayerNorm.bias', 'encoder.layer.9.attention.self.query.bias', 'encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.layer.12.output.LayerNorm.weight', 'encoder.layer.16.attention.self.value.bias', 'encoder.layer.17.output.LayerNorm.bias', 'encoder.layer.11.output.dense.bias', 'encoder.layer.6.attention.self.query.weight', 'encoder.layer.22.attention.self.value.bias', 'encoder.layer.14.attention.output.LayerNorm.bias', 'encoder.layer.23.output.dense.bias', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.14.attention.self.key.bias', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.22.attention.self.query.bias', 'encoder.layer.20.output.dense.weight', 'encoder.layer.1.attention.output.dense.weight', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.6.attention.self.key.bias', 'encoder.layer.11.output.LayerNorm.weight', 'encoder.layer.6.attention.output.dense.weight', 'encoder.layer.21.attention.self.value.weight', 'encoder.layer.17.output.dense.bias', 'encoder.layer.14.attention.self.value.bias', 'encoder.layer.17.attention.output.dense.bias', 'encoder.layer.9.attention.self.key.weight', 'encoder.layer.4.attention.output.dense.weight', 'encoder.layer.15.output.dense.bias', 'encoder.layer.10.attention.self.query.bias', 'encoder.layer.12.attention.self.value.bias', 'encoder.layer.10.attention.output.LayerNorm.weight', 'encoder.layer.12.attention.self.query.weight', 'encoder.layer.0.attention.self.value.weight', 'encoder.layer.11.attention.self.key.weight', 'encoder.layer.19.attention.output.LayerNorm.bias', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.21.attention.output.LayerNorm.bias', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.14.output.LayerNorm.bias', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.12.output.LayerNorm.bias', 'embeddings.word_embeddings.weight', 'encoder.layer.18.attention.output.LayerNorm.bias', 'encoder.layer.7.output.LayerNorm.bias', 'encoder.layer.20.intermediate.dense.bias', 'encoder.layer.5.attention.self.key.weight', 'encoder.layer.16.attention.self.query.bias', 'encoder.layer.21.output.LayerNorm.weight', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.13.attention.self.value.weight', 'encoder.layer.21.attention.self.key.weight', 'encoder.layer.2.attention.self.query.bias', 'encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.9.attention.output.dense.weight', 'encoder.layer.22.attention.output.LayerNorm.bias', 'encoder.layer.12.intermediate.dense.weight', 'encoder.layer.20.attention.output.LayerNorm.weight', 'encoder.layer.8.attention.output.LayerNorm.weight', 'encoder.layer.2.attention.output.dense.bias', 'encoder.layer.9.attention.self.query.weight', 'encoder.layer.3.output.dense.bias', 'encoder.layer.22.attention.self.key.bias', 'encoder.layer.7.attention.output.LayerNorm.weight', 'encoder.layer.10.output.LayerNorm.weight', 'encoder.layer.7.output.LayerNorm.weight', 'encoder.layer.14.attention.self.value.weight', 'encoder.layer.7.attention.self.key.weight', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.16.intermediate.dense.weight', 'encoder.layer.16.output.dense.weight', 'encoder.layer.5.attention.self.value.bias', 'encoder.layer.9.output.LayerNorm.bias', 'encoder.layer.15.attention.self.value.weight', 'encoder.layer.2.attention.output.LayerNorm.bias', 'encoder.layer.13.output.LayerNorm.weight', 'encoder.layer.8.attention.output.dense.bias', 'encoder.layer.16.attention.output.LayerNorm.bias', 'encoder.layer.8.attention.output.LayerNorm.bias', 'encoder.layer.17.intermediate.dense.bias', 'encoder.layer.1.attention.self.query.weight', 'encoder.layer.16.intermediate.dense.bias', 'encoder.layer.1.attention.self.key.bias', 'embeddings.LayerNorm.weight', 'encoder.layer.21.attention.self.key.bias', 'encoder.layer.14.attention.self.key.weight', 'encoder.layer.8.output.dense.weight', 'encoder.layer.1.output.dense.bias', 'encoder.layer.21.output.LayerNorm.bias', 'encoder.layer.15.attention.output.dense.bias', 'encoder.layer.3.attention.output.dense.bias', 'encoder.layer.12.intermediate.dense.bias', 'encoder.layer.0.attention.output.LayerNorm.weight', 'encoder.layer.17.attention.self.query.bias', 'encoder.layer.6.attention.self.query.bias', 'encoder.layer.2.attention.self.key.weight', 'encoder.layer.2.attention.self.value.bias', 'encoder.layer.10.attention.self.value.weight', 'encoder.layer.15.intermediate.dense.weight', 'encoder.layer.12.attention.output.LayerNorm.bias', 'encoder.layer.19.intermediate.dense.bias', 'encoder.layer.19.attention.output.dense.weight', 'encoder.layer.22.output.dense.bias', 'encoder.layer.23.intermediate.dense.bias', 'encoder.layer.4.output.dense.bias', 'encoder.layer.13.attention.self.key.bias', 'encoder.layer.22.attention.self.value.weight', 'encoder.layer.14.output.LayerNorm.weight', 'encoder.layer.11.output.dense.weight', 'encoder.layer.9.output.dense.weight', 'encoder.layer.3.attention.self.query.bias', 'encoder.layer.19.output.dense.bias', 'encoder.layer.17.attention.self.key.bias', 'encoder.layer.17.attention.output.LayerNorm.bias', 'encoder.layer.18.output.LayerNorm.weight', 'encoder.layer.18.attention.output.dense.weight', 'encoder.layer.15.attention.output.dense.weight', 'encoder.layer.6.intermediate.dense.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Overwriting existing adapter 'ep'.
Overwriting existing adapter 'tp'.
Overwriting existing adapter 'es'.
Overwriting existing adapter 'ts'.
Overwriting existing adapter fusion module 'ep,tp,es,ts'
05/09/2022 09:04:03 - INFO - __main__ -   Creating features from dataset file at .
/cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//squad/xlm-KG_LR3e-5_EPOCH2.0_maxlen384_batchsize4_gradacc4
XLMConfig {
  "architectures": [
    "XLMRobertaForMaskedLM"
  ],
  "asm": false,
  "attention_dropout": 0.1,
  "attention_probs_dropout_prob": 0.1,
  "bos_index": 0,
  "bos_token_id": 0,
  "causal": false,
  "dropout": 0.1,
  "emb_dim": 1024,
  "embed_init_std": 0.02209708691207961,
  "end_n_top": 5,
  "eos_index": 1,
  "eos_token_id": 2,
  "gelu_activation": true,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "init_std": 0.02,
  "initializer_range": 0.02,
  "intermediate_size": 4096,
  "is_encoder": true,
  "lang_id": 0,
  "layer_norm_eps": 1e-05,
  "mask_index": 5,
  "mask_token_id": 0,
  "max_position_embeddings": 514,
  "model_type": "xlm",
  "n_heads": 16,
  "n_langs": 1,
  "n_layers": 24,
  "output_past": true,
  "pad_index": 2,
  "pad_token_id": 1,
  "sinusoidal_embeddings": false,
  "start_n_top": 5,
  "summary_activation": null,
  "summary_first_dropout": 0.1,
  "summary_proj_to_labels": true,
  "summary_type": "first",
  "summary_use_proj": true,
  "transformers_version": "4.17.0",
  "type_vocab_size": 1,
  "unk_index": 3,
  "use_lang_emb": false,
  "vocab_size": 250002
}

  0%|          | 0/48 [00:00<?, ?it/s] 17%|█▋        | 8/48 [00:00<00:00, 76.48it/s] 33%|███▎      | 16/48 [00:00<00:00, 58.56it/s] 48%|████▊     | 23/48 [00:00<00:00, 57.38it/s] 60%|██████    | 29/48 [00:00<00:00, 56.27it/s] 75%|███████▌  | 36/48 [00:00<00:00, 60.47it/s] 92%|█████████▏| 44/48 [00:00<00:00, 64.51it/s]100%|██████████| 48/48 [00:00<00:00, 62.91it/s]
convert squad examples to features:   0%|          | 0/1190 [00:00<?, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.
convert squad examples to features:   0%|          | 1/1190 [00:00<04:22,  4.53it/s]convert squad examples to features:   3%|▎         | 33/1190 [00:00<00:10, 106.05it/s]convert squad examples to features:   5%|▌         | 65/1190 [00:00<00:09, 124.96it/s]convert squad examples to features:   8%|▊         | 97/1190 [00:00<00:06, 158.63it/s]convert squad examples to features:  11%|█         | 129/1190 [00:00<00:05, 183.44it/s]convert squad examples to features:  14%|█▎        | 161/1190 [00:00<00:05, 201.77it/s]convert squad examples to features:  16%|█▌        | 193/1190 [00:01<00:04, 210.42it/s]convert squad examples to features:  19%|█▉        | 225/1190 [00:01<00:04, 204.22it/s]convert squad examples to features:  22%|██▏       | 257/1190 [00:01<00:05, 165.52it/s]convert squad examples to features:  24%|██▍       | 289/1190 [00:01<00:05, 164.24it/s]convert squad examples to features:  27%|██▋       | 321/1190 [00:01<00:05, 159.33it/s]convert squad examples to features:  30%|██▉       | 353/1190 [00:02<00:05, 155.44it/s]convert squad examples to features:  32%|███▏      | 385/1190 [00:03<00:10, 76.41it/s] convert squad examples to features:  35%|███▌      | 417/1190 [00:03<00:09, 80.14it/s]convert squad examples to features:  38%|███▊      | 449/1190 [00:03<00:08, 85.80it/s]convert squad examples to features:  40%|████      | 481/1190 [00:04<00:07, 96.36it/s]convert squad examples to features:  43%|████▎     | 513/1190 [00:04<00:06, 101.47it/s]convert squad examples to features:  46%|████▌     | 545/1190 [00:04<00:06, 99.05it/s] convert squad examples to features:  48%|████▊     | 577/1190 [00:04<00:05, 105.34it/s]convert squad examples to features:  51%|█████     | 609/1190 [00:05<00:05, 98.96it/s] convert squad examples to features:  54%|█████▍    | 641/1190 [00:05<00:05, 100.45it/s]convert squad examples to features:  57%|█████▋    | 673/1190 [00:05<00:05, 96.93it/s] convert squad examples to features:  59%|█████▉    | 705/1190 [00:06<00:04, 103.65it/s]convert squad examples to features:  62%|██████▏   | 737/1190 [00:06<00:04, 110.00it/s]convert squad examples to features:  65%|██████▍   | 769/1190 [00:06<00:03, 119.50it/s]convert squad examples to features:  67%|██████▋   | 801/1190 [00:06<00:03, 126.75it/s]convert squad examples to features:  70%|███████   | 833/1190 [00:07<00:03, 109.10it/s]convert squad examples to features:  73%|███████▎  | 865/1190 [00:07<00:02, 118.50it/s]convert squad examples to features:  75%|███████▌  | 897/1190 [00:07<00:02, 108.37it/s]convert squad examples to features:  78%|███████▊  | 929/1190 [00:08<00:02, 111.09it/s]convert squad examples to features:  81%|████████  | 961/1190 [00:08<00:02, 113.50it/s]convert squad examples to features:  83%|████████▎ | 993/1190 [00:08<00:01, 122.71it/s]convert squad examples to features:  86%|████████▌ | 1025/1190 [00:08<00:01, 131.19it/s]convert squad examples to features:  89%|████████▉ | 1057/1190 [00:08<00:00, 135.96it/s]convert squad examples to features:  92%|█████████▏| 1089/1190 [00:09<00:00, 139.27it/s]convert squad examples to features:  94%|█████████▍| 1121/1190 [00:09<00:00, 129.94it/s]convert squad examples to features:  97%|█████████▋| 1153/1190 [00:09<00:00, 120.76it/s]convert squad examples to features: 100%|██████████| 1190/1190 [00:09<00:00, 121.14it/s]/cluster/project/sachan/yifan/softwares/anaconda/anaconda3/envs/xfactr/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2272: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

add example index and unique id:   0%|          | 0/1190 [00:00<?, ?it/s]add example index and unique id: 100%|██████████| 1190/1190 [00:00<00:00, 389543.57it/s]
05/09/2022 09:04:14 - INFO - __main__ -   Saving features into cached file ./cached_xquad.el.json_xlm-KG_LR3e-5_EPOCH2.0_maxlen384_batchsize4_gradacc4_384_el
05/09/2022 09:04:16 - INFO - __main__ -   ***** Running evaluation  *****
05/09/2022 09:04:16 - INFO - __main__ -     Num examples = 1488
05/09/2022 09:04:16 - INFO - __main__ -     Batch size = 8
Evaluating:   0%|          | 0/186 [00:00<?, ?it/s]Evaluating:   1%|          | 1/186 [00:00<02:45,  1.12it/s]Evaluating:   1%|          | 2/186 [00:01<01:45,  1.75it/s]Evaluating:   2%|▏         | 3/186 [00:01<01:25,  2.14it/s]Evaluating:   2%|▏         | 4/186 [00:01<01:16,  2.38it/s]Evaluating:   3%|▎         | 5/186 [00:02<01:11,  2.54it/s]Evaluating:   3%|▎         | 6/186 [00:02<01:07,  2.66it/s]Evaluating:   4%|▍         | 7/186 [00:02<01:05,  2.74it/s]Evaluating:   4%|▍         | 8/186 [00:03<01:03,  2.79it/s]Evaluating:   5%|▍         | 9/186 [00:03<01:02,  2.82it/s]Evaluating:   5%|▌         | 10/186 [00:03<01:01,  2.84it/s]Evaluating:   6%|▌         | 11/186 [00:04<01:01,  2.86it/s]Evaluating:   6%|▋         | 12/186 [00:04<01:00,  2.88it/s]Evaluating:   7%|▋         | 13/186 [00:05<00:59,  2.89it/s]Evaluating:   8%|▊         | 14/186 [00:05<00:59,  2.89it/s]Evaluating:   8%|▊         | 15/186 [00:05<00:59,  2.90it/s]Evaluating:   9%|▊         | 16/186 [00:06<00:58,  2.90it/s]Evaluating:   9%|▉         | 17/186 [00:06<00:58,  2.90it/s]Evaluating:  10%|▉         | 18/186 [00:06<00:57,  2.90it/s]Evaluating:  10%|█         | 19/186 [00:07<00:57,  2.90it/s]Evaluating:  11%|█         | 20/186 [00:07<00:57,  2.90it/s]Evaluating:  11%|█▏        | 21/186 [00:07<00:56,  2.90it/s]Evaluating:  12%|█▏        | 22/186 [00:08<00:56,  2.90it/s]Evaluating:  12%|█▏        | 23/186 [00:08<00:56,  2.91it/s]Evaluating:  13%|█▎        | 24/186 [00:08<00:55,  2.92it/s]Evaluating:  13%|█▎        | 25/186 [00:09<00:55,  2.92it/s]Evaluating:  14%|█▍        | 26/186 [00:09<00:54,  2.92it/s]Evaluating:  15%|█▍        | 27/186 [00:09<00:54,  2.92it/s]Evaluating:  15%|█▌        | 28/186 [00:10<00:54,  2.92it/s]Evaluating:  16%|█▌        | 29/186 [00:10<00:53,  2.92it/s]Evaluating:  16%|█▌        | 30/186 [00:10<00:53,  2.92it/s]Evaluating:  17%|█▋        | 31/186 [00:11<00:53,  2.92it/s]Evaluating:  17%|█▋        | 32/186 [00:11<00:52,  2.92it/s]Evaluating:  18%|█▊        | 33/186 [00:11<00:52,  2.91it/s]Evaluating:  18%|█▊        | 34/186 [00:12<00:52,  2.91it/s]Evaluating:  19%|█▉        | 35/186 [00:12<00:52,  2.90it/s]Evaluating:  19%|█▉        | 36/186 [00:12<00:51,  2.91it/s]Evaluating:  20%|█▉        | 37/186 [00:13<00:51,  2.90it/s]Evaluating:  20%|██        | 38/186 [00:13<00:51,  2.90it/s]Evaluating:  21%|██        | 39/186 [00:13<00:50,  2.90it/s]Evaluating:  22%|██▏       | 40/186 [00:14<00:50,  2.91it/s]Evaluating:  22%|██▏       | 41/186 [00:14<00:49,  2.90it/s]Evaluating:  23%|██▎       | 42/186 [00:14<00:49,  2.91it/s]Evaluating:  23%|██▎       | 43/186 [00:15<00:49,  2.91it/s]Evaluating:  24%|██▎       | 44/186 [00:15<00:48,  2.91it/s]Evaluating:  24%|██▍       | 45/186 [00:16<00:48,  2.91it/s]Evaluating:  25%|██▍       | 46/186 [00:16<00:48,  2.91it/s]Evaluating:  25%|██▌       | 47/186 [00:16<00:47,  2.91it/s]Evaluating:  26%|██▌       | 48/186 [00:17<00:47,  2.92it/s]Evaluating:  26%|██▋       | 49/186 [00:17<00:46,  2.92it/s]Evaluating:  27%|██▋       | 50/186 [00:17<00:46,  2.92it/s]Evaluating:  27%|██▋       | 51/186 [00:18<00:46,  2.92it/s]Evaluating:  28%|██▊       | 52/186 [00:18<00:45,  2.92it/s]Evaluating:  28%|██▊       | 53/186 [00:18<00:45,  2.92it/s]Evaluating:  29%|██▉       | 54/186 [00:19<00:45,  2.92it/s]Evaluating:  30%|██▉       | 55/186 [00:19<00:45,  2.91it/s]Evaluating:  30%|███       | 56/186 [00:19<00:44,  2.91it/s]Evaluating:  31%|███       | 57/186 [00:20<00:44,  2.90it/s]Evaluating:  31%|███       | 58/186 [00:20<00:44,  2.90it/s]Evaluating:  32%|███▏      | 59/186 [00:20<00:43,  2.90it/s]Evaluating:  32%|███▏      | 60/186 [00:21<00:43,  2.89it/s]Evaluating:  33%|███▎      | 61/186 [00:21<00:43,  2.89it/s]Evaluating:  33%|███▎      | 62/186 [00:21<00:42,  2.89it/s]Evaluating:  34%|███▍      | 63/186 [00:22<00:42,  2.90it/s]Evaluating:  34%|███▍      | 64/186 [00:22<00:41,  2.91it/s]Evaluating:  35%|███▍      | 65/186 [00:22<00:41,  2.90it/s]Evaluating:  35%|███▌      | 66/186 [00:23<00:41,  2.89it/s]Evaluating:  36%|███▌      | 67/186 [00:23<00:41,  2.89it/s]Evaluating:  37%|███▋      | 68/186 [00:23<00:40,  2.88it/s]Evaluating:  37%|███▋      | 69/186 [00:24<00:40,  2.88it/s]Evaluating:  38%|███▊      | 70/186 [00:24<00:40,  2.89it/s]Evaluating:  38%|███▊      | 71/186 [00:24<00:39,  2.89it/s]Evaluating:  39%|███▊      | 72/186 [00:25<00:39,  2.89it/s]Evaluating:  39%|███▉      | 73/186 [00:25<00:39,  2.89it/s]Evaluating:  40%|███▉      | 74/186 [00:26<00:38,  2.90it/s]Evaluating:  40%|████      | 75/186 [00:26<00:38,  2.90it/s]Evaluating:  41%|████      | 76/186 [00:26<00:37,  2.90it/s]Evaluating:  41%|████▏     | 77/186 [00:27<00:37,  2.90it/s]Evaluating:  42%|████▏     | 78/186 [00:27<00:37,  2.90it/s]Evaluating:  42%|████▏     | 79/186 [00:27<00:36,  2.89it/s]Evaluating:  43%|████▎     | 80/186 [00:28<00:36,  2.90it/s]Evaluating:  44%|████▎     | 81/186 [00:28<00:36,  2.89it/s]Evaluating:  44%|████▍     | 82/186 [00:28<00:35,  2.90it/s]Evaluating:  45%|████▍     | 83/186 [00:29<00:35,  2.90it/s]Evaluating:  45%|████▌     | 84/186 [00:29<00:35,  2.91it/s]Evaluating:  46%|████▌     | 85/186 [00:29<00:34,  2.91it/s]Evaluating:  46%|████▌     | 86/186 [00:30<00:35,  2.83it/s]Evaluating:  47%|████▋     | 87/186 [00:30<00:34,  2.86it/s]Evaluating:  47%|████▋     | 88/186 [00:30<00:34,  2.87it/s]Evaluating:  48%|████▊     | 89/186 [00:31<00:33,  2.88it/s]Evaluating:  48%|████▊     | 90/186 [00:31<00:33,  2.89it/s]Evaluating:  49%|████▉     | 91/186 [00:31<00:32,  2.89it/s]Evaluating:  49%|████▉     | 92/186 [00:32<00:32,  2.89it/s]Evaluating:  50%|█████     | 93/186 [00:32<00:32,  2.89it/s]Evaluating:  51%|█████     | 94/186 [00:32<00:31,  2.88it/s]Evaluating:  51%|█████     | 95/186 [00:33<00:31,  2.88it/s]Evaluating:  52%|█████▏    | 96/186 [00:33<00:31,  2.88it/s]Evaluating:  52%|█████▏    | 97/186 [00:33<00:30,  2.88it/s]Evaluating:  53%|█████▎    | 98/186 [00:34<00:30,  2.88it/s]Evaluating:  53%|█████▎    | 99/186 [00:34<00:30,  2.88it/s]Evaluating:  54%|█████▍    | 100/186 [00:35<00:29,  2.88it/s]Evaluating:  54%|█████▍    | 101/186 [00:35<00:29,  2.88it/s]Evaluating:  55%|█████▍    | 102/186 [00:35<00:29,  2.87it/s]Evaluating:  55%|█████▌    | 103/186 [00:36<00:28,  2.87it/s]Evaluating:  56%|█████▌    | 104/186 [00:36<00:28,  2.87it/s]Evaluating:  56%|█████▋    | 105/186 [00:36<00:28,  2.87it/s]Evaluating:  57%|█████▋    | 106/186 [00:37<00:27,  2.88it/s]Evaluating:  58%|█████▊    | 107/186 [00:37<00:27,  2.88it/s]Evaluating:  58%|█████▊    | 108/186 [00:37<00:27,  2.88it/s]Evaluating:  59%|█████▊    | 109/186 [00:38<00:26,  2.88it/s]Evaluating:  59%|█████▉    | 110/186 [00:38<00:26,  2.89it/s]Evaluating:  60%|█████▉    | 111/186 [00:38<00:25,  2.89it/s]Evaluating:  60%|██████    | 112/186 [00:39<00:25,  2.89it/s]Evaluating:  61%|██████    | 113/186 [00:39<00:25,  2.89it/s]Evaluating:  61%|██████▏   | 114/186 [00:39<00:24,  2.89it/s]Evaluating:  62%|██████▏   | 115/186 [00:40<00:24,  2.90it/s]Evaluating:  62%|██████▏   | 116/186 [00:40<00:24,  2.91it/s]Evaluating:  63%|██████▎   | 117/186 [00:40<00:23,  2.91it/s]Evaluating:  63%|██████▎   | 118/186 [00:41<00:23,  2.91it/s]Evaluating:  64%|██████▍   | 119/186 [00:41<00:23,  2.91it/s]Evaluating:  65%|██████▍   | 120/186 [00:41<00:22,  2.90it/s]Evaluating:  65%|██████▌   | 121/186 [00:42<00:22,  2.89it/s]Evaluating:  66%|██████▌   | 122/186 [00:42<00:22,  2.89it/s]Evaluating:  66%|██████▌   | 123/186 [00:42<00:21,  2.89it/s]Evaluating:  67%|██████▋   | 124/186 [00:43<00:21,  2.89it/s]Evaluating:  67%|██████▋   | 125/186 [00:43<00:21,  2.90it/s]Evaluating:  68%|██████▊   | 126/186 [00:44<00:20,  2.91it/s]Evaluating:  68%|██████▊   | 127/186 [00:44<00:20,  2.90it/s]Evaluating:  69%|██████▉   | 128/186 [00:44<00:19,  2.91it/s]Evaluating:  69%|██████▉   | 129/186 [00:45<00:19,  2.91it/s]Evaluating:  70%|██████▉   | 130/186 [00:45<00:19,  2.91it/s]Evaluating:  70%|███████   | 131/186 [00:45<00:18,  2.90it/s]Evaluating:  71%|███████   | 132/186 [00:46<00:18,  2.89it/s]Evaluating:  72%|███████▏  | 133/186 [00:46<00:18,  2.89it/s]Evaluating:  72%|███████▏  | 134/186 [00:46<00:18,  2.87it/s]Evaluating:  73%|███████▎  | 135/186 [00:47<00:17,  2.86it/s]Evaluating:  73%|███████▎  | 136/186 [00:47<00:17,  2.88it/s]Evaluating:  74%|███████▎  | 137/186 [00:47<00:17,  2.88it/s]Evaluating:  74%|███████▍  | 138/186 [00:48<00:16,  2.88it/s]Evaluating:  75%|███████▍  | 139/186 [00:48<00:16,  2.88it/s]Evaluating:  75%|███████▌  | 140/186 [00:48<00:15,  2.89it/s]Evaluating:  76%|███████▌  | 141/186 [00:49<00:15,  2.89it/s]Evaluating:  76%|███████▋  | 142/186 [00:49<00:15,  2.89it/s]Evaluating:  77%|███████▋  | 143/186 [00:49<00:14,  2.88it/s]Evaluating:  77%|███████▋  | 144/186 [00:50<00:14,  2.88it/s]Evaluating:  78%|███████▊  | 145/186 [00:50<00:14,  2.89it/s]Evaluating:  78%|███████▊  | 146/186 [00:50<00:13,  2.88it/s]Evaluating:  79%|███████▉  | 147/186 [00:51<00:13,  2.89it/s]Evaluating:  80%|███████▉  | 148/186 [00:51<00:13,  2.89it/s]Evaluating:  80%|████████  | 149/186 [00:51<00:12,  2.89it/s]Evaluating:  81%|████████  | 150/186 [00:52<00:12,  2.89it/s]Evaluating:  81%|████████  | 151/186 [00:52<00:12,  2.88it/s]Evaluating:  82%|████████▏ | 152/186 [00:53<00:11,  2.88it/s]Evaluating:  82%|████████▏ | 153/186 [00:53<00:11,  2.87it/s]Evaluating:  83%|████████▎ | 154/186 [00:53<00:11,  2.88it/s]Evaluating:  83%|████████▎ | 155/186 [00:54<00:10,  2.89it/s]Evaluating:  84%|████████▍ | 156/186 [00:54<00:10,  2.89it/s]Evaluating:  84%|████████▍ | 157/186 [00:54<00:10,  2.89it/s]Evaluating:  85%|████████▍ | 158/186 [00:55<00:09,  2.89it/s]Evaluating:  85%|████████▌ | 159/186 [00:55<00:09,  2.89it/s]Evaluating:  86%|████████▌ | 160/186 [00:55<00:09,  2.88it/s]Evaluating:  87%|████████▋ | 161/186 [00:56<00:08,  2.89it/s]Evaluating:  87%|████████▋ | 162/186 [00:56<00:08,  2.90it/s]Evaluating:  88%|████████▊ | 163/186 [00:56<00:07,  2.90it/s]Evaluating:  88%|████████▊ | 164/186 [00:57<00:07,  2.90it/s]Evaluating:  89%|████████▊ | 165/186 [00:57<00:07,  2.90it/s]Evaluating:  89%|████████▉ | 166/186 [00:57<00:06,  2.90it/s]Evaluating:  90%|████████▉ | 167/186 [00:58<00:06,  2.91it/s]Evaluating:  90%|█████████ | 168/186 [00:58<00:06,  2.91it/s]Evaluating:  91%|█████████ | 169/186 [00:58<00:05,  2.91it/s]Evaluating:  91%|█████████▏| 170/186 [00:59<00:05,  2.91it/s]Evaluating:  92%|█████████▏| 171/186 [00:59<00:05,  2.92it/s]Evaluating:  92%|█████████▏| 172/186 [00:59<00:04,  2.93it/s]Evaluating:  93%|█████████▎| 173/186 [01:00<00:04,  2.92it/s]Evaluating:  94%|█████████▎| 174/186 [01:00<00:04,  2.92it/s]Evaluating:  94%|█████████▍| 175/186 [01:00<00:03,  2.90it/s]Evaluating:  95%|█████████▍| 176/186 [01:01<00:03,  2.90it/s]Evaluating:  95%|█████████▌| 177/186 [01:01<00:03,  2.90it/s]Evaluating:  96%|█████████▌| 178/186 [01:01<00:02,  2.90it/s]Evaluating:  96%|█████████▌| 179/186 [01:02<00:02,  2.89it/s]Evaluating:  97%|█████████▋| 180/186 [01:02<00:02,  2.89it/s]Evaluating:  97%|█████████▋| 181/186 [01:03<00:01,  2.90it/s]Evaluating:  98%|█████████▊| 182/186 [01:03<00:01,  2.90it/s]Evaluating:  98%|█████████▊| 183/186 [01:03<00:01,  2.90it/s]Evaluating:  99%|█████████▉| 184/186 [01:04<00:00,  2.89it/s]Evaluating:  99%|█████████▉| 185/186 [01:04<00:00,  2.89it/s]Evaluating: 100%|██████████| 186/186 [01:04<00:00,  2.89it/s]Evaluating: 100%|██████████| 186/186 [01:04<00:00,  2.87it/s]
05/09/2022 09:05:21 - INFO - __main__ -     Evaluation done in total 64.761639 secs (0.043523 sec per example)
05/09/2022 09:05:27 - INFO - __main__ -   Results: {'exact': 60.7563025210084, 'f1': 78.90516891161646, 'total': 1190, 'HasAns_exact': 60.7563025210084, 'HasAns_f1': 78.90516891161646, 'HasAns_total': 1190, 'best_exact': 60.7563025210084, 'best_exact_thresh': 0.0, 'best_f1': 78.90516891161646, 'best_f1_thresh': 0.0}
  ru 
2022-05-09 09:05:31.109493: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0
05/09/2022 09:05:35 - WARNING - __main__ -   Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, 16-bits training: False
You are using a model of type xlm-roberta to instantiate a model of type xlm. This is not supported for all configurations of models and can yield errors.
Some weights of the model checkpoint at /cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//squad/xlm-KG_LR3e-5_EPOCH2.0_maxlen384_batchsize4_gradacc4 were not used when initializing XLMRobertaModel: ['base_model.encoder.layer.22.attention.self.value.bias', 'base_model.encoder.layer.21.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.21.attention.self.query.bias', 'base_model.encoder.layer.23.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.13.attention.self.query.weight', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.19.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.3.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.15.attention.output.dense.bias', 'base_model.encoder.layer.2.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.8.attention.self.key.weight', 'base_model.encoder.layer.2.attention.self.value.weight', 'base_model.encoder.layer.14.attention.self.value.weight', 'base_model.encoder.layer.10.attention.output.LayerNorm.weight', 'base_model.encoder.layer.19.intermediate.dense.weight', 'base_model.encoder.layer.1.attention.self.key.weight', 'base_model.encoder.layer.19.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.9.attention.self.query.weight', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.1.attention.self.query.bias', 'base_model.encoder.layer.6.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.15.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.17.output.LayerNorm.bias', 'base_model.encoder.layer.5.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.5.attention.output.dense.bias', 'base_model.encoder.layer.18.attention.self.query.weight', 'base_model.encoder.layer.14.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.17.attention.output.dense.bias', 'qa_outputs.weight', 'base_model.encoder.layer.12.attention.self.value.bias', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.16.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.22.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.6.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.2.output.adapters.ep.adapter_down.0.weight', 'base_model.embeddings.LayerNorm.bias', 'base_model.encoder.layer.5.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.4.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.23.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.0.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.16.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.11.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.0.attention.self.key.weight', 'base_model.encoder.layer.13.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.15.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.18.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.16.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.21.attention.output.LayerNorm.bias', 'base_model.encoder.layer.17.intermediate.dense.bias', 'base_model.encoder.layer.9.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.0.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.0.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.11.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.4.output.LayerNorm.weight', 'base_model.encoder.layer.4.output.adapters.es.adapter_down.0.bias', 'base_model.embeddings.token_type_embeddings.weight', 'base_model.encoder.layer.8.output.dense.weight', 'base_model.encoder.layer.15.attention.self.query.bias', 'base_model.encoder.layer.15.attention.self.key.weight', 'base_model.encoder.layer.2.output.LayerNorm.weight', 'base_model.encoder.layer.20.output.dense.bias', 'base_model.encoder.layer.14.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.22.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.2.attention.self.key.bias', 'base_model.encoder.layer.7.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.12.attention.output.LayerNorm.bias', 'base_model.encoder.layer.0.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.13.attention.output.dense.bias', 'base_model.encoder.layer.7.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.0.attention.self.key.bias', 'base_model.encoder.layer.4.attention.self.query.bias', 'base_model.encoder.layer.22.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.3.attention.output.LayerNorm.weight', 'base_model.encoder.layer.11.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.11.output.LayerNorm.bias', 'base_model.encoder.layer.13.intermediate.dense.bias', 'base_model.encoder.layer.15.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.20.attention.self.value.bias', 'base_model.encoder.layer.13.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.4.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.7.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.14.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.9.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.0.attention.self.query.bias', 'base_model.encoder.layer.4.output.LayerNorm.bias', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.14.output.dense.weight', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.18.output.dense.weight', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.17.attention.self.key.bias', 'base_model.encoder.layer.15.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.20.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.22.attention.self.query.weight', 'base_model.encoder.layer.22.attention.self.value.weight', 'base_model.encoder.layer.12.output.LayerNorm.bias', 'base_model.encoder.layer.7.output.LayerNorm.bias', 'base_model.encoder.layer.11.output.LayerNorm.weight', 'base_model.encoder.layer.14.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.22.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.13.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.10.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.9.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.9.attention.output.LayerNorm.weight', 'base_model.encoder.layer.17.attention.self.value.weight', 'base_model.encoder.layer.6.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.7.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.19.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.20.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.3.attention.self.query.weight', 'base_model.encoder.layer.6.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.13.output.LayerNorm.bias', 'base_model.encoder.layer.3.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.14.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.1.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.2.attention.self.key.weight', 'base_model.encoder.layer.23.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.17.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.22.intermediate.dense.bias', 'base_model.encoder.layer.0.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.17.output.dense.weight', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.17.attention.self.query.bias', 'base_model.encoder.layer.23.attention.output.LayerNorm.bias', 'base_model.encoder.layer.6.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.16.output.dense.weight', 'base_model.encoder.layer.19.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.3.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.12.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.10.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.23.attention.self.query.weight', 'base_model.encoder.layer.13.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.10.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.21.attention.self.value.bias', 'base_model.encoder.layer.11.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.19.attention.output.LayerNorm.weight', 'base_model.encoder.layer.10.attention.self.query.bias', 'base_model.encoder.layer.17.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.7.attention.self.value.weight', 'base_model.encoder.layer.18.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.3.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.13.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.8.output.LayerNorm.bias', 'base_model.encoder.layer.18.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.13.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.4.intermediate.dense.weight', 'base_model.encoder.layer.8.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.5.intermediate.dense.weight', 'base_model.encoder.layer.7.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.15.output.dense.weight', 'base_model.encoder.layer.18.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.14.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.16.attention.self.key.weight', 'base_model.encoder.layer.22.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.21.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.8.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.4.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.7.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.21.attention.self.query.weight', 'base_model.encoder.layer.19.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.12.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.8.intermediate.dense.weight', 'base_model.encoder.layer.6.output.LayerNorm.weight', 'base_model.encoder.layer.8.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.10.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.23.attention.self.value.bias', 'base_model.encoder.layer.18.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.23.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.6.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.0.output.LayerNorm.weight', 'base_model.encoder.layer.18.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.20.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.4.attention.output.dense.weight', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.22.attention.output.LayerNorm.weight', 'base_model.encoder.layer.12.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.19.attention.self.query.weight', 'base_model.encoder.layer.22.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.9.intermediate.dense.bias', 'base_model.encoder.layer.13.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.0.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.3.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.14.attention.self.key.weight', 'base_model.encoder.layer.14.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.19.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.14.intermediate.dense.weight', 'base_model.encoder.layer.7.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.0.attention.self.value.weight', 'base_model.encoder.layer.11.attention.self.key.bias', 'base_model.encoder.layer.9.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.0.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.6.output.LayerNorm.bias', 'base_model.encoder.layer.13.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.12.attention.self.query.weight', 'base_model.encoder.layer.21.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.14.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.23.attention.self.value.weight', 'base_model.encoder.layer.22.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.6.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.12.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.4.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.6.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.21.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.6.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.10.intermediate.dense.weight', 'base_model.encoder.layer.9.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.8.output.LayerNorm.weight', 'base_model.encoder.layer.6.attention.self.key.bias', 'base_model.encoder.layer.5.attention.output.LayerNorm.weight', 'base_model.encoder.layer.20.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.19.attention.self.key.weight', 'base_model.encoder.layer.1.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.2.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.21.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.22.output.LayerNorm.weight', 'base_model.encoder.layer.9.attention.output.dense.bias', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.13.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.20.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.9.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.23.output.dense.bias', 'base_model.encoder.layer.5.attention.self.key.bias', 'base_model.encoder.layer.23.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.7.attention.self.key.bias', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.3.attention.self.value.bias', 'base_model.encoder.layer.2.attention.self.query.bias', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.0.output.dense.bias', 'base_model.encoder.layer.2.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.12.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.0.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.1.intermediate.dense.weight', 'base_model.encoder.layer.3.intermediate.dense.weight', 'base_model.encoder.layer.11.intermediate.dense.bias', 'base_model.encoder.layer.12.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.9.output.dense.weight', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.19.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.1.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.21.output.dense.weight', 'base_model.encoder.layer.0.attention.output.LayerNorm.weight', 'base_model.encoder.layer.7.attention.self.query.weight', 'base_model.encoder.layer.7.attention.self.query.bias', 'base_model.encoder.layer.14.intermediate.dense.bias', 'base_model.encoder.layer.3.attention.output.LayerNorm.bias', 'base_model.encoder.layer.7.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.3.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.6.intermediate.dense.weight', 'base_model.encoder.layer.4.attention.output.dense.bias', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.17.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.21.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.6.attention.self.key.weight', 'base_model.encoder.layer.0.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.20.output.LayerNorm.bias', 'base_model.encoder.layer.22.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.12.intermediate.dense.weight', 'base_model.encoder.layer.13.attention.self.key.weight', 'base_model.encoder.layer.20.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.19.attention.output.LayerNorm.bias', 'base_model.encoder.layer.23.intermediate.dense.bias', 'base_model.encoder.layer.18.attention.output.LayerNorm.bias', 'base_model.encoder.layer.23.attention.self.key.weight', 'base_model.encoder.layer.8.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.8.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.17.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.16.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.21.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.1.attention.self.key.bias', 'base_model.encoder.layer.4.output.dense.bias', 'base_model.encoder.layer.22.output.dense.weight', 'base_model.embeddings.position_embeddings.weight', 'base_model.encoder.layer.19.output.dense.bias', 'base_model.encoder.layer.12.intermediate.dense.bias', 'base_model.encoder.layer.0.output.dense.weight', 'base_model.encoder.layer.14.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.18.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.11.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.21.output.LayerNorm.bias', 'base_model.encoder.layer.19.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.3.attention.self.key.bias', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.7.output.dense.bias', 'base_model.encoder.layer.5.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.4.attention.output.LayerNorm.bias', 'base_model.encoder.layer.8.attention.self.value.bias', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.8.intermediate.dense.bias', 'base_model.encoder.layer.16.output.LayerNorm.weight', 'base_model.encoder.layer.18.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.0.attention.output.dense.bias', 'base_model.encoder.layer.19.attention.self.value.weight', 'base_model.encoder.layer.21.attention.self.key.bias', 'base_model.encoder.layer.16.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.13.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.3.output.LayerNorm.bias', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.11.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.2.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.16.attention.self.value.weight', 'base_model.encoder.layer.16.output.dense.bias', 'base_model.encoder.layer.15.attention.self.value.weight', 'base_model.encoder.layer.2.attention.output.dense.bias', 'base_model.encoder.layer.7.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.22.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.8.attention.self.query.weight', 'base_model.encoder.layer.22.output.LayerNorm.bias', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.5.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.21.attention.output.dense.weight', 'base_model.encoder.layer.10.attention.output.LayerNorm.bias', 'base_model.encoder.layer.6.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.19.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.6.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.13.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.23.attention.self.key.bias', 'base_model.encoder.layer.1.output.dense.weight', 'base_model.encoder.layer.4.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.8.output.adapters.ts.adapter_down.0.bias', 'base_model.embeddings.position_ids', 'base_model.encoder.layer.13.output.dense.weight', 'base_model.embeddings.LayerNorm.weight', 'base_model.encoder.layer.6.attention.output.LayerNorm.bias', 'base_model.encoder.layer.13.attention.self.value.bias', 'base_model.encoder.layer.16.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.1.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.7.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.17.attention.output.dense.weight', 'base_model.encoder.layer.10.attention.self.key.weight', 'base_model.encoder.layer.1.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.11.attention.self.query.weight', 'base_model.encoder.layer.14.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.8.attention.output.LayerNorm.bias', 'base_model.encoder.layer.13.output.dense.bias', 'base_model.encoder.layer.7.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.14.output.LayerNorm.bias', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.20.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.0.output.adapters.es.adapter_up.bias', 'base_model.embeddings.word_embeddings.weight', 'base_model.encoder.layer.5.attention.self.query.weight', 'base_model.encoder.layer.8.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.12.output.LayerNorm.weight', 'base_model.encoder.layer.1.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.8.attention.output.dense.weight', 'base_model.encoder.layer.17.output.LayerNorm.weight', 'base_model.encoder.layer.22.output.dense.bias', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.11.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.5.attention.self.query.bias', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.5.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.22.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.4.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.8.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.10.output.LayerNorm.bias', 'base_model.encoder.layer.20.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.14.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.12.attention.self.value.weight', 'base_model.encoder.layer.12.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.8.attention.output.LayerNorm.weight', 'base_model.encoder.layer.17.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.15.intermediate.dense.bias', 'base_model.encoder.layer.7.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.13.attention.self.value.weight', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.21.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.10.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.11.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.14.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.16.intermediate.dense.weight', 'base_model.encoder.layer.1.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.3.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.17.attention.output.LayerNorm.weight', 'base_model.encoder.layer.19.intermediate.dense.bias', 'base_model.encoder.layer.18.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.21.attention.output.dense.bias', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.6.attention.self.query.weight', 'base_model.encoder.layer.9.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.15.attention.output.dense.weight', 'base_model.encoder.layer.15.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.13.attention.self.key.bias', 'base_model.encoder.layer.17.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.1.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.12.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.7.intermediate.dense.bias', 'base_model.encoder.layer.14.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.18.attention.self.value.bias', 'base_model.encoder.layer.22.attention.output.dense.bias', 'base_model.encoder.layer.11.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.3.attention.output.dense.weight', 'base_model.encoder.layer.9.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.2.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.10.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.16.attention.self.key.bias', 'base_model.encoder.layer.16.attention.output.LayerNorm.bias', 'base_model.encoder.layer.22.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.20.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.13.attention.output.dense.weight', 'base_model.encoder.layer.16.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.15.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.15.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.6.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.10.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.9.intermediate.dense.weight', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.6.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.12.output.dense.weight', 'base_model.encoder.layer.2.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.23.attention.output.dense.weight', 'base_model.encoder.layer.15.attention.self.value.bias', 'base_model.encoder.layer.4.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.16.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.22.attention.self.query.bias', 'base_model.encoder.layer.23.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.3.intermediate.dense.bias', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.12.attention.output.dense.bias', 'base_model.encoder.layer.10.output.LayerNorm.weight', 'base_model.encoder.layer.2.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.7.intermediate.dense.weight', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.20.output.LayerNorm.weight', 'base_model.encoder.layer.7.output.dense.weight', 'base_model.encoder.layer.2.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.6.intermediate.dense.bias', 'base_model.encoder.layer.18.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.6.output.adapters.es.adapter_down.0.weight', 'qa_outputs.bias', 'base_model.encoder.layer.9.attention.self.value.weight', 'base_model.encoder.layer.5.output.dense.weight', 'base_model.encoder.layer.19.attention.self.value.bias', 'base_model.encoder.layer.16.attention.output.dense.weight', 'base_model.encoder.layer.4.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.23.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.20.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.12.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.23.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.5.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.2.output.dense.bias', 'base_model.encoder.layer.21.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.10.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.1.attention.output.dense.weight', 'base_model.encoder.layer.20.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.5.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.4.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.14.attention.output.dense.weight', 'base_model.encoder.layer.8.attention.self.value.weight', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.2.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.12.attention.output.dense.weight', 'base_model.encoder.layer.7.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.7.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.10.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.22.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.8.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.8.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.5.attention.self.key.weight', 'base_model.encoder.layer.14.attention.self.query.weight', 'base_model.encoder.layer.4.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.9.output.LayerNorm.weight', 'base_model.encoder.layer.10.attention.self.query.weight', 'base_model.encoder.layer.6.attention.output.dense.weight', 'base_model.encoder.layer.4.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.7.attention.self.value.bias', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.17.attention.output.LayerNorm.bias', 'base_model.encoder.layer.11.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.15.intermediate.dense.weight', 'base_model.encoder.layer.16.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.14.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.5.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.1.attention.output.dense.bias', 'base_model.encoder.layer.21.intermediate.dense.weight', 'base_model.encoder.layer.22.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.6.output.dense.bias', 'base_model.encoder.layer.2.output.dense.weight', 'base_model.encoder.layer.14.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.22.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.19.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.17.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.2.attention.self.value.bias', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.19.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.3.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.6.attention.output.dense.bias', 'base_model.encoder.layer.4.attention.self.value.bias', 'base_model.encoder.layer.14.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.18.intermediate.dense.bias', 'base_model.encoder.layer.2.attention.output.LayerNorm.weight', 'base_model.encoder.layer.1.output.LayerNorm.weight', 'base_model.encoder.layer.4.output.dense.weight', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.10.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.21.attention.output.LayerNorm.weight', 'base_model.encoder.layer.21.output.adapters.ep.adapter_up.bias', 'base_model.pooler.dense.weight', 'base_model.encoder.layer.17.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.13.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.11.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.7.output.LayerNorm.weight', 'base_model.encoder.layer.11.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.17.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.1.attention.self.query.weight', 'base_model.encoder.layer.15.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.5.intermediate.dense.bias', 'base_model.encoder.layer.16.attention.output.LayerNorm.weight', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.11.attention.self.value.bias', 'base_model.encoder.layer.23.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.3.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.4.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.16.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.21.output.LayerNorm.weight', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.pooler.dense.bias', 'base_model.encoder.layer.10.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.18.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.18.attention.output.dense.weight', 'base_model.encoder.layer.20.attention.output.LayerNorm.weight', 'base_model.encoder.layer.12.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.16.output.LayerNorm.bias', 'base_model.encoder.layer.9.attention.self.value.bias', 'base_model.encoder.layer.13.output.LayerNorm.weight', 'base_model.encoder.layer.4.attention.self.value.weight', 'base_model.encoder.layer.6.attention.self.value.bias', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.23.attention.output.dense.bias', 'base_model.encoder.layer.15.attention.self.query.weight', 'base_model.encoder.layer.16.attention.self.value.bias', 'base_model.encoder.layer.17.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.6.attention.output.LayerNorm.weight', 'base_model.encoder.layer.1.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.9.attention.self.key.bias', 'base_model.encoder.layer.5.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.16.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.1.attention.output.LayerNorm.weight', 'base_model.encoder.layer.18.output.dense.bias', 'base_model.encoder.layer.23.attention.output.LayerNorm.weight', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.9.output.LayerNorm.bias', 'base_model.encoder.layer.9.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.18.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.21.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.5.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.9.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.3.output.dense.weight', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.3.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.21.attention.self.value.weight', 'base_model.encoder.layer.7.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.20.attention.self.key.bias', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.7.attention.self.key.weight', 'base_model.encoder.layer.11.intermediate.dense.weight', 'base_model.encoder.layer.7.attention.output.dense.weight', 'base_model.encoder.layer.20.intermediate.dense.bias', 'base_model.encoder.layer.19.output.dense.weight', 'base_model.encoder.layer.16.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.0.attention.output.LayerNorm.bias', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.22.attention.output.dense.weight', 'base_model.encoder.layer.16.attention.self.query.weight', 'base_model.encoder.layer.1.output.LayerNorm.bias', 'base_model.encoder.layer.9.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.14.output.LayerNorm.weight', 'base_model.encoder.layer.10.attention.self.value.weight', 'base_model.encoder.layer.12.attention.self.query.bias', 'base_model.encoder.layer.11.attention.self.value.weight', 'base_model.encoder.layer.20.attention.output.LayerNorm.bias', 'base_model.encoder.layer.21.output.dense.bias', 'base_model.encoder.layer.23.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.11.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.18.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.18.attention.self.query.bias', 'base_model.encoder.layer.18.attention.self.key.bias', 'base_model.encoder.layer.20.attention.self.query.bias', 'base_model.encoder.layer.18.attention.self.key.weight', 'base_model.encoder.layer.10.attention.output.dense.weight', 'base_model.encoder.layer.1.attention.self.value.bias', 'base_model.encoder.layer.0.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.2.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.2.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.8.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.17.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.3.attention.self.query.bias', 'base_model.encoder.layer.11.attention.self.key.weight', 'base_model.encoder.layer.21.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.7.attention.output.LayerNorm.bias', 'base_model.encoder.layer.21.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.3.attention.output.dense.bias', 'base_model.encoder.layer.5.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.11.output.dense.bias', 'base_model.encoder.layer.20.intermediate.dense.weight', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.2.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.15.attention.self.key.bias', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.11.attention.output.dense.weight', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.21.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.2.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.8.attention.self.query.bias', 'base_model.encoder.layer.19.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.2.attention.output.dense.weight', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.11.attention.output.LayerNorm.bias', 'base_model.encoder.layer.17.attention.self.key.weight', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.18.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.2.attention.output.LayerNorm.bias', 'base_model.encoder.layer.0.attention.output.dense.weight', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.11.output.dense.weight', 'base_model.encoder.layer.9.attention.output.dense.weight', 'base_model.encoder.layer.3.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.21.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.16.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.18.intermediate.dense.weight', 'base_model.encoder.layer.10.attention.self.value.bias', 'base_model.encoder.layer.11.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.5.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.20.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.9.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.18.output.LayerNorm.weight', 'base_model.encoder.layer.5.output.dense.bias', 'base_model.encoder.layer.9.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.14.attention.output.dense.bias', 'base_model.encoder.layer.4.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.15.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.12.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.17.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.8.attention.self.key.bias', 'base_model.encoder.layer.5.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.3.attention.self.key.weight', 'base_model.encoder.layer.17.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.20.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.6.attention.self.query.bias', 'base_model.encoder.layer.19.attention.self.key.bias', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.18.attention.self.value.weight', 'base_model.encoder.layer.18.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.11.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.8.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.12.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.12.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.1.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.15.output.LayerNorm.bias', 'base_model.encoder.layer.13.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.17.intermediate.dense.weight', 'base_model.encoder.layer.19.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.4.intermediate.dense.bias', 'base_model.encoder.layer.0.intermediate.dense.weight', 'base_model.encoder.layer.12.attention.output.LayerNorm.weight', 'base_model.encoder.layer.17.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.10.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.20.attention.output.dense.weight', 'base_model.encoder.layer.21.intermediate.dense.bias', 'base_model.encoder.layer.16.attention.self.query.bias', 'base_model.encoder.layer.19.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.1.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.4.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.13.attention.self.query.bias', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.14.attention.self.query.bias', 'base_model.encoder.layer.1.intermediate.dense.bias', 'base_model.encoder.layer.10.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.4.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.15.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.23.attention.self.query.bias', 'base_model.encoder.layer.17.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.5.attention.output.dense.weight', 'base_model.encoder.layer.5.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.22.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.23.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.20.output.dense.weight', 'base_model.encoder.layer.15.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.20.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.0.attention.self.query.weight', 'base_model.encoder.layer.5.output.LayerNorm.weight', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.15.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.7.attention.output.dense.bias', 'base_model.encoder.layer.12.attention.self.key.weight', 'base_model.encoder.layer.4.attention.output.LayerNorm.weight', 'base_model.encoder.layer.10.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.11.attention.output.dense.bias', 'base_model.encoder.layer.17.attention.self.value.bias', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.11.attention.output.LayerNorm.weight', 'base_model.encoder.layer.22.attention.output.LayerNorm.bias', 'base_model.encoder.layer.0.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.5.attention.output.LayerNorm.bias', 'base_model.encoder.layer.9.attention.self.query.bias', 'base_model.encoder.layer.5.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.1.output.dense.bias', 'base_model.encoder.layer.19.output.LayerNorm.bias', 'base_model.encoder.layer.23.output.LayerNorm.weight', 'base_model.encoder.layer.13.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.19.attention.output.dense.weight', 'base_model.encoder.layer.10.output.dense.bias', 'base_model.encoder.layer.3.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.0.intermediate.dense.bias', 'base_model.encoder.layer.14.attention.output.LayerNorm.weight', 'base_model.encoder.layer.19.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.0.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.9.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.21.attention.self.key.weight', 'base_model.encoder.layer.6.attention.self.value.weight', 'base_model.encoder.layer.13.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.0.attention.self.value.bias', 'base_model.encoder.layer.0.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.9.output.dense.bias', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.20.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.3.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.14.output.dense.bias', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.12.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.17.output.dense.bias', 'base_model.encoder.layer.6.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.10.attention.output.dense.bias', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.13.attention.output.LayerNorm.weight', 'base_model.encoder.layer.21.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.23.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.1.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.10.attention.self.key.bias', 'base_model.encoder.layer.15.output.LayerNorm.weight', 'base_model.encoder.layer.0.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.3.attention.self.value.weight', 'base_model.encoder.layer.15.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.7.attention.output.LayerNorm.weight', 'base_model.encoder.layer.7.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.8.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.12.attention.self.key.bias', 'base_model.encoder.layer.4.attention.self.query.weight', 'base_model.encoder.layer.5.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.9.attention.output.LayerNorm.bias', 'base_model.encoder.layer.9.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.1.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.1.attention.self.value.weight', 'base_model.encoder.layer.23.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.23.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.3.output.dense.bias', 'base_model.encoder.layer.9.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.18.attention.output.dense.bias', 'base_model.encoder.layer.14.attention.self.key.bias', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.8.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.8.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.10.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.23.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.4.attention.self.key.bias', 'base_model.encoder.layer.16.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.23.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.3.output.LayerNorm.weight', 'base_model.encoder.layer.15.output.dense.bias', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.16.intermediate.dense.bias', 'base_model.encoder.layer.0.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.12.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.20.attention.self.key.weight', 'base_model.encoder.layer.14.attention.output.LayerNorm.bias', 'base_model.encoder.layer.18.output.LayerNorm.bias', 'base_model.encoder.layer.19.output.LayerNorm.weight', 'base_model.encoder.layer.22.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.23.output.dense.weight', 'base_model.encoder.layer.5.attention.self.value.bias', 'base_model.encoder.layer.1.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.2.attention.self.query.weight', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.13.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.23.output.LayerNorm.bias', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.3.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.6.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.11.attention.self.query.bias', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.3.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.13.attention.output.LayerNorm.bias', 'base_model.encoder.layer.14.attention.self.value.bias', 'base_model.encoder.layer.9.attention.self.key.weight', 'base_model.encoder.layer.1.attention.output.LayerNorm.bias', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.0.output.LayerNorm.bias', 'base_model.encoder.layer.17.attention.self.query.weight', 'base_model.encoder.layer.20.attention.output.dense.bias', 'base_model.encoder.layer.10.intermediate.dense.bias', 'base_model.encoder.layer.4.attention.self.key.weight', 'base_model.encoder.layer.6.output.dense.weight', 'base_model.encoder.layer.18.attention.output.LayerNorm.weight', 'base_model.encoder.layer.16.attention.output.dense.bias', 'base_model.encoder.layer.17.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.2.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.2.intermediate.dense.weight', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.11.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.1.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.12.output.dense.bias', 'base_model.encoder.layer.15.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.19.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.20.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.1.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.18.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.23.intermediate.dense.weight', 'base_model.encoder.layer.3.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.2.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.16.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.19.attention.output.dense.bias', 'base_model.encoder.layer.12.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.10.output.dense.weight', 'base_model.encoder.layer.22.intermediate.dense.weight', 'base_model.encoder.layer.5.output.LayerNorm.bias', 'base_model.encoder.layer.8.output.dense.bias', 'base_model.encoder.layer.20.attention.self.query.weight', 'base_model.encoder.layer.22.attention.self.key.bias', 'base_model.encoder.layer.19.attention.self.query.bias', 'base_model.encoder.layer.2.output.LayerNorm.bias', 'base_model.encoder.layer.15.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.15.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.8.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.20.attention.self.value.weight', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.10.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.8.attention.output.dense.bias', 'base_model.encoder.layer.16.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.5.attention.self.value.weight', 'base_model.encoder.layer.2.intermediate.dense.bias', 'base_model.encoder.layer.15.attention.output.LayerNorm.weight', 'base_model.encoder.layer.22.attention.self.key.weight', 'base_model.encoder.layer.15.attention.output.LayerNorm.bias', 'base_model.encoder.layer.13.intermediate.dense.weight']
- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of XLMRobertaModel were not initialized from the model checkpoint at /cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//squad/xlm-KG_LR3e-5_EPOCH2.0_maxlen384_batchsize4_gradacc4 and are newly initialized: ['encoder.layer.9.attention.output.dense.bias', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.22.attention.self.query.weight', 'encoder.layer.12.output.LayerNorm.bias', 'encoder.layer.22.attention.output.LayerNorm.bias', 'encoder.layer.6.attention.output.dense.weight', 'encoder.layer.19.intermediate.dense.bias', 'encoder.layer.18.output.dense.weight', 'encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.layer.6.output.LayerNorm.bias', 'encoder.layer.8.attention.self.value.bias', 'encoder.layer.11.attention.self.value.bias', 'encoder.layer.12.attention.self.value.bias', 'encoder.layer.21.attention.self.key.weight', 'encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.0.attention.self.value.weight', 'encoder.layer.7.attention.self.query.weight', 'encoder.layer.14.attention.self.value.weight', 'encoder.layer.0.attention.self.query.weight', 'encoder.layer.13.attention.output.LayerNorm.weight', 'encoder.layer.8.attention.output.LayerNorm.bias', 'encoder.layer.0.attention.self.key.weight', 'encoder.layer.1.attention.self.query.weight', 'encoder.layer.17.attention.self.value.bias', 'encoder.layer.3.attention.self.key.weight', 'encoder.layer.1.attention.output.LayerNorm.weight', 'encoder.layer.16.output.dense.weight', 'encoder.layer.19.attention.self.value.weight', 'encoder.layer.23.output.LayerNorm.bias', 'encoder.layer.17.attention.output.LayerNorm.bias', 'encoder.layer.5.output.LayerNorm.bias', 'encoder.layer.20.attention.self.value.bias', 'encoder.layer.16.attention.self.key.weight', 'encoder.layer.11.attention.self.query.bias', 'encoder.layer.2.output.dense.bias', 'encoder.layer.21.output.dense.weight', 'encoder.layer.23.attention.self.value.bias', 'encoder.layer.14.attention.self.query.bias', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.12.attention.output.LayerNorm.weight', 'encoder.layer.17.output.LayerNorm.bias', 'encoder.layer.22.intermediate.dense.bias', 'encoder.layer.5.attention.self.value.weight', 'encoder.layer.3.attention.output.dense.bias', 'encoder.layer.12.intermediate.dense.bias', 'encoder.layer.17.attention.output.dense.bias', 'encoder.layer.9.output.LayerNorm.weight', 'encoder.layer.16.output.dense.bias', 'encoder.layer.19.attention.self.query.weight', 'encoder.layer.5.output.dense.bias', 'encoder.layer.5.attention.output.dense.bias', 'encoder.layer.7.attention.self.value.weight', 'encoder.layer.17.attention.self.value.weight', 'encoder.layer.3.attention.self.query.bias', 'encoder.layer.9.attention.self.key.bias', 'encoder.layer.10.attention.self.query.weight', 'encoder.layer.20.attention.output.LayerNorm.weight', 'encoder.layer.21.attention.output.dense.weight', 'encoder.layer.3.attention.self.value.bias', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.1.output.dense.weight', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.6.attention.self.value.bias', 'encoder.layer.2.attention.output.dense.bias', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.2.attention.output.LayerNorm.bias', 'encoder.layer.5.attention.self.key.bias', 'encoder.layer.10.output.dense.weight', 'encoder.layer.22.output.LayerNorm.bias', 'encoder.layer.13.attention.self.query.bias', 'encoder.layer.23.attention.output.dense.bias', 'encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.layer.0.attention.self.value.bias', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.3.attention.self.query.weight', 'encoder.layer.13.attention.self.value.weight', 'encoder.layer.17.attention.self.key.weight', 'encoder.layer.13.attention.output.dense.weight', 'encoder.layer.10.intermediate.dense.weight', 'encoder.layer.6.attention.self.key.weight', 'encoder.layer.21.output.LayerNorm.bias', 'encoder.layer.20.attention.self.key.bias', 'encoder.layer.9.attention.output.dense.weight', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.11.attention.output.dense.weight', 'encoder.layer.13.output.dense.weight', 'embeddings.LayerNorm.weight', 'encoder.layer.14.output.LayerNorm.weight', 'encoder.layer.19.output.dense.weight', 'encoder.layer.20.intermediate.dense.weight', 'encoder.layer.20.output.dense.weight', 'encoder.layer.21.intermediate.dense.bias', 'encoder.layer.20.attention.self.query.weight', 'encoder.layer.2.attention.self.value.bias', 'encoder.layer.11.attention.self.key.weight', 'encoder.layer.13.output.LayerNorm.bias', 'encoder.layer.23.intermediate.dense.bias', 'encoder.layer.21.attention.output.LayerNorm.weight', 'encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.layer.19.attention.output.dense.weight', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.22.output.dense.weight', 'encoder.layer.10.attention.self.key.weight', 'encoder.layer.7.attention.self.key.weight', 'encoder.layer.8.attention.self.value.weight', 'encoder.layer.9.attention.self.value.weight', 'encoder.layer.23.attention.self.query.weight', 'encoder.layer.6.output.dense.weight', 'encoder.layer.8.attention.output.LayerNorm.weight', 'encoder.layer.0.attention.self.key.bias', 'encoder.layer.8.attention.output.dense.weight', 'encoder.layer.14.attention.output.LayerNorm.bias', 'encoder.layer.20.attention.output.dense.weight', 'encoder.layer.21.attention.output.LayerNorm.bias', 'encoder.layer.22.output.LayerNorm.weight', 'encoder.layer.23.output.dense.bias', 'encoder.layer.1.attention.output.dense.bias', 'encoder.layer.10.attention.output.LayerNorm.weight', 'encoder.layer.19.attention.self.value.bias', 'encoder.layer.15.attention.self.key.weight', 'encoder.layer.15.output.dense.weight', 'encoder.layer.8.output.dense.bias', 'encoder.layer.13.intermediate.dense.bias', 'encoder.layer.16.attention.self.query.weight', 'encoder.layer.15.attention.output.LayerNorm.weight', 'encoder.layer.2.attention.self.key.bias', 'encoder.layer.2.attention.self.key.weight', 'encoder.layer.23.attention.output.LayerNorm.bias', 'encoder.layer.4.attention.self.value.bias', 'encoder.layer.12.attention.self.key.bias', 'encoder.layer.9.attention.output.LayerNorm.weight', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.10.attention.output.dense.weight', 'encoder.layer.15.output.LayerNorm.bias', 'encoder.layer.4.attention.output.dense.weight', 'encoder.layer.14.attention.self.key.bias', 'encoder.layer.3.attention.self.value.weight', 'encoder.layer.15.attention.self.query.weight', 'encoder.layer.6.attention.output.dense.bias', 'encoder.layer.1.attention.self.query.bias', 'encoder.layer.18.attention.output.dense.weight', 'encoder.layer.10.attention.self.key.bias', 'encoder.layer.20.attention.self.key.weight', 'encoder.layer.17.attention.self.key.bias', 'encoder.layer.22.attention.self.value.weight', 'encoder.layer.1.attention.self.key.bias', 'encoder.layer.4.output.dense.weight', 'encoder.layer.13.output.LayerNorm.weight', 'encoder.layer.5.attention.self.query.bias', 'encoder.layer.15.output.dense.bias', 'encoder.layer.13.attention.self.query.weight', 'encoder.layer.0.output.LayerNorm.weight', 'embeddings.LayerNorm.bias', 'encoder.layer.22.output.dense.bias', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.10.output.dense.bias', 'encoder.layer.14.output.LayerNorm.bias', 'encoder.layer.23.output.dense.weight', 'encoder.layer.11.attention.self.query.weight', 'encoder.layer.11.output.dense.bias', 'encoder.layer.16.attention.self.value.bias', 'encoder.layer.8.attention.self.key.weight', 'encoder.layer.18.intermediate.dense.weight', 'encoder.layer.11.output.dense.weight', 'encoder.layer.20.output.dense.bias', 'encoder.layer.9.attention.self.value.bias', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.17.attention.self.query.weight', 'encoder.layer.8.output.LayerNorm.weight', 'encoder.layer.6.output.dense.bias', 'encoder.layer.8.attention.self.query.bias', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.7.output.dense.weight', 'encoder.layer.23.attention.self.key.weight', 'encoder.layer.19.output.dense.bias', 'encoder.layer.23.attention.self.value.weight', 'encoder.layer.13.attention.output.LayerNorm.bias', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.2.attention.self.value.weight', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.16.attention.self.key.bias', 'encoder.layer.19.attention.self.query.bias', 'encoder.layer.9.attention.self.key.weight', 'encoder.layer.1.attention.self.key.weight', 'encoder.layer.1.attention.self.value.weight', 'embeddings.token_type_embeddings.weight', 'encoder.layer.15.output.LayerNorm.weight', 'encoder.layer.16.intermediate.dense.weight', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.17.attention.self.query.bias', 'encoder.layer.19.attention.output.LayerNorm.bias', 'encoder.layer.22.attention.self.query.bias', 'encoder.layer.13.attention.output.dense.bias', 'encoder.layer.22.attention.output.dense.weight', 'encoder.layer.15.attention.self.value.weight', 'encoder.layer.17.attention.output.dense.weight', 'encoder.layer.6.attention.self.query.weight', 'encoder.layer.7.attention.output.LayerNorm.bias', 'encoder.layer.9.attention.self.query.bias', 'encoder.layer.15.attention.output.dense.weight', 'encoder.layer.16.attention.output.dense.bias', 'encoder.layer.5.attention.self.query.weight', 'encoder.layer.12.attention.self.query.weight', 'encoder.layer.16.intermediate.dense.bias', 'encoder.layer.9.output.LayerNorm.bias', 'encoder.layer.18.output.dense.bias', 'encoder.layer.10.output.LayerNorm.weight', 'encoder.layer.4.attention.self.value.weight', 'encoder.layer.20.attention.output.dense.bias', 'encoder.layer.18.attention.output.dense.bias', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.21.attention.self.value.bias', 'encoder.layer.17.output.dense.bias', 'encoder.layer.21.attention.self.value.weight', 'encoder.layer.8.attention.self.query.weight', 'encoder.layer.9.output.dense.weight', 'encoder.layer.6.attention.output.LayerNorm.bias', 'encoder.layer.4.attention.self.query.bias', 'encoder.layer.7.attention.output.LayerNorm.weight', 'encoder.layer.15.intermediate.dense.bias', 'encoder.layer.19.output.LayerNorm.weight', 'embeddings.word_embeddings.weight', 'encoder.layer.14.attention.output.dense.bias', 'encoder.layer.18.intermediate.dense.bias', 'encoder.layer.20.output.LayerNorm.bias', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.14.attention.output.dense.weight', 'encoder.layer.19.attention.output.LayerNorm.weight', 'pooler.dense.weight', 'encoder.layer.19.output.LayerNorm.bias', 'encoder.layer.21.attention.self.query.bias', 'encoder.layer.2.attention.output.LayerNorm.weight', 'encoder.layer.1.attention.output.dense.weight', 'encoder.layer.0.attention.output.dense.weight', 'encoder.layer.4.attention.self.query.weight', 'encoder.layer.14.output.dense.weight', 'encoder.layer.17.output.dense.weight', 'encoder.layer.14.output.dense.bias', 'encoder.layer.13.attention.self.value.bias', 'encoder.layer.14.intermediate.dense.weight', 'encoder.layer.12.attention.self.value.weight', 'encoder.layer.21.output.LayerNorm.weight', 'embeddings.position_embeddings.weight', 'encoder.layer.11.attention.output.dense.bias', 'encoder.layer.12.output.dense.bias', 'encoder.layer.5.attention.self.key.weight', 'encoder.layer.5.attention.output.LayerNorm.weight', 'encoder.layer.21.attention.self.query.weight', 'encoder.layer.14.attention.output.LayerNorm.weight', 'encoder.layer.21.output.dense.bias', 'encoder.layer.14.attention.self.key.weight', 'encoder.layer.18.attention.output.LayerNorm.weight', 'encoder.layer.12.attention.self.key.weight', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.20.attention.self.query.bias', 'encoder.layer.10.attention.self.value.weight', 'pooler.dense.bias', 'encoder.layer.7.attention.output.dense.weight', 'encoder.layer.10.attention.self.query.bias', 'encoder.layer.14.intermediate.dense.bias', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.7.output.dense.bias', 'encoder.layer.18.output.LayerNorm.weight', 'encoder.layer.19.attention.output.dense.bias', 'encoder.layer.18.attention.self.value.weight', 'encoder.layer.17.intermediate.dense.bias', 'encoder.layer.20.attention.output.LayerNorm.bias', 'encoder.layer.9.output.dense.bias', 'encoder.layer.13.attention.self.key.bias', 'encoder.layer.15.attention.self.key.bias', 'encoder.layer.12.attention.output.LayerNorm.bias', 'encoder.layer.4.attention.self.key.weight', 'encoder.layer.15.attention.output.dense.bias', 'encoder.layer.15.attention.output.LayerNorm.bias', 'encoder.layer.12.attention.output.dense.bias', 'encoder.layer.21.attention.output.dense.bias', 'encoder.layer.7.attention.self.query.bias', 'encoder.layer.4.output.dense.bias', 'encoder.layer.15.attention.self.value.bias', 'encoder.layer.22.attention.output.LayerNorm.weight', 'encoder.layer.0.output.dense.weight', 'encoder.layer.7.attention.self.value.bias', 'encoder.layer.11.attention.self.key.bias', 'encoder.layer.6.attention.self.key.bias', 'encoder.layer.18.attention.output.LayerNorm.bias', 'encoder.layer.16.output.LayerNorm.weight', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.21.attention.self.key.bias', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.12.output.LayerNorm.weight', 'encoder.layer.7.attention.output.dense.bias', 'encoder.layer.11.attention.self.value.weight', 'encoder.layer.4.attention.output.LayerNorm.weight', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.22.attention.output.dense.bias', 'encoder.layer.10.attention.output.dense.bias', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.18.attention.self.key.weight', 'encoder.layer.7.output.LayerNorm.bias', 'encoder.layer.0.attention.output.LayerNorm.weight', 'encoder.layer.3.attention.self.key.bias', 'encoder.layer.8.attention.self.key.bias', 'encoder.layer.10.attention.output.LayerNorm.bias', 'encoder.layer.1.output.dense.bias', 'encoder.layer.7.output.LayerNorm.weight', 'encoder.layer.6.attention.self.value.weight', 'encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.layer.2.attention.self.query.bias', 'encoder.layer.19.intermediate.dense.weight', 'encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.layer.23.attention.output.LayerNorm.weight', 'encoder.layer.18.attention.self.query.weight', 'encoder.layer.22.attention.self.value.bias', 'encoder.layer.13.intermediate.dense.weight', 'encoder.layer.14.attention.self.query.weight', 'encoder.layer.15.attention.self.query.bias', 'encoder.layer.23.attention.self.key.bias', 'encoder.layer.15.intermediate.dense.weight', 'encoder.layer.5.output.dense.weight', 'encoder.layer.19.attention.self.key.weight', 'encoder.layer.14.attention.self.value.bias', 'encoder.layer.4.attention.output.dense.bias', 'encoder.layer.10.attention.self.value.bias', 'encoder.layer.23.attention.self.query.bias', 'encoder.layer.16.attention.output.dense.weight', 'encoder.layer.18.output.LayerNorm.bias', 'encoder.layer.16.output.LayerNorm.bias', 'encoder.layer.17.attention.output.LayerNorm.weight', 'encoder.layer.2.attention.self.query.weight', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.21.intermediate.dense.weight', 'encoder.layer.6.attention.output.LayerNorm.weight', 'encoder.layer.12.intermediate.dense.weight', 'encoder.layer.17.intermediate.dense.weight', 'encoder.layer.3.output.dense.weight', 'encoder.layer.12.output.dense.weight', 'encoder.layer.23.intermediate.dense.weight', 'encoder.layer.12.attention.output.dense.weight', 'encoder.layer.2.attention.output.dense.weight', 'encoder.layer.16.attention.output.LayerNorm.weight', 'encoder.layer.4.attention.self.key.bias', 'encoder.layer.22.intermediate.dense.weight', 'encoder.layer.13.output.dense.bias', 'encoder.layer.5.attention.self.value.bias', 'encoder.layer.5.attention.output.dense.weight', 'encoder.layer.17.output.LayerNorm.weight', 'encoder.layer.7.intermediate.dense.bias', 'encoder.layer.18.attention.self.value.bias', 'encoder.layer.0.attention.self.query.bias', 'encoder.layer.16.attention.output.LayerNorm.bias', 'encoder.layer.16.attention.self.query.bias', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.22.attention.self.key.bias', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.1.attention.self.value.bias', 'encoder.layer.6.attention.self.query.bias', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.9.attention.output.LayerNorm.bias', 'encoder.layer.13.attention.self.key.weight', 'encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.layer.7.attention.self.key.bias', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.23.output.LayerNorm.weight', 'encoder.layer.10.output.LayerNorm.bias', 'encoder.layer.11.output.LayerNorm.weight', 'encoder.layer.16.attention.self.value.weight', 'encoder.layer.8.attention.output.dense.bias', 'encoder.layer.18.attention.self.query.bias', 'encoder.layer.19.attention.self.key.bias', 'encoder.layer.12.attention.self.query.bias', 'encoder.layer.8.output.LayerNorm.bias', 'encoder.layer.22.attention.self.key.weight', 'encoder.layer.20.output.LayerNorm.weight', 'encoder.layer.11.output.LayerNorm.bias', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.0.output.dense.bias', 'encoder.layer.20.attention.self.value.weight', 'encoder.layer.0.attention.output.dense.bias', 'encoder.layer.23.attention.output.dense.weight', 'encoder.layer.11.attention.output.LayerNorm.weight', 'encoder.layer.8.output.dense.weight', 'encoder.layer.18.attention.self.key.bias', 'encoder.layer.2.output.dense.weight', 'encoder.layer.3.output.dense.bias', 'encoder.layer.20.intermediate.dense.bias', 'encoder.layer.4.attention.output.LayerNorm.bias', 'encoder.layer.9.attention.self.query.weight', 'encoder.layer.3.attention.output.dense.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Overwriting existing adapter 'ep'.
Overwriting existing adapter 'tp'.
Overwriting existing adapter 'es'.
Overwriting existing adapter 'ts'.
Overwriting existing adapter fusion module 'ep,tp,es,ts'
05/09/2022 09:06:03 - INFO - __main__ -   lang2id = None
05/09/2022 09:06:09 - INFO - __main__ -   Training/evaluation parameters Namespace(adam_epsilon=1e-08, cache_dir='', config_name='', data_dir=None, device=device(type='cuda'), do_eval=True, do_lower_case=False, do_train=False, doc_stride=128, eval_all_checkpoints=False, eval_lang='ru', evaluate_during_training=False, fp16=False, fp16_opt_level='O1', gradient_accumulation_steps=1, learning_rate=5e-05, local_rank=-1, logging_steps=50, max_answer_length=30, max_grad_norm=1.0, max_query_length=64, max_seq_length=384, max_steps=-1, model_name='xlm-KG', model_name_or_path='/cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//squad/xlm-KG_LR3e-5_EPOCH2.0_maxlen384_batchsize4_gradacc4', model_type='xlm', modelkg_dir='/cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/adapter/xlmr_adapter', n_best_size=20, n_gpu=1, no_cuda=False, null_score_diff_threshold=0.0, num_train_epochs=3.0, output_dir='/cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//squad/xlm-KG_LR3e-5_EPOCH2.0_maxlen384_batchsize4_gradacc4/predictions/xquad/', overwrite_cache=False, overwrite_output_dir=False, per_gpu_eval_batch_size=8, per_gpu_train_batch_size=8, predict_file='/cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/download//xquad//xquad.ru.json', save_steps=50, seed=42, server_ip='', server_port='', threads=1, tokenizer_name='', train_file=None, train_lang='en', verbose_logging=False, version_2_with_negative=False, warmup_steps=0, weight_decay=0.0)
05/09/2022 09:06:09 - INFO - __main__ -   Loading checkpoint /cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//squad/xlm-KG_LR3e-5_EPOCH2.0_maxlen384_batchsize4_gradacc4 for evaluation
05/09/2022 09:06:09 - INFO - __main__ -   Evaluate the following checkpoints: ['/cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//squad/xlm-KG_LR3e-5_EPOCH2.0_maxlen384_batchsize4_gradacc4']
Some weights of the model checkpoint at /cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//squad/xlm-KG_LR3e-5_EPOCH2.0_maxlen384_batchsize4_gradacc4 were not used when initializing XLMRobertaModel: ['base_model.encoder.layer.22.attention.self.value.bias', 'base_model.encoder.layer.21.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.21.attention.self.query.bias', 'base_model.encoder.layer.23.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.13.attention.self.query.weight', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.19.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.3.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.15.attention.output.dense.bias', 'base_model.encoder.layer.2.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.8.attention.self.key.weight', 'base_model.encoder.layer.2.attention.self.value.weight', 'base_model.encoder.layer.14.attention.self.value.weight', 'base_model.encoder.layer.10.attention.output.LayerNorm.weight', 'base_model.encoder.layer.19.intermediate.dense.weight', 'base_model.encoder.layer.1.attention.self.key.weight', 'base_model.encoder.layer.19.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.9.attention.self.query.weight', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.1.attention.self.query.bias', 'base_model.encoder.layer.6.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.15.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.17.output.LayerNorm.bias', 'base_model.encoder.layer.5.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.5.attention.output.dense.bias', 'base_model.encoder.layer.18.attention.self.query.weight', 'base_model.encoder.layer.14.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.17.attention.output.dense.bias', 'qa_outputs.weight', 'base_model.encoder.layer.12.attention.self.value.bias', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.16.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.22.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.6.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.2.output.adapters.ep.adapter_down.0.weight', 'base_model.embeddings.LayerNorm.bias', 'base_model.encoder.layer.5.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.4.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.23.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.0.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.16.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.11.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.0.attention.self.key.weight', 'base_model.encoder.layer.13.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.15.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.18.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.16.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.21.attention.output.LayerNorm.bias', 'base_model.encoder.layer.17.intermediate.dense.bias', 'base_model.encoder.layer.9.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.0.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.0.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.11.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.4.output.LayerNorm.weight', 'base_model.encoder.layer.4.output.adapters.es.adapter_down.0.bias', 'base_model.embeddings.token_type_embeddings.weight', 'base_model.encoder.layer.8.output.dense.weight', 'base_model.encoder.layer.15.attention.self.query.bias', 'base_model.encoder.layer.15.attention.self.key.weight', 'base_model.encoder.layer.2.output.LayerNorm.weight', 'base_model.encoder.layer.20.output.dense.bias', 'base_model.encoder.layer.14.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.22.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.2.attention.self.key.bias', 'base_model.encoder.layer.7.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.12.attention.output.LayerNorm.bias', 'base_model.encoder.layer.0.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.13.attention.output.dense.bias', 'base_model.encoder.layer.7.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.0.attention.self.key.bias', 'base_model.encoder.layer.4.attention.self.query.bias', 'base_model.encoder.layer.22.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.3.attention.output.LayerNorm.weight', 'base_model.encoder.layer.11.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.11.output.LayerNorm.bias', 'base_model.encoder.layer.13.intermediate.dense.bias', 'base_model.encoder.layer.15.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.20.attention.self.value.bias', 'base_model.encoder.layer.13.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.4.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.7.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.14.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.9.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.0.attention.self.query.bias', 'base_model.encoder.layer.4.output.LayerNorm.bias', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.14.output.dense.weight', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.18.output.dense.weight', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.17.attention.self.key.bias', 'base_model.encoder.layer.15.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.20.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.22.attention.self.query.weight', 'base_model.encoder.layer.22.attention.self.value.weight', 'base_model.encoder.layer.12.output.LayerNorm.bias', 'base_model.encoder.layer.7.output.LayerNorm.bias', 'base_model.encoder.layer.11.output.LayerNorm.weight', 'base_model.encoder.layer.14.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.22.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.13.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.10.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.9.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.9.attention.output.LayerNorm.weight', 'base_model.encoder.layer.17.attention.self.value.weight', 'base_model.encoder.layer.6.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.7.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.19.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.20.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.3.attention.self.query.weight', 'base_model.encoder.layer.6.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.13.output.LayerNorm.bias', 'base_model.encoder.layer.3.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.14.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.1.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.2.attention.self.key.weight', 'base_model.encoder.layer.23.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.17.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.22.intermediate.dense.bias', 'base_model.encoder.layer.0.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.17.output.dense.weight', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.17.attention.self.query.bias', 'base_model.encoder.layer.23.attention.output.LayerNorm.bias', 'base_model.encoder.layer.6.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.16.output.dense.weight', 'base_model.encoder.layer.19.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.3.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.12.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.10.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.23.attention.self.query.weight', 'base_model.encoder.layer.13.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.10.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.21.attention.self.value.bias', 'base_model.encoder.layer.11.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.19.attention.output.LayerNorm.weight', 'base_model.encoder.layer.10.attention.self.query.bias', 'base_model.encoder.layer.17.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.7.attention.self.value.weight', 'base_model.encoder.layer.18.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.3.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.13.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.8.output.LayerNorm.bias', 'base_model.encoder.layer.18.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.13.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.4.intermediate.dense.weight', 'base_model.encoder.layer.8.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.5.intermediate.dense.weight', 'base_model.encoder.layer.7.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.15.output.dense.weight', 'base_model.encoder.layer.18.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.14.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.16.attention.self.key.weight', 'base_model.encoder.layer.22.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.21.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.8.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.4.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.7.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.21.attention.self.query.weight', 'base_model.encoder.layer.19.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.12.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.8.intermediate.dense.weight', 'base_model.encoder.layer.6.output.LayerNorm.weight', 'base_model.encoder.layer.8.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.10.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.23.attention.self.value.bias', 'base_model.encoder.layer.18.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.23.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.6.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.0.output.LayerNorm.weight', 'base_model.encoder.layer.18.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.20.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.4.attention.output.dense.weight', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.22.attention.output.LayerNorm.weight', 'base_model.encoder.layer.12.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.19.attention.self.query.weight', 'base_model.encoder.layer.22.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.9.intermediate.dense.bias', 'base_model.encoder.layer.13.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.0.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.3.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.14.attention.self.key.weight', 'base_model.encoder.layer.14.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.19.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.14.intermediate.dense.weight', 'base_model.encoder.layer.7.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.0.attention.self.value.weight', 'base_model.encoder.layer.11.attention.self.key.bias', 'base_model.encoder.layer.9.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.0.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.6.output.LayerNorm.bias', 'base_model.encoder.layer.13.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.12.attention.self.query.weight', 'base_model.encoder.layer.21.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.14.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.23.attention.self.value.weight', 'base_model.encoder.layer.22.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.6.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.12.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.4.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.6.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.21.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.6.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.10.intermediate.dense.weight', 'base_model.encoder.layer.9.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.8.output.LayerNorm.weight', 'base_model.encoder.layer.6.attention.self.key.bias', 'base_model.encoder.layer.5.attention.output.LayerNorm.weight', 'base_model.encoder.layer.20.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.19.attention.self.key.weight', 'base_model.encoder.layer.1.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.2.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.21.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.22.output.LayerNorm.weight', 'base_model.encoder.layer.9.attention.output.dense.bias', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.13.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.20.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.9.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.23.output.dense.bias', 'base_model.encoder.layer.5.attention.self.key.bias', 'base_model.encoder.layer.23.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.7.attention.self.key.bias', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.3.attention.self.value.bias', 'base_model.encoder.layer.2.attention.self.query.bias', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.0.output.dense.bias', 'base_model.encoder.layer.2.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.12.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.0.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.1.intermediate.dense.weight', 'base_model.encoder.layer.3.intermediate.dense.weight', 'base_model.encoder.layer.11.intermediate.dense.bias', 'base_model.encoder.layer.12.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.9.output.dense.weight', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.19.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.1.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.21.output.dense.weight', 'base_model.encoder.layer.0.attention.output.LayerNorm.weight', 'base_model.encoder.layer.7.attention.self.query.weight', 'base_model.encoder.layer.7.attention.self.query.bias', 'base_model.encoder.layer.14.intermediate.dense.bias', 'base_model.encoder.layer.3.attention.output.LayerNorm.bias', 'base_model.encoder.layer.7.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.3.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.6.intermediate.dense.weight', 'base_model.encoder.layer.4.attention.output.dense.bias', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.17.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.21.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.6.attention.self.key.weight', 'base_model.encoder.layer.0.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.20.output.LayerNorm.bias', 'base_model.encoder.layer.22.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.12.intermediate.dense.weight', 'base_model.encoder.layer.13.attention.self.key.weight', 'base_model.encoder.layer.20.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.19.attention.output.LayerNorm.bias', 'base_model.encoder.layer.23.intermediate.dense.bias', 'base_model.encoder.layer.18.attention.output.LayerNorm.bias', 'base_model.encoder.layer.23.attention.self.key.weight', 'base_model.encoder.layer.8.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.8.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.17.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.16.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.21.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.1.attention.self.key.bias', 'base_model.encoder.layer.4.output.dense.bias', 'base_model.encoder.layer.22.output.dense.weight', 'base_model.embeddings.position_embeddings.weight', 'base_model.encoder.layer.19.output.dense.bias', 'base_model.encoder.layer.12.intermediate.dense.bias', 'base_model.encoder.layer.0.output.dense.weight', 'base_model.encoder.layer.14.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.18.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.11.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.21.output.LayerNorm.bias', 'base_model.encoder.layer.19.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.3.attention.self.key.bias', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.7.output.dense.bias', 'base_model.encoder.layer.5.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.4.attention.output.LayerNorm.bias', 'base_model.encoder.layer.8.attention.self.value.bias', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.8.intermediate.dense.bias', 'base_model.encoder.layer.16.output.LayerNorm.weight', 'base_model.encoder.layer.18.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.0.attention.output.dense.bias', 'base_model.encoder.layer.19.attention.self.value.weight', 'base_model.encoder.layer.21.attention.self.key.bias', 'base_model.encoder.layer.16.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.13.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.3.output.LayerNorm.bias', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.11.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.2.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.16.attention.self.value.weight', 'base_model.encoder.layer.16.output.dense.bias', 'base_model.encoder.layer.15.attention.self.value.weight', 'base_model.encoder.layer.2.attention.output.dense.bias', 'base_model.encoder.layer.7.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.22.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.8.attention.self.query.weight', 'base_model.encoder.layer.22.output.LayerNorm.bias', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.5.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.21.attention.output.dense.weight', 'base_model.encoder.layer.10.attention.output.LayerNorm.bias', 'base_model.encoder.layer.6.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.19.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.6.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.13.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.23.attention.self.key.bias', 'base_model.encoder.layer.1.output.dense.weight', 'base_model.encoder.layer.4.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.8.output.adapters.ts.adapter_down.0.bias', 'base_model.embeddings.position_ids', 'base_model.encoder.layer.13.output.dense.weight', 'base_model.embeddings.LayerNorm.weight', 'base_model.encoder.layer.6.attention.output.LayerNorm.bias', 'base_model.encoder.layer.13.attention.self.value.bias', 'base_model.encoder.layer.16.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.1.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.7.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.17.attention.output.dense.weight', 'base_model.encoder.layer.10.attention.self.key.weight', 'base_model.encoder.layer.1.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.11.attention.self.query.weight', 'base_model.encoder.layer.14.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.8.attention.output.LayerNorm.bias', 'base_model.encoder.layer.13.output.dense.bias', 'base_model.encoder.layer.7.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.14.output.LayerNorm.bias', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.20.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.0.output.adapters.es.adapter_up.bias', 'base_model.embeddings.word_embeddings.weight', 'base_model.encoder.layer.5.attention.self.query.weight', 'base_model.encoder.layer.8.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.12.output.LayerNorm.weight', 'base_model.encoder.layer.1.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.8.attention.output.dense.weight', 'base_model.encoder.layer.17.output.LayerNorm.weight', 'base_model.encoder.layer.22.output.dense.bias', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.11.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.5.attention.self.query.bias', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.5.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.22.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.4.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.8.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.10.output.LayerNorm.bias', 'base_model.encoder.layer.20.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.14.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.12.attention.self.value.weight', 'base_model.encoder.layer.12.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.8.attention.output.LayerNorm.weight', 'base_model.encoder.layer.17.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.15.intermediate.dense.bias', 'base_model.encoder.layer.7.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.13.attention.self.value.weight', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.21.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.10.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.11.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.14.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.16.intermediate.dense.weight', 'base_model.encoder.layer.1.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.3.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.17.attention.output.LayerNorm.weight', 'base_model.encoder.layer.19.intermediate.dense.bias', 'base_model.encoder.layer.18.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.21.attention.output.dense.bias', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.6.attention.self.query.weight', 'base_model.encoder.layer.9.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.15.attention.output.dense.weight', 'base_model.encoder.layer.15.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.13.attention.self.key.bias', 'base_model.encoder.layer.17.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.1.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.12.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.7.intermediate.dense.bias', 'base_model.encoder.layer.14.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.18.attention.self.value.bias', 'base_model.encoder.layer.22.attention.output.dense.bias', 'base_model.encoder.layer.11.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.3.attention.output.dense.weight', 'base_model.encoder.layer.9.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.2.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.10.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.16.attention.self.key.bias', 'base_model.encoder.layer.16.attention.output.LayerNorm.bias', 'base_model.encoder.layer.22.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.20.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.13.attention.output.dense.weight', 'base_model.encoder.layer.16.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.15.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.15.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.6.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.10.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.9.intermediate.dense.weight', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.6.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.12.output.dense.weight', 'base_model.encoder.layer.2.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.23.attention.output.dense.weight', 'base_model.encoder.layer.15.attention.self.value.bias', 'base_model.encoder.layer.4.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.16.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.22.attention.self.query.bias', 'base_model.encoder.layer.23.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.3.intermediate.dense.bias', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.12.attention.output.dense.bias', 'base_model.encoder.layer.10.output.LayerNorm.weight', 'base_model.encoder.layer.2.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.7.intermediate.dense.weight', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.20.output.LayerNorm.weight', 'base_model.encoder.layer.7.output.dense.weight', 'base_model.encoder.layer.2.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.6.intermediate.dense.bias', 'base_model.encoder.layer.18.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.6.output.adapters.es.adapter_down.0.weight', 'qa_outputs.bias', 'base_model.encoder.layer.9.attention.self.value.weight', 'base_model.encoder.layer.5.output.dense.weight', 'base_model.encoder.layer.19.attention.self.value.bias', 'base_model.encoder.layer.16.attention.output.dense.weight', 'base_model.encoder.layer.4.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.23.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.20.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.12.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.23.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.5.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.2.output.dense.bias', 'base_model.encoder.layer.21.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.10.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.1.attention.output.dense.weight', 'base_model.encoder.layer.20.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.5.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.4.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.14.attention.output.dense.weight', 'base_model.encoder.layer.8.attention.self.value.weight', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.2.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.12.attention.output.dense.weight', 'base_model.encoder.layer.7.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.7.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.10.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.22.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.8.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.8.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.5.attention.self.key.weight', 'base_model.encoder.layer.14.attention.self.query.weight', 'base_model.encoder.layer.4.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.9.output.LayerNorm.weight', 'base_model.encoder.layer.10.attention.self.query.weight', 'base_model.encoder.layer.6.attention.output.dense.weight', 'base_model.encoder.layer.4.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.7.attention.self.value.bias', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.17.attention.output.LayerNorm.bias', 'base_model.encoder.layer.11.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.15.intermediate.dense.weight', 'base_model.encoder.layer.16.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.14.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.5.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.1.attention.output.dense.bias', 'base_model.encoder.layer.21.intermediate.dense.weight', 'base_model.encoder.layer.22.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.6.output.dense.bias', 'base_model.encoder.layer.2.output.dense.weight', 'base_model.encoder.layer.14.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.22.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.19.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.17.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.2.attention.self.value.bias', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.19.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.3.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.6.attention.output.dense.bias', 'base_model.encoder.layer.4.attention.self.value.bias', 'base_model.encoder.layer.14.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.18.intermediate.dense.bias', 'base_model.encoder.layer.2.attention.output.LayerNorm.weight', 'base_model.encoder.layer.1.output.LayerNorm.weight', 'base_model.encoder.layer.4.output.dense.weight', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.10.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.21.attention.output.LayerNorm.weight', 'base_model.encoder.layer.21.output.adapters.ep.adapter_up.bias', 'base_model.pooler.dense.weight', 'base_model.encoder.layer.17.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.13.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.11.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.7.output.LayerNorm.weight', 'base_model.encoder.layer.11.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.17.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.1.attention.self.query.weight', 'base_model.encoder.layer.15.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.5.intermediate.dense.bias', 'base_model.encoder.layer.16.attention.output.LayerNorm.weight', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.11.attention.self.value.bias', 'base_model.encoder.layer.23.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.3.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.4.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.16.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.21.output.LayerNorm.weight', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.pooler.dense.bias', 'base_model.encoder.layer.10.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.18.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.18.attention.output.dense.weight', 'base_model.encoder.layer.20.attention.output.LayerNorm.weight', 'base_model.encoder.layer.12.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.16.output.LayerNorm.bias', 'base_model.encoder.layer.9.attention.self.value.bias', 'base_model.encoder.layer.13.output.LayerNorm.weight', 'base_model.encoder.layer.4.attention.self.value.weight', 'base_model.encoder.layer.6.attention.self.value.bias', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.23.attention.output.dense.bias', 'base_model.encoder.layer.15.attention.self.query.weight', 'base_model.encoder.layer.16.attention.self.value.bias', 'base_model.encoder.layer.17.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.6.attention.output.LayerNorm.weight', 'base_model.encoder.layer.1.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.9.attention.self.key.bias', 'base_model.encoder.layer.5.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.16.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.1.attention.output.LayerNorm.weight', 'base_model.encoder.layer.18.output.dense.bias', 'base_model.encoder.layer.23.attention.output.LayerNorm.weight', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.9.output.LayerNorm.bias', 'base_model.encoder.layer.9.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.18.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.21.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.5.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.9.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.3.output.dense.weight', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.3.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.21.attention.self.value.weight', 'base_model.encoder.layer.7.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.20.attention.self.key.bias', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.7.attention.self.key.weight', 'base_model.encoder.layer.11.intermediate.dense.weight', 'base_model.encoder.layer.7.attention.output.dense.weight', 'base_model.encoder.layer.20.intermediate.dense.bias', 'base_model.encoder.layer.19.output.dense.weight', 'base_model.encoder.layer.16.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.0.attention.output.LayerNorm.bias', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.22.attention.output.dense.weight', 'base_model.encoder.layer.16.attention.self.query.weight', 'base_model.encoder.layer.1.output.LayerNorm.bias', 'base_model.encoder.layer.9.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.14.output.LayerNorm.weight', 'base_model.encoder.layer.10.attention.self.value.weight', 'base_model.encoder.layer.12.attention.self.query.bias', 'base_model.encoder.layer.11.attention.self.value.weight', 'base_model.encoder.layer.20.attention.output.LayerNorm.bias', 'base_model.encoder.layer.21.output.dense.bias', 'base_model.encoder.layer.23.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.11.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.18.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.18.attention.self.query.bias', 'base_model.encoder.layer.18.attention.self.key.bias', 'base_model.encoder.layer.20.attention.self.query.bias', 'base_model.encoder.layer.18.attention.self.key.weight', 'base_model.encoder.layer.10.attention.output.dense.weight', 'base_model.encoder.layer.1.attention.self.value.bias', 'base_model.encoder.layer.0.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.2.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.2.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.8.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.17.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.3.attention.self.query.bias', 'base_model.encoder.layer.11.attention.self.key.weight', 'base_model.encoder.layer.21.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.7.attention.output.LayerNorm.bias', 'base_model.encoder.layer.21.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.3.attention.output.dense.bias', 'base_model.encoder.layer.5.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.11.output.dense.bias', 'base_model.encoder.layer.20.intermediate.dense.weight', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.2.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.15.attention.self.key.bias', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.11.attention.output.dense.weight', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.21.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.2.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.8.attention.self.query.bias', 'base_model.encoder.layer.19.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.2.attention.output.dense.weight', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.11.attention.output.LayerNorm.bias', 'base_model.encoder.layer.17.attention.self.key.weight', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.18.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.2.attention.output.LayerNorm.bias', 'base_model.encoder.layer.0.attention.output.dense.weight', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.11.output.dense.weight', 'base_model.encoder.layer.9.attention.output.dense.weight', 'base_model.encoder.layer.3.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.21.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.16.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.18.intermediate.dense.weight', 'base_model.encoder.layer.10.attention.self.value.bias', 'base_model.encoder.layer.11.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.5.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.20.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.9.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.18.output.LayerNorm.weight', 'base_model.encoder.layer.5.output.dense.bias', 'base_model.encoder.layer.9.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.14.attention.output.dense.bias', 'base_model.encoder.layer.4.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.15.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.12.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.17.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.8.attention.self.key.bias', 'base_model.encoder.layer.5.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.3.attention.self.key.weight', 'base_model.encoder.layer.17.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.20.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.6.attention.self.query.bias', 'base_model.encoder.layer.19.attention.self.key.bias', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.18.attention.self.value.weight', 'base_model.encoder.layer.18.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.11.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.8.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.12.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.12.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.1.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.15.output.LayerNorm.bias', 'base_model.encoder.layer.13.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.17.intermediate.dense.weight', 'base_model.encoder.layer.19.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.4.intermediate.dense.bias', 'base_model.encoder.layer.0.intermediate.dense.weight', 'base_model.encoder.layer.12.attention.output.LayerNorm.weight', 'base_model.encoder.layer.17.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.10.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.20.attention.output.dense.weight', 'base_model.encoder.layer.21.intermediate.dense.bias', 'base_model.encoder.layer.16.attention.self.query.bias', 'base_model.encoder.layer.19.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.1.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.4.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.13.attention.self.query.bias', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.14.attention.self.query.bias', 'base_model.encoder.layer.1.intermediate.dense.bias', 'base_model.encoder.layer.10.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.4.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.15.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.23.attention.self.query.bias', 'base_model.encoder.layer.17.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.5.attention.output.dense.weight', 'base_model.encoder.layer.5.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.22.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.23.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.20.output.dense.weight', 'base_model.encoder.layer.15.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.20.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.0.attention.self.query.weight', 'base_model.encoder.layer.5.output.LayerNorm.weight', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.15.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.7.attention.output.dense.bias', 'base_model.encoder.layer.12.attention.self.key.weight', 'base_model.encoder.layer.4.attention.output.LayerNorm.weight', 'base_model.encoder.layer.10.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.11.attention.output.dense.bias', 'base_model.encoder.layer.17.attention.self.value.bias', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.11.attention.output.LayerNorm.weight', 'base_model.encoder.layer.22.attention.output.LayerNorm.bias', 'base_model.encoder.layer.0.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.5.attention.output.LayerNorm.bias', 'base_model.encoder.layer.9.attention.self.query.bias', 'base_model.encoder.layer.5.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.1.output.dense.bias', 'base_model.encoder.layer.19.output.LayerNorm.bias', 'base_model.encoder.layer.23.output.LayerNorm.weight', 'base_model.encoder.layer.13.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.19.attention.output.dense.weight', 'base_model.encoder.layer.10.output.dense.bias', 'base_model.encoder.layer.3.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.0.intermediate.dense.bias', 'base_model.encoder.layer.14.attention.output.LayerNorm.weight', 'base_model.encoder.layer.19.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.0.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.9.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.21.attention.self.key.weight', 'base_model.encoder.layer.6.attention.self.value.weight', 'base_model.encoder.layer.13.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.0.attention.self.value.bias', 'base_model.encoder.layer.0.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.9.output.dense.bias', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.20.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.3.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.14.output.dense.bias', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.12.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.17.output.dense.bias', 'base_model.encoder.layer.6.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.10.attention.output.dense.bias', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.13.attention.output.LayerNorm.weight', 'base_model.encoder.layer.21.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.23.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.1.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.10.attention.self.key.bias', 'base_model.encoder.layer.15.output.LayerNorm.weight', 'base_model.encoder.layer.0.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.3.attention.self.value.weight', 'base_model.encoder.layer.15.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.7.attention.output.LayerNorm.weight', 'base_model.encoder.layer.7.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.8.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.12.attention.self.key.bias', 'base_model.encoder.layer.4.attention.self.query.weight', 'base_model.encoder.layer.5.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.9.attention.output.LayerNorm.bias', 'base_model.encoder.layer.9.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.1.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.1.attention.self.value.weight', 'base_model.encoder.layer.23.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.23.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.3.output.dense.bias', 'base_model.encoder.layer.9.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.18.attention.output.dense.bias', 'base_model.encoder.layer.14.attention.self.key.bias', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.8.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.8.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.10.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.23.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.4.attention.self.key.bias', 'base_model.encoder.layer.16.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.23.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.3.output.LayerNorm.weight', 'base_model.encoder.layer.15.output.dense.bias', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.16.intermediate.dense.bias', 'base_model.encoder.layer.0.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.12.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.20.attention.self.key.weight', 'base_model.encoder.layer.14.attention.output.LayerNorm.bias', 'base_model.encoder.layer.18.output.LayerNorm.bias', 'base_model.encoder.layer.19.output.LayerNorm.weight', 'base_model.encoder.layer.22.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.23.output.dense.weight', 'base_model.encoder.layer.5.attention.self.value.bias', 'base_model.encoder.layer.1.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.2.attention.self.query.weight', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.13.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.23.output.LayerNorm.bias', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.3.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.6.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.11.attention.self.query.bias', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.3.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.13.attention.output.LayerNorm.bias', 'base_model.encoder.layer.14.attention.self.value.bias', 'base_model.encoder.layer.9.attention.self.key.weight', 'base_model.encoder.layer.1.attention.output.LayerNorm.bias', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.0.output.LayerNorm.bias', 'base_model.encoder.layer.17.attention.self.query.weight', 'base_model.encoder.layer.20.attention.output.dense.bias', 'base_model.encoder.layer.10.intermediate.dense.bias', 'base_model.encoder.layer.4.attention.self.key.weight', 'base_model.encoder.layer.6.output.dense.weight', 'base_model.encoder.layer.18.attention.output.LayerNorm.weight', 'base_model.encoder.layer.16.attention.output.dense.bias', 'base_model.encoder.layer.17.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.2.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.2.intermediate.dense.weight', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.11.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.1.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.12.output.dense.bias', 'base_model.encoder.layer.15.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.19.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.20.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.1.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.18.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.23.intermediate.dense.weight', 'base_model.encoder.layer.3.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.2.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.16.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.19.attention.output.dense.bias', 'base_model.encoder.layer.12.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.10.output.dense.weight', 'base_model.encoder.layer.22.intermediate.dense.weight', 'base_model.encoder.layer.5.output.LayerNorm.bias', 'base_model.encoder.layer.8.output.dense.bias', 'base_model.encoder.layer.20.attention.self.query.weight', 'base_model.encoder.layer.22.attention.self.key.bias', 'base_model.encoder.layer.19.attention.self.query.bias', 'base_model.encoder.layer.2.output.LayerNorm.bias', 'base_model.encoder.layer.15.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.15.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.8.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.20.attention.self.value.weight', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.10.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.8.attention.output.dense.bias', 'base_model.encoder.layer.16.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.5.attention.self.value.weight', 'base_model.encoder.layer.2.intermediate.dense.bias', 'base_model.encoder.layer.15.attention.output.LayerNorm.weight', 'base_model.encoder.layer.22.attention.self.key.weight', 'base_model.encoder.layer.15.attention.output.LayerNorm.bias', 'base_model.encoder.layer.13.intermediate.dense.weight']
- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of XLMRobertaModel were not initialized from the model checkpoint at /cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//squad/xlm-KG_LR3e-5_EPOCH2.0_maxlen384_batchsize4_gradacc4 and are newly initialized: ['encoder.layer.9.attention.output.dense.bias', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.22.attention.self.query.weight', 'encoder.layer.12.output.LayerNorm.bias', 'encoder.layer.22.attention.output.LayerNorm.bias', 'encoder.layer.6.attention.output.dense.weight', 'encoder.layer.19.intermediate.dense.bias', 'encoder.layer.18.output.dense.weight', 'encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.layer.6.output.LayerNorm.bias', 'encoder.layer.8.attention.self.value.bias', 'encoder.layer.11.attention.self.value.bias', 'encoder.layer.12.attention.self.value.bias', 'encoder.layer.21.attention.self.key.weight', 'encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.0.attention.self.value.weight', 'encoder.layer.7.attention.self.query.weight', 'encoder.layer.14.attention.self.value.weight', 'encoder.layer.0.attention.self.query.weight', 'encoder.layer.13.attention.output.LayerNorm.weight', 'encoder.layer.8.attention.output.LayerNorm.bias', 'encoder.layer.0.attention.self.key.weight', 'encoder.layer.1.attention.self.query.weight', 'encoder.layer.17.attention.self.value.bias', 'encoder.layer.3.attention.self.key.weight', 'encoder.layer.1.attention.output.LayerNorm.weight', 'encoder.layer.16.output.dense.weight', 'encoder.layer.19.attention.self.value.weight', 'encoder.layer.23.output.LayerNorm.bias', 'encoder.layer.17.attention.output.LayerNorm.bias', 'encoder.layer.5.output.LayerNorm.bias', 'encoder.layer.20.attention.self.value.bias', 'encoder.layer.16.attention.self.key.weight', 'encoder.layer.11.attention.self.query.bias', 'encoder.layer.2.output.dense.bias', 'encoder.layer.21.output.dense.weight', 'encoder.layer.23.attention.self.value.bias', 'encoder.layer.14.attention.self.query.bias', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.12.attention.output.LayerNorm.weight', 'encoder.layer.17.output.LayerNorm.bias', 'encoder.layer.22.intermediate.dense.bias', 'encoder.layer.5.attention.self.value.weight', 'encoder.layer.3.attention.output.dense.bias', 'encoder.layer.12.intermediate.dense.bias', 'encoder.layer.17.attention.output.dense.bias', 'encoder.layer.9.output.LayerNorm.weight', 'encoder.layer.16.output.dense.bias', 'encoder.layer.19.attention.self.query.weight', 'encoder.layer.5.output.dense.bias', 'encoder.layer.5.attention.output.dense.bias', 'encoder.layer.7.attention.self.value.weight', 'encoder.layer.17.attention.self.value.weight', 'encoder.layer.3.attention.self.query.bias', 'encoder.layer.9.attention.self.key.bias', 'encoder.layer.10.attention.self.query.weight', 'encoder.layer.20.attention.output.LayerNorm.weight', 'encoder.layer.21.attention.output.dense.weight', 'encoder.layer.3.attention.self.value.bias', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.1.output.dense.weight', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.6.attention.self.value.bias', 'encoder.layer.2.attention.output.dense.bias', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.2.attention.output.LayerNorm.bias', 'encoder.layer.5.attention.self.key.bias', 'encoder.layer.10.output.dense.weight', 'encoder.layer.22.output.LayerNorm.bias', 'encoder.layer.13.attention.self.query.bias', 'encoder.layer.23.attention.output.dense.bias', 'encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.layer.0.attention.self.value.bias', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.3.attention.self.query.weight', 'encoder.layer.13.attention.self.value.weight', 'encoder.layer.17.attention.self.key.weight', 'encoder.layer.13.attention.output.dense.weight', 'encoder.layer.10.intermediate.dense.weight', 'encoder.layer.6.attention.self.key.weight', 'encoder.layer.21.output.LayerNorm.bias', 'encoder.layer.20.attention.self.key.bias', 'encoder.layer.9.attention.output.dense.weight', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.11.attention.output.dense.weight', 'encoder.layer.13.output.dense.weight', 'embeddings.LayerNorm.weight', 'encoder.layer.14.output.LayerNorm.weight', 'encoder.layer.19.output.dense.weight', 'encoder.layer.20.intermediate.dense.weight', 'encoder.layer.20.output.dense.weight', 'encoder.layer.21.intermediate.dense.bias', 'encoder.layer.20.attention.self.query.weight', 'encoder.layer.2.attention.self.value.bias', 'encoder.layer.11.attention.self.key.weight', 'encoder.layer.13.output.LayerNorm.bias', 'encoder.layer.23.intermediate.dense.bias', 'encoder.layer.21.attention.output.LayerNorm.weight', 'encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.layer.19.attention.output.dense.weight', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.22.output.dense.weight', 'encoder.layer.10.attention.self.key.weight', 'encoder.layer.7.attention.self.key.weight', 'encoder.layer.8.attention.self.value.weight', 'encoder.layer.9.attention.self.value.weight', 'encoder.layer.23.attention.self.query.weight', 'encoder.layer.6.output.dense.weight', 'encoder.layer.8.attention.output.LayerNorm.weight', 'encoder.layer.0.attention.self.key.bias', 'encoder.layer.8.attention.output.dense.weight', 'encoder.layer.14.attention.output.LayerNorm.bias', 'encoder.layer.20.attention.output.dense.weight', 'encoder.layer.21.attention.output.LayerNorm.bias', 'encoder.layer.22.output.LayerNorm.weight', 'encoder.layer.23.output.dense.bias', 'encoder.layer.1.attention.output.dense.bias', 'encoder.layer.10.attention.output.LayerNorm.weight', 'encoder.layer.19.attention.self.value.bias', 'encoder.layer.15.attention.self.key.weight', 'encoder.layer.15.output.dense.weight', 'encoder.layer.8.output.dense.bias', 'encoder.layer.13.intermediate.dense.bias', 'encoder.layer.16.attention.self.query.weight', 'encoder.layer.15.attention.output.LayerNorm.weight', 'encoder.layer.2.attention.self.key.bias', 'encoder.layer.2.attention.self.key.weight', 'encoder.layer.23.attention.output.LayerNorm.bias', 'encoder.layer.4.attention.self.value.bias', 'encoder.layer.12.attention.self.key.bias', 'encoder.layer.9.attention.output.LayerNorm.weight', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.10.attention.output.dense.weight', 'encoder.layer.15.output.LayerNorm.bias', 'encoder.layer.4.attention.output.dense.weight', 'encoder.layer.14.attention.self.key.bias', 'encoder.layer.3.attention.self.value.weight', 'encoder.layer.15.attention.self.query.weight', 'encoder.layer.6.attention.output.dense.bias', 'encoder.layer.1.attention.self.query.bias', 'encoder.layer.18.attention.output.dense.weight', 'encoder.layer.10.attention.self.key.bias', 'encoder.layer.20.attention.self.key.weight', 'encoder.layer.17.attention.self.key.bias', 'encoder.layer.22.attention.self.value.weight', 'encoder.layer.1.attention.self.key.bias', 'encoder.layer.4.output.dense.weight', 'encoder.layer.13.output.LayerNorm.weight', 'encoder.layer.5.attention.self.query.bias', 'encoder.layer.15.output.dense.bias', 'encoder.layer.13.attention.self.query.weight', 'encoder.layer.0.output.LayerNorm.weight', 'embeddings.LayerNorm.bias', 'encoder.layer.22.output.dense.bias', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.10.output.dense.bias', 'encoder.layer.14.output.LayerNorm.bias', 'encoder.layer.23.output.dense.weight', 'encoder.layer.11.attention.self.query.weight', 'encoder.layer.11.output.dense.bias', 'encoder.layer.16.attention.self.value.bias', 'encoder.layer.8.attention.self.key.weight', 'encoder.layer.18.intermediate.dense.weight', 'encoder.layer.11.output.dense.weight', 'encoder.layer.20.output.dense.bias', 'encoder.layer.9.attention.self.value.bias', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.17.attention.self.query.weight', 'encoder.layer.8.output.LayerNorm.weight', 'encoder.layer.6.output.dense.bias', 'encoder.layer.8.attention.self.query.bias', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.7.output.dense.weight', 'encoder.layer.23.attention.self.key.weight', 'encoder.layer.19.output.dense.bias', 'encoder.layer.23.attention.self.value.weight', 'encoder.layer.13.attention.output.LayerNorm.bias', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.2.attention.self.value.weight', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.16.attention.self.key.bias', 'encoder.layer.19.attention.self.query.bias', 'encoder.layer.9.attention.self.key.weight', 'encoder.layer.1.attention.self.key.weight', 'encoder.layer.1.attention.self.value.weight', 'embeddings.token_type_embeddings.weight', 'encoder.layer.15.output.LayerNorm.weight', 'encoder.layer.16.intermediate.dense.weight', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.17.attention.self.query.bias', 'encoder.layer.19.attention.output.LayerNorm.bias', 'encoder.layer.22.attention.self.query.bias', 'encoder.layer.13.attention.output.dense.bias', 'encoder.layer.22.attention.output.dense.weight', 'encoder.layer.15.attention.self.value.weight', 'encoder.layer.17.attention.output.dense.weight', 'encoder.layer.6.attention.self.query.weight', 'encoder.layer.7.attention.output.LayerNorm.bias', 'encoder.layer.9.attention.self.query.bias', 'encoder.layer.15.attention.output.dense.weight', 'encoder.layer.16.attention.output.dense.bias', 'encoder.layer.5.attention.self.query.weight', 'encoder.layer.12.attention.self.query.weight', 'encoder.layer.16.intermediate.dense.bias', 'encoder.layer.9.output.LayerNorm.bias', 'encoder.layer.18.output.dense.bias', 'encoder.layer.10.output.LayerNorm.weight', 'encoder.layer.4.attention.self.value.weight', 'encoder.layer.20.attention.output.dense.bias', 'encoder.layer.18.attention.output.dense.bias', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.21.attention.self.value.bias', 'encoder.layer.17.output.dense.bias', 'encoder.layer.21.attention.self.value.weight', 'encoder.layer.8.attention.self.query.weight', 'encoder.layer.9.output.dense.weight', 'encoder.layer.6.attention.output.LayerNorm.bias', 'encoder.layer.4.attention.self.query.bias', 'encoder.layer.7.attention.output.LayerNorm.weight', 'encoder.layer.15.intermediate.dense.bias', 'encoder.layer.19.output.LayerNorm.weight', 'embeddings.word_embeddings.weight', 'encoder.layer.14.attention.output.dense.bias', 'encoder.layer.18.intermediate.dense.bias', 'encoder.layer.20.output.LayerNorm.bias', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.14.attention.output.dense.weight', 'encoder.layer.19.attention.output.LayerNorm.weight', 'pooler.dense.weight', 'encoder.layer.19.output.LayerNorm.bias', 'encoder.layer.21.attention.self.query.bias', 'encoder.layer.2.attention.output.LayerNorm.weight', 'encoder.layer.1.attention.output.dense.weight', 'encoder.layer.0.attention.output.dense.weight', 'encoder.layer.4.attention.self.query.weight', 'encoder.layer.14.output.dense.weight', 'encoder.layer.17.output.dense.weight', 'encoder.layer.14.output.dense.bias', 'encoder.layer.13.attention.self.value.bias', 'encoder.layer.14.intermediate.dense.weight', 'encoder.layer.12.attention.self.value.weight', 'encoder.layer.21.output.LayerNorm.weight', 'embeddings.position_embeddings.weight', 'encoder.layer.11.attention.output.dense.bias', 'encoder.layer.12.output.dense.bias', 'encoder.layer.5.attention.self.key.weight', 'encoder.layer.5.attention.output.LayerNorm.weight', 'encoder.layer.21.attention.self.query.weight', 'encoder.layer.14.attention.output.LayerNorm.weight', 'encoder.layer.21.output.dense.bias', 'encoder.layer.14.attention.self.key.weight', 'encoder.layer.18.attention.output.LayerNorm.weight', 'encoder.layer.12.attention.self.key.weight', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.20.attention.self.query.bias', 'encoder.layer.10.attention.self.value.weight', 'pooler.dense.bias', 'encoder.layer.7.attention.output.dense.weight', 'encoder.layer.10.attention.self.query.bias', 'encoder.layer.14.intermediate.dense.bias', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.7.output.dense.bias', 'encoder.layer.18.output.LayerNorm.weight', 'encoder.layer.19.attention.output.dense.bias', 'encoder.layer.18.attention.self.value.weight', 'encoder.layer.17.intermediate.dense.bias', 'encoder.layer.20.attention.output.LayerNorm.bias', 'encoder.layer.9.output.dense.bias', 'encoder.layer.13.attention.self.key.bias', 'encoder.layer.15.attention.self.key.bias', 'encoder.layer.12.attention.output.LayerNorm.bias', 'encoder.layer.4.attention.self.key.weight', 'encoder.layer.15.attention.output.dense.bias', 'encoder.layer.15.attention.output.LayerNorm.bias', 'encoder.layer.12.attention.output.dense.bias', 'encoder.layer.21.attention.output.dense.bias', 'encoder.layer.7.attention.self.query.bias', 'encoder.layer.4.output.dense.bias', 'encoder.layer.15.attention.self.value.bias', 'encoder.layer.22.attention.output.LayerNorm.weight', 'encoder.layer.0.output.dense.weight', 'encoder.layer.7.attention.self.value.bias', 'encoder.layer.11.attention.self.key.bias', 'encoder.layer.6.attention.self.key.bias', 'encoder.layer.18.attention.output.LayerNorm.bias', 'encoder.layer.16.output.LayerNorm.weight', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.21.attention.self.key.bias', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.12.output.LayerNorm.weight', 'encoder.layer.7.attention.output.dense.bias', 'encoder.layer.11.attention.self.value.weight', 'encoder.layer.4.attention.output.LayerNorm.weight', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.22.attention.output.dense.bias', 'encoder.layer.10.attention.output.dense.bias', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.18.attention.self.key.weight', 'encoder.layer.7.output.LayerNorm.bias', 'encoder.layer.0.attention.output.LayerNorm.weight', 'encoder.layer.3.attention.self.key.bias', 'encoder.layer.8.attention.self.key.bias', 'encoder.layer.10.attention.output.LayerNorm.bias', 'encoder.layer.1.output.dense.bias', 'encoder.layer.7.output.LayerNorm.weight', 'encoder.layer.6.attention.self.value.weight', 'encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.layer.2.attention.self.query.bias', 'encoder.layer.19.intermediate.dense.weight', 'encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.layer.23.attention.output.LayerNorm.weight', 'encoder.layer.18.attention.self.query.weight', 'encoder.layer.22.attention.self.value.bias', 'encoder.layer.13.intermediate.dense.weight', 'encoder.layer.14.attention.self.query.weight', 'encoder.layer.15.attention.self.query.bias', 'encoder.layer.23.attention.self.key.bias', 'encoder.layer.15.intermediate.dense.weight', 'encoder.layer.5.output.dense.weight', 'encoder.layer.19.attention.self.key.weight', 'encoder.layer.14.attention.self.value.bias', 'encoder.layer.4.attention.output.dense.bias', 'encoder.layer.10.attention.self.value.bias', 'encoder.layer.23.attention.self.query.bias', 'encoder.layer.16.attention.output.dense.weight', 'encoder.layer.18.output.LayerNorm.bias', 'encoder.layer.16.output.LayerNorm.bias', 'encoder.layer.17.attention.output.LayerNorm.weight', 'encoder.layer.2.attention.self.query.weight', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.21.intermediate.dense.weight', 'encoder.layer.6.attention.output.LayerNorm.weight', 'encoder.layer.12.intermediate.dense.weight', 'encoder.layer.17.intermediate.dense.weight', 'encoder.layer.3.output.dense.weight', 'encoder.layer.12.output.dense.weight', 'encoder.layer.23.intermediate.dense.weight', 'encoder.layer.12.attention.output.dense.weight', 'encoder.layer.2.attention.output.dense.weight', 'encoder.layer.16.attention.output.LayerNorm.weight', 'encoder.layer.4.attention.self.key.bias', 'encoder.layer.22.intermediate.dense.weight', 'encoder.layer.13.output.dense.bias', 'encoder.layer.5.attention.self.value.bias', 'encoder.layer.5.attention.output.dense.weight', 'encoder.layer.17.output.LayerNorm.weight', 'encoder.layer.7.intermediate.dense.bias', 'encoder.layer.18.attention.self.value.bias', 'encoder.layer.0.attention.self.query.bias', 'encoder.layer.16.attention.output.LayerNorm.bias', 'encoder.layer.16.attention.self.query.bias', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.22.attention.self.key.bias', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.1.attention.self.value.bias', 'encoder.layer.6.attention.self.query.bias', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.9.attention.output.LayerNorm.bias', 'encoder.layer.13.attention.self.key.weight', 'encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.layer.7.attention.self.key.bias', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.23.output.LayerNorm.weight', 'encoder.layer.10.output.LayerNorm.bias', 'encoder.layer.11.output.LayerNorm.weight', 'encoder.layer.16.attention.self.value.weight', 'encoder.layer.8.attention.output.dense.bias', 'encoder.layer.18.attention.self.query.bias', 'encoder.layer.19.attention.self.key.bias', 'encoder.layer.12.attention.self.query.bias', 'encoder.layer.8.output.LayerNorm.bias', 'encoder.layer.22.attention.self.key.weight', 'encoder.layer.20.output.LayerNorm.weight', 'encoder.layer.11.output.LayerNorm.bias', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.0.output.dense.bias', 'encoder.layer.20.attention.self.value.weight', 'encoder.layer.0.attention.output.dense.bias', 'encoder.layer.23.attention.output.dense.weight', 'encoder.layer.11.attention.output.LayerNorm.weight', 'encoder.layer.8.output.dense.weight', 'encoder.layer.18.attention.self.key.bias', 'encoder.layer.2.output.dense.weight', 'encoder.layer.3.output.dense.bias', 'encoder.layer.20.intermediate.dense.bias', 'encoder.layer.4.attention.output.LayerNorm.bias', 'encoder.layer.9.attention.self.query.weight', 'encoder.layer.3.attention.output.dense.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Overwriting existing adapter 'ep'.
Overwriting existing adapter 'tp'.
Overwriting existing adapter 'es'.
Overwriting existing adapter 'ts'.
Overwriting existing adapter fusion module 'ep,tp,es,ts'
05/09/2022 09:06:39 - INFO - __main__ -   Creating features from dataset file at .
/cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//squad/xlm-KG_LR3e-5_EPOCH2.0_maxlen384_batchsize4_gradacc4
XLMConfig {
  "architectures": [
    "XLMRobertaForMaskedLM"
  ],
  "asm": false,
  "attention_dropout": 0.1,
  "attention_probs_dropout_prob": 0.1,
  "bos_index": 0,
  "bos_token_id": 0,
  "causal": false,
  "dropout": 0.1,
  "emb_dim": 1024,
  "embed_init_std": 0.02209708691207961,
  "end_n_top": 5,
  "eos_index": 1,
  "eos_token_id": 2,
  "gelu_activation": true,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "init_std": 0.02,
  "initializer_range": 0.02,
  "intermediate_size": 4096,
  "is_encoder": true,
  "lang_id": 0,
  "layer_norm_eps": 1e-05,
  "mask_index": 5,
  "mask_token_id": 0,
  "max_position_embeddings": 514,
  "model_type": "xlm",
  "n_heads": 16,
  "n_langs": 1,
  "n_layers": 24,
  "output_past": true,
  "pad_index": 2,
  "pad_token_id": 1,
  "sinusoidal_embeddings": false,
  "start_n_top": 5,
  "summary_activation": null,
  "summary_first_dropout": 0.1,
  "summary_proj_to_labels": true,
  "summary_type": "first",
  "summary_use_proj": true,
  "transformers_version": "4.17.0",
  "type_vocab_size": 1,
  "unk_index": 3,
  "use_lang_emb": false,
  "vocab_size": 250002
}

  0%|          | 0/48 [00:00<?, ?it/s] 15%|█▍        | 7/48 [00:00<00:00, 64.67it/s] 31%|███▏      | 15/48 [00:00<00:00, 73.30it/s] 48%|████▊     | 23/48 [00:00<00:00, 58.49it/s] 62%|██████▎   | 30/48 [00:00<00:00, 58.68it/s] 77%|███████▋  | 37/48 [00:00<00:00, 60.00it/s] 96%|█████████▌| 46/48 [00:00<00:00, 66.88it/s]100%|██████████| 48/48 [00:00<00:00, 65.05it/s]
convert squad examples to features:   0%|          | 0/1190 [00:00<?, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.
convert squad examples to features:   0%|          | 1/1190 [00:00<07:31,  2.63it/s]convert squad examples to features:   5%|▌         | 65/1190 [00:00<00:09, 115.29it/s]convert squad examples to features:   8%|▊         | 97/1190 [00:00<00:08, 129.20it/s]convert squad examples to features:  11%|█         | 129/1190 [00:01<00:07, 149.00it/s]convert squad examples to features:  14%|█▎        | 161/1190 [00:01<00:05, 172.64it/s]convert squad examples to features:  16%|█▌        | 193/1190 [00:01<00:05, 176.92it/s]convert squad examples to features:  19%|█▉        | 225/1190 [00:01<00:05, 170.82it/s]convert squad examples to features:  22%|██▏       | 257/1190 [00:01<00:06, 152.49it/s]convert squad examples to features:  24%|██▍       | 289/1190 [00:01<00:05, 164.63it/s]convert squad examples to features:  27%|██▋       | 321/1190 [00:02<00:05, 160.24it/s]convert squad examples to features:  30%|██▉       | 353/1190 [00:02<00:05, 166.70it/s]convert squad examples to features:  32%|███▏      | 385/1190 [00:03<00:09, 82.75it/s] convert squad examples to features:  35%|███▌      | 417/1190 [00:03<00:08, 90.60it/s]convert squad examples to features:  38%|███▊      | 449/1190 [00:03<00:07, 100.67it/s]convert squad examples to features:  40%|████      | 481/1190 [00:03<00:06, 108.57it/s]convert squad examples to features:  43%|████▎     | 513/1190 [00:04<00:05, 114.50it/s]convert squad examples to features:  46%|████▌     | 545/1190 [00:04<00:05, 120.87it/s]convert squad examples to features:  48%|████▊     | 577/1190 [00:04<00:04, 129.91it/s]convert squad examples to features:  51%|█████     | 609/1190 [00:04<00:04, 123.31it/s]convert squad examples to features:  54%|█████▍    | 641/1190 [00:05<00:04, 123.65it/s]convert squad examples to features:  57%|█████▋    | 673/1190 [00:05<00:04, 120.44it/s]convert squad examples to features:  59%|█████▉    | 705/1190 [00:05<00:03, 125.41it/s]convert squad examples to features:  62%|██████▏   | 737/1190 [00:05<00:03, 134.93it/s]convert squad examples to features:  65%|██████▍   | 769/1190 [00:06<00:03, 136.48it/s]convert squad examples to features:  67%|██████▋   | 801/1190 [00:06<00:02, 141.27it/s]convert squad examples to features:  70%|███████   | 833/1190 [00:06<00:02, 130.23it/s]convert squad examples to features:  73%|███████▎  | 865/1190 [00:06<00:02, 141.30it/s]convert squad examples to features:  75%|███████▌  | 897/1190 [00:07<00:02, 130.61it/s]convert squad examples to features:  78%|███████▊  | 929/1190 [00:07<00:02, 127.61it/s]convert squad examples to features:  81%|████████  | 961/1190 [00:07<00:01, 137.97it/s]convert squad examples to features:  83%|████████▎ | 993/1190 [00:07<00:01, 146.32it/s]convert squad examples to features:  86%|████████▌ | 1025/1190 [00:07<00:01, 151.62it/s]convert squad examples to features:  89%|████████▉ | 1057/1190 [00:08<00:00, 149.55it/s]convert squad examples to features:  92%|█████████▏| 1089/1190 [00:08<00:00, 155.05it/s]convert squad examples to features:  94%|█████████▍| 1121/1190 [00:08<00:00, 148.68it/s]convert squad examples to features:  97%|█████████▋| 1153/1190 [00:08<00:00, 146.19it/s]convert squad examples to features: 100%|██████████| 1190/1190 [00:08<00:00, 135.23it/s]
add example index and unique id:   0%|          | 0/1190 [00:00<?, ?it/s]add example index and unique id: 100%|██████████| 1190/1190 [00:00<00:00, 440881.70it/s]
05/09/2022 09:06:48 - INFO - __main__ -   Saving features into cached file ./cached_xquad.ru.json_xlm-KG_LR3e-5_EPOCH2.0_maxlen384_batchsize4_gradacc4_384_ru
05/09/2022 09:06:50 - INFO - __main__ -   ***** Running evaluation  *****
05/09/2022 09:06:50 - INFO - __main__ -     Num examples = 1332
05/09/2022 09:06:50 - INFO - __main__ -     Batch size = 8
Evaluating:   0%|          | 0/167 [00:00<?, ?it/s]Evaluating:   1%|          | 1/167 [00:00<02:31,  1.09it/s]Evaluating:   1%|          | 2/167 [00:01<01:35,  1.73it/s]Evaluating:   2%|▏         | 3/167 [00:01<01:17,  2.12it/s]Evaluating:   2%|▏         | 4/167 [00:01<01:08,  2.37it/s]Evaluating:   3%|▎         | 5/167 [00:02<01:03,  2.54it/s]Evaluating:   4%|▎         | 6/167 [00:02<01:00,  2.65it/s]Evaluating:   4%|▍         | 7/167 [00:02<00:58,  2.74it/s]Evaluating:   5%|▍         | 8/167 [00:03<00:57,  2.78it/s]Evaluating:   5%|▌         | 9/167 [00:03<00:55,  2.82it/s]Evaluating:   6%|▌         | 10/167 [00:04<00:55,  2.84it/s]Evaluating:   7%|▋         | 11/167 [00:04<00:54,  2.86it/s]Evaluating:   7%|▋         | 12/167 [00:04<00:54,  2.87it/s]Evaluating:   8%|▊         | 13/167 [00:05<00:53,  2.88it/s]Evaluating:   8%|▊         | 14/167 [00:05<00:53,  2.88it/s]Evaluating:   9%|▉         | 15/167 [00:05<00:52,  2.88it/s]Evaluating:  10%|▉         | 16/167 [00:06<00:52,  2.89it/s]Evaluating:  10%|█         | 17/167 [00:06<00:51,  2.90it/s]Evaluating:  11%|█         | 18/167 [00:06<00:51,  2.90it/s]Evaluating:  11%|█▏        | 19/167 [00:07<00:51,  2.90it/s]Evaluating:  12%|█▏        | 20/167 [00:07<00:50,  2.89it/s]Evaluating:  13%|█▎        | 21/167 [00:07<00:50,  2.90it/s]Evaluating:  13%|█▎        | 22/167 [00:08<00:49,  2.90it/s]Evaluating:  14%|█▍        | 23/167 [00:08<00:49,  2.90it/s]Evaluating:  14%|█▍        | 24/167 [00:08<00:49,  2.90it/s]Evaluating:  15%|█▍        | 25/167 [00:09<00:48,  2.90it/s]Evaluating:  16%|█▌        | 26/167 [00:09<00:48,  2.90it/s]Evaluating:  16%|█▌        | 27/167 [00:09<00:48,  2.90it/s]Evaluating:  17%|█▋        | 28/167 [00:10<00:48,  2.89it/s]Evaluating:  17%|█▋        | 29/167 [00:10<00:47,  2.90it/s]Evaluating:  18%|█▊        | 30/167 [00:10<00:47,  2.91it/s]Evaluating:  19%|█▊        | 31/167 [00:11<00:46,  2.92it/s]Evaluating:  19%|█▉        | 32/167 [00:11<00:46,  2.91it/s]Evaluating:  20%|█▉        | 33/167 [00:11<00:46,  2.90it/s]Evaluating:  20%|██        | 34/167 [00:12<00:45,  2.90it/s]Evaluating:  21%|██        | 35/167 [00:12<00:45,  2.91it/s]Evaluating:  22%|██▏       | 36/167 [00:12<00:44,  2.91it/s]Evaluating:  22%|██▏       | 37/167 [00:13<00:44,  2.92it/s]Evaluating:  23%|██▎       | 38/167 [00:13<00:44,  2.91it/s]Evaluating:  23%|██▎       | 39/167 [00:14<00:44,  2.91it/s]Evaluating:  24%|██▍       | 40/167 [00:14<00:43,  2.90it/s]Evaluating:  25%|██▍       | 41/167 [00:14<00:43,  2.91it/s]Evaluating:  25%|██▌       | 42/167 [00:15<00:42,  2.92it/s]Evaluating:  26%|██▌       | 43/167 [00:15<00:42,  2.92it/s]Evaluating:  26%|██▋       | 44/167 [00:15<00:42,  2.91it/s]Evaluating:  27%|██▋       | 45/167 [00:16<00:41,  2.91it/s]Evaluating:  28%|██▊       | 46/167 [00:16<00:41,  2.90it/s]Evaluating:  28%|██▊       | 47/167 [00:16<00:41,  2.91it/s]Evaluating:  29%|██▊       | 48/167 [00:17<00:40,  2.91it/s]Evaluating:  29%|██▉       | 49/167 [00:17<00:40,  2.91it/s]Evaluating:  30%|██▉       | 50/167 [00:17<00:40,  2.91it/s]Evaluating:  31%|███       | 51/167 [00:18<00:39,  2.91it/s]Evaluating:  31%|███       | 52/167 [00:18<00:39,  2.91it/s]Evaluating:  32%|███▏      | 53/167 [00:18<00:39,  2.90it/s]Evaluating:  32%|███▏      | 54/167 [00:19<00:39,  2.89it/s]Evaluating:  33%|███▎      | 55/167 [00:19<00:38,  2.89it/s]Evaluating:  34%|███▎      | 56/167 [00:19<00:38,  2.89it/s]Evaluating:  34%|███▍      | 57/167 [00:20<00:38,  2.89it/s]Evaluating:  35%|███▍      | 58/167 [00:20<00:37,  2.88it/s]Evaluating:  35%|███▌      | 59/167 [00:20<00:37,  2.88it/s]Evaluating:  36%|███▌      | 60/167 [00:21<00:37,  2.87it/s]Evaluating:  37%|███▋      | 61/167 [00:21<00:37,  2.86it/s]Evaluating:  37%|███▋      | 62/167 [00:21<00:36,  2.87it/s]Evaluating:  38%|███▊      | 63/167 [00:22<00:36,  2.88it/s]Evaluating:  38%|███▊      | 64/167 [00:22<00:35,  2.89it/s]Evaluating:  39%|███▉      | 65/167 [00:22<00:35,  2.89it/s]Evaluating:  40%|███▉      | 66/167 [00:23<00:34,  2.90it/s]Evaluating:  40%|████      | 67/167 [00:23<00:34,  2.90it/s]Evaluating:  41%|████      | 68/167 [00:24<00:34,  2.90it/s]Evaluating:  41%|████▏     | 69/167 [00:24<00:33,  2.89it/s]Evaluating:  42%|████▏     | 70/167 [00:24<00:33,  2.89it/s]Evaluating:  43%|████▎     | 71/167 [00:25<00:33,  2.89it/s]Evaluating:  43%|████▎     | 72/167 [00:25<00:32,  2.90it/s]Evaluating:  44%|████▎     | 73/167 [00:25<00:32,  2.89it/s]Evaluating:  44%|████▍     | 74/167 [00:26<00:32,  2.89it/s]Evaluating:  45%|████▍     | 75/167 [00:26<00:31,  2.90it/s]Evaluating:  46%|████▌     | 76/167 [00:26<00:31,  2.90it/s]Evaluating:  46%|████▌     | 77/167 [00:27<00:30,  2.91it/s]Evaluating:  47%|████▋     | 78/167 [00:27<00:30,  2.90it/s]Evaluating:  47%|████▋     | 79/167 [00:27<00:30,  2.90it/s]Evaluating:  48%|████▊     | 80/167 [00:28<00:30,  2.90it/s]Evaluating:  49%|████▊     | 81/167 [00:28<00:29,  2.90it/s]Evaluating:  49%|████▉     | 82/167 [00:28<00:29,  2.89it/s]Evaluating:  50%|████▉     | 83/167 [00:29<00:29,  2.90it/s]Evaluating:  50%|█████     | 84/167 [00:29<00:28,  2.90it/s]Evaluating:  51%|█████     | 85/167 [00:29<00:28,  2.90it/s]Evaluating:  51%|█████▏    | 86/167 [00:30<00:27,  2.91it/s]Evaluating:  52%|█████▏    | 87/167 [00:30<00:27,  2.92it/s]Evaluating:  53%|█████▎    | 88/167 [00:30<00:27,  2.91it/s]Evaluating:  53%|█████▎    | 89/167 [00:31<00:26,  2.90it/s]Evaluating:  54%|█████▍    | 90/167 [00:31<00:26,  2.89it/s]Evaluating:  54%|█████▍    | 91/167 [00:31<00:26,  2.88it/s]Evaluating:  55%|█████▌    | 92/167 [00:32<00:25,  2.89it/s]Evaluating:  56%|█████▌    | 93/167 [00:32<00:25,  2.89it/s]Evaluating:  56%|█████▋    | 94/167 [00:32<00:25,  2.88it/s]Evaluating:  57%|█████▋    | 95/167 [00:33<00:24,  2.88it/s]Evaluating:  57%|█████▋    | 96/167 [00:33<00:24,  2.89it/s]Evaluating:  58%|█████▊    | 97/167 [00:34<00:24,  2.89it/s]Evaluating:  59%|█████▊    | 98/167 [00:34<00:23,  2.89it/s]Evaluating:  59%|█████▉    | 99/167 [00:34<00:23,  2.90it/s]Evaluating:  60%|█████▉    | 100/167 [00:35<00:23,  2.89it/s]Evaluating:  60%|██████    | 101/167 [00:35<00:22,  2.90it/s]Evaluating:  61%|██████    | 102/167 [00:35<00:22,  2.91it/s]Evaluating:  62%|██████▏   | 103/167 [00:36<00:21,  2.91it/s]Evaluating:  62%|██████▏   | 104/167 [00:36<00:21,  2.91it/s]Evaluating:  63%|██████▎   | 105/167 [00:36<00:21,  2.90it/s]Evaluating:  63%|██████▎   | 106/167 [00:37<00:20,  2.91it/s]Evaluating:  64%|██████▍   | 107/167 [00:37<00:20,  2.91it/s]Evaluating:  65%|██████▍   | 108/167 [00:37<00:20,  2.92it/s]Evaluating:  65%|██████▌   | 109/167 [00:38<00:19,  2.92it/s]Evaluating:  66%|██████▌   | 110/167 [00:38<00:19,  2.91it/s]Evaluating:  66%|██████▋   | 111/167 [00:38<00:19,  2.92it/s]Evaluating:  67%|██████▋   | 112/167 [00:39<00:18,  2.91it/s]Evaluating:  68%|██████▊   | 113/167 [00:39<00:18,  2.91it/s]Evaluating:  68%|██████▊   | 114/167 [00:39<00:18,  2.91it/s]Evaluating:  69%|██████▉   | 115/167 [00:40<00:18,  2.84it/s]Evaluating:  69%|██████▉   | 116/167 [00:40<00:17,  2.86it/s]Evaluating:  70%|███████   | 117/167 [00:40<00:17,  2.87it/s]Evaluating:  71%|███████   | 118/167 [00:41<00:17,  2.88it/s]Evaluating:  71%|███████▏  | 119/167 [00:41<00:16,  2.88it/s]Evaluating:  72%|███████▏  | 120/167 [00:41<00:16,  2.89it/s]Evaluating:  72%|███████▏  | 121/167 [00:42<00:15,  2.90it/s]Evaluating:  73%|███████▎  | 122/167 [00:42<00:15,  2.90it/s]Evaluating:  74%|███████▎  | 123/167 [00:42<00:15,  2.91it/s]Evaluating:  74%|███████▍  | 124/167 [00:43<00:14,  2.91it/s]Evaluating:  75%|███████▍  | 125/167 [00:43<00:14,  2.91it/s]Evaluating:  75%|███████▌  | 126/167 [00:44<00:14,  2.91it/s]Evaluating:  76%|███████▌  | 127/167 [00:44<00:13,  2.91it/s]Evaluating:  77%|███████▋  | 128/167 [00:44<00:13,  2.90it/s]Evaluating:  77%|███████▋  | 129/167 [00:45<00:13,  2.90it/s]Evaluating:  78%|███████▊  | 130/167 [00:45<00:12,  2.90it/s]Evaluating:  78%|███████▊  | 131/167 [00:45<00:12,  2.89it/s]Evaluating:  79%|███████▉  | 132/167 [00:46<00:12,  2.90it/s]Evaluating:  80%|███████▉  | 133/167 [00:46<00:11,  2.89it/s]Evaluating:  80%|████████  | 134/167 [00:46<00:11,  2.88it/s]Evaluating:  81%|████████  | 135/167 [00:47<00:11,  2.89it/s]Evaluating:  81%|████████▏ | 136/167 [00:47<00:10,  2.90it/s]Evaluating:  82%|████████▏ | 137/167 [00:47<00:10,  2.91it/s]Evaluating:  83%|████████▎ | 138/167 [00:48<00:09,  2.91it/s]Evaluating:  83%|████████▎ | 139/167 [00:48<00:09,  2.91it/s]Evaluating:  84%|████████▍ | 140/167 [00:48<00:09,  2.91it/s]Evaluating:  84%|████████▍ | 141/167 [00:49<00:08,  2.92it/s]Evaluating:  85%|████████▌ | 142/167 [00:49<00:08,  2.91it/s]Evaluating:  86%|████████▌ | 143/167 [00:49<00:08,  2.92it/s]Evaluating:  86%|████████▌ | 144/167 [00:50<00:07,  2.92it/s]Evaluating:  87%|████████▋ | 145/167 [00:50<00:07,  2.92it/s]Evaluating:  87%|████████▋ | 146/167 [00:50<00:07,  2.93it/s]Evaluating:  88%|████████▊ | 147/167 [00:51<00:06,  2.93it/s]Evaluating:  89%|████████▊ | 148/167 [00:51<00:06,  2.93it/s]Evaluating:  89%|████████▉ | 149/167 [00:51<00:06,  2.92it/s]Evaluating:  90%|████████▉ | 150/167 [00:52<00:05,  2.92it/s]Evaluating:  90%|█████████ | 151/167 [00:52<00:05,  2.92it/s]Evaluating:  91%|█████████ | 152/167 [00:52<00:05,  2.92it/s]Evaluating:  92%|█████████▏| 153/167 [00:53<00:04,  2.91it/s]Evaluating:  92%|█████████▏| 154/167 [00:53<00:04,  2.91it/s]Evaluating:  93%|█████████▎| 155/167 [00:53<00:04,  2.90it/s]Evaluating:  93%|█████████▎| 156/167 [00:54<00:03,  2.91it/s]Evaluating:  94%|█████████▍| 157/167 [00:54<00:03,  2.91it/s]Evaluating:  95%|█████████▍| 158/167 [00:55<00:03,  2.91it/s]Evaluating:  95%|█████████▌| 159/167 [00:55<00:02,  2.91it/s]Evaluating:  96%|█████████▌| 160/167 [00:55<00:02,  2.91it/s]Evaluating:  96%|█████████▋| 161/167 [00:56<00:02,  2.91it/s]Evaluating:  97%|█████████▋| 162/167 [00:56<00:01,  2.90it/s]Evaluating:  98%|█████████▊| 163/167 [00:56<00:01,  2.90it/s]Evaluating:  98%|█████████▊| 164/167 [00:57<00:01,  2.89it/s]Evaluating:  99%|█████████▉| 165/167 [00:57<00:00,  2.88it/s]Evaluating:  99%|█████████▉| 166/167 [00:57<00:00,  2.88it/s]Evaluating: 100%|██████████| 167/167 [00:57<00:00,  3.34it/s]Evaluating: 100%|██████████| 167/167 [00:57<00:00,  2.88it/s]
05/09/2022 09:07:48 - INFO - __main__ -     Evaluation done in total 57.981563 secs (0.043530 sec per example)
05/09/2022 09:07:55 - INFO - __main__ -   Results: {'exact': 63.445378151260506, 'f1': 79.33143807559422, 'total': 1190, 'HasAns_exact': 63.445378151260506, 'HasAns_f1': 79.33143807559422, 'HasAns_total': 1190, 'best_exact': 63.445378151260506, 'best_exact_thresh': 0.0, 'best_f1': 79.33143807559422, 'best_f1_thresh': 0.0}
  tr 
2022-05-09 09:07:59.368172: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0
05/09/2022 09:08:03 - WARNING - __main__ -   Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, 16-bits training: False
You are using a model of type xlm-roberta to instantiate a model of type xlm. This is not supported for all configurations of models and can yield errors.
Some weights of the model checkpoint at /cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//squad/xlm-KG_LR3e-5_EPOCH2.0_maxlen384_batchsize4_gradacc4 were not used when initializing XLMRobertaModel: ['base_model.encoder.layer.18.attention.self.value.weight', 'base_model.encoder.layer.4.output.dense.weight', 'base_model.encoder.layer.6.attention.self.key.bias', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.6.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.17.output.dense.weight', 'base_model.encoder.layer.20.attention.output.dense.weight', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.21.output.LayerNorm.bias', 'base_model.encoder.layer.11.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.14.attention.self.key.weight', 'base_model.pooler.dense.weight', 'base_model.encoder.layer.12.output.dense.weight', 'base_model.encoder.layer.22.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.18.output.dense.bias', 'base_model.encoder.layer.11.output.adapters.tp.adapter_up.weight', 'base_model.embeddings.position_embeddings.weight', 'base_model.encoder.layer.20.attention.self.key.bias', 'base_model.encoder.layer.10.attention.self.key.weight', 'base_model.encoder.layer.14.output.dense.bias', 'base_model.encoder.layer.10.attention.output.dense.weight', 'base_model.encoder.layer.13.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.9.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.16.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.13.attention.self.query.weight', 'base_model.encoder.layer.14.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.10.output.dense.weight', 'base_model.encoder.layer.15.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.21.attention.output.dense.bias', 'base_model.encoder.layer.8.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.18.attention.self.key.bias', 'base_model.encoder.layer.21.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.1.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.4.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.5.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.21.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.3.attention.output.LayerNorm.weight', 'base_model.encoder.layer.20.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.22.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.12.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.12.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.11.attention.self.key.weight', 'base_model.encoder.layer.10.output.dense.bias', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.11.output.LayerNorm.weight', 'base_model.encoder.layer.23.output.dense.weight', 'base_model.encoder.layer.22.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.21.attention.self.value.bias', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.18.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.11.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.4.output.dense.bias', 'base_model.encoder.layer.3.attention.self.key.weight', 'base_model.encoder.layer.9.output.LayerNorm.weight', 'base_model.encoder.layer.10.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.23.intermediate.dense.weight', 'base_model.encoder.layer.17.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.4.attention.output.LayerNorm.weight', 'base_model.encoder.layer.10.attention.self.key.bias', 'base_model.encoder.layer.13.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.14.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.3.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.8.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.15.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.14.attention.self.key.bias', 'base_model.encoder.layer.15.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.7.output.dense.weight', 'base_model.encoder.layer.4.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.14.intermediate.dense.bias', 'base_model.encoder.layer.6.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.18.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.0.output.dense.weight', 'base_model.encoder.layer.1.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.11.attention.output.LayerNorm.weight', 'base_model.encoder.layer.17.attention.output.dense.weight', 'base_model.encoder.layer.10.attention.self.query.weight', 'base_model.encoder.layer.3.attention.self.value.weight', 'base_model.encoder.layer.3.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.5.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.0.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.6.output.LayerNorm.weight', 'base_model.encoder.layer.20.attention.output.LayerNorm.weight', 'base_model.encoder.layer.3.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.12.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.7.attention.output.LayerNorm.bias', 'base_model.encoder.layer.19.output.dense.bias', 'base_model.encoder.layer.5.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.5.attention.self.query.weight', 'base_model.encoder.layer.20.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.10.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.16.attention.self.key.bias', 'base_model.encoder.layer.3.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.17.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.23.attention.self.query.bias', 'base_model.encoder.layer.8.attention.self.query.weight', 'base_model.encoder.layer.7.attention.self.query.weight', 'base_model.encoder.layer.5.attention.self.value.bias', 'base_model.encoder.layer.6.intermediate.dense.bias', 'base_model.encoder.layer.17.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.11.intermediate.dense.bias', 'base_model.encoder.layer.5.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.12.intermediate.dense.bias', 'base_model.encoder.layer.12.attention.output.LayerNorm.weight', 'base_model.encoder.layer.22.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.9.attention.output.dense.weight', 'base_model.encoder.layer.12.attention.self.value.bias', 'base_model.encoder.layer.23.attention.self.key.bias', 'base_model.encoder.layer.5.intermediate.dense.weight', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.13.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.11.attention.self.value.weight', 'base_model.encoder.layer.21.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.7.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.9.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.3.attention.output.dense.bias', 'base_model.encoder.layer.9.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.15.intermediate.dense.bias', 'base_model.encoder.layer.23.attention.output.LayerNorm.bias', 'base_model.encoder.layer.5.output.dense.weight', 'base_model.encoder.layer.21.attention.self.query.weight', 'base_model.encoder.layer.5.output.LayerNorm.bias', 'base_model.encoder.layer.6.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.11.attention.self.value.bias', 'base_model.encoder.layer.9.attention.output.dense.bias', 'base_model.encoder.layer.8.attention.output.dense.bias', 'base_model.encoder.layer.18.attention.self.key.weight', 'base_model.encoder.layer.2.intermediate.dense.bias', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.11.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.18.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.21.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.23.attention.self.value.bias', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.13.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.13.attention.self.value.weight', 'base_model.encoder.layer.7.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.7.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.15.attention.self.key.bias', 'base_model.encoder.layer.3.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.19.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.1.attention.self.key.weight', 'base_model.encoder.layer.21.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.6.output.dense.bias', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.19.attention.self.value.weight', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.18.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.19.output.LayerNorm.weight', 'base_model.encoder.layer.19.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.17.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.13.output.dense.weight', 'base_model.encoder.layer.22.attention.output.dense.bias', 'base_model.encoder.layer.2.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.14.attention.self.query.weight', 'base_model.encoder.layer.17.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.0.attention.self.query.bias', 'base_model.encoder.layer.15.attention.self.value.bias', 'base_model.encoder.layer.3.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.17.attention.self.value.weight', 'base_model.encoder.layer.5.attention.self.key.bias', 'base_model.encoder.layer.6.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.8.output.dense.weight', 'base_model.embeddings.LayerNorm.weight', 'base_model.encoder.layer.4.attention.output.dense.weight', 'base_model.encoder.layer.14.attention.self.value.weight', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.21.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.15.output.LayerNorm.bias', 'base_model.encoder.layer.23.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.3.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.6.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.14.attention.output.LayerNorm.weight', 'base_model.encoder.layer.7.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.3.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.14.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.2.output.dense.weight', 'base_model.encoder.layer.6.attention.self.key.weight', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.15.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.18.output.LayerNorm.weight', 'base_model.encoder.layer.11.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.14.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.23.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.2.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.8.output.LayerNorm.bias', 'base_model.encoder.layer.15.attention.self.value.weight', 'base_model.encoder.layer.20.output.dense.weight', 'base_model.encoder.layer.20.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.21.attention.self.key.bias', 'base_model.encoder.layer.0.intermediate.dense.bias', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.20.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.1.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.21.output.dense.bias', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.18.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.1.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.23.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.13.attention.output.dense.bias', 'base_model.encoder.layer.16.intermediate.dense.weight', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.5.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.21.attention.self.query.bias', 'base_model.encoder.layer.5.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.5.attention.self.value.weight', 'base_model.encoder.layer.10.output.LayerNorm.bias', 'base_model.encoder.layer.12.attention.self.value.weight', 'base_model.encoder.layer.11.output.dense.bias', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.9.intermediate.dense.weight', 'base_model.encoder.layer.12.output.LayerNorm.bias', 'base_model.encoder.layer.18.attention.self.value.bias', 'base_model.encoder.layer.20.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.6.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.18.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.6.attention.self.query.bias', 'base_model.encoder.layer.6.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.1.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.10.intermediate.dense.bias', 'base_model.encoder.layer.13.intermediate.dense.bias', 'base_model.encoder.layer.15.attention.self.query.weight', 'base_model.encoder.layer.21.intermediate.dense.weight', 'base_model.encoder.layer.16.attention.output.LayerNorm.bias', 'base_model.encoder.layer.17.output.dense.bias', 'base_model.encoder.layer.1.attention.self.key.bias', 'base_model.encoder.layer.0.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.19.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.7.output.LayerNorm.bias', 'base_model.encoder.layer.16.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.19.attention.output.LayerNorm.weight', 'base_model.encoder.layer.21.attention.output.LayerNorm.weight', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.5.attention.self.key.weight', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.8.attention.self.value.bias', 'base_model.encoder.layer.19.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.0.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.11.attention.output.dense.weight', 'base_model.encoder.layer.22.attention.self.query.weight', 'base_model.encoder.layer.7.output.LayerNorm.weight', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.8.intermediate.dense.weight', 'base_model.encoder.layer.8.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.15.attention.output.dense.bias', 'base_model.encoder.layer.4.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.8.intermediate.dense.bias', 'base_model.encoder.layer.3.attention.self.value.bias', 'base_model.encoder.layer.13.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.23.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.9.attention.self.key.weight', 'base_model.encoder.layer.13.output.LayerNorm.weight', 'base_model.encoder.layer.2.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.12.intermediate.dense.weight', 'base_model.encoder.layer.22.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.0.attention.output.LayerNorm.bias', 'base_model.encoder.layer.6.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.2.attention.self.value.weight', 'base_model.encoder.layer.2.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.21.attention.self.key.weight', 'base_model.encoder.layer.9.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.6.output.LayerNorm.bias', 'base_model.encoder.layer.1.output.dense.bias', 'base_model.encoder.layer.21.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.15.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.7.attention.self.key.bias', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.4.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.23.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.5.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.13.attention.self.key.weight', 'base_model.encoder.layer.9.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.19.attention.output.dense.bias', 'base_model.encoder.layer.0.attention.output.dense.weight', 'base_model.encoder.layer.12.output.dense.bias', 'base_model.encoder.layer.5.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.19.intermediate.dense.bias', 'base_model.encoder.layer.20.attention.self.query.bias', 'base_model.encoder.layer.6.attention.self.value.bias', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.9.output.dense.weight', 'base_model.encoder.layer.22.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.23.output.LayerNorm.weight', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.16.attention.self.query.weight', 'base_model.encoder.layer.19.attention.self.query.bias', 'base_model.encoder.layer.3.attention.self.query.weight', 'base_model.encoder.layer.5.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.16.attention.output.LayerNorm.weight', 'base_model.encoder.layer.19.output.dense.weight', 'base_model.encoder.layer.11.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.12.attention.self.key.weight', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.14.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.8.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.7.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.9.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.8.attention.self.key.weight', 'base_model.encoder.layer.4.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.12.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.8.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.14.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.20.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.20.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.4.attention.output.dense.bias', 'base_model.encoder.layer.19.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.22.attention.output.LayerNorm.bias', 'base_model.encoder.layer.12.attention.self.query.bias', 'base_model.encoder.layer.7.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.10.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.23.attention.self.query.weight', 'base_model.encoder.layer.15.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.23.attention.self.value.weight', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.22.attention.self.query.bias', 'base_model.encoder.layer.12.attention.self.key.bias', 'base_model.encoder.layer.23.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.13.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.8.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.4.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.16.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.15.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.5.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.7.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.23.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.2.attention.output.dense.bias', 'base_model.encoder.layer.3.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.6.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.5.attention.output.LayerNorm.weight', 'base_model.encoder.layer.8.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.11.attention.output.dense.bias', 'base_model.encoder.layer.11.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.20.output.LayerNorm.weight', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.20.intermediate.dense.weight', 'base_model.encoder.layer.17.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.20.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.7.attention.output.dense.weight', 'base_model.encoder.layer.4.attention.self.key.weight', 'base_model.encoder.layer.16.attention.output.dense.weight', 'base_model.encoder.layer.20.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.1.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.5.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.17.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.9.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.16.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.0.attention.self.value.weight', 'base_model.encoder.layer.10.intermediate.dense.weight', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.19.attention.self.query.weight', 'base_model.encoder.layer.22.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.16.intermediate.dense.bias', 'base_model.encoder.layer.23.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.20.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.3.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.16.attention.self.value.weight', 'base_model.encoder.layer.12.attention.output.LayerNorm.bias', 'base_model.encoder.layer.18.attention.output.dense.bias', 'base_model.encoder.layer.8.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.9.intermediate.dense.bias', 'base_model.encoder.layer.8.attention.output.LayerNorm.weight', 'base_model.encoder.layer.5.output.LayerNorm.weight', 'base_model.encoder.layer.2.attention.self.query.bias', 'base_model.encoder.layer.0.attention.self.key.bias', 'base_model.encoder.layer.10.attention.self.value.bias', 'base_model.encoder.layer.20.attention.self.key.weight', 'base_model.encoder.layer.21.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.23.output.LayerNorm.bias', 'base_model.encoder.layer.5.output.adapters.ts.adapter_down.0.weight', 'base_model.embeddings.word_embeddings.weight', 'base_model.encoder.layer.1.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.14.intermediate.dense.weight', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.13.output.LayerNorm.bias', 'base_model.encoder.layer.1.attention.self.value.bias', 'base_model.encoder.layer.1.intermediate.dense.weight', 'base_model.encoder.layer.11.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.10.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.23.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.3.attention.output.dense.weight', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.7.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.11.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.1.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.17.output.LayerNorm.weight', 'base_model.encoder.layer.11.output.dense.weight', 'base_model.encoder.layer.9.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.4.attention.self.value.weight', 'base_model.encoder.layer.14.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.6.attention.output.dense.bias', 'base_model.encoder.layer.2.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.8.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.13.attention.output.LayerNorm.weight', 'base_model.encoder.layer.6.attention.output.dense.weight', 'base_model.encoder.layer.19.output.LayerNorm.bias', 'base_model.encoder.layer.19.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.19.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.18.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.16.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.14.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.22.output.LayerNorm.bias', 'base_model.encoder.layer.23.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.10.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.6.attention.output.LayerNorm.bias', 'base_model.encoder.layer.18.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.13.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.19.attention.output.dense.weight', 'base_model.encoder.layer.15.attention.self.query.bias', 'base_model.encoder.layer.1.output.LayerNorm.weight', 'base_model.encoder.layer.2.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.8.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.15.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.0.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.15.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.14.output.LayerNorm.bias', 'base_model.encoder.layer.1.attention.self.value.weight', 'base_model.encoder.layer.17.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.18.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.22.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.17.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.6.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.18.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.19.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.6.output.dense.weight', 'base_model.encoder.layer.11.attention.output.LayerNorm.bias', 'base_model.encoder.layer.6.attention.self.query.weight', 'base_model.encoder.layer.2.attention.self.value.bias', 'base_model.encoder.layer.22.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.2.attention.self.query.weight', 'base_model.encoder.layer.11.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.19.intermediate.dense.weight', 'base_model.encoder.layer.0.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.22.output.dense.bias', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.15.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.5.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.12.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.18.attention.self.query.weight', 'base_model.encoder.layer.3.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.2.attention.output.LayerNorm.bias', 'base_model.encoder.layer.2.attention.output.dense.weight', 'base_model.encoder.layer.3.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.4.intermediate.dense.weight', 'base_model.encoder.layer.1.attention.self.query.weight', 'base_model.encoder.layer.13.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.9.attention.self.query.weight', 'base_model.encoder.layer.16.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.12.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.21.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.3.output.LayerNorm.weight', 'base_model.encoder.layer.15.output.dense.bias', 'base_model.encoder.layer.5.intermediate.dense.bias', 'base_model.encoder.layer.22.attention.self.value.bias', 'base_model.encoder.layer.17.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.18.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.13.output.dense.bias', 'base_model.encoder.layer.12.output.LayerNorm.weight', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.20.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.15.attention.output.dense.weight', 'base_model.encoder.layer.21.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.17.attention.self.key.bias', 'base_model.encoder.layer.4.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.0.attention.output.dense.bias', 'base_model.encoder.layer.17.intermediate.dense.weight', 'base_model.encoder.layer.17.attention.self.value.bias', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.11.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.4.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.7.attention.self.query.bias', 'base_model.encoder.layer.22.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.8.attention.self.query.bias', 'base_model.encoder.layer.10.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.4.attention.self.query.bias', 'base_model.encoder.layer.16.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.0.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.3.attention.output.LayerNorm.bias', 'base_model.encoder.layer.7.attention.output.LayerNorm.weight', 'base_model.encoder.layer.9.attention.self.value.bias', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.18.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.1.attention.output.LayerNorm.bias', 'base_model.encoder.layer.22.attention.self.key.weight', 'base_model.encoder.layer.14.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.17.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.19.attention.self.key.weight', 'base_model.encoder.layer.8.attention.self.value.weight', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.1.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.2.attention.output.LayerNorm.weight', 'base_model.encoder.layer.7.intermediate.dense.bias', 'base_model.encoder.layer.22.output.LayerNorm.weight', 'base_model.encoder.layer.23.intermediate.dense.bias', 'base_model.encoder.layer.16.attention.output.dense.bias', 'base_model.encoder.layer.8.output.dense.bias', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.15.output.LayerNorm.weight', 'base_model.encoder.layer.2.attention.self.key.weight', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.11.output.LayerNorm.bias', 'base_model.encoder.layer.22.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.0.attention.self.query.weight', 'base_model.encoder.layer.15.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.9.output.adapters.es.adapter_up.weight', 'base_model.embeddings.LayerNorm.bias', 'base_model.encoder.layer.13.intermediate.dense.weight', 'base_model.encoder.layer.8.output.LayerNorm.weight', 'base_model.encoder.layer.8.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.0.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.10.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.15.attention.output.LayerNorm.bias', 'base_model.encoder.layer.8.attention.output.LayerNorm.bias', 'base_model.encoder.layer.4.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.23.attention.self.key.weight', 'base_model.encoder.layer.1.attention.self.query.bias', 'base_model.encoder.layer.11.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.9.attention.output.LayerNorm.weight', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.17.attention.output.LayerNorm.weight', 'base_model.encoder.layer.18.intermediate.dense.weight', 'base_model.encoder.layer.2.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.13.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.16.output.dense.weight', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.17.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.19.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.6.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.6.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.6.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.9.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.0.attention.self.value.bias', 'base_model.encoder.layer.22.attention.output.LayerNorm.weight', 'base_model.encoder.layer.13.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.13.attention.self.key.bias', 'base_model.encoder.layer.18.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.10.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.3.intermediate.dense.weight', 'base_model.encoder.layer.3.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.21.output.dense.weight', 'base_model.encoder.layer.6.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.4.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.0.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.9.output.LayerNorm.bias', 'base_model.encoder.layer.13.attention.output.LayerNorm.bias', 'base_model.encoder.layer.0.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.20.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.14.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.11.intermediate.dense.weight', 'base_model.encoder.layer.19.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.7.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.5.attention.output.dense.bias', 'base_model.encoder.layer.10.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.9.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.19.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.9.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.22.output.dense.weight', 'base_model.encoder.layer.0.output.dense.bias', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.7.intermediate.dense.weight', 'base_model.encoder.layer.4.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.10.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.17.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.14.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.4.attention.output.LayerNorm.bias', 'base_model.encoder.layer.23.attention.output.dense.bias', 'base_model.encoder.layer.10.attention.output.LayerNorm.bias', 'base_model.encoder.layer.9.attention.self.value.weight', 'base_model.encoder.layer.11.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.1.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.15.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.12.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.18.attention.output.LayerNorm.bias', 'base_model.encoder.layer.7.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.0.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.19.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.16.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.8.attention.self.key.bias', 'base_model.encoder.layer.10.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.12.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.17.attention.output.dense.bias', 'base_model.encoder.layer.9.attention.self.key.bias', 'base_model.encoder.layer.3.attention.self.key.bias', 'base_model.encoder.layer.11.attention.self.key.bias', 'base_model.encoder.layer.20.attention.self.value.bias', 'base_model.encoder.layer.6.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.20.output.dense.bias', 'base_model.encoder.layer.7.output.dense.bias', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.0.output.LayerNorm.bias', 'base_model.encoder.layer.13.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.8.attention.output.dense.weight', 'base_model.encoder.layer.16.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.21.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.9.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.1.attention.output.dense.weight', 'base_model.encoder.layer.18.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.21.attention.output.LayerNorm.bias', 'base_model.encoder.layer.2.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.4.output.LayerNorm.weight', 'base_model.encoder.layer.2.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.10.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.20.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.10.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.5.attention.output.LayerNorm.bias', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.8.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.2.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.12.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.12.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.7.attention.output.dense.bias', 'base_model.encoder.layer.21.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.8.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.14.attention.output.LayerNorm.bias', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.18.output.LayerNorm.bias', 'base_model.encoder.layer.22.intermediate.dense.weight', 'base_model.encoder.layer.16.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.2.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.4.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.0.intermediate.dense.weight', 'base_model.encoder.layer.13.attention.self.value.bias', 'base_model.encoder.layer.13.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.23.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.4.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.12.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.4.attention.self.key.bias', 'base_model.encoder.layer.1.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.2.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.16.attention.self.key.weight', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.17.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.15.attention.self.key.weight', 'base_model.encoder.layer.1.output.dense.weight', 'base_model.encoder.layer.20.output.LayerNorm.bias', 'base_model.embeddings.token_type_embeddings.weight', 'base_model.encoder.layer.7.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.11.attention.self.query.bias', 'base_model.encoder.layer.21.output.LayerNorm.weight', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.19.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.22.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.15.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.20.attention.self.query.weight', 'base_model.encoder.layer.7.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.17.attention.self.key.weight', 'base_model.encoder.layer.9.attention.self.query.bias', 'base_model.encoder.layer.14.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.6.attention.self.value.weight', 'base_model.encoder.layer.15.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.10.output.LayerNorm.weight', 'base_model.encoder.layer.22.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.19.attention.self.key.bias', 'base_model.encoder.layer.10.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.17.attention.self.query.weight', 'base_model.encoder.layer.20.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.2.attention.self.key.bias', 'base_model.encoder.layer.23.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.0.output.LayerNorm.weight', 'base_model.encoder.layer.23.output.dense.bias', 'base_model.encoder.layer.7.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.4.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.22.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.3.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.17.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.22.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.0.attention.self.key.weight', 'base_model.encoder.layer.9.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.embeddings.position_ids', 'base_model.encoder.layer.23.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.5.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.18.output.dense.weight', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.19.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.6.attention.output.LayerNorm.weight', 'base_model.encoder.layer.14.attention.output.dense.weight', 'base_model.encoder.layer.23.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.12.attention.self.query.weight', 'base_model.encoder.layer.22.attention.self.value.weight', 'base_model.encoder.layer.10.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.16.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.1.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.3.output.dense.weight', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.7.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.18.attention.output.LayerNorm.weight', 'base_model.encoder.layer.19.attention.output.LayerNorm.bias', 'base_model.encoder.layer.15.output.dense.weight', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.7.attention.self.value.weight', 'base_model.encoder.layer.12.attention.output.dense.bias', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.17.attention.output.LayerNorm.bias', 'base_model.encoder.layer.11.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.14.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.22.intermediate.dense.bias', 'base_model.encoder.layer.12.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.16.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.21.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.3.output.dense.bias', 'base_model.encoder.layer.20.attention.output.dense.bias', 'base_model.encoder.layer.18.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.0.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.1.attention.output.LayerNorm.weight', 'base_model.encoder.layer.7.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.18.attention.output.dense.weight', 'base_model.encoder.layer.9.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.18.output.adapters.tp.adapter_up.weight', 'qa_outputs.bias', 'base_model.encoder.layer.13.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.5.attention.self.query.bias', 'base_model.encoder.layer.5.attention.output.dense.weight', 'base_model.encoder.layer.9.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.10.attention.self.query.bias', 'base_model.encoder.layer.2.output.dense.bias', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.15.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.14.attention.output.dense.bias', 'base_model.encoder.layer.4.attention.self.query.weight', 'base_model.encoder.layer.6.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.23.attention.output.LayerNorm.weight', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.20.attention.output.LayerNorm.bias', 'base_model.encoder.layer.11.attention.self.query.weight', 'base_model.encoder.layer.3.intermediate.dense.bias', 'base_model.encoder.layer.22.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.21.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.12.attention.output.dense.weight', 'base_model.encoder.layer.23.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.17.intermediate.dense.bias', 'base_model.encoder.layer.3.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.21.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.3.attention.self.query.bias', 'base_model.encoder.layer.21.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.20.intermediate.dense.bias', 'base_model.encoder.layer.8.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.14.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.11.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.16.attention.self.value.bias', 'base_model.encoder.layer.14.output.LayerNorm.weight', 'base_model.encoder.layer.5.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.17.output.LayerNorm.bias', 'base_model.encoder.layer.16.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.1.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.8.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.18.intermediate.dense.bias', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.2.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.13.attention.output.dense.weight', 'base_model.encoder.layer.14.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.15.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.4.intermediate.dense.bias', 'base_model.encoder.layer.16.attention.self.query.bias', 'base_model.encoder.layer.1.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.16.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.13.attention.self.query.bias', 'base_model.encoder.layer.4.output.adapters.ts.adapter_up.weight', 'base_model.pooler.dense.bias', 'base_model.encoder.layer.5.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.14.attention.self.value.bias', 'base_model.encoder.layer.5.output.dense.bias', 'base_model.encoder.layer.2.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.21.intermediate.dense.bias', 'base_model.encoder.layer.0.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.1.intermediate.dense.bias', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.23.attention.output.dense.weight', 'base_model.encoder.layer.1.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.23.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.2.intermediate.dense.weight', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.10.attention.output.dense.bias', 'base_model.encoder.layer.9.attention.output.LayerNorm.bias', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.16.output.dense.bias', 'base_model.encoder.layer.15.attention.output.LayerNorm.weight', 'base_model.encoder.layer.20.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.16.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.16.output.LayerNorm.bias', 'base_model.encoder.layer.16.output.LayerNorm.weight', 'base_model.encoder.layer.17.attention.self.query.bias', 'base_model.encoder.layer.10.attention.self.value.weight', 'base_model.encoder.layer.8.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.12.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.9.output.dense.bias', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.1.output.LayerNorm.bias', 'base_model.encoder.layer.4.attention.self.value.bias', 'base_model.encoder.layer.7.attention.self.value.bias', 'base_model.encoder.layer.10.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.21.attention.self.value.weight', 'base_model.encoder.layer.22.attention.self.key.bias', 'base_model.encoder.layer.14.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.3.output.LayerNorm.bias', 'base_model.encoder.layer.19.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.13.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.4.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.4.output.LayerNorm.bias', 'base_model.encoder.layer.18.attention.self.query.bias', 'base_model.encoder.layer.14.output.dense.weight', 'base_model.encoder.layer.0.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.14.attention.self.query.bias', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.13.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.0.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.19.attention.self.value.bias', 'base_model.encoder.layer.22.attention.output.dense.weight', 'base_model.encoder.layer.2.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.12.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.20.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.10.attention.output.LayerNorm.weight', 'base_model.encoder.layer.21.attention.output.dense.weight', 'base_model.encoder.layer.1.attention.output.dense.bias', 'base_model.encoder.layer.2.output.LayerNorm.weight', 'base_model.encoder.layer.11.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.1.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.6.intermediate.dense.weight', 'base_model.encoder.layer.2.output.LayerNorm.bias', 'base_model.encoder.layer.13.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.15.intermediate.dense.weight', 'base_model.encoder.layer.2.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.0.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.7.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.19.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.12.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.0.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.16.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.20.attention.self.value.weight', 'base_model.encoder.layer.3.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.7.attention.self.key.weight', 'qa_outputs.weight', 'base_model.encoder.layer.17.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.12.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.0.attention.output.LayerNorm.weight']
- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of XLMRobertaModel were not initialized from the model checkpoint at /cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//squad/xlm-KG_LR3e-5_EPOCH2.0_maxlen384_batchsize4_gradacc4 and are newly initialized: ['encoder.layer.15.attention.self.query.weight', 'encoder.layer.10.attention.self.query.weight', 'encoder.layer.0.attention.self.key.bias', 'encoder.layer.23.output.LayerNorm.weight', 'encoder.layer.7.attention.output.dense.weight', 'encoder.layer.23.intermediate.dense.weight', 'encoder.layer.12.intermediate.dense.weight', 'encoder.layer.4.attention.self.query.weight', 'encoder.layer.14.output.LayerNorm.weight', 'encoder.layer.21.attention.self.query.bias', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.10.attention.self.value.bias', 'encoder.layer.15.attention.self.key.weight', 'encoder.layer.20.output.dense.weight', 'encoder.layer.14.output.LayerNorm.bias', 'encoder.layer.23.intermediate.dense.bias', 'encoder.layer.19.attention.output.LayerNorm.weight', 'encoder.layer.10.output.LayerNorm.weight', 'encoder.layer.1.attention.self.value.weight', 'encoder.layer.12.attention.output.dense.weight', 'encoder.layer.0.output.dense.weight', 'encoder.layer.14.attention.self.key.weight', 'encoder.layer.10.attention.self.key.weight', 'encoder.layer.14.attention.output.dense.bias', 'encoder.layer.18.attention.output.LayerNorm.bias', 'encoder.layer.2.output.dense.weight', 'encoder.layer.12.attention.self.key.bias', 'encoder.layer.10.output.dense.bias', 'encoder.layer.23.attention.self.query.weight', 'encoder.layer.9.attention.output.LayerNorm.bias', 'encoder.layer.21.output.dense.bias', 'encoder.layer.21.attention.output.LayerNorm.weight', 'encoder.layer.19.attention.self.value.weight', 'encoder.layer.22.output.dense.bias', 'encoder.layer.22.intermediate.dense.bias', 'encoder.layer.13.attention.self.key.bias', 'encoder.layer.5.attention.output.dense.weight', 'encoder.layer.8.attention.self.key.weight', 'encoder.layer.8.attention.output.LayerNorm.weight', 'encoder.layer.0.attention.self.query.bias', 'encoder.layer.13.attention.self.value.weight', 'encoder.layer.1.output.LayerNorm.weight', 'pooler.dense.bias', 'encoder.layer.16.attention.self.query.bias', 'encoder.layer.13.intermediate.dense.weight', 'encoder.layer.17.intermediate.dense.weight', 'encoder.layer.20.attention.self.value.bias', 'encoder.layer.6.attention.self.key.bias', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.19.attention.output.dense.bias', 'encoder.layer.10.attention.self.key.bias', 'encoder.layer.8.attention.self.value.bias', 'encoder.layer.6.attention.self.value.weight', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.16.intermediate.dense.weight', 'encoder.layer.23.attention.self.key.weight', 'encoder.layer.19.output.dense.weight', 'embeddings.word_embeddings.weight', 'encoder.layer.11.output.dense.weight', 'encoder.layer.18.attention.self.query.weight', 'encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.layer.8.attention.output.dense.weight', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.19.attention.self.key.bias', 'encoder.layer.20.attention.self.key.weight', 'encoder.layer.18.output.LayerNorm.bias', 'encoder.layer.15.attention.self.key.bias', 'encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.layer.20.attention.self.query.bias', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.3.output.dense.bias', 'encoder.layer.20.intermediate.dense.bias', 'encoder.layer.13.attention.self.key.weight', 'encoder.layer.3.attention.self.key.bias', 'encoder.layer.3.attention.self.value.weight', 'encoder.layer.19.output.dense.bias', 'encoder.layer.20.attention.self.query.weight', 'encoder.layer.23.output.dense.weight', 'encoder.layer.16.output.LayerNorm.weight', 'encoder.layer.11.attention.self.key.bias', 'encoder.layer.20.attention.self.value.weight', 'encoder.layer.13.output.dense.bias', 'encoder.layer.22.attention.self.key.weight', 'encoder.layer.0.output.dense.bias', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.18.attention.output.LayerNorm.weight', 'encoder.layer.20.attention.self.key.bias', 'encoder.layer.4.attention.output.dense.bias', 'encoder.layer.21.output.LayerNorm.weight', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.15.output.LayerNorm.weight', 'encoder.layer.21.attention.self.query.weight', 'encoder.layer.11.attention.output.dense.weight', 'encoder.layer.17.attention.output.dense.bias', 'encoder.layer.23.output.LayerNorm.bias', 'encoder.layer.4.attention.self.key.weight', 'embeddings.LayerNorm.weight', 'encoder.layer.3.attention.self.value.bias', 'encoder.layer.11.attention.self.query.bias', 'encoder.layer.18.attention.output.dense.bias', 'encoder.layer.19.attention.output.LayerNorm.bias', 'encoder.layer.0.attention.output.dense.bias', 'encoder.layer.12.attention.output.dense.bias', 'encoder.layer.13.attention.output.dense.weight', 'encoder.layer.6.attention.self.key.weight', 'encoder.layer.15.output.LayerNorm.bias', 'encoder.layer.21.intermediate.dense.weight', 'encoder.layer.4.attention.self.key.bias', 'encoder.layer.17.intermediate.dense.bias', 'encoder.layer.15.attention.output.dense.bias', 'encoder.layer.17.attention.self.value.bias', 'encoder.layer.7.attention.self.value.weight', 'encoder.layer.11.attention.output.dense.bias', 'encoder.layer.1.attention.self.query.bias', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.11.attention.self.value.bias', 'encoder.layer.14.attention.output.LayerNorm.bias', 'encoder.layer.17.attention.output.LayerNorm.weight', 'encoder.layer.19.attention.self.key.weight', 'encoder.layer.21.attention.self.key.weight', 'encoder.layer.12.attention.self.query.bias', 'encoder.layer.12.attention.self.key.weight', 'encoder.layer.21.attention.self.value.bias', 'encoder.layer.16.attention.self.value.weight', 'encoder.layer.10.attention.output.dense.bias', 'encoder.layer.8.attention.output.LayerNorm.bias', 'encoder.layer.6.output.dense.bias', 'encoder.layer.7.output.dense.bias', 'encoder.layer.16.attention.self.value.bias', 'encoder.layer.14.attention.self.query.bias', 'encoder.layer.19.attention.self.query.weight', 'encoder.layer.9.attention.self.key.weight', 'encoder.layer.10.output.dense.weight', 'encoder.layer.9.output.dense.weight', 'encoder.layer.14.attention.self.value.weight', 'encoder.layer.20.output.LayerNorm.weight', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.9.attention.self.key.bias', 'encoder.layer.5.attention.self.value.weight', 'encoder.layer.22.attention.output.LayerNorm.bias', 'encoder.layer.5.attention.self.key.bias', 'encoder.layer.4.output.dense.weight', 'encoder.layer.6.attention.self.query.weight', 'encoder.layer.17.output.dense.bias', 'encoder.layer.14.output.dense.weight', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.8.attention.output.dense.bias', 'encoder.layer.14.attention.self.key.bias', 'encoder.layer.18.attention.self.value.weight', 'encoder.layer.7.attention.self.key.bias', 'encoder.layer.13.attention.self.value.bias', 'encoder.layer.19.intermediate.dense.bias', 'encoder.layer.16.output.dense.weight', 'encoder.layer.8.attention.self.query.bias', 'encoder.layer.10.attention.output.LayerNorm.bias', 'encoder.layer.8.output.LayerNorm.weight', 'encoder.layer.7.attention.self.key.weight', 'encoder.layer.15.attention.self.value.weight', 'encoder.layer.1.attention.self.query.weight', 'encoder.layer.3.attention.self.key.weight', 'encoder.layer.7.attention.output.dense.bias', 'encoder.layer.22.attention.self.key.bias', 'encoder.layer.15.attention.output.LayerNorm.weight', 'encoder.layer.2.attention.self.key.bias', 'encoder.layer.20.output.LayerNorm.bias', 'encoder.layer.8.attention.self.query.weight', 'encoder.layer.2.attention.self.value.bias', 'encoder.layer.11.attention.self.value.weight', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.15.attention.self.value.bias', 'encoder.layer.12.output.dense.weight', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.19.output.LayerNorm.weight', 'encoder.layer.1.attention.output.dense.weight', 'encoder.layer.23.attention.self.key.bias', 'encoder.layer.22.output.dense.weight', 'encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.13.attention.output.dense.bias', 'encoder.layer.1.attention.output.dense.bias', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.3.attention.self.query.weight', 'encoder.layer.22.attention.output.dense.bias', 'encoder.layer.16.output.LayerNorm.bias', 'encoder.layer.5.attention.self.value.bias', 'encoder.layer.15.output.dense.bias', 'encoder.layer.16.intermediate.dense.bias', 'encoder.layer.6.output.LayerNorm.bias', 'encoder.layer.22.output.LayerNorm.weight', 'encoder.layer.18.intermediate.dense.weight', 'encoder.layer.12.output.LayerNorm.bias', 'encoder.layer.7.attention.output.LayerNorm.bias', 'encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.layer.23.attention.output.LayerNorm.weight', 'encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.16.attention.self.query.weight', 'encoder.layer.1.attention.self.key.weight', 'encoder.layer.6.attention.output.dense.bias', 'encoder.layer.2.attention.self.value.weight', 'encoder.layer.17.attention.output.LayerNorm.bias', 'encoder.layer.18.output.dense.weight', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.14.attention.self.query.weight', 'encoder.layer.7.output.dense.weight', 'encoder.layer.23.output.dense.bias', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.18.intermediate.dense.bias', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.6.attention.self.value.bias', 'encoder.layer.14.output.dense.bias', 'encoder.layer.21.attention.self.value.weight', 'encoder.layer.18.attention.self.key.bias', 'encoder.layer.0.attention.self.value.bias', 'encoder.layer.15.output.dense.weight', 'encoder.layer.8.output.LayerNorm.bias', 'encoder.layer.20.attention.output.dense.bias', 'encoder.layer.13.output.dense.weight', 'encoder.layer.18.attention.output.dense.weight', 'encoder.layer.10.attention.output.LayerNorm.weight', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.12.attention.output.LayerNorm.bias', 'encoder.layer.9.output.LayerNorm.weight', 'encoder.layer.5.attention.self.query.weight', 'encoder.layer.21.output.LayerNorm.bias', 'embeddings.LayerNorm.bias', 'encoder.layer.3.attention.output.dense.bias', 'encoder.layer.4.attention.self.query.bias', 'encoder.layer.7.attention.output.LayerNorm.weight', 'encoder.layer.3.output.dense.weight', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.7.attention.self.query.bias', 'encoder.layer.15.attention.self.query.bias', 'encoder.layer.3.attention.self.query.bias', 'encoder.layer.9.attention.self.value.weight', 'encoder.layer.2.attention.output.dense.weight', 'encoder.layer.2.attention.self.query.weight', 'encoder.layer.18.output.dense.bias', 'encoder.layer.9.attention.output.dense.weight', 'encoder.layer.18.attention.self.key.weight', 'encoder.layer.19.output.LayerNorm.bias', 'encoder.layer.17.attention.self.value.weight', 'encoder.layer.16.attention.output.dense.weight', 'encoder.layer.9.attention.self.value.bias', 'encoder.layer.5.attention.self.query.bias', 'encoder.layer.2.attention.output.dense.bias', 'encoder.layer.23.attention.self.value.bias', 'encoder.layer.15.intermediate.dense.bias', 'encoder.layer.22.attention.self.query.bias', 'encoder.layer.22.intermediate.dense.weight', 'encoder.layer.10.attention.self.query.bias', 'encoder.layer.6.output.dense.weight', 'encoder.layer.8.output.dense.weight', 'encoder.layer.2.attention.self.key.weight', 'encoder.layer.13.attention.output.LayerNorm.bias', 'encoder.layer.20.output.dense.bias', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.10.attention.self.value.weight', 'encoder.layer.17.attention.self.key.weight', 'encoder.layer.4.attention.self.value.weight', 'encoder.layer.17.output.LayerNorm.weight', 'encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.layer.6.attention.output.LayerNorm.bias', 'encoder.layer.22.output.LayerNorm.bias', 'encoder.layer.16.attention.self.key.bias', 'encoder.layer.21.attention.output.dense.bias', 'encoder.layer.15.attention.output.dense.weight', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.12.intermediate.dense.bias', 'encoder.layer.9.attention.self.query.weight', 'encoder.layer.10.attention.output.dense.weight', 'encoder.layer.4.output.dense.bias', 'encoder.layer.3.attention.output.dense.weight', 'encoder.layer.23.attention.output.LayerNorm.bias', 'encoder.layer.17.attention.output.dense.weight', 'encoder.layer.6.attention.output.LayerNorm.weight', 'encoder.layer.19.attention.output.dense.weight', 'encoder.layer.12.attention.output.LayerNorm.weight', 'encoder.layer.17.attention.self.query.weight', 'encoder.layer.8.output.dense.bias', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.13.attention.self.query.weight', 'encoder.layer.12.output.LayerNorm.weight', 'encoder.layer.12.output.dense.bias', 'encoder.layer.16.attention.output.dense.bias', 'encoder.layer.5.output.dense.weight', 'encoder.layer.14.attention.output.dense.weight', 'embeddings.position_embeddings.weight', 'encoder.layer.9.attention.output.LayerNorm.weight', 'encoder.layer.13.intermediate.dense.bias', 'encoder.layer.20.attention.output.dense.weight', 'encoder.layer.18.attention.self.query.bias', 'encoder.layer.22.attention.output.dense.weight', 'encoder.layer.19.attention.self.query.bias', 'encoder.layer.9.attention.self.query.bias', 'encoder.layer.21.attention.self.key.bias', 'encoder.layer.13.attention.output.LayerNorm.weight', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.1.attention.self.key.bias', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.0.attention.self.value.weight', 'encoder.layer.23.attention.self.query.bias', 'encoder.layer.22.attention.output.LayerNorm.weight', 'encoder.layer.19.intermediate.dense.weight', 'encoder.layer.11.output.LayerNorm.bias', 'encoder.layer.22.attention.self.query.weight', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.0.attention.output.dense.weight', 'encoder.layer.12.attention.self.query.weight', 'encoder.layer.0.attention.self.key.weight', 'encoder.layer.11.output.dense.bias', 'encoder.layer.22.attention.self.value.weight', 'encoder.layer.13.output.LayerNorm.bias', 'encoder.layer.14.attention.output.LayerNorm.weight', 'encoder.layer.0.attention.output.LayerNorm.weight', 'encoder.layer.7.attention.self.query.weight', 'encoder.layer.16.attention.self.key.weight', 'encoder.layer.2.attention.self.query.bias', 'encoder.layer.5.attention.self.key.weight', 'encoder.layer.11.output.LayerNorm.weight', 'encoder.layer.14.attention.self.value.bias', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.13.attention.self.query.bias', 'pooler.dense.weight', 'encoder.layer.16.output.dense.bias', 'encoder.layer.4.attention.output.dense.weight', 'encoder.layer.4.attention.output.LayerNorm.bias', 'encoder.layer.7.output.LayerNorm.weight', 'encoder.layer.21.intermediate.dense.bias', 'encoder.layer.8.attention.self.key.bias', 'encoder.layer.22.attention.self.value.bias', 'encoder.layer.4.attention.self.value.bias', 'encoder.layer.5.attention.output.LayerNorm.weight', 'encoder.layer.9.output.dense.bias', 'encoder.layer.9.attention.output.dense.bias', 'encoder.layer.20.attention.output.LayerNorm.weight', 'encoder.layer.11.attention.output.LayerNorm.weight', 'encoder.layer.16.attention.output.LayerNorm.weight', 'encoder.layer.7.intermediate.dense.bias', 'encoder.layer.14.intermediate.dense.bias', 'encoder.layer.1.attention.output.LayerNorm.weight', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.6.attention.self.query.bias', 'encoder.layer.12.attention.self.value.weight', 'encoder.layer.21.attention.output.dense.weight', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.23.attention.self.value.weight', 'encoder.layer.23.attention.output.dense.bias', 'encoder.layer.12.attention.self.value.bias', 'encoder.layer.17.output.LayerNorm.bias', 'encoder.layer.19.attention.self.value.bias', 'encoder.layer.4.attention.output.LayerNorm.weight', 'encoder.layer.2.attention.output.LayerNorm.weight', 'encoder.layer.15.attention.output.LayerNorm.bias', 'encoder.layer.5.output.LayerNorm.bias', 'encoder.layer.16.attention.output.LayerNorm.bias', 'encoder.layer.1.attention.self.value.bias', 'encoder.layer.23.attention.output.dense.weight', 'encoder.layer.15.intermediate.dense.weight', 'encoder.layer.17.attention.self.key.bias', 'encoder.layer.5.attention.output.dense.bias', 'encoder.layer.1.output.dense.bias', 'encoder.layer.21.output.dense.weight', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.7.output.LayerNorm.bias', 'encoder.layer.8.attention.self.value.weight', 'encoder.layer.20.intermediate.dense.weight', 'encoder.layer.9.output.LayerNorm.bias', 'encoder.layer.10.intermediate.dense.weight', 'encoder.layer.1.output.dense.weight', 'encoder.layer.20.attention.output.LayerNorm.bias', 'encoder.layer.13.output.LayerNorm.weight', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.7.attention.self.value.bias', 'encoder.layer.18.output.LayerNorm.weight', 'encoder.layer.14.intermediate.dense.weight', 'embeddings.token_type_embeddings.weight', 'encoder.layer.11.attention.self.query.weight', 'encoder.layer.18.attention.self.value.bias', 'encoder.layer.2.attention.output.LayerNorm.bias', 'encoder.layer.21.attention.output.LayerNorm.bias', 'encoder.layer.17.attention.self.query.bias', 'encoder.layer.2.output.dense.bias', 'encoder.layer.5.output.dense.bias', 'encoder.layer.6.attention.output.dense.weight', 'encoder.layer.0.attention.self.query.weight', 'encoder.layer.10.output.LayerNorm.bias', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.17.output.dense.weight', 'encoder.layer.11.attention.self.key.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Overwriting existing adapter 'ep'.
Overwriting existing adapter 'tp'.
Overwriting existing adapter 'es'.
Overwriting existing adapter 'ts'.
Overwriting existing adapter fusion module 'ep,tp,es,ts'
05/09/2022 09:08:29 - INFO - __main__ -   lang2id = None
05/09/2022 09:08:35 - INFO - __main__ -   Training/evaluation parameters Namespace(adam_epsilon=1e-08, cache_dir='', config_name='', data_dir=None, device=device(type='cuda'), do_eval=True, do_lower_case=False, do_train=False, doc_stride=128, eval_all_checkpoints=False, eval_lang='tr', evaluate_during_training=False, fp16=False, fp16_opt_level='O1', gradient_accumulation_steps=1, learning_rate=5e-05, local_rank=-1, logging_steps=50, max_answer_length=30, max_grad_norm=1.0, max_query_length=64, max_seq_length=384, max_steps=-1, model_name='xlm-KG', model_name_or_path='/cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//squad/xlm-KG_LR3e-5_EPOCH2.0_maxlen384_batchsize4_gradacc4', model_type='xlm', modelkg_dir='/cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/adapter/xlmr_adapter', n_best_size=20, n_gpu=1, no_cuda=False, null_score_diff_threshold=0.0, num_train_epochs=3.0, output_dir='/cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//squad/xlm-KG_LR3e-5_EPOCH2.0_maxlen384_batchsize4_gradacc4/predictions/xquad/', overwrite_cache=False, overwrite_output_dir=False, per_gpu_eval_batch_size=8, per_gpu_train_batch_size=8, predict_file='/cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/download//xquad//xquad.tr.json', save_steps=50, seed=42, server_ip='', server_port='', threads=1, tokenizer_name='', train_file=None, train_lang='en', verbose_logging=False, version_2_with_negative=False, warmup_steps=0, weight_decay=0.0)
05/09/2022 09:08:35 - INFO - __main__ -   Loading checkpoint /cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//squad/xlm-KG_LR3e-5_EPOCH2.0_maxlen384_batchsize4_gradacc4 for evaluation
05/09/2022 09:08:35 - INFO - __main__ -   Evaluate the following checkpoints: ['/cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//squad/xlm-KG_LR3e-5_EPOCH2.0_maxlen384_batchsize4_gradacc4']
Some weights of the model checkpoint at /cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//squad/xlm-KG_LR3e-5_EPOCH2.0_maxlen384_batchsize4_gradacc4 were not used when initializing XLMRobertaModel: ['base_model.encoder.layer.18.attention.self.value.weight', 'base_model.encoder.layer.4.output.dense.weight', 'base_model.encoder.layer.6.attention.self.key.bias', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.6.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.17.output.dense.weight', 'base_model.encoder.layer.20.attention.output.dense.weight', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.21.output.LayerNorm.bias', 'base_model.encoder.layer.11.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.14.attention.self.key.weight', 'base_model.pooler.dense.weight', 'base_model.encoder.layer.12.output.dense.weight', 'base_model.encoder.layer.22.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.18.output.dense.bias', 'base_model.encoder.layer.11.output.adapters.tp.adapter_up.weight', 'base_model.embeddings.position_embeddings.weight', 'base_model.encoder.layer.20.attention.self.key.bias', 'base_model.encoder.layer.10.attention.self.key.weight', 'base_model.encoder.layer.14.output.dense.bias', 'base_model.encoder.layer.10.attention.output.dense.weight', 'base_model.encoder.layer.13.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.9.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.16.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.13.attention.self.query.weight', 'base_model.encoder.layer.14.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.10.output.dense.weight', 'base_model.encoder.layer.15.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.21.attention.output.dense.bias', 'base_model.encoder.layer.8.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.18.attention.self.key.bias', 'base_model.encoder.layer.21.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.1.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.4.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.5.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.21.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.3.attention.output.LayerNorm.weight', 'base_model.encoder.layer.20.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.22.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.12.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.12.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.11.attention.self.key.weight', 'base_model.encoder.layer.10.output.dense.bias', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.11.output.LayerNorm.weight', 'base_model.encoder.layer.23.output.dense.weight', 'base_model.encoder.layer.22.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.21.attention.self.value.bias', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.18.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.11.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.4.output.dense.bias', 'base_model.encoder.layer.3.attention.self.key.weight', 'base_model.encoder.layer.9.output.LayerNorm.weight', 'base_model.encoder.layer.10.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.23.intermediate.dense.weight', 'base_model.encoder.layer.17.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.4.attention.output.LayerNorm.weight', 'base_model.encoder.layer.10.attention.self.key.bias', 'base_model.encoder.layer.13.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.14.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.3.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.8.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.15.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.14.attention.self.key.bias', 'base_model.encoder.layer.15.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.7.output.dense.weight', 'base_model.encoder.layer.4.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.14.intermediate.dense.bias', 'base_model.encoder.layer.6.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.18.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.0.output.dense.weight', 'base_model.encoder.layer.1.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.11.attention.output.LayerNorm.weight', 'base_model.encoder.layer.17.attention.output.dense.weight', 'base_model.encoder.layer.10.attention.self.query.weight', 'base_model.encoder.layer.3.attention.self.value.weight', 'base_model.encoder.layer.3.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.5.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.0.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.6.output.LayerNorm.weight', 'base_model.encoder.layer.20.attention.output.LayerNorm.weight', 'base_model.encoder.layer.3.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.12.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.7.attention.output.LayerNorm.bias', 'base_model.encoder.layer.19.output.dense.bias', 'base_model.encoder.layer.5.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.5.attention.self.query.weight', 'base_model.encoder.layer.20.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.10.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.16.attention.self.key.bias', 'base_model.encoder.layer.3.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.17.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.23.attention.self.query.bias', 'base_model.encoder.layer.8.attention.self.query.weight', 'base_model.encoder.layer.7.attention.self.query.weight', 'base_model.encoder.layer.5.attention.self.value.bias', 'base_model.encoder.layer.6.intermediate.dense.bias', 'base_model.encoder.layer.17.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.11.intermediate.dense.bias', 'base_model.encoder.layer.5.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.12.intermediate.dense.bias', 'base_model.encoder.layer.12.attention.output.LayerNorm.weight', 'base_model.encoder.layer.22.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.9.attention.output.dense.weight', 'base_model.encoder.layer.12.attention.self.value.bias', 'base_model.encoder.layer.23.attention.self.key.bias', 'base_model.encoder.layer.5.intermediate.dense.weight', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.13.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.11.attention.self.value.weight', 'base_model.encoder.layer.21.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.7.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.9.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.3.attention.output.dense.bias', 'base_model.encoder.layer.9.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.15.intermediate.dense.bias', 'base_model.encoder.layer.23.attention.output.LayerNorm.bias', 'base_model.encoder.layer.5.output.dense.weight', 'base_model.encoder.layer.21.attention.self.query.weight', 'base_model.encoder.layer.5.output.LayerNorm.bias', 'base_model.encoder.layer.6.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.11.attention.self.value.bias', 'base_model.encoder.layer.9.attention.output.dense.bias', 'base_model.encoder.layer.8.attention.output.dense.bias', 'base_model.encoder.layer.18.attention.self.key.weight', 'base_model.encoder.layer.2.intermediate.dense.bias', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.11.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.18.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.21.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.23.attention.self.value.bias', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.13.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.13.attention.self.value.weight', 'base_model.encoder.layer.7.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.7.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.15.attention.self.key.bias', 'base_model.encoder.layer.3.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.19.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.1.attention.self.key.weight', 'base_model.encoder.layer.21.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.6.output.dense.bias', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.19.attention.self.value.weight', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.18.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.19.output.LayerNorm.weight', 'base_model.encoder.layer.19.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.17.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.13.output.dense.weight', 'base_model.encoder.layer.22.attention.output.dense.bias', 'base_model.encoder.layer.2.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.14.attention.self.query.weight', 'base_model.encoder.layer.17.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.0.attention.self.query.bias', 'base_model.encoder.layer.15.attention.self.value.bias', 'base_model.encoder.layer.3.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.17.attention.self.value.weight', 'base_model.encoder.layer.5.attention.self.key.bias', 'base_model.encoder.layer.6.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.8.output.dense.weight', 'base_model.embeddings.LayerNorm.weight', 'base_model.encoder.layer.4.attention.output.dense.weight', 'base_model.encoder.layer.14.attention.self.value.weight', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.21.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.15.output.LayerNorm.bias', 'base_model.encoder.layer.23.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.3.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.6.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.14.attention.output.LayerNorm.weight', 'base_model.encoder.layer.7.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.3.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.14.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.2.output.dense.weight', 'base_model.encoder.layer.6.attention.self.key.weight', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.15.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.18.output.LayerNorm.weight', 'base_model.encoder.layer.11.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.14.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.23.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.2.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.8.output.LayerNorm.bias', 'base_model.encoder.layer.15.attention.self.value.weight', 'base_model.encoder.layer.20.output.dense.weight', 'base_model.encoder.layer.20.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.21.attention.self.key.bias', 'base_model.encoder.layer.0.intermediate.dense.bias', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.20.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.1.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.21.output.dense.bias', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.18.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.1.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.23.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.13.attention.output.dense.bias', 'base_model.encoder.layer.16.intermediate.dense.weight', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.5.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.21.attention.self.query.bias', 'base_model.encoder.layer.5.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.5.attention.self.value.weight', 'base_model.encoder.layer.10.output.LayerNorm.bias', 'base_model.encoder.layer.12.attention.self.value.weight', 'base_model.encoder.layer.11.output.dense.bias', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.9.intermediate.dense.weight', 'base_model.encoder.layer.12.output.LayerNorm.bias', 'base_model.encoder.layer.18.attention.self.value.bias', 'base_model.encoder.layer.20.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.6.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.18.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.6.attention.self.query.bias', 'base_model.encoder.layer.6.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.1.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.10.intermediate.dense.bias', 'base_model.encoder.layer.13.intermediate.dense.bias', 'base_model.encoder.layer.15.attention.self.query.weight', 'base_model.encoder.layer.21.intermediate.dense.weight', 'base_model.encoder.layer.16.attention.output.LayerNorm.bias', 'base_model.encoder.layer.17.output.dense.bias', 'base_model.encoder.layer.1.attention.self.key.bias', 'base_model.encoder.layer.0.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.19.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.7.output.LayerNorm.bias', 'base_model.encoder.layer.16.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.19.attention.output.LayerNorm.weight', 'base_model.encoder.layer.21.attention.output.LayerNorm.weight', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.5.attention.self.key.weight', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.8.attention.self.value.bias', 'base_model.encoder.layer.19.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.0.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.11.attention.output.dense.weight', 'base_model.encoder.layer.22.attention.self.query.weight', 'base_model.encoder.layer.7.output.LayerNorm.weight', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.8.intermediate.dense.weight', 'base_model.encoder.layer.8.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.15.attention.output.dense.bias', 'base_model.encoder.layer.4.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.8.intermediate.dense.bias', 'base_model.encoder.layer.3.attention.self.value.bias', 'base_model.encoder.layer.13.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.23.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.9.attention.self.key.weight', 'base_model.encoder.layer.13.output.LayerNorm.weight', 'base_model.encoder.layer.2.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.12.intermediate.dense.weight', 'base_model.encoder.layer.22.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.0.attention.output.LayerNorm.bias', 'base_model.encoder.layer.6.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.2.attention.self.value.weight', 'base_model.encoder.layer.2.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.21.attention.self.key.weight', 'base_model.encoder.layer.9.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.6.output.LayerNorm.bias', 'base_model.encoder.layer.1.output.dense.bias', 'base_model.encoder.layer.21.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.15.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.7.attention.self.key.bias', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.4.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.23.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.5.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.13.attention.self.key.weight', 'base_model.encoder.layer.9.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.19.attention.output.dense.bias', 'base_model.encoder.layer.0.attention.output.dense.weight', 'base_model.encoder.layer.12.output.dense.bias', 'base_model.encoder.layer.5.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.19.intermediate.dense.bias', 'base_model.encoder.layer.20.attention.self.query.bias', 'base_model.encoder.layer.6.attention.self.value.bias', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.9.output.dense.weight', 'base_model.encoder.layer.22.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.23.output.LayerNorm.weight', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.16.attention.self.query.weight', 'base_model.encoder.layer.19.attention.self.query.bias', 'base_model.encoder.layer.3.attention.self.query.weight', 'base_model.encoder.layer.5.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.16.attention.output.LayerNorm.weight', 'base_model.encoder.layer.19.output.dense.weight', 'base_model.encoder.layer.11.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.12.attention.self.key.weight', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.14.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.8.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.7.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.9.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.8.attention.self.key.weight', 'base_model.encoder.layer.4.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.12.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.8.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.14.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.20.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.20.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.4.attention.output.dense.bias', 'base_model.encoder.layer.19.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.22.attention.output.LayerNorm.bias', 'base_model.encoder.layer.12.attention.self.query.bias', 'base_model.encoder.layer.7.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.10.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.23.attention.self.query.weight', 'base_model.encoder.layer.15.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.23.attention.self.value.weight', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.22.attention.self.query.bias', 'base_model.encoder.layer.12.attention.self.key.bias', 'base_model.encoder.layer.23.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.13.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.8.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.4.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.16.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.15.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.5.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.7.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.23.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.2.attention.output.dense.bias', 'base_model.encoder.layer.3.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.6.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.5.attention.output.LayerNorm.weight', 'base_model.encoder.layer.8.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.11.attention.output.dense.bias', 'base_model.encoder.layer.11.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.20.output.LayerNorm.weight', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.20.intermediate.dense.weight', 'base_model.encoder.layer.17.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.20.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.7.attention.output.dense.weight', 'base_model.encoder.layer.4.attention.self.key.weight', 'base_model.encoder.layer.16.attention.output.dense.weight', 'base_model.encoder.layer.20.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.1.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.5.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.17.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.9.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.16.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.0.attention.self.value.weight', 'base_model.encoder.layer.10.intermediate.dense.weight', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.19.attention.self.query.weight', 'base_model.encoder.layer.22.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.16.intermediate.dense.bias', 'base_model.encoder.layer.23.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.20.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.3.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.16.attention.self.value.weight', 'base_model.encoder.layer.12.attention.output.LayerNorm.bias', 'base_model.encoder.layer.18.attention.output.dense.bias', 'base_model.encoder.layer.8.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.9.intermediate.dense.bias', 'base_model.encoder.layer.8.attention.output.LayerNorm.weight', 'base_model.encoder.layer.5.output.LayerNorm.weight', 'base_model.encoder.layer.2.attention.self.query.bias', 'base_model.encoder.layer.0.attention.self.key.bias', 'base_model.encoder.layer.10.attention.self.value.bias', 'base_model.encoder.layer.20.attention.self.key.weight', 'base_model.encoder.layer.21.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.23.output.LayerNorm.bias', 'base_model.encoder.layer.5.output.adapters.ts.adapter_down.0.weight', 'base_model.embeddings.word_embeddings.weight', 'base_model.encoder.layer.1.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.14.intermediate.dense.weight', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.13.output.LayerNorm.bias', 'base_model.encoder.layer.1.attention.self.value.bias', 'base_model.encoder.layer.1.intermediate.dense.weight', 'base_model.encoder.layer.11.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.10.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.23.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.3.attention.output.dense.weight', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.7.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.11.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.1.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.17.output.LayerNorm.weight', 'base_model.encoder.layer.11.output.dense.weight', 'base_model.encoder.layer.9.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.4.attention.self.value.weight', 'base_model.encoder.layer.14.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.6.attention.output.dense.bias', 'base_model.encoder.layer.2.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.8.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.13.attention.output.LayerNorm.weight', 'base_model.encoder.layer.6.attention.output.dense.weight', 'base_model.encoder.layer.19.output.LayerNorm.bias', 'base_model.encoder.layer.19.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.19.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.18.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.16.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.14.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.22.output.LayerNorm.bias', 'base_model.encoder.layer.23.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.10.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.6.attention.output.LayerNorm.bias', 'base_model.encoder.layer.18.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.13.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.19.attention.output.dense.weight', 'base_model.encoder.layer.15.attention.self.query.bias', 'base_model.encoder.layer.1.output.LayerNorm.weight', 'base_model.encoder.layer.2.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.8.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.15.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.0.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.15.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.14.output.LayerNorm.bias', 'base_model.encoder.layer.1.attention.self.value.weight', 'base_model.encoder.layer.17.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.18.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.22.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.17.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.6.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.18.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.19.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.6.output.dense.weight', 'base_model.encoder.layer.11.attention.output.LayerNorm.bias', 'base_model.encoder.layer.6.attention.self.query.weight', 'base_model.encoder.layer.2.attention.self.value.bias', 'base_model.encoder.layer.22.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.2.attention.self.query.weight', 'base_model.encoder.layer.11.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.19.intermediate.dense.weight', 'base_model.encoder.layer.0.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.22.output.dense.bias', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.15.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.5.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.12.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.18.attention.self.query.weight', 'base_model.encoder.layer.3.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.2.attention.output.LayerNorm.bias', 'base_model.encoder.layer.2.attention.output.dense.weight', 'base_model.encoder.layer.3.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.4.intermediate.dense.weight', 'base_model.encoder.layer.1.attention.self.query.weight', 'base_model.encoder.layer.13.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.9.attention.self.query.weight', 'base_model.encoder.layer.16.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.12.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.21.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.3.output.LayerNorm.weight', 'base_model.encoder.layer.15.output.dense.bias', 'base_model.encoder.layer.5.intermediate.dense.bias', 'base_model.encoder.layer.22.attention.self.value.bias', 'base_model.encoder.layer.17.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.18.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.13.output.dense.bias', 'base_model.encoder.layer.12.output.LayerNorm.weight', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.20.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.15.attention.output.dense.weight', 'base_model.encoder.layer.21.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.17.attention.self.key.bias', 'base_model.encoder.layer.4.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.0.attention.output.dense.bias', 'base_model.encoder.layer.17.intermediate.dense.weight', 'base_model.encoder.layer.17.attention.self.value.bias', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.11.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.4.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.7.attention.self.query.bias', 'base_model.encoder.layer.22.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.8.attention.self.query.bias', 'base_model.encoder.layer.10.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.4.attention.self.query.bias', 'base_model.encoder.layer.16.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.0.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.3.attention.output.LayerNorm.bias', 'base_model.encoder.layer.7.attention.output.LayerNorm.weight', 'base_model.encoder.layer.9.attention.self.value.bias', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.18.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.1.attention.output.LayerNorm.bias', 'base_model.encoder.layer.22.attention.self.key.weight', 'base_model.encoder.layer.14.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.17.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.19.attention.self.key.weight', 'base_model.encoder.layer.8.attention.self.value.weight', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.1.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.2.attention.output.LayerNorm.weight', 'base_model.encoder.layer.7.intermediate.dense.bias', 'base_model.encoder.layer.22.output.LayerNorm.weight', 'base_model.encoder.layer.23.intermediate.dense.bias', 'base_model.encoder.layer.16.attention.output.dense.bias', 'base_model.encoder.layer.8.output.dense.bias', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.15.output.LayerNorm.weight', 'base_model.encoder.layer.2.attention.self.key.weight', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.11.output.LayerNorm.bias', 'base_model.encoder.layer.22.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.0.attention.self.query.weight', 'base_model.encoder.layer.15.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.9.output.adapters.es.adapter_up.weight', 'base_model.embeddings.LayerNorm.bias', 'base_model.encoder.layer.13.intermediate.dense.weight', 'base_model.encoder.layer.8.output.LayerNorm.weight', 'base_model.encoder.layer.8.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.0.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.10.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.15.attention.output.LayerNorm.bias', 'base_model.encoder.layer.8.attention.output.LayerNorm.bias', 'base_model.encoder.layer.4.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.23.attention.self.key.weight', 'base_model.encoder.layer.1.attention.self.query.bias', 'base_model.encoder.layer.11.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.9.attention.output.LayerNorm.weight', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.17.attention.output.LayerNorm.weight', 'base_model.encoder.layer.18.intermediate.dense.weight', 'base_model.encoder.layer.2.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.13.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.16.output.dense.weight', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.17.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.19.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.6.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.6.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.6.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.9.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.0.attention.self.value.bias', 'base_model.encoder.layer.22.attention.output.LayerNorm.weight', 'base_model.encoder.layer.13.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.13.attention.self.key.bias', 'base_model.encoder.layer.18.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.10.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.3.intermediate.dense.weight', 'base_model.encoder.layer.3.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.21.output.dense.weight', 'base_model.encoder.layer.6.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.4.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.0.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.9.output.LayerNorm.bias', 'base_model.encoder.layer.13.attention.output.LayerNorm.bias', 'base_model.encoder.layer.0.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.20.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.14.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.11.intermediate.dense.weight', 'base_model.encoder.layer.19.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.7.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.5.attention.output.dense.bias', 'base_model.encoder.layer.10.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.9.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.19.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.9.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.22.output.dense.weight', 'base_model.encoder.layer.0.output.dense.bias', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.7.intermediate.dense.weight', 'base_model.encoder.layer.4.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.10.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.17.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.14.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.4.attention.output.LayerNorm.bias', 'base_model.encoder.layer.23.attention.output.dense.bias', 'base_model.encoder.layer.10.attention.output.LayerNorm.bias', 'base_model.encoder.layer.9.attention.self.value.weight', 'base_model.encoder.layer.11.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.1.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.15.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.12.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.18.attention.output.LayerNorm.bias', 'base_model.encoder.layer.7.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.0.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.19.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.16.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.8.attention.self.key.bias', 'base_model.encoder.layer.10.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.12.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.17.attention.output.dense.bias', 'base_model.encoder.layer.9.attention.self.key.bias', 'base_model.encoder.layer.3.attention.self.key.bias', 'base_model.encoder.layer.11.attention.self.key.bias', 'base_model.encoder.layer.20.attention.self.value.bias', 'base_model.encoder.layer.6.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.20.output.dense.bias', 'base_model.encoder.layer.7.output.dense.bias', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.0.output.LayerNorm.bias', 'base_model.encoder.layer.13.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.8.attention.output.dense.weight', 'base_model.encoder.layer.16.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.21.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.9.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.1.attention.output.dense.weight', 'base_model.encoder.layer.18.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.21.attention.output.LayerNorm.bias', 'base_model.encoder.layer.2.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.4.output.LayerNorm.weight', 'base_model.encoder.layer.2.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.10.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.20.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.10.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.5.attention.output.LayerNorm.bias', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.8.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.2.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.12.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.12.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.7.attention.output.dense.bias', 'base_model.encoder.layer.21.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.8.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.14.attention.output.LayerNorm.bias', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.18.output.LayerNorm.bias', 'base_model.encoder.layer.22.intermediate.dense.weight', 'base_model.encoder.layer.16.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.2.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.4.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.0.intermediate.dense.weight', 'base_model.encoder.layer.13.attention.self.value.bias', 'base_model.encoder.layer.13.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.23.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.4.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.12.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.4.attention.self.key.bias', 'base_model.encoder.layer.1.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.2.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.16.attention.self.key.weight', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.17.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.15.attention.self.key.weight', 'base_model.encoder.layer.1.output.dense.weight', 'base_model.encoder.layer.20.output.LayerNorm.bias', 'base_model.embeddings.token_type_embeddings.weight', 'base_model.encoder.layer.7.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.11.attention.self.query.bias', 'base_model.encoder.layer.21.output.LayerNorm.weight', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.19.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.22.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.15.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.20.attention.self.query.weight', 'base_model.encoder.layer.7.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.17.attention.self.key.weight', 'base_model.encoder.layer.9.attention.self.query.bias', 'base_model.encoder.layer.14.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.6.attention.self.value.weight', 'base_model.encoder.layer.15.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.10.output.LayerNorm.weight', 'base_model.encoder.layer.22.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.19.attention.self.key.bias', 'base_model.encoder.layer.10.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.17.attention.self.query.weight', 'base_model.encoder.layer.20.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.2.attention.self.key.bias', 'base_model.encoder.layer.23.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.0.output.LayerNorm.weight', 'base_model.encoder.layer.23.output.dense.bias', 'base_model.encoder.layer.7.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.4.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.22.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.3.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.17.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.22.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.0.attention.self.key.weight', 'base_model.encoder.layer.9.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.embeddings.position_ids', 'base_model.encoder.layer.23.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.5.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.18.output.dense.weight', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.19.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.6.attention.output.LayerNorm.weight', 'base_model.encoder.layer.14.attention.output.dense.weight', 'base_model.encoder.layer.23.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.12.attention.self.query.weight', 'base_model.encoder.layer.22.attention.self.value.weight', 'base_model.encoder.layer.10.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.16.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.1.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.3.output.dense.weight', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.7.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.18.attention.output.LayerNorm.weight', 'base_model.encoder.layer.19.attention.output.LayerNorm.bias', 'base_model.encoder.layer.15.output.dense.weight', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.7.attention.self.value.weight', 'base_model.encoder.layer.12.attention.output.dense.bias', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.17.attention.output.LayerNorm.bias', 'base_model.encoder.layer.11.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.14.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.22.intermediate.dense.bias', 'base_model.encoder.layer.12.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.16.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.21.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.3.output.dense.bias', 'base_model.encoder.layer.20.attention.output.dense.bias', 'base_model.encoder.layer.18.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.0.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.1.attention.output.LayerNorm.weight', 'base_model.encoder.layer.7.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.18.attention.output.dense.weight', 'base_model.encoder.layer.9.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.18.output.adapters.tp.adapter_up.weight', 'qa_outputs.bias', 'base_model.encoder.layer.13.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.5.attention.self.query.bias', 'base_model.encoder.layer.5.attention.output.dense.weight', 'base_model.encoder.layer.9.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.10.attention.self.query.bias', 'base_model.encoder.layer.2.output.dense.bias', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.15.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.14.attention.output.dense.bias', 'base_model.encoder.layer.4.attention.self.query.weight', 'base_model.encoder.layer.6.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.23.attention.output.LayerNorm.weight', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.20.attention.output.LayerNorm.bias', 'base_model.encoder.layer.11.attention.self.query.weight', 'base_model.encoder.layer.3.intermediate.dense.bias', 'base_model.encoder.layer.22.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.21.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.12.attention.output.dense.weight', 'base_model.encoder.layer.23.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.17.intermediate.dense.bias', 'base_model.encoder.layer.3.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.21.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.3.attention.self.query.bias', 'base_model.encoder.layer.21.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.20.intermediate.dense.bias', 'base_model.encoder.layer.8.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.14.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.11.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.16.attention.self.value.bias', 'base_model.encoder.layer.14.output.LayerNorm.weight', 'base_model.encoder.layer.5.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.17.output.LayerNorm.bias', 'base_model.encoder.layer.16.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.1.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.8.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.18.intermediate.dense.bias', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.2.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.13.attention.output.dense.weight', 'base_model.encoder.layer.14.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.15.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.4.intermediate.dense.bias', 'base_model.encoder.layer.16.attention.self.query.bias', 'base_model.encoder.layer.1.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.16.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.13.attention.self.query.bias', 'base_model.encoder.layer.4.output.adapters.ts.adapter_up.weight', 'base_model.pooler.dense.bias', 'base_model.encoder.layer.5.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.14.attention.self.value.bias', 'base_model.encoder.layer.5.output.dense.bias', 'base_model.encoder.layer.2.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.21.intermediate.dense.bias', 'base_model.encoder.layer.0.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.1.intermediate.dense.bias', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.23.attention.output.dense.weight', 'base_model.encoder.layer.1.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.23.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.2.intermediate.dense.weight', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.10.attention.output.dense.bias', 'base_model.encoder.layer.9.attention.output.LayerNorm.bias', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.16.output.dense.bias', 'base_model.encoder.layer.15.attention.output.LayerNorm.weight', 'base_model.encoder.layer.20.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.16.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.16.output.LayerNorm.bias', 'base_model.encoder.layer.16.output.LayerNorm.weight', 'base_model.encoder.layer.17.attention.self.query.bias', 'base_model.encoder.layer.10.attention.self.value.weight', 'base_model.encoder.layer.8.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.12.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.9.output.dense.bias', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.1.output.LayerNorm.bias', 'base_model.encoder.layer.4.attention.self.value.bias', 'base_model.encoder.layer.7.attention.self.value.bias', 'base_model.encoder.layer.10.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.21.attention.self.value.weight', 'base_model.encoder.layer.22.attention.self.key.bias', 'base_model.encoder.layer.14.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.3.output.LayerNorm.bias', 'base_model.encoder.layer.19.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.13.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.4.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.4.output.LayerNorm.bias', 'base_model.encoder.layer.18.attention.self.query.bias', 'base_model.encoder.layer.14.output.dense.weight', 'base_model.encoder.layer.0.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.14.attention.self.query.bias', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.13.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.0.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.19.attention.self.value.bias', 'base_model.encoder.layer.22.attention.output.dense.weight', 'base_model.encoder.layer.2.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.12.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.20.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.10.attention.output.LayerNorm.weight', 'base_model.encoder.layer.21.attention.output.dense.weight', 'base_model.encoder.layer.1.attention.output.dense.bias', 'base_model.encoder.layer.2.output.LayerNorm.weight', 'base_model.encoder.layer.11.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.1.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.6.intermediate.dense.weight', 'base_model.encoder.layer.2.output.LayerNorm.bias', 'base_model.encoder.layer.13.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.15.intermediate.dense.weight', 'base_model.encoder.layer.2.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.0.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.7.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.19.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.12.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.0.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.16.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.20.attention.self.value.weight', 'base_model.encoder.layer.3.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.7.attention.self.key.weight', 'qa_outputs.weight', 'base_model.encoder.layer.17.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.12.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.0.attention.output.LayerNorm.weight']
- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of XLMRobertaModel were not initialized from the model checkpoint at /cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//squad/xlm-KG_LR3e-5_EPOCH2.0_maxlen384_batchsize4_gradacc4 and are newly initialized: ['encoder.layer.15.attention.self.query.weight', 'encoder.layer.10.attention.self.query.weight', 'encoder.layer.0.attention.self.key.bias', 'encoder.layer.23.output.LayerNorm.weight', 'encoder.layer.7.attention.output.dense.weight', 'encoder.layer.23.intermediate.dense.weight', 'encoder.layer.12.intermediate.dense.weight', 'encoder.layer.4.attention.self.query.weight', 'encoder.layer.14.output.LayerNorm.weight', 'encoder.layer.21.attention.self.query.bias', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.10.attention.self.value.bias', 'encoder.layer.15.attention.self.key.weight', 'encoder.layer.20.output.dense.weight', 'encoder.layer.14.output.LayerNorm.bias', 'encoder.layer.23.intermediate.dense.bias', 'encoder.layer.19.attention.output.LayerNorm.weight', 'encoder.layer.10.output.LayerNorm.weight', 'encoder.layer.1.attention.self.value.weight', 'encoder.layer.12.attention.output.dense.weight', 'encoder.layer.0.output.dense.weight', 'encoder.layer.14.attention.self.key.weight', 'encoder.layer.10.attention.self.key.weight', 'encoder.layer.14.attention.output.dense.bias', 'encoder.layer.18.attention.output.LayerNorm.bias', 'encoder.layer.2.output.dense.weight', 'encoder.layer.12.attention.self.key.bias', 'encoder.layer.10.output.dense.bias', 'encoder.layer.23.attention.self.query.weight', 'encoder.layer.9.attention.output.LayerNorm.bias', 'encoder.layer.21.output.dense.bias', 'encoder.layer.21.attention.output.LayerNorm.weight', 'encoder.layer.19.attention.self.value.weight', 'encoder.layer.22.output.dense.bias', 'encoder.layer.22.intermediate.dense.bias', 'encoder.layer.13.attention.self.key.bias', 'encoder.layer.5.attention.output.dense.weight', 'encoder.layer.8.attention.self.key.weight', 'encoder.layer.8.attention.output.LayerNorm.weight', 'encoder.layer.0.attention.self.query.bias', 'encoder.layer.13.attention.self.value.weight', 'encoder.layer.1.output.LayerNorm.weight', 'pooler.dense.bias', 'encoder.layer.16.attention.self.query.bias', 'encoder.layer.13.intermediate.dense.weight', 'encoder.layer.17.intermediate.dense.weight', 'encoder.layer.20.attention.self.value.bias', 'encoder.layer.6.attention.self.key.bias', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.19.attention.output.dense.bias', 'encoder.layer.10.attention.self.key.bias', 'encoder.layer.8.attention.self.value.bias', 'encoder.layer.6.attention.self.value.weight', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.16.intermediate.dense.weight', 'encoder.layer.23.attention.self.key.weight', 'encoder.layer.19.output.dense.weight', 'embeddings.word_embeddings.weight', 'encoder.layer.11.output.dense.weight', 'encoder.layer.18.attention.self.query.weight', 'encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.layer.8.attention.output.dense.weight', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.19.attention.self.key.bias', 'encoder.layer.20.attention.self.key.weight', 'encoder.layer.18.output.LayerNorm.bias', 'encoder.layer.15.attention.self.key.bias', 'encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.layer.20.attention.self.query.bias', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.3.output.dense.bias', 'encoder.layer.20.intermediate.dense.bias', 'encoder.layer.13.attention.self.key.weight', 'encoder.layer.3.attention.self.key.bias', 'encoder.layer.3.attention.self.value.weight', 'encoder.layer.19.output.dense.bias', 'encoder.layer.20.attention.self.query.weight', 'encoder.layer.23.output.dense.weight', 'encoder.layer.16.output.LayerNorm.weight', 'encoder.layer.11.attention.self.key.bias', 'encoder.layer.20.attention.self.value.weight', 'encoder.layer.13.output.dense.bias', 'encoder.layer.22.attention.self.key.weight', 'encoder.layer.0.output.dense.bias', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.18.attention.output.LayerNorm.weight', 'encoder.layer.20.attention.self.key.bias', 'encoder.layer.4.attention.output.dense.bias', 'encoder.layer.21.output.LayerNorm.weight', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.15.output.LayerNorm.weight', 'encoder.layer.21.attention.self.query.weight', 'encoder.layer.11.attention.output.dense.weight', 'encoder.layer.17.attention.output.dense.bias', 'encoder.layer.23.output.LayerNorm.bias', 'encoder.layer.4.attention.self.key.weight', 'embeddings.LayerNorm.weight', 'encoder.layer.3.attention.self.value.bias', 'encoder.layer.11.attention.self.query.bias', 'encoder.layer.18.attention.output.dense.bias', 'encoder.layer.19.attention.output.LayerNorm.bias', 'encoder.layer.0.attention.output.dense.bias', 'encoder.layer.12.attention.output.dense.bias', 'encoder.layer.13.attention.output.dense.weight', 'encoder.layer.6.attention.self.key.weight', 'encoder.layer.15.output.LayerNorm.bias', 'encoder.layer.21.intermediate.dense.weight', 'encoder.layer.4.attention.self.key.bias', 'encoder.layer.17.intermediate.dense.bias', 'encoder.layer.15.attention.output.dense.bias', 'encoder.layer.17.attention.self.value.bias', 'encoder.layer.7.attention.self.value.weight', 'encoder.layer.11.attention.output.dense.bias', 'encoder.layer.1.attention.self.query.bias', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.11.attention.self.value.bias', 'encoder.layer.14.attention.output.LayerNorm.bias', 'encoder.layer.17.attention.output.LayerNorm.weight', 'encoder.layer.19.attention.self.key.weight', 'encoder.layer.21.attention.self.key.weight', 'encoder.layer.12.attention.self.query.bias', 'encoder.layer.12.attention.self.key.weight', 'encoder.layer.21.attention.self.value.bias', 'encoder.layer.16.attention.self.value.weight', 'encoder.layer.10.attention.output.dense.bias', 'encoder.layer.8.attention.output.LayerNorm.bias', 'encoder.layer.6.output.dense.bias', 'encoder.layer.7.output.dense.bias', 'encoder.layer.16.attention.self.value.bias', 'encoder.layer.14.attention.self.query.bias', 'encoder.layer.19.attention.self.query.weight', 'encoder.layer.9.attention.self.key.weight', 'encoder.layer.10.output.dense.weight', 'encoder.layer.9.output.dense.weight', 'encoder.layer.14.attention.self.value.weight', 'encoder.layer.20.output.LayerNorm.weight', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.9.attention.self.key.bias', 'encoder.layer.5.attention.self.value.weight', 'encoder.layer.22.attention.output.LayerNorm.bias', 'encoder.layer.5.attention.self.key.bias', 'encoder.layer.4.output.dense.weight', 'encoder.layer.6.attention.self.query.weight', 'encoder.layer.17.output.dense.bias', 'encoder.layer.14.output.dense.weight', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.8.attention.output.dense.bias', 'encoder.layer.14.attention.self.key.bias', 'encoder.layer.18.attention.self.value.weight', 'encoder.layer.7.attention.self.key.bias', 'encoder.layer.13.attention.self.value.bias', 'encoder.layer.19.intermediate.dense.bias', 'encoder.layer.16.output.dense.weight', 'encoder.layer.8.attention.self.query.bias', 'encoder.layer.10.attention.output.LayerNorm.bias', 'encoder.layer.8.output.LayerNorm.weight', 'encoder.layer.7.attention.self.key.weight', 'encoder.layer.15.attention.self.value.weight', 'encoder.layer.1.attention.self.query.weight', 'encoder.layer.3.attention.self.key.weight', 'encoder.layer.7.attention.output.dense.bias', 'encoder.layer.22.attention.self.key.bias', 'encoder.layer.15.attention.output.LayerNorm.weight', 'encoder.layer.2.attention.self.key.bias', 'encoder.layer.20.output.LayerNorm.bias', 'encoder.layer.8.attention.self.query.weight', 'encoder.layer.2.attention.self.value.bias', 'encoder.layer.11.attention.self.value.weight', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.15.attention.self.value.bias', 'encoder.layer.12.output.dense.weight', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.19.output.LayerNorm.weight', 'encoder.layer.1.attention.output.dense.weight', 'encoder.layer.23.attention.self.key.bias', 'encoder.layer.22.output.dense.weight', 'encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.13.attention.output.dense.bias', 'encoder.layer.1.attention.output.dense.bias', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.3.attention.self.query.weight', 'encoder.layer.22.attention.output.dense.bias', 'encoder.layer.16.output.LayerNorm.bias', 'encoder.layer.5.attention.self.value.bias', 'encoder.layer.15.output.dense.bias', 'encoder.layer.16.intermediate.dense.bias', 'encoder.layer.6.output.LayerNorm.bias', 'encoder.layer.22.output.LayerNorm.weight', 'encoder.layer.18.intermediate.dense.weight', 'encoder.layer.12.output.LayerNorm.bias', 'encoder.layer.7.attention.output.LayerNorm.bias', 'encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.layer.23.attention.output.LayerNorm.weight', 'encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.16.attention.self.query.weight', 'encoder.layer.1.attention.self.key.weight', 'encoder.layer.6.attention.output.dense.bias', 'encoder.layer.2.attention.self.value.weight', 'encoder.layer.17.attention.output.LayerNorm.bias', 'encoder.layer.18.output.dense.weight', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.14.attention.self.query.weight', 'encoder.layer.7.output.dense.weight', 'encoder.layer.23.output.dense.bias', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.18.intermediate.dense.bias', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.6.attention.self.value.bias', 'encoder.layer.14.output.dense.bias', 'encoder.layer.21.attention.self.value.weight', 'encoder.layer.18.attention.self.key.bias', 'encoder.layer.0.attention.self.value.bias', 'encoder.layer.15.output.dense.weight', 'encoder.layer.8.output.LayerNorm.bias', 'encoder.layer.20.attention.output.dense.bias', 'encoder.layer.13.output.dense.weight', 'encoder.layer.18.attention.output.dense.weight', 'encoder.layer.10.attention.output.LayerNorm.weight', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.12.attention.output.LayerNorm.bias', 'encoder.layer.9.output.LayerNorm.weight', 'encoder.layer.5.attention.self.query.weight', 'encoder.layer.21.output.LayerNorm.bias', 'embeddings.LayerNorm.bias', 'encoder.layer.3.attention.output.dense.bias', 'encoder.layer.4.attention.self.query.bias', 'encoder.layer.7.attention.output.LayerNorm.weight', 'encoder.layer.3.output.dense.weight', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.7.attention.self.query.bias', 'encoder.layer.15.attention.self.query.bias', 'encoder.layer.3.attention.self.query.bias', 'encoder.layer.9.attention.self.value.weight', 'encoder.layer.2.attention.output.dense.weight', 'encoder.layer.2.attention.self.query.weight', 'encoder.layer.18.output.dense.bias', 'encoder.layer.9.attention.output.dense.weight', 'encoder.layer.18.attention.self.key.weight', 'encoder.layer.19.output.LayerNorm.bias', 'encoder.layer.17.attention.self.value.weight', 'encoder.layer.16.attention.output.dense.weight', 'encoder.layer.9.attention.self.value.bias', 'encoder.layer.5.attention.self.query.bias', 'encoder.layer.2.attention.output.dense.bias', 'encoder.layer.23.attention.self.value.bias', 'encoder.layer.15.intermediate.dense.bias', 'encoder.layer.22.attention.self.query.bias', 'encoder.layer.22.intermediate.dense.weight', 'encoder.layer.10.attention.self.query.bias', 'encoder.layer.6.output.dense.weight', 'encoder.layer.8.output.dense.weight', 'encoder.layer.2.attention.self.key.weight', 'encoder.layer.13.attention.output.LayerNorm.bias', 'encoder.layer.20.output.dense.bias', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.10.attention.self.value.weight', 'encoder.layer.17.attention.self.key.weight', 'encoder.layer.4.attention.self.value.weight', 'encoder.layer.17.output.LayerNorm.weight', 'encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.layer.6.attention.output.LayerNorm.bias', 'encoder.layer.22.output.LayerNorm.bias', 'encoder.layer.16.attention.self.key.bias', 'encoder.layer.21.attention.output.dense.bias', 'encoder.layer.15.attention.output.dense.weight', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.12.intermediate.dense.bias', 'encoder.layer.9.attention.self.query.weight', 'encoder.layer.10.attention.output.dense.weight', 'encoder.layer.4.output.dense.bias', 'encoder.layer.3.attention.output.dense.weight', 'encoder.layer.23.attention.output.LayerNorm.bias', 'encoder.layer.17.attention.output.dense.weight', 'encoder.layer.6.attention.output.LayerNorm.weight', 'encoder.layer.19.attention.output.dense.weight', 'encoder.layer.12.attention.output.LayerNorm.weight', 'encoder.layer.17.attention.self.query.weight', 'encoder.layer.8.output.dense.bias', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.13.attention.self.query.weight', 'encoder.layer.12.output.LayerNorm.weight', 'encoder.layer.12.output.dense.bias', 'encoder.layer.16.attention.output.dense.bias', 'encoder.layer.5.output.dense.weight', 'encoder.layer.14.attention.output.dense.weight', 'embeddings.position_embeddings.weight', 'encoder.layer.9.attention.output.LayerNorm.weight', 'encoder.layer.13.intermediate.dense.bias', 'encoder.layer.20.attention.output.dense.weight', 'encoder.layer.18.attention.self.query.bias', 'encoder.layer.22.attention.output.dense.weight', 'encoder.layer.19.attention.self.query.bias', 'encoder.layer.9.attention.self.query.bias', 'encoder.layer.21.attention.self.key.bias', 'encoder.layer.13.attention.output.LayerNorm.weight', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.1.attention.self.key.bias', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.0.attention.self.value.weight', 'encoder.layer.23.attention.self.query.bias', 'encoder.layer.22.attention.output.LayerNorm.weight', 'encoder.layer.19.intermediate.dense.weight', 'encoder.layer.11.output.LayerNorm.bias', 'encoder.layer.22.attention.self.query.weight', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.0.attention.output.dense.weight', 'encoder.layer.12.attention.self.query.weight', 'encoder.layer.0.attention.self.key.weight', 'encoder.layer.11.output.dense.bias', 'encoder.layer.22.attention.self.value.weight', 'encoder.layer.13.output.LayerNorm.bias', 'encoder.layer.14.attention.output.LayerNorm.weight', 'encoder.layer.0.attention.output.LayerNorm.weight', 'encoder.layer.7.attention.self.query.weight', 'encoder.layer.16.attention.self.key.weight', 'encoder.layer.2.attention.self.query.bias', 'encoder.layer.5.attention.self.key.weight', 'encoder.layer.11.output.LayerNorm.weight', 'encoder.layer.14.attention.self.value.bias', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.13.attention.self.query.bias', 'pooler.dense.weight', 'encoder.layer.16.output.dense.bias', 'encoder.layer.4.attention.output.dense.weight', 'encoder.layer.4.attention.output.LayerNorm.bias', 'encoder.layer.7.output.LayerNorm.weight', 'encoder.layer.21.intermediate.dense.bias', 'encoder.layer.8.attention.self.key.bias', 'encoder.layer.22.attention.self.value.bias', 'encoder.layer.4.attention.self.value.bias', 'encoder.layer.5.attention.output.LayerNorm.weight', 'encoder.layer.9.output.dense.bias', 'encoder.layer.9.attention.output.dense.bias', 'encoder.layer.20.attention.output.LayerNorm.weight', 'encoder.layer.11.attention.output.LayerNorm.weight', 'encoder.layer.16.attention.output.LayerNorm.weight', 'encoder.layer.7.intermediate.dense.bias', 'encoder.layer.14.intermediate.dense.bias', 'encoder.layer.1.attention.output.LayerNorm.weight', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.6.attention.self.query.bias', 'encoder.layer.12.attention.self.value.weight', 'encoder.layer.21.attention.output.dense.weight', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.23.attention.self.value.weight', 'encoder.layer.23.attention.output.dense.bias', 'encoder.layer.12.attention.self.value.bias', 'encoder.layer.17.output.LayerNorm.bias', 'encoder.layer.19.attention.self.value.bias', 'encoder.layer.4.attention.output.LayerNorm.weight', 'encoder.layer.2.attention.output.LayerNorm.weight', 'encoder.layer.15.attention.output.LayerNorm.bias', 'encoder.layer.5.output.LayerNorm.bias', 'encoder.layer.16.attention.output.LayerNorm.bias', 'encoder.layer.1.attention.self.value.bias', 'encoder.layer.23.attention.output.dense.weight', 'encoder.layer.15.intermediate.dense.weight', 'encoder.layer.17.attention.self.key.bias', 'encoder.layer.5.attention.output.dense.bias', 'encoder.layer.1.output.dense.bias', 'encoder.layer.21.output.dense.weight', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.7.output.LayerNorm.bias', 'encoder.layer.8.attention.self.value.weight', 'encoder.layer.20.intermediate.dense.weight', 'encoder.layer.9.output.LayerNorm.bias', 'encoder.layer.10.intermediate.dense.weight', 'encoder.layer.1.output.dense.weight', 'encoder.layer.20.attention.output.LayerNorm.bias', 'encoder.layer.13.output.LayerNorm.weight', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.7.attention.self.value.bias', 'encoder.layer.18.output.LayerNorm.weight', 'encoder.layer.14.intermediate.dense.weight', 'embeddings.token_type_embeddings.weight', 'encoder.layer.11.attention.self.query.weight', 'encoder.layer.18.attention.self.value.bias', 'encoder.layer.2.attention.output.LayerNorm.bias', 'encoder.layer.21.attention.output.LayerNorm.bias', 'encoder.layer.17.attention.self.query.bias', 'encoder.layer.2.output.dense.bias', 'encoder.layer.5.output.dense.bias', 'encoder.layer.6.attention.output.dense.weight', 'encoder.layer.0.attention.self.query.weight', 'encoder.layer.10.output.LayerNorm.bias', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.17.output.dense.weight', 'encoder.layer.11.attention.self.key.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Overwriting existing adapter 'ep'.
Overwriting existing adapter 'tp'.
Overwriting existing adapter 'es'.
Overwriting existing adapter 'ts'.
Overwriting existing adapter fusion module 'ep,tp,es,ts'
05/09/2022 09:09:06 - INFO - __main__ -   Creating features from dataset file at .
/cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//squad/xlm-KG_LR3e-5_EPOCH2.0_maxlen384_batchsize4_gradacc4
XLMConfig {
  "architectures": [
    "XLMRobertaForMaskedLM"
  ],
  "asm": false,
  "attention_dropout": 0.1,
  "attention_probs_dropout_prob": 0.1,
  "bos_index": 0,
  "bos_token_id": 0,
  "causal": false,
  "dropout": 0.1,
  "emb_dim": 1024,
  "embed_init_std": 0.02209708691207961,
  "end_n_top": 5,
  "eos_index": 1,
  "eos_token_id": 2,
  "gelu_activation": true,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "init_std": 0.02,
  "initializer_range": 0.02,
  "intermediate_size": 4096,
  "is_encoder": true,
  "lang_id": 0,
  "layer_norm_eps": 1e-05,
  "mask_index": 5,
  "mask_token_id": 0,
  "max_position_embeddings": 514,
  "model_type": "xlm",
  "n_heads": 16,
  "n_langs": 1,
  "n_layers": 24,
  "output_past": true,
  "pad_index": 2,
  "pad_token_id": 1,
  "sinusoidal_embeddings": false,
  "start_n_top": 5,
  "summary_activation": null,
  "summary_first_dropout": 0.1,
  "summary_proj_to_labels": true,
  "summary_type": "first",
  "summary_use_proj": true,
  "transformers_version": "4.17.0",
  "type_vocab_size": 1,
  "unk_index": 3,
  "use_lang_emb": false,
  "vocab_size": 250002
}

  0%|          | 0/48 [00:00<?, ?it/s] 21%|██        | 10/48 [00:00<00:00, 97.42it/s] 42%|████▏     | 20/48 [00:00<00:00, 64.07it/s] 58%|█████▊    | 28/48 [00:00<00:00, 62.89it/s] 75%|███████▌  | 36/48 [00:00<00:00, 67.70it/s] 92%|█████████▏| 44/48 [00:00<00:00, 69.37it/s]100%|██████████| 48/48 [00:00<00:00, 69.21it/s]
convert squad examples to features:   0%|          | 0/1190 [00:00<?, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.
convert squad examples to features:   0%|          | 1/1190 [00:00<04:27,  4.45it/s]convert squad examples to features:   3%|▎         | 33/1190 [00:00<00:09, 124.33it/s]convert squad examples to features:   5%|▌         | 65/1190 [00:00<00:07, 144.36it/s]convert squad examples to features:   8%|▊         | 97/1190 [00:00<00:07, 154.39it/s]convert squad examples to features:  11%|█         | 129/1190 [00:00<00:06, 175.64it/s]convert squad examples to features:  14%|█▎        | 161/1190 [00:01<00:05, 181.01it/s]convert squad examples to features:  16%|█▌        | 193/1190 [00:01<00:05, 189.37it/s]convert squad examples to features:  19%|█▉        | 225/1190 [00:01<00:05, 188.49it/s]convert squad examples to features:  22%|██▏       | 257/1190 [00:01<00:05, 185.09it/s]convert squad examples to features:  24%|██▍       | 289/1190 [00:01<00:05, 176.25it/s]convert squad examples to features:  27%|██▋       | 321/1190 [00:01<00:04, 183.39it/s]convert squad examples to features:  30%|██▉       | 353/1190 [00:02<00:04, 189.56it/s]convert squad examples to features:  32%|███▏      | 385/1190 [00:02<00:07, 101.93it/s]convert squad examples to features:  35%|███▌      | 417/1190 [00:02<00:06, 117.24it/s]convert squad examples to features:  38%|███▊      | 449/1190 [00:03<00:05, 131.44it/s]convert squad examples to features:  40%|████      | 481/1190 [00:03<00:05, 140.95it/s]convert squad examples to features:  43%|████▎     | 513/1190 [00:03<00:04, 148.54it/s]convert squad examples to features:  46%|████▌     | 545/1190 [00:03<00:04, 143.10it/s]convert squad examples to features:  48%|████▊     | 577/1190 [00:03<00:04, 145.86it/s]convert squad examples to features:  51%|█████     | 609/1190 [00:04<00:03, 146.90it/s]convert squad examples to features:  54%|█████▍    | 641/1190 [00:04<00:03, 149.82it/s]convert squad examples to features:  57%|█████▋    | 673/1190 [00:04<00:03, 141.28it/s]convert squad examples to features:  59%|█████▉    | 705/1190 [00:04<00:03, 143.26it/s]convert squad examples to features:  62%|██████▏   | 737/1190 [00:04<00:02, 155.78it/s]convert squad examples to features:  65%|██████▍   | 769/1190 [00:05<00:02, 165.68it/s]convert squad examples to features:  67%|██████▋   | 801/1190 [00:05<00:02, 168.36it/s]convert squad examples to features:  70%|███████   | 833/1190 [00:05<00:02, 161.34it/s]convert squad examples to features:  73%|███████▎  | 865/1190 [00:05<00:02, 160.17it/s]convert squad examples to features:  75%|███████▌  | 897/1190 [00:05<00:01, 154.94it/s]convert squad examples to features:  78%|███████▊  | 929/1190 [00:06<00:01, 157.97it/s]convert squad examples to features:  81%|████████  | 961/1190 [00:06<00:01, 153.46it/s]convert squad examples to features:  83%|████████▎ | 993/1190 [00:06<00:01, 174.83it/s]convert squad examples to features:  86%|████████▌ | 1025/1190 [00:06<00:00, 186.24it/s]convert squad examples to features:  89%|████████▉ | 1057/1190 [00:06<00:00, 192.71it/s]convert squad examples to features:  92%|█████████▏| 1089/1190 [00:06<00:00, 197.70it/s]convert squad examples to features:  94%|█████████▍| 1121/1190 [00:07<00:00, 191.01it/s]convert squad examples to features:  97%|█████████▋| 1153/1190 [00:07<00:00, 177.76it/s]convert squad examples to features: 100%|██████████| 1190/1190 [00:07<00:00, 162.53it/s]
add example index and unique id:   0%|          | 0/1190 [00:00<?, ?it/s]add example index and unique id: 100%|██████████| 1190/1190 [00:00<00:00, 558864.83it/s]
05/09/2022 09:09:15 - INFO - __main__ -   Saving features into cached file ./cached_xquad.tr.json_xlm-KG_LR3e-5_EPOCH2.0_maxlen384_batchsize4_gradacc4_384_tr
05/09/2022 09:09:16 - INFO - __main__ -   ***** Running evaluation  *****
05/09/2022 09:09:16 - INFO - __main__ -     Num examples = 1274
05/09/2022 09:09:16 - INFO - __main__ -     Batch size = 8
Evaluating:   0%|          | 0/160 [00:00<?, ?it/s]Evaluating:   1%|          | 1/160 [00:00<02:33,  1.04it/s]Evaluating:   1%|▏         | 2/160 [00:01<01:34,  1.67it/s]Evaluating:   2%|▏         | 3/160 [00:01<01:15,  2.08it/s]Evaluating:   2%|▎         | 4/160 [00:01<01:06,  2.34it/s]Evaluating:   3%|▎         | 5/160 [00:02<01:01,  2.52it/s]Evaluating:   4%|▍         | 6/160 [00:02<00:58,  2.63it/s]Evaluating:   4%|▍         | 7/160 [00:03<00:56,  2.72it/s]Evaluating:   5%|▌         | 8/160 [00:03<00:54,  2.78it/s]Evaluating:   6%|▌         | 9/160 [00:03<00:53,  2.83it/s]Evaluating:   6%|▋         | 10/160 [00:04<00:52,  2.85it/s]Evaluating:   7%|▋         | 11/160 [00:04<00:51,  2.87it/s]Evaluating:   8%|▊         | 12/160 [00:04<00:51,  2.88it/s]Evaluating:   8%|▊         | 13/160 [00:05<00:50,  2.90it/s]Evaluating:   9%|▉         | 14/160 [00:05<00:50,  2.90it/s]Evaluating:   9%|▉         | 15/160 [00:05<00:49,  2.90it/s]Evaluating:  10%|█         | 16/160 [00:06<00:49,  2.91it/s]Evaluating:  11%|█         | 17/160 [00:06<00:49,  2.91it/s]Evaluating:  11%|█▏        | 18/160 [00:06<00:48,  2.91it/s]Evaluating:  12%|█▏        | 19/160 [00:07<00:48,  2.92it/s]Evaluating:  12%|█▎        | 20/160 [00:07<00:47,  2.92it/s]Evaluating:  13%|█▎        | 21/160 [00:07<00:47,  2.92it/s]Evaluating:  14%|█▍        | 22/160 [00:08<00:47,  2.92it/s]Evaluating:  14%|█▍        | 23/160 [00:08<00:46,  2.93it/s]Evaluating:  15%|█▌        | 24/160 [00:08<00:46,  2.92it/s]Evaluating:  16%|█▌        | 25/160 [00:09<00:46,  2.92it/s]Evaluating:  16%|█▋        | 26/160 [00:09<00:46,  2.91it/s]Evaluating:  17%|█▋        | 27/160 [00:09<00:45,  2.92it/s]Evaluating:  18%|█▊        | 28/160 [00:10<00:45,  2.92it/s]Evaluating:  18%|█▊        | 29/160 [00:10<00:44,  2.92it/s]Evaluating:  19%|█▉        | 30/160 [00:10<00:44,  2.92it/s]Evaluating:  19%|█▉        | 31/160 [00:11<00:44,  2.92it/s]Evaluating:  20%|██        | 32/160 [00:11<00:43,  2.92it/s]Evaluating:  21%|██        | 33/160 [00:11<00:43,  2.92it/s]Evaluating:  21%|██▏       | 34/160 [00:12<00:43,  2.92it/s]Evaluating:  22%|██▏       | 35/160 [00:12<00:42,  2.92it/s]Evaluating:  22%|██▎       | 36/160 [00:12<00:42,  2.92it/s]Evaluating:  23%|██▎       | 37/160 [00:13<00:42,  2.92it/s]Evaluating:  24%|██▍       | 38/160 [00:13<00:41,  2.92it/s]Evaluating:  24%|██▍       | 39/160 [00:13<00:41,  2.92it/s]Evaluating:  25%|██▌       | 40/160 [00:14<00:41,  2.90it/s]Evaluating:  26%|██▌       | 41/160 [00:14<00:40,  2.90it/s]Evaluating:  26%|██▋       | 42/160 [00:15<00:40,  2.90it/s]Evaluating:  27%|██▋       | 43/160 [00:15<00:40,  2.91it/s]Evaluating:  28%|██▊       | 44/160 [00:15<00:39,  2.91it/s]Evaluating:  28%|██▊       | 45/160 [00:16<00:39,  2.91it/s]Evaluating:  29%|██▉       | 46/160 [00:16<00:39,  2.91it/s]Evaluating:  29%|██▉       | 47/160 [00:16<00:38,  2.91it/s]Evaluating:  30%|███       | 48/160 [00:17<00:38,  2.92it/s]Evaluating:  31%|███       | 49/160 [00:17<00:38,  2.92it/s]Evaluating:  31%|███▏      | 50/160 [00:17<00:37,  2.91it/s]Evaluating:  32%|███▏      | 51/160 [00:18<00:37,  2.90it/s]Evaluating:  32%|███▎      | 52/160 [00:18<00:37,  2.89it/s]Evaluating:  33%|███▎      | 53/160 [00:18<00:36,  2.90it/s]Evaluating:  34%|███▍      | 54/160 [00:19<00:36,  2.89it/s]Evaluating:  34%|███▍      | 55/160 [00:19<00:36,  2.89it/s]Evaluating:  35%|███▌      | 56/160 [00:19<00:35,  2.89it/s]Evaluating:  36%|███▌      | 57/160 [00:20<00:35,  2.89it/s]Evaluating:  36%|███▋      | 58/160 [00:20<00:35,  2.89it/s]Evaluating:  37%|███▋      | 59/160 [00:20<00:35,  2.89it/s]Evaluating:  38%|███▊      | 60/160 [00:21<00:34,  2.89it/s]Evaluating:  38%|███▊      | 61/160 [00:21<00:34,  2.89it/s]Evaluating:  39%|███▉      | 62/160 [00:21<00:33,  2.90it/s]Evaluating:  39%|███▉      | 63/160 [00:22<00:33,  2.90it/s]Evaluating:  40%|████      | 64/160 [00:22<00:33,  2.90it/s]Evaluating:  41%|████      | 65/160 [00:22<00:32,  2.90it/s]Evaluating:  41%|████▏     | 66/160 [00:23<00:32,  2.90it/s]Evaluating:  42%|████▏     | 67/160 [00:23<00:32,  2.90it/s]Evaluating:  42%|████▎     | 68/160 [00:23<00:31,  2.90it/s]Evaluating:  43%|████▎     | 69/160 [00:24<00:31,  2.90it/s]Evaluating:  44%|████▍     | 70/160 [00:24<00:30,  2.90it/s]Evaluating:  44%|████▍     | 71/160 [00:25<00:30,  2.91it/s]Evaluating:  45%|████▌     | 72/160 [00:25<00:30,  2.91it/s]Evaluating:  46%|████▌     | 73/160 [00:25<00:30,  2.90it/s]Evaluating:  46%|████▋     | 74/160 [00:26<00:29,  2.90it/s]Evaluating:  47%|████▋     | 75/160 [00:26<00:29,  2.89it/s]Evaluating:  48%|████▊     | 76/160 [00:26<00:29,  2.89it/s]Evaluating:  48%|████▊     | 77/160 [00:27<00:28,  2.89it/s]Evaluating:  49%|████▉     | 78/160 [00:27<00:28,  2.90it/s]Evaluating:  49%|████▉     | 79/160 [00:27<00:27,  2.90it/s]Evaluating:  50%|█████     | 80/160 [00:28<00:27,  2.91it/s]Evaluating:  51%|█████     | 81/160 [00:28<00:27,  2.91it/s]Evaluating:  51%|█████▏    | 82/160 [00:28<00:26,  2.91it/s]Evaluating:  52%|█████▏    | 83/160 [00:29<00:26,  2.90it/s]Evaluating:  52%|█████▎    | 84/160 [00:29<00:26,  2.91it/s]Evaluating:  53%|█████▎    | 85/160 [00:29<00:25,  2.90it/s]Evaluating:  54%|█████▍    | 86/160 [00:30<00:25,  2.90it/s]Evaluating:  54%|█████▍    | 87/160 [00:30<00:25,  2.90it/s]Evaluating:  55%|█████▌    | 88/160 [00:30<00:24,  2.90it/s]Evaluating:  56%|█████▌    | 89/160 [00:31<00:24,  2.91it/s]Evaluating:  56%|█████▋    | 90/160 [00:31<00:24,  2.91it/s]Evaluating:  57%|█████▋    | 91/160 [00:31<00:23,  2.91it/s]Evaluating:  57%|█████▊    | 92/160 [00:32<00:23,  2.92it/s]Evaluating:  58%|█████▊    | 93/160 [00:32<00:23,  2.91it/s]Evaluating:  59%|█████▉    | 94/160 [00:32<00:22,  2.90it/s]Evaluating:  59%|█████▉    | 95/160 [00:33<00:22,  2.90it/s]Evaluating:  60%|██████    | 96/160 [00:33<00:21,  2.91it/s]Evaluating:  61%|██████    | 97/160 [00:33<00:21,  2.91it/s]Evaluating:  61%|██████▏   | 98/160 [00:34<00:21,  2.92it/s]Evaluating:  62%|██████▏   | 99/160 [00:34<00:20,  2.92it/s]Evaluating:  62%|██████▎   | 100/160 [00:35<00:20,  2.92it/s]Evaluating:  63%|██████▎   | 101/160 [00:35<00:20,  2.92it/s]Evaluating:  64%|██████▍   | 102/160 [00:35<00:19,  2.92it/s]Evaluating:  64%|██████▍   | 103/160 [00:36<00:19,  2.92it/s]Evaluating:  65%|██████▌   | 104/160 [00:36<00:19,  2.91it/s]Evaluating:  66%|██████▌   | 105/160 [00:36<00:18,  2.91it/s]Evaluating:  66%|██████▋   | 106/160 [00:37<00:18,  2.91it/s]Evaluating:  67%|██████▋   | 107/160 [00:37<00:18,  2.91it/s]Evaluating:  68%|██████▊   | 108/160 [00:37<00:17,  2.91it/s]Evaluating:  68%|██████▊   | 109/160 [00:38<00:17,  2.92it/s]Evaluating:  69%|██████▉   | 110/160 [00:38<00:17,  2.92it/s]Evaluating:  69%|██████▉   | 111/160 [00:38<00:16,  2.92it/s]Evaluating:  70%|███████   | 112/160 [00:39<00:16,  2.92it/s]Evaluating:  71%|███████   | 113/160 [00:39<00:16,  2.92it/s]Evaluating:  71%|███████▏  | 114/160 [00:39<00:15,  2.91it/s]Evaluating:  72%|███████▏  | 115/160 [00:40<00:15,  2.91it/s]Evaluating:  72%|███████▎  | 116/160 [00:40<00:15,  2.91it/s]Evaluating:  73%|███████▎  | 117/160 [00:40<00:14,  2.91it/s]Evaluating:  74%|███████▍  | 118/160 [00:41<00:14,  2.90it/s]Evaluating:  74%|███████▍  | 119/160 [00:41<00:14,  2.91it/s]Evaluating:  75%|███████▌  | 120/160 [00:41<00:13,  2.91it/s]Evaluating:  76%|███████▌  | 121/160 [00:42<00:13,  2.91it/s]Evaluating:  76%|███████▋  | 122/160 [00:42<00:13,  2.90it/s]Evaluating:  77%|███████▋  | 123/160 [00:42<00:12,  2.91it/s]Evaluating:  78%|███████▊  | 124/160 [00:43<00:12,  2.90it/s]Evaluating:  78%|███████▊  | 125/160 [00:43<00:12,  2.90it/s]Evaluating:  79%|███████▉  | 126/160 [00:43<00:11,  2.90it/s]Evaluating:  79%|███████▉  | 127/160 [00:44<00:11,  2.90it/s]Evaluating:  80%|████████  | 128/160 [00:44<00:11,  2.88it/s]Evaluating:  81%|████████  | 129/160 [00:44<00:10,  2.88it/s]Evaluating:  81%|████████▏ | 130/160 [00:45<00:10,  2.83it/s]Evaluating:  82%|████████▏ | 131/160 [00:45<00:10,  2.86it/s]Evaluating:  82%|████████▎ | 132/160 [00:46<00:09,  2.88it/s]Evaluating:  83%|████████▎ | 133/160 [00:46<00:09,  2.89it/s]Evaluating:  84%|████████▍ | 134/160 [00:46<00:08,  2.90it/s]Evaluating:  84%|████████▍ | 135/160 [00:47<00:08,  2.90it/s]Evaluating:  85%|████████▌ | 136/160 [00:47<00:08,  2.91it/s]Evaluating:  86%|████████▌ | 137/160 [00:47<00:07,  2.92it/s]Evaluating:  86%|████████▋ | 138/160 [00:48<00:07,  2.90it/s]Evaluating:  87%|████████▋ | 139/160 [00:48<00:07,  2.89it/s]Evaluating:  88%|████████▊ | 140/160 [00:48<00:06,  2.90it/s]Evaluating:  88%|████████▊ | 141/160 [00:49<00:06,  2.90it/s]Evaluating:  89%|████████▉ | 142/160 [00:49<00:06,  2.90it/s]Evaluating:  89%|████████▉ | 143/160 [00:49<00:05,  2.90it/s]Evaluating:  90%|█████████ | 144/160 [00:50<00:05,  2.90it/s]Evaluating:  91%|█████████ | 145/160 [00:50<00:05,  2.91it/s]Evaluating:  91%|█████████▏| 146/160 [00:50<00:04,  2.91it/s]Evaluating:  92%|█████████▏| 147/160 [00:51<00:04,  2.91it/s]Evaluating:  92%|█████████▎| 148/160 [00:51<00:04,  2.91it/s]Evaluating:  93%|█████████▎| 149/160 [00:51<00:03,  2.91it/s]Evaluating:  94%|█████████▍| 150/160 [00:52<00:03,  2.91it/s]Evaluating:  94%|█████████▍| 151/160 [00:52<00:03,  2.91it/s]Evaluating:  95%|█████████▌| 152/160 [00:52<00:02,  2.91it/s]Evaluating:  96%|█████████▌| 153/160 [00:53<00:02,  2.91it/s]Evaluating:  96%|█████████▋| 154/160 [00:53<00:02,  2.91it/s]Evaluating:  97%|█████████▋| 155/160 [00:53<00:01,  2.91it/s]Evaluating:  98%|█████████▊| 156/160 [00:54<00:01,  2.90it/s]Evaluating:  98%|█████████▊| 157/160 [00:54<00:01,  2.90it/s]Evaluating:  99%|█████████▉| 158/160 [00:54<00:00,  2.88it/s]Evaluating:  99%|█████████▉| 159/160 [00:55<00:00,  2.89it/s]Evaluating: 100%|██████████| 160/160 [00:55<00:00,  3.60it/s]Evaluating: 100%|██████████| 160/160 [00:55<00:00,  2.89it/s]
05/09/2022 09:10:12 - INFO - __main__ -     Evaluation done in total 55.445288 secs (0.043521 sec per example)
05/09/2022 09:10:18 - INFO - __main__ -   Results: {'exact': 58.319327731092436, 'f1': 74.40996742687409, 'total': 1190, 'HasAns_exact': 58.319327731092436, 'HasAns_f1': 74.40996742687409, 'HasAns_total': 1190, 'best_exact': 58.319327731092436, 'best_exact_thresh': 0.0, 'best_f1': 74.40996742687409, 'best_f1_thresh': 0.0}
  ar 
2022-05-09 09:10:22.475871: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0
05/09/2022 09:10:26 - WARNING - __main__ -   Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, 16-bits training: False
You are using a model of type xlm-roberta to instantiate a model of type xlm. This is not supported for all configurations of models and can yield errors.
Some weights of the model checkpoint at /cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//squad/xlm-KG_LR3e-5_EPOCH2.0_maxlen384_batchsize4_gradacc4 were not used when initializing XLMRobertaModel: ['base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.2.attention.output.LayerNorm.bias', 'base_model.encoder.layer.19.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.16.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.10.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.18.attention.output.LayerNorm.weight', 'base_model.encoder.layer.8.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.4.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.12.output.dense.weight', 'base_model.encoder.layer.8.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.19.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.15.attention.output.LayerNorm.bias', 'base_model.encoder.layer.22.attention.self.value.bias', 'base_model.encoder.layer.12.attention.output.LayerNorm.weight', 'base_model.encoder.layer.17.attention.self.query.weight', 'base_model.encoder.layer.10.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.11.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.14.intermediate.dense.weight', 'base_model.encoder.layer.19.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.0.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.17.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.4.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.3.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.22.attention.output.dense.bias', 'base_model.encoder.layer.10.attention.output.LayerNorm.weight', 'base_model.encoder.layer.1.output.LayerNorm.bias', 'base_model.encoder.layer.3.intermediate.dense.weight', 'base_model.encoder.layer.5.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.22.intermediate.dense.bias', 'base_model.encoder.layer.10.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.17.attention.self.value.bias', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.23.output.dense.weight', 'base_model.encoder.layer.0.output.LayerNorm.weight', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.8.attention.output.dense.weight', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.23.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.15.output.dense.bias', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.5.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.5.output.adapters.tp.adapter_up.bias', 'base_model.embeddings.token_type_embeddings.weight', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.4.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.2.attention.self.value.bias', 'base_model.encoder.layer.14.attention.output.LayerNorm.weight', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.16.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.3.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.5.output.LayerNorm.bias', 'base_model.encoder.layer.7.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.9.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.20.attention.self.query.weight', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.13.attention.self.value.bias', 'base_model.encoder.layer.6.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.13.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.2.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.14.output.LayerNorm.weight', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.14.attention.self.query.bias', 'base_model.encoder.layer.18.attention.self.value.bias', 'base_model.encoder.layer.17.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.10.output.LayerNorm.weight', 'base_model.encoder.layer.3.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.15.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.21.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.5.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.6.output.LayerNorm.bias', 'base_model.encoder.layer.6.attention.output.LayerNorm.bias', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.12.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.23.output.LayerNorm.weight', 'base_model.encoder.layer.0.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.4.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.16.attention.self.key.bias', 'base_model.encoder.layer.7.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.10.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.2.output.LayerNorm.bias', 'base_model.encoder.layer.11.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.2.output.dense.weight', 'base_model.encoder.layer.19.intermediate.dense.weight', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.21.intermediate.dense.weight', 'base_model.encoder.layer.18.attention.self.key.weight', 'base_model.encoder.layer.12.output.LayerNorm.weight', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.13.attention.output.LayerNorm.weight', 'base_model.encoder.layer.4.output.LayerNorm.weight', 'base_model.encoder.layer.2.attention.self.key.weight', 'base_model.encoder.layer.8.attention.self.query.weight', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.19.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.12.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.10.output.LayerNorm.bias', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.6.intermediate.dense.bias', 'base_model.encoder.layer.8.attention.self.key.bias', 'base_model.encoder.layer.20.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.20.output.dense.weight', 'base_model.encoder.layer.0.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.13.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.9.attention.self.query.weight', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.18.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.21.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.14.intermediate.dense.bias', 'base_model.encoder.layer.2.attention.self.query.weight', 'base_model.encoder.layer.15.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.10.attention.output.dense.bias', 'base_model.encoder.layer.14.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.3.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.6.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.20.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.19.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.9.output.dense.weight', 'base_model.encoder.layer.21.attention.self.key.weight', 'base_model.encoder.layer.6.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.4.intermediate.dense.bias', 'base_model.encoder.layer.0.attention.output.dense.weight', 'base_model.encoder.layer.10.attention.self.query.weight', 'base_model.encoder.layer.20.attention.output.LayerNorm.bias', 'base_model.encoder.layer.3.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.15.attention.output.dense.bias', 'base_model.encoder.layer.0.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.19.output.LayerNorm.bias', 'base_model.encoder.layer.2.attention.output.dense.weight', 'base_model.embeddings.word_embeddings.weight', 'base_model.encoder.layer.4.attention.output.dense.bias', 'base_model.encoder.layer.15.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.5.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.11.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.23.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.23.attention.self.value.bias', 'base_model.encoder.layer.15.attention.self.key.bias', 'base_model.encoder.layer.7.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.8.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.21.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.19.intermediate.dense.bias', 'base_model.encoder.layer.20.attention.self.value.weight', 'base_model.encoder.layer.20.output.dense.bias', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.22.attention.self.key.weight', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.9.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.2.attention.self.query.bias', 'base_model.encoder.layer.23.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.22.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.20.output.LayerNorm.weight', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.13.attention.self.value.weight', 'base_model.encoder.layer.21.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.14.attention.self.key.bias', 'base_model.encoder.layer.16.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.16.output.LayerNorm.weight', 'base_model.encoder.layer.18.output.LayerNorm.weight', 'base_model.encoder.layer.6.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.15.intermediate.dense.bias', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.16.attention.output.LayerNorm.bias', 'base_model.encoder.layer.19.output.dense.bias', 'base_model.encoder.layer.12.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.16.attention.self.query.weight', 'base_model.encoder.layer.6.attention.output.dense.weight', 'base_model.encoder.layer.8.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.14.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.21.attention.self.query.weight', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.22.attention.output.LayerNorm.bias', 'base_model.encoder.layer.10.attention.self.query.bias', 'base_model.encoder.layer.20.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.23.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.10.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.16.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.17.intermediate.dense.bias', 'base_model.encoder.layer.22.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.17.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.13.attention.output.LayerNorm.bias', 'base_model.encoder.layer.0.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.21.attention.output.LayerNorm.bias', 'base_model.encoder.layer.5.attention.output.dense.weight', 'base_model.encoder.layer.17.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.10.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.2.output.LayerNorm.weight', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.0.attention.self.query.bias', 'base_model.encoder.layer.16.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.21.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.7.output.dense.bias', 'base_model.encoder.layer.4.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.5.attention.output.LayerNorm.weight', 'base_model.encoder.layer.5.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.0.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.3.attention.self.key.weight', 'base_model.encoder.layer.17.attention.self.value.weight', 'base_model.encoder.layer.13.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.11.attention.self.query.bias', 'base_model.encoder.layer.4.attention.self.key.weight', 'base_model.encoder.layer.17.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.11.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.17.output.LayerNorm.bias', 'base_model.encoder.layer.2.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.0.attention.self.value.bias', 'base_model.encoder.layer.14.attention.output.LayerNorm.bias', 'base_model.encoder.layer.15.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.3.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.15.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.0.attention.output.dense.bias', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.4.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.8.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.12.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.14.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.3.attention.self.value.bias', 'base_model.encoder.layer.17.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.7.attention.self.key.bias', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.18.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.4.attention.self.key.bias', 'base_model.encoder.layer.13.output.LayerNorm.bias', 'base_model.encoder.layer.9.output.LayerNorm.bias', 'base_model.encoder.layer.1.attention.output.dense.bias', 'base_model.encoder.layer.15.output.LayerNorm.weight', 'base_model.encoder.layer.17.attention.self.key.weight', 'base_model.encoder.layer.20.intermediate.dense.weight', 'base_model.encoder.layer.19.attention.output.dense.weight', 'base_model.encoder.layer.10.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.8.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.6.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.13.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.16.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.pooler.dense.weight', 'base_model.encoder.layer.23.attention.self.query.weight', 'base_model.encoder.layer.17.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.8.attention.self.value.bias', 'base_model.encoder.layer.4.attention.self.value.weight', 'base_model.encoder.layer.13.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.13.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.14.attention.self.query.weight', 'base_model.encoder.layer.5.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.12.output.dense.bias', 'base_model.encoder.layer.12.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.23.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.18.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.18.attention.output.dense.weight', 'base_model.encoder.layer.17.attention.self.key.bias', 'base_model.encoder.layer.18.output.dense.weight', 'base_model.encoder.layer.1.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.18.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.5.output.LayerNorm.weight', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.22.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.13.attention.output.dense.bias', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.5.attention.output.dense.bias', 'base_model.encoder.layer.15.output.LayerNorm.bias', 'base_model.encoder.layer.17.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.6.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.18.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.20.attention.output.LayerNorm.weight', 'base_model.encoder.layer.3.output.LayerNorm.bias', 'base_model.encoder.layer.7.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.3.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.6.output.dense.bias', 'base_model.encoder.layer.0.output.dense.weight', 'base_model.encoder.layer.13.attention.self.query.bias', 'base_model.encoder.layer.9.attention.output.LayerNorm.weight', 'base_model.encoder.layer.12.attention.output.dense.bias', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.3.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.8.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.8.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.17.attention.self.query.bias', 'base_model.encoder.layer.20.attention.output.dense.bias', 'base_model.encoder.layer.18.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.13.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.6.attention.output.LayerNorm.weight', 'base_model.encoder.layer.6.output.dense.weight', 'base_model.encoder.layer.22.output.dense.weight', 'base_model.encoder.layer.11.output.dense.bias', 'base_model.encoder.layer.15.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.16.intermediate.dense.bias', 'base_model.encoder.layer.3.output.dense.bias', 'base_model.encoder.layer.15.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.2.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.16.output.dense.weight', 'base_model.encoder.layer.7.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.21.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.5.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.23.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.10.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.12.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.4.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.20.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.3.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.2.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.23.attention.output.LayerNorm.bias', 'base_model.encoder.layer.11.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.12.attention.self.value.bias', 'base_model.encoder.layer.15.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.21.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.11.intermediate.dense.bias', 'base_model.encoder.layer.5.attention.self.value.weight', 'base_model.encoder.layer.0.intermediate.dense.weight', 'base_model.encoder.layer.2.intermediate.dense.bias', 'base_model.encoder.layer.9.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.12.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.1.attention.self.key.bias', 'base_model.encoder.layer.20.output.LayerNorm.bias', 'base_model.encoder.layer.5.attention.output.LayerNorm.bias', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.13.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.9.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.8.output.LayerNorm.weight', 'base_model.encoder.layer.7.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.12.output.LayerNorm.bias', 'base_model.encoder.layer.1.attention.output.LayerNorm.weight', 'base_model.encoder.layer.7.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.20.attention.self.value.bias', 'base_model.encoder.layer.21.output.LayerNorm.weight', 'base_model.encoder.layer.22.attention.self.query.weight', 'base_model.encoder.layer.18.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.0.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.6.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.19.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.2.output.dense.bias', 'base_model.encoder.layer.4.attention.output.dense.weight', 'base_model.encoder.layer.14.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.19.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.18.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.0.output.dense.bias', 'base_model.encoder.layer.9.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.15.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.1.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.12.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.3.attention.output.dense.weight', 'base_model.encoder.layer.7.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.16.attention.self.query.bias', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.22.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.7.attention.self.query.weight', 'base_model.encoder.layer.19.attention.output.LayerNorm.weight', 'base_model.encoder.layer.12.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.0.attention.self.query.weight', 'base_model.encoder.layer.13.intermediate.dense.bias', 'base_model.encoder.layer.8.output.dense.weight', 'base_model.encoder.layer.18.intermediate.dense.bias', 'base_model.encoder.layer.12.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.9.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.14.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.22.attention.self.value.weight', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.1.attention.self.value.weight', 'base_model.encoder.layer.2.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.2.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.18.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.7.output.dense.weight', 'base_model.encoder.layer.7.attention.self.key.weight', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.21.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.10.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.2.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.11.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.6.intermediate.dense.weight', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.23.attention.output.dense.bias', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.9.attention.self.value.weight', 'base_model.encoder.layer.16.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.6.output.LayerNorm.weight', 'base_model.encoder.layer.16.attention.self.value.weight', 'base_model.encoder.layer.21.attention.self.query.bias', 'base_model.encoder.layer.5.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.8.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.4.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.10.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.3.attention.self.query.weight', 'base_model.encoder.layer.14.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.10.intermediate.dense.weight', 'base_model.encoder.layer.14.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.16.output.dense.bias', 'base_model.encoder.layer.16.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.11.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.21.attention.self.key.bias', 'base_model.encoder.layer.6.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.16.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.19.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.18.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.20.attention.self.query.bias', 'base_model.encoder.layer.6.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.23.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.17.output.dense.bias', 'base_model.encoder.layer.23.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.4.attention.self.query.weight', 'base_model.encoder.layer.0.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.17.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.6.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.21.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.23.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.9.attention.self.key.bias', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.2.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.21.attention.output.LayerNorm.weight', 'base_model.encoder.layer.13.output.dense.bias', 'base_model.encoder.layer.22.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.23.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.4.attention.output.LayerNorm.bias', 'base_model.encoder.layer.4.output.dense.weight', 'base_model.encoder.layer.18.attention.self.query.bias', 'base_model.encoder.layer.7.attention.self.query.bias', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.15.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.6.attention.self.query.weight', 'base_model.encoder.layer.0.attention.output.LayerNorm.bias', 'base_model.encoder.layer.11.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.1.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.0.attention.self.key.weight', 'base_model.encoder.layer.10.output.dense.weight', 'base_model.encoder.layer.19.attention.self.query.weight', 'base_model.encoder.layer.18.attention.output.dense.bias', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.22.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.17.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.22.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.12.attention.output.dense.weight', 'base_model.encoder.layer.21.output.dense.bias', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.2.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.13.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.10.attention.self.key.weight', 'base_model.encoder.layer.8.output.dense.bias', 'base_model.encoder.layer.23.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.4.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.14.attention.output.dense.bias', 'base_model.encoder.layer.21.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.17.output.dense.weight', 'base_model.encoder.layer.1.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.embeddings.LayerNorm.weight', 'base_model.encoder.layer.1.output.dense.bias', 'base_model.embeddings.position_ids', 'base_model.encoder.layer.20.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.6.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.13.attention.self.query.weight', 'base_model.encoder.layer.3.intermediate.dense.bias', 'base_model.encoder.layer.19.attention.output.dense.bias', 'base_model.encoder.layer.7.attention.output.dense.weight', 'base_model.encoder.layer.7.output.LayerNorm.weight', 'base_model.encoder.layer.15.attention.output.LayerNorm.weight', 'base_model.encoder.layer.16.output.LayerNorm.bias', 'base_model.encoder.layer.9.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.18.output.dense.bias', 'base_model.encoder.layer.1.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.15.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.12.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.15.attention.self.query.weight', 'base_model.encoder.layer.2.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.15.attention.self.query.bias', 'base_model.encoder.layer.16.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.0.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.11.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.4.attention.self.value.bias', 'base_model.encoder.layer.0.attention.self.key.bias', 'base_model.encoder.layer.2.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.13.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.0.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.19.output.dense.weight', 'base_model.encoder.layer.17.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.12.attention.self.key.bias', 'base_model.encoder.layer.7.attention.output.dense.bias', 'base_model.encoder.layer.7.output.LayerNorm.bias', 'base_model.encoder.layer.22.attention.self.query.bias', 'base_model.encoder.layer.1.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.3.attention.output.dense.bias', 'base_model.encoder.layer.19.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.12.attention.self.key.weight', 'base_model.encoder.layer.22.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.23.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.11.attention.output.LayerNorm.bias', 'base_model.encoder.layer.12.intermediate.dense.bias', 'base_model.encoder.layer.14.output.LayerNorm.bias', 'base_model.encoder.layer.22.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.14.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.19.attention.self.value.bias', 'base_model.encoder.layer.1.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.2.attention.output.dense.bias', 'base_model.encoder.layer.5.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.20.attention.output.dense.weight', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.8.attention.self.query.bias', 'base_model.encoder.layer.23.attention.self.key.weight', 'base_model.encoder.layer.16.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.17.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.20.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.20.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.21.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.5.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.5.attention.self.value.bias', 'base_model.encoder.layer.4.attention.output.LayerNorm.weight', 'base_model.encoder.layer.0.attention.output.LayerNorm.weight', 'base_model.encoder.layer.21.output.LayerNorm.bias', 'base_model.encoder.layer.2.intermediate.dense.weight', 'base_model.encoder.layer.5.attention.self.query.bias', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.8.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.7.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.4.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.21.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.6.attention.self.value.weight', 'base_model.encoder.layer.9.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.9.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.23.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.22.output.adapters.tp.adapter_up.weight', 'base_model.pooler.dense.bias', 'base_model.encoder.layer.7.attention.self.value.bias', 'base_model.encoder.layer.8.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.14.output.dense.weight', 'base_model.encoder.layer.16.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.4.attention.self.query.bias', 'base_model.encoder.layer.1.attention.self.query.weight', 'base_model.encoder.layer.10.output.dense.bias', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.7.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.20.attention.self.key.bias', 'base_model.encoder.layer.6.attention.self.value.bias', 'base_model.encoder.layer.17.attention.output.dense.weight', 'base_model.encoder.layer.21.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.19.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.13.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.20.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.20.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.5.attention.self.key.weight', 'base_model.encoder.layer.5.intermediate.dense.weight', 'base_model.encoder.layer.11.attention.self.value.bias', 'base_model.encoder.layer.14.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.11.attention.self.value.weight', 'base_model.encoder.layer.5.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.16.attention.output.dense.weight', 'base_model.encoder.layer.15.output.dense.weight', 'base_model.encoder.layer.22.output.LayerNorm.weight', 'base_model.encoder.layer.2.attention.self.value.weight', 'base_model.encoder.layer.21.attention.self.value.bias', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.5.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.20.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.0.attention.self.value.weight', 'base_model.encoder.layer.16.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.20.intermediate.dense.bias', 'base_model.encoder.layer.21.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.14.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.13.attention.self.key.bias', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.19.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.4.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.16.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.7.attention.output.LayerNorm.weight', 'base_model.encoder.layer.1.output.LayerNorm.weight', 'base_model.encoder.layer.2.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.1.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.19.output.LayerNorm.weight', 'base_model.encoder.layer.9.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.6.attention.self.key.weight', 'qa_outputs.weight', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.18.attention.self.key.bias', 'base_model.encoder.layer.17.attention.output.LayerNorm.weight', 'base_model.encoder.layer.6.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.8.attention.output.LayerNorm.bias', 'base_model.encoder.layer.3.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.5.output.dense.weight', 'base_model.encoder.layer.6.attention.self.query.bias', 'base_model.encoder.layer.13.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.14.attention.self.value.bias', 'base_model.encoder.layer.14.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.17.attention.output.dense.bias', 'base_model.encoder.layer.4.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.19.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.18.attention.self.value.weight', 'base_model.encoder.layer.1.attention.self.value.bias', 'base_model.encoder.layer.16.attention.self.value.bias', 'base_model.encoder.layer.11.intermediate.dense.weight', 'base_model.encoder.layer.10.attention.output.LayerNorm.bias', 'base_model.encoder.layer.19.attention.self.key.weight', 'base_model.encoder.layer.4.output.LayerNorm.bias', 'base_model.encoder.layer.18.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.21.intermediate.dense.bias', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.21.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.14.attention.self.value.weight', 'base_model.encoder.layer.10.intermediate.dense.bias', 'base_model.encoder.layer.0.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.17.attention.output.LayerNorm.bias', 'base_model.encoder.layer.18.attention.self.query.weight', 'base_model.encoder.layer.21.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.8.attention.self.value.weight', 'base_model.encoder.layer.23.intermediate.dense.weight', 'base_model.encoder.layer.16.intermediate.dense.weight', 'base_model.encoder.layer.4.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.20.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.17.intermediate.dense.weight', 'base_model.encoder.layer.23.intermediate.dense.bias', 'base_model.encoder.layer.7.attention.output.LayerNorm.bias', 'base_model.encoder.layer.3.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.10.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.10.attention.self.key.bias', 'base_model.encoder.layer.1.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.3.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.15.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.1.attention.self.key.weight', 'base_model.encoder.layer.4.output.dense.bias', 'base_model.encoder.layer.7.attention.self.value.weight', 'base_model.encoder.layer.11.attention.output.LayerNorm.weight', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.14.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.13.attention.output.dense.weight', 'base_model.encoder.layer.7.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.20.attention.self.key.weight', 'base_model.encoder.layer.10.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.20.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.1.attention.output.dense.weight', 'base_model.encoder.layer.12.attention.self.query.bias', 'base_model.encoder.layer.12.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.4.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.23.output.dense.bias', 'base_model.encoder.layer.17.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.10.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.11.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.14.output.dense.bias', 'base_model.encoder.layer.9.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.4.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.0.output.LayerNorm.bias', 'base_model.encoder.layer.11.output.LayerNorm.bias', 'base_model.encoder.layer.12.attention.self.value.weight', 'base_model.encoder.layer.16.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.20.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.12.intermediate.dense.weight', 'base_model.encoder.layer.21.attention.output.dense.weight', 'base_model.encoder.layer.0.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.11.output.dense.weight', 'base_model.encoder.layer.10.attention.output.dense.weight', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.1.intermediate.dense.bias', 'base_model.encoder.layer.8.attention.output.dense.bias', 'base_model.encoder.layer.16.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.9.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.23.attention.self.value.weight', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.19.attention.self.value.weight', 'base_model.encoder.layer.12.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.6.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.7.intermediate.dense.weight', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.7.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.0.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.3.output.dense.weight', 'base_model.encoder.layer.9.output.dense.bias', 'base_model.encoder.layer.13.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.3.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.8.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.15.intermediate.dense.weight', 'base_model.encoder.layer.7.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.5.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.11.attention.output.dense.bias', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.9.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.8.attention.self.key.weight', 'base_model.encoder.layer.23.output.LayerNorm.bias', 'base_model.encoder.layer.19.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.2.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.22.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.22.attention.output.LayerNorm.weight', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.11.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.15.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.12.attention.output.LayerNorm.bias', 'base_model.encoder.layer.1.attention.output.LayerNorm.bias', 'base_model.encoder.layer.9.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.23.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.1.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.6.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.19.attention.self.key.bias', 'base_model.encoder.layer.12.attention.self.query.weight', 'base_model.encoder.layer.23.attention.self.query.bias', 'base_model.encoder.layer.6.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.14.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.10.output.adapters.ep.adapter_up.bias', 'base_model.embeddings.position_embeddings.weight', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.9.attention.self.key.weight', 'base_model.encoder.layer.23.attention.output.dense.weight', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.13.output.dense.weight', 'base_model.embeddings.LayerNorm.bias', 'base_model.encoder.layer.18.output.LayerNorm.bias', 'base_model.encoder.layer.15.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.2.attention.self.key.bias', 'base_model.encoder.layer.9.attention.output.dense.bias', 'base_model.encoder.layer.9.attention.self.query.bias', 'base_model.encoder.layer.6.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.5.output.dense.bias', 'base_model.encoder.layer.8.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.12.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.17.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.11.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.12.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.17.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.2.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.12.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.22.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.3.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.14.attention.output.dense.weight', 'base_model.encoder.layer.6.attention.self.key.bias', 'base_model.encoder.layer.11.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.8.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.21.attention.output.dense.bias', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.14.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.9.intermediate.dense.weight', 'base_model.encoder.layer.13.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.1.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.6.attention.output.dense.bias', 'base_model.encoder.layer.15.attention.self.key.weight', 'base_model.encoder.layer.18.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.15.attention.self.value.bias', 'base_model.encoder.layer.15.attention.output.dense.weight', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.16.attention.self.key.weight', 'base_model.encoder.layer.1.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.3.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.14.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.16.attention.output.dense.bias', 'base_model.encoder.layer.18.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.5.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.19.attention.output.LayerNorm.bias', 'base_model.encoder.layer.20.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.13.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.5.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.9.output.LayerNorm.weight', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.9.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.14.attention.self.key.weight', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.7.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.10.attention.self.value.weight', 'base_model.encoder.layer.3.attention.output.LayerNorm.weight', 'base_model.encoder.layer.22.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.18.attention.output.LayerNorm.bias', 'base_model.encoder.layer.18.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.2.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.20.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.0.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.8.attention.output.LayerNorm.weight', 'base_model.encoder.layer.1.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.11.attention.self.key.bias', 'base_model.encoder.layer.22.output.dense.bias', 'base_model.encoder.layer.18.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.13.output.LayerNorm.weight', 'base_model.encoder.layer.13.attention.self.key.weight', 'base_model.encoder.layer.22.attention.output.dense.weight', 'base_model.encoder.layer.9.attention.output.dense.weight', 'base_model.encoder.layer.10.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.11.output.LayerNorm.weight', 'base_model.encoder.layer.19.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.16.attention.output.LayerNorm.weight', 'base_model.encoder.layer.22.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.19.attention.self.query.bias', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.1.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.11.attention.self.key.weight', 'base_model.encoder.layer.10.attention.self.value.bias', 'base_model.encoder.layer.9.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.13.intermediate.dense.weight', 'base_model.encoder.layer.0.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.11.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.13.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.2.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.22.output.LayerNorm.bias', 'base_model.encoder.layer.1.attention.self.query.bias', 'base_model.encoder.layer.3.attention.self.key.bias', 'base_model.encoder.layer.8.intermediate.dense.bias', 'base_model.encoder.layer.9.attention.output.LayerNorm.bias', 'base_model.encoder.layer.11.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.19.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.0.intermediate.dense.bias', 'base_model.encoder.layer.8.output.LayerNorm.bias', 'base_model.encoder.layer.3.output.LayerNorm.weight', 'base_model.encoder.layer.19.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.1.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.3.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.5.attention.self.key.bias', 'base_model.encoder.layer.11.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.22.attention.self.key.bias', 'base_model.encoder.layer.10.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.8.intermediate.dense.weight', 'base_model.encoder.layer.11.attention.output.dense.weight', 'base_model.encoder.layer.17.output.LayerNorm.weight', 'base_model.encoder.layer.20.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.3.attention.self.query.bias', 'base_model.encoder.layer.1.output.dense.weight', 'base_model.encoder.layer.2.attention.output.LayerNorm.weight', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.21.attention.self.value.weight', 'base_model.encoder.layer.4.intermediate.dense.weight', 'base_model.encoder.layer.22.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.23.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.11.attention.self.query.weight', 'base_model.encoder.layer.22.intermediate.dense.weight', 'base_model.encoder.layer.23.attention.output.LayerNorm.weight', 'base_model.encoder.layer.7.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.17.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.23.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.0.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.9.attention.self.value.bias', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.15.attention.self.value.weight', 'base_model.encoder.layer.18.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.21.output.dense.weight', 'base_model.encoder.layer.4.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.1.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.1.intermediate.dense.weight', 'base_model.encoder.layer.3.attention.self.value.weight', 'base_model.encoder.layer.7.intermediate.dense.bias', 'base_model.encoder.layer.18.intermediate.dense.weight', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.9.intermediate.dense.bias', 'base_model.encoder.layer.15.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.23.attention.self.key.bias', 'qa_outputs.bias', 'base_model.encoder.layer.22.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.15.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.5.attention.self.query.weight', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.5.intermediate.dense.bias', 'base_model.encoder.layer.8.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.8.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.7.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.14.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.3.attention.output.LayerNorm.bias']
- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of XLMRobertaModel were not initialized from the model checkpoint at /cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//squad/xlm-KG_LR3e-5_EPOCH2.0_maxlen384_batchsize4_gradacc4 and are newly initialized: ['encoder.layer.13.attention.self.query.bias', 'encoder.layer.11.attention.self.value.bias', 'encoder.layer.9.attention.self.query.bias', 'encoder.layer.16.output.dense.bias', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.12.intermediate.dense.weight', 'encoder.layer.18.attention.output.LayerNorm.bias', 'encoder.layer.17.intermediate.dense.bias', 'encoder.layer.16.attention.self.value.bias', 'encoder.layer.8.attention.self.key.bias', 'encoder.layer.20.attention.output.LayerNorm.bias', 'encoder.layer.10.attention.self.query.bias', 'encoder.layer.23.attention.output.dense.weight', 'encoder.layer.13.intermediate.dense.weight', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.17.attention.self.query.weight', 'encoder.layer.13.attention.self.value.weight', 'encoder.layer.23.attention.self.query.weight', 'encoder.layer.13.output.LayerNorm.bias', 'encoder.layer.17.output.dense.bias', 'encoder.layer.6.attention.self.query.weight', 'encoder.layer.2.attention.self.key.bias', 'encoder.layer.11.attention.output.dense.bias', 'encoder.layer.11.attention.output.LayerNorm.weight', 'encoder.layer.15.attention.self.key.bias', 'encoder.layer.8.attention.output.dense.weight', 'encoder.layer.18.attention.self.key.weight', 'encoder.layer.18.attention.self.query.bias', 'encoder.layer.8.output.LayerNorm.bias', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.12.output.LayerNorm.weight', 'encoder.layer.14.attention.output.LayerNorm.weight', 'encoder.layer.16.attention.self.key.bias', 'encoder.layer.0.attention.output.dense.bias', 'embeddings.token_type_embeddings.weight', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.16.attention.output.LayerNorm.bias', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.18.output.dense.bias', 'encoder.layer.13.attention.self.key.weight', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.8.attention.self.key.weight', 'encoder.layer.7.attention.self.key.bias', 'encoder.layer.21.attention.output.dense.bias', 'encoder.layer.15.attention.output.dense.bias', 'encoder.layer.10.output.dense.bias', 'encoder.layer.11.attention.output.dense.weight', 'encoder.layer.4.attention.output.LayerNorm.weight', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.13.attention.output.dense.bias', 'encoder.layer.1.attention.output.dense.bias', 'encoder.layer.3.attention.output.dense.weight', 'encoder.layer.6.attention.self.key.weight', 'encoder.layer.23.output.LayerNorm.bias', 'encoder.layer.20.attention.output.LayerNorm.weight', 'encoder.layer.12.attention.self.value.weight', 'encoder.layer.12.attention.self.key.weight', 'encoder.layer.15.attention.output.dense.weight', 'encoder.layer.14.attention.output.dense.weight', 'encoder.layer.7.attention.self.value.bias', 'encoder.layer.20.output.LayerNorm.weight', 'encoder.layer.9.attention.self.key.bias', 'encoder.layer.19.attention.self.key.bias', 'encoder.layer.3.attention.self.value.weight', 'encoder.layer.2.attention.self.value.bias', 'encoder.layer.10.attention.output.LayerNorm.bias', 'encoder.layer.22.attention.self.value.bias', 'encoder.layer.9.attention.output.dense.bias', 'encoder.layer.10.attention.self.key.bias', 'encoder.layer.17.output.LayerNorm.bias', 'encoder.layer.7.output.dense.weight', 'encoder.layer.20.intermediate.dense.bias', 'encoder.layer.18.attention.self.value.bias', 'encoder.layer.6.attention.self.value.weight', 'encoder.layer.21.attention.self.key.weight', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.23.attention.self.query.bias', 'encoder.layer.6.attention.self.query.bias', 'encoder.layer.14.attention.self.query.bias', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.4.attention.output.dense.weight', 'encoder.layer.20.attention.output.dense.bias', 'encoder.layer.5.attention.self.key.weight', 'encoder.layer.8.attention.self.query.weight', 'encoder.layer.3.output.dense.bias', 'encoder.layer.19.attention.self.key.weight', 'encoder.layer.2.attention.self.query.bias', 'encoder.layer.19.output.dense.weight', 'encoder.layer.22.output.dense.bias', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.23.attention.self.key.weight', 'encoder.layer.22.attention.output.dense.weight', 'encoder.layer.1.attention.self.key.bias', 'encoder.layer.18.output.LayerNorm.bias', 'encoder.layer.10.attention.self.value.weight', 'encoder.layer.2.attention.self.key.weight', 'encoder.layer.18.attention.output.dense.weight', 'encoder.layer.22.attention.output.LayerNorm.bias', 'encoder.layer.6.output.dense.weight', 'encoder.layer.2.attention.output.LayerNorm.bias', 'encoder.layer.9.attention.self.query.weight', 'encoder.layer.20.intermediate.dense.weight', 'encoder.layer.2.attention.output.LayerNorm.weight', 'encoder.layer.17.attention.output.LayerNorm.weight', 'encoder.layer.4.output.dense.bias', 'encoder.layer.19.attention.output.LayerNorm.weight', 'encoder.layer.15.output.dense.bias', 'encoder.layer.6.attention.output.dense.bias', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.13.attention.output.LayerNorm.weight', 'encoder.layer.17.output.LayerNorm.weight', 'encoder.layer.3.attention.self.query.bias', 'encoder.layer.17.attention.self.key.bias', 'encoder.layer.19.attention.self.value.weight', 'encoder.layer.20.output.dense.weight', 'encoder.layer.0.attention.output.LayerNorm.weight', 'encoder.layer.15.attention.output.LayerNorm.bias', 'encoder.layer.19.attention.self.query.weight', 'encoder.layer.4.attention.self.query.weight', 'encoder.layer.0.attention.self.query.weight', 'encoder.layer.18.intermediate.dense.bias', 'encoder.layer.0.attention.output.dense.weight', 'encoder.layer.5.attention.self.value.bias', 'encoder.layer.8.output.dense.bias', 'encoder.layer.13.output.LayerNorm.weight', 'encoder.layer.9.attention.self.value.bias', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.5.output.dense.weight', 'encoder.layer.23.attention.output.LayerNorm.bias', 'encoder.layer.9.attention.self.key.weight', 'encoder.layer.21.output.LayerNorm.weight', 'encoder.layer.1.attention.self.value.weight', 'encoder.layer.14.attention.self.value.weight', 'encoder.layer.6.output.dense.bias', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.17.output.dense.weight', 'encoder.layer.15.intermediate.dense.weight', 'encoder.layer.3.output.dense.weight', 'embeddings.LayerNorm.bias', 'encoder.layer.1.attention.self.query.weight', 'encoder.layer.8.attention.output.dense.bias', 'encoder.layer.13.output.dense.weight', 'encoder.layer.2.output.dense.weight', 'encoder.layer.7.output.LayerNorm.weight', 'encoder.layer.15.output.LayerNorm.weight', 'encoder.layer.8.attention.self.value.bias', 'encoder.layer.18.attention.self.key.bias', 'encoder.layer.8.output.dense.weight', 'encoder.layer.15.attention.self.query.weight', 'encoder.layer.2.attention.self.query.weight', 'encoder.layer.21.attention.self.value.bias', 'encoder.layer.17.attention.self.key.weight', 'encoder.layer.4.attention.self.query.bias', 'encoder.layer.23.intermediate.dense.bias', 'encoder.layer.1.attention.output.LayerNorm.weight', 'encoder.layer.3.attention.self.value.bias', 'encoder.layer.18.attention.self.query.weight', 'encoder.layer.21.attention.self.key.bias', 'encoder.layer.15.intermediate.dense.bias', 'embeddings.word_embeddings.weight', 'encoder.layer.15.attention.self.value.weight', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.2.attention.self.value.weight', 'encoder.layer.23.output.LayerNorm.weight', 'encoder.layer.7.attention.output.LayerNorm.bias', 'encoder.layer.7.intermediate.dense.bias', 'embeddings.position_embeddings.weight', 'encoder.layer.21.output.LayerNorm.bias', 'encoder.layer.18.attention.output.LayerNorm.weight', 'encoder.layer.19.attention.output.LayerNorm.bias', 'encoder.layer.9.attention.output.LayerNorm.weight', 'encoder.layer.20.attention.self.value.bias', 'encoder.layer.19.attention.output.dense.weight', 'encoder.layer.7.output.dense.bias', 'encoder.layer.16.attention.self.key.weight', 'embeddings.LayerNorm.weight', 'encoder.layer.19.output.dense.bias', 'encoder.layer.17.attention.output.dense.weight', 'encoder.layer.22.attention.output.LayerNorm.weight', 'encoder.layer.9.output.dense.weight', 'encoder.layer.15.attention.self.value.bias', 'encoder.layer.10.intermediate.dense.weight', 'encoder.layer.12.attention.self.key.bias', 'encoder.layer.8.output.LayerNorm.weight', 'encoder.layer.22.attention.self.value.weight', 'encoder.layer.12.attention.output.LayerNorm.bias', 'encoder.layer.22.output.dense.weight', 'encoder.layer.21.attention.output.dense.weight', 'encoder.layer.4.attention.output.LayerNorm.bias', 'encoder.layer.12.attention.output.dense.weight', 'encoder.layer.6.attention.self.value.bias', 'encoder.layer.10.output.LayerNorm.bias', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.23.attention.self.key.bias', 'encoder.layer.23.output.dense.bias', 'encoder.layer.12.attention.self.query.weight', 'encoder.layer.3.attention.self.key.bias', 'encoder.layer.9.attention.self.value.weight', 'encoder.layer.16.attention.self.query.weight', 'encoder.layer.19.intermediate.dense.bias', 'pooler.dense.bias', 'encoder.layer.21.attention.output.LayerNorm.bias', 'encoder.layer.15.attention.self.query.bias', 'encoder.layer.21.attention.self.query.bias', 'encoder.layer.13.attention.self.value.bias', 'encoder.layer.8.attention.output.LayerNorm.bias', 'encoder.layer.8.attention.output.LayerNorm.weight', 'encoder.layer.17.intermediate.dense.weight', 'encoder.layer.14.output.LayerNorm.bias', 'encoder.layer.8.attention.self.query.bias', 'encoder.layer.12.output.LayerNorm.bias', 'encoder.layer.6.attention.output.LayerNorm.weight', 'encoder.layer.14.output.LayerNorm.weight', 'encoder.layer.23.attention.self.value.weight', 'encoder.layer.16.output.LayerNorm.bias', 'encoder.layer.20.attention.self.key.bias', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.20.output.dense.bias', 'encoder.layer.17.attention.self.value.weight', 'encoder.layer.15.attention.self.key.weight', 'encoder.layer.21.attention.self.value.weight', 'encoder.layer.11.attention.self.key.bias', 'encoder.layer.4.attention.self.value.bias', 'encoder.layer.8.attention.self.value.weight', 'encoder.layer.10.output.dense.weight', 'encoder.layer.4.attention.output.dense.bias', 'encoder.layer.5.attention.self.query.weight', 'encoder.layer.22.output.LayerNorm.weight', 'encoder.layer.17.attention.self.value.bias', 'encoder.layer.9.output.LayerNorm.weight', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.1.attention.self.key.weight', 'encoder.layer.22.attention.output.dense.bias', 'encoder.layer.11.output.dense.weight', 'encoder.layer.14.attention.self.value.bias', 'encoder.layer.7.attention.output.dense.bias', 'encoder.layer.19.attention.output.dense.bias', 'encoder.layer.4.attention.self.key.weight', 'encoder.layer.0.attention.self.query.bias', 'encoder.layer.0.attention.self.value.bias', 'encoder.layer.15.output.dense.weight', 'encoder.layer.10.output.LayerNorm.weight', 'encoder.layer.3.attention.self.key.weight', 'encoder.layer.5.attention.self.query.bias', 'encoder.layer.17.attention.self.query.bias', 'encoder.layer.21.intermediate.dense.bias', 'encoder.layer.7.attention.output.dense.weight', 'encoder.layer.16.attention.output.dense.weight', 'encoder.layer.7.attention.self.value.weight', 'encoder.layer.15.attention.output.LayerNorm.weight', 'encoder.layer.1.attention.output.dense.weight', 'encoder.layer.19.output.LayerNorm.weight', 'encoder.layer.19.intermediate.dense.weight', 'encoder.layer.21.attention.self.query.weight', 'encoder.layer.11.attention.self.query.weight', 'encoder.layer.10.attention.self.query.weight', 'encoder.layer.6.attention.output.dense.weight', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.14.attention.output.dense.bias', 'encoder.layer.3.attention.output.dense.bias', 'encoder.layer.11.output.dense.bias', 'encoder.layer.14.output.dense.bias', 'encoder.layer.21.intermediate.dense.weight', 'encoder.layer.16.intermediate.dense.bias', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.16.output.LayerNorm.weight', 'encoder.layer.14.attention.self.key.weight', 'encoder.layer.13.attention.self.key.bias', 'encoder.layer.11.attention.self.key.weight', 'encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.layer.13.attention.output.LayerNorm.bias', 'encoder.layer.12.output.dense.weight', 'encoder.layer.9.attention.output.dense.weight', 'encoder.layer.10.attention.self.key.weight', 'encoder.layer.18.attention.self.value.weight', 'encoder.layer.17.attention.output.LayerNorm.bias', 'encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.0.output.dense.bias', 'encoder.layer.1.attention.self.query.bias', 'encoder.layer.0.attention.self.key.weight', 'encoder.layer.2.attention.output.dense.bias', 'encoder.layer.7.attention.self.query.bias', 'encoder.layer.10.attention.output.LayerNorm.weight', 'encoder.layer.22.attention.self.key.weight', 'encoder.layer.23.attention.output.LayerNorm.weight', 'encoder.layer.12.attention.self.query.bias', 'encoder.layer.20.attention.self.query.bias', 'encoder.layer.16.attention.self.query.bias', 'encoder.layer.15.output.LayerNorm.bias', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.1.attention.self.value.bias', 'encoder.layer.5.attention.self.value.weight', 'encoder.layer.22.intermediate.dense.weight', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.5.output.dense.bias', 'encoder.layer.0.output.dense.weight', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.11.output.LayerNorm.weight', 'encoder.layer.18.intermediate.dense.weight', 'encoder.layer.1.output.dense.weight', 'encoder.layer.3.attention.self.query.weight', 'encoder.layer.13.output.dense.bias', 'encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.layer.4.attention.self.key.bias', 'encoder.layer.13.attention.output.dense.weight', 'encoder.layer.0.attention.self.value.weight', 'encoder.layer.13.intermediate.dense.bias', 'encoder.layer.9.output.LayerNorm.bias', 'encoder.layer.13.attention.self.query.weight', 'encoder.layer.22.attention.self.key.bias', 'encoder.layer.6.attention.output.LayerNorm.bias', 'encoder.layer.5.attention.output.dense.weight', 'encoder.layer.19.output.LayerNorm.bias', 'encoder.layer.7.attention.self.query.weight', 'encoder.layer.7.attention.self.key.weight', 'pooler.dense.weight', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.23.attention.output.dense.bias', 'encoder.layer.23.attention.self.value.bias', 'encoder.layer.16.attention.self.value.weight', 'encoder.layer.6.attention.self.key.bias', 'encoder.layer.20.attention.self.query.weight', 'encoder.layer.7.output.LayerNorm.bias', 'encoder.layer.18.attention.output.dense.bias', 'encoder.layer.0.attention.self.key.bias', 'encoder.layer.22.attention.self.query.weight', 'encoder.layer.20.output.LayerNorm.bias', 'encoder.layer.12.attention.self.value.bias', 'encoder.layer.16.intermediate.dense.weight', 'encoder.layer.20.attention.self.value.weight', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.23.intermediate.dense.weight', 'encoder.layer.18.output.dense.weight', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.5.attention.output.LayerNorm.weight', 'encoder.layer.5.output.LayerNorm.bias', 'encoder.layer.9.attention.output.LayerNorm.bias', 'encoder.layer.14.attention.self.key.bias', 'encoder.layer.14.attention.output.LayerNorm.bias', 'encoder.layer.9.output.dense.bias', 'encoder.layer.21.attention.output.LayerNorm.weight', 'encoder.layer.23.output.dense.weight', 'encoder.layer.12.intermediate.dense.bias', 'encoder.layer.20.attention.output.dense.weight', 'encoder.layer.21.output.dense.bias', 'encoder.layer.16.attention.output.LayerNorm.weight', 'encoder.layer.22.output.LayerNorm.bias', 'encoder.layer.14.output.dense.weight', 'encoder.layer.20.attention.self.key.weight', 'encoder.layer.21.output.dense.weight', 'encoder.layer.14.intermediate.dense.weight', 'encoder.layer.14.attention.self.query.weight', 'encoder.layer.11.output.LayerNorm.bias', 'encoder.layer.11.attention.self.value.weight', 'encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.7.attention.output.LayerNorm.weight', 'encoder.layer.16.attention.output.dense.bias', 'encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.18.output.LayerNorm.weight', 'encoder.layer.6.output.LayerNorm.bias', 'encoder.layer.16.output.dense.weight', 'encoder.layer.5.attention.self.key.bias', 'encoder.layer.1.output.dense.bias', 'encoder.layer.10.attention.output.dense.weight', 'encoder.layer.10.attention.self.value.bias', 'encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.layer.5.attention.output.dense.bias', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.12.attention.output.dense.bias', 'encoder.layer.22.intermediate.dense.bias', 'encoder.layer.4.output.dense.weight', 'encoder.layer.2.output.dense.bias', 'encoder.layer.14.intermediate.dense.bias', 'encoder.layer.10.attention.output.dense.bias', 'encoder.layer.4.attention.self.value.weight', 'encoder.layer.11.attention.self.query.bias', 'encoder.layer.2.attention.output.dense.weight', 'encoder.layer.12.attention.output.LayerNorm.weight', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.12.output.dense.bias', 'encoder.layer.17.attention.output.dense.bias', 'encoder.layer.19.attention.self.query.bias', 'encoder.layer.22.attention.self.query.bias', 'encoder.layer.19.attention.self.value.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Overwriting existing adapter 'ep'.
Overwriting existing adapter 'tp'.
Overwriting existing adapter 'es'.
Overwriting existing adapter 'ts'.
Overwriting existing adapter fusion module 'ep,tp,es,ts'
05/09/2022 09:10:53 - INFO - __main__ -   lang2id = None
05/09/2022 09:10:59 - INFO - __main__ -   Training/evaluation parameters Namespace(adam_epsilon=1e-08, cache_dir='', config_name='', data_dir=None, device=device(type='cuda'), do_eval=True, do_lower_case=False, do_train=False, doc_stride=128, eval_all_checkpoints=False, eval_lang='ar', evaluate_during_training=False, fp16=False, fp16_opt_level='O1', gradient_accumulation_steps=1, learning_rate=5e-05, local_rank=-1, logging_steps=50, max_answer_length=30, max_grad_norm=1.0, max_query_length=64, max_seq_length=384, max_steps=-1, model_name='xlm-KG', model_name_or_path='/cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//squad/xlm-KG_LR3e-5_EPOCH2.0_maxlen384_batchsize4_gradacc4', model_type='xlm', modelkg_dir='/cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/adapter/xlmr_adapter', n_best_size=20, n_gpu=1, no_cuda=False, null_score_diff_threshold=0.0, num_train_epochs=3.0, output_dir='/cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//squad/xlm-KG_LR3e-5_EPOCH2.0_maxlen384_batchsize4_gradacc4/predictions/xquad/', overwrite_cache=False, overwrite_output_dir=False, per_gpu_eval_batch_size=8, per_gpu_train_batch_size=8, predict_file='/cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/download//xquad//xquad.ar.json', save_steps=50, seed=42, server_ip='', server_port='', threads=1, tokenizer_name='', train_file=None, train_lang='en', verbose_logging=False, version_2_with_negative=False, warmup_steps=0, weight_decay=0.0)
05/09/2022 09:10:59 - INFO - __main__ -   Loading checkpoint /cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//squad/xlm-KG_LR3e-5_EPOCH2.0_maxlen384_batchsize4_gradacc4 for evaluation
05/09/2022 09:10:59 - INFO - __main__ -   Evaluate the following checkpoints: ['/cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//squad/xlm-KG_LR3e-5_EPOCH2.0_maxlen384_batchsize4_gradacc4']
Some weights of the model checkpoint at /cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//squad/xlm-KG_LR3e-5_EPOCH2.0_maxlen384_batchsize4_gradacc4 were not used when initializing XLMRobertaModel: ['base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.2.attention.output.LayerNorm.bias', 'base_model.encoder.layer.19.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.16.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.10.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.18.attention.output.LayerNorm.weight', 'base_model.encoder.layer.8.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.4.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.12.output.dense.weight', 'base_model.encoder.layer.8.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.19.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.15.attention.output.LayerNorm.bias', 'base_model.encoder.layer.22.attention.self.value.bias', 'base_model.encoder.layer.12.attention.output.LayerNorm.weight', 'base_model.encoder.layer.17.attention.self.query.weight', 'base_model.encoder.layer.10.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.11.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.14.intermediate.dense.weight', 'base_model.encoder.layer.19.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.0.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.17.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.4.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.3.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.22.attention.output.dense.bias', 'base_model.encoder.layer.10.attention.output.LayerNorm.weight', 'base_model.encoder.layer.1.output.LayerNorm.bias', 'base_model.encoder.layer.3.intermediate.dense.weight', 'base_model.encoder.layer.5.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.22.intermediate.dense.bias', 'base_model.encoder.layer.10.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.17.attention.self.value.bias', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.23.output.dense.weight', 'base_model.encoder.layer.0.output.LayerNorm.weight', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.8.attention.output.dense.weight', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.23.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.15.output.dense.bias', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.5.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.5.output.adapters.tp.adapter_up.bias', 'base_model.embeddings.token_type_embeddings.weight', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.4.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.2.attention.self.value.bias', 'base_model.encoder.layer.14.attention.output.LayerNorm.weight', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.16.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.3.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.5.output.LayerNorm.bias', 'base_model.encoder.layer.7.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.9.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.20.attention.self.query.weight', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.13.attention.self.value.bias', 'base_model.encoder.layer.6.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.13.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.2.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.14.output.LayerNorm.weight', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.14.attention.self.query.bias', 'base_model.encoder.layer.18.attention.self.value.bias', 'base_model.encoder.layer.17.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.10.output.LayerNorm.weight', 'base_model.encoder.layer.3.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.15.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.21.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.5.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.6.output.LayerNorm.bias', 'base_model.encoder.layer.6.attention.output.LayerNorm.bias', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.12.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.23.output.LayerNorm.weight', 'base_model.encoder.layer.0.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.4.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.16.attention.self.key.bias', 'base_model.encoder.layer.7.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.10.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.2.output.LayerNorm.bias', 'base_model.encoder.layer.11.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.2.output.dense.weight', 'base_model.encoder.layer.19.intermediate.dense.weight', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.21.intermediate.dense.weight', 'base_model.encoder.layer.18.attention.self.key.weight', 'base_model.encoder.layer.12.output.LayerNorm.weight', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.13.attention.output.LayerNorm.weight', 'base_model.encoder.layer.4.output.LayerNorm.weight', 'base_model.encoder.layer.2.attention.self.key.weight', 'base_model.encoder.layer.8.attention.self.query.weight', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.19.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.12.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.10.output.LayerNorm.bias', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.6.intermediate.dense.bias', 'base_model.encoder.layer.8.attention.self.key.bias', 'base_model.encoder.layer.20.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.20.output.dense.weight', 'base_model.encoder.layer.0.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.13.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.9.attention.self.query.weight', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.18.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.21.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.14.intermediate.dense.bias', 'base_model.encoder.layer.2.attention.self.query.weight', 'base_model.encoder.layer.15.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.10.attention.output.dense.bias', 'base_model.encoder.layer.14.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.3.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.6.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.20.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.19.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.9.output.dense.weight', 'base_model.encoder.layer.21.attention.self.key.weight', 'base_model.encoder.layer.6.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.4.intermediate.dense.bias', 'base_model.encoder.layer.0.attention.output.dense.weight', 'base_model.encoder.layer.10.attention.self.query.weight', 'base_model.encoder.layer.20.attention.output.LayerNorm.bias', 'base_model.encoder.layer.3.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.15.attention.output.dense.bias', 'base_model.encoder.layer.0.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.19.output.LayerNorm.bias', 'base_model.encoder.layer.2.attention.output.dense.weight', 'base_model.embeddings.word_embeddings.weight', 'base_model.encoder.layer.4.attention.output.dense.bias', 'base_model.encoder.layer.15.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.5.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.11.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.23.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.23.attention.self.value.bias', 'base_model.encoder.layer.15.attention.self.key.bias', 'base_model.encoder.layer.7.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.8.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.21.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.19.intermediate.dense.bias', 'base_model.encoder.layer.20.attention.self.value.weight', 'base_model.encoder.layer.20.output.dense.bias', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.22.attention.self.key.weight', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.9.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.2.attention.self.query.bias', 'base_model.encoder.layer.23.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.22.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.20.output.LayerNorm.weight', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.13.attention.self.value.weight', 'base_model.encoder.layer.21.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.14.attention.self.key.bias', 'base_model.encoder.layer.16.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.16.output.LayerNorm.weight', 'base_model.encoder.layer.18.output.LayerNorm.weight', 'base_model.encoder.layer.6.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.15.intermediate.dense.bias', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.16.attention.output.LayerNorm.bias', 'base_model.encoder.layer.19.output.dense.bias', 'base_model.encoder.layer.12.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.16.attention.self.query.weight', 'base_model.encoder.layer.6.attention.output.dense.weight', 'base_model.encoder.layer.8.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.14.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.21.attention.self.query.weight', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.22.attention.output.LayerNorm.bias', 'base_model.encoder.layer.10.attention.self.query.bias', 'base_model.encoder.layer.20.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.23.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.10.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.16.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.17.intermediate.dense.bias', 'base_model.encoder.layer.22.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.17.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.13.attention.output.LayerNorm.bias', 'base_model.encoder.layer.0.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.21.attention.output.LayerNorm.bias', 'base_model.encoder.layer.5.attention.output.dense.weight', 'base_model.encoder.layer.17.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.10.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.2.output.LayerNorm.weight', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.0.attention.self.query.bias', 'base_model.encoder.layer.16.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.21.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.7.output.dense.bias', 'base_model.encoder.layer.4.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.5.attention.output.LayerNorm.weight', 'base_model.encoder.layer.5.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.0.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.3.attention.self.key.weight', 'base_model.encoder.layer.17.attention.self.value.weight', 'base_model.encoder.layer.13.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.11.attention.self.query.bias', 'base_model.encoder.layer.4.attention.self.key.weight', 'base_model.encoder.layer.17.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.11.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.17.output.LayerNorm.bias', 'base_model.encoder.layer.2.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.0.attention.self.value.bias', 'base_model.encoder.layer.14.attention.output.LayerNorm.bias', 'base_model.encoder.layer.15.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.3.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.15.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.0.attention.output.dense.bias', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.4.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.8.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.12.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.14.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.3.attention.self.value.bias', 'base_model.encoder.layer.17.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.7.attention.self.key.bias', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.18.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.4.attention.self.key.bias', 'base_model.encoder.layer.13.output.LayerNorm.bias', 'base_model.encoder.layer.9.output.LayerNorm.bias', 'base_model.encoder.layer.1.attention.output.dense.bias', 'base_model.encoder.layer.15.output.LayerNorm.weight', 'base_model.encoder.layer.17.attention.self.key.weight', 'base_model.encoder.layer.20.intermediate.dense.weight', 'base_model.encoder.layer.19.attention.output.dense.weight', 'base_model.encoder.layer.10.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.8.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.6.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.13.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.16.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.pooler.dense.weight', 'base_model.encoder.layer.23.attention.self.query.weight', 'base_model.encoder.layer.17.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.8.attention.self.value.bias', 'base_model.encoder.layer.4.attention.self.value.weight', 'base_model.encoder.layer.13.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.13.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.14.attention.self.query.weight', 'base_model.encoder.layer.5.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.12.output.dense.bias', 'base_model.encoder.layer.12.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.23.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.18.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.18.attention.output.dense.weight', 'base_model.encoder.layer.17.attention.self.key.bias', 'base_model.encoder.layer.18.output.dense.weight', 'base_model.encoder.layer.1.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.18.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.5.output.LayerNorm.weight', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.22.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.13.attention.output.dense.bias', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.5.attention.output.dense.bias', 'base_model.encoder.layer.15.output.LayerNorm.bias', 'base_model.encoder.layer.17.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.6.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.18.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.20.attention.output.LayerNorm.weight', 'base_model.encoder.layer.3.output.LayerNorm.bias', 'base_model.encoder.layer.7.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.3.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.6.output.dense.bias', 'base_model.encoder.layer.0.output.dense.weight', 'base_model.encoder.layer.13.attention.self.query.bias', 'base_model.encoder.layer.9.attention.output.LayerNorm.weight', 'base_model.encoder.layer.12.attention.output.dense.bias', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.3.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.8.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.8.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.17.attention.self.query.bias', 'base_model.encoder.layer.20.attention.output.dense.bias', 'base_model.encoder.layer.18.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.13.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.6.attention.output.LayerNorm.weight', 'base_model.encoder.layer.6.output.dense.weight', 'base_model.encoder.layer.22.output.dense.weight', 'base_model.encoder.layer.11.output.dense.bias', 'base_model.encoder.layer.15.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.16.intermediate.dense.bias', 'base_model.encoder.layer.3.output.dense.bias', 'base_model.encoder.layer.15.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.2.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.16.output.dense.weight', 'base_model.encoder.layer.7.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.21.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.5.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.23.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.10.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.12.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.4.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.20.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.3.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.2.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.23.attention.output.LayerNorm.bias', 'base_model.encoder.layer.11.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.12.attention.self.value.bias', 'base_model.encoder.layer.15.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.21.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.11.intermediate.dense.bias', 'base_model.encoder.layer.5.attention.self.value.weight', 'base_model.encoder.layer.0.intermediate.dense.weight', 'base_model.encoder.layer.2.intermediate.dense.bias', 'base_model.encoder.layer.9.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.12.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.1.attention.self.key.bias', 'base_model.encoder.layer.20.output.LayerNorm.bias', 'base_model.encoder.layer.5.attention.output.LayerNorm.bias', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.13.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.9.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.8.output.LayerNorm.weight', 'base_model.encoder.layer.7.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.12.output.LayerNorm.bias', 'base_model.encoder.layer.1.attention.output.LayerNorm.weight', 'base_model.encoder.layer.7.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.20.attention.self.value.bias', 'base_model.encoder.layer.21.output.LayerNorm.weight', 'base_model.encoder.layer.22.attention.self.query.weight', 'base_model.encoder.layer.18.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.0.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.6.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.19.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.2.output.dense.bias', 'base_model.encoder.layer.4.attention.output.dense.weight', 'base_model.encoder.layer.14.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.19.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.18.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.0.output.dense.bias', 'base_model.encoder.layer.9.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.15.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.1.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.12.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.3.attention.output.dense.weight', 'base_model.encoder.layer.7.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.16.attention.self.query.bias', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.22.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.7.attention.self.query.weight', 'base_model.encoder.layer.19.attention.output.LayerNorm.weight', 'base_model.encoder.layer.12.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.0.attention.self.query.weight', 'base_model.encoder.layer.13.intermediate.dense.bias', 'base_model.encoder.layer.8.output.dense.weight', 'base_model.encoder.layer.18.intermediate.dense.bias', 'base_model.encoder.layer.12.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.9.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.14.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.22.attention.self.value.weight', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.1.attention.self.value.weight', 'base_model.encoder.layer.2.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.2.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.18.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.7.output.dense.weight', 'base_model.encoder.layer.7.attention.self.key.weight', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.21.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.10.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.2.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.11.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.6.intermediate.dense.weight', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.23.attention.output.dense.bias', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.9.attention.self.value.weight', 'base_model.encoder.layer.16.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.6.output.LayerNorm.weight', 'base_model.encoder.layer.16.attention.self.value.weight', 'base_model.encoder.layer.21.attention.self.query.bias', 'base_model.encoder.layer.5.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.8.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.4.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.10.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.3.attention.self.query.weight', 'base_model.encoder.layer.14.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.10.intermediate.dense.weight', 'base_model.encoder.layer.14.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.16.output.dense.bias', 'base_model.encoder.layer.16.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.11.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.21.attention.self.key.bias', 'base_model.encoder.layer.6.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.16.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.19.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.18.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.20.attention.self.query.bias', 'base_model.encoder.layer.6.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.23.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.17.output.dense.bias', 'base_model.encoder.layer.23.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.4.attention.self.query.weight', 'base_model.encoder.layer.0.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.17.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.6.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.21.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.23.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.9.attention.self.key.bias', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.2.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.21.attention.output.LayerNorm.weight', 'base_model.encoder.layer.13.output.dense.bias', 'base_model.encoder.layer.22.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.23.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.4.attention.output.LayerNorm.bias', 'base_model.encoder.layer.4.output.dense.weight', 'base_model.encoder.layer.18.attention.self.query.bias', 'base_model.encoder.layer.7.attention.self.query.bias', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.15.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.6.attention.self.query.weight', 'base_model.encoder.layer.0.attention.output.LayerNorm.bias', 'base_model.encoder.layer.11.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.1.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.0.attention.self.key.weight', 'base_model.encoder.layer.10.output.dense.weight', 'base_model.encoder.layer.19.attention.self.query.weight', 'base_model.encoder.layer.18.attention.output.dense.bias', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.22.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.17.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.22.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.12.attention.output.dense.weight', 'base_model.encoder.layer.21.output.dense.bias', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.2.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.13.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.10.attention.self.key.weight', 'base_model.encoder.layer.8.output.dense.bias', 'base_model.encoder.layer.23.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.4.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.14.attention.output.dense.bias', 'base_model.encoder.layer.21.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.17.output.dense.weight', 'base_model.encoder.layer.1.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.embeddings.LayerNorm.weight', 'base_model.encoder.layer.1.output.dense.bias', 'base_model.embeddings.position_ids', 'base_model.encoder.layer.20.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.6.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.13.attention.self.query.weight', 'base_model.encoder.layer.3.intermediate.dense.bias', 'base_model.encoder.layer.19.attention.output.dense.bias', 'base_model.encoder.layer.7.attention.output.dense.weight', 'base_model.encoder.layer.7.output.LayerNorm.weight', 'base_model.encoder.layer.15.attention.output.LayerNorm.weight', 'base_model.encoder.layer.16.output.LayerNorm.bias', 'base_model.encoder.layer.9.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.18.output.dense.bias', 'base_model.encoder.layer.1.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.15.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.12.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.15.attention.self.query.weight', 'base_model.encoder.layer.2.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.15.attention.self.query.bias', 'base_model.encoder.layer.16.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.0.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.11.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.4.attention.self.value.bias', 'base_model.encoder.layer.0.attention.self.key.bias', 'base_model.encoder.layer.2.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.13.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.0.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.19.output.dense.weight', 'base_model.encoder.layer.17.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.12.attention.self.key.bias', 'base_model.encoder.layer.7.attention.output.dense.bias', 'base_model.encoder.layer.7.output.LayerNorm.bias', 'base_model.encoder.layer.22.attention.self.query.bias', 'base_model.encoder.layer.1.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.3.attention.output.dense.bias', 'base_model.encoder.layer.19.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.12.attention.self.key.weight', 'base_model.encoder.layer.22.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.23.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.11.attention.output.LayerNorm.bias', 'base_model.encoder.layer.12.intermediate.dense.bias', 'base_model.encoder.layer.14.output.LayerNorm.bias', 'base_model.encoder.layer.22.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.14.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.19.attention.self.value.bias', 'base_model.encoder.layer.1.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.2.attention.output.dense.bias', 'base_model.encoder.layer.5.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.20.attention.output.dense.weight', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.8.attention.self.query.bias', 'base_model.encoder.layer.23.attention.self.key.weight', 'base_model.encoder.layer.16.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.17.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.20.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.20.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.21.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.5.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.5.attention.self.value.bias', 'base_model.encoder.layer.4.attention.output.LayerNorm.weight', 'base_model.encoder.layer.0.attention.output.LayerNorm.weight', 'base_model.encoder.layer.21.output.LayerNorm.bias', 'base_model.encoder.layer.2.intermediate.dense.weight', 'base_model.encoder.layer.5.attention.self.query.bias', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.8.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.7.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.4.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.21.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.6.attention.self.value.weight', 'base_model.encoder.layer.9.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.9.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.23.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.22.output.adapters.tp.adapter_up.weight', 'base_model.pooler.dense.bias', 'base_model.encoder.layer.7.attention.self.value.bias', 'base_model.encoder.layer.8.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.14.output.dense.weight', 'base_model.encoder.layer.16.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.4.attention.self.query.bias', 'base_model.encoder.layer.1.attention.self.query.weight', 'base_model.encoder.layer.10.output.dense.bias', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.7.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.20.attention.self.key.bias', 'base_model.encoder.layer.6.attention.self.value.bias', 'base_model.encoder.layer.17.attention.output.dense.weight', 'base_model.encoder.layer.21.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.19.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.13.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.20.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.20.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.5.attention.self.key.weight', 'base_model.encoder.layer.5.intermediate.dense.weight', 'base_model.encoder.layer.11.attention.self.value.bias', 'base_model.encoder.layer.14.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.11.attention.self.value.weight', 'base_model.encoder.layer.5.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.16.attention.output.dense.weight', 'base_model.encoder.layer.15.output.dense.weight', 'base_model.encoder.layer.22.output.LayerNorm.weight', 'base_model.encoder.layer.2.attention.self.value.weight', 'base_model.encoder.layer.21.attention.self.value.bias', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.5.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.20.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.0.attention.self.value.weight', 'base_model.encoder.layer.16.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.20.intermediate.dense.bias', 'base_model.encoder.layer.21.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.14.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.13.attention.self.key.bias', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.19.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.4.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.16.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.7.attention.output.LayerNorm.weight', 'base_model.encoder.layer.1.output.LayerNorm.weight', 'base_model.encoder.layer.2.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.1.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.19.output.LayerNorm.weight', 'base_model.encoder.layer.9.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.6.attention.self.key.weight', 'qa_outputs.weight', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.18.attention.self.key.bias', 'base_model.encoder.layer.17.attention.output.LayerNorm.weight', 'base_model.encoder.layer.6.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.8.attention.output.LayerNorm.bias', 'base_model.encoder.layer.3.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.5.output.dense.weight', 'base_model.encoder.layer.6.attention.self.query.bias', 'base_model.encoder.layer.13.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.14.attention.self.value.bias', 'base_model.encoder.layer.14.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.17.attention.output.dense.bias', 'base_model.encoder.layer.4.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.19.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.18.attention.self.value.weight', 'base_model.encoder.layer.1.attention.self.value.bias', 'base_model.encoder.layer.16.attention.self.value.bias', 'base_model.encoder.layer.11.intermediate.dense.weight', 'base_model.encoder.layer.10.attention.output.LayerNorm.bias', 'base_model.encoder.layer.19.attention.self.key.weight', 'base_model.encoder.layer.4.output.LayerNorm.bias', 'base_model.encoder.layer.18.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.21.intermediate.dense.bias', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.21.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.14.attention.self.value.weight', 'base_model.encoder.layer.10.intermediate.dense.bias', 'base_model.encoder.layer.0.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.17.attention.output.LayerNorm.bias', 'base_model.encoder.layer.18.attention.self.query.weight', 'base_model.encoder.layer.21.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.8.attention.self.value.weight', 'base_model.encoder.layer.23.intermediate.dense.weight', 'base_model.encoder.layer.16.intermediate.dense.weight', 'base_model.encoder.layer.4.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.20.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.17.intermediate.dense.weight', 'base_model.encoder.layer.23.intermediate.dense.bias', 'base_model.encoder.layer.7.attention.output.LayerNorm.bias', 'base_model.encoder.layer.3.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.10.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.10.attention.self.key.bias', 'base_model.encoder.layer.1.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.3.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.15.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.1.attention.self.key.weight', 'base_model.encoder.layer.4.output.dense.bias', 'base_model.encoder.layer.7.attention.self.value.weight', 'base_model.encoder.layer.11.attention.output.LayerNorm.weight', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.14.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.13.attention.output.dense.weight', 'base_model.encoder.layer.7.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.20.attention.self.key.weight', 'base_model.encoder.layer.10.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.20.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.1.attention.output.dense.weight', 'base_model.encoder.layer.12.attention.self.query.bias', 'base_model.encoder.layer.12.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.4.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.23.output.dense.bias', 'base_model.encoder.layer.17.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.10.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.11.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.14.output.dense.bias', 'base_model.encoder.layer.9.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.4.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.0.output.LayerNorm.bias', 'base_model.encoder.layer.11.output.LayerNorm.bias', 'base_model.encoder.layer.12.attention.self.value.weight', 'base_model.encoder.layer.16.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.20.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.12.intermediate.dense.weight', 'base_model.encoder.layer.21.attention.output.dense.weight', 'base_model.encoder.layer.0.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.11.output.dense.weight', 'base_model.encoder.layer.10.attention.output.dense.weight', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.1.intermediate.dense.bias', 'base_model.encoder.layer.8.attention.output.dense.bias', 'base_model.encoder.layer.16.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.9.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.23.attention.self.value.weight', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.19.attention.self.value.weight', 'base_model.encoder.layer.12.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.6.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.7.intermediate.dense.weight', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.7.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.0.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.3.output.dense.weight', 'base_model.encoder.layer.9.output.dense.bias', 'base_model.encoder.layer.13.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.3.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.8.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.15.intermediate.dense.weight', 'base_model.encoder.layer.7.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.5.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.11.attention.output.dense.bias', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.9.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.8.attention.self.key.weight', 'base_model.encoder.layer.23.output.LayerNorm.bias', 'base_model.encoder.layer.19.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.2.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.22.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.22.attention.output.LayerNorm.weight', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.11.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.15.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.12.attention.output.LayerNorm.bias', 'base_model.encoder.layer.1.attention.output.LayerNorm.bias', 'base_model.encoder.layer.9.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.23.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.1.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.6.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.19.attention.self.key.bias', 'base_model.encoder.layer.12.attention.self.query.weight', 'base_model.encoder.layer.23.attention.self.query.bias', 'base_model.encoder.layer.6.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.14.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.10.output.adapters.ep.adapter_up.bias', 'base_model.embeddings.position_embeddings.weight', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.9.attention.self.key.weight', 'base_model.encoder.layer.23.attention.output.dense.weight', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.13.output.dense.weight', 'base_model.embeddings.LayerNorm.bias', 'base_model.encoder.layer.18.output.LayerNorm.bias', 'base_model.encoder.layer.15.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.2.attention.self.key.bias', 'base_model.encoder.layer.9.attention.output.dense.bias', 'base_model.encoder.layer.9.attention.self.query.bias', 'base_model.encoder.layer.6.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.5.output.dense.bias', 'base_model.encoder.layer.8.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.12.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.17.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.11.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.12.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.17.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.2.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.12.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.22.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.3.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.14.attention.output.dense.weight', 'base_model.encoder.layer.6.attention.self.key.bias', 'base_model.encoder.layer.11.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.8.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.21.attention.output.dense.bias', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.14.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.9.intermediate.dense.weight', 'base_model.encoder.layer.13.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.1.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.6.attention.output.dense.bias', 'base_model.encoder.layer.15.attention.self.key.weight', 'base_model.encoder.layer.18.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.15.attention.self.value.bias', 'base_model.encoder.layer.15.attention.output.dense.weight', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.16.attention.self.key.weight', 'base_model.encoder.layer.1.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.3.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.14.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.16.attention.output.dense.bias', 'base_model.encoder.layer.18.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.5.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.19.attention.output.LayerNorm.bias', 'base_model.encoder.layer.20.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.13.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.5.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.9.output.LayerNorm.weight', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.9.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.14.attention.self.key.weight', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.7.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.10.attention.self.value.weight', 'base_model.encoder.layer.3.attention.output.LayerNorm.weight', 'base_model.encoder.layer.22.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.18.attention.output.LayerNorm.bias', 'base_model.encoder.layer.18.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.2.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.20.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.0.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.8.attention.output.LayerNorm.weight', 'base_model.encoder.layer.1.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.11.attention.self.key.bias', 'base_model.encoder.layer.22.output.dense.bias', 'base_model.encoder.layer.18.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.13.output.LayerNorm.weight', 'base_model.encoder.layer.13.attention.self.key.weight', 'base_model.encoder.layer.22.attention.output.dense.weight', 'base_model.encoder.layer.9.attention.output.dense.weight', 'base_model.encoder.layer.10.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.11.output.LayerNorm.weight', 'base_model.encoder.layer.19.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.16.attention.output.LayerNorm.weight', 'base_model.encoder.layer.22.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.19.attention.self.query.bias', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.1.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.11.attention.self.key.weight', 'base_model.encoder.layer.10.attention.self.value.bias', 'base_model.encoder.layer.9.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.13.intermediate.dense.weight', 'base_model.encoder.layer.0.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.11.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.13.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.2.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.22.output.LayerNorm.bias', 'base_model.encoder.layer.1.attention.self.query.bias', 'base_model.encoder.layer.3.attention.self.key.bias', 'base_model.encoder.layer.8.intermediate.dense.bias', 'base_model.encoder.layer.9.attention.output.LayerNorm.bias', 'base_model.encoder.layer.11.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.19.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.0.intermediate.dense.bias', 'base_model.encoder.layer.8.output.LayerNorm.bias', 'base_model.encoder.layer.3.output.LayerNorm.weight', 'base_model.encoder.layer.19.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.1.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.3.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.5.attention.self.key.bias', 'base_model.encoder.layer.11.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.22.attention.self.key.bias', 'base_model.encoder.layer.10.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.8.intermediate.dense.weight', 'base_model.encoder.layer.11.attention.output.dense.weight', 'base_model.encoder.layer.17.output.LayerNorm.weight', 'base_model.encoder.layer.20.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.3.attention.self.query.bias', 'base_model.encoder.layer.1.output.dense.weight', 'base_model.encoder.layer.2.attention.output.LayerNorm.weight', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.21.attention.self.value.weight', 'base_model.encoder.layer.4.intermediate.dense.weight', 'base_model.encoder.layer.22.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.23.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.11.attention.self.query.weight', 'base_model.encoder.layer.22.intermediate.dense.weight', 'base_model.encoder.layer.23.attention.output.LayerNorm.weight', 'base_model.encoder.layer.7.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.17.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.23.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.0.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.9.attention.self.value.bias', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.15.attention.self.value.weight', 'base_model.encoder.layer.18.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.21.output.dense.weight', 'base_model.encoder.layer.4.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.1.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.1.intermediate.dense.weight', 'base_model.encoder.layer.3.attention.self.value.weight', 'base_model.encoder.layer.7.intermediate.dense.bias', 'base_model.encoder.layer.18.intermediate.dense.weight', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.9.intermediate.dense.bias', 'base_model.encoder.layer.15.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.23.attention.self.key.bias', 'qa_outputs.bias', 'base_model.encoder.layer.22.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.15.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.5.attention.self.query.weight', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.5.intermediate.dense.bias', 'base_model.encoder.layer.8.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.8.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.7.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.14.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.3.attention.output.LayerNorm.bias']
- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of XLMRobertaModel were not initialized from the model checkpoint at /cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//squad/xlm-KG_LR3e-5_EPOCH2.0_maxlen384_batchsize4_gradacc4 and are newly initialized: ['encoder.layer.13.attention.self.query.bias', 'encoder.layer.11.attention.self.value.bias', 'encoder.layer.9.attention.self.query.bias', 'encoder.layer.16.output.dense.bias', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.12.intermediate.dense.weight', 'encoder.layer.18.attention.output.LayerNorm.bias', 'encoder.layer.17.intermediate.dense.bias', 'encoder.layer.16.attention.self.value.bias', 'encoder.layer.8.attention.self.key.bias', 'encoder.layer.20.attention.output.LayerNorm.bias', 'encoder.layer.10.attention.self.query.bias', 'encoder.layer.23.attention.output.dense.weight', 'encoder.layer.13.intermediate.dense.weight', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.17.attention.self.query.weight', 'encoder.layer.13.attention.self.value.weight', 'encoder.layer.23.attention.self.query.weight', 'encoder.layer.13.output.LayerNorm.bias', 'encoder.layer.17.output.dense.bias', 'encoder.layer.6.attention.self.query.weight', 'encoder.layer.2.attention.self.key.bias', 'encoder.layer.11.attention.output.dense.bias', 'encoder.layer.11.attention.output.LayerNorm.weight', 'encoder.layer.15.attention.self.key.bias', 'encoder.layer.8.attention.output.dense.weight', 'encoder.layer.18.attention.self.key.weight', 'encoder.layer.18.attention.self.query.bias', 'encoder.layer.8.output.LayerNorm.bias', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.12.output.LayerNorm.weight', 'encoder.layer.14.attention.output.LayerNorm.weight', 'encoder.layer.16.attention.self.key.bias', 'encoder.layer.0.attention.output.dense.bias', 'embeddings.token_type_embeddings.weight', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.16.attention.output.LayerNorm.bias', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.18.output.dense.bias', 'encoder.layer.13.attention.self.key.weight', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.8.attention.self.key.weight', 'encoder.layer.7.attention.self.key.bias', 'encoder.layer.21.attention.output.dense.bias', 'encoder.layer.15.attention.output.dense.bias', 'encoder.layer.10.output.dense.bias', 'encoder.layer.11.attention.output.dense.weight', 'encoder.layer.4.attention.output.LayerNorm.weight', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.13.attention.output.dense.bias', 'encoder.layer.1.attention.output.dense.bias', 'encoder.layer.3.attention.output.dense.weight', 'encoder.layer.6.attention.self.key.weight', 'encoder.layer.23.output.LayerNorm.bias', 'encoder.layer.20.attention.output.LayerNorm.weight', 'encoder.layer.12.attention.self.value.weight', 'encoder.layer.12.attention.self.key.weight', 'encoder.layer.15.attention.output.dense.weight', 'encoder.layer.14.attention.output.dense.weight', 'encoder.layer.7.attention.self.value.bias', 'encoder.layer.20.output.LayerNorm.weight', 'encoder.layer.9.attention.self.key.bias', 'encoder.layer.19.attention.self.key.bias', 'encoder.layer.3.attention.self.value.weight', 'encoder.layer.2.attention.self.value.bias', 'encoder.layer.10.attention.output.LayerNorm.bias', 'encoder.layer.22.attention.self.value.bias', 'encoder.layer.9.attention.output.dense.bias', 'encoder.layer.10.attention.self.key.bias', 'encoder.layer.17.output.LayerNorm.bias', 'encoder.layer.7.output.dense.weight', 'encoder.layer.20.intermediate.dense.bias', 'encoder.layer.18.attention.self.value.bias', 'encoder.layer.6.attention.self.value.weight', 'encoder.layer.21.attention.self.key.weight', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.23.attention.self.query.bias', 'encoder.layer.6.attention.self.query.bias', 'encoder.layer.14.attention.self.query.bias', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.4.attention.output.dense.weight', 'encoder.layer.20.attention.output.dense.bias', 'encoder.layer.5.attention.self.key.weight', 'encoder.layer.8.attention.self.query.weight', 'encoder.layer.3.output.dense.bias', 'encoder.layer.19.attention.self.key.weight', 'encoder.layer.2.attention.self.query.bias', 'encoder.layer.19.output.dense.weight', 'encoder.layer.22.output.dense.bias', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.23.attention.self.key.weight', 'encoder.layer.22.attention.output.dense.weight', 'encoder.layer.1.attention.self.key.bias', 'encoder.layer.18.output.LayerNorm.bias', 'encoder.layer.10.attention.self.value.weight', 'encoder.layer.2.attention.self.key.weight', 'encoder.layer.18.attention.output.dense.weight', 'encoder.layer.22.attention.output.LayerNorm.bias', 'encoder.layer.6.output.dense.weight', 'encoder.layer.2.attention.output.LayerNorm.bias', 'encoder.layer.9.attention.self.query.weight', 'encoder.layer.20.intermediate.dense.weight', 'encoder.layer.2.attention.output.LayerNorm.weight', 'encoder.layer.17.attention.output.LayerNorm.weight', 'encoder.layer.4.output.dense.bias', 'encoder.layer.19.attention.output.LayerNorm.weight', 'encoder.layer.15.output.dense.bias', 'encoder.layer.6.attention.output.dense.bias', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.13.attention.output.LayerNorm.weight', 'encoder.layer.17.output.LayerNorm.weight', 'encoder.layer.3.attention.self.query.bias', 'encoder.layer.17.attention.self.key.bias', 'encoder.layer.19.attention.self.value.weight', 'encoder.layer.20.output.dense.weight', 'encoder.layer.0.attention.output.LayerNorm.weight', 'encoder.layer.15.attention.output.LayerNorm.bias', 'encoder.layer.19.attention.self.query.weight', 'encoder.layer.4.attention.self.query.weight', 'encoder.layer.0.attention.self.query.weight', 'encoder.layer.18.intermediate.dense.bias', 'encoder.layer.0.attention.output.dense.weight', 'encoder.layer.5.attention.self.value.bias', 'encoder.layer.8.output.dense.bias', 'encoder.layer.13.output.LayerNorm.weight', 'encoder.layer.9.attention.self.value.bias', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.5.output.dense.weight', 'encoder.layer.23.attention.output.LayerNorm.bias', 'encoder.layer.9.attention.self.key.weight', 'encoder.layer.21.output.LayerNorm.weight', 'encoder.layer.1.attention.self.value.weight', 'encoder.layer.14.attention.self.value.weight', 'encoder.layer.6.output.dense.bias', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.17.output.dense.weight', 'encoder.layer.15.intermediate.dense.weight', 'encoder.layer.3.output.dense.weight', 'embeddings.LayerNorm.bias', 'encoder.layer.1.attention.self.query.weight', 'encoder.layer.8.attention.output.dense.bias', 'encoder.layer.13.output.dense.weight', 'encoder.layer.2.output.dense.weight', 'encoder.layer.7.output.LayerNorm.weight', 'encoder.layer.15.output.LayerNorm.weight', 'encoder.layer.8.attention.self.value.bias', 'encoder.layer.18.attention.self.key.bias', 'encoder.layer.8.output.dense.weight', 'encoder.layer.15.attention.self.query.weight', 'encoder.layer.2.attention.self.query.weight', 'encoder.layer.21.attention.self.value.bias', 'encoder.layer.17.attention.self.key.weight', 'encoder.layer.4.attention.self.query.bias', 'encoder.layer.23.intermediate.dense.bias', 'encoder.layer.1.attention.output.LayerNorm.weight', 'encoder.layer.3.attention.self.value.bias', 'encoder.layer.18.attention.self.query.weight', 'encoder.layer.21.attention.self.key.bias', 'encoder.layer.15.intermediate.dense.bias', 'embeddings.word_embeddings.weight', 'encoder.layer.15.attention.self.value.weight', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.2.attention.self.value.weight', 'encoder.layer.23.output.LayerNorm.weight', 'encoder.layer.7.attention.output.LayerNorm.bias', 'encoder.layer.7.intermediate.dense.bias', 'embeddings.position_embeddings.weight', 'encoder.layer.21.output.LayerNorm.bias', 'encoder.layer.18.attention.output.LayerNorm.weight', 'encoder.layer.19.attention.output.LayerNorm.bias', 'encoder.layer.9.attention.output.LayerNorm.weight', 'encoder.layer.20.attention.self.value.bias', 'encoder.layer.19.attention.output.dense.weight', 'encoder.layer.7.output.dense.bias', 'encoder.layer.16.attention.self.key.weight', 'embeddings.LayerNorm.weight', 'encoder.layer.19.output.dense.bias', 'encoder.layer.17.attention.output.dense.weight', 'encoder.layer.22.attention.output.LayerNorm.weight', 'encoder.layer.9.output.dense.weight', 'encoder.layer.15.attention.self.value.bias', 'encoder.layer.10.intermediate.dense.weight', 'encoder.layer.12.attention.self.key.bias', 'encoder.layer.8.output.LayerNorm.weight', 'encoder.layer.22.attention.self.value.weight', 'encoder.layer.12.attention.output.LayerNorm.bias', 'encoder.layer.22.output.dense.weight', 'encoder.layer.21.attention.output.dense.weight', 'encoder.layer.4.attention.output.LayerNorm.bias', 'encoder.layer.12.attention.output.dense.weight', 'encoder.layer.6.attention.self.value.bias', 'encoder.layer.10.output.LayerNorm.bias', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.23.attention.self.key.bias', 'encoder.layer.23.output.dense.bias', 'encoder.layer.12.attention.self.query.weight', 'encoder.layer.3.attention.self.key.bias', 'encoder.layer.9.attention.self.value.weight', 'encoder.layer.16.attention.self.query.weight', 'encoder.layer.19.intermediate.dense.bias', 'pooler.dense.bias', 'encoder.layer.21.attention.output.LayerNorm.bias', 'encoder.layer.15.attention.self.query.bias', 'encoder.layer.21.attention.self.query.bias', 'encoder.layer.13.attention.self.value.bias', 'encoder.layer.8.attention.output.LayerNorm.bias', 'encoder.layer.8.attention.output.LayerNorm.weight', 'encoder.layer.17.intermediate.dense.weight', 'encoder.layer.14.output.LayerNorm.bias', 'encoder.layer.8.attention.self.query.bias', 'encoder.layer.12.output.LayerNorm.bias', 'encoder.layer.6.attention.output.LayerNorm.weight', 'encoder.layer.14.output.LayerNorm.weight', 'encoder.layer.23.attention.self.value.weight', 'encoder.layer.16.output.LayerNorm.bias', 'encoder.layer.20.attention.self.key.bias', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.20.output.dense.bias', 'encoder.layer.17.attention.self.value.weight', 'encoder.layer.15.attention.self.key.weight', 'encoder.layer.21.attention.self.value.weight', 'encoder.layer.11.attention.self.key.bias', 'encoder.layer.4.attention.self.value.bias', 'encoder.layer.8.attention.self.value.weight', 'encoder.layer.10.output.dense.weight', 'encoder.layer.4.attention.output.dense.bias', 'encoder.layer.5.attention.self.query.weight', 'encoder.layer.22.output.LayerNorm.weight', 'encoder.layer.17.attention.self.value.bias', 'encoder.layer.9.output.LayerNorm.weight', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.1.attention.self.key.weight', 'encoder.layer.22.attention.output.dense.bias', 'encoder.layer.11.output.dense.weight', 'encoder.layer.14.attention.self.value.bias', 'encoder.layer.7.attention.output.dense.bias', 'encoder.layer.19.attention.output.dense.bias', 'encoder.layer.4.attention.self.key.weight', 'encoder.layer.0.attention.self.query.bias', 'encoder.layer.0.attention.self.value.bias', 'encoder.layer.15.output.dense.weight', 'encoder.layer.10.output.LayerNorm.weight', 'encoder.layer.3.attention.self.key.weight', 'encoder.layer.5.attention.self.query.bias', 'encoder.layer.17.attention.self.query.bias', 'encoder.layer.21.intermediate.dense.bias', 'encoder.layer.7.attention.output.dense.weight', 'encoder.layer.16.attention.output.dense.weight', 'encoder.layer.7.attention.self.value.weight', 'encoder.layer.15.attention.output.LayerNorm.weight', 'encoder.layer.1.attention.output.dense.weight', 'encoder.layer.19.output.LayerNorm.weight', 'encoder.layer.19.intermediate.dense.weight', 'encoder.layer.21.attention.self.query.weight', 'encoder.layer.11.attention.self.query.weight', 'encoder.layer.10.attention.self.query.weight', 'encoder.layer.6.attention.output.dense.weight', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.14.attention.output.dense.bias', 'encoder.layer.3.attention.output.dense.bias', 'encoder.layer.11.output.dense.bias', 'encoder.layer.14.output.dense.bias', 'encoder.layer.21.intermediate.dense.weight', 'encoder.layer.16.intermediate.dense.bias', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.16.output.LayerNorm.weight', 'encoder.layer.14.attention.self.key.weight', 'encoder.layer.13.attention.self.key.bias', 'encoder.layer.11.attention.self.key.weight', 'encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.layer.13.attention.output.LayerNorm.bias', 'encoder.layer.12.output.dense.weight', 'encoder.layer.9.attention.output.dense.weight', 'encoder.layer.10.attention.self.key.weight', 'encoder.layer.18.attention.self.value.weight', 'encoder.layer.17.attention.output.LayerNorm.bias', 'encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.0.output.dense.bias', 'encoder.layer.1.attention.self.query.bias', 'encoder.layer.0.attention.self.key.weight', 'encoder.layer.2.attention.output.dense.bias', 'encoder.layer.7.attention.self.query.bias', 'encoder.layer.10.attention.output.LayerNorm.weight', 'encoder.layer.22.attention.self.key.weight', 'encoder.layer.23.attention.output.LayerNorm.weight', 'encoder.layer.12.attention.self.query.bias', 'encoder.layer.20.attention.self.query.bias', 'encoder.layer.16.attention.self.query.bias', 'encoder.layer.15.output.LayerNorm.bias', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.1.attention.self.value.bias', 'encoder.layer.5.attention.self.value.weight', 'encoder.layer.22.intermediate.dense.weight', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.5.output.dense.bias', 'encoder.layer.0.output.dense.weight', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.11.output.LayerNorm.weight', 'encoder.layer.18.intermediate.dense.weight', 'encoder.layer.1.output.dense.weight', 'encoder.layer.3.attention.self.query.weight', 'encoder.layer.13.output.dense.bias', 'encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.layer.4.attention.self.key.bias', 'encoder.layer.13.attention.output.dense.weight', 'encoder.layer.0.attention.self.value.weight', 'encoder.layer.13.intermediate.dense.bias', 'encoder.layer.9.output.LayerNorm.bias', 'encoder.layer.13.attention.self.query.weight', 'encoder.layer.22.attention.self.key.bias', 'encoder.layer.6.attention.output.LayerNorm.bias', 'encoder.layer.5.attention.output.dense.weight', 'encoder.layer.19.output.LayerNorm.bias', 'encoder.layer.7.attention.self.query.weight', 'encoder.layer.7.attention.self.key.weight', 'pooler.dense.weight', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.23.attention.output.dense.bias', 'encoder.layer.23.attention.self.value.bias', 'encoder.layer.16.attention.self.value.weight', 'encoder.layer.6.attention.self.key.bias', 'encoder.layer.20.attention.self.query.weight', 'encoder.layer.7.output.LayerNorm.bias', 'encoder.layer.18.attention.output.dense.bias', 'encoder.layer.0.attention.self.key.bias', 'encoder.layer.22.attention.self.query.weight', 'encoder.layer.20.output.LayerNorm.bias', 'encoder.layer.12.attention.self.value.bias', 'encoder.layer.16.intermediate.dense.weight', 'encoder.layer.20.attention.self.value.weight', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.23.intermediate.dense.weight', 'encoder.layer.18.output.dense.weight', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.5.attention.output.LayerNorm.weight', 'encoder.layer.5.output.LayerNorm.bias', 'encoder.layer.9.attention.output.LayerNorm.bias', 'encoder.layer.14.attention.self.key.bias', 'encoder.layer.14.attention.output.LayerNorm.bias', 'encoder.layer.9.output.dense.bias', 'encoder.layer.21.attention.output.LayerNorm.weight', 'encoder.layer.23.output.dense.weight', 'encoder.layer.12.intermediate.dense.bias', 'encoder.layer.20.attention.output.dense.weight', 'encoder.layer.21.output.dense.bias', 'encoder.layer.16.attention.output.LayerNorm.weight', 'encoder.layer.22.output.LayerNorm.bias', 'encoder.layer.14.output.dense.weight', 'encoder.layer.20.attention.self.key.weight', 'encoder.layer.21.output.dense.weight', 'encoder.layer.14.intermediate.dense.weight', 'encoder.layer.14.attention.self.query.weight', 'encoder.layer.11.output.LayerNorm.bias', 'encoder.layer.11.attention.self.value.weight', 'encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.7.attention.output.LayerNorm.weight', 'encoder.layer.16.attention.output.dense.bias', 'encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.18.output.LayerNorm.weight', 'encoder.layer.6.output.LayerNorm.bias', 'encoder.layer.16.output.dense.weight', 'encoder.layer.5.attention.self.key.bias', 'encoder.layer.1.output.dense.bias', 'encoder.layer.10.attention.output.dense.weight', 'encoder.layer.10.attention.self.value.bias', 'encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.layer.5.attention.output.dense.bias', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.12.attention.output.dense.bias', 'encoder.layer.22.intermediate.dense.bias', 'encoder.layer.4.output.dense.weight', 'encoder.layer.2.output.dense.bias', 'encoder.layer.14.intermediate.dense.bias', 'encoder.layer.10.attention.output.dense.bias', 'encoder.layer.4.attention.self.value.weight', 'encoder.layer.11.attention.self.query.bias', 'encoder.layer.2.attention.output.dense.weight', 'encoder.layer.12.attention.output.LayerNorm.weight', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.12.output.dense.bias', 'encoder.layer.17.attention.output.dense.bias', 'encoder.layer.19.attention.self.query.bias', 'encoder.layer.22.attention.self.query.bias', 'encoder.layer.19.attention.self.value.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Overwriting existing adapter 'ep'.
Overwriting existing adapter 'tp'.
Overwriting existing adapter 'es'.
Overwriting existing adapter 'ts'.
Overwriting existing adapter fusion module 'ep,tp,es,ts'
05/09/2022 09:11:29 - INFO - __main__ -   Creating features from dataset file at .
/cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//squad/xlm-KG_LR3e-5_EPOCH2.0_maxlen384_batchsize4_gradacc4
XLMConfig {
  "architectures": [
    "XLMRobertaForMaskedLM"
  ],
  "asm": false,
  "attention_dropout": 0.1,
  "attention_probs_dropout_prob": 0.1,
  "bos_index": 0,
  "bos_token_id": 0,
  "causal": false,
  "dropout": 0.1,
  "emb_dim": 1024,
  "embed_init_std": 0.02209708691207961,
  "end_n_top": 5,
  "eos_index": 1,
  "eos_token_id": 2,
  "gelu_activation": true,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "init_std": 0.02,
  "initializer_range": 0.02,
  "intermediate_size": 4096,
  "is_encoder": true,
  "lang_id": 0,
  "layer_norm_eps": 1e-05,
  "mask_index": 5,
  "mask_token_id": 0,
  "max_position_embeddings": 514,
  "model_type": "xlm",
  "n_heads": 16,
  "n_langs": 1,
  "n_layers": 24,
  "output_past": true,
  "pad_index": 2,
  "pad_token_id": 1,
  "sinusoidal_embeddings": false,
  "start_n_top": 5,
  "summary_activation": null,
  "summary_first_dropout": 0.1,
  "summary_proj_to_labels": true,
  "summary_type": "first",
  "summary_use_proj": true,
  "transformers_version": "4.17.0",
  "type_vocab_size": 1,
  "unk_index": 3,
  "use_lang_emb": false,
  "vocab_size": 250002
}

  0%|          | 0/48 [00:00<?, ?it/s] 19%|█▉        | 9/48 [00:00<00:00, 83.46it/s] 38%|███▊      | 18/48 [00:00<00:00, 59.72it/s] 54%|█████▍    | 26/48 [00:00<00:00, 66.50it/s] 71%|███████   | 34/48 [00:00<00:00, 68.02it/s] 90%|████████▉ | 43/48 [00:00<00:00, 73.72it/s]100%|██████████| 48/48 [00:00<00:00, 72.08it/s]
convert squad examples to features:   0%|          | 0/1190 [00:00<?, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.
convert squad examples to features:   0%|          | 1/1190 [00:00<05:48,  3.41it/s]convert squad examples to features:   5%|▌         | 65/1190 [00:00<00:07, 145.55it/s]convert squad examples to features:   8%|▊         | 97/1190 [00:00<00:06, 166.41it/s]convert squad examples to features:  11%|█         | 129/1190 [00:00<00:05, 179.82it/s]convert squad examples to features:  14%|█▎        | 161/1190 [00:00<00:05, 187.70it/s]convert squad examples to features:  16%|█▌        | 193/1190 [00:01<00:04, 213.81it/s]convert squad examples to features:  22%|██▏       | 257/1190 [00:01<00:04, 197.75it/s]convert squad examples to features:  24%|██▍       | 289/1190 [00:01<00:04, 195.22it/s]convert squad examples to features:  27%|██▋       | 321/1190 [00:01<00:04, 178.52it/s]convert squad examples to features:  30%|██▉       | 353/1190 [00:01<00:04, 203.46it/s]convert squad examples to features:  32%|███▏      | 385/1190 [00:02<00:08, 99.52it/s] convert squad examples to features:  35%|███▌      | 417/1190 [00:02<00:07, 110.01it/s]convert squad examples to features:  38%|███▊      | 449/1190 [00:03<00:06, 116.27it/s]convert squad examples to features:  40%|████      | 481/1190 [00:03<00:05, 120.71it/s]convert squad examples to features:  43%|████▎     | 513/1190 [00:03<00:05, 129.56it/s]convert squad examples to features:  46%|████▌     | 545/1190 [00:03<00:05, 127.30it/s]convert squad examples to features:  48%|████▊     | 577/1190 [00:04<00:04, 136.86it/s]convert squad examples to features:  51%|█████     | 609/1190 [00:04<00:04, 134.30it/s]convert squad examples to features:  54%|█████▍    | 641/1190 [00:04<00:04, 135.76it/s]convert squad examples to features:  57%|█████▋    | 673/1190 [00:04<00:03, 129.88it/s]convert squad examples to features:  59%|█████▉    | 705/1190 [00:04<00:03, 135.44it/s]convert squad examples to features:  62%|██████▏   | 737/1190 [00:05<00:02, 154.70it/s]convert squad examples to features:  65%|██████▍   | 769/1190 [00:05<00:02, 154.89it/s]convert squad examples to features:  67%|██████▋   | 801/1190 [00:05<00:02, 164.29it/s]convert squad examples to features:  70%|███████   | 833/1190 [00:05<00:02, 151.05it/s]convert squad examples to features:  73%|███████▎  | 865/1190 [00:05<00:02, 154.33it/s]convert squad examples to features:  75%|███████▌  | 897/1190 [00:06<00:01, 158.42it/s]convert squad examples to features:  78%|███████▊  | 929/1190 [00:06<00:01, 151.83it/s]convert squad examples to features:  83%|████████▎ | 993/1190 [00:06<00:01, 183.92it/s]convert squad examples to features:  86%|████████▌ | 1025/1190 [00:06<00:00, 182.55it/s]convert squad examples to features:  89%|████████▉ | 1057/1190 [00:06<00:00, 182.58it/s]convert squad examples to features:  92%|█████████▏| 1089/1190 [00:07<00:00, 186.28it/s]convert squad examples to features:  94%|█████████▍| 1121/1190 [00:07<00:00, 175.13it/s]convert squad examples to features:  97%|█████████▋| 1153/1190 [00:07<00:00, 163.60it/s]convert squad examples to features: 100%|██████████| 1190/1190 [00:07<00:00, 156.44it/s]
add example index and unique id:   0%|          | 0/1190 [00:00<?, ?it/s]add example index and unique id: 100%|██████████| 1190/1190 [00:00<00:00, 641133.17it/s]
05/09/2022 09:11:37 - INFO - __main__ -   Saving features into cached file ./cached_xquad.ar.json_xlm-KG_LR3e-5_EPOCH2.0_maxlen384_batchsize4_gradacc4_384_ar
05/09/2022 09:11:39 - INFO - __main__ -   ***** Running evaluation  *****
05/09/2022 09:11:39 - INFO - __main__ -     Num examples = 1318
05/09/2022 09:11:39 - INFO - __main__ -     Batch size = 8
Evaluating:   0%|          | 0/165 [00:00<?, ?it/s]Evaluating:   1%|          | 1/165 [00:00<02:40,  1.02it/s]Evaluating:   1%|          | 2/165 [00:01<01:39,  1.65it/s]Evaluating:   2%|▏         | 3/165 [00:01<01:19,  2.04it/s]Evaluating:   2%|▏         | 4/165 [00:02<01:09,  2.31it/s]Evaluating:   3%|▎         | 5/165 [00:02<01:04,  2.50it/s]Evaluating:   4%|▎         | 6/165 [00:02<01:00,  2.63it/s]Evaluating:   4%|▍         | 7/165 [00:03<00:58,  2.72it/s]Evaluating:   5%|▍         | 8/165 [00:03<00:56,  2.78it/s]Evaluating:   5%|▌         | 9/165 [00:03<00:55,  2.82it/s]Evaluating:   6%|▌         | 10/165 [00:04<00:54,  2.83it/s]Evaluating:   7%|▋         | 11/165 [00:04<00:53,  2.86it/s]Evaluating:   7%|▋         | 12/165 [00:04<00:53,  2.87it/s]Evaluating:   8%|▊         | 13/165 [00:05<00:52,  2.89it/s]Evaluating:   8%|▊         | 14/165 [00:05<00:52,  2.89it/s]Evaluating:   9%|▉         | 15/165 [00:05<00:51,  2.90it/s]Evaluating:  10%|▉         | 16/165 [00:06<00:51,  2.90it/s]Evaluating:  10%|█         | 17/165 [00:06<00:51,  2.90it/s]Evaluating:  11%|█         | 18/165 [00:06<00:50,  2.89it/s]Evaluating:  12%|█▏        | 19/165 [00:07<00:50,  2.90it/s]Evaluating:  12%|█▏        | 20/165 [00:07<00:50,  2.89it/s]Evaluating:  13%|█▎        | 21/165 [00:07<00:49,  2.90it/s]Evaluating:  13%|█▎        | 22/165 [00:08<00:49,  2.91it/s]Evaluating:  14%|█▍        | 23/165 [00:08<00:48,  2.92it/s]Evaluating:  15%|█▍        | 24/165 [00:08<00:48,  2.92it/s]Evaluating:  15%|█▌        | 25/165 [00:09<00:47,  2.92it/s]Evaluating:  16%|█▌        | 26/165 [00:09<00:47,  2.92it/s]Evaluating:  16%|█▋        | 27/165 [00:09<00:47,  2.92it/s]Evaluating:  17%|█▋        | 28/165 [00:10<00:46,  2.92it/s]Evaluating:  18%|█▊        | 29/165 [00:10<00:46,  2.91it/s]Evaluating:  18%|█▊        | 30/165 [00:10<00:46,  2.91it/s]Evaluating:  19%|█▉        | 31/165 [00:11<00:46,  2.91it/s]Evaluating:  19%|█▉        | 32/165 [00:11<00:45,  2.91it/s]Evaluating:  20%|██        | 33/165 [00:11<00:45,  2.91it/s]Evaluating:  21%|██        | 34/165 [00:12<00:44,  2.91it/s]Evaluating:  21%|██        | 35/165 [00:12<00:44,  2.91it/s]Evaluating:  22%|██▏       | 36/165 [00:13<00:44,  2.91it/s]Evaluating:  22%|██▏       | 37/165 [00:13<00:44,  2.91it/s]Evaluating:  23%|██▎       | 38/165 [00:13<00:43,  2.91it/s]Evaluating:  24%|██▎       | 39/165 [00:14<00:43,  2.92it/s]Evaluating:  24%|██▍       | 40/165 [00:14<00:42,  2.91it/s]Evaluating:  25%|██▍       | 41/165 [00:14<00:42,  2.91it/s]Evaluating:  25%|██▌       | 42/165 [00:15<00:42,  2.91it/s]Evaluating:  26%|██▌       | 43/165 [00:15<00:41,  2.91it/s]Evaluating:  27%|██▋       | 44/165 [00:15<00:41,  2.90it/s]Evaluating:  27%|██▋       | 45/165 [00:16<00:41,  2.89it/s]Evaluating:  28%|██▊       | 46/165 [00:16<00:40,  2.91it/s]Evaluating:  28%|██▊       | 47/165 [00:16<00:40,  2.92it/s]Evaluating:  29%|██▉       | 48/165 [00:17<00:40,  2.92it/s]Evaluating:  30%|██▉       | 49/165 [00:17<00:39,  2.92it/s]Evaluating:  30%|███       | 50/165 [00:17<00:39,  2.92it/s]Evaluating:  31%|███       | 51/165 [00:18<00:39,  2.91it/s]Evaluating:  32%|███▏      | 52/165 [00:18<00:38,  2.90it/s]Evaluating:  32%|███▏      | 53/165 [00:18<00:38,  2.90it/s]Evaluating:  33%|███▎      | 54/165 [00:19<00:38,  2.89it/s]Evaluating:  33%|███▎      | 55/165 [00:19<00:38,  2.87it/s]Evaluating:  34%|███▍      | 56/165 [00:19<00:37,  2.87it/s]Evaluating:  35%|███▍      | 57/165 [00:20<00:37,  2.88it/s]Evaluating:  35%|███▌      | 58/165 [00:20<00:37,  2.87it/s]Evaluating:  36%|███▌      | 59/165 [00:20<00:36,  2.87it/s]Evaluating:  36%|███▋      | 60/165 [00:21<00:36,  2.87it/s]Evaluating:  37%|███▋      | 61/165 [00:21<00:36,  2.87it/s]Evaluating:  38%|███▊      | 62/165 [00:22<00:35,  2.88it/s]Evaluating:  38%|███▊      | 63/165 [00:22<00:35,  2.88it/s]Evaluating:  39%|███▉      | 64/165 [00:22<00:35,  2.88it/s]Evaluating:  39%|███▉      | 65/165 [00:23<00:34,  2.88it/s]Evaluating:  40%|████      | 66/165 [00:23<00:34,  2.88it/s]Evaluating:  41%|████      | 67/165 [00:23<00:33,  2.90it/s]Evaluating:  41%|████      | 68/165 [00:24<00:33,  2.90it/s]Evaluating:  42%|████▏     | 69/165 [00:24<00:33,  2.90it/s]Evaluating:  42%|████▏     | 70/165 [00:24<00:32,  2.89it/s]Evaluating:  43%|████▎     | 71/165 [00:25<00:32,  2.89it/s]Evaluating:  44%|████▎     | 72/165 [00:25<00:32,  2.88it/s]Evaluating:  44%|████▍     | 73/165 [00:25<00:31,  2.89it/s]Evaluating:  45%|████▍     | 74/165 [00:26<00:31,  2.89it/s]Evaluating:  45%|████▌     | 75/165 [00:26<00:31,  2.89it/s]Evaluating:  46%|████▌     | 76/165 [00:26<00:30,  2.89it/s]Evaluating:  47%|████▋     | 77/165 [00:27<00:30,  2.89it/s]Evaluating:  47%|████▋     | 78/165 [00:27<00:30,  2.90it/s]Evaluating:  48%|████▊     | 79/165 [00:27<00:29,  2.90it/s]Evaluating:  48%|████▊     | 80/165 [00:28<00:29,  2.89it/s]Evaluating:  49%|████▉     | 81/165 [00:28<00:29,  2.89it/s]Evaluating:  50%|████▉     | 82/165 [00:28<00:28,  2.90it/s]Evaluating:  50%|█████     | 83/165 [00:29<00:28,  2.90it/s]Evaluating:  51%|█████     | 84/165 [00:29<00:27,  2.91it/s]Evaluating:  52%|█████▏    | 85/165 [00:29<00:27,  2.90it/s]Evaluating:  52%|█████▏    | 86/165 [00:30<00:27,  2.91it/s]Evaluating:  53%|█████▎    | 87/165 [00:30<00:26,  2.91it/s]Evaluating:  53%|█████▎    | 88/165 [00:30<00:26,  2.91it/s]Evaluating:  54%|█████▍    | 89/165 [00:31<00:26,  2.91it/s]Evaluating:  55%|█████▍    | 90/165 [00:31<00:25,  2.92it/s]Evaluating:  55%|█████▌    | 91/165 [00:32<00:25,  2.91it/s]Evaluating:  56%|█████▌    | 92/165 [00:32<00:25,  2.91it/s]Evaluating:  56%|█████▋    | 93/165 [00:32<00:24,  2.90it/s]Evaluating:  57%|█████▋    | 94/165 [00:33<00:24,  2.89it/s]Evaluating:  58%|█████▊    | 95/165 [00:33<00:24,  2.90it/s]Evaluating:  58%|█████▊    | 96/165 [00:33<00:23,  2.91it/s]Evaluating:  59%|█████▉    | 97/165 [00:34<00:23,  2.91it/s]Evaluating:  59%|█████▉    | 98/165 [00:34<00:23,  2.90it/s]Evaluating:  60%|██████    | 99/165 [00:34<00:22,  2.90it/s]Evaluating:  61%|██████    | 100/165 [00:35<00:22,  2.90it/s]Evaluating:  61%|██████    | 101/165 [00:35<00:22,  2.89it/s]Evaluating:  62%|██████▏   | 102/165 [00:35<00:21,  2.90it/s]Evaluating:  62%|██████▏   | 103/165 [00:36<00:21,  2.89it/s]Evaluating:  63%|██████▎   | 104/165 [00:36<00:21,  2.90it/s]Evaluating:  64%|██████▎   | 105/165 [00:36<00:20,  2.90it/s]Evaluating:  64%|██████▍   | 106/165 [00:37<00:20,  2.90it/s]Evaluating:  65%|██████▍   | 107/165 [00:37<00:19,  2.91it/s]Evaluating:  65%|██████▌   | 108/165 [00:37<00:19,  2.91it/s]Evaluating:  66%|██████▌   | 109/165 [00:38<00:19,  2.91it/s]Evaluating:  67%|██████▋   | 110/165 [00:38<00:18,  2.91it/s]Evaluating:  67%|██████▋   | 111/165 [00:38<00:18,  2.91it/s]Evaluating:  68%|██████▊   | 112/165 [00:39<00:18,  2.92it/s]Evaluating:  68%|██████▊   | 113/165 [00:39<00:17,  2.92it/s]Evaluating:  69%|██████▉   | 114/165 [00:39<00:17,  2.92it/s]Evaluating:  70%|██████▉   | 115/165 [00:40<00:17,  2.92it/s]Evaluating:  70%|███████   | 116/165 [00:40<00:16,  2.92it/s]Evaluating:  71%|███████   | 117/165 [00:40<00:16,  2.91it/s]Evaluating:  72%|███████▏  | 118/165 [00:41<00:16,  2.91it/s]Evaluating:  72%|███████▏  | 119/165 [00:41<00:15,  2.90it/s]Evaluating:  73%|███████▎  | 120/165 [00:41<00:15,  2.89it/s]Evaluating:  73%|███████▎  | 121/165 [00:42<00:15,  2.89it/s]Evaluating:  74%|███████▍  | 122/165 [00:42<00:14,  2.89it/s]Evaluating:  75%|███████▍  | 123/165 [00:43<00:14,  2.90it/s]Evaluating:  75%|███████▌  | 124/165 [00:43<00:14,  2.90it/s]Evaluating:  76%|███████▌  | 125/165 [00:43<00:13,  2.90it/s]Evaluating:  76%|███████▋  | 126/165 [00:44<00:13,  2.90it/s]Evaluating:  77%|███████▋  | 127/165 [00:44<00:13,  2.91it/s]Evaluating:  78%|███████▊  | 128/165 [00:44<00:12,  2.89it/s]Evaluating:  78%|███████▊  | 129/165 [00:45<00:12,  2.90it/s]Evaluating:  79%|███████▉  | 130/165 [00:45<00:12,  2.82it/s]Evaluating:  79%|███████▉  | 131/165 [00:45<00:11,  2.84it/s]Evaluating:  80%|████████  | 132/165 [00:46<00:11,  2.85it/s]Evaluating:  81%|████████  | 133/165 [00:46<00:11,  2.86it/s]Evaluating:  81%|████████  | 134/165 [00:46<00:10,  2.87it/s]Evaluating:  82%|████████▏ | 135/165 [00:47<00:10,  2.87it/s]Evaluating:  82%|████████▏ | 136/165 [00:47<00:10,  2.87it/s]Evaluating:  83%|████████▎ | 137/165 [00:47<00:09,  2.88it/s]Evaluating:  84%|████████▎ | 138/165 [00:48<00:09,  2.90it/s]Evaluating:  84%|████████▍ | 139/165 [00:48<00:08,  2.90it/s]Evaluating:  85%|████████▍ | 140/165 [00:48<00:08,  2.91it/s]Evaluating:  85%|████████▌ | 141/165 [00:49<00:08,  2.91it/s]Evaluating:  86%|████████▌ | 142/165 [00:49<00:07,  2.91it/s]Evaluating:  87%|████████▋ | 143/165 [00:49<00:07,  2.89it/s]Evaluating:  87%|████████▋ | 144/165 [00:50<00:07,  2.90it/s]Evaluating:  88%|████████▊ | 145/165 [00:50<00:06,  2.90it/s]Evaluating:  88%|████████▊ | 146/165 [00:50<00:06,  2.90it/s]Evaluating:  89%|████████▉ | 147/165 [00:51<00:06,  2.90it/s]Evaluating:  90%|████████▉ | 148/165 [00:51<00:05,  2.90it/s]Evaluating:  90%|█████████ | 149/165 [00:52<00:05,  2.90it/s]Evaluating:  91%|█████████ | 150/165 [00:52<00:05,  2.91it/s]Evaluating:  92%|█████████▏| 151/165 [00:52<00:04,  2.91it/s]Evaluating:  92%|█████████▏| 152/165 [00:53<00:04,  2.91it/s]Evaluating:  93%|█████████▎| 153/165 [00:53<00:04,  2.91it/s]Evaluating:  93%|█████████▎| 154/165 [00:53<00:03,  2.91it/s]Evaluating:  94%|█████████▍| 155/165 [00:54<00:03,  2.91it/s]Evaluating:  95%|█████████▍| 156/165 [00:54<00:03,  2.91it/s]Evaluating:  95%|█████████▌| 157/165 [00:54<00:02,  2.91it/s]Evaluating:  96%|█████████▌| 158/165 [00:55<00:02,  2.91it/s]Evaluating:  96%|█████████▋| 159/165 [00:55<00:02,  2.92it/s]Evaluating:  97%|█████████▋| 160/165 [00:55<00:01,  2.92it/s]Evaluating:  98%|█████████▊| 161/165 [00:56<00:01,  2.92it/s]Evaluating:  98%|█████████▊| 162/165 [00:56<00:01,  2.92it/s]Evaluating:  99%|█████████▉| 163/165 [00:56<00:00,  2.91it/s]Evaluating:  99%|█████████▉| 164/165 [00:57<00:00,  2.90it/s]Evaluating: 100%|██████████| 165/165 [00:57<00:00,  3.10it/s]Evaluating: 100%|██████████| 165/165 [00:57<00:00,  2.87it/s]
05/09/2022 09:12:36 - INFO - __main__ -     Evaluation done in total 57.453010 secs (0.043591 sec per example)
05/09/2022 09:12:42 - INFO - __main__ -   Results: {'exact': 56.890756302521005, 'f1': 73.99907257379327, 'total': 1190, 'HasAns_exact': 56.890756302521005, 'HasAns_f1': 73.99907257379327, 'HasAns_total': 1190, 'best_exact': 56.890756302521005, 'best_exact_thresh': 0.0, 'best_f1': 73.99907257379327, 'best_f1_thresh': 0.0}
  vi 
2022-05-09 09:12:46.339718: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0
05/09/2022 09:12:50 - WARNING - __main__ -   Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, 16-bits training: False
You are using a model of type xlm-roberta to instantiate a model of type xlm. This is not supported for all configurations of models and can yield errors.
Some weights of the model checkpoint at /cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//squad/xlm-KG_LR3e-5_EPOCH2.0_maxlen384_batchsize4_gradacc4 were not used when initializing XLMRobertaModel: ['base_model.encoder.layer.14.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.13.attention.self.query.weight', 'base_model.encoder.layer.7.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.3.attention.output.dense.weight', 'base_model.encoder.layer.14.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.10.attention.self.key.bias', 'base_model.encoder.layer.18.output.adapters.es.adapter_up.bias', 'base_model.pooler.dense.bias', 'base_model.encoder.layer.5.attention.self.key.weight', 'base_model.encoder.layer.2.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.20.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.4.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.17.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.10.attention.output.LayerNorm.weight', 'base_model.encoder.layer.4.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.20.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.22.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.7.attention.output.LayerNorm.bias', 'base_model.encoder.layer.2.intermediate.dense.weight', 'base_model.encoder.layer.22.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.15.attention.self.key.weight', 'base_model.encoder.layer.8.attention.output.LayerNorm.bias', 'base_model.encoder.layer.10.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.6.attention.self.query.weight', 'base_model.encoder.layer.6.output.dense.bias', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.18.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.19.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.22.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.8.attention.self.value.weight', 'base_model.encoder.layer.9.output.dense.bias', 'base_model.encoder.layer.4.attention.self.value.weight', 'base_model.encoder.layer.15.attention.output.dense.weight', 'base_model.encoder.layer.17.output.dense.bias', 'base_model.encoder.layer.12.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.23.attention.self.value.weight', 'base_model.encoder.layer.8.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.14.output.dense.bias', 'base_model.encoder.layer.6.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.22.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.4.attention.output.LayerNorm.weight', 'base_model.encoder.layer.11.intermediate.dense.bias', 'base_model.encoder.layer.11.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.0.output.dense.weight', 'base_model.encoder.layer.17.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.23.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.9.attention.output.dense.weight', 'base_model.encoder.layer.7.attention.output.dense.weight', 'base_model.encoder.layer.9.attention.self.key.bias', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.1.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.19.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.5.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.9.output.dense.weight', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.20.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.23.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.18.attention.output.LayerNorm.bias', 'base_model.encoder.layer.7.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.0.attention.self.key.weight', 'base_model.encoder.layer.14.attention.output.LayerNorm.bias', 'base_model.encoder.layer.21.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.12.output.dense.weight', 'base_model.encoder.layer.5.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.15.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.23.attention.output.dense.bias', 'base_model.encoder.layer.5.attention.self.value.weight', 'base_model.encoder.layer.5.output.dense.bias', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.12.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.8.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.12.output.LayerNorm.weight', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.11.attention.self.key.weight', 'base_model.encoder.layer.6.attention.self.key.weight', 'base_model.encoder.layer.3.output.adapters.ep.adapter_down.0.bias', 'base_model.embeddings.LayerNorm.bias', 'base_model.encoder.layer.10.output.LayerNorm.bias', 'base_model.encoder.layer.1.intermediate.dense.weight', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.2.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.8.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.17.attention.output.dense.weight', 'base_model.encoder.layer.10.attention.self.query.bias', 'base_model.encoder.layer.14.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.9.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.15.output.LayerNorm.bias', 'base_model.encoder.layer.19.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.2.output.dense.weight', 'base_model.embeddings.LayerNorm.weight', 'base_model.encoder.layer.2.attention.self.key.weight', 'base_model.encoder.layer.7.attention.self.query.bias', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.21.attention.output.LayerNorm.bias', 'base_model.encoder.layer.8.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.9.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.6.intermediate.dense.weight', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.1.attention.self.value.weight', 'base_model.encoder.layer.13.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.5.attention.output.dense.bias', 'base_model.encoder.layer.22.attention.output.dense.bias', 'base_model.encoder.layer.15.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.3.attention.self.query.bias', 'base_model.encoder.layer.23.output.LayerNorm.weight', 'base_model.encoder.layer.10.intermediate.dense.bias', 'base_model.encoder.layer.2.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.22.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.12.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.14.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.0.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.23.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.6.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.8.intermediate.dense.bias', 'base_model.encoder.layer.17.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.14.output.dense.weight', 'base_model.encoder.layer.9.attention.self.query.bias', 'base_model.encoder.layer.1.attention.output.LayerNorm.bias', 'base_model.encoder.layer.12.attention.self.query.weight', 'base_model.encoder.layer.1.attention.self.query.bias', 'base_model.encoder.layer.2.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.20.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.13.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.21.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.20.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.21.attention.self.query.weight', 'base_model.encoder.layer.2.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.14.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.18.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.6.output.dense.weight', 'base_model.encoder.layer.15.intermediate.dense.weight', 'base_model.encoder.layer.6.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.10.attention.output.dense.weight', 'base_model.encoder.layer.16.attention.self.query.weight', 'base_model.embeddings.position_ids', 'base_model.encoder.layer.21.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.12.attention.output.LayerNorm.weight', 'base_model.encoder.layer.17.attention.self.query.weight', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.18.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.8.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.12.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.14.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.9.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.13.intermediate.dense.weight', 'base_model.encoder.layer.23.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.0.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.12.attention.output.dense.weight', 'base_model.encoder.layer.18.attention.self.query.weight', 'base_model.encoder.layer.22.attention.self.key.weight', 'base_model.encoder.layer.6.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.2.output.LayerNorm.weight', 'base_model.encoder.layer.13.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.21.attention.self.value.weight', 'base_model.encoder.layer.21.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.9.attention.self.value.bias', 'base_model.encoder.layer.15.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.3.output.dense.weight', 'base_model.encoder.layer.12.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.23.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.20.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.10.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.4.output.dense.bias', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.7.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.5.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.17.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.10.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.16.output.LayerNorm.bias', 'base_model.encoder.layer.3.attention.self.key.bias', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.12.attention.self.key.weight', 'base_model.encoder.layer.12.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.23.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.2.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.18.intermediate.dense.bias', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.0.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.16.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.22.attention.self.value.bias', 'base_model.encoder.layer.14.attention.self.key.bias', 'base_model.encoder.layer.22.attention.output.dense.weight', 'base_model.encoder.layer.22.intermediate.dense.bias', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.5.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.9.output.adapters.es.adapter_down.0.weight', 'qa_outputs.bias', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.9.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.3.attention.output.LayerNorm.bias', 'base_model.encoder.layer.8.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.5.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.5.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.12.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.22.attention.self.value.weight', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.3.intermediate.dense.bias', 'base_model.encoder.layer.6.attention.output.dense.weight', 'base_model.encoder.layer.17.attention.self.query.bias', 'base_model.encoder.layer.14.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.0.output.dense.bias', 'base_model.encoder.layer.11.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.3.attention.self.query.weight', 'base_model.encoder.layer.5.attention.self.query.bias', 'base_model.encoder.layer.11.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.14.attention.self.query.bias', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.11.output.LayerNorm.weight', 'base_model.encoder.layer.0.attention.output.dense.bias', 'base_model.encoder.layer.3.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.12.attention.output.LayerNorm.bias', 'base_model.encoder.layer.16.output.LayerNorm.weight', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.19.intermediate.dense.bias', 'base_model.encoder.layer.8.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.1.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.20.attention.output.LayerNorm.weight', 'base_model.encoder.layer.21.output.LayerNorm.bias', 'base_model.encoder.layer.8.output.dense.weight', 'base_model.encoder.layer.16.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.21.intermediate.dense.bias', 'base_model.encoder.layer.11.output.dense.weight', 'base_model.encoder.layer.13.intermediate.dense.bias', 'base_model.encoder.layer.13.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.0.output.adapters.es.adapter_up.weight', 'base_model.embeddings.word_embeddings.weight', 'base_model.encoder.layer.17.attention.self.value.weight', 'base_model.encoder.layer.21.output.LayerNorm.weight', 'base_model.encoder.layer.11.intermediate.dense.weight', 'base_model.encoder.layer.1.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.3.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.20.output.adapters.ep.adapter_down.0.bias', 'base_model.embeddings.token_type_embeddings.weight', 'base_model.encoder.layer.7.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.18.output.LayerNorm.bias', 'base_model.encoder.layer.8.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.6.attention.self.value.bias', 'base_model.encoder.layer.14.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.1.attention.self.key.weight', 'base_model.encoder.layer.4.attention.self.query.bias', 'base_model.encoder.layer.3.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.19.output.LayerNorm.bias', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.16.attention.self.query.bias', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.20.output.dense.weight', 'base_model.encoder.layer.0.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.15.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.7.output.LayerNorm.bias', 'base_model.encoder.layer.16.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.17.intermediate.dense.bias', 'base_model.encoder.layer.11.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.15.intermediate.dense.bias', 'base_model.encoder.layer.5.intermediate.dense.bias', 'base_model.encoder.layer.5.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.18.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.22.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.15.output.LayerNorm.weight', 'base_model.encoder.layer.20.output.LayerNorm.bias', 'base_model.encoder.layer.6.attention.output.LayerNorm.weight', 'base_model.encoder.layer.20.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.0.attention.self.value.weight', 'base_model.encoder.layer.10.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.10.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.11.attention.self.key.bias', 'base_model.encoder.layer.3.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.10.attention.output.dense.bias', 'base_model.encoder.layer.7.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.13.output.LayerNorm.weight', 'base_model.encoder.layer.14.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.17.attention.self.key.weight', 'base_model.pooler.dense.weight', 'base_model.encoder.layer.16.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.20.attention.self.value.weight', 'base_model.encoder.layer.23.attention.output.dense.weight', 'base_model.encoder.layer.1.attention.output.dense.weight', 'base_model.encoder.layer.20.attention.self.value.bias', 'base_model.encoder.layer.0.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.8.attention.self.key.weight', 'base_model.encoder.layer.2.attention.self.key.bias', 'base_model.encoder.layer.13.attention.output.dense.weight', 'base_model.encoder.layer.15.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.18.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.7.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.16.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.2.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.7.attention.self.value.bias', 'base_model.encoder.layer.0.attention.self.query.weight', 'base_model.encoder.layer.13.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.5.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.16.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.19.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.14.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.17.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.4.attention.self.query.weight', 'base_model.encoder.layer.10.attention.self.value.weight', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.1.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.5.attention.output.dense.weight', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.9.attention.output.LayerNorm.bias', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.20.attention.output.LayerNorm.bias', 'base_model.encoder.layer.1.attention.output.LayerNorm.weight', 'base_model.encoder.layer.16.intermediate.dense.weight', 'base_model.encoder.layer.15.attention.self.query.bias', 'base_model.encoder.layer.7.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.9.output.LayerNorm.weight', 'base_model.encoder.layer.6.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.3.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.4.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.3.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.8.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.8.intermediate.dense.weight', 'base_model.encoder.layer.11.attention.output.LayerNorm.weight', 'base_model.encoder.layer.23.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.8.attention.self.query.bias', 'base_model.encoder.layer.7.intermediate.dense.bias', 'base_model.encoder.layer.15.attention.output.LayerNorm.weight', 'base_model.encoder.layer.19.attention.output.dense.bias', 'base_model.encoder.layer.6.attention.output.dense.bias', 'base_model.encoder.layer.14.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.9.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.12.attention.self.query.bias', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.23.attention.output.LayerNorm.weight', 'base_model.encoder.layer.22.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.6.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.14.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.6.attention.self.value.weight', 'base_model.encoder.layer.3.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.4.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.10.attention.self.query.weight', 'base_model.encoder.layer.15.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.9.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.18.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.15.attention.output.dense.bias', 'base_model.encoder.layer.1.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.12.intermediate.dense.bias', 'base_model.encoder.layer.12.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.15.attention.self.value.bias', 'base_model.encoder.layer.16.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.2.intermediate.dense.bias', 'base_model.encoder.layer.7.attention.self.value.weight', 'base_model.encoder.layer.10.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.5.attention.self.query.weight', 'base_model.encoder.layer.12.attention.self.key.bias', 'base_model.encoder.layer.17.attention.output.LayerNorm.weight', 'base_model.encoder.layer.17.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.0.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.13.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.10.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.19.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.21.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.18.attention.self.value.weight', 'base_model.encoder.layer.18.attention.self.value.bias', 'base_model.encoder.layer.10.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.19.output.dense.bias', 'base_model.encoder.layer.10.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.7.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.13.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.10.intermediate.dense.weight', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.11.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.13.attention.self.value.bias', 'base_model.encoder.layer.1.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.18.attention.self.key.weight', 'base_model.encoder.layer.5.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.15.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.15.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.13.attention.self.query.bias', 'base_model.encoder.layer.7.attention.self.query.weight', 'base_model.encoder.layer.9.attention.self.value.weight', 'base_model.encoder.layer.12.output.dense.bias', 'base_model.encoder.layer.0.attention.self.value.bias', 'base_model.encoder.layer.17.output.dense.weight', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.0.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.9.intermediate.dense.bias', 'base_model.encoder.layer.21.output.dense.weight', 'base_model.encoder.layer.4.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.4.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.17.attention.output.dense.bias', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.7.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.11.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.23.attention.self.value.bias', 'base_model.encoder.layer.14.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.10.output.dense.bias', 'base_model.encoder.layer.20.attention.output.dense.bias', 'base_model.encoder.layer.8.attention.output.dense.weight', 'base_model.encoder.layer.12.attention.output.dense.bias', 'base_model.encoder.layer.3.attention.output.LayerNorm.weight', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.14.intermediate.dense.weight', 'base_model.encoder.layer.18.attention.output.LayerNorm.weight', 'base_model.encoder.layer.19.output.LayerNorm.weight', 'base_model.encoder.layer.22.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.3.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.15.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.3.attention.self.value.weight', 'base_model.encoder.layer.6.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.23.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.2.attention.self.value.bias', 'base_model.encoder.layer.7.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.9.attention.output.dense.bias', 'base_model.encoder.layer.4.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.23.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.18.output.dense.weight', 'base_model.encoder.layer.10.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.22.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.23.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.18.attention.output.dense.weight', 'base_model.encoder.layer.10.attention.self.key.weight', 'base_model.encoder.layer.8.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.23.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.2.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.10.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.4.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.17.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.20.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.19.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.3.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.4.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.14.output.LayerNorm.bias', 'base_model.encoder.layer.16.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.0.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.12.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.3.output.LayerNorm.weight', 'base_model.encoder.layer.23.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.12.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.11.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.6.attention.self.key.bias', 'base_model.encoder.layer.13.attention.self.key.weight', 'base_model.encoder.layer.19.attention.output.LayerNorm.bias', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.3.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.9.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.22.output.dense.weight', 'base_model.encoder.layer.23.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.21.output.dense.bias', 'base_model.encoder.layer.6.attention.output.LayerNorm.bias', 'base_model.encoder.layer.5.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.11.attention.output.dense.weight', 'base_model.encoder.layer.18.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.16.attention.self.value.bias', 'base_model.encoder.layer.2.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.5.attention.self.value.bias', 'base_model.encoder.layer.9.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.11.attention.self.value.bias', 'base_model.encoder.layer.7.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.20.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.22.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.7.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.5.attention.output.LayerNorm.bias', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.1.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.22.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.17.attention.self.key.bias', 'base_model.encoder.layer.22.attention.output.LayerNorm.bias', 'base_model.encoder.layer.2.attention.output.dense.bias', 'base_model.encoder.layer.14.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.23.output.LayerNorm.bias', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.8.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.18.attention.self.query.bias', 'base_model.encoder.layer.19.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.16.attention.output.LayerNorm.weight', 'base_model.encoder.layer.18.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.18.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.4.output.LayerNorm.bias', 'base_model.encoder.layer.5.attention.output.LayerNorm.weight', 'base_model.encoder.layer.8.output.LayerNorm.weight', 'base_model.encoder.layer.9.intermediate.dense.weight', 'base_model.encoder.layer.7.attention.self.key.weight', 'base_model.encoder.layer.17.attention.self.value.bias', 'base_model.encoder.layer.7.output.LayerNorm.weight', 'base_model.encoder.layer.8.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.0.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.4.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.4.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.21.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.0.output.LayerNorm.weight', 'base_model.encoder.layer.23.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.3.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.14.attention.output.dense.bias', 'base_model.encoder.layer.13.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.22.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.19.attention.self.query.bias', 'base_model.encoder.layer.19.attention.self.value.bias', 'base_model.encoder.layer.9.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.14.attention.self.key.weight', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.1.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.0.output.LayerNorm.bias', 'base_model.encoder.layer.15.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.1.output.LayerNorm.bias', 'base_model.encoder.layer.16.attention.output.dense.weight', 'base_model.encoder.layer.19.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.2.attention.output.LayerNorm.bias', 'base_model.encoder.layer.1.attention.self.query.weight', 'base_model.encoder.layer.0.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.4.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.22.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.21.attention.self.key.weight', 'base_model.encoder.layer.13.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.22.attention.self.key.bias', 'base_model.encoder.layer.20.attention.self.query.bias', 'base_model.encoder.layer.8.attention.self.key.bias', 'base_model.encoder.layer.21.attention.output.dense.weight', 'base_model.encoder.layer.23.attention.output.LayerNorm.bias', 'base_model.encoder.layer.1.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.4.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.23.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.6.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.6.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.14.attention.self.query.weight', 'base_model.encoder.layer.17.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.11.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.13.attention.output.LayerNorm.bias', 'base_model.encoder.layer.23.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.14.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.1.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.7.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.8.output.LayerNorm.bias', 'base_model.encoder.layer.6.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.11.output.LayerNorm.bias', 'base_model.encoder.layer.15.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.9.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.9.attention.self.query.weight', 'base_model.encoder.layer.18.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.4.intermediate.dense.weight', 'base_model.encoder.layer.20.output.LayerNorm.weight', 'base_model.encoder.layer.21.attention.self.key.bias', 'base_model.encoder.layer.16.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.1.attention.output.dense.bias', 'base_model.encoder.layer.13.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.2.output.dense.bias', 'base_model.encoder.layer.21.attention.output.LayerNorm.weight', 'base_model.encoder.layer.17.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.6.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.23.intermediate.dense.weight', 'base_model.encoder.layer.16.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.19.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.21.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.16.attention.output.dense.bias', 'base_model.encoder.layer.16.attention.self.key.bias', 'base_model.encoder.layer.17.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.22.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.16.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.3.output.dense.bias', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.4.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.17.output.LayerNorm.bias', 'base_model.encoder.layer.21.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.23.attention.self.key.bias', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.0.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.3.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.11.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.18.output.dense.bias', 'base_model.encoder.layer.22.attention.output.LayerNorm.weight', 'base_model.encoder.layer.23.output.dense.weight', 'base_model.encoder.layer.8.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.2.attention.output.dense.weight', 'qa_outputs.weight', 'base_model.encoder.layer.4.output.LayerNorm.weight', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.14.intermediate.dense.bias', 'base_model.encoder.layer.2.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.13.output.dense.bias', 'base_model.encoder.layer.8.attention.output.dense.bias', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.11.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.9.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.11.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.11.attention.output.LayerNorm.bias', 'base_model.encoder.layer.18.attention.output.dense.bias', 'base_model.encoder.layer.0.attention.output.LayerNorm.bias', 'base_model.encoder.layer.1.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.12.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.1.output.dense.weight', 'base_model.encoder.layer.5.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.0.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.4.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.16.output.dense.bias', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.8.output.dense.bias', 'base_model.encoder.layer.4.intermediate.dense.bias', 'base_model.encoder.layer.2.attention.self.value.weight', 'base_model.encoder.layer.17.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.11.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.15.attention.output.LayerNorm.bias', 'base_model.encoder.layer.6.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.23.attention.self.key.weight', 'base_model.encoder.layer.2.attention.self.query.bias', 'base_model.encoder.layer.20.output.dense.bias', 'base_model.encoder.layer.22.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.1.attention.self.value.bias', 'base_model.encoder.layer.8.attention.output.LayerNorm.weight', 'base_model.encoder.layer.4.attention.self.value.bias', 'base_model.encoder.layer.23.attention.self.query.bias', 'base_model.encoder.layer.10.attention.output.LayerNorm.bias', 'base_model.encoder.layer.2.output.LayerNorm.bias', 'base_model.encoder.layer.3.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.8.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.13.attention.self.value.weight', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.18.output.LayerNorm.weight', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.13.output.LayerNorm.bias', 'base_model.encoder.layer.8.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.20.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.21.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.15.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.8.attention.self.query.weight', 'base_model.encoder.layer.11.attention.self.value.weight', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.14.attention.self.value.weight', 'base_model.encoder.layer.1.attention.self.key.bias', 'base_model.encoder.layer.15.output.dense.weight', 'base_model.encoder.layer.1.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.3.attention.self.value.bias', 'base_model.encoder.layer.4.attention.self.key.bias', 'base_model.encoder.layer.8.attention.self.value.bias', 'base_model.encoder.layer.15.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.10.output.dense.weight', 'base_model.encoder.layer.6.attention.self.query.bias', 'base_model.encoder.layer.22.intermediate.dense.weight', 'base_model.encoder.layer.0.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.1.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.6.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.11.attention.self.query.weight', 'base_model.encoder.layer.13.attention.output.LayerNorm.weight', 'base_model.encoder.layer.12.attention.self.value.bias', 'base_model.encoder.layer.19.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.12.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.16.output.dense.weight', 'base_model.encoder.layer.19.attention.self.key.bias', 'base_model.encoder.layer.17.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.17.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.21.attention.self.value.bias', 'base_model.encoder.layer.21.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.18.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.14.attention.self.value.bias', 'base_model.encoder.layer.17.intermediate.dense.weight', 'base_model.encoder.layer.11.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.17.output.LayerNorm.weight', 'base_model.encoder.layer.17.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.10.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.21.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.7.output.dense.weight', 'base_model.encoder.layer.21.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.16.attention.self.value.weight', 'base_model.encoder.layer.5.output.LayerNorm.bias', 'base_model.encoder.layer.4.attention.self.key.weight', 'base_model.encoder.layer.5.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.9.attention.self.key.weight', 'base_model.encoder.layer.19.intermediate.dense.weight', 'base_model.encoder.layer.1.output.dense.bias', 'base_model.encoder.layer.2.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.2.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.7.intermediate.dense.weight', 'base_model.encoder.layer.12.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.7.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.20.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.18.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.4.attention.output.dense.weight', 'base_model.encoder.layer.23.intermediate.dense.bias', 'base_model.encoder.layer.17.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.15.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.1.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.0.intermediate.dense.bias', 'base_model.encoder.layer.20.intermediate.dense.bias', 'base_model.encoder.layer.0.attention.self.query.bias', 'base_model.encoder.layer.10.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.5.output.dense.weight', 'base_model.encoder.layer.12.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.4.attention.output.LayerNorm.bias', 'base_model.encoder.layer.11.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.21.intermediate.dense.weight', 'base_model.encoder.layer.9.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.20.intermediate.dense.weight', 'base_model.encoder.layer.22.output.dense.bias', 'base_model.encoder.layer.2.attention.output.LayerNorm.weight', 'base_model.encoder.layer.1.output.LayerNorm.weight', 'base_model.encoder.layer.5.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.5.output.LayerNorm.weight', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.21.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.3.intermediate.dense.weight', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.22.attention.self.query.weight', 'base_model.encoder.layer.13.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.16.intermediate.dense.bias', 'base_model.encoder.layer.8.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.15.output.dense.bias', 'base_model.encoder.layer.2.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.2.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.13.attention.self.key.bias', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.22.output.LayerNorm.weight', 'base_model.encoder.layer.9.output.LayerNorm.bias', 'base_model.encoder.layer.6.output.LayerNorm.bias', 'base_model.encoder.layer.19.attention.self.key.weight', 'base_model.encoder.layer.7.attention.self.key.bias', 'base_model.encoder.layer.2.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.10.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.11.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.2.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.6.output.LayerNorm.weight', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.14.output.LayerNorm.weight', 'base_model.encoder.layer.23.attention.self.query.weight', 'base_model.encoder.layer.14.attention.output.dense.weight', 'base_model.encoder.layer.7.attention.output.LayerNorm.weight', 'base_model.encoder.layer.1.intermediate.dense.bias', 'base_model.encoder.layer.12.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.5.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.0.intermediate.dense.weight', 'base_model.encoder.layer.3.attention.self.key.weight', 'base_model.encoder.layer.16.attention.self.key.weight', 'base_model.encoder.layer.20.attention.self.key.weight', 'base_model.encoder.layer.5.intermediate.dense.weight', 'base_model.encoder.layer.5.output.adapters.ep.adapter_up.bias', 'base_model.embeddings.position_embeddings.weight', 'base_model.encoder.layer.9.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.18.attention.self.key.bias', 'base_model.encoder.layer.3.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.17.attention.output.LayerNorm.bias', 'base_model.encoder.layer.11.attention.output.dense.bias', 'base_model.encoder.layer.17.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.1.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.6.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.16.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.11.output.dense.bias', 'base_model.encoder.layer.13.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.14.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.21.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.7.output.dense.bias', 'base_model.encoder.layer.18.intermediate.dense.weight', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.12.output.LayerNorm.bias', 'base_model.encoder.layer.4.output.dense.weight', 'base_model.encoder.layer.7.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.1.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.21.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.19.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.19.attention.output.LayerNorm.weight', 'base_model.encoder.layer.14.attention.output.LayerNorm.weight', 'base_model.encoder.layer.15.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.22.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.9.attention.output.LayerNorm.weight', 'base_model.encoder.layer.5.attention.self.key.bias', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.3.attention.output.dense.bias', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.0.attention.self.key.bias', 'base_model.encoder.layer.20.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.13.output.dense.weight', 'base_model.encoder.layer.19.attention.output.dense.weight', 'base_model.encoder.layer.15.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.19.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.13.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.13.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.0.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.19.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.11.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.6.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.9.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.16.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.18.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.0.attention.output.dense.weight', 'base_model.encoder.layer.20.attention.self.query.weight', 'base_model.encoder.layer.6.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.13.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.19.attention.self.value.weight', 'base_model.encoder.layer.20.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.10.attention.self.value.bias', 'base_model.encoder.layer.13.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.12.attention.self.value.weight', 'base_model.encoder.layer.22.output.LayerNorm.bias', 'base_model.encoder.layer.10.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.16.attention.output.LayerNorm.bias', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.10.output.LayerNorm.weight', 'base_model.encoder.layer.16.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.12.intermediate.dense.weight', 'base_model.encoder.layer.21.attention.self.query.bias', 'base_model.encoder.layer.21.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.22.attention.self.query.bias', 'base_model.encoder.layer.0.attention.output.LayerNorm.weight', 'base_model.encoder.layer.4.attention.output.dense.bias', 'base_model.encoder.layer.3.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.7.attention.output.dense.bias', 'base_model.encoder.layer.10.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.16.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.18.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.2.attention.self.query.weight', 'base_model.encoder.layer.4.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.9.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.20.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.21.attention.output.dense.bias', 'base_model.encoder.layer.20.attention.self.key.bias', 'base_model.encoder.layer.15.attention.self.key.bias', 'base_model.encoder.layer.20.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.5.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.16.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.3.output.LayerNorm.bias', 'base_model.encoder.layer.15.attention.self.query.weight', 'base_model.encoder.layer.19.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.15.attention.self.value.weight', 'base_model.encoder.layer.7.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.23.output.dense.bias', 'base_model.encoder.layer.19.attention.self.query.weight', 'base_model.encoder.layer.19.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.6.intermediate.dense.bias', 'base_model.encoder.layer.11.attention.self.query.bias', 'base_model.encoder.layer.19.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.12.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.0.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.18.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.19.output.dense.weight', 'base_model.encoder.layer.13.attention.output.dense.bias', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.20.attention.output.dense.weight']
- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of XLMRobertaModel were not initialized from the model checkpoint at /cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//squad/xlm-KG_LR3e-5_EPOCH2.0_maxlen384_batchsize4_gradacc4 and are newly initialized: ['encoder.layer.14.intermediate.dense.bias', 'encoder.layer.16.attention.self.key.bias', 'encoder.layer.5.attention.output.LayerNorm.weight', 'encoder.layer.8.attention.output.dense.weight', 'encoder.layer.15.attention.output.dense.weight', 'encoder.layer.21.attention.output.dense.bias', 'encoder.layer.22.attention.self.query.bias', 'encoder.layer.8.attention.self.key.bias', 'encoder.layer.20.attention.output.dense.bias', 'encoder.layer.17.attention.self.value.bias', 'encoder.layer.0.attention.output.LayerNorm.weight', 'encoder.layer.8.attention.self.value.weight', 'encoder.layer.23.output.LayerNorm.bias', 'encoder.layer.17.output.dense.bias', 'encoder.layer.4.attention.output.LayerNorm.weight', 'encoder.layer.7.output.dense.bias', 'encoder.layer.19.attention.self.key.weight', 'encoder.layer.16.attention.output.dense.weight', 'encoder.layer.3.attention.self.key.weight', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.10.attention.self.query.bias', 'encoder.layer.10.attention.output.LayerNorm.bias', 'encoder.layer.22.output.LayerNorm.weight', 'encoder.layer.16.intermediate.dense.weight', 'encoder.layer.18.intermediate.dense.bias', 'encoder.layer.20.output.LayerNorm.weight', 'encoder.layer.11.attention.output.dense.bias', 'encoder.layer.1.attention.output.LayerNorm.weight', 'encoder.layer.16.output.dense.weight', 'encoder.layer.14.attention.self.query.bias', 'encoder.layer.3.attention.self.value.bias', 'encoder.layer.23.attention.output.dense.weight', 'encoder.layer.10.attention.output.dense.weight', 'encoder.layer.7.attention.output.dense.bias', 'encoder.layer.3.attention.self.query.bias', 'encoder.layer.11.output.LayerNorm.bias', 'encoder.layer.14.attention.output.dense.weight', 'encoder.layer.18.output.dense.weight', 'encoder.layer.16.attention.output.dense.bias', 'encoder.layer.23.attention.self.key.bias', 'encoder.layer.23.attention.self.value.weight', 'encoder.layer.22.attention.output.LayerNorm.bias', 'encoder.layer.14.attention.self.query.weight', 'encoder.layer.14.attention.self.key.bias', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.18.output.LayerNorm.bias', 'encoder.layer.12.attention.self.value.weight', 'encoder.layer.20.intermediate.dense.weight', 'encoder.layer.20.attention.self.key.bias', 'encoder.layer.2.output.dense.bias', 'encoder.layer.8.attention.self.query.bias', 'encoder.layer.8.output.LayerNorm.bias', 'encoder.layer.5.attention.self.query.weight', 'encoder.layer.13.attention.output.dense.bias', 'encoder.layer.5.attention.self.key.bias', 'encoder.layer.13.attention.output.LayerNorm.weight', 'encoder.layer.13.output.LayerNorm.weight', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.14.attention.self.key.weight', 'encoder.layer.10.attention.self.key.weight', 'encoder.layer.4.output.dense.bias', 'encoder.layer.13.attention.self.value.weight', 'encoder.layer.9.attention.output.dense.weight', 'encoder.layer.11.attention.self.value.bias', 'encoder.layer.10.attention.self.value.weight', 'encoder.layer.12.output.LayerNorm.weight', 'encoder.layer.4.attention.self.key.weight', 'encoder.layer.13.attention.self.key.bias', 'encoder.layer.1.attention.self.query.bias', 'encoder.layer.4.attention.output.LayerNorm.bias', 'encoder.layer.15.intermediate.dense.bias', 'encoder.layer.16.output.LayerNorm.weight', 'encoder.layer.0.attention.self.query.weight', 'encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.layer.4.attention.self.query.weight', 'encoder.layer.13.attention.self.query.weight', 'encoder.layer.10.output.LayerNorm.weight', 'encoder.layer.21.intermediate.dense.weight', 'encoder.layer.7.attention.self.value.weight', 'encoder.layer.22.intermediate.dense.bias', 'encoder.layer.19.attention.output.dense.bias', 'encoder.layer.6.attention.output.dense.weight', 'encoder.layer.7.attention.output.dense.weight', 'encoder.layer.18.intermediate.dense.weight', 'encoder.layer.5.attention.self.query.bias', 'encoder.layer.1.attention.self.key.bias', 'encoder.layer.7.attention.self.key.bias', 'encoder.layer.2.attention.output.dense.bias', 'encoder.layer.12.attention.self.key.weight', 'encoder.layer.9.attention.self.query.weight', 'encoder.layer.9.attention.self.query.bias', 'encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.layer.14.output.dense.bias', 'encoder.layer.15.output.LayerNorm.bias', 'encoder.layer.9.output.dense.weight', 'encoder.layer.4.output.dense.weight', 'encoder.layer.23.output.dense.bias', 'encoder.layer.22.attention.output.dense.weight', 'encoder.layer.16.output.dense.bias', 'encoder.layer.23.attention.self.key.weight', 'encoder.layer.8.attention.self.key.weight', 'encoder.layer.21.output.LayerNorm.weight', 'encoder.layer.1.attention.self.value.weight', 'encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.layer.16.attention.self.value.weight', 'encoder.layer.4.attention.self.value.weight', 'encoder.layer.9.attention.self.value.weight', 'encoder.layer.4.attention.self.query.bias', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.13.intermediate.dense.weight', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.6.attention.output.LayerNorm.bias', 'encoder.layer.21.intermediate.dense.bias', 'encoder.layer.19.attention.output.LayerNorm.weight', 'encoder.layer.2.attention.output.dense.weight', 'encoder.layer.12.attention.output.LayerNorm.weight', 'encoder.layer.2.attention.self.key.weight', 'encoder.layer.5.output.dense.bias', 'encoder.layer.17.attention.output.LayerNorm.bias', 'encoder.layer.4.attention.output.dense.bias', 'encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.layer.0.attention.output.dense.bias', 'encoder.layer.4.attention.self.value.bias', 'encoder.layer.13.attention.output.dense.weight', 'encoder.layer.7.output.LayerNorm.weight', 'encoder.layer.19.output.dense.bias', 'encoder.layer.6.attention.self.value.bias', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.20.output.dense.weight', 'encoder.layer.18.attention.self.value.bias', 'encoder.layer.16.attention.self.query.weight', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.5.attention.output.dense.bias', 'embeddings.position_embeddings.weight', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.12.output.dense.weight', 'encoder.layer.19.output.LayerNorm.bias', 'encoder.layer.12.intermediate.dense.bias', 'encoder.layer.8.attention.output.dense.bias', 'encoder.layer.14.output.LayerNorm.weight', 'encoder.layer.11.attention.self.value.weight', 'encoder.layer.17.attention.output.dense.bias', 'encoder.layer.12.attention.output.dense.weight', 'encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.15.attention.self.key.weight', 'encoder.layer.18.attention.output.dense.weight', 'encoder.layer.2.attention.self.value.weight', 'encoder.layer.12.attention.output.LayerNorm.bias', 'encoder.layer.5.attention.self.key.weight', 'encoder.layer.23.attention.self.value.bias', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.8.attention.output.LayerNorm.bias', 'encoder.layer.19.attention.self.key.bias', 'encoder.layer.21.attention.self.query.weight', 'encoder.layer.0.attention.self.query.bias', 'encoder.layer.15.attention.self.value.bias', 'encoder.layer.19.intermediate.dense.weight', 'encoder.layer.15.attention.self.query.weight', 'encoder.layer.19.intermediate.dense.bias', 'encoder.layer.0.attention.self.value.bias', 'encoder.layer.2.attention.self.key.bias', 'encoder.layer.23.intermediate.dense.bias', 'encoder.layer.2.output.dense.weight', 'encoder.layer.3.attention.output.dense.weight', 'encoder.layer.22.attention.self.key.weight', 'encoder.layer.21.attention.self.key.weight', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.6.attention.output.LayerNorm.weight', 'encoder.layer.7.attention.self.key.weight', 'encoder.layer.23.attention.self.query.bias', 'encoder.layer.22.attention.self.query.weight', 'encoder.layer.18.attention.output.dense.bias', 'encoder.layer.2.attention.self.value.bias', 'encoder.layer.9.attention.self.key.weight', 'encoder.layer.8.output.LayerNorm.weight', 'encoder.layer.17.attention.self.value.weight', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.21.output.LayerNorm.bias', 'encoder.layer.14.attention.output.LayerNorm.weight', 'encoder.layer.9.output.LayerNorm.weight', 'encoder.layer.6.output.dense.weight', 'encoder.layer.18.attention.output.LayerNorm.bias', 'encoder.layer.8.output.dense.bias', 'encoder.layer.16.intermediate.dense.bias', 'encoder.layer.10.output.dense.weight', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.13.attention.output.LayerNorm.bias', 'encoder.layer.10.attention.output.dense.bias', 'encoder.layer.11.attention.self.query.weight', 'encoder.layer.22.intermediate.dense.weight', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.11.attention.self.query.bias', 'encoder.layer.15.output.dense.weight', 'encoder.layer.15.output.LayerNorm.weight', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.7.attention.output.LayerNorm.weight', 'encoder.layer.23.attention.output.LayerNorm.weight', 'encoder.layer.17.attention.output.LayerNorm.weight', 'encoder.layer.21.attention.self.value.weight', 'encoder.layer.5.output.dense.weight', 'encoder.layer.23.attention.output.LayerNorm.bias', 'encoder.layer.21.attention.output.LayerNorm.weight', 'encoder.layer.6.output.LayerNorm.bias', 'encoder.layer.14.attention.output.LayerNorm.bias', 'encoder.layer.21.attention.output.dense.weight', 'encoder.layer.17.attention.self.key.bias', 'encoder.layer.17.attention.self.query.weight', 'encoder.layer.9.attention.self.value.bias', 'encoder.layer.21.attention.output.LayerNorm.bias', 'encoder.layer.14.output.LayerNorm.bias', 'encoder.layer.17.attention.self.key.weight', 'encoder.layer.19.attention.self.query.bias', 'encoder.layer.6.attention.self.key.bias', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.3.attention.self.key.bias', 'encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.layer.1.attention.output.dense.weight', 'encoder.layer.16.attention.self.value.bias', 'encoder.layer.3.attention.self.query.weight', 'encoder.layer.7.output.dense.weight', 'encoder.layer.20.attention.self.query.weight', 'encoder.layer.17.attention.output.dense.weight', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.1.output.dense.bias', 'encoder.layer.10.attention.self.query.weight', 'encoder.layer.7.attention.self.query.bias', 'encoder.layer.3.output.dense.weight', 'encoder.layer.19.output.dense.weight', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.20.attention.self.key.weight', 'encoder.layer.1.attention.self.value.bias', 'encoder.layer.0.attention.output.dense.weight', 'encoder.layer.9.attention.output.LayerNorm.weight', 'encoder.layer.18.output.LayerNorm.weight', 'embeddings.LayerNorm.weight', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.0.output.dense.weight', 'encoder.layer.13.attention.self.query.bias', 'encoder.layer.20.intermediate.dense.bias', 'encoder.layer.18.attention.self.query.weight', 'encoder.layer.20.attention.output.LayerNorm.bias', 'encoder.layer.15.attention.output.dense.bias', 'encoder.layer.19.attention.self.value.weight', 'embeddings.token_type_embeddings.weight', 'encoder.layer.9.attention.output.dense.bias', 'encoder.layer.12.output.LayerNorm.bias', 'encoder.layer.17.output.LayerNorm.bias', 'encoder.layer.5.attention.self.value.weight', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.layer.19.attention.output.LayerNorm.bias', 'encoder.layer.14.attention.output.dense.bias', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.13.attention.self.value.bias', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.15.intermediate.dense.weight', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.17.attention.self.query.bias', 'encoder.layer.14.attention.self.value.bias', 'encoder.layer.18.attention.output.LayerNorm.weight', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.17.output.LayerNorm.weight', 'encoder.layer.11.output.LayerNorm.weight', 'encoder.layer.8.attention.output.LayerNorm.weight', 'encoder.layer.10.attention.self.key.bias', 'encoder.layer.15.attention.self.query.bias', 'encoder.layer.22.output.LayerNorm.bias', 'encoder.layer.23.attention.self.query.weight', 'encoder.layer.7.intermediate.dense.bias', 'encoder.layer.3.output.dense.bias', 'encoder.layer.8.output.dense.weight', 'encoder.layer.15.attention.output.LayerNorm.weight', 'encoder.layer.20.attention.output.LayerNorm.weight', 'encoder.layer.11.attention.self.key.bias', 'encoder.layer.2.attention.output.LayerNorm.bias', 'encoder.layer.17.intermediate.dense.bias', 'encoder.layer.2.attention.self.query.weight', 'encoder.layer.13.output.dense.bias', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.22.attention.self.key.bias', 'encoder.layer.18.attention.self.key.weight', 'encoder.layer.1.attention.self.query.weight', 'encoder.layer.10.attention.output.LayerNorm.weight', 'embeddings.word_embeddings.weight', 'pooler.dense.bias', 'encoder.layer.10.attention.self.value.bias', 'encoder.layer.12.attention.self.query.weight', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.2.attention.output.LayerNorm.weight', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.20.output.dense.bias', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.23.intermediate.dense.weight', 'encoder.layer.6.attention.self.value.weight', 'encoder.layer.12.attention.self.value.bias', 'encoder.layer.1.output.dense.weight', 'encoder.layer.17.intermediate.dense.weight', 'encoder.layer.10.intermediate.dense.weight', 'encoder.layer.23.output.dense.weight', 'encoder.layer.22.output.dense.bias', 'encoder.layer.18.attention.self.key.bias', 'encoder.layer.7.attention.self.value.bias', 'encoder.layer.21.attention.self.query.bias', 'encoder.layer.14.intermediate.dense.weight', 'encoder.layer.20.attention.self.value.weight', 'encoder.layer.3.attention.output.dense.bias', 'encoder.layer.18.output.dense.bias', 'encoder.layer.17.output.dense.weight', 'encoder.layer.20.attention.output.dense.weight', 'encoder.layer.12.attention.self.query.bias', 'encoder.layer.13.attention.self.key.weight', 'encoder.layer.5.attention.self.value.bias', 'encoder.layer.7.attention.self.query.weight', 'encoder.layer.13.output.dense.weight', 'encoder.layer.23.output.LayerNorm.weight', 'encoder.layer.10.output.LayerNorm.bias', 'encoder.layer.2.attention.self.query.bias', 'encoder.layer.16.attention.self.query.bias', 'encoder.layer.6.attention.self.query.bias', 'encoder.layer.13.intermediate.dense.bias', 'encoder.layer.0.output.dense.bias', 'encoder.layer.19.attention.self.value.bias', 'encoder.layer.16.output.LayerNorm.bias', 'encoder.layer.21.output.dense.weight', 'encoder.layer.1.attention.output.dense.bias', 'encoder.layer.12.attention.self.key.bias', 'encoder.layer.12.intermediate.dense.weight', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.20.attention.self.value.bias', 'encoder.layer.6.attention.output.dense.bias', 'encoder.layer.22.output.dense.weight', 'encoder.layer.16.attention.output.LayerNorm.bias', 'encoder.layer.15.attention.output.LayerNorm.bias', 'encoder.layer.0.attention.self.key.bias', 'encoder.layer.0.attention.self.value.weight', 'encoder.layer.20.output.LayerNorm.bias', 'encoder.layer.16.attention.self.key.weight', 'encoder.layer.9.output.LayerNorm.bias', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.16.attention.output.LayerNorm.weight', 'encoder.layer.9.output.dense.bias', 'embeddings.LayerNorm.bias', 'encoder.layer.9.attention.self.key.bias', 'encoder.layer.23.attention.output.dense.bias', 'encoder.layer.8.attention.self.value.bias', 'encoder.layer.14.attention.self.value.weight', 'encoder.layer.15.output.dense.bias', 'encoder.layer.6.attention.self.query.weight', 'encoder.layer.22.attention.output.dense.bias', 'encoder.layer.3.attention.self.value.weight', 'encoder.layer.22.attention.self.value.weight', 'encoder.layer.11.attention.self.key.weight', 'encoder.layer.18.attention.self.value.weight', 'encoder.layer.19.attention.output.dense.weight', 'encoder.layer.6.attention.self.key.weight', 'encoder.layer.11.output.dense.weight', 'encoder.layer.1.attention.self.key.weight', 'pooler.dense.weight', 'encoder.layer.13.output.LayerNorm.bias', 'encoder.layer.21.attention.self.key.bias', 'encoder.layer.5.output.LayerNorm.bias', 'encoder.layer.5.attention.output.dense.weight', 'encoder.layer.9.attention.output.LayerNorm.bias', 'encoder.layer.11.attention.output.LayerNorm.weight', 'encoder.layer.15.attention.self.value.weight', 'encoder.layer.11.output.dense.bias', 'encoder.layer.0.attention.self.key.weight', 'encoder.layer.11.attention.output.dense.weight', 'encoder.layer.8.attention.self.query.weight', 'encoder.layer.7.output.LayerNorm.bias', 'encoder.layer.18.attention.self.query.bias', 'encoder.layer.20.attention.self.query.bias', 'encoder.layer.4.attention.output.dense.weight', 'encoder.layer.15.attention.self.key.bias', 'encoder.layer.21.output.dense.bias', 'encoder.layer.4.attention.self.key.bias', 'encoder.layer.10.output.dense.bias', 'encoder.layer.19.attention.self.query.weight', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.21.attention.self.value.bias', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.7.attention.output.LayerNorm.bias', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.12.output.dense.bias', 'encoder.layer.19.output.LayerNorm.weight', 'encoder.layer.14.output.dense.weight', 'encoder.layer.22.attention.self.value.bias', 'encoder.layer.12.attention.output.dense.bias', 'encoder.layer.22.attention.output.LayerNorm.weight', 'encoder.layer.6.output.dense.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Overwriting existing adapter 'ep'.
Overwriting existing adapter 'tp'.
Overwriting existing adapter 'es'.
Overwriting existing adapter 'ts'.
Overwriting existing adapter fusion module 'ep,tp,es,ts'
05/09/2022 09:13:18 - INFO - __main__ -   lang2id = None
05/09/2022 09:13:24 - INFO - __main__ -   Training/evaluation parameters Namespace(adam_epsilon=1e-08, cache_dir='', config_name='', data_dir=None, device=device(type='cuda'), do_eval=True, do_lower_case=False, do_train=False, doc_stride=128, eval_all_checkpoints=False, eval_lang='vi', evaluate_during_training=False, fp16=False, fp16_opt_level='O1', gradient_accumulation_steps=1, learning_rate=5e-05, local_rank=-1, logging_steps=50, max_answer_length=30, max_grad_norm=1.0, max_query_length=64, max_seq_length=384, max_steps=-1, model_name='xlm-KG', model_name_or_path='/cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//squad/xlm-KG_LR3e-5_EPOCH2.0_maxlen384_batchsize4_gradacc4', model_type='xlm', modelkg_dir='/cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/adapter/xlmr_adapter', n_best_size=20, n_gpu=1, no_cuda=False, null_score_diff_threshold=0.0, num_train_epochs=3.0, output_dir='/cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//squad/xlm-KG_LR3e-5_EPOCH2.0_maxlen384_batchsize4_gradacc4/predictions/xquad/', overwrite_cache=False, overwrite_output_dir=False, per_gpu_eval_batch_size=8, per_gpu_train_batch_size=8, predict_file='/cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/download//xquad//xquad.vi.json', save_steps=50, seed=42, server_ip='', server_port='', threads=1, tokenizer_name='', train_file=None, train_lang='en', verbose_logging=False, version_2_with_negative=False, warmup_steps=0, weight_decay=0.0)
05/09/2022 09:13:24 - INFO - __main__ -   Loading checkpoint /cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//squad/xlm-KG_LR3e-5_EPOCH2.0_maxlen384_batchsize4_gradacc4 for evaluation
05/09/2022 09:13:24 - INFO - __main__ -   Evaluate the following checkpoints: ['/cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//squad/xlm-KG_LR3e-5_EPOCH2.0_maxlen384_batchsize4_gradacc4']
Some weights of the model checkpoint at /cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//squad/xlm-KG_LR3e-5_EPOCH2.0_maxlen384_batchsize4_gradacc4 were not used when initializing XLMRobertaModel: ['base_model.encoder.layer.14.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.13.attention.self.query.weight', 'base_model.encoder.layer.7.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.3.attention.output.dense.weight', 'base_model.encoder.layer.14.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.10.attention.self.key.bias', 'base_model.encoder.layer.18.output.adapters.es.adapter_up.bias', 'base_model.pooler.dense.bias', 'base_model.encoder.layer.5.attention.self.key.weight', 'base_model.encoder.layer.2.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.20.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.4.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.17.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.10.attention.output.LayerNorm.weight', 'base_model.encoder.layer.4.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.20.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.22.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.7.attention.output.LayerNorm.bias', 'base_model.encoder.layer.2.intermediate.dense.weight', 'base_model.encoder.layer.22.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.15.attention.self.key.weight', 'base_model.encoder.layer.8.attention.output.LayerNorm.bias', 'base_model.encoder.layer.10.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.6.attention.self.query.weight', 'base_model.encoder.layer.6.output.dense.bias', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.18.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.19.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.22.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.8.attention.self.value.weight', 'base_model.encoder.layer.9.output.dense.bias', 'base_model.encoder.layer.4.attention.self.value.weight', 'base_model.encoder.layer.15.attention.output.dense.weight', 'base_model.encoder.layer.17.output.dense.bias', 'base_model.encoder.layer.12.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.23.attention.self.value.weight', 'base_model.encoder.layer.8.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.14.output.dense.bias', 'base_model.encoder.layer.6.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.22.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.4.attention.output.LayerNorm.weight', 'base_model.encoder.layer.11.intermediate.dense.bias', 'base_model.encoder.layer.11.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.0.output.dense.weight', 'base_model.encoder.layer.17.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.23.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.9.attention.output.dense.weight', 'base_model.encoder.layer.7.attention.output.dense.weight', 'base_model.encoder.layer.9.attention.self.key.bias', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.1.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.19.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.5.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.9.output.dense.weight', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.20.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.23.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.18.attention.output.LayerNorm.bias', 'base_model.encoder.layer.7.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.0.attention.self.key.weight', 'base_model.encoder.layer.14.attention.output.LayerNorm.bias', 'base_model.encoder.layer.21.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.12.output.dense.weight', 'base_model.encoder.layer.5.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.15.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.23.attention.output.dense.bias', 'base_model.encoder.layer.5.attention.self.value.weight', 'base_model.encoder.layer.5.output.dense.bias', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.12.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.8.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.12.output.LayerNorm.weight', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.11.attention.self.key.weight', 'base_model.encoder.layer.6.attention.self.key.weight', 'base_model.encoder.layer.3.output.adapters.ep.adapter_down.0.bias', 'base_model.embeddings.LayerNorm.bias', 'base_model.encoder.layer.10.output.LayerNorm.bias', 'base_model.encoder.layer.1.intermediate.dense.weight', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.2.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.8.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.17.attention.output.dense.weight', 'base_model.encoder.layer.10.attention.self.query.bias', 'base_model.encoder.layer.14.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.9.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.15.output.LayerNorm.bias', 'base_model.encoder.layer.19.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.2.output.dense.weight', 'base_model.embeddings.LayerNorm.weight', 'base_model.encoder.layer.2.attention.self.key.weight', 'base_model.encoder.layer.7.attention.self.query.bias', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.21.attention.output.LayerNorm.bias', 'base_model.encoder.layer.8.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.9.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.6.intermediate.dense.weight', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.1.attention.self.value.weight', 'base_model.encoder.layer.13.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.5.attention.output.dense.bias', 'base_model.encoder.layer.22.attention.output.dense.bias', 'base_model.encoder.layer.15.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.3.attention.self.query.bias', 'base_model.encoder.layer.23.output.LayerNorm.weight', 'base_model.encoder.layer.10.intermediate.dense.bias', 'base_model.encoder.layer.2.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.22.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.12.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.14.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.0.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.23.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.6.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.8.intermediate.dense.bias', 'base_model.encoder.layer.17.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.14.output.dense.weight', 'base_model.encoder.layer.9.attention.self.query.bias', 'base_model.encoder.layer.1.attention.output.LayerNorm.bias', 'base_model.encoder.layer.12.attention.self.query.weight', 'base_model.encoder.layer.1.attention.self.query.bias', 'base_model.encoder.layer.2.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.20.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.13.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.21.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.20.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.21.attention.self.query.weight', 'base_model.encoder.layer.2.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.14.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.18.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.6.output.dense.weight', 'base_model.encoder.layer.15.intermediate.dense.weight', 'base_model.encoder.layer.6.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.10.attention.output.dense.weight', 'base_model.encoder.layer.16.attention.self.query.weight', 'base_model.embeddings.position_ids', 'base_model.encoder.layer.21.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.12.attention.output.LayerNorm.weight', 'base_model.encoder.layer.17.attention.self.query.weight', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.18.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.8.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.12.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.14.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.9.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.13.intermediate.dense.weight', 'base_model.encoder.layer.23.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.0.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.12.attention.output.dense.weight', 'base_model.encoder.layer.18.attention.self.query.weight', 'base_model.encoder.layer.22.attention.self.key.weight', 'base_model.encoder.layer.6.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.2.output.LayerNorm.weight', 'base_model.encoder.layer.13.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.21.attention.self.value.weight', 'base_model.encoder.layer.21.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.9.attention.self.value.bias', 'base_model.encoder.layer.15.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.3.output.dense.weight', 'base_model.encoder.layer.12.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.23.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.20.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.10.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.4.output.dense.bias', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.7.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.5.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.17.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.10.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.16.output.LayerNorm.bias', 'base_model.encoder.layer.3.attention.self.key.bias', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.12.attention.self.key.weight', 'base_model.encoder.layer.12.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.23.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.2.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.18.intermediate.dense.bias', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.0.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.16.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.22.attention.self.value.bias', 'base_model.encoder.layer.14.attention.self.key.bias', 'base_model.encoder.layer.22.attention.output.dense.weight', 'base_model.encoder.layer.22.intermediate.dense.bias', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.5.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.9.output.adapters.es.adapter_down.0.weight', 'qa_outputs.bias', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.9.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.3.attention.output.LayerNorm.bias', 'base_model.encoder.layer.8.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.5.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.5.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.12.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.22.attention.self.value.weight', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.3.intermediate.dense.bias', 'base_model.encoder.layer.6.attention.output.dense.weight', 'base_model.encoder.layer.17.attention.self.query.bias', 'base_model.encoder.layer.14.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.0.output.dense.bias', 'base_model.encoder.layer.11.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.3.attention.self.query.weight', 'base_model.encoder.layer.5.attention.self.query.bias', 'base_model.encoder.layer.11.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.14.attention.self.query.bias', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.11.output.LayerNorm.weight', 'base_model.encoder.layer.0.attention.output.dense.bias', 'base_model.encoder.layer.3.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.12.attention.output.LayerNorm.bias', 'base_model.encoder.layer.16.output.LayerNorm.weight', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.19.intermediate.dense.bias', 'base_model.encoder.layer.8.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.1.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.20.attention.output.LayerNorm.weight', 'base_model.encoder.layer.21.output.LayerNorm.bias', 'base_model.encoder.layer.8.output.dense.weight', 'base_model.encoder.layer.16.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.21.intermediate.dense.bias', 'base_model.encoder.layer.11.output.dense.weight', 'base_model.encoder.layer.13.intermediate.dense.bias', 'base_model.encoder.layer.13.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.0.output.adapters.es.adapter_up.weight', 'base_model.embeddings.word_embeddings.weight', 'base_model.encoder.layer.17.attention.self.value.weight', 'base_model.encoder.layer.21.output.LayerNorm.weight', 'base_model.encoder.layer.11.intermediate.dense.weight', 'base_model.encoder.layer.1.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.3.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.20.output.adapters.ep.adapter_down.0.bias', 'base_model.embeddings.token_type_embeddings.weight', 'base_model.encoder.layer.7.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.18.output.LayerNorm.bias', 'base_model.encoder.layer.8.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.6.attention.self.value.bias', 'base_model.encoder.layer.14.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.1.attention.self.key.weight', 'base_model.encoder.layer.4.attention.self.query.bias', 'base_model.encoder.layer.3.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.19.output.LayerNorm.bias', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.16.attention.self.query.bias', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.20.output.dense.weight', 'base_model.encoder.layer.0.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.15.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.7.output.LayerNorm.bias', 'base_model.encoder.layer.16.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.17.intermediate.dense.bias', 'base_model.encoder.layer.11.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.15.intermediate.dense.bias', 'base_model.encoder.layer.5.intermediate.dense.bias', 'base_model.encoder.layer.5.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.18.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.22.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.15.output.LayerNorm.weight', 'base_model.encoder.layer.20.output.LayerNorm.bias', 'base_model.encoder.layer.6.attention.output.LayerNorm.weight', 'base_model.encoder.layer.20.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.0.attention.self.value.weight', 'base_model.encoder.layer.10.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.10.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.11.attention.self.key.bias', 'base_model.encoder.layer.3.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.10.attention.output.dense.bias', 'base_model.encoder.layer.7.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.13.output.LayerNorm.weight', 'base_model.encoder.layer.14.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.17.attention.self.key.weight', 'base_model.pooler.dense.weight', 'base_model.encoder.layer.16.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.20.attention.self.value.weight', 'base_model.encoder.layer.23.attention.output.dense.weight', 'base_model.encoder.layer.1.attention.output.dense.weight', 'base_model.encoder.layer.20.attention.self.value.bias', 'base_model.encoder.layer.0.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.8.attention.self.key.weight', 'base_model.encoder.layer.2.attention.self.key.bias', 'base_model.encoder.layer.13.attention.output.dense.weight', 'base_model.encoder.layer.15.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.18.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.7.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.16.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.2.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.7.attention.self.value.bias', 'base_model.encoder.layer.0.attention.self.query.weight', 'base_model.encoder.layer.13.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.5.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.16.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.19.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.14.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.17.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.4.attention.self.query.weight', 'base_model.encoder.layer.10.attention.self.value.weight', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.1.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.5.attention.output.dense.weight', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.9.attention.output.LayerNorm.bias', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.20.attention.output.LayerNorm.bias', 'base_model.encoder.layer.1.attention.output.LayerNorm.weight', 'base_model.encoder.layer.16.intermediate.dense.weight', 'base_model.encoder.layer.15.attention.self.query.bias', 'base_model.encoder.layer.7.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.9.output.LayerNorm.weight', 'base_model.encoder.layer.6.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.3.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.4.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.3.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.8.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.8.intermediate.dense.weight', 'base_model.encoder.layer.11.attention.output.LayerNorm.weight', 'base_model.encoder.layer.23.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.8.attention.self.query.bias', 'base_model.encoder.layer.7.intermediate.dense.bias', 'base_model.encoder.layer.15.attention.output.LayerNorm.weight', 'base_model.encoder.layer.19.attention.output.dense.bias', 'base_model.encoder.layer.6.attention.output.dense.bias', 'base_model.encoder.layer.14.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.9.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.12.attention.self.query.bias', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.23.attention.output.LayerNorm.weight', 'base_model.encoder.layer.22.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.6.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.14.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.6.attention.self.value.weight', 'base_model.encoder.layer.3.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.4.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.10.attention.self.query.weight', 'base_model.encoder.layer.15.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.9.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.18.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.15.attention.output.dense.bias', 'base_model.encoder.layer.1.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.12.intermediate.dense.bias', 'base_model.encoder.layer.12.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.15.attention.self.value.bias', 'base_model.encoder.layer.16.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.2.intermediate.dense.bias', 'base_model.encoder.layer.7.attention.self.value.weight', 'base_model.encoder.layer.10.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.5.attention.self.query.weight', 'base_model.encoder.layer.12.attention.self.key.bias', 'base_model.encoder.layer.17.attention.output.LayerNorm.weight', 'base_model.encoder.layer.17.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.0.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.13.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.10.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.19.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.21.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.18.attention.self.value.weight', 'base_model.encoder.layer.18.attention.self.value.bias', 'base_model.encoder.layer.10.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.19.output.dense.bias', 'base_model.encoder.layer.10.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.7.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.13.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.10.intermediate.dense.weight', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.11.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.13.attention.self.value.bias', 'base_model.encoder.layer.1.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.18.attention.self.key.weight', 'base_model.encoder.layer.5.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.15.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.15.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.13.attention.self.query.bias', 'base_model.encoder.layer.7.attention.self.query.weight', 'base_model.encoder.layer.9.attention.self.value.weight', 'base_model.encoder.layer.12.output.dense.bias', 'base_model.encoder.layer.0.attention.self.value.bias', 'base_model.encoder.layer.17.output.dense.weight', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.0.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.9.intermediate.dense.bias', 'base_model.encoder.layer.21.output.dense.weight', 'base_model.encoder.layer.4.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.4.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.17.attention.output.dense.bias', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.7.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.11.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.23.attention.self.value.bias', 'base_model.encoder.layer.14.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.10.output.dense.bias', 'base_model.encoder.layer.20.attention.output.dense.bias', 'base_model.encoder.layer.8.attention.output.dense.weight', 'base_model.encoder.layer.12.attention.output.dense.bias', 'base_model.encoder.layer.3.attention.output.LayerNorm.weight', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.14.intermediate.dense.weight', 'base_model.encoder.layer.18.attention.output.LayerNorm.weight', 'base_model.encoder.layer.19.output.LayerNorm.weight', 'base_model.encoder.layer.22.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.3.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.15.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.3.attention.self.value.weight', 'base_model.encoder.layer.6.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.23.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.2.attention.self.value.bias', 'base_model.encoder.layer.7.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.9.attention.output.dense.bias', 'base_model.encoder.layer.4.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.23.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.18.output.dense.weight', 'base_model.encoder.layer.10.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.22.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.23.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.18.attention.output.dense.weight', 'base_model.encoder.layer.10.attention.self.key.weight', 'base_model.encoder.layer.8.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.23.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.2.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.10.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.4.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.17.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.20.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.19.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.3.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.4.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.14.output.LayerNorm.bias', 'base_model.encoder.layer.16.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.0.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.12.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.3.output.LayerNorm.weight', 'base_model.encoder.layer.23.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.12.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.11.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.6.attention.self.key.bias', 'base_model.encoder.layer.13.attention.self.key.weight', 'base_model.encoder.layer.19.attention.output.LayerNorm.bias', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.3.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.9.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.22.output.dense.weight', 'base_model.encoder.layer.23.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.21.output.dense.bias', 'base_model.encoder.layer.6.attention.output.LayerNorm.bias', 'base_model.encoder.layer.5.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.11.attention.output.dense.weight', 'base_model.encoder.layer.18.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.16.attention.self.value.bias', 'base_model.encoder.layer.2.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.5.attention.self.value.bias', 'base_model.encoder.layer.9.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.11.attention.self.value.bias', 'base_model.encoder.layer.7.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.20.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.22.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.7.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.5.attention.output.LayerNorm.bias', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.1.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.22.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.17.attention.self.key.bias', 'base_model.encoder.layer.22.attention.output.LayerNorm.bias', 'base_model.encoder.layer.2.attention.output.dense.bias', 'base_model.encoder.layer.14.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.23.output.LayerNorm.bias', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.8.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.18.attention.self.query.bias', 'base_model.encoder.layer.19.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.16.attention.output.LayerNorm.weight', 'base_model.encoder.layer.18.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.18.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.4.output.LayerNorm.bias', 'base_model.encoder.layer.5.attention.output.LayerNorm.weight', 'base_model.encoder.layer.8.output.LayerNorm.weight', 'base_model.encoder.layer.9.intermediate.dense.weight', 'base_model.encoder.layer.7.attention.self.key.weight', 'base_model.encoder.layer.17.attention.self.value.bias', 'base_model.encoder.layer.7.output.LayerNorm.weight', 'base_model.encoder.layer.8.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.0.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.4.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.4.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.21.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.0.output.LayerNorm.weight', 'base_model.encoder.layer.23.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.3.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.14.attention.output.dense.bias', 'base_model.encoder.layer.13.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.22.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.19.attention.self.query.bias', 'base_model.encoder.layer.19.attention.self.value.bias', 'base_model.encoder.layer.9.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.14.attention.self.key.weight', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.1.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.0.output.LayerNorm.bias', 'base_model.encoder.layer.15.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.1.output.LayerNorm.bias', 'base_model.encoder.layer.16.attention.output.dense.weight', 'base_model.encoder.layer.19.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.2.attention.output.LayerNorm.bias', 'base_model.encoder.layer.1.attention.self.query.weight', 'base_model.encoder.layer.0.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.4.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.22.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.21.attention.self.key.weight', 'base_model.encoder.layer.13.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.22.attention.self.key.bias', 'base_model.encoder.layer.20.attention.self.query.bias', 'base_model.encoder.layer.8.attention.self.key.bias', 'base_model.encoder.layer.21.attention.output.dense.weight', 'base_model.encoder.layer.23.attention.output.LayerNorm.bias', 'base_model.encoder.layer.1.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.4.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.23.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.6.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.6.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.14.attention.self.query.weight', 'base_model.encoder.layer.17.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.11.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.13.attention.output.LayerNorm.bias', 'base_model.encoder.layer.23.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.14.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.1.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.7.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.8.output.LayerNorm.bias', 'base_model.encoder.layer.6.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.11.output.LayerNorm.bias', 'base_model.encoder.layer.15.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.9.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.9.attention.self.query.weight', 'base_model.encoder.layer.18.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.4.intermediate.dense.weight', 'base_model.encoder.layer.20.output.LayerNorm.weight', 'base_model.encoder.layer.21.attention.self.key.bias', 'base_model.encoder.layer.16.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.1.attention.output.dense.bias', 'base_model.encoder.layer.13.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.2.output.dense.bias', 'base_model.encoder.layer.21.attention.output.LayerNorm.weight', 'base_model.encoder.layer.17.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.6.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.23.intermediate.dense.weight', 'base_model.encoder.layer.16.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.19.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.21.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.16.attention.output.dense.bias', 'base_model.encoder.layer.16.attention.self.key.bias', 'base_model.encoder.layer.17.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.22.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.16.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.3.output.dense.bias', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.4.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.17.output.LayerNorm.bias', 'base_model.encoder.layer.21.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.23.attention.self.key.bias', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.0.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.3.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.11.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.18.output.dense.bias', 'base_model.encoder.layer.22.attention.output.LayerNorm.weight', 'base_model.encoder.layer.23.output.dense.weight', 'base_model.encoder.layer.8.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.2.attention.output.dense.weight', 'qa_outputs.weight', 'base_model.encoder.layer.4.output.LayerNorm.weight', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.14.intermediate.dense.bias', 'base_model.encoder.layer.2.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.13.output.dense.bias', 'base_model.encoder.layer.8.attention.output.dense.bias', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.11.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.9.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.11.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.11.attention.output.LayerNorm.bias', 'base_model.encoder.layer.18.attention.output.dense.bias', 'base_model.encoder.layer.0.attention.output.LayerNorm.bias', 'base_model.encoder.layer.1.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.12.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.1.output.dense.weight', 'base_model.encoder.layer.5.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.0.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.4.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.16.output.dense.bias', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.8.output.dense.bias', 'base_model.encoder.layer.4.intermediate.dense.bias', 'base_model.encoder.layer.2.attention.self.value.weight', 'base_model.encoder.layer.17.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.11.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.15.attention.output.LayerNorm.bias', 'base_model.encoder.layer.6.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.23.attention.self.key.weight', 'base_model.encoder.layer.2.attention.self.query.bias', 'base_model.encoder.layer.20.output.dense.bias', 'base_model.encoder.layer.22.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.1.attention.self.value.bias', 'base_model.encoder.layer.8.attention.output.LayerNorm.weight', 'base_model.encoder.layer.4.attention.self.value.bias', 'base_model.encoder.layer.23.attention.self.query.bias', 'base_model.encoder.layer.10.attention.output.LayerNorm.bias', 'base_model.encoder.layer.2.output.LayerNorm.bias', 'base_model.encoder.layer.3.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.8.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.13.attention.self.value.weight', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.18.output.LayerNorm.weight', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.13.output.LayerNorm.bias', 'base_model.encoder.layer.8.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.20.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.21.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.15.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.8.attention.self.query.weight', 'base_model.encoder.layer.11.attention.self.value.weight', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.14.attention.self.value.weight', 'base_model.encoder.layer.1.attention.self.key.bias', 'base_model.encoder.layer.15.output.dense.weight', 'base_model.encoder.layer.1.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.3.attention.self.value.bias', 'base_model.encoder.layer.4.attention.self.key.bias', 'base_model.encoder.layer.8.attention.self.value.bias', 'base_model.encoder.layer.15.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.10.output.dense.weight', 'base_model.encoder.layer.6.attention.self.query.bias', 'base_model.encoder.layer.22.intermediate.dense.weight', 'base_model.encoder.layer.0.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.1.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.6.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.11.attention.self.query.weight', 'base_model.encoder.layer.13.attention.output.LayerNorm.weight', 'base_model.encoder.layer.12.attention.self.value.bias', 'base_model.encoder.layer.19.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.12.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.16.output.dense.weight', 'base_model.encoder.layer.19.attention.self.key.bias', 'base_model.encoder.layer.17.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.17.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.21.attention.self.value.bias', 'base_model.encoder.layer.21.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.18.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.14.attention.self.value.bias', 'base_model.encoder.layer.17.intermediate.dense.weight', 'base_model.encoder.layer.11.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.17.output.LayerNorm.weight', 'base_model.encoder.layer.17.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.10.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.21.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.7.output.dense.weight', 'base_model.encoder.layer.21.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.16.attention.self.value.weight', 'base_model.encoder.layer.5.output.LayerNorm.bias', 'base_model.encoder.layer.4.attention.self.key.weight', 'base_model.encoder.layer.5.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.9.attention.self.key.weight', 'base_model.encoder.layer.19.intermediate.dense.weight', 'base_model.encoder.layer.1.output.dense.bias', 'base_model.encoder.layer.2.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.2.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.7.intermediate.dense.weight', 'base_model.encoder.layer.12.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.7.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.20.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.18.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.4.attention.output.dense.weight', 'base_model.encoder.layer.23.intermediate.dense.bias', 'base_model.encoder.layer.17.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.15.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.1.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.0.intermediate.dense.bias', 'base_model.encoder.layer.20.intermediate.dense.bias', 'base_model.encoder.layer.0.attention.self.query.bias', 'base_model.encoder.layer.10.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.5.output.dense.weight', 'base_model.encoder.layer.12.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.4.attention.output.LayerNorm.bias', 'base_model.encoder.layer.11.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.21.intermediate.dense.weight', 'base_model.encoder.layer.9.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.20.intermediate.dense.weight', 'base_model.encoder.layer.22.output.dense.bias', 'base_model.encoder.layer.2.attention.output.LayerNorm.weight', 'base_model.encoder.layer.1.output.LayerNorm.weight', 'base_model.encoder.layer.5.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.5.output.LayerNorm.weight', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.21.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.3.intermediate.dense.weight', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.22.attention.self.query.weight', 'base_model.encoder.layer.13.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.16.intermediate.dense.bias', 'base_model.encoder.layer.8.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.15.output.dense.bias', 'base_model.encoder.layer.2.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.2.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.13.attention.self.key.bias', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.22.output.LayerNorm.weight', 'base_model.encoder.layer.9.output.LayerNorm.bias', 'base_model.encoder.layer.6.output.LayerNorm.bias', 'base_model.encoder.layer.19.attention.self.key.weight', 'base_model.encoder.layer.7.attention.self.key.bias', 'base_model.encoder.layer.2.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.10.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.11.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.2.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.6.output.LayerNorm.weight', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.14.output.LayerNorm.weight', 'base_model.encoder.layer.23.attention.self.query.weight', 'base_model.encoder.layer.14.attention.output.dense.weight', 'base_model.encoder.layer.7.attention.output.LayerNorm.weight', 'base_model.encoder.layer.1.intermediate.dense.bias', 'base_model.encoder.layer.12.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.5.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.0.intermediate.dense.weight', 'base_model.encoder.layer.3.attention.self.key.weight', 'base_model.encoder.layer.16.attention.self.key.weight', 'base_model.encoder.layer.20.attention.self.key.weight', 'base_model.encoder.layer.5.intermediate.dense.weight', 'base_model.encoder.layer.5.output.adapters.ep.adapter_up.bias', 'base_model.embeddings.position_embeddings.weight', 'base_model.encoder.layer.9.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.18.attention.self.key.bias', 'base_model.encoder.layer.3.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.17.attention.output.LayerNorm.bias', 'base_model.encoder.layer.11.attention.output.dense.bias', 'base_model.encoder.layer.17.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.1.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.6.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.16.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.11.output.dense.bias', 'base_model.encoder.layer.13.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.14.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.21.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.7.output.dense.bias', 'base_model.encoder.layer.18.intermediate.dense.weight', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.12.output.LayerNorm.bias', 'base_model.encoder.layer.4.output.dense.weight', 'base_model.encoder.layer.7.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.1.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.21.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.19.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.19.attention.output.LayerNorm.weight', 'base_model.encoder.layer.14.attention.output.LayerNorm.weight', 'base_model.encoder.layer.15.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.22.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.9.attention.output.LayerNorm.weight', 'base_model.encoder.layer.5.attention.self.key.bias', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.3.attention.output.dense.bias', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.0.attention.self.key.bias', 'base_model.encoder.layer.20.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.13.output.dense.weight', 'base_model.encoder.layer.19.attention.output.dense.weight', 'base_model.encoder.layer.15.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.19.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.13.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.13.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.0.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.19.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.11.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.6.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.9.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.16.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.18.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.0.attention.output.dense.weight', 'base_model.encoder.layer.20.attention.self.query.weight', 'base_model.encoder.layer.6.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.13.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.19.attention.self.value.weight', 'base_model.encoder.layer.20.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.10.attention.self.value.bias', 'base_model.encoder.layer.13.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.12.attention.self.value.weight', 'base_model.encoder.layer.22.output.LayerNorm.bias', 'base_model.encoder.layer.10.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.16.attention.output.LayerNorm.bias', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.10.output.LayerNorm.weight', 'base_model.encoder.layer.16.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.12.intermediate.dense.weight', 'base_model.encoder.layer.21.attention.self.query.bias', 'base_model.encoder.layer.21.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.22.attention.self.query.bias', 'base_model.encoder.layer.0.attention.output.LayerNorm.weight', 'base_model.encoder.layer.4.attention.output.dense.bias', 'base_model.encoder.layer.3.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.7.attention.output.dense.bias', 'base_model.encoder.layer.10.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.16.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.18.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.2.attention.self.query.weight', 'base_model.encoder.layer.4.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.9.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.20.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.21.attention.output.dense.bias', 'base_model.encoder.layer.20.attention.self.key.bias', 'base_model.encoder.layer.15.attention.self.key.bias', 'base_model.encoder.layer.20.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.5.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.16.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.3.output.LayerNorm.bias', 'base_model.encoder.layer.15.attention.self.query.weight', 'base_model.encoder.layer.19.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.15.attention.self.value.weight', 'base_model.encoder.layer.7.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.23.output.dense.bias', 'base_model.encoder.layer.19.attention.self.query.weight', 'base_model.encoder.layer.19.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.6.intermediate.dense.bias', 'base_model.encoder.layer.11.attention.self.query.bias', 'base_model.encoder.layer.19.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.12.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.0.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.18.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.19.output.dense.weight', 'base_model.encoder.layer.13.attention.output.dense.bias', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.20.attention.output.dense.weight']
- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of XLMRobertaModel were not initialized from the model checkpoint at /cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//squad/xlm-KG_LR3e-5_EPOCH2.0_maxlen384_batchsize4_gradacc4 and are newly initialized: ['encoder.layer.14.intermediate.dense.bias', 'encoder.layer.16.attention.self.key.bias', 'encoder.layer.5.attention.output.LayerNorm.weight', 'encoder.layer.8.attention.output.dense.weight', 'encoder.layer.15.attention.output.dense.weight', 'encoder.layer.21.attention.output.dense.bias', 'encoder.layer.22.attention.self.query.bias', 'encoder.layer.8.attention.self.key.bias', 'encoder.layer.20.attention.output.dense.bias', 'encoder.layer.17.attention.self.value.bias', 'encoder.layer.0.attention.output.LayerNorm.weight', 'encoder.layer.8.attention.self.value.weight', 'encoder.layer.23.output.LayerNorm.bias', 'encoder.layer.17.output.dense.bias', 'encoder.layer.4.attention.output.LayerNorm.weight', 'encoder.layer.7.output.dense.bias', 'encoder.layer.19.attention.self.key.weight', 'encoder.layer.16.attention.output.dense.weight', 'encoder.layer.3.attention.self.key.weight', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.10.attention.self.query.bias', 'encoder.layer.10.attention.output.LayerNorm.bias', 'encoder.layer.22.output.LayerNorm.weight', 'encoder.layer.16.intermediate.dense.weight', 'encoder.layer.18.intermediate.dense.bias', 'encoder.layer.20.output.LayerNorm.weight', 'encoder.layer.11.attention.output.dense.bias', 'encoder.layer.1.attention.output.LayerNorm.weight', 'encoder.layer.16.output.dense.weight', 'encoder.layer.14.attention.self.query.bias', 'encoder.layer.3.attention.self.value.bias', 'encoder.layer.23.attention.output.dense.weight', 'encoder.layer.10.attention.output.dense.weight', 'encoder.layer.7.attention.output.dense.bias', 'encoder.layer.3.attention.self.query.bias', 'encoder.layer.11.output.LayerNorm.bias', 'encoder.layer.14.attention.output.dense.weight', 'encoder.layer.18.output.dense.weight', 'encoder.layer.16.attention.output.dense.bias', 'encoder.layer.23.attention.self.key.bias', 'encoder.layer.23.attention.self.value.weight', 'encoder.layer.22.attention.output.LayerNorm.bias', 'encoder.layer.14.attention.self.query.weight', 'encoder.layer.14.attention.self.key.bias', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.18.output.LayerNorm.bias', 'encoder.layer.12.attention.self.value.weight', 'encoder.layer.20.intermediate.dense.weight', 'encoder.layer.20.attention.self.key.bias', 'encoder.layer.2.output.dense.bias', 'encoder.layer.8.attention.self.query.bias', 'encoder.layer.8.output.LayerNorm.bias', 'encoder.layer.5.attention.self.query.weight', 'encoder.layer.13.attention.output.dense.bias', 'encoder.layer.5.attention.self.key.bias', 'encoder.layer.13.attention.output.LayerNorm.weight', 'encoder.layer.13.output.LayerNorm.weight', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.14.attention.self.key.weight', 'encoder.layer.10.attention.self.key.weight', 'encoder.layer.4.output.dense.bias', 'encoder.layer.13.attention.self.value.weight', 'encoder.layer.9.attention.output.dense.weight', 'encoder.layer.11.attention.self.value.bias', 'encoder.layer.10.attention.self.value.weight', 'encoder.layer.12.output.LayerNorm.weight', 'encoder.layer.4.attention.self.key.weight', 'encoder.layer.13.attention.self.key.bias', 'encoder.layer.1.attention.self.query.bias', 'encoder.layer.4.attention.output.LayerNorm.bias', 'encoder.layer.15.intermediate.dense.bias', 'encoder.layer.16.output.LayerNorm.weight', 'encoder.layer.0.attention.self.query.weight', 'encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.layer.4.attention.self.query.weight', 'encoder.layer.13.attention.self.query.weight', 'encoder.layer.10.output.LayerNorm.weight', 'encoder.layer.21.intermediate.dense.weight', 'encoder.layer.7.attention.self.value.weight', 'encoder.layer.22.intermediate.dense.bias', 'encoder.layer.19.attention.output.dense.bias', 'encoder.layer.6.attention.output.dense.weight', 'encoder.layer.7.attention.output.dense.weight', 'encoder.layer.18.intermediate.dense.weight', 'encoder.layer.5.attention.self.query.bias', 'encoder.layer.1.attention.self.key.bias', 'encoder.layer.7.attention.self.key.bias', 'encoder.layer.2.attention.output.dense.bias', 'encoder.layer.12.attention.self.key.weight', 'encoder.layer.9.attention.self.query.weight', 'encoder.layer.9.attention.self.query.bias', 'encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.layer.14.output.dense.bias', 'encoder.layer.15.output.LayerNorm.bias', 'encoder.layer.9.output.dense.weight', 'encoder.layer.4.output.dense.weight', 'encoder.layer.23.output.dense.bias', 'encoder.layer.22.attention.output.dense.weight', 'encoder.layer.16.output.dense.bias', 'encoder.layer.23.attention.self.key.weight', 'encoder.layer.8.attention.self.key.weight', 'encoder.layer.21.output.LayerNorm.weight', 'encoder.layer.1.attention.self.value.weight', 'encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.layer.16.attention.self.value.weight', 'encoder.layer.4.attention.self.value.weight', 'encoder.layer.9.attention.self.value.weight', 'encoder.layer.4.attention.self.query.bias', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.13.intermediate.dense.weight', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.6.attention.output.LayerNorm.bias', 'encoder.layer.21.intermediate.dense.bias', 'encoder.layer.19.attention.output.LayerNorm.weight', 'encoder.layer.2.attention.output.dense.weight', 'encoder.layer.12.attention.output.LayerNorm.weight', 'encoder.layer.2.attention.self.key.weight', 'encoder.layer.5.output.dense.bias', 'encoder.layer.17.attention.output.LayerNorm.bias', 'encoder.layer.4.attention.output.dense.bias', 'encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.layer.0.attention.output.dense.bias', 'encoder.layer.4.attention.self.value.bias', 'encoder.layer.13.attention.output.dense.weight', 'encoder.layer.7.output.LayerNorm.weight', 'encoder.layer.19.output.dense.bias', 'encoder.layer.6.attention.self.value.bias', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.20.output.dense.weight', 'encoder.layer.18.attention.self.value.bias', 'encoder.layer.16.attention.self.query.weight', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.5.attention.output.dense.bias', 'embeddings.position_embeddings.weight', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.12.output.dense.weight', 'encoder.layer.19.output.LayerNorm.bias', 'encoder.layer.12.intermediate.dense.bias', 'encoder.layer.8.attention.output.dense.bias', 'encoder.layer.14.output.LayerNorm.weight', 'encoder.layer.11.attention.self.value.weight', 'encoder.layer.17.attention.output.dense.bias', 'encoder.layer.12.attention.output.dense.weight', 'encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.15.attention.self.key.weight', 'encoder.layer.18.attention.output.dense.weight', 'encoder.layer.2.attention.self.value.weight', 'encoder.layer.12.attention.output.LayerNorm.bias', 'encoder.layer.5.attention.self.key.weight', 'encoder.layer.23.attention.self.value.bias', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.8.attention.output.LayerNorm.bias', 'encoder.layer.19.attention.self.key.bias', 'encoder.layer.21.attention.self.query.weight', 'encoder.layer.0.attention.self.query.bias', 'encoder.layer.15.attention.self.value.bias', 'encoder.layer.19.intermediate.dense.weight', 'encoder.layer.15.attention.self.query.weight', 'encoder.layer.19.intermediate.dense.bias', 'encoder.layer.0.attention.self.value.bias', 'encoder.layer.2.attention.self.key.bias', 'encoder.layer.23.intermediate.dense.bias', 'encoder.layer.2.output.dense.weight', 'encoder.layer.3.attention.output.dense.weight', 'encoder.layer.22.attention.self.key.weight', 'encoder.layer.21.attention.self.key.weight', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.6.attention.output.LayerNorm.weight', 'encoder.layer.7.attention.self.key.weight', 'encoder.layer.23.attention.self.query.bias', 'encoder.layer.22.attention.self.query.weight', 'encoder.layer.18.attention.output.dense.bias', 'encoder.layer.2.attention.self.value.bias', 'encoder.layer.9.attention.self.key.weight', 'encoder.layer.8.output.LayerNorm.weight', 'encoder.layer.17.attention.self.value.weight', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.21.output.LayerNorm.bias', 'encoder.layer.14.attention.output.LayerNorm.weight', 'encoder.layer.9.output.LayerNorm.weight', 'encoder.layer.6.output.dense.weight', 'encoder.layer.18.attention.output.LayerNorm.bias', 'encoder.layer.8.output.dense.bias', 'encoder.layer.16.intermediate.dense.bias', 'encoder.layer.10.output.dense.weight', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.13.attention.output.LayerNorm.bias', 'encoder.layer.10.attention.output.dense.bias', 'encoder.layer.11.attention.self.query.weight', 'encoder.layer.22.intermediate.dense.weight', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.11.attention.self.query.bias', 'encoder.layer.15.output.dense.weight', 'encoder.layer.15.output.LayerNorm.weight', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.7.attention.output.LayerNorm.weight', 'encoder.layer.23.attention.output.LayerNorm.weight', 'encoder.layer.17.attention.output.LayerNorm.weight', 'encoder.layer.21.attention.self.value.weight', 'encoder.layer.5.output.dense.weight', 'encoder.layer.23.attention.output.LayerNorm.bias', 'encoder.layer.21.attention.output.LayerNorm.weight', 'encoder.layer.6.output.LayerNorm.bias', 'encoder.layer.14.attention.output.LayerNorm.bias', 'encoder.layer.21.attention.output.dense.weight', 'encoder.layer.17.attention.self.key.bias', 'encoder.layer.17.attention.self.query.weight', 'encoder.layer.9.attention.self.value.bias', 'encoder.layer.21.attention.output.LayerNorm.bias', 'encoder.layer.14.output.LayerNorm.bias', 'encoder.layer.17.attention.self.key.weight', 'encoder.layer.19.attention.self.query.bias', 'encoder.layer.6.attention.self.key.bias', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.3.attention.self.key.bias', 'encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.layer.1.attention.output.dense.weight', 'encoder.layer.16.attention.self.value.bias', 'encoder.layer.3.attention.self.query.weight', 'encoder.layer.7.output.dense.weight', 'encoder.layer.20.attention.self.query.weight', 'encoder.layer.17.attention.output.dense.weight', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.1.output.dense.bias', 'encoder.layer.10.attention.self.query.weight', 'encoder.layer.7.attention.self.query.bias', 'encoder.layer.3.output.dense.weight', 'encoder.layer.19.output.dense.weight', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.20.attention.self.key.weight', 'encoder.layer.1.attention.self.value.bias', 'encoder.layer.0.attention.output.dense.weight', 'encoder.layer.9.attention.output.LayerNorm.weight', 'encoder.layer.18.output.LayerNorm.weight', 'embeddings.LayerNorm.weight', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.0.output.dense.weight', 'encoder.layer.13.attention.self.query.bias', 'encoder.layer.20.intermediate.dense.bias', 'encoder.layer.18.attention.self.query.weight', 'encoder.layer.20.attention.output.LayerNorm.bias', 'encoder.layer.15.attention.output.dense.bias', 'encoder.layer.19.attention.self.value.weight', 'embeddings.token_type_embeddings.weight', 'encoder.layer.9.attention.output.dense.bias', 'encoder.layer.12.output.LayerNorm.bias', 'encoder.layer.17.output.LayerNorm.bias', 'encoder.layer.5.attention.self.value.weight', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.layer.19.attention.output.LayerNorm.bias', 'encoder.layer.14.attention.output.dense.bias', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.13.attention.self.value.bias', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.15.intermediate.dense.weight', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.17.attention.self.query.bias', 'encoder.layer.14.attention.self.value.bias', 'encoder.layer.18.attention.output.LayerNorm.weight', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.17.output.LayerNorm.weight', 'encoder.layer.11.output.LayerNorm.weight', 'encoder.layer.8.attention.output.LayerNorm.weight', 'encoder.layer.10.attention.self.key.bias', 'encoder.layer.15.attention.self.query.bias', 'encoder.layer.22.output.LayerNorm.bias', 'encoder.layer.23.attention.self.query.weight', 'encoder.layer.7.intermediate.dense.bias', 'encoder.layer.3.output.dense.bias', 'encoder.layer.8.output.dense.weight', 'encoder.layer.15.attention.output.LayerNorm.weight', 'encoder.layer.20.attention.output.LayerNorm.weight', 'encoder.layer.11.attention.self.key.bias', 'encoder.layer.2.attention.output.LayerNorm.bias', 'encoder.layer.17.intermediate.dense.bias', 'encoder.layer.2.attention.self.query.weight', 'encoder.layer.13.output.dense.bias', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.22.attention.self.key.bias', 'encoder.layer.18.attention.self.key.weight', 'encoder.layer.1.attention.self.query.weight', 'encoder.layer.10.attention.output.LayerNorm.weight', 'embeddings.word_embeddings.weight', 'pooler.dense.bias', 'encoder.layer.10.attention.self.value.bias', 'encoder.layer.12.attention.self.query.weight', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.2.attention.output.LayerNorm.weight', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.20.output.dense.bias', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.23.intermediate.dense.weight', 'encoder.layer.6.attention.self.value.weight', 'encoder.layer.12.attention.self.value.bias', 'encoder.layer.1.output.dense.weight', 'encoder.layer.17.intermediate.dense.weight', 'encoder.layer.10.intermediate.dense.weight', 'encoder.layer.23.output.dense.weight', 'encoder.layer.22.output.dense.bias', 'encoder.layer.18.attention.self.key.bias', 'encoder.layer.7.attention.self.value.bias', 'encoder.layer.21.attention.self.query.bias', 'encoder.layer.14.intermediate.dense.weight', 'encoder.layer.20.attention.self.value.weight', 'encoder.layer.3.attention.output.dense.bias', 'encoder.layer.18.output.dense.bias', 'encoder.layer.17.output.dense.weight', 'encoder.layer.20.attention.output.dense.weight', 'encoder.layer.12.attention.self.query.bias', 'encoder.layer.13.attention.self.key.weight', 'encoder.layer.5.attention.self.value.bias', 'encoder.layer.7.attention.self.query.weight', 'encoder.layer.13.output.dense.weight', 'encoder.layer.23.output.LayerNorm.weight', 'encoder.layer.10.output.LayerNorm.bias', 'encoder.layer.2.attention.self.query.bias', 'encoder.layer.16.attention.self.query.bias', 'encoder.layer.6.attention.self.query.bias', 'encoder.layer.13.intermediate.dense.bias', 'encoder.layer.0.output.dense.bias', 'encoder.layer.19.attention.self.value.bias', 'encoder.layer.16.output.LayerNorm.bias', 'encoder.layer.21.output.dense.weight', 'encoder.layer.1.attention.output.dense.bias', 'encoder.layer.12.attention.self.key.bias', 'encoder.layer.12.intermediate.dense.weight', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.20.attention.self.value.bias', 'encoder.layer.6.attention.output.dense.bias', 'encoder.layer.22.output.dense.weight', 'encoder.layer.16.attention.output.LayerNorm.bias', 'encoder.layer.15.attention.output.LayerNorm.bias', 'encoder.layer.0.attention.self.key.bias', 'encoder.layer.0.attention.self.value.weight', 'encoder.layer.20.output.LayerNorm.bias', 'encoder.layer.16.attention.self.key.weight', 'encoder.layer.9.output.LayerNorm.bias', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.16.attention.output.LayerNorm.weight', 'encoder.layer.9.output.dense.bias', 'embeddings.LayerNorm.bias', 'encoder.layer.9.attention.self.key.bias', 'encoder.layer.23.attention.output.dense.bias', 'encoder.layer.8.attention.self.value.bias', 'encoder.layer.14.attention.self.value.weight', 'encoder.layer.15.output.dense.bias', 'encoder.layer.6.attention.self.query.weight', 'encoder.layer.22.attention.output.dense.bias', 'encoder.layer.3.attention.self.value.weight', 'encoder.layer.22.attention.self.value.weight', 'encoder.layer.11.attention.self.key.weight', 'encoder.layer.18.attention.self.value.weight', 'encoder.layer.19.attention.output.dense.weight', 'encoder.layer.6.attention.self.key.weight', 'encoder.layer.11.output.dense.weight', 'encoder.layer.1.attention.self.key.weight', 'pooler.dense.weight', 'encoder.layer.13.output.LayerNorm.bias', 'encoder.layer.21.attention.self.key.bias', 'encoder.layer.5.output.LayerNorm.bias', 'encoder.layer.5.attention.output.dense.weight', 'encoder.layer.9.attention.output.LayerNorm.bias', 'encoder.layer.11.attention.output.LayerNorm.weight', 'encoder.layer.15.attention.self.value.weight', 'encoder.layer.11.output.dense.bias', 'encoder.layer.0.attention.self.key.weight', 'encoder.layer.11.attention.output.dense.weight', 'encoder.layer.8.attention.self.query.weight', 'encoder.layer.7.output.LayerNorm.bias', 'encoder.layer.18.attention.self.query.bias', 'encoder.layer.20.attention.self.query.bias', 'encoder.layer.4.attention.output.dense.weight', 'encoder.layer.15.attention.self.key.bias', 'encoder.layer.21.output.dense.bias', 'encoder.layer.4.attention.self.key.bias', 'encoder.layer.10.output.dense.bias', 'encoder.layer.19.attention.self.query.weight', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.21.attention.self.value.bias', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.7.attention.output.LayerNorm.bias', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.12.output.dense.bias', 'encoder.layer.19.output.LayerNorm.weight', 'encoder.layer.14.output.dense.weight', 'encoder.layer.22.attention.self.value.bias', 'encoder.layer.12.attention.output.dense.bias', 'encoder.layer.22.attention.output.LayerNorm.weight', 'encoder.layer.6.output.dense.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Overwriting existing adapter 'ep'.
Overwriting existing adapter 'tp'.
Overwriting existing adapter 'es'.
Overwriting existing adapter 'ts'.
Overwriting existing adapter fusion module 'ep,tp,es,ts'
05/09/2022 09:13:56 - INFO - __main__ -   Creating features from dataset file at .
/cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//squad/xlm-KG_LR3e-5_EPOCH2.0_maxlen384_batchsize4_gradacc4
XLMConfig {
  "architectures": [
    "XLMRobertaForMaskedLM"
  ],
  "asm": false,
  "attention_dropout": 0.1,
  "attention_probs_dropout_prob": 0.1,
  "bos_index": 0,
  "bos_token_id": 0,
  "causal": false,
  "dropout": 0.1,
  "emb_dim": 1024,
  "embed_init_std": 0.02209708691207961,
  "end_n_top": 5,
  "eos_index": 1,
  "eos_token_id": 2,
  "gelu_activation": true,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "init_std": 0.02,
  "initializer_range": 0.02,
  "intermediate_size": 4096,
  "is_encoder": true,
  "lang_id": 0,
  "layer_norm_eps": 1e-05,
  "mask_index": 5,
  "mask_token_id": 0,
  "max_position_embeddings": 514,
  "model_type": "xlm",
  "n_heads": 16,
  "n_langs": 1,
  "n_layers": 24,
  "output_past": true,
  "pad_index": 2,
  "pad_token_id": 1,
  "sinusoidal_embeddings": false,
  "start_n_top": 5,
  "summary_activation": null,
  "summary_first_dropout": 0.1,
  "summary_proj_to_labels": true,
  "summary_type": "first",
  "summary_use_proj": true,
  "transformers_version": "4.17.0",
  "type_vocab_size": 1,
  "unk_index": 3,
  "use_lang_emb": false,
  "vocab_size": 250002
}

  0%|          | 0/48 [00:00<?, ?it/s] 21%|██        | 10/48 [00:00<00:00, 96.71it/s] 42%|████▏     | 20/48 [00:00<00:00, 73.56it/s] 58%|█████▊    | 28/48 [00:00<00:00, 69.20it/s] 77%|███████▋  | 37/48 [00:00<00:00, 73.81it/s]100%|██████████| 48/48 [00:00<00:00, 82.75it/s]100%|██████████| 48/48 [00:00<00:00, 79.09it/s]
convert squad examples to features:   0%|          | 0/1190 [00:00<?, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.
convert squad examples to features:   0%|          | 1/1190 [00:00<08:19,  2.38it/s]convert squad examples to features:   3%|▎         | 33/1190 [00:00<00:15, 75.01it/s]convert squad examples to features:   5%|▌         | 65/1190 [00:00<00:12, 92.85it/s]convert squad examples to features:   8%|▊         | 97/1190 [00:01<00:09, 110.19it/s]convert squad examples to features:  11%|█         | 129/1190 [00:01<00:07, 134.56it/s]convert squad examples to features:  14%|█▎        | 161/1190 [00:01<00:06, 149.51it/s]convert squad examples to features:  16%|█▌        | 193/1190 [00:01<00:06, 164.64it/s]convert squad examples to features:  19%|█▉        | 225/1190 [00:01<00:06, 157.31it/s]convert squad examples to features:  22%|██▏       | 257/1190 [00:02<00:06, 139.33it/s]convert squad examples to features:  24%|██▍       | 289/1190 [00:02<00:06, 144.17it/s]convert squad examples to features:  27%|██▋       | 321/1190 [00:02<00:06, 136.08it/s]convert squad examples to features:  30%|██▉       | 353/1190 [00:02<00:05, 141.70it/s]convert squad examples to features:  32%|███▏      | 385/1190 [00:03<00:11, 70.24it/s] convert squad examples to features:  35%|███▌      | 417/1190 [00:03<00:09, 80.34it/s]convert squad examples to features:  38%|███▊      | 449/1190 [00:04<00:08, 86.79it/s]convert squad examples to features:  40%|████      | 481/1190 [00:04<00:07, 92.98it/s]convert squad examples to features:  43%|████▎     | 513/1190 [00:04<00:06, 97.69it/s]convert squad examples to features:  46%|████▌     | 545/1190 [00:05<00:06, 100.98it/s]convert squad examples to features:  48%|████▊     | 577/1190 [00:05<00:05, 108.35it/s]convert squad examples to features:  51%|█████     | 609/1190 [00:05<00:05, 107.94it/s]convert squad examples to features:  54%|█████▍    | 641/1190 [00:06<00:05, 107.15it/s]convert squad examples to features:  57%|█████▋    | 673/1190 [00:06<00:05, 103.38it/s]convert squad examples to features:  59%|█████▉    | 705/1190 [00:06<00:04, 106.06it/s]convert squad examples to features:  62%|██████▏   | 737/1190 [00:06<00:04, 111.77it/s]convert squad examples to features:  65%|██████▍   | 769/1190 [00:07<00:03, 120.41it/s]convert squad examples to features:  67%|██████▋   | 801/1190 [00:07<00:02, 132.17it/s]convert squad examples to features:  70%|███████   | 833/1190 [00:07<00:03, 116.04it/s]convert squad examples to features:  73%|███████▎  | 865/1190 [00:07<00:02, 118.47it/s]convert squad examples to features:  75%|███████▌  | 897/1190 [00:08<00:02, 114.62it/s]convert squad examples to features:  78%|███████▊  | 929/1190 [00:08<00:02, 107.44it/s]convert squad examples to features:  81%|████████  | 961/1190 [00:08<00:01, 119.62it/s]convert squad examples to features:  83%|████████▎ | 993/1190 [00:08<00:01, 125.92it/s]convert squad examples to features:  86%|████████▌ | 1025/1190 [00:09<00:01, 135.44it/s]convert squad examples to features:  89%|████████▉ | 1057/1190 [00:09<00:00, 144.33it/s]convert squad examples to features:  92%|█████████▏| 1089/1190 [00:09<00:00, 137.74it/s]convert squad examples to features:  94%|█████████▍| 1121/1190 [00:09<00:00, 131.23it/s]convert squad examples to features:  97%|█████████▋| 1153/1190 [00:10<00:00, 125.11it/s]convert squad examples to features: 100%|██████████| 1190/1190 [00:10<00:00, 117.18it/s]/cluster/project/sachan/yifan/softwares/anaconda/anaconda3/envs/xfactr/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2272: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

add example index and unique id:   0%|          | 0/1190 [00:00<?, ?it/s]add example index and unique id: 100%|██████████| 1190/1190 [00:00<00:00, 511290.90it/s]
05/09/2022 09:14:07 - INFO - __main__ -   Saving features into cached file ./cached_xquad.vi.json_xlm-KG_LR3e-5_EPOCH2.0_maxlen384_batchsize4_gradacc4_384_vi
05/09/2022 09:14:09 - INFO - __main__ -   ***** Running evaluation  *****
05/09/2022 09:14:09 - INFO - __main__ -     Num examples = 1314
05/09/2022 09:14:09 - INFO - __main__ -     Batch size = 8
Evaluating:   0%|          | 0/165 [00:00<?, ?it/s]Evaluating:   1%|          | 1/165 [00:00<02:29,  1.09it/s]Evaluating:   1%|          | 2/165 [00:01<01:34,  1.72it/s]Evaluating:   2%|▏         | 3/165 [00:01<01:16,  2.12it/s]Evaluating:   2%|▏         | 4/165 [00:01<01:08,  2.36it/s]Evaluating:   3%|▎         | 5/165 [00:02<01:03,  2.53it/s]Evaluating:   4%|▎         | 6/165 [00:02<00:59,  2.65it/s]Evaluating:   4%|▍         | 7/165 [00:02<00:57,  2.74it/s]Evaluating:   5%|▍         | 8/165 [00:03<00:56,  2.79it/s]Evaluating:   5%|▌         | 9/165 [00:03<00:55,  2.82it/s]Evaluating:   6%|▌         | 10/165 [00:04<00:54,  2.85it/s]Evaluating:   7%|▋         | 11/165 [00:04<00:53,  2.86it/s]Evaluating:   7%|▋         | 12/165 [00:04<00:53,  2.88it/s]Evaluating:   8%|▊         | 13/165 [00:05<00:52,  2.89it/s]Evaluating:   8%|▊         | 14/165 [00:05<00:52,  2.89it/s]Evaluating:   9%|▉         | 15/165 [00:05<00:51,  2.90it/s]Evaluating:  10%|▉         | 16/165 [00:06<00:51,  2.90it/s]Evaluating:  10%|█         | 17/165 [00:06<00:50,  2.91it/s]Evaluating:  11%|█         | 18/165 [00:06<00:50,  2.91it/s]Evaluating:  12%|█▏        | 19/165 [00:07<00:50,  2.90it/s]Evaluating:  12%|█▏        | 20/165 [00:07<00:49,  2.91it/s]Evaluating:  13%|█▎        | 21/165 [00:07<00:49,  2.91it/s]Evaluating:  13%|█▎        | 22/165 [00:08<00:49,  2.91it/s]Evaluating:  14%|█▍        | 23/165 [00:08<00:48,  2.91it/s]Evaluating:  15%|█▍        | 24/165 [00:08<00:48,  2.91it/s]Evaluating:  15%|█▌        | 25/165 [00:09<00:48,  2.91it/s]Evaluating:  16%|█▌        | 26/165 [00:09<00:47,  2.92it/s]Evaluating:  16%|█▋        | 27/165 [00:09<00:47,  2.92it/s]Evaluating:  17%|█▋        | 28/165 [00:10<00:46,  2.92it/s]Evaluating:  18%|█▊        | 29/165 [00:10<00:46,  2.92it/s]Evaluating:  18%|█▊        | 30/165 [00:10<00:46,  2.92it/s]Evaluating:  19%|█▉        | 31/165 [00:11<00:45,  2.92it/s]Evaluating:  19%|█▉        | 32/165 [00:11<00:45,  2.92it/s]Evaluating:  20%|██        | 33/165 [00:11<00:45,  2.92it/s]Evaluating:  21%|██        | 34/165 [00:12<00:44,  2.92it/s]Evaluating:  21%|██        | 35/165 [00:12<00:44,  2.91it/s]Evaluating:  22%|██▏       | 36/165 [00:12<00:44,  2.92it/s]Evaluating:  22%|██▏       | 37/165 [00:13<00:43,  2.92it/s]Evaluating:  23%|██▎       | 38/165 [00:13<00:43,  2.92it/s]Evaluating:  24%|██▎       | 39/165 [00:13<00:43,  2.92it/s]Evaluating:  24%|██▍       | 40/165 [00:14<00:43,  2.90it/s]Evaluating:  25%|██▍       | 41/165 [00:14<00:42,  2.91it/s]Evaluating:  25%|██▌       | 42/165 [00:14<00:42,  2.91it/s]Evaluating:  26%|██▌       | 43/165 [00:15<00:41,  2.91it/s]Evaluating:  27%|██▋       | 44/165 [00:15<00:41,  2.90it/s]Evaluating:  27%|██▋       | 45/165 [00:16<00:41,  2.90it/s]Evaluating:  28%|██▊       | 46/165 [00:16<00:40,  2.91it/s]Evaluating:  28%|██▊       | 47/165 [00:16<00:40,  2.91it/s]Evaluating:  29%|██▉       | 48/165 [00:17<00:40,  2.90it/s]Evaluating:  30%|██▉       | 49/165 [00:17<00:39,  2.91it/s]Evaluating:  30%|███       | 50/165 [00:17<00:39,  2.91it/s]Evaluating:  31%|███       | 51/165 [00:18<00:39,  2.92it/s]Evaluating:  32%|███▏      | 52/165 [00:18<00:38,  2.91it/s]Evaluating:  32%|███▏      | 53/165 [00:18<00:38,  2.91it/s]Evaluating:  33%|███▎      | 54/165 [00:19<00:38,  2.90it/s]Evaluating:  33%|███▎      | 55/165 [00:19<00:38,  2.89it/s]Evaluating:  34%|███▍      | 56/165 [00:19<00:37,  2.88it/s]Evaluating:  35%|███▍      | 57/165 [00:20<00:37,  2.88it/s]Evaluating:  35%|███▌      | 58/165 [00:20<00:37,  2.87it/s]Evaluating:  36%|███▌      | 59/165 [00:20<00:36,  2.88it/s]Evaluating:  36%|███▋      | 60/165 [00:21<00:36,  2.88it/s]Evaluating:  37%|███▋      | 61/165 [00:21<00:36,  2.88it/s]Evaluating:  38%|███▊      | 62/165 [00:21<00:35,  2.87it/s]Evaluating:  38%|███▊      | 63/165 [00:22<00:35,  2.88it/s]Evaluating:  39%|███▉      | 64/165 [00:22<00:35,  2.88it/s]Evaluating:  39%|███▉      | 65/165 [00:22<00:34,  2.89it/s]Evaluating:  40%|████      | 66/165 [00:23<00:34,  2.89it/s]Evaluating:  41%|████      | 67/165 [00:23<00:33,  2.90it/s]Evaluating:  41%|████      | 68/165 [00:23<00:33,  2.91it/s]Evaluating:  42%|████▏     | 69/165 [00:24<00:32,  2.91it/s]Evaluating:  42%|████▏     | 70/165 [00:24<00:32,  2.91it/s]Evaluating:  43%|████▎     | 71/165 [00:25<00:32,  2.90it/s]Evaluating:  44%|████▎     | 72/165 [00:25<00:32,  2.90it/s]Evaluating:  44%|████▍     | 73/165 [00:25<00:31,  2.91it/s]Evaluating:  45%|████▍     | 74/165 [00:26<00:31,  2.91it/s]Evaluating:  45%|████▌     | 75/165 [00:26<00:30,  2.92it/s]Evaluating:  46%|████▌     | 76/165 [00:26<00:30,  2.92it/s]Evaluating:  47%|████▋     | 77/165 [00:27<00:30,  2.91it/s]Evaluating:  47%|████▋     | 78/165 [00:27<00:29,  2.91it/s]Evaluating:  48%|████▊     | 79/165 [00:27<00:29,  2.91it/s]Evaluating:  48%|████▊     | 80/165 [00:28<00:29,  2.90it/s]Evaluating:  49%|████▉     | 81/165 [00:28<00:28,  2.90it/s]Evaluating:  50%|████▉     | 82/165 [00:28<00:28,  2.90it/s]Evaluating:  50%|█████     | 83/165 [00:29<00:28,  2.91it/s]Evaluating:  51%|█████     | 84/165 [00:29<00:27,  2.91it/s]Evaluating:  52%|█████▏    | 85/165 [00:29<00:27,  2.92it/s]Evaluating:  52%|█████▏    | 86/165 [00:30<00:27,  2.92it/s]Evaluating:  53%|█████▎    | 87/165 [00:30<00:26,  2.92it/s]Evaluating:  53%|█████▎    | 88/165 [00:30<00:26,  2.92it/s]Evaluating:  54%|█████▍    | 89/165 [00:31<00:26,  2.92it/s]Evaluating:  55%|█████▍    | 90/165 [00:31<00:25,  2.91it/s]Evaluating:  55%|█████▌    | 91/165 [00:31<00:25,  2.91it/s]Evaluating:  56%|█████▌    | 92/165 [00:32<00:25,  2.91it/s]Evaluating:  56%|█████▋    | 93/165 [00:32<00:24,  2.91it/s]Evaluating:  57%|█████▋    | 94/165 [00:32<00:24,  2.91it/s]Evaluating:  58%|█████▊    | 95/165 [00:33<00:24,  2.90it/s]Evaluating:  58%|█████▊    | 96/165 [00:33<00:23,  2.91it/s]Evaluating:  59%|█████▉    | 97/165 [00:33<00:23,  2.91it/s]Evaluating:  59%|█████▉    | 98/165 [00:34<00:23,  2.89it/s]Evaluating:  60%|██████    | 99/165 [00:34<00:22,  2.89it/s]Evaluating:  61%|██████    | 100/165 [00:34<00:22,  2.90it/s]Evaluating:  61%|██████    | 101/165 [00:35<00:22,  2.90it/s]Evaluating:  62%|██████▏   | 102/165 [00:35<00:21,  2.91it/s]Evaluating:  62%|██████▏   | 103/165 [00:36<00:21,  2.91it/s]Evaluating:  63%|██████▎   | 104/165 [00:36<00:20,  2.91it/s]Evaluating:  64%|██████▎   | 105/165 [00:36<00:20,  2.91it/s]Evaluating:  64%|██████▍   | 106/165 [00:37<00:20,  2.91it/s]Evaluating:  65%|██████▍   | 107/165 [00:37<00:20,  2.90it/s]Evaluating:  65%|██████▌   | 108/165 [00:37<00:19,  2.89it/s]Evaluating:  66%|██████▌   | 109/165 [00:38<00:19,  2.90it/s]Evaluating:  67%|██████▋   | 110/165 [00:38<00:18,  2.90it/s]Evaluating:  67%|██████▋   | 111/165 [00:38<00:18,  2.90it/s]Evaluating:  68%|██████▊   | 112/165 [00:39<00:18,  2.89it/s]Evaluating:  68%|██████▊   | 113/165 [00:39<00:17,  2.90it/s]Evaluating:  69%|██████▉   | 114/165 [00:39<00:17,  2.91it/s]Evaluating:  70%|██████▉   | 115/165 [00:40<00:17,  2.91it/s]Evaluating:  70%|███████   | 116/165 [00:40<00:16,  2.90it/s]Evaluating:  71%|███████   | 117/165 [00:40<00:16,  2.90it/s]Evaluating:  72%|███████▏  | 118/165 [00:41<00:16,  2.90it/s]Evaluating:  72%|███████▏  | 119/165 [00:41<00:15,  2.90it/s]Evaluating:  73%|███████▎  | 120/165 [00:41<00:15,  2.90it/s]Evaluating:  73%|███████▎  | 121/165 [00:42<00:15,  2.90it/s]Evaluating:  74%|███████▍  | 122/165 [00:42<00:14,  2.90it/s]Evaluating:  75%|███████▍  | 123/165 [00:42<00:14,  2.90it/s]Evaluating:  75%|███████▌  | 124/165 [00:43<00:14,  2.90it/s]Evaluating:  76%|███████▌  | 125/165 [00:43<00:13,  2.90it/s]Evaluating:  76%|███████▋  | 126/165 [00:43<00:13,  2.90it/s]Evaluating:  77%|███████▋  | 127/165 [00:44<00:13,  2.91it/s]Evaluating:  78%|███████▊  | 128/165 [00:44<00:12,  2.92it/s]Evaluating:  78%|███████▊  | 129/165 [00:44<00:12,  2.92it/s]Evaluating:  79%|███████▉  | 130/165 [00:45<00:12,  2.85it/s]Evaluating:  79%|███████▉  | 131/165 [00:45<00:11,  2.86it/s]Evaluating:  80%|████████  | 132/165 [00:46<00:11,  2.87it/s]Evaluating:  81%|████████  | 133/165 [00:46<00:11,  2.88it/s]Evaluating:  81%|████████  | 134/165 [00:46<00:10,  2.88it/s]Evaluating:  82%|████████▏ | 135/165 [00:47<00:10,  2.89it/s]Evaluating:  82%|████████▏ | 136/165 [00:47<00:09,  2.90it/s]Evaluating:  83%|████████▎ | 137/165 [00:47<00:09,  2.89it/s]Evaluating:  84%|████████▎ | 138/165 [00:48<00:09,  2.90it/s]Evaluating:  84%|████████▍ | 139/165 [00:48<00:08,  2.90it/s]Evaluating:  85%|████████▍ | 140/165 [00:48<00:08,  2.91it/s]Evaluating:  85%|████████▌ | 141/165 [00:49<00:08,  2.91it/s]Evaluating:  86%|████████▌ | 142/165 [00:49<00:07,  2.90it/s]Evaluating:  87%|████████▋ | 143/165 [00:49<00:07,  2.90it/s]Evaluating:  87%|████████▋ | 144/165 [00:50<00:07,  2.91it/s]Evaluating:  88%|████████▊ | 145/165 [00:50<00:06,  2.91it/s]Evaluating:  88%|████████▊ | 146/165 [00:50<00:06,  2.92it/s]Evaluating:  89%|████████▉ | 147/165 [00:51<00:06,  2.92it/s]Evaluating:  90%|████████▉ | 148/165 [00:51<00:05,  2.91it/s]Evaluating:  90%|█████████ | 149/165 [00:51<00:05,  2.91it/s]Evaluating:  91%|█████████ | 150/165 [00:52<00:05,  2.92it/s]Evaluating:  92%|█████████▏| 151/165 [00:52<00:04,  2.92it/s]Evaluating:  92%|█████████▏| 152/165 [00:52<00:04,  2.92it/s]Evaluating:  93%|█████████▎| 153/165 [00:53<00:04,  2.91it/s]Evaluating:  93%|█████████▎| 154/165 [00:53<00:03,  2.90it/s]Evaluating:  94%|█████████▍| 155/165 [00:53<00:03,  2.91it/s]Evaluating:  95%|█████████▍| 156/165 [00:54<00:03,  2.90it/s]Evaluating:  95%|█████████▌| 157/165 [00:54<00:02,  2.91it/s]Evaluating:  96%|█████████▌| 158/165 [00:54<00:02,  2.90it/s]Evaluating:  96%|█████████▋| 159/165 [00:55<00:02,  2.90it/s]Evaluating:  97%|█████████▋| 160/165 [00:55<00:01,  2.90it/s]Evaluating:  98%|█████████▊| 161/165 [00:55<00:01,  2.91it/s]Evaluating:  98%|█████████▊| 162/165 [00:56<00:01,  2.90it/s]Evaluating:  99%|█████████▉| 163/165 [00:56<00:00,  2.90it/s]Evaluating:  99%|█████████▉| 164/165 [00:57<00:00,  2.90it/s]Evaluating: 100%|██████████| 165/165 [00:57<00:00,  3.65it/s]Evaluating: 100%|██████████| 165/165 [00:57<00:00,  2.89it/s]
05/09/2022 09:15:06 - INFO - __main__ -     Evaluation done in total 57.137916 secs (0.043484 sec per example)
05/09/2022 09:15:12 - INFO - __main__ -   Results: {'exact': 60.0, 'f1': 79.2424511417761, 'total': 1190, 'HasAns_exact': 60.0, 'HasAns_f1': 79.2424511417761, 'HasAns_total': 1190, 'best_exact': 60.0, 'best_exact_thresh': 0.0, 'best_f1': 79.2424511417761, 'best_f1_thresh': 0.0}
  th 
2022-05-09 09:15:16.081121: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0
05/09/2022 09:15:20 - WARNING - __main__ -   Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, 16-bits training: False
You are using a model of type xlm-roberta to instantiate a model of type xlm. This is not supported for all configurations of models and can yield errors.
Some weights of the model checkpoint at /cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//squad/xlm-KG_LR3e-5_EPOCH2.0_maxlen384_batchsize4_gradacc4 were not used when initializing XLMRobertaModel: ['base_model.encoder.layer.20.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.11.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.12.attention.self.value.weight', 'base_model.encoder.layer.8.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.20.intermediate.dense.weight', 'base_model.encoder.layer.14.attention.output.dense.weight', 'base_model.encoder.layer.21.attention.self.value.weight', 'base_model.encoder.layer.2.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.23.attention.self.key.bias', 'base_model.encoder.layer.21.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.8.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.3.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.16.intermediate.dense.weight', 'base_model.encoder.layer.18.attention.self.query.bias', 'base_model.encoder.layer.5.attention.self.key.weight', 'base_model.encoder.layer.5.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.7.attention.self.value.weight', 'base_model.encoder.layer.23.output.LayerNorm.weight', 'base_model.encoder.layer.0.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.1.output.LayerNorm.bias', 'base_model.encoder.layer.22.intermediate.dense.bias', 'base_model.encoder.layer.23.attention.output.dense.weight', 'base_model.encoder.layer.17.attention.output.dense.weight', 'base_model.encoder.layer.23.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.21.attention.self.value.bias', 'base_model.encoder.layer.10.attention.self.value.bias', 'base_model.encoder.layer.2.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.9.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.6.attention.output.LayerNorm.bias', 'base_model.encoder.layer.16.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.5.intermediate.dense.bias', 'base_model.encoder.layer.9.intermediate.dense.weight', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.8.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.23.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.21.attention.output.dense.bias', 'base_model.encoder.layer.20.attention.output.LayerNorm.bias', 'base_model.encoder.layer.1.attention.output.LayerNorm.weight', 'base_model.encoder.layer.6.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.8.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.12.attention.output.dense.bias', 'base_model.encoder.layer.23.attention.output.LayerNorm.bias', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.13.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.12.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.9.attention.self.key.weight', 'base_model.encoder.layer.20.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.20.output.LayerNorm.weight', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.19.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.2.output.dense.weight', 'base_model.encoder.layer.9.output.dense.weight', 'base_model.encoder.layer.8.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.21.intermediate.dense.bias', 'base_model.encoder.layer.3.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.9.attention.self.value.bias', 'base_model.encoder.layer.10.attention.output.LayerNorm.bias', 'base_model.encoder.layer.15.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.15.attention.output.dense.weight', 'base_model.encoder.layer.18.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.5.attention.output.dense.weight', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.7.output.dense.bias', 'base_model.encoder.layer.20.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.16.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.14.output.dense.bias', 'base_model.encoder.layer.7.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.21.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.19.attention.self.value.weight', 'base_model.encoder.layer.1.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.5.attention.self.key.bias', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.4.attention.self.key.weight', 'base_model.encoder.layer.7.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.3.output.LayerNorm.bias', 'base_model.encoder.layer.12.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.12.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.4.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.10.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.10.attention.self.query.weight', 'base_model.encoder.layer.13.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.4.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.5.attention.output.LayerNorm.weight', 'base_model.encoder.layer.7.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.17.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.2.intermediate.dense.bias', 'base_model.encoder.layer.18.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.21.attention.output.dense.weight', 'base_model.encoder.layer.18.attention.output.LayerNorm.weight', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.8.attention.self.key.weight', 'base_model.encoder.layer.0.attention.self.query.bias', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.13.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.22.output.LayerNorm.bias', 'base_model.encoder.layer.1.attention.self.query.weight', 'base_model.encoder.layer.1.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.8.output.dense.bias', 'base_model.encoder.layer.8.intermediate.dense.bias', 'base_model.encoder.layer.2.output.dense.bias', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.17.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.20.attention.self.value.bias', 'base_model.encoder.layer.1.attention.self.value.bias', 'base_model.encoder.layer.0.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.2.attention.self.query.weight', 'base_model.encoder.layer.18.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.23.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.9.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.4.attention.self.value.weight', 'base_model.encoder.layer.3.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.22.attention.self.query.weight', 'base_model.encoder.layer.4.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.13.attention.self.query.weight', 'base_model.encoder.layer.13.attention.self.value.weight', 'base_model.encoder.layer.0.attention.self.key.bias', 'base_model.encoder.layer.6.attention.output.dense.bias', 'base_model.encoder.layer.17.attention.self.key.weight', 'base_model.encoder.layer.18.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.16.attention.self.query.weight', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.2.output.LayerNorm.bias', 'base_model.encoder.layer.10.attention.output.dense.weight', 'base_model.encoder.layer.6.attention.self.value.bias', 'base_model.encoder.layer.22.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.16.intermediate.dense.bias', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.23.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.11.output.dense.bias', 'base_model.encoder.layer.9.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.17.attention.self.query.bias', 'base_model.encoder.layer.11.attention.output.dense.bias', 'base_model.encoder.layer.0.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.14.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.8.attention.output.dense.weight', 'base_model.encoder.layer.14.attention.output.LayerNorm.weight', 'base_model.encoder.layer.21.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.22.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.13.attention.self.value.bias', 'base_model.encoder.layer.17.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.23.attention.self.value.bias', 'base_model.encoder.layer.2.attention.output.LayerNorm.bias', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.5.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.21.output.dense.bias', 'base_model.encoder.layer.11.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.19.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.5.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.10.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.1.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.19.attention.self.value.bias', 'base_model.encoder.layer.2.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.10.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.11.attention.self.query.bias', 'base_model.encoder.layer.12.intermediate.dense.weight', 'base_model.encoder.layer.19.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.5.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.5.attention.self.value.bias', 'base_model.encoder.layer.2.attention.self.key.weight', 'base_model.encoder.layer.2.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.1.attention.output.dense.bias', 'base_model.encoder.layer.4.attention.self.key.bias', 'base_model.encoder.layer.7.attention.output.LayerNorm.weight', 'base_model.encoder.layer.11.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.12.intermediate.dense.bias', 'base_model.encoder.layer.12.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.15.attention.self.query.weight', 'base_model.encoder.layer.16.attention.output.LayerNorm.weight', 'base_model.encoder.layer.19.attention.output.LayerNorm.bias', 'base_model.encoder.layer.18.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.13.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.13.output.dense.bias', 'base_model.encoder.layer.21.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.11.intermediate.dense.bias', 'base_model.encoder.layer.10.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.6.attention.output.LayerNorm.weight', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.13.attention.output.LayerNorm.bias', 'base_model.encoder.layer.22.output.adapters.es.adapter_down.0.bias', 'base_model.embeddings.position_embeddings.weight', 'base_model.encoder.layer.13.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.11.attention.self.query.weight', 'base_model.encoder.layer.16.output.adapters.es.adapter_up.weight', 'qa_outputs.weight', 'base_model.encoder.layer.2.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.18.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.21.intermediate.dense.weight', 'base_model.encoder.layer.17.attention.self.key.bias', 'base_model.encoder.layer.0.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.1.attention.output.LayerNorm.bias', 'base_model.encoder.layer.7.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.7.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.9.attention.output.dense.bias', 'base_model.encoder.layer.19.attention.self.key.bias', 'base_model.encoder.layer.19.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.10.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.7.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.22.attention.self.key.weight', 'base_model.encoder.layer.19.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.18.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.16.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.19.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.22.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.1.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.2.attention.output.LayerNorm.weight', 'base_model.encoder.layer.4.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.11.attention.output.LayerNorm.weight', 'base_model.encoder.layer.12.attention.output.LayerNorm.bias', 'base_model.encoder.layer.1.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.21.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.20.output.dense.bias', 'base_model.encoder.layer.20.attention.self.query.weight', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.20.output.LayerNorm.bias', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.7.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.22.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.12.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.15.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.16.attention.self.key.weight', 'base_model.pooler.dense.bias', 'base_model.encoder.layer.17.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.3.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.10.output.LayerNorm.weight', 'base_model.encoder.layer.22.attention.self.key.bias', 'base_model.encoder.layer.15.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.17.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.23.attention.output.LayerNorm.weight', 'base_model.encoder.layer.20.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.18.attention.output.dense.bias', 'base_model.encoder.layer.14.attention.self.value.bias', 'base_model.encoder.layer.6.attention.self.value.weight', 'base_model.encoder.layer.13.attention.self.key.bias', 'base_model.encoder.layer.7.attention.self.key.bias', 'base_model.encoder.layer.11.attention.self.key.bias', 'base_model.encoder.layer.11.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.3.output.dense.bias', 'base_model.encoder.layer.0.attention.self.value.bias', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.9.output.dense.bias', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.13.output.LayerNorm.weight', 'base_model.encoder.layer.17.attention.self.value.bias', 'base_model.encoder.layer.6.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.9.attention.output.dense.weight', 'base_model.encoder.layer.6.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.5.output.LayerNorm.bias', 'base_model.encoder.layer.5.output.dense.bias', 'base_model.encoder.layer.0.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.10.attention.output.LayerNorm.weight', 'base_model.encoder.layer.17.intermediate.dense.bias', 'base_model.encoder.layer.9.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.15.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.14.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.5.attention.output.LayerNorm.bias', 'base_model.encoder.layer.16.output.dense.bias', 'base_model.encoder.layer.3.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.18.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.0.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.8.attention.self.query.weight', 'base_model.encoder.layer.19.attention.self.key.weight', 'base_model.encoder.layer.12.attention.self.value.bias', 'base_model.encoder.layer.17.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.9.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.5.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.16.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.13.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.23.intermediate.dense.weight', 'base_model.encoder.layer.14.intermediate.dense.bias', 'base_model.encoder.layer.1.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.11.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.5.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.7.attention.output.dense.weight', 'base_model.encoder.layer.13.attention.output.dense.bias', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.4.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.2.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.8.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.14.attention.self.value.weight', 'base_model.encoder.layer.11.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.3.attention.output.LayerNorm.bias', 'base_model.encoder.layer.4.output.LayerNorm.bias', 'base_model.encoder.layer.6.attention.output.dense.weight', 'base_model.encoder.layer.12.attention.self.key.bias', 'base_model.encoder.layer.6.attention.self.key.bias', 'base_model.encoder.layer.15.attention.output.LayerNorm.weight', 'base_model.encoder.layer.7.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.18.attention.self.key.bias', 'base_model.encoder.layer.22.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.8.attention.output.LayerNorm.weight', 'base_model.encoder.layer.3.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.15.attention.output.LayerNorm.bias', 'base_model.encoder.layer.3.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.7.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.8.attention.self.value.bias', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.9.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.14.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.18.attention.self.query.weight', 'base_model.embeddings.word_embeddings.weight', 'base_model.encoder.layer.15.intermediate.dense.bias', 'base_model.encoder.layer.17.output.LayerNorm.bias', 'base_model.encoder.layer.7.attention.self.key.weight', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.21.output.LayerNorm.weight', 'base_model.encoder.layer.14.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.9.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.2.output.LayerNorm.weight', 'base_model.encoder.layer.0.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.6.output.LayerNorm.weight', 'base_model.encoder.layer.1.output.dense.weight', 'base_model.encoder.layer.4.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.14.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.4.attention.output.LayerNorm.bias', 'base_model.encoder.layer.12.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.22.attention.output.LayerNorm.weight', 'base_model.encoder.layer.23.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.17.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.11.intermediate.dense.weight', 'base_model.encoder.layer.18.attention.self.value.weight', 'base_model.encoder.layer.9.attention.self.value.weight', 'base_model.encoder.layer.3.attention.self.key.weight', 'base_model.encoder.layer.4.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.18.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.20.attention.output.dense.weight', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.19.attention.output.dense.weight', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.20.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.23.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.0.output.dense.bias', 'base_model.encoder.layer.0.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.8.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.22.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.19.output.LayerNorm.bias', 'base_model.encoder.layer.18.intermediate.dense.weight', 'base_model.encoder.layer.4.attention.output.dense.weight', 'base_model.encoder.layer.1.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.4.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.9.output.LayerNorm.bias', 'base_model.encoder.layer.0.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.11.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.10.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.12.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.15.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.18.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.5.attention.self.query.weight', 'base_model.encoder.layer.15.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.3.attention.output.dense.weight', 'base_model.encoder.layer.10.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.4.attention.self.query.weight', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.14.attention.self.key.weight', 'base_model.encoder.layer.18.attention.self.key.weight', 'base_model.encoder.layer.16.output.LayerNorm.bias', 'base_model.encoder.layer.21.attention.self.key.bias', 'base_model.encoder.layer.22.attention.output.LayerNorm.bias', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.15.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.12.output.LayerNorm.bias', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.21.attention.self.query.weight', 'base_model.encoder.layer.22.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.21.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.0.intermediate.dense.bias', 'base_model.encoder.layer.21.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.3.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.8.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.15.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.3.output.LayerNorm.weight', 'base_model.encoder.layer.7.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.0.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.18.attention.output.dense.weight', 'base_model.encoder.layer.5.attention.output.dense.bias', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.7.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.12.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.23.attention.self.query.bias', 'base_model.encoder.layer.0.attention.output.dense.bias', 'base_model.encoder.layer.14.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.23.attention.output.dense.bias', 'base_model.encoder.layer.3.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.17.output.dense.bias', 'base_model.encoder.layer.1.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.8.output.dense.weight', 'base_model.encoder.layer.22.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.1.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.9.attention.self.key.bias', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.11.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.17.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.14.intermediate.dense.weight', 'base_model.encoder.layer.5.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.23.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.17.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.14.attention.self.query.weight', 'base_model.encoder.layer.20.attention.output.LayerNorm.weight', 'base_model.encoder.layer.23.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.16.attention.output.LayerNorm.bias', 'base_model.encoder.layer.22.attention.output.dense.weight', 'base_model.encoder.layer.11.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.16.attention.output.dense.weight', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.17.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.3.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.15.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.20.output.dense.weight', 'base_model.encoder.layer.5.output.dense.weight', 'base_model.encoder.layer.18.attention.output.LayerNorm.bias', 'base_model.encoder.layer.20.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.0.output.LayerNorm.weight', 'base_model.encoder.layer.21.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.3.attention.output.LayerNorm.weight', 'base_model.encoder.layer.19.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.1.intermediate.dense.weight', 'base_model.encoder.layer.7.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.22.intermediate.dense.weight', 'base_model.encoder.layer.17.output.LayerNorm.weight', 'base_model.encoder.layer.18.output.dense.weight', 'base_model.encoder.layer.9.attention.self.query.weight', 'base_model.encoder.layer.4.intermediate.dense.bias', 'base_model.encoder.layer.14.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.16.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.10.attention.self.key.weight', 'base_model.encoder.layer.5.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.9.output.LayerNorm.weight', 'base_model.encoder.layer.22.output.dense.bias', 'base_model.encoder.layer.15.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.23.output.adapters.ts.adapter_up.weight', 'base_model.embeddings.position_ids', 'base_model.encoder.layer.6.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.15.attention.output.dense.bias', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.4.attention.self.value.bias', 'base_model.encoder.layer.5.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.8.attention.output.dense.bias', 'base_model.encoder.layer.14.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.19.attention.output.dense.bias', 'base_model.encoder.layer.20.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.15.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.18.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.1.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.1.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.10.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.18.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.3.attention.self.query.bias', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.19.output.dense.bias', 'base_model.encoder.layer.7.output.LayerNorm.weight', 'base_model.encoder.layer.12.output.LayerNorm.weight', 'base_model.encoder.layer.19.intermediate.dense.weight', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.6.attention.self.key.weight', 'base_model.encoder.layer.6.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.17.intermediate.dense.weight', 'base_model.encoder.layer.2.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.2.attention.self.value.weight', 'base_model.encoder.layer.1.attention.self.key.weight', 'base_model.encoder.layer.3.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.15.attention.self.key.bias', 'base_model.encoder.layer.16.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.12.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.0.output.dense.weight', 'base_model.encoder.layer.13.attention.output.dense.weight', 'base_model.encoder.layer.22.attention.self.query.bias', 'base_model.encoder.layer.11.output.dense.weight', 'base_model.encoder.layer.22.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.4.attention.output.LayerNorm.weight', 'base_model.encoder.layer.8.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.19.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.5.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.13.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.22.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.5.intermediate.dense.weight', 'base_model.encoder.layer.12.attention.self.query.weight', 'base_model.encoder.layer.12.output.dense.bias', 'base_model.encoder.layer.13.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.23.output.LayerNorm.bias', 'base_model.encoder.layer.0.attention.output.dense.weight', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.8.intermediate.dense.weight', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.10.attention.output.dense.bias', 'base_model.encoder.layer.14.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.13.attention.output.LayerNorm.weight', 'base_model.encoder.layer.16.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.8.attention.self.query.bias', 'base_model.encoder.layer.9.intermediate.dense.bias', 'base_model.encoder.layer.3.intermediate.dense.bias', 'base_model.encoder.layer.18.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.2.attention.self.value.bias', 'base_model.encoder.layer.1.attention.self.value.weight', 'base_model.encoder.layer.7.attention.self.value.bias', 'base_model.encoder.layer.6.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.10.output.dense.bias', 'base_model.encoder.layer.17.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.22.attention.output.dense.bias', 'base_model.encoder.layer.16.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.7.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.11.attention.output.LayerNorm.bias', 'base_model.encoder.layer.3.attention.self.value.bias', 'base_model.encoder.layer.23.attention.self.query.weight', 'base_model.encoder.layer.0.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.10.attention.self.value.weight', 'base_model.encoder.layer.6.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.8.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.13.intermediate.dense.bias', 'base_model.encoder.layer.20.attention.self.key.weight', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.23.output.dense.weight', 'base_model.encoder.layer.20.intermediate.dense.bias', 'base_model.encoder.layer.19.output.dense.weight', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.19.attention.self.query.bias', 'base_model.encoder.layer.19.intermediate.dense.bias', 'base_model.encoder.layer.20.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.7.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.17.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.19.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.10.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.17.attention.output.dense.bias', 'base_model.encoder.layer.17.attention.self.query.weight', 'base_model.encoder.layer.21.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.10.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.4.output.dense.bias', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.16.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.12.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.18.output.LayerNorm.bias', 'base_model.encoder.layer.9.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.11.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.12.attention.output.LayerNorm.weight', 'base_model.encoder.layer.23.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.6.intermediate.dense.bias', 'base_model.encoder.layer.19.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.16.attention.self.query.bias', 'base_model.encoder.layer.3.attention.self.key.bias', 'base_model.encoder.layer.0.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.18.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.13.intermediate.dense.weight', 'base_model.encoder.layer.8.attention.self.key.bias', 'base_model.encoder.layer.21.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.4.intermediate.dense.weight', 'base_model.encoder.layer.7.output.adapters.tp.adapter_up.weight', 'qa_outputs.bias', 'base_model.encoder.layer.7.attention.self.query.weight', 'base_model.encoder.layer.14.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.16.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.20.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.9.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.9.attention.self.query.bias', 'base_model.encoder.layer.12.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.13.output.dense.weight', 'base_model.encoder.layer.8.output.LayerNorm.weight', 'base_model.encoder.layer.4.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.7.intermediate.dense.weight', 'base_model.encoder.layer.9.attention.output.LayerNorm.bias', 'base_model.encoder.layer.6.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.16.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.20.attention.output.dense.bias', 'base_model.encoder.layer.12.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.23.output.dense.bias', 'base_model.encoder.layer.12.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.19.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.7.attention.output.dense.bias', 'base_model.encoder.layer.1.attention.self.key.bias', 'base_model.encoder.layer.7.attention.self.query.bias', 'base_model.encoder.layer.10.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.2.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.11.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.21.output.LayerNorm.bias', 'base_model.encoder.layer.9.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.15.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.20.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.16.attention.self.key.bias', 'base_model.encoder.layer.18.intermediate.dense.bias', 'base_model.encoder.layer.21.attention.output.LayerNorm.bias', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.21.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.12.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.14.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.22.output.dense.weight', 'base_model.encoder.layer.10.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.19.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.12.output.dense.weight', 'base_model.encoder.layer.9.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.23.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.12.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.19.attention.output.LayerNorm.weight', 'base_model.encoder.layer.20.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.14.attention.self.query.bias', 'base_model.encoder.layer.13.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.4.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.11.output.LayerNorm.weight', 'base_model.encoder.layer.19.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.10.intermediate.dense.weight', 'base_model.encoder.layer.14.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.6.attention.self.query.weight', 'base_model.encoder.layer.0.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.2.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.9.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.3.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.1.output.LayerNorm.weight', 'base_model.encoder.layer.15.attention.self.key.weight', 'base_model.encoder.layer.7.output.LayerNorm.bias', 'base_model.encoder.layer.15.output.LayerNorm.bias', 'base_model.encoder.layer.14.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.19.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.19.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.1.attention.self.query.bias', 'base_model.encoder.layer.21.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.0.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.23.intermediate.dense.bias', 'base_model.encoder.layer.11.attention.self.key.weight', 'base_model.encoder.layer.3.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.4.output.LayerNorm.weight', 'base_model.encoder.layer.15.output.dense.weight', 'base_model.encoder.layer.14.output.LayerNorm.weight', 'base_model.encoder.layer.17.attention.self.value.weight', 'base_model.encoder.layer.4.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.6.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.11.attention.output.dense.weight', 'base_model.encoder.layer.22.attention.self.value.bias', 'base_model.encoder.layer.2.attention.self.query.bias', 'base_model.encoder.layer.17.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.2.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.5.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.11.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.18.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.0.attention.output.LayerNorm.weight', 'base_model.encoder.layer.1.intermediate.dense.bias', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.20.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.18.output.LayerNorm.weight', 'base_model.encoder.layer.0.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.4.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.6.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.21.output.dense.weight', 'base_model.encoder.layer.4.attention.self.query.bias', 'base_model.encoder.layer.4.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.12.attention.self.query.bias', 'base_model.encoder.layer.15.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.8.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.22.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.0.attention.self.query.weight', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.17.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.3.output.dense.weight', 'base_model.encoder.layer.5.attention.self.value.weight', 'base_model.encoder.layer.10.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.8.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.1.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.6.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.11.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.12.attention.output.dense.weight', 'base_model.encoder.layer.16.attention.output.dense.bias', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.0.attention.self.key.weight', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.14.attention.output.dense.bias', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.3.attention.self.query.weight', 'base_model.encoder.layer.17.attention.output.LayerNorm.bias', 'base_model.encoder.layer.21.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.7.intermediate.dense.bias', 'base_model.encoder.layer.18.attention.self.value.bias', 'base_model.encoder.layer.9.output.adapters.ts.adapter_up.weight', 'base_model.embeddings.LayerNorm.weight', 'base_model.encoder.layer.4.attention.output.dense.bias', 'base_model.encoder.layer.15.attention.self.value.bias', 'base_model.encoder.layer.11.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.8.attention.self.value.weight', 'base_model.encoder.layer.11.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.10.output.dense.weight', 'base_model.encoder.layer.14.output.LayerNorm.bias', 'base_model.encoder.layer.1.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.10.output.LayerNorm.bias', 'base_model.encoder.layer.20.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.2.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.11.attention.self.value.weight', 'base_model.encoder.layer.6.output.LayerNorm.bias', 'base_model.encoder.layer.8.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.16.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.23.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.15.attention.self.value.weight', 'base_model.encoder.layer.16.attention.self.value.bias', 'base_model.encoder.layer.6.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.17.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.2.attention.self.key.bias', 'base_model.encoder.layer.6.output.dense.weight', 'base_model.encoder.layer.10.intermediate.dense.bias', 'base_model.encoder.layer.4.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.22.attention.self.value.weight', 'base_model.encoder.layer.2.attention.output.dense.weight', 'base_model.embeddings.LayerNorm.bias', 'base_model.encoder.layer.20.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.3.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.9.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.9.attention.output.LayerNorm.weight', 'base_model.encoder.layer.19.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.20.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.22.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.3.intermediate.dense.weight', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.6.output.dense.bias', 'base_model.encoder.layer.21.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.12.attention.self.key.weight', 'base_model.encoder.layer.23.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.embeddings.token_type_embeddings.weight', 'base_model.encoder.layer.1.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.19.output.LayerNorm.weight', 'base_model.encoder.layer.9.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.21.attention.self.query.bias', 'base_model.encoder.layer.22.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.6.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.18.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.20.attention.self.value.weight', 'base_model.encoder.layer.16.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.13.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.16.output.LayerNorm.weight', 'base_model.encoder.layer.22.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.13.attention.self.key.weight', 'base_model.encoder.layer.2.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.5.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.0.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.10.attention.self.key.bias', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.3.attention.output.dense.bias', 'base_model.encoder.layer.21.attention.output.LayerNorm.weight', 'base_model.encoder.layer.17.output.dense.weight', 'base_model.encoder.layer.7.attention.output.LayerNorm.bias', 'base_model.encoder.layer.2.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.13.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.14.attention.self.key.bias', 'base_model.encoder.layer.4.output.dense.weight', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.1.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.1.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.0.output.LayerNorm.bias', 'base_model.encoder.layer.15.output.LayerNorm.weight', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.15.output.dense.bias', 'base_model.encoder.layer.17.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.13.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.23.attention.self.key.weight', 'base_model.encoder.layer.16.attention.self.value.weight', 'base_model.encoder.layer.6.intermediate.dense.weight', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.5.output.LayerNorm.weight', 'base_model.encoder.layer.1.output.dense.bias', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.11.output.LayerNorm.bias', 'base_model.encoder.layer.23.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.7.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.3.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.8.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.0.attention.output.LayerNorm.bias', 'base_model.encoder.layer.5.attention.self.query.bias', 'base_model.encoder.layer.2.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.13.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.5.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.0.intermediate.dense.weight', 'base_model.encoder.layer.18.output.dense.bias', 'base_model.encoder.layer.8.attention.output.LayerNorm.bias', 'base_model.encoder.layer.15.attention.self.query.bias', 'base_model.encoder.layer.15.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.6.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.21.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.8.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.17.attention.output.LayerNorm.weight', 'base_model.encoder.layer.23.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.19.attention.self.query.weight', 'base_model.encoder.layer.11.attention.self.value.bias', 'base_model.encoder.layer.23.output.adapters.ep.adapter_down.0.bias', 'base_model.pooler.dense.weight', 'base_model.encoder.layer.5.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.10.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.11.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.13.attention.self.query.bias', 'base_model.encoder.layer.15.intermediate.dense.weight', 'base_model.encoder.layer.6.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.14.output.dense.weight', 'base_model.encoder.layer.16.output.dense.weight', 'base_model.encoder.layer.8.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.10.attention.self.query.bias', 'base_model.encoder.layer.4.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.20.attention.self.query.bias', 'base_model.encoder.layer.20.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.3.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.14.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.2.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.7.output.dense.weight', 'base_model.encoder.layer.3.attention.self.value.weight', 'base_model.encoder.layer.21.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.22.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.10.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.4.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.13.output.LayerNorm.bias', 'base_model.encoder.layer.0.attention.self.value.weight', 'base_model.encoder.layer.21.attention.self.key.weight', 'base_model.encoder.layer.16.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.2.intermediate.dense.weight', 'base_model.encoder.layer.13.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.15.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.15.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.10.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.13.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.14.attention.output.LayerNorm.bias', 'base_model.encoder.layer.16.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.1.attention.output.dense.weight', 'base_model.encoder.layer.6.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.12.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.14.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.5.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.2.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.9.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.13.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.6.attention.self.query.bias', 'base_model.encoder.layer.2.attention.output.dense.bias', 'base_model.encoder.layer.14.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.5.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.20.attention.self.key.bias', 'base_model.encoder.layer.23.attention.self.value.weight', 'base_model.encoder.layer.22.output.LayerNorm.weight', 'base_model.encoder.layer.8.output.LayerNorm.bias']
- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of XLMRobertaModel were not initialized from the model checkpoint at /cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//squad/xlm-KG_LR3e-5_EPOCH2.0_maxlen384_batchsize4_gradacc4 and are newly initialized: ['encoder.layer.6.attention.self.key.weight', 'encoder.layer.20.output.LayerNorm.bias', 'encoder.layer.20.attention.self.key.weight', 'encoder.layer.4.attention.output.LayerNorm.weight', 'encoder.layer.12.attention.output.dense.bias', 'encoder.layer.14.attention.self.key.weight', 'encoder.layer.20.output.dense.weight', 'encoder.layer.22.attention.self.value.bias', 'encoder.layer.12.attention.self.key.weight', 'encoder.layer.23.intermediate.dense.weight', 'encoder.layer.19.output.LayerNorm.bias', 'embeddings.LayerNorm.bias', 'encoder.layer.17.attention.self.query.bias', 'encoder.layer.8.attention.self.value.bias', 'encoder.layer.19.attention.output.LayerNorm.weight', 'encoder.layer.18.attention.self.value.bias', 'encoder.layer.2.attention.output.LayerNorm.weight', 'encoder.layer.8.output.LayerNorm.weight', 'pooler.dense.weight', 'encoder.layer.0.output.dense.weight', 'encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.layer.7.attention.output.LayerNorm.weight', 'encoder.layer.17.attention.self.key.weight', 'encoder.layer.15.attention.self.key.bias', 'encoder.layer.21.attention.self.value.weight', 'encoder.layer.16.attention.output.LayerNorm.bias', 'encoder.layer.8.output.dense.weight', 'encoder.layer.16.output.dense.weight', 'encoder.layer.6.attention.output.LayerNorm.bias', 'encoder.layer.1.attention.self.query.bias', 'encoder.layer.13.output.LayerNorm.weight', 'encoder.layer.4.attention.output.dense.weight', 'encoder.layer.14.intermediate.dense.weight', 'encoder.layer.1.attention.self.value.bias', 'encoder.layer.6.output.LayerNorm.bias', 'encoder.layer.16.output.dense.bias', 'encoder.layer.22.attention.self.key.bias', 'embeddings.position_embeddings.weight', 'encoder.layer.23.output.dense.bias', 'encoder.layer.13.intermediate.dense.weight', 'encoder.layer.15.output.LayerNorm.weight', 'encoder.layer.17.attention.output.dense.weight', 'encoder.layer.4.output.dense.bias', 'encoder.layer.16.attention.self.key.bias', 'encoder.layer.13.output.dense.weight', 'encoder.layer.18.output.dense.weight', 'encoder.layer.1.output.dense.bias', 'encoder.layer.5.output.dense.bias', 'encoder.layer.10.attention.self.key.bias', 'encoder.layer.14.output.dense.bias', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.21.attention.output.LayerNorm.weight', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.9.output.dense.weight', 'encoder.layer.5.intermediate.dense.bias', 'embeddings.LayerNorm.weight', 'encoder.layer.1.attention.self.value.weight', 'encoder.layer.8.attention.output.LayerNorm.bias', 'encoder.layer.19.attention.output.LayerNorm.bias', 'encoder.layer.0.attention.self.query.weight', 'encoder.layer.16.intermediate.dense.bias', 'encoder.layer.4.attention.output.dense.bias', 'encoder.layer.3.intermediate.dense.bias', 'embeddings.token_type_embeddings.weight', 'encoder.layer.3.attention.self.query.bias', 'encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.17.intermediate.dense.weight', 'encoder.layer.18.attention.output.LayerNorm.weight', 'encoder.layer.5.output.LayerNorm.bias', 'encoder.layer.17.output.LayerNorm.weight', 'encoder.layer.8.output.dense.bias', 'encoder.layer.10.attention.self.query.weight', 'encoder.layer.7.output.LayerNorm.weight', 'encoder.layer.18.attention.output.dense.bias', 'encoder.layer.6.attention.output.dense.bias', 'embeddings.word_embeddings.weight', 'encoder.layer.8.attention.output.LayerNorm.weight', 'encoder.layer.1.attention.output.LayerNorm.weight', 'encoder.layer.12.attention.self.value.weight', 'encoder.layer.2.attention.self.key.bias', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.11.attention.output.LayerNorm.weight', 'encoder.layer.21.output.dense.bias', 'encoder.layer.11.attention.self.value.bias', 'encoder.layer.14.attention.self.key.bias', 'encoder.layer.4.attention.self.key.bias', 'encoder.layer.6.output.dense.bias', 'encoder.layer.19.attention.output.dense.weight', 'encoder.layer.11.attention.self.key.weight', 'encoder.layer.2.attention.self.value.weight', 'encoder.layer.22.attention.output.dense.bias', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.10.attention.output.dense.weight', 'encoder.layer.16.intermediate.dense.weight', 'encoder.layer.14.attention.self.value.bias', 'encoder.layer.17.attention.output.dense.bias', 'encoder.layer.10.attention.output.dense.bias', 'encoder.layer.22.attention.output.LayerNorm.weight', 'encoder.layer.22.attention.output.LayerNorm.bias', 'encoder.layer.0.attention.self.key.bias', 'encoder.layer.22.attention.self.key.weight', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.layer.11.output.dense.weight', 'encoder.layer.13.attention.self.query.weight', 'encoder.layer.1.attention.self.query.weight', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.13.attention.self.key.bias', 'encoder.layer.21.attention.self.query.bias', 'encoder.layer.5.attention.self.query.weight', 'encoder.layer.12.attention.self.query.bias', 'encoder.layer.10.intermediate.dense.weight', 'encoder.layer.17.attention.self.query.weight', 'encoder.layer.7.attention.self.value.weight', 'encoder.layer.11.output.LayerNorm.bias', 'encoder.layer.23.attention.self.key.bias', 'encoder.layer.21.attention.output.LayerNorm.bias', 'encoder.layer.1.attention.self.key.bias', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.23.attention.output.LayerNorm.bias', 'encoder.layer.18.attention.self.query.bias', 'encoder.layer.18.attention.self.value.weight', 'encoder.layer.19.attention.self.value.bias', 'encoder.layer.5.attention.output.dense.bias', 'encoder.layer.8.attention.self.query.weight', 'encoder.layer.3.attention.self.value.weight', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.20.attention.self.value.bias', 'encoder.layer.12.output.dense.weight', 'encoder.layer.2.attention.self.query.bias', 'encoder.layer.3.output.dense.bias', 'encoder.layer.22.attention.self.query.bias', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.16.attention.self.value.weight', 'encoder.layer.23.output.dense.weight', 'encoder.layer.22.output.dense.weight', 'encoder.layer.3.attention.self.value.bias', 'encoder.layer.8.attention.self.value.weight', 'encoder.layer.9.attention.self.value.bias', 'encoder.layer.23.attention.self.query.weight', 'encoder.layer.11.attention.self.key.bias', 'encoder.layer.20.attention.output.LayerNorm.weight', 'encoder.layer.10.attention.self.value.weight', 'encoder.layer.13.attention.output.dense.weight', 'encoder.layer.0.attention.self.query.bias', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.20.attention.self.query.bias', 'encoder.layer.15.attention.self.query.bias', 'encoder.layer.22.output.LayerNorm.weight', 'encoder.layer.12.attention.output.LayerNorm.bias', 'encoder.layer.16.output.LayerNorm.bias', 'encoder.layer.22.attention.output.dense.weight', 'encoder.layer.5.attention.self.value.weight', 'encoder.layer.15.intermediate.dense.bias', 'encoder.layer.17.intermediate.dense.bias', 'encoder.layer.8.output.LayerNorm.bias', 'encoder.layer.4.attention.self.query.weight', 'encoder.layer.17.attention.self.key.bias', 'encoder.layer.14.intermediate.dense.bias', 'encoder.layer.9.output.LayerNorm.bias', 'encoder.layer.9.attention.self.key.bias', 'encoder.layer.7.attention.self.key.weight', 'encoder.layer.14.attention.self.value.weight', 'encoder.layer.0.attention.output.dense.weight', 'encoder.layer.13.attention.output.LayerNorm.weight', 'encoder.layer.15.attention.output.LayerNorm.weight', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.7.attention.output.dense.bias', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.14.attention.output.dense.bias', 'encoder.layer.7.attention.self.value.bias', 'encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.layer.17.attention.output.LayerNorm.weight', 'encoder.layer.3.attention.self.key.bias', 'encoder.layer.18.output.LayerNorm.weight', 'encoder.layer.12.output.dense.bias', 'encoder.layer.6.attention.output.dense.weight', 'encoder.layer.19.attention.self.value.weight', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.15.attention.output.dense.weight', 'encoder.layer.11.attention.self.value.weight', 'encoder.layer.9.attention.output.dense.weight', 'encoder.layer.20.attention.output.LayerNorm.bias', 'encoder.layer.5.attention.output.dense.weight', 'encoder.layer.2.attention.output.dense.bias', 'encoder.layer.14.attention.output.dense.weight', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.4.output.dense.weight', 'encoder.layer.10.attention.self.query.bias', 'encoder.layer.3.attention.output.dense.bias', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.16.attention.self.value.bias', 'encoder.layer.20.attention.self.value.weight', 'encoder.layer.14.output.LayerNorm.bias', 'encoder.layer.19.attention.self.key.weight', 'encoder.layer.22.attention.self.query.weight', 'encoder.layer.23.output.LayerNorm.bias', 'encoder.layer.22.output.dense.bias', 'encoder.layer.6.output.dense.weight', 'encoder.layer.12.attention.self.key.bias', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.1.output.dense.weight', 'encoder.layer.20.intermediate.dense.weight', 'encoder.layer.16.attention.output.dense.bias', 'encoder.layer.9.attention.self.value.weight', 'encoder.layer.19.intermediate.dense.weight', 'encoder.layer.9.attention.output.dense.bias', 'encoder.layer.15.attention.output.dense.bias', 'encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.layer.13.intermediate.dense.bias', 'encoder.layer.17.attention.output.LayerNorm.bias', 'encoder.layer.19.attention.self.query.weight', 'encoder.layer.16.attention.output.dense.weight', 'encoder.layer.10.attention.self.value.bias', 'encoder.layer.11.attention.output.dense.weight', 'encoder.layer.18.intermediate.dense.bias', 'encoder.layer.21.attention.self.key.bias', 'encoder.layer.3.attention.self.key.weight', 'encoder.layer.7.intermediate.dense.bias', 'encoder.layer.21.attention.self.value.bias', 'encoder.layer.23.attention.self.value.weight', 'encoder.layer.7.attention.self.key.bias', 'encoder.layer.23.output.LayerNorm.weight', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.15.output.LayerNorm.bias', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.12.intermediate.dense.weight', 'encoder.layer.4.attention.self.value.weight', 'encoder.layer.21.output.LayerNorm.bias', 'encoder.layer.13.attention.output.LayerNorm.bias', 'encoder.layer.5.attention.self.key.bias', 'encoder.layer.23.attention.self.value.bias', 'encoder.layer.7.attention.self.query.weight', 'encoder.layer.20.intermediate.dense.bias', 'pooler.dense.bias', 'encoder.layer.10.output.dense.bias', 'encoder.layer.0.attention.output.LayerNorm.weight', 'encoder.layer.3.output.dense.weight', 'encoder.layer.6.attention.self.value.weight', 'encoder.layer.5.attention.self.value.bias', 'encoder.layer.19.attention.output.dense.bias', 'encoder.layer.15.attention.self.value.bias', 'encoder.layer.12.intermediate.dense.bias', 'encoder.layer.1.attention.output.dense.weight', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.0.attention.self.value.bias', 'encoder.layer.11.output.LayerNorm.weight', 'encoder.layer.7.attention.self.query.bias', 'encoder.layer.11.attention.output.dense.bias', 'encoder.layer.17.output.dense.weight', 'encoder.layer.21.intermediate.dense.weight', 'encoder.layer.4.attention.self.key.weight', 'encoder.layer.6.attention.self.key.bias', 'encoder.layer.9.attention.self.key.weight', 'encoder.layer.23.attention.output.dense.bias', 'encoder.layer.18.attention.self.query.weight', 'encoder.layer.13.attention.self.key.weight', 'encoder.layer.22.intermediate.dense.bias', 'encoder.layer.12.attention.self.value.bias', 'encoder.layer.9.attention.output.LayerNorm.bias', 'encoder.layer.2.output.dense.bias', 'encoder.layer.23.attention.self.query.bias', 'encoder.layer.15.attention.self.value.weight', 'encoder.layer.19.output.dense.bias', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.16.output.LayerNorm.weight', 'encoder.layer.15.output.dense.bias', 'encoder.layer.17.output.LayerNorm.bias', 'encoder.layer.2.output.dense.weight', 'encoder.layer.14.attention.output.LayerNorm.bias', 'encoder.layer.20.attention.self.query.weight', 'encoder.layer.22.intermediate.dense.weight', 'encoder.layer.15.output.dense.weight', 'encoder.layer.21.attention.output.dense.bias', 'encoder.layer.8.attention.self.key.bias', 'encoder.layer.8.attention.output.dense.bias', 'encoder.layer.15.attention.self.query.weight', 'encoder.layer.15.intermediate.dense.weight', 'encoder.layer.6.attention.self.query.weight', 'encoder.layer.17.attention.self.value.weight', 'encoder.layer.10.output.dense.weight', 'encoder.layer.21.intermediate.dense.bias', 'encoder.layer.11.attention.self.query.bias', 'encoder.layer.8.attention.output.dense.weight', 'encoder.layer.12.output.LayerNorm.bias', 'encoder.layer.2.attention.output.LayerNorm.bias', 'encoder.layer.21.attention.self.key.weight', 'encoder.layer.9.attention.output.LayerNorm.weight', 'encoder.layer.21.attention.self.query.weight', 'encoder.layer.9.attention.self.query.bias', 'encoder.layer.2.attention.output.dense.weight', 'encoder.layer.10.attention.output.LayerNorm.bias', 'encoder.layer.16.attention.self.query.bias', 'encoder.layer.13.attention.self.value.weight', 'encoder.layer.6.attention.self.value.bias', 'encoder.layer.18.attention.self.key.weight', 'encoder.layer.15.attention.self.key.weight', 'encoder.layer.18.output.LayerNorm.bias', 'encoder.layer.12.attention.self.query.weight', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.10.output.LayerNorm.weight', 'encoder.layer.6.attention.self.query.bias', 'encoder.layer.14.attention.self.query.weight', 'encoder.layer.11.attention.self.query.weight', 'encoder.layer.23.attention.self.key.weight', 'encoder.layer.19.attention.self.key.bias', 'encoder.layer.18.attention.self.key.bias', 'encoder.layer.3.attention.self.query.weight', 'encoder.layer.18.intermediate.dense.weight', 'encoder.layer.12.attention.output.dense.weight', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.7.output.dense.bias', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.13.attention.output.dense.bias', 'encoder.layer.21.output.dense.weight', 'encoder.layer.7.attention.output.dense.weight', 'encoder.layer.4.attention.output.LayerNorm.bias', 'encoder.layer.13.output.LayerNorm.bias', 'encoder.layer.14.attention.output.LayerNorm.weight', 'encoder.layer.18.output.dense.bias', 'encoder.layer.21.attention.output.dense.weight', 'encoder.layer.1.attention.output.dense.bias', 'encoder.layer.20.output.dense.bias', 'encoder.layer.5.attention.self.key.weight', 'encoder.layer.16.attention.self.query.weight', 'encoder.layer.20.output.LayerNorm.weight', 'encoder.layer.2.attention.self.value.bias', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.19.intermediate.dense.bias', 'encoder.layer.21.output.LayerNorm.weight', 'encoder.layer.9.output.LayerNorm.weight', 'encoder.layer.2.attention.self.key.weight', 'encoder.layer.22.attention.self.value.weight', 'encoder.layer.3.attention.output.dense.weight', 'encoder.layer.12.attention.output.LayerNorm.weight', 'encoder.layer.7.attention.output.LayerNorm.bias', 'encoder.layer.0.attention.output.dense.bias', 'encoder.layer.11.output.dense.bias', 'encoder.layer.8.attention.self.key.weight', 'encoder.layer.13.output.dense.bias', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.20.attention.output.dense.bias', 'encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.13.attention.self.query.bias', 'encoder.layer.19.output.LayerNorm.weight', 'encoder.layer.22.output.LayerNorm.bias', 'encoder.layer.5.attention.self.query.bias', 'encoder.layer.10.output.LayerNorm.bias', 'encoder.layer.15.attention.output.LayerNorm.bias', 'encoder.layer.0.attention.self.value.weight', 'encoder.layer.17.attention.self.value.bias', 'encoder.layer.19.output.dense.weight', 'encoder.layer.1.attention.self.key.weight', 'encoder.layer.7.output.dense.weight', 'encoder.layer.13.attention.self.value.bias', 'encoder.layer.7.output.LayerNorm.bias', 'encoder.layer.10.attention.output.LayerNorm.weight', 'encoder.layer.19.attention.self.query.bias', 'encoder.layer.14.attention.self.query.bias', 'encoder.layer.0.output.dense.bias', 'encoder.layer.8.attention.self.query.bias', 'encoder.layer.2.attention.self.query.weight', 'encoder.layer.4.attention.self.query.bias', 'encoder.layer.6.attention.output.LayerNorm.weight', 'encoder.layer.9.attention.self.query.weight', 'encoder.layer.20.attention.self.key.bias', 'encoder.layer.23.attention.output.LayerNorm.weight', 'encoder.layer.16.attention.output.LayerNorm.weight', 'encoder.layer.17.output.dense.bias', 'encoder.layer.16.attention.self.key.weight', 'encoder.layer.23.intermediate.dense.bias', 'encoder.layer.9.output.dense.bias', 'encoder.layer.20.attention.output.dense.weight', 'encoder.layer.18.attention.output.LayerNorm.bias', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.4.attention.self.value.bias', 'encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.layer.0.attention.self.key.weight', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.10.attention.self.key.weight', 'encoder.layer.23.attention.output.dense.weight', 'encoder.layer.5.attention.output.LayerNorm.weight', 'encoder.layer.5.output.dense.weight', 'encoder.layer.18.attention.output.dense.weight', 'encoder.layer.12.output.LayerNorm.weight', 'encoder.layer.14.output.LayerNorm.weight', 'encoder.layer.14.output.dense.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Overwriting existing adapter 'ep'.
Overwriting existing adapter 'tp'.
Overwriting existing adapter 'es'.
Overwriting existing adapter 'ts'.
Overwriting existing adapter fusion module 'ep,tp,es,ts'
05/09/2022 09:15:46 - INFO - __main__ -   lang2id = None
05/09/2022 09:15:51 - INFO - __main__ -   Training/evaluation parameters Namespace(adam_epsilon=1e-08, cache_dir='', config_name='', data_dir=None, device=device(type='cuda'), do_eval=True, do_lower_case=False, do_train=False, doc_stride=128, eval_all_checkpoints=False, eval_lang='th', evaluate_during_training=False, fp16=False, fp16_opt_level='O1', gradient_accumulation_steps=1, learning_rate=5e-05, local_rank=-1, logging_steps=50, max_answer_length=30, max_grad_norm=1.0, max_query_length=64, max_seq_length=384, max_steps=-1, model_name='xlm-KG', model_name_or_path='/cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//squad/xlm-KG_LR3e-5_EPOCH2.0_maxlen384_batchsize4_gradacc4', model_type='xlm', modelkg_dir='/cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/adapter/xlmr_adapter', n_best_size=20, n_gpu=1, no_cuda=False, null_score_diff_threshold=0.0, num_train_epochs=3.0, output_dir='/cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//squad/xlm-KG_LR3e-5_EPOCH2.0_maxlen384_batchsize4_gradacc4/predictions/xquad/', overwrite_cache=False, overwrite_output_dir=False, per_gpu_eval_batch_size=8, per_gpu_train_batch_size=8, predict_file='/cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/download//xquad//xquad.th.json', save_steps=50, seed=42, server_ip='', server_port='', threads=1, tokenizer_name='', train_file=None, train_lang='en', verbose_logging=False, version_2_with_negative=False, warmup_steps=0, weight_decay=0.0)
05/09/2022 09:15:51 - INFO - __main__ -   Loading checkpoint /cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//squad/xlm-KG_LR3e-5_EPOCH2.0_maxlen384_batchsize4_gradacc4 for evaluation
05/09/2022 09:15:51 - INFO - __main__ -   Evaluate the following checkpoints: ['/cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//squad/xlm-KG_LR3e-5_EPOCH2.0_maxlen384_batchsize4_gradacc4']
Some weights of the model checkpoint at /cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//squad/xlm-KG_LR3e-5_EPOCH2.0_maxlen384_batchsize4_gradacc4 were not used when initializing XLMRobertaModel: ['base_model.encoder.layer.20.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.11.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.12.attention.self.value.weight', 'base_model.encoder.layer.8.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.20.intermediate.dense.weight', 'base_model.encoder.layer.14.attention.output.dense.weight', 'base_model.encoder.layer.21.attention.self.value.weight', 'base_model.encoder.layer.2.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.23.attention.self.key.bias', 'base_model.encoder.layer.21.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.8.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.3.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.16.intermediate.dense.weight', 'base_model.encoder.layer.18.attention.self.query.bias', 'base_model.encoder.layer.5.attention.self.key.weight', 'base_model.encoder.layer.5.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.7.attention.self.value.weight', 'base_model.encoder.layer.23.output.LayerNorm.weight', 'base_model.encoder.layer.0.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.1.output.LayerNorm.bias', 'base_model.encoder.layer.22.intermediate.dense.bias', 'base_model.encoder.layer.23.attention.output.dense.weight', 'base_model.encoder.layer.17.attention.output.dense.weight', 'base_model.encoder.layer.23.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.21.attention.self.value.bias', 'base_model.encoder.layer.10.attention.self.value.bias', 'base_model.encoder.layer.2.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.9.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.6.attention.output.LayerNorm.bias', 'base_model.encoder.layer.16.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.5.intermediate.dense.bias', 'base_model.encoder.layer.9.intermediate.dense.weight', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.8.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.23.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.21.attention.output.dense.bias', 'base_model.encoder.layer.20.attention.output.LayerNorm.bias', 'base_model.encoder.layer.1.attention.output.LayerNorm.weight', 'base_model.encoder.layer.6.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.8.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.12.attention.output.dense.bias', 'base_model.encoder.layer.23.attention.output.LayerNorm.bias', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.13.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.12.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.9.attention.self.key.weight', 'base_model.encoder.layer.20.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.20.output.LayerNorm.weight', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.19.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.2.output.dense.weight', 'base_model.encoder.layer.9.output.dense.weight', 'base_model.encoder.layer.8.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.21.intermediate.dense.bias', 'base_model.encoder.layer.3.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.9.attention.self.value.bias', 'base_model.encoder.layer.10.attention.output.LayerNorm.bias', 'base_model.encoder.layer.15.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.15.attention.output.dense.weight', 'base_model.encoder.layer.18.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.5.attention.output.dense.weight', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.7.output.dense.bias', 'base_model.encoder.layer.20.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.16.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.14.output.dense.bias', 'base_model.encoder.layer.7.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.21.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.19.attention.self.value.weight', 'base_model.encoder.layer.1.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.5.attention.self.key.bias', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.4.attention.self.key.weight', 'base_model.encoder.layer.7.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.3.output.LayerNorm.bias', 'base_model.encoder.layer.12.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.12.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.4.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.10.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.10.attention.self.query.weight', 'base_model.encoder.layer.13.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.4.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.5.attention.output.LayerNorm.weight', 'base_model.encoder.layer.7.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.17.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.2.intermediate.dense.bias', 'base_model.encoder.layer.18.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.21.attention.output.dense.weight', 'base_model.encoder.layer.18.attention.output.LayerNorm.weight', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.8.attention.self.key.weight', 'base_model.encoder.layer.0.attention.self.query.bias', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.13.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.22.output.LayerNorm.bias', 'base_model.encoder.layer.1.attention.self.query.weight', 'base_model.encoder.layer.1.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.8.output.dense.bias', 'base_model.encoder.layer.8.intermediate.dense.bias', 'base_model.encoder.layer.2.output.dense.bias', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.17.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.20.attention.self.value.bias', 'base_model.encoder.layer.1.attention.self.value.bias', 'base_model.encoder.layer.0.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.2.attention.self.query.weight', 'base_model.encoder.layer.18.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.23.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.9.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.4.attention.self.value.weight', 'base_model.encoder.layer.3.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.22.attention.self.query.weight', 'base_model.encoder.layer.4.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.13.attention.self.query.weight', 'base_model.encoder.layer.13.attention.self.value.weight', 'base_model.encoder.layer.0.attention.self.key.bias', 'base_model.encoder.layer.6.attention.output.dense.bias', 'base_model.encoder.layer.17.attention.self.key.weight', 'base_model.encoder.layer.18.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.16.attention.self.query.weight', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.2.output.LayerNorm.bias', 'base_model.encoder.layer.10.attention.output.dense.weight', 'base_model.encoder.layer.6.attention.self.value.bias', 'base_model.encoder.layer.22.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.16.intermediate.dense.bias', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.23.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.11.output.dense.bias', 'base_model.encoder.layer.9.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.17.attention.self.query.bias', 'base_model.encoder.layer.11.attention.output.dense.bias', 'base_model.encoder.layer.0.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.14.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.8.attention.output.dense.weight', 'base_model.encoder.layer.14.attention.output.LayerNorm.weight', 'base_model.encoder.layer.21.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.22.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.13.attention.self.value.bias', 'base_model.encoder.layer.17.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.23.attention.self.value.bias', 'base_model.encoder.layer.2.attention.output.LayerNorm.bias', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.5.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.21.output.dense.bias', 'base_model.encoder.layer.11.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.19.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.5.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.10.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.1.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.19.attention.self.value.bias', 'base_model.encoder.layer.2.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.10.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.11.attention.self.query.bias', 'base_model.encoder.layer.12.intermediate.dense.weight', 'base_model.encoder.layer.19.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.5.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.5.attention.self.value.bias', 'base_model.encoder.layer.2.attention.self.key.weight', 'base_model.encoder.layer.2.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.1.attention.output.dense.bias', 'base_model.encoder.layer.4.attention.self.key.bias', 'base_model.encoder.layer.7.attention.output.LayerNorm.weight', 'base_model.encoder.layer.11.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.12.intermediate.dense.bias', 'base_model.encoder.layer.12.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.15.attention.self.query.weight', 'base_model.encoder.layer.16.attention.output.LayerNorm.weight', 'base_model.encoder.layer.19.attention.output.LayerNorm.bias', 'base_model.encoder.layer.18.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.13.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.13.output.dense.bias', 'base_model.encoder.layer.21.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.11.intermediate.dense.bias', 'base_model.encoder.layer.10.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.6.attention.output.LayerNorm.weight', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.13.attention.output.LayerNorm.bias', 'base_model.encoder.layer.22.output.adapters.es.adapter_down.0.bias', 'base_model.embeddings.position_embeddings.weight', 'base_model.encoder.layer.13.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.11.attention.self.query.weight', 'base_model.encoder.layer.16.output.adapters.es.adapter_up.weight', 'qa_outputs.weight', 'base_model.encoder.layer.2.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.18.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.21.intermediate.dense.weight', 'base_model.encoder.layer.17.attention.self.key.bias', 'base_model.encoder.layer.0.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.1.attention.output.LayerNorm.bias', 'base_model.encoder.layer.7.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.7.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.9.attention.output.dense.bias', 'base_model.encoder.layer.19.attention.self.key.bias', 'base_model.encoder.layer.19.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.10.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.7.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.22.attention.self.key.weight', 'base_model.encoder.layer.19.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.18.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.16.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.19.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.22.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.1.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.2.attention.output.LayerNorm.weight', 'base_model.encoder.layer.4.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.11.attention.output.LayerNorm.weight', 'base_model.encoder.layer.12.attention.output.LayerNorm.bias', 'base_model.encoder.layer.1.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.21.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.20.output.dense.bias', 'base_model.encoder.layer.20.attention.self.query.weight', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.20.output.LayerNorm.bias', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.7.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.22.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.12.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.15.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.16.attention.self.key.weight', 'base_model.pooler.dense.bias', 'base_model.encoder.layer.17.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.3.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.10.output.LayerNorm.weight', 'base_model.encoder.layer.22.attention.self.key.bias', 'base_model.encoder.layer.15.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.17.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.23.attention.output.LayerNorm.weight', 'base_model.encoder.layer.20.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.18.attention.output.dense.bias', 'base_model.encoder.layer.14.attention.self.value.bias', 'base_model.encoder.layer.6.attention.self.value.weight', 'base_model.encoder.layer.13.attention.self.key.bias', 'base_model.encoder.layer.7.attention.self.key.bias', 'base_model.encoder.layer.11.attention.self.key.bias', 'base_model.encoder.layer.11.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.3.output.dense.bias', 'base_model.encoder.layer.0.attention.self.value.bias', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.9.output.dense.bias', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.13.output.LayerNorm.weight', 'base_model.encoder.layer.17.attention.self.value.bias', 'base_model.encoder.layer.6.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.9.attention.output.dense.weight', 'base_model.encoder.layer.6.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.5.output.LayerNorm.bias', 'base_model.encoder.layer.5.output.dense.bias', 'base_model.encoder.layer.0.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.10.attention.output.LayerNorm.weight', 'base_model.encoder.layer.17.intermediate.dense.bias', 'base_model.encoder.layer.9.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.15.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.14.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.5.attention.output.LayerNorm.bias', 'base_model.encoder.layer.16.output.dense.bias', 'base_model.encoder.layer.3.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.18.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.0.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.8.attention.self.query.weight', 'base_model.encoder.layer.19.attention.self.key.weight', 'base_model.encoder.layer.12.attention.self.value.bias', 'base_model.encoder.layer.17.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.9.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.5.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.16.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.13.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.23.intermediate.dense.weight', 'base_model.encoder.layer.14.intermediate.dense.bias', 'base_model.encoder.layer.1.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.11.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.5.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.7.attention.output.dense.weight', 'base_model.encoder.layer.13.attention.output.dense.bias', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.4.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.2.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.8.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.14.attention.self.value.weight', 'base_model.encoder.layer.11.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.3.attention.output.LayerNorm.bias', 'base_model.encoder.layer.4.output.LayerNorm.bias', 'base_model.encoder.layer.6.attention.output.dense.weight', 'base_model.encoder.layer.12.attention.self.key.bias', 'base_model.encoder.layer.6.attention.self.key.bias', 'base_model.encoder.layer.15.attention.output.LayerNorm.weight', 'base_model.encoder.layer.7.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.18.attention.self.key.bias', 'base_model.encoder.layer.22.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.8.attention.output.LayerNorm.weight', 'base_model.encoder.layer.3.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.15.attention.output.LayerNorm.bias', 'base_model.encoder.layer.3.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.7.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.8.attention.self.value.bias', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.9.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.14.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.18.attention.self.query.weight', 'base_model.embeddings.word_embeddings.weight', 'base_model.encoder.layer.15.intermediate.dense.bias', 'base_model.encoder.layer.17.output.LayerNorm.bias', 'base_model.encoder.layer.7.attention.self.key.weight', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.21.output.LayerNorm.weight', 'base_model.encoder.layer.14.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.9.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.2.output.LayerNorm.weight', 'base_model.encoder.layer.0.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.6.output.LayerNorm.weight', 'base_model.encoder.layer.1.output.dense.weight', 'base_model.encoder.layer.4.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.14.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.4.attention.output.LayerNorm.bias', 'base_model.encoder.layer.12.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.22.attention.output.LayerNorm.weight', 'base_model.encoder.layer.23.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.17.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.11.intermediate.dense.weight', 'base_model.encoder.layer.18.attention.self.value.weight', 'base_model.encoder.layer.9.attention.self.value.weight', 'base_model.encoder.layer.3.attention.self.key.weight', 'base_model.encoder.layer.4.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.18.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.20.attention.output.dense.weight', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.19.attention.output.dense.weight', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.20.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.23.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.0.output.dense.bias', 'base_model.encoder.layer.0.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.8.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.22.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.19.output.LayerNorm.bias', 'base_model.encoder.layer.18.intermediate.dense.weight', 'base_model.encoder.layer.4.attention.output.dense.weight', 'base_model.encoder.layer.1.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.4.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.9.output.LayerNorm.bias', 'base_model.encoder.layer.0.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.11.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.10.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.12.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.15.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.18.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.5.attention.self.query.weight', 'base_model.encoder.layer.15.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.3.attention.output.dense.weight', 'base_model.encoder.layer.10.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.4.attention.self.query.weight', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.14.attention.self.key.weight', 'base_model.encoder.layer.18.attention.self.key.weight', 'base_model.encoder.layer.16.output.LayerNorm.bias', 'base_model.encoder.layer.21.attention.self.key.bias', 'base_model.encoder.layer.22.attention.output.LayerNorm.bias', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.15.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.12.output.LayerNorm.bias', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.21.attention.self.query.weight', 'base_model.encoder.layer.22.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.21.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.0.intermediate.dense.bias', 'base_model.encoder.layer.21.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.3.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.8.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.15.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.3.output.LayerNorm.weight', 'base_model.encoder.layer.7.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.0.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.18.attention.output.dense.weight', 'base_model.encoder.layer.5.attention.output.dense.bias', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.7.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.12.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.23.attention.self.query.bias', 'base_model.encoder.layer.0.attention.output.dense.bias', 'base_model.encoder.layer.14.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.23.attention.output.dense.bias', 'base_model.encoder.layer.3.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.17.output.dense.bias', 'base_model.encoder.layer.1.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.8.output.dense.weight', 'base_model.encoder.layer.22.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.1.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.9.attention.self.key.bias', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.11.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.17.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.14.intermediate.dense.weight', 'base_model.encoder.layer.5.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.23.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.17.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.14.attention.self.query.weight', 'base_model.encoder.layer.20.attention.output.LayerNorm.weight', 'base_model.encoder.layer.23.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.16.attention.output.LayerNorm.bias', 'base_model.encoder.layer.22.attention.output.dense.weight', 'base_model.encoder.layer.11.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.16.attention.output.dense.weight', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.17.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.3.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.15.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.20.output.dense.weight', 'base_model.encoder.layer.5.output.dense.weight', 'base_model.encoder.layer.18.attention.output.LayerNorm.bias', 'base_model.encoder.layer.20.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.0.output.LayerNorm.weight', 'base_model.encoder.layer.21.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.3.attention.output.LayerNorm.weight', 'base_model.encoder.layer.19.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.1.intermediate.dense.weight', 'base_model.encoder.layer.7.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.22.intermediate.dense.weight', 'base_model.encoder.layer.17.output.LayerNorm.weight', 'base_model.encoder.layer.18.output.dense.weight', 'base_model.encoder.layer.9.attention.self.query.weight', 'base_model.encoder.layer.4.intermediate.dense.bias', 'base_model.encoder.layer.14.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.16.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.10.attention.self.key.weight', 'base_model.encoder.layer.5.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.9.output.LayerNorm.weight', 'base_model.encoder.layer.22.output.dense.bias', 'base_model.encoder.layer.15.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.23.output.adapters.ts.adapter_up.weight', 'base_model.embeddings.position_ids', 'base_model.encoder.layer.6.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.15.attention.output.dense.bias', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.4.attention.self.value.bias', 'base_model.encoder.layer.5.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.8.attention.output.dense.bias', 'base_model.encoder.layer.14.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.19.attention.output.dense.bias', 'base_model.encoder.layer.20.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.15.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.18.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.1.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.1.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.10.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.18.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.3.attention.self.query.bias', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.19.output.dense.bias', 'base_model.encoder.layer.7.output.LayerNorm.weight', 'base_model.encoder.layer.12.output.LayerNorm.weight', 'base_model.encoder.layer.19.intermediate.dense.weight', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.6.attention.self.key.weight', 'base_model.encoder.layer.6.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.17.intermediate.dense.weight', 'base_model.encoder.layer.2.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.2.attention.self.value.weight', 'base_model.encoder.layer.1.attention.self.key.weight', 'base_model.encoder.layer.3.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.15.attention.self.key.bias', 'base_model.encoder.layer.16.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.12.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.0.output.dense.weight', 'base_model.encoder.layer.13.attention.output.dense.weight', 'base_model.encoder.layer.22.attention.self.query.bias', 'base_model.encoder.layer.11.output.dense.weight', 'base_model.encoder.layer.22.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.4.attention.output.LayerNorm.weight', 'base_model.encoder.layer.8.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.19.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.5.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.13.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.22.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.5.intermediate.dense.weight', 'base_model.encoder.layer.12.attention.self.query.weight', 'base_model.encoder.layer.12.output.dense.bias', 'base_model.encoder.layer.13.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.23.output.LayerNorm.bias', 'base_model.encoder.layer.0.attention.output.dense.weight', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.8.intermediate.dense.weight', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.10.attention.output.dense.bias', 'base_model.encoder.layer.14.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.13.attention.output.LayerNorm.weight', 'base_model.encoder.layer.16.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.8.attention.self.query.bias', 'base_model.encoder.layer.9.intermediate.dense.bias', 'base_model.encoder.layer.3.intermediate.dense.bias', 'base_model.encoder.layer.18.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.2.attention.self.value.bias', 'base_model.encoder.layer.1.attention.self.value.weight', 'base_model.encoder.layer.7.attention.self.value.bias', 'base_model.encoder.layer.6.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.10.output.dense.bias', 'base_model.encoder.layer.17.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.22.attention.output.dense.bias', 'base_model.encoder.layer.16.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.7.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.11.attention.output.LayerNorm.bias', 'base_model.encoder.layer.3.attention.self.value.bias', 'base_model.encoder.layer.23.attention.self.query.weight', 'base_model.encoder.layer.0.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.10.attention.self.value.weight', 'base_model.encoder.layer.6.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.8.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.13.intermediate.dense.bias', 'base_model.encoder.layer.20.attention.self.key.weight', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.23.output.dense.weight', 'base_model.encoder.layer.20.intermediate.dense.bias', 'base_model.encoder.layer.19.output.dense.weight', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.19.attention.self.query.bias', 'base_model.encoder.layer.19.intermediate.dense.bias', 'base_model.encoder.layer.20.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.7.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.17.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.19.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.10.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.17.attention.output.dense.bias', 'base_model.encoder.layer.17.attention.self.query.weight', 'base_model.encoder.layer.21.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.10.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.4.output.dense.bias', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.16.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.12.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.18.output.LayerNorm.bias', 'base_model.encoder.layer.9.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.11.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.12.attention.output.LayerNorm.weight', 'base_model.encoder.layer.23.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.6.intermediate.dense.bias', 'base_model.encoder.layer.19.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.16.attention.self.query.bias', 'base_model.encoder.layer.3.attention.self.key.bias', 'base_model.encoder.layer.0.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.18.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.13.intermediate.dense.weight', 'base_model.encoder.layer.8.attention.self.key.bias', 'base_model.encoder.layer.21.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.4.intermediate.dense.weight', 'base_model.encoder.layer.7.output.adapters.tp.adapter_up.weight', 'qa_outputs.bias', 'base_model.encoder.layer.7.attention.self.query.weight', 'base_model.encoder.layer.14.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.16.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.20.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.9.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.9.attention.self.query.bias', 'base_model.encoder.layer.12.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.13.output.dense.weight', 'base_model.encoder.layer.8.output.LayerNorm.weight', 'base_model.encoder.layer.4.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.7.intermediate.dense.weight', 'base_model.encoder.layer.9.attention.output.LayerNorm.bias', 'base_model.encoder.layer.6.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.16.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.20.attention.output.dense.bias', 'base_model.encoder.layer.12.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.23.output.dense.bias', 'base_model.encoder.layer.12.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.19.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.7.attention.output.dense.bias', 'base_model.encoder.layer.1.attention.self.key.bias', 'base_model.encoder.layer.7.attention.self.query.bias', 'base_model.encoder.layer.10.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.2.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.11.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.21.output.LayerNorm.bias', 'base_model.encoder.layer.9.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.15.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.20.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.16.attention.self.key.bias', 'base_model.encoder.layer.18.intermediate.dense.bias', 'base_model.encoder.layer.21.attention.output.LayerNorm.bias', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.21.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.12.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.14.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.22.output.dense.weight', 'base_model.encoder.layer.10.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.19.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.12.output.dense.weight', 'base_model.encoder.layer.9.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.23.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.12.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.19.attention.output.LayerNorm.weight', 'base_model.encoder.layer.20.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.14.attention.self.query.bias', 'base_model.encoder.layer.13.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.4.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.11.output.LayerNorm.weight', 'base_model.encoder.layer.19.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.10.intermediate.dense.weight', 'base_model.encoder.layer.14.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.6.attention.self.query.weight', 'base_model.encoder.layer.0.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.2.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.9.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.3.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.1.output.LayerNorm.weight', 'base_model.encoder.layer.15.attention.self.key.weight', 'base_model.encoder.layer.7.output.LayerNorm.bias', 'base_model.encoder.layer.15.output.LayerNorm.bias', 'base_model.encoder.layer.14.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.19.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.19.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.1.attention.self.query.bias', 'base_model.encoder.layer.21.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.0.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.23.intermediate.dense.bias', 'base_model.encoder.layer.11.attention.self.key.weight', 'base_model.encoder.layer.3.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.4.output.LayerNorm.weight', 'base_model.encoder.layer.15.output.dense.weight', 'base_model.encoder.layer.14.output.LayerNorm.weight', 'base_model.encoder.layer.17.attention.self.value.weight', 'base_model.encoder.layer.4.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.6.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.11.attention.output.dense.weight', 'base_model.encoder.layer.22.attention.self.value.bias', 'base_model.encoder.layer.2.attention.self.query.bias', 'base_model.encoder.layer.17.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.2.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.5.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.11.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.18.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.0.attention.output.LayerNorm.weight', 'base_model.encoder.layer.1.intermediate.dense.bias', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.20.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.18.output.LayerNorm.weight', 'base_model.encoder.layer.0.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.4.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.6.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.21.output.dense.weight', 'base_model.encoder.layer.4.attention.self.query.bias', 'base_model.encoder.layer.4.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.12.attention.self.query.bias', 'base_model.encoder.layer.15.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.8.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.22.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.0.attention.self.query.weight', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.17.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.3.output.dense.weight', 'base_model.encoder.layer.5.attention.self.value.weight', 'base_model.encoder.layer.10.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.8.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.1.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.6.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.11.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.12.attention.output.dense.weight', 'base_model.encoder.layer.16.attention.output.dense.bias', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.0.attention.self.key.weight', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.14.attention.output.dense.bias', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.3.attention.self.query.weight', 'base_model.encoder.layer.17.attention.output.LayerNorm.bias', 'base_model.encoder.layer.21.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.7.intermediate.dense.bias', 'base_model.encoder.layer.18.attention.self.value.bias', 'base_model.encoder.layer.9.output.adapters.ts.adapter_up.weight', 'base_model.embeddings.LayerNorm.weight', 'base_model.encoder.layer.4.attention.output.dense.bias', 'base_model.encoder.layer.15.attention.self.value.bias', 'base_model.encoder.layer.11.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.8.attention.self.value.weight', 'base_model.encoder.layer.11.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.10.output.dense.weight', 'base_model.encoder.layer.14.output.LayerNorm.bias', 'base_model.encoder.layer.1.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.10.output.LayerNorm.bias', 'base_model.encoder.layer.20.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.2.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.11.attention.self.value.weight', 'base_model.encoder.layer.6.output.LayerNorm.bias', 'base_model.encoder.layer.8.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.16.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.23.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.15.attention.self.value.weight', 'base_model.encoder.layer.16.attention.self.value.bias', 'base_model.encoder.layer.6.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.17.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.2.attention.self.key.bias', 'base_model.encoder.layer.6.output.dense.weight', 'base_model.encoder.layer.10.intermediate.dense.bias', 'base_model.encoder.layer.4.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.22.attention.self.value.weight', 'base_model.encoder.layer.2.attention.output.dense.weight', 'base_model.embeddings.LayerNorm.bias', 'base_model.encoder.layer.20.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.3.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.9.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.9.attention.output.LayerNorm.weight', 'base_model.encoder.layer.19.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.20.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.22.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.3.intermediate.dense.weight', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.6.output.dense.bias', 'base_model.encoder.layer.21.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.12.attention.self.key.weight', 'base_model.encoder.layer.23.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.embeddings.token_type_embeddings.weight', 'base_model.encoder.layer.1.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.19.output.LayerNorm.weight', 'base_model.encoder.layer.9.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.21.attention.self.query.bias', 'base_model.encoder.layer.22.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.6.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.18.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.20.attention.self.value.weight', 'base_model.encoder.layer.16.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.13.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.16.output.LayerNorm.weight', 'base_model.encoder.layer.22.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.13.attention.self.key.weight', 'base_model.encoder.layer.2.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.5.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.0.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.10.attention.self.key.bias', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.3.attention.output.dense.bias', 'base_model.encoder.layer.21.attention.output.LayerNorm.weight', 'base_model.encoder.layer.17.output.dense.weight', 'base_model.encoder.layer.7.attention.output.LayerNorm.bias', 'base_model.encoder.layer.2.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.13.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.14.attention.self.key.bias', 'base_model.encoder.layer.4.output.dense.weight', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.1.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.1.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.0.output.LayerNorm.bias', 'base_model.encoder.layer.15.output.LayerNorm.weight', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.15.output.dense.bias', 'base_model.encoder.layer.17.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.13.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.23.attention.self.key.weight', 'base_model.encoder.layer.16.attention.self.value.weight', 'base_model.encoder.layer.6.intermediate.dense.weight', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.5.output.LayerNorm.weight', 'base_model.encoder.layer.1.output.dense.bias', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.11.output.LayerNorm.bias', 'base_model.encoder.layer.23.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.7.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.3.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.8.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.0.attention.output.LayerNorm.bias', 'base_model.encoder.layer.5.attention.self.query.bias', 'base_model.encoder.layer.2.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.13.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.5.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.0.intermediate.dense.weight', 'base_model.encoder.layer.18.output.dense.bias', 'base_model.encoder.layer.8.attention.output.LayerNorm.bias', 'base_model.encoder.layer.15.attention.self.query.bias', 'base_model.encoder.layer.15.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.6.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.21.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.8.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.17.attention.output.LayerNorm.weight', 'base_model.encoder.layer.23.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.19.attention.self.query.weight', 'base_model.encoder.layer.11.attention.self.value.bias', 'base_model.encoder.layer.23.output.adapters.ep.adapter_down.0.bias', 'base_model.pooler.dense.weight', 'base_model.encoder.layer.5.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.10.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.11.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.13.attention.self.query.bias', 'base_model.encoder.layer.15.intermediate.dense.weight', 'base_model.encoder.layer.6.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.14.output.dense.weight', 'base_model.encoder.layer.16.output.dense.weight', 'base_model.encoder.layer.8.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.10.attention.self.query.bias', 'base_model.encoder.layer.4.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.20.attention.self.query.bias', 'base_model.encoder.layer.20.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.3.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.14.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.2.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.7.output.dense.weight', 'base_model.encoder.layer.3.attention.self.value.weight', 'base_model.encoder.layer.21.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.22.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.10.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.4.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.13.output.LayerNorm.bias', 'base_model.encoder.layer.0.attention.self.value.weight', 'base_model.encoder.layer.21.attention.self.key.weight', 'base_model.encoder.layer.16.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.2.intermediate.dense.weight', 'base_model.encoder.layer.13.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.15.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.15.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.10.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.13.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.14.attention.output.LayerNorm.bias', 'base_model.encoder.layer.16.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.1.attention.output.dense.weight', 'base_model.encoder.layer.6.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.12.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.14.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.5.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.2.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.9.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.13.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.6.attention.self.query.bias', 'base_model.encoder.layer.2.attention.output.dense.bias', 'base_model.encoder.layer.14.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.5.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.20.attention.self.key.bias', 'base_model.encoder.layer.23.attention.self.value.weight', 'base_model.encoder.layer.22.output.LayerNorm.weight', 'base_model.encoder.layer.8.output.LayerNorm.bias']
- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of XLMRobertaModel were not initialized from the model checkpoint at /cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//squad/xlm-KG_LR3e-5_EPOCH2.0_maxlen384_batchsize4_gradacc4 and are newly initialized: ['encoder.layer.6.attention.self.key.weight', 'encoder.layer.20.output.LayerNorm.bias', 'encoder.layer.20.attention.self.key.weight', 'encoder.layer.4.attention.output.LayerNorm.weight', 'encoder.layer.12.attention.output.dense.bias', 'encoder.layer.14.attention.self.key.weight', 'encoder.layer.20.output.dense.weight', 'encoder.layer.22.attention.self.value.bias', 'encoder.layer.12.attention.self.key.weight', 'encoder.layer.23.intermediate.dense.weight', 'encoder.layer.19.output.LayerNorm.bias', 'embeddings.LayerNorm.bias', 'encoder.layer.17.attention.self.query.bias', 'encoder.layer.8.attention.self.value.bias', 'encoder.layer.19.attention.output.LayerNorm.weight', 'encoder.layer.18.attention.self.value.bias', 'encoder.layer.2.attention.output.LayerNorm.weight', 'encoder.layer.8.output.LayerNorm.weight', 'pooler.dense.weight', 'encoder.layer.0.output.dense.weight', 'encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.layer.7.attention.output.LayerNorm.weight', 'encoder.layer.17.attention.self.key.weight', 'encoder.layer.15.attention.self.key.bias', 'encoder.layer.21.attention.self.value.weight', 'encoder.layer.16.attention.output.LayerNorm.bias', 'encoder.layer.8.output.dense.weight', 'encoder.layer.16.output.dense.weight', 'encoder.layer.6.attention.output.LayerNorm.bias', 'encoder.layer.1.attention.self.query.bias', 'encoder.layer.13.output.LayerNorm.weight', 'encoder.layer.4.attention.output.dense.weight', 'encoder.layer.14.intermediate.dense.weight', 'encoder.layer.1.attention.self.value.bias', 'encoder.layer.6.output.LayerNorm.bias', 'encoder.layer.16.output.dense.bias', 'encoder.layer.22.attention.self.key.bias', 'embeddings.position_embeddings.weight', 'encoder.layer.23.output.dense.bias', 'encoder.layer.13.intermediate.dense.weight', 'encoder.layer.15.output.LayerNorm.weight', 'encoder.layer.17.attention.output.dense.weight', 'encoder.layer.4.output.dense.bias', 'encoder.layer.16.attention.self.key.bias', 'encoder.layer.13.output.dense.weight', 'encoder.layer.18.output.dense.weight', 'encoder.layer.1.output.dense.bias', 'encoder.layer.5.output.dense.bias', 'encoder.layer.10.attention.self.key.bias', 'encoder.layer.14.output.dense.bias', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.21.attention.output.LayerNorm.weight', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.9.output.dense.weight', 'encoder.layer.5.intermediate.dense.bias', 'embeddings.LayerNorm.weight', 'encoder.layer.1.attention.self.value.weight', 'encoder.layer.8.attention.output.LayerNorm.bias', 'encoder.layer.19.attention.output.LayerNorm.bias', 'encoder.layer.0.attention.self.query.weight', 'encoder.layer.16.intermediate.dense.bias', 'encoder.layer.4.attention.output.dense.bias', 'encoder.layer.3.intermediate.dense.bias', 'embeddings.token_type_embeddings.weight', 'encoder.layer.3.attention.self.query.bias', 'encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.17.intermediate.dense.weight', 'encoder.layer.18.attention.output.LayerNorm.weight', 'encoder.layer.5.output.LayerNorm.bias', 'encoder.layer.17.output.LayerNorm.weight', 'encoder.layer.8.output.dense.bias', 'encoder.layer.10.attention.self.query.weight', 'encoder.layer.7.output.LayerNorm.weight', 'encoder.layer.18.attention.output.dense.bias', 'encoder.layer.6.attention.output.dense.bias', 'embeddings.word_embeddings.weight', 'encoder.layer.8.attention.output.LayerNorm.weight', 'encoder.layer.1.attention.output.LayerNorm.weight', 'encoder.layer.12.attention.self.value.weight', 'encoder.layer.2.attention.self.key.bias', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.11.attention.output.LayerNorm.weight', 'encoder.layer.21.output.dense.bias', 'encoder.layer.11.attention.self.value.bias', 'encoder.layer.14.attention.self.key.bias', 'encoder.layer.4.attention.self.key.bias', 'encoder.layer.6.output.dense.bias', 'encoder.layer.19.attention.output.dense.weight', 'encoder.layer.11.attention.self.key.weight', 'encoder.layer.2.attention.self.value.weight', 'encoder.layer.22.attention.output.dense.bias', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.10.attention.output.dense.weight', 'encoder.layer.16.intermediate.dense.weight', 'encoder.layer.14.attention.self.value.bias', 'encoder.layer.17.attention.output.dense.bias', 'encoder.layer.10.attention.output.dense.bias', 'encoder.layer.22.attention.output.LayerNorm.weight', 'encoder.layer.22.attention.output.LayerNorm.bias', 'encoder.layer.0.attention.self.key.bias', 'encoder.layer.22.attention.self.key.weight', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.layer.11.output.dense.weight', 'encoder.layer.13.attention.self.query.weight', 'encoder.layer.1.attention.self.query.weight', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.13.attention.self.key.bias', 'encoder.layer.21.attention.self.query.bias', 'encoder.layer.5.attention.self.query.weight', 'encoder.layer.12.attention.self.query.bias', 'encoder.layer.10.intermediate.dense.weight', 'encoder.layer.17.attention.self.query.weight', 'encoder.layer.7.attention.self.value.weight', 'encoder.layer.11.output.LayerNorm.bias', 'encoder.layer.23.attention.self.key.bias', 'encoder.layer.21.attention.output.LayerNorm.bias', 'encoder.layer.1.attention.self.key.bias', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.23.attention.output.LayerNorm.bias', 'encoder.layer.18.attention.self.query.bias', 'encoder.layer.18.attention.self.value.weight', 'encoder.layer.19.attention.self.value.bias', 'encoder.layer.5.attention.output.dense.bias', 'encoder.layer.8.attention.self.query.weight', 'encoder.layer.3.attention.self.value.weight', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.20.attention.self.value.bias', 'encoder.layer.12.output.dense.weight', 'encoder.layer.2.attention.self.query.bias', 'encoder.layer.3.output.dense.bias', 'encoder.layer.22.attention.self.query.bias', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.16.attention.self.value.weight', 'encoder.layer.23.output.dense.weight', 'encoder.layer.22.output.dense.weight', 'encoder.layer.3.attention.self.value.bias', 'encoder.layer.8.attention.self.value.weight', 'encoder.layer.9.attention.self.value.bias', 'encoder.layer.23.attention.self.query.weight', 'encoder.layer.11.attention.self.key.bias', 'encoder.layer.20.attention.output.LayerNorm.weight', 'encoder.layer.10.attention.self.value.weight', 'encoder.layer.13.attention.output.dense.weight', 'encoder.layer.0.attention.self.query.bias', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.20.attention.self.query.bias', 'encoder.layer.15.attention.self.query.bias', 'encoder.layer.22.output.LayerNorm.weight', 'encoder.layer.12.attention.output.LayerNorm.bias', 'encoder.layer.16.output.LayerNorm.bias', 'encoder.layer.22.attention.output.dense.weight', 'encoder.layer.5.attention.self.value.weight', 'encoder.layer.15.intermediate.dense.bias', 'encoder.layer.17.intermediate.dense.bias', 'encoder.layer.8.output.LayerNorm.bias', 'encoder.layer.4.attention.self.query.weight', 'encoder.layer.17.attention.self.key.bias', 'encoder.layer.14.intermediate.dense.bias', 'encoder.layer.9.output.LayerNorm.bias', 'encoder.layer.9.attention.self.key.bias', 'encoder.layer.7.attention.self.key.weight', 'encoder.layer.14.attention.self.value.weight', 'encoder.layer.0.attention.output.dense.weight', 'encoder.layer.13.attention.output.LayerNorm.weight', 'encoder.layer.15.attention.output.LayerNorm.weight', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.7.attention.output.dense.bias', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.14.attention.output.dense.bias', 'encoder.layer.7.attention.self.value.bias', 'encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.layer.17.attention.output.LayerNorm.weight', 'encoder.layer.3.attention.self.key.bias', 'encoder.layer.18.output.LayerNorm.weight', 'encoder.layer.12.output.dense.bias', 'encoder.layer.6.attention.output.dense.weight', 'encoder.layer.19.attention.self.value.weight', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.15.attention.output.dense.weight', 'encoder.layer.11.attention.self.value.weight', 'encoder.layer.9.attention.output.dense.weight', 'encoder.layer.20.attention.output.LayerNorm.bias', 'encoder.layer.5.attention.output.dense.weight', 'encoder.layer.2.attention.output.dense.bias', 'encoder.layer.14.attention.output.dense.weight', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.4.output.dense.weight', 'encoder.layer.10.attention.self.query.bias', 'encoder.layer.3.attention.output.dense.bias', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.16.attention.self.value.bias', 'encoder.layer.20.attention.self.value.weight', 'encoder.layer.14.output.LayerNorm.bias', 'encoder.layer.19.attention.self.key.weight', 'encoder.layer.22.attention.self.query.weight', 'encoder.layer.23.output.LayerNorm.bias', 'encoder.layer.22.output.dense.bias', 'encoder.layer.6.output.dense.weight', 'encoder.layer.12.attention.self.key.bias', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.1.output.dense.weight', 'encoder.layer.20.intermediate.dense.weight', 'encoder.layer.16.attention.output.dense.bias', 'encoder.layer.9.attention.self.value.weight', 'encoder.layer.19.intermediate.dense.weight', 'encoder.layer.9.attention.output.dense.bias', 'encoder.layer.15.attention.output.dense.bias', 'encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.layer.13.intermediate.dense.bias', 'encoder.layer.17.attention.output.LayerNorm.bias', 'encoder.layer.19.attention.self.query.weight', 'encoder.layer.16.attention.output.dense.weight', 'encoder.layer.10.attention.self.value.bias', 'encoder.layer.11.attention.output.dense.weight', 'encoder.layer.18.intermediate.dense.bias', 'encoder.layer.21.attention.self.key.bias', 'encoder.layer.3.attention.self.key.weight', 'encoder.layer.7.intermediate.dense.bias', 'encoder.layer.21.attention.self.value.bias', 'encoder.layer.23.attention.self.value.weight', 'encoder.layer.7.attention.self.key.bias', 'encoder.layer.23.output.LayerNorm.weight', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.15.output.LayerNorm.bias', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.12.intermediate.dense.weight', 'encoder.layer.4.attention.self.value.weight', 'encoder.layer.21.output.LayerNorm.bias', 'encoder.layer.13.attention.output.LayerNorm.bias', 'encoder.layer.5.attention.self.key.bias', 'encoder.layer.23.attention.self.value.bias', 'encoder.layer.7.attention.self.query.weight', 'encoder.layer.20.intermediate.dense.bias', 'pooler.dense.bias', 'encoder.layer.10.output.dense.bias', 'encoder.layer.0.attention.output.LayerNorm.weight', 'encoder.layer.3.output.dense.weight', 'encoder.layer.6.attention.self.value.weight', 'encoder.layer.5.attention.self.value.bias', 'encoder.layer.19.attention.output.dense.bias', 'encoder.layer.15.attention.self.value.bias', 'encoder.layer.12.intermediate.dense.bias', 'encoder.layer.1.attention.output.dense.weight', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.0.attention.self.value.bias', 'encoder.layer.11.output.LayerNorm.weight', 'encoder.layer.7.attention.self.query.bias', 'encoder.layer.11.attention.output.dense.bias', 'encoder.layer.17.output.dense.weight', 'encoder.layer.21.intermediate.dense.weight', 'encoder.layer.4.attention.self.key.weight', 'encoder.layer.6.attention.self.key.bias', 'encoder.layer.9.attention.self.key.weight', 'encoder.layer.23.attention.output.dense.bias', 'encoder.layer.18.attention.self.query.weight', 'encoder.layer.13.attention.self.key.weight', 'encoder.layer.22.intermediate.dense.bias', 'encoder.layer.12.attention.self.value.bias', 'encoder.layer.9.attention.output.LayerNorm.bias', 'encoder.layer.2.output.dense.bias', 'encoder.layer.23.attention.self.query.bias', 'encoder.layer.15.attention.self.value.weight', 'encoder.layer.19.output.dense.bias', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.16.output.LayerNorm.weight', 'encoder.layer.15.output.dense.bias', 'encoder.layer.17.output.LayerNorm.bias', 'encoder.layer.2.output.dense.weight', 'encoder.layer.14.attention.output.LayerNorm.bias', 'encoder.layer.20.attention.self.query.weight', 'encoder.layer.22.intermediate.dense.weight', 'encoder.layer.15.output.dense.weight', 'encoder.layer.21.attention.output.dense.bias', 'encoder.layer.8.attention.self.key.bias', 'encoder.layer.8.attention.output.dense.bias', 'encoder.layer.15.attention.self.query.weight', 'encoder.layer.15.intermediate.dense.weight', 'encoder.layer.6.attention.self.query.weight', 'encoder.layer.17.attention.self.value.weight', 'encoder.layer.10.output.dense.weight', 'encoder.layer.21.intermediate.dense.bias', 'encoder.layer.11.attention.self.query.bias', 'encoder.layer.8.attention.output.dense.weight', 'encoder.layer.12.output.LayerNorm.bias', 'encoder.layer.2.attention.output.LayerNorm.bias', 'encoder.layer.21.attention.self.key.weight', 'encoder.layer.9.attention.output.LayerNorm.weight', 'encoder.layer.21.attention.self.query.weight', 'encoder.layer.9.attention.self.query.bias', 'encoder.layer.2.attention.output.dense.weight', 'encoder.layer.10.attention.output.LayerNorm.bias', 'encoder.layer.16.attention.self.query.bias', 'encoder.layer.13.attention.self.value.weight', 'encoder.layer.6.attention.self.value.bias', 'encoder.layer.18.attention.self.key.weight', 'encoder.layer.15.attention.self.key.weight', 'encoder.layer.18.output.LayerNorm.bias', 'encoder.layer.12.attention.self.query.weight', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.10.output.LayerNorm.weight', 'encoder.layer.6.attention.self.query.bias', 'encoder.layer.14.attention.self.query.weight', 'encoder.layer.11.attention.self.query.weight', 'encoder.layer.23.attention.self.key.weight', 'encoder.layer.19.attention.self.key.bias', 'encoder.layer.18.attention.self.key.bias', 'encoder.layer.3.attention.self.query.weight', 'encoder.layer.18.intermediate.dense.weight', 'encoder.layer.12.attention.output.dense.weight', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.7.output.dense.bias', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.13.attention.output.dense.bias', 'encoder.layer.21.output.dense.weight', 'encoder.layer.7.attention.output.dense.weight', 'encoder.layer.4.attention.output.LayerNorm.bias', 'encoder.layer.13.output.LayerNorm.bias', 'encoder.layer.14.attention.output.LayerNorm.weight', 'encoder.layer.18.output.dense.bias', 'encoder.layer.21.attention.output.dense.weight', 'encoder.layer.1.attention.output.dense.bias', 'encoder.layer.20.output.dense.bias', 'encoder.layer.5.attention.self.key.weight', 'encoder.layer.16.attention.self.query.weight', 'encoder.layer.20.output.LayerNorm.weight', 'encoder.layer.2.attention.self.value.bias', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.19.intermediate.dense.bias', 'encoder.layer.21.output.LayerNorm.weight', 'encoder.layer.9.output.LayerNorm.weight', 'encoder.layer.2.attention.self.key.weight', 'encoder.layer.22.attention.self.value.weight', 'encoder.layer.3.attention.output.dense.weight', 'encoder.layer.12.attention.output.LayerNorm.weight', 'encoder.layer.7.attention.output.LayerNorm.bias', 'encoder.layer.0.attention.output.dense.bias', 'encoder.layer.11.output.dense.bias', 'encoder.layer.8.attention.self.key.weight', 'encoder.layer.13.output.dense.bias', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.20.attention.output.dense.bias', 'encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.13.attention.self.query.bias', 'encoder.layer.19.output.LayerNorm.weight', 'encoder.layer.22.output.LayerNorm.bias', 'encoder.layer.5.attention.self.query.bias', 'encoder.layer.10.output.LayerNorm.bias', 'encoder.layer.15.attention.output.LayerNorm.bias', 'encoder.layer.0.attention.self.value.weight', 'encoder.layer.17.attention.self.value.bias', 'encoder.layer.19.output.dense.weight', 'encoder.layer.1.attention.self.key.weight', 'encoder.layer.7.output.dense.weight', 'encoder.layer.13.attention.self.value.bias', 'encoder.layer.7.output.LayerNorm.bias', 'encoder.layer.10.attention.output.LayerNorm.weight', 'encoder.layer.19.attention.self.query.bias', 'encoder.layer.14.attention.self.query.bias', 'encoder.layer.0.output.dense.bias', 'encoder.layer.8.attention.self.query.bias', 'encoder.layer.2.attention.self.query.weight', 'encoder.layer.4.attention.self.query.bias', 'encoder.layer.6.attention.output.LayerNorm.weight', 'encoder.layer.9.attention.self.query.weight', 'encoder.layer.20.attention.self.key.bias', 'encoder.layer.23.attention.output.LayerNorm.weight', 'encoder.layer.16.attention.output.LayerNorm.weight', 'encoder.layer.17.output.dense.bias', 'encoder.layer.16.attention.self.key.weight', 'encoder.layer.23.intermediate.dense.bias', 'encoder.layer.9.output.dense.bias', 'encoder.layer.20.attention.output.dense.weight', 'encoder.layer.18.attention.output.LayerNorm.bias', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.4.attention.self.value.bias', 'encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.layer.0.attention.self.key.weight', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.10.attention.self.key.weight', 'encoder.layer.23.attention.output.dense.weight', 'encoder.layer.5.attention.output.LayerNorm.weight', 'encoder.layer.5.output.dense.weight', 'encoder.layer.18.attention.output.dense.weight', 'encoder.layer.12.output.LayerNorm.weight', 'encoder.layer.14.output.LayerNorm.weight', 'encoder.layer.14.output.dense.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Overwriting existing adapter 'ep'.
Overwriting existing adapter 'tp'.
Overwriting existing adapter 'es'.
Overwriting existing adapter 'ts'.
Overwriting existing adapter fusion module 'ep,tp,es,ts'
05/09/2022 09:16:20 - INFO - __main__ -   Creating features from dataset file at .
/cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//squad/xlm-KG_LR3e-5_EPOCH2.0_maxlen384_batchsize4_gradacc4
XLMConfig {
  "architectures": [
    "XLMRobertaForMaskedLM"
  ],
  "asm": false,
  "attention_dropout": 0.1,
  "attention_probs_dropout_prob": 0.1,
  "bos_index": 0,
  "bos_token_id": 0,
  "causal": false,
  "dropout": 0.1,
  "emb_dim": 1024,
  "embed_init_std": 0.02209708691207961,
  "end_n_top": 5,
  "eos_index": 1,
  "eos_token_id": 2,
  "gelu_activation": true,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "init_std": 0.02,
  "initializer_range": 0.02,
  "intermediate_size": 4096,
  "is_encoder": true,
  "lang_id": 0,
  "layer_norm_eps": 1e-05,
  "mask_index": 5,
  "mask_token_id": 0,
  "max_position_embeddings": 514,
  "model_type": "xlm",
  "n_heads": 16,
  "n_langs": 1,
  "n_layers": 24,
  "output_past": true,
  "pad_index": 2,
  "pad_token_id": 1,
  "sinusoidal_embeddings": false,
  "start_n_top": 5,
  "summary_activation": null,
  "summary_first_dropout": 0.1,
  "summary_proj_to_labels": true,
  "summary_type": "first",
  "summary_use_proj": true,
  "transformers_version": "4.17.0",
  "type_vocab_size": 1,
  "unk_index": 3,
  "use_lang_emb": false,
  "vocab_size": 250002
}

  0%|          | 0/48 [00:00<?, ?it/s] 23%|██▎       | 11/48 [00:00<00:00, 98.86it/s] 44%|████▍     | 21/48 [00:00<00:00, 64.68it/s] 60%|██████    | 29/48 [00:00<00:00, 67.17it/s] 77%|███████▋  | 37/48 [00:00<00:00, 70.83it/s] 98%|█████████▊| 47/48 [00:00<00:00, 78.61it/s]100%|██████████| 48/48 [00:00<00:00, 74.76it/s]
convert squad examples to features:   0%|          | 0/1190 [00:00<?, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.
convert squad examples to features:   0%|          | 1/1190 [00:00<04:22,  4.53it/s]convert squad examples to features:   5%|▌         | 65/1190 [00:00<00:06, 183.69it/s]convert squad examples to features:   8%|▊         | 97/1190 [00:00<00:05, 213.35it/s]convert squad examples to features:  14%|█▎        | 161/1190 [00:00<00:03, 281.19it/s]convert squad examples to features:  16%|█▌        | 193/1190 [00:00<00:03, 286.02it/s]convert squad examples to features:  19%|█▉        | 225/1190 [00:00<00:03, 293.03it/s]convert squad examples to features:  22%|██▏       | 257/1190 [00:01<00:03, 240.65it/s]convert squad examples to features:  24%|██▍       | 289/1190 [00:01<00:03, 252.06it/s]convert squad examples to features:  27%|██▋       | 321/1190 [00:01<00:03, 241.99it/s]convert squad examples to features:  30%|██▉       | 353/1190 [00:01<00:03, 236.44it/s]convert squad examples to features:  32%|███▏      | 385/1190 [00:02<00:06, 119.37it/s]convert squad examples to features:  35%|███▌      | 417/1190 [00:02<00:05, 135.17it/s]convert squad examples to features:  38%|███▊      | 449/1190 [00:02<00:05, 142.90it/s]convert squad examples to features:  40%|████      | 481/1190 [00:02<00:04, 152.61it/s]convert squad examples to features:  43%|████▎     | 513/1190 [00:02<00:04, 166.08it/s]convert squad examples to features:  46%|████▌     | 545/1190 [00:02<00:03, 170.63it/s]convert squad examples to features:  48%|████▊     | 577/1190 [00:03<00:03, 179.08it/s]convert squad examples to features:  51%|█████     | 609/1190 [00:03<00:03, 163.96it/s]convert squad examples to features:  54%|█████▍    | 641/1190 [00:03<00:03, 164.48it/s]convert squad examples to features:  57%|█████▋    | 673/1190 [00:03<00:03, 159.74it/s]convert squad examples to features:  59%|█████▉    | 705/1190 [00:03<00:02, 175.49it/s]convert squad examples to features:  62%|██████▏   | 737/1190 [00:04<00:02, 194.08it/s]convert squad examples to features:  65%|██████▍   | 769/1190 [00:04<00:02, 209.06it/s]convert squad examples to features:  67%|██████▋   | 801/1190 [00:04<00:01, 195.93it/s]convert squad examples to features:  70%|███████   | 833/1190 [00:04<00:02, 171.85it/s]convert squad examples to features:  73%|███████▎  | 865/1190 [00:04<00:01, 172.08it/s]convert squad examples to features:  75%|███████▌  | 897/1190 [00:04<00:01, 178.57it/s]convert squad examples to features:  78%|███████▊  | 929/1190 [00:05<00:01, 175.63it/s]convert squad examples to features:  83%|████████▎ | 993/1190 [00:05<00:00, 217.60it/s]convert squad examples to features:  86%|████████▌ | 1025/1190 [00:05<00:00, 220.44it/s]convert squad examples to features:  89%|████████▉ | 1057/1190 [00:05<00:00, 236.57it/s]convert squad examples to features:  92%|█████████▏| 1089/1190 [00:05<00:00, 238.92it/s]convert squad examples to features:  94%|█████████▍| 1121/1190 [00:05<00:00, 241.91it/s]convert squad examples to features:  97%|█████████▋| 1153/1190 [00:05<00:00, 235.27it/s]convert squad examples to features: 100%|██████████| 1190/1190 [00:05<00:00, 199.62it/s]
add example index and unique id:   0%|          | 0/1190 [00:00<?, ?it/s]add example index and unique id: 100%|██████████| 1190/1190 [00:00<00:00, 358204.52it/s]
05/09/2022 09:16:27 - INFO - __main__ -   Saving features into cached file ./cached_xquad.th.json_xlm-KG_LR3e-5_EPOCH2.0_maxlen384_batchsize4_gradacc4_384_th
05/09/2022 09:16:28 - INFO - __main__ -   ***** Running evaluation  *****
05/09/2022 09:16:28 - INFO - __main__ -     Num examples = 1314
05/09/2022 09:16:28 - INFO - __main__ -     Batch size = 8
Evaluating:   0%|          | 0/165 [00:00<?, ?it/s]Evaluating:   1%|          | 1/165 [00:00<02:34,  1.06it/s]Evaluating:   1%|          | 2/165 [00:01<01:36,  1.69it/s]Evaluating:   2%|▏         | 3/165 [00:01<01:17,  2.09it/s]Evaluating:   2%|▏         | 4/165 [00:01<01:08,  2.36it/s]Evaluating:   3%|▎         | 5/165 [00:02<01:03,  2.53it/s]Evaluating:   4%|▎         | 6/165 [00:02<00:59,  2.66it/s]Evaluating:   4%|▍         | 7/165 [00:03<00:57,  2.73it/s]Evaluating:   5%|▍         | 8/165 [00:03<00:56,  2.78it/s]Evaluating:   5%|▌         | 9/165 [00:03<00:55,  2.82it/s]Evaluating:   6%|▌         | 10/165 [00:04<00:54,  2.84it/s]Evaluating:   7%|▋         | 11/165 [00:04<00:53,  2.87it/s]Evaluating:   7%|▋         | 12/165 [00:04<00:52,  2.89it/s]Evaluating:   8%|▊         | 13/165 [00:05<00:52,  2.90it/s]Evaluating:   8%|▊         | 14/165 [00:05<00:51,  2.91it/s]Evaluating:   9%|▉         | 15/165 [00:05<00:51,  2.91it/s]Evaluating:  10%|▉         | 16/165 [00:06<00:51,  2.91it/s]Evaluating:  10%|█         | 17/165 [00:06<00:50,  2.91it/s]Evaluating:  11%|█         | 18/165 [00:06<00:50,  2.91it/s]Evaluating:  12%|█▏        | 19/165 [00:07<00:50,  2.92it/s]Evaluating:  12%|█▏        | 20/165 [00:07<00:49,  2.92it/s]Evaluating:  13%|█▎        | 21/165 [00:07<00:49,  2.92it/s]Evaluating:  13%|█▎        | 22/165 [00:08<00:48,  2.92it/s]Evaluating:  14%|█▍        | 23/165 [00:08<00:48,  2.93it/s]Evaluating:  15%|█▍        | 24/165 [00:08<00:48,  2.92it/s]Evaluating:  15%|█▌        | 25/165 [00:09<00:48,  2.91it/s]Evaluating:  16%|█▌        | 26/165 [00:09<00:47,  2.91it/s]Evaluating:  16%|█▋        | 27/165 [00:09<00:47,  2.91it/s]Evaluating:  17%|█▋        | 28/165 [00:10<00:47,  2.91it/s]Evaluating:  18%|█▊        | 29/165 [00:10<00:46,  2.91it/s]Evaluating:  18%|█▊        | 30/165 [00:10<00:46,  2.91it/s]Evaluating:  19%|█▉        | 31/165 [00:11<00:45,  2.91it/s]Evaluating:  19%|█▉        | 32/165 [00:11<00:45,  2.92it/s]Evaluating:  20%|██        | 33/165 [00:11<00:45,  2.92it/s]Evaluating:  21%|██        | 34/165 [00:12<00:44,  2.91it/s]Evaluating:  21%|██        | 35/165 [00:12<00:44,  2.91it/s]Evaluating:  22%|██▏       | 36/165 [00:12<00:44,  2.92it/s]Evaluating:  22%|██▏       | 37/165 [00:13<00:43,  2.92it/s]Evaluating:  23%|██▎       | 38/165 [00:13<00:43,  2.91it/s]Evaluating:  24%|██▎       | 39/165 [00:13<00:43,  2.91it/s]Evaluating:  24%|██▍       | 40/165 [00:14<00:43,  2.89it/s]Evaluating:  25%|██▍       | 41/165 [00:14<00:42,  2.89it/s]Evaluating:  25%|██▌       | 42/165 [00:15<00:42,  2.90it/s]Evaluating:  26%|██▌       | 43/165 [00:15<00:42,  2.90it/s]Evaluating:  27%|██▋       | 44/165 [00:15<00:41,  2.90it/s]Evaluating:  27%|██▋       | 45/165 [00:16<00:41,  2.90it/s]Evaluating:  28%|██▊       | 46/165 [00:16<00:41,  2.90it/s]Evaluating:  28%|██▊       | 47/165 [00:16<00:40,  2.91it/s]Evaluating:  29%|██▉       | 48/165 [00:17<00:40,  2.91it/s]Evaluating:  30%|██▉       | 49/165 [00:17<00:40,  2.90it/s]Evaluating:  30%|███       | 50/165 [00:17<00:39,  2.88it/s]Evaluating:  31%|███       | 51/165 [00:18<00:39,  2.90it/s]Evaluating:  32%|███▏      | 52/165 [00:18<00:38,  2.90it/s]Evaluating:  32%|███▏      | 53/165 [00:18<00:38,  2.90it/s]Evaluating:  33%|███▎      | 54/165 [00:19<00:38,  2.90it/s]Evaluating:  33%|███▎      | 55/165 [00:19<00:38,  2.89it/s]Evaluating:  34%|███▍      | 56/165 [00:19<00:37,  2.89it/s]Evaluating:  35%|███▍      | 57/165 [00:20<00:37,  2.89it/s]Evaluating:  35%|███▌      | 58/165 [00:20<00:37,  2.89it/s]Evaluating:  36%|███▌      | 59/165 [00:20<00:36,  2.90it/s]Evaluating:  36%|███▋      | 60/165 [00:21<00:36,  2.90it/s]Evaluating:  37%|███▋      | 61/165 [00:21<00:35,  2.91it/s]Evaluating:  38%|███▊      | 62/165 [00:21<00:35,  2.90it/s]Evaluating:  38%|███▊      | 63/165 [00:22<00:35,  2.91it/s]Evaluating:  39%|███▉      | 64/165 [00:22<00:34,  2.91it/s]Evaluating:  39%|███▉      | 65/165 [00:22<00:34,  2.91it/s]Evaluating:  40%|████      | 66/165 [00:23<00:33,  2.91it/s]Evaluating:  41%|████      | 67/165 [00:23<00:33,  2.91it/s]Evaluating:  41%|████      | 68/165 [00:23<00:33,  2.91it/s]Evaluating:  42%|████▏     | 69/165 [00:24<00:32,  2.91it/s]Evaluating:  42%|████▏     | 70/165 [00:24<00:32,  2.91it/s]Evaluating:  43%|████▎     | 71/165 [00:25<00:32,  2.91it/s]Evaluating:  44%|████▎     | 72/165 [00:25<00:32,  2.90it/s]Evaluating:  44%|████▍     | 73/165 [00:25<00:31,  2.90it/s]Evaluating:  45%|████▍     | 74/165 [00:26<00:31,  2.90it/s]Evaluating:  45%|████▌     | 75/165 [00:26<00:31,  2.90it/s]Evaluating:  46%|████▌     | 76/165 [00:26<00:30,  2.90it/s]Evaluating:  47%|████▋     | 77/165 [00:27<00:30,  2.90it/s]Evaluating:  47%|████▋     | 78/165 [00:27<00:30,  2.89it/s]Evaluating:  48%|████▊     | 79/165 [00:27<00:29,  2.89it/s]Evaluating:  48%|████▊     | 80/165 [00:28<00:29,  2.90it/s]Evaluating:  49%|████▉     | 81/165 [00:28<00:28,  2.91it/s]Evaluating:  50%|████▉     | 82/165 [00:28<00:28,  2.92it/s]Evaluating:  50%|█████     | 83/165 [00:29<00:28,  2.91it/s]Evaluating:  51%|█████     | 84/165 [00:29<00:27,  2.91it/s]Evaluating:  52%|█████▏    | 85/165 [00:29<00:27,  2.91it/s]Evaluating:  52%|█████▏    | 86/165 [00:30<00:27,  2.91it/s]Evaluating:  53%|█████▎    | 87/165 [00:30<00:26,  2.91it/s]Evaluating:  53%|█████▎    | 88/165 [00:30<00:26,  2.91it/s]Evaluating:  54%|█████▍    | 89/165 [00:31<00:26,  2.91it/s]Evaluating:  55%|█████▍    | 90/165 [00:31<00:25,  2.91it/s]Evaluating:  55%|█████▌    | 91/165 [00:31<00:25,  2.91it/s]Evaluating:  56%|█████▌    | 92/165 [00:32<00:25,  2.91it/s]Evaluating:  56%|█████▋    | 93/165 [00:32<00:24,  2.91it/s]Evaluating:  57%|█████▋    | 94/165 [00:32<00:24,  2.92it/s]Evaluating:  58%|█████▊    | 95/165 [00:33<00:23,  2.92it/s]Evaluating:  58%|█████▊    | 96/165 [00:33<00:23,  2.90it/s]Evaluating:  59%|█████▉    | 97/165 [00:33<00:23,  2.90it/s]Evaluating:  59%|█████▉    | 98/165 [00:34<00:23,  2.91it/s]Evaluating:  60%|██████    | 99/165 [00:34<00:22,  2.91it/s]Evaluating:  61%|██████    | 100/165 [00:34<00:22,  2.90it/s]Evaluating:  61%|██████    | 101/165 [00:35<00:22,  2.91it/s]Evaluating:  62%|██████▏   | 102/165 [00:35<00:21,  2.92it/s]Evaluating:  62%|██████▏   | 103/165 [00:36<00:21,  2.92it/s]Evaluating:  63%|██████▎   | 104/165 [00:36<00:20,  2.92it/s]Evaluating:  64%|██████▎   | 105/165 [00:36<00:20,  2.91it/s]Evaluating:  64%|██████▍   | 106/165 [00:37<00:20,  2.91it/s]Evaluating:  65%|██████▍   | 107/165 [00:37<00:19,  2.92it/s]Evaluating:  65%|██████▌   | 108/165 [00:37<00:19,  2.92it/s]Evaluating:  66%|██████▌   | 109/165 [00:38<00:19,  2.92it/s]Evaluating:  67%|██████▋   | 110/165 [00:38<00:18,  2.92it/s]Evaluating:  67%|██████▋   | 111/165 [00:38<00:18,  2.92it/s]Evaluating:  68%|██████▊   | 112/165 [00:39<00:18,  2.92it/s]Evaluating:  68%|██████▊   | 113/165 [00:39<00:17,  2.92it/s]Evaluating:  69%|██████▉   | 114/165 [00:39<00:17,  2.92it/s]Evaluating:  70%|██████▉   | 115/165 [00:40<00:17,  2.91it/s]Evaluating:  70%|███████   | 116/165 [00:40<00:16,  2.90it/s]Evaluating:  71%|███████   | 117/165 [00:40<00:16,  2.90it/s]Evaluating:  72%|███████▏  | 118/165 [00:41<00:16,  2.89it/s]Evaluating:  72%|███████▏  | 119/165 [00:41<00:15,  2.89it/s]Evaluating:  73%|███████▎  | 120/165 [00:41<00:15,  2.89it/s]Evaluating:  73%|███████▎  | 121/165 [00:42<00:15,  2.87it/s]Evaluating:  74%|███████▍  | 122/165 [00:42<00:14,  2.88it/s]Evaluating:  75%|███████▍  | 123/165 [00:42<00:14,  2.90it/s]Evaluating:  75%|███████▌  | 124/165 [00:43<00:14,  2.91it/s]Evaluating:  76%|███████▌  | 125/165 [00:43<00:13,  2.89it/s]Evaluating:  76%|███████▋  | 126/165 [00:43<00:13,  2.89it/s]Evaluating:  77%|███████▋  | 127/165 [00:44<00:13,  2.90it/s]Evaluating:  78%|███████▊  | 128/165 [00:44<00:12,  2.89it/s]Evaluating:  78%|███████▊  | 129/165 [00:44<00:12,  2.89it/s]Evaluating:  79%|███████▉  | 130/165 [00:45<00:12,  2.79it/s]Evaluating:  79%|███████▉  | 131/165 [00:45<00:12,  2.82it/s]Evaluating:  80%|████████  | 132/165 [00:46<00:11,  2.84it/s]Evaluating:  81%|████████  | 133/165 [00:46<00:11,  2.87it/s]Evaluating:  81%|████████  | 134/165 [00:46<00:10,  2.89it/s]Evaluating:  82%|████████▏ | 135/165 [00:47<00:10,  2.89it/s]Evaluating:  82%|████████▏ | 136/165 [00:47<00:09,  2.90it/s]Evaluating:  83%|████████▎ | 137/165 [00:47<00:09,  2.91it/s]Evaluating:  84%|████████▎ | 138/165 [00:48<00:09,  2.91it/s]Evaluating:  84%|████████▍ | 139/165 [00:48<00:08,  2.92it/s]Evaluating:  85%|████████▍ | 140/165 [00:48<00:08,  2.91it/s]Evaluating:  85%|████████▌ | 141/165 [00:49<00:08,  2.91it/s]Evaluating:  86%|████████▌ | 142/165 [00:49<00:07,  2.91it/s]Evaluating:  87%|████████▋ | 143/165 [00:49<00:07,  2.91it/s]Evaluating:  87%|████████▋ | 144/165 [00:50<00:07,  2.92it/s]Evaluating:  88%|████████▊ | 145/165 [00:50<00:06,  2.92it/s]Evaluating:  88%|████████▊ | 146/165 [00:50<00:06,  2.92it/s]Evaluating:  89%|████████▉ | 147/165 [00:51<00:06,  2.93it/s]Evaluating:  90%|████████▉ | 148/165 [00:51<00:05,  2.93it/s]Evaluating:  90%|█████████ | 149/165 [00:51<00:05,  2.93it/s]Evaluating:  91%|█████████ | 150/165 [00:52<00:05,  2.92it/s]Evaluating:  92%|█████████▏| 151/165 [00:52<00:04,  2.92it/s]Evaluating:  92%|█████████▏| 152/165 [00:52<00:04,  2.92it/s]Evaluating:  93%|█████████▎| 153/165 [00:53<00:04,  2.92it/s]Evaluating:  93%|█████████▎| 154/165 [00:53<00:03,  2.92it/s]Evaluating:  94%|█████████▍| 155/165 [00:53<00:03,  2.92it/s]Evaluating:  95%|█████████▍| 156/165 [00:54<00:03,  2.92it/s]Evaluating:  95%|█████████▌| 157/165 [00:54<00:02,  2.92it/s]Evaluating:  96%|█████████▌| 158/165 [00:54<00:02,  2.92it/s]Evaluating:  96%|█████████▋| 159/165 [00:55<00:02,  2.91it/s]Evaluating:  97%|█████████▋| 160/165 [00:55<00:01,  2.91it/s]Evaluating:  98%|█████████▊| 161/165 [00:55<00:01,  2.91it/s]Evaluating:  98%|█████████▊| 162/165 [00:56<00:01,  2.90it/s]Evaluating:  99%|█████████▉| 163/165 [00:56<00:00,  2.89it/s]Evaluating:  99%|█████████▉| 164/165 [00:57<00:00,  2.89it/s]Evaluating: 100%|██████████| 165/165 [00:57<00:00,  3.52it/s]Evaluating: 100%|██████████| 165/165 [00:57<00:00,  2.89it/s]
05/09/2022 09:17:26 - INFO - __main__ -     Evaluation done in total 57.175572 secs (0.043513 sec per example)
05/09/2022 09:17:35 - INFO - __main__ -   Results: {'exact': 62.26890756302521, 'f1': 73.00226828699387, 'total': 1190, 'HasAns_exact': 62.26890756302521, 'HasAns_f1': 73.00226828699387, 'HasAns_total': 1190, 'best_exact': 62.26890756302521, 'best_exact_thresh': 0.0, 'best_f1': 73.00226828699387, 'best_f1_thresh': 0.0}
  zh 
2022-05-09 09:17:39.487172: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0
05/09/2022 09:17:43 - WARNING - __main__ -   Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, 16-bits training: False
You are using a model of type xlm-roberta to instantiate a model of type xlm. This is not supported for all configurations of models and can yield errors.
Some weights of the model checkpoint at /cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//squad/xlm-KG_LR3e-5_EPOCH2.0_maxlen384_batchsize4_gradacc4 were not used when initializing XLMRobertaModel: ['base_model.encoder.layer.23.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.7.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.16.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.9.attention.output.LayerNorm.weight', 'base_model.encoder.layer.2.attention.self.query.bias', 'base_model.encoder.layer.16.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.13.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.18.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.10.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.18.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.21.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.11.attention.self.query.weight', 'base_model.encoder.layer.23.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.19.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.12.attention.self.key.bias', 'base_model.encoder.layer.20.attention.output.LayerNorm.weight', 'base_model.encoder.layer.6.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.9.intermediate.dense.weight', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.10.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.18.output.LayerNorm.bias', 'base_model.encoder.layer.17.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.20.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.2.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.3.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.4.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.16.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.12.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.15.intermediate.dense.weight', 'base_model.encoder.layer.1.attention.output.LayerNorm.bias', 'base_model.encoder.layer.2.intermediate.dense.bias', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.6.output.dense.bias', 'base_model.encoder.layer.23.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.6.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.10.output.LayerNorm.weight', 'base_model.encoder.layer.16.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.3.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.10.attention.self.key.weight', 'base_model.encoder.layer.8.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.22.intermediate.dense.bias', 'base_model.encoder.layer.10.intermediate.dense.weight', 'base_model.encoder.layer.13.attention.output.LayerNorm.weight', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.14.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.7.attention.self.key.bias', 'base_model.encoder.layer.21.attention.output.LayerNorm.weight', 'base_model.encoder.layer.14.attention.output.LayerNorm.bias', 'base_model.encoder.layer.0.output.dense.weight', 'base_model.encoder.layer.22.attention.self.key.weight', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.16.attention.output.LayerNorm.weight', 'base_model.encoder.layer.16.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.19.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.15.output.dense.weight', 'base_model.encoder.layer.0.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.12.attention.output.LayerNorm.weight', 'base_model.encoder.layer.18.attention.self.key.bias', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.18.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.3.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.3.attention.output.dense.weight', 'base_model.encoder.layer.16.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.20.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.18.attention.self.query.bias', 'base_model.encoder.layer.19.output.LayerNorm.weight', 'base_model.encoder.layer.19.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.6.attention.self.value.weight', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.10.attention.self.value.bias', 'base_model.encoder.layer.20.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.7.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.11.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.2.attention.self.key.bias', 'base_model.encoder.layer.8.attention.self.query.bias', 'base_model.encoder.layer.8.intermediate.dense.weight', 'base_model.encoder.layer.22.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.4.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.14.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.7.intermediate.dense.bias', 'base_model.encoder.layer.22.attention.self.query.weight', 'base_model.encoder.layer.11.attention.self.value.weight', 'base_model.embeddings.token_type_embeddings.weight', 'base_model.encoder.layer.18.intermediate.dense.bias', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.18.attention.self.query.weight', 'base_model.encoder.layer.23.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.8.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.11.attention.self.value.bias', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.13.output.adapters.ep.adapter_down.0.weight', 'base_model.pooler.dense.bias', 'base_model.encoder.layer.1.output.dense.bias', 'base_model.encoder.layer.7.attention.self.query.weight', 'base_model.encoder.layer.12.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.23.attention.self.query.bias', 'base_model.encoder.layer.16.output.LayerNorm.weight', 'base_model.encoder.layer.8.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.1.attention.self.value.bias', 'base_model.encoder.layer.21.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.1.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.6.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.6.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.15.attention.self.key.weight', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.15.output.dense.bias', 'base_model.encoder.layer.11.attention.output.dense.weight', 'base_model.encoder.layer.15.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.3.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.16.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.22.output.dense.weight', 'base_model.encoder.layer.2.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.11.output.LayerNorm.weight', 'base_model.encoder.layer.13.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.21.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.7.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.0.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.13.attention.self.value.bias', 'base_model.encoder.layer.19.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.2.output.dense.bias', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.1.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.7.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.0.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.14.attention.self.query.bias', 'base_model.encoder.layer.4.output.dense.weight', 'base_model.encoder.layer.9.output.LayerNorm.bias', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.13.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.7.attention.output.dense.weight', 'base_model.encoder.layer.8.output.LayerNorm.bias', 'base_model.encoder.layer.17.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.17.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.18.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.embeddings.position_embeddings.weight', 'base_model.encoder.layer.9.attention.output.dense.weight', 'base_model.encoder.layer.12.attention.output.dense.weight', 'base_model.encoder.layer.8.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.2.output.LayerNorm.bias', 'base_model.encoder.layer.6.output.dense.weight', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.19.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.22.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.1.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.6.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.19.output.dense.weight', 'base_model.encoder.layer.23.attention.self.key.bias', 'base_model.encoder.layer.10.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.5.output.LayerNorm.bias', 'base_model.encoder.layer.15.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.11.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.17.attention.self.key.bias', 'base_model.encoder.layer.12.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.19.output.dense.bias', 'base_model.encoder.layer.23.output.LayerNorm.weight', 'base_model.encoder.layer.15.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.21.attention.self.query.weight', 'base_model.encoder.layer.14.attention.self.key.weight', 'base_model.encoder.layer.16.attention.self.value.bias', 'base_model.encoder.layer.13.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.4.attention.self.key.bias', 'base_model.encoder.layer.21.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.16.intermediate.dense.weight', 'base_model.encoder.layer.23.output.dense.bias', 'base_model.encoder.layer.3.attention.self.query.bias', 'base_model.encoder.layer.17.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.18.output.dense.weight', 'base_model.encoder.layer.8.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.1.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.5.output.dense.weight', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.19.attention.output.dense.bias', 'base_model.encoder.layer.19.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.12.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.18.attention.self.value.bias', 'base_model.encoder.layer.19.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.20.output.LayerNorm.bias', 'base_model.encoder.layer.19.output.LayerNorm.bias', 'base_model.encoder.layer.7.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.20.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.20.intermediate.dense.bias', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.11.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.9.attention.output.LayerNorm.bias', 'base_model.encoder.layer.17.attention.self.value.weight', 'base_model.encoder.layer.11.output.dense.weight', 'base_model.encoder.layer.20.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.22.attention.output.LayerNorm.weight', 'base_model.encoder.layer.12.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.22.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.5.intermediate.dense.bias', 'base_model.encoder.layer.9.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.12.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.10.output.dense.bias', 'base_model.encoder.layer.12.attention.self.query.bias', 'base_model.encoder.layer.15.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.4.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.17.attention.output.dense.weight', 'base_model.encoder.layer.6.output.LayerNorm.bias', 'base_model.encoder.layer.19.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.8.attention.output.LayerNorm.bias', 'base_model.encoder.layer.13.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.20.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.23.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.12.output.LayerNorm.weight', 'base_model.encoder.layer.6.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.7.output.LayerNorm.weight', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.4.attention.self.value.bias', 'base_model.encoder.layer.20.attention.self.value.weight', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.7.attention.self.key.weight', 'base_model.encoder.layer.10.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.23.attention.self.query.weight', 'base_model.encoder.layer.7.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.23.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.18.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.19.intermediate.dense.weight', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.13.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.17.output.LayerNorm.weight', 'base_model.encoder.layer.0.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.9.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.17.output.dense.weight', 'base_model.encoder.layer.19.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.19.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.20.output.dense.bias', 'base_model.encoder.layer.20.attention.self.key.weight', 'base_model.encoder.layer.4.intermediate.dense.bias', 'base_model.encoder.layer.15.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.17.attention.self.key.weight', 'base_model.encoder.layer.15.attention.self.value.bias', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.0.attention.output.LayerNorm.bias', 'base_model.encoder.layer.20.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.8.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.22.attention.output.LayerNorm.bias', 'base_model.encoder.layer.2.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.6.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.20.attention.output.dense.weight', 'base_model.encoder.layer.6.attention.self.query.weight', 'base_model.encoder.layer.20.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.6.attention.output.LayerNorm.weight', 'base_model.encoder.layer.13.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.18.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.16.intermediate.dense.bias', 'base_model.encoder.layer.5.attention.self.value.bias', 'base_model.encoder.layer.18.attention.output.LayerNorm.bias', 'base_model.encoder.layer.12.intermediate.dense.bias', 'base_model.encoder.layer.1.attention.self.query.bias', 'base_model.encoder.layer.10.output.LayerNorm.bias', 'base_model.encoder.layer.17.attention.output.LayerNorm.bias', 'base_model.encoder.layer.10.attention.output.LayerNorm.weight', 'base_model.encoder.layer.8.attention.output.dense.weight', 'base_model.encoder.layer.4.output.LayerNorm.weight', 'base_model.encoder.layer.0.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.22.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.15.attention.self.query.bias', 'base_model.encoder.layer.22.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.14.intermediate.dense.bias', 'base_model.encoder.layer.22.output.LayerNorm.bias', 'base_model.encoder.layer.21.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.21.attention.self.key.bias', 'base_model.encoder.layer.14.intermediate.dense.weight', 'base_model.encoder.layer.2.attention.output.dense.weight', 'base_model.encoder.layer.0.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.6.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.4.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.23.intermediate.dense.bias', 'base_model.encoder.layer.6.attention.output.LayerNorm.bias', 'base_model.encoder.layer.14.attention.output.dense.bias', 'base_model.encoder.layer.21.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.17.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.1.attention.self.query.weight', 'base_model.encoder.layer.7.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.7.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.14.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.7.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.18.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.3.attention.output.LayerNorm.weight', 'base_model.encoder.layer.22.attention.self.value.bias', 'base_model.encoder.layer.5.attention.output.LayerNorm.weight', 'base_model.encoder.layer.2.attention.output.LayerNorm.weight', 'base_model.encoder.layer.2.attention.self.query.weight', 'base_model.encoder.layer.8.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.12.attention.output.LayerNorm.bias', 'base_model.encoder.layer.17.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.21.attention.output.LayerNorm.bias', 'base_model.encoder.layer.5.attention.self.query.bias', 'base_model.encoder.layer.4.attention.self.query.weight', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.9.intermediate.dense.bias', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.11.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.16.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.15.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.13.attention.output.LayerNorm.bias', 'base_model.encoder.layer.12.output.dense.bias', 'base_model.encoder.layer.3.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.5.output.dense.bias', 'base_model.encoder.layer.23.output.LayerNorm.bias', 'base_model.encoder.layer.18.attention.output.LayerNorm.weight', 'base_model.encoder.layer.1.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.13.output.dense.weight', 'base_model.encoder.layer.1.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.16.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.4.attention.output.dense.bias', 'base_model.encoder.layer.3.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.5.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.21.attention.self.value.bias', 'base_model.encoder.layer.5.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.17.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.9.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.16.attention.self.query.weight', 'base_model.encoder.layer.20.attention.self.query.weight', 'base_model.encoder.layer.13.attention.self.value.weight', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.23.attention.output.dense.weight', 'base_model.encoder.layer.6.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.4.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.21.attention.output.dense.bias', 'base_model.encoder.layer.18.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.18.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.7.output.dense.bias', 'base_model.encoder.layer.23.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.17.intermediate.dense.weight', 'base_model.encoder.layer.6.attention.self.query.bias', 'base_model.encoder.layer.11.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.3.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.14.output.dense.bias', 'base_model.encoder.layer.16.output.LayerNorm.bias', 'base_model.encoder.layer.12.output.dense.weight', 'base_model.encoder.layer.1.output.LayerNorm.weight', 'base_model.encoder.layer.0.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.5.attention.output.dense.weight', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.16.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.19.attention.self.key.weight', 'base_model.encoder.layer.6.attention.self.value.bias', 'base_model.encoder.layer.15.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.6.attention.output.dense.bias', 'base_model.encoder.layer.13.output.adapters.es.adapter_up.bias', 'qa_outputs.bias', 'base_model.encoder.layer.3.attention.self.key.weight', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.14.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.20.attention.output.LayerNorm.bias', 'base_model.encoder.layer.2.attention.output.dense.bias', 'base_model.encoder.layer.3.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.5.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.17.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.5.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.6.output.LayerNorm.weight', 'base_model.encoder.layer.22.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.0.attention.output.dense.weight', 'base_model.encoder.layer.3.attention.output.dense.bias', 'base_model.encoder.layer.13.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.8.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.7.intermediate.dense.weight', 'base_model.encoder.layer.4.output.dense.bias', 'base_model.encoder.layer.1.intermediate.dense.bias', 'base_model.encoder.layer.1.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.19.intermediate.dense.bias', 'base_model.encoder.layer.10.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.9.attention.self.query.weight', 'base_model.encoder.layer.5.intermediate.dense.weight', 'base_model.encoder.layer.9.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.22.attention.output.dense.weight', 'base_model.encoder.layer.14.attention.self.value.weight', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.23.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.21.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.21.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.8.intermediate.dense.bias', 'base_model.encoder.layer.20.output.LayerNorm.weight', 'base_model.encoder.layer.2.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.7.attention.output.dense.bias', 'base_model.encoder.layer.22.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.13.attention.self.key.weight', 'base_model.encoder.layer.15.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.12.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.17.attention.self.value.bias', 'base_model.encoder.layer.16.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.17.attention.output.LayerNorm.weight', 'base_model.encoder.layer.10.attention.output.dense.weight', 'base_model.encoder.layer.17.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.21.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.7.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.1.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.7.output.LayerNorm.bias', 'base_model.encoder.layer.16.attention.self.key.bias', 'base_model.encoder.layer.10.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.10.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.20.attention.self.value.bias', 'base_model.encoder.layer.22.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.14.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.8.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.21.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.3.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.11.output.dense.bias', 'base_model.encoder.layer.3.attention.self.value.weight', 'base_model.encoder.layer.0.attention.self.value.weight', 'base_model.encoder.layer.12.attention.self.key.weight', 'base_model.encoder.layer.10.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.2.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.14.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.21.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.10.attention.output.LayerNorm.bias', 'base_model.encoder.layer.15.output.adapters.ts.adapter_up.weight', 'base_model.pooler.dense.weight', 'base_model.encoder.layer.0.attention.self.query.weight', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.23.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.6.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.20.attention.self.key.bias', 'base_model.encoder.layer.21.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.0.output.LayerNorm.weight', 'base_model.encoder.layer.10.intermediate.dense.bias', 'base_model.encoder.layer.12.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.10.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.13.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.13.output.LayerNorm.bias', 'base_model.encoder.layer.2.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.0.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.11.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.11.intermediate.dense.weight', 'base_model.encoder.layer.2.attention.self.value.bias', 'base_model.encoder.layer.14.attention.output.LayerNorm.weight', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.6.attention.self.key.bias', 'base_model.encoder.layer.7.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.17.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.18.attention.output.dense.bias', 'base_model.encoder.layer.20.output.dense.weight', 'base_model.encoder.layer.7.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.5.output.LayerNorm.weight', 'base_model.encoder.layer.5.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.17.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.8.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.21.output.dense.bias', 'base_model.encoder.layer.11.attention.output.LayerNorm.bias', 'base_model.encoder.layer.22.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.11.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.13.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.11.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.15.intermediate.dense.bias', 'base_model.encoder.layer.21.output.dense.weight', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.21.attention.output.dense.weight', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.19.attention.output.LayerNorm.weight', 'base_model.encoder.layer.1.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.10.attention.self.key.bias', 'base_model.encoder.layer.23.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.13.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.4.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.2.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.13.attention.output.dense.weight', 'base_model.encoder.layer.8.attention.self.key.weight', 'base_model.encoder.layer.8.attention.output.LayerNorm.weight', 'base_model.encoder.layer.9.output.dense.bias', 'base_model.encoder.layer.14.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.3.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.16.attention.output.dense.bias', 'base_model.encoder.layer.12.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.22.intermediate.dense.weight', 'base_model.encoder.layer.13.output.LayerNorm.weight', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.18.output.LayerNorm.weight', 'base_model.encoder.layer.0.attention.output.LayerNorm.weight', 'base_model.encoder.layer.7.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.4.attention.self.value.weight', 'base_model.encoder.layer.7.attention.self.value.bias', 'base_model.encoder.layer.1.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.8.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.9.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.9.attention.self.key.bias', 'base_model.encoder.layer.17.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.14.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.9.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.21.attention.self.query.bias', 'base_model.encoder.layer.8.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.8.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.21.output.LayerNorm.bias', 'base_model.embeddings.LayerNorm.weight', 'base_model.encoder.layer.0.attention.output.dense.bias', 'base_model.encoder.layer.5.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.9.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.11.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.4.attention.self.key.weight', 'base_model.encoder.layer.14.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.18.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.13.intermediate.dense.weight', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.5.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.5.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.1.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.2.attention.output.LayerNorm.bias', 'base_model.encoder.layer.1.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.11.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.20.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.9.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.23.attention.output.LayerNorm.bias', 'base_model.encoder.layer.2.output.LayerNorm.weight', 'base_model.encoder.layer.0.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.3.output.LayerNorm.bias', 'base_model.encoder.layer.9.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.4.attention.output.LayerNorm.weight', 'base_model.encoder.layer.13.attention.self.query.bias', 'base_model.encoder.layer.14.attention.self.key.bias', 'base_model.encoder.layer.15.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.22.output.dense.bias', 'base_model.encoder.layer.22.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.23.attention.self.key.weight', 'base_model.encoder.layer.8.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.0.output.dense.bias', 'base_model.encoder.layer.6.attention.self.key.weight', 'base_model.encoder.layer.6.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.5.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.2.attention.self.value.weight', 'base_model.encoder.layer.8.attention.self.value.weight', 'base_model.encoder.layer.12.attention.output.dense.bias', 'base_model.encoder.layer.17.output.LayerNorm.bias', 'base_model.encoder.layer.21.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.12.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.9.attention.self.value.bias', 'base_model.encoder.layer.12.output.LayerNorm.bias', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.1.attention.output.dense.weight', 'base_model.encoder.layer.7.attention.output.LayerNorm.bias', 'base_model.encoder.layer.8.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.14.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.15.output.LayerNorm.weight', 'base_model.encoder.layer.13.attention.self.query.weight', 'base_model.encoder.layer.5.attention.self.query.weight', 'base_model.encoder.layer.19.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.15.output.LayerNorm.bias', 'base_model.encoder.layer.3.intermediate.dense.weight', 'base_model.encoder.layer.17.attention.self.query.bias', 'base_model.encoder.layer.11.output.LayerNorm.bias', 'base_model.encoder.layer.20.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.10.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.4.intermediate.dense.weight', 'base_model.encoder.layer.12.attention.self.value.bias', 'base_model.encoder.layer.7.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.6.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.19.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.19.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.21.attention.self.key.weight', 'base_model.encoder.layer.12.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.18.output.dense.bias', 'base_model.encoder.layer.1.intermediate.dense.weight', 'base_model.encoder.layer.23.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.23.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.4.attention.self.query.bias', 'base_model.encoder.layer.1.output.LayerNorm.bias', 'base_model.encoder.layer.9.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.4.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.8.attention.self.query.weight', 'base_model.encoder.layer.8.attention.self.key.bias', 'base_model.encoder.layer.0.attention.self.query.bias', 'base_model.encoder.layer.23.attention.self.value.weight', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.15.attention.output.dense.bias', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.1.output.dense.weight', 'base_model.encoder.layer.14.attention.output.dense.weight', 'base_model.encoder.layer.4.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.22.attention.self.key.bias', 'base_model.encoder.layer.22.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.7.output.dense.weight', 'base_model.encoder.layer.11.attention.output.LayerNorm.weight', 'base_model.encoder.layer.14.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.4.attention.output.LayerNorm.bias', 'base_model.encoder.layer.0.attention.self.value.bias', 'base_model.encoder.layer.21.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.19.attention.output.LayerNorm.bias', 'base_model.encoder.layer.3.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.9.attention.self.value.weight', 'base_model.encoder.layer.18.attention.self.value.weight', 'base_model.encoder.layer.22.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.15.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.6.intermediate.dense.bias', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.0.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.1.attention.self.key.bias', 'base_model.encoder.layer.4.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.8.output.dense.bias', 'base_model.encoder.layer.6.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.1.attention.output.dense.bias', 'base_model.encoder.layer.19.output.adapters.es.adapter_down.0.bias', 'base_model.embeddings.LayerNorm.bias', 'base_model.encoder.layer.16.attention.self.query.bias', 'base_model.encoder.layer.23.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.16.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.1.attention.output.LayerNorm.weight', 'base_model.encoder.layer.19.attention.self.query.bias', 'base_model.encoder.layer.10.output.dense.weight', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.17.attention.self.query.weight', 'base_model.encoder.layer.22.attention.self.query.bias', 'base_model.encoder.layer.17.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.22.output.LayerNorm.weight', 'base_model.encoder.layer.13.attention.output.dense.bias', 'base_model.encoder.layer.18.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.3.output.LayerNorm.weight', 'base_model.encoder.layer.3.attention.self.value.bias', 'base_model.encoder.layer.14.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.4.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.17.intermediate.dense.bias', 'base_model.encoder.layer.12.attention.self.value.weight', 'base_model.encoder.layer.9.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.2.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.5.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.12.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.4.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.10.attention.self.query.weight', 'base_model.encoder.layer.16.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.21.intermediate.dense.bias', 'base_model.encoder.layer.11.attention.self.key.weight', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.0.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.12.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.1.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.10.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.14.output.LayerNorm.weight', 'base_model.encoder.layer.20.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.5.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.0.intermediate.dense.bias', 'base_model.encoder.layer.22.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.19.attention.self.value.bias', 'base_model.encoder.layer.15.attention.self.value.weight', 'base_model.encoder.layer.22.attention.self.value.weight', 'base_model.encoder.layer.4.attention.output.dense.weight', 'base_model.encoder.layer.3.attention.self.query.weight', 'base_model.encoder.layer.22.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.2.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.15.attention.self.query.weight', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.9.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.11.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.6.intermediate.dense.weight', 'base_model.encoder.layer.16.attention.self.value.weight', 'base_model.encoder.layer.20.intermediate.dense.weight', 'base_model.encoder.layer.2.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.12.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.3.intermediate.dense.bias', 'base_model.encoder.layer.13.intermediate.dense.bias', 'base_model.encoder.layer.7.attention.output.LayerNorm.weight', 'base_model.encoder.layer.0.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.2.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.13.attention.self.key.bias', 'base_model.encoder.layer.14.attention.self.query.weight', 'base_model.encoder.layer.10.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.14.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.13.output.dense.bias', 'base_model.encoder.layer.14.attention.self.value.bias', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.embeddings.word_embeddings.weight', 'base_model.encoder.layer.3.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.17.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.22.attention.output.dense.bias', 'base_model.encoder.layer.19.attention.self.key.bias', 'base_model.encoder.layer.15.attention.output.LayerNorm.weight', 'base_model.encoder.layer.5.attention.self.value.weight', 'base_model.encoder.layer.16.attention.output.dense.weight', 'base_model.encoder.layer.21.attention.self.value.weight', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.16.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.15.attention.output.dense.weight', 'base_model.encoder.layer.16.attention.self.key.weight', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.17.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.16.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.9.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.15.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.15.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.20.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.21.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.1.attention.self.value.weight', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.10.attention.self.query.bias', 'base_model.encoder.layer.10.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.10.attention.output.dense.bias', 'base_model.encoder.layer.1.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.19.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.9.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.15.attention.self.key.bias', 'base_model.encoder.layer.20.attention.self.query.bias', 'base_model.encoder.layer.3.attention.self.key.bias', 'base_model.encoder.layer.9.attention.self.query.bias', 'base_model.encoder.layer.16.output.dense.bias', 'base_model.encoder.layer.0.intermediate.dense.weight', 'base_model.encoder.layer.23.intermediate.dense.weight', 'base_model.encoder.layer.4.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.4.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.6.attention.output.dense.weight', 'base_model.encoder.layer.3.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.13.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.8.attention.output.dense.bias', 'base_model.embeddings.position_ids', 'base_model.encoder.layer.3.output.dense.weight', 'base_model.encoder.layer.3.output.dense.bias', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.20.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.1.attention.self.key.weight', 'base_model.encoder.layer.12.attention.self.query.weight', 'qa_outputs.weight', 'base_model.encoder.layer.2.attention.self.key.weight', 'base_model.encoder.layer.5.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.0.attention.self.key.bias', 'base_model.encoder.layer.4.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.16.output.dense.weight', 'base_model.encoder.layer.23.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.23.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.23.attention.output.LayerNorm.weight', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.2.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.2.output.dense.weight', 'base_model.encoder.layer.5.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.18.attention.self.key.weight', 'base_model.encoder.layer.10.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.19.attention.output.dense.weight', 'base_model.encoder.layer.11.intermediate.dense.bias', 'base_model.encoder.layer.2.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.9.output.LayerNorm.weight', 'base_model.encoder.layer.11.attention.self.key.bias', 'base_model.encoder.layer.14.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.16.attention.output.LayerNorm.bias', 'base_model.encoder.layer.15.attention.output.LayerNorm.bias', 'base_model.encoder.layer.23.attention.output.dense.bias', 'base_model.encoder.layer.10.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.8.output.dense.weight', 'base_model.encoder.layer.14.output.dense.weight', 'base_model.encoder.layer.0.attention.self.key.weight', 'base_model.encoder.layer.8.output.LayerNorm.weight', 'base_model.encoder.layer.12.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.18.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.9.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.16.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.18.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.10.attention.self.value.weight', 'base_model.encoder.layer.5.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.9.attention.self.key.weight', 'base_model.encoder.layer.6.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.11.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.5.attention.self.key.weight', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.11.attention.output.dense.bias', 'base_model.encoder.layer.15.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.18.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.23.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.2.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.4.output.LayerNorm.bias', 'base_model.encoder.layer.0.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.22.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.0.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.1.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.3.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.19.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.2.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.17.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.3.attention.output.LayerNorm.bias', 'base_model.encoder.layer.9.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.12.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.20.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.7.attention.self.value.weight', 'base_model.encoder.layer.12.intermediate.dense.weight', 'base_model.encoder.layer.15.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.7.attention.self.query.bias', 'base_model.encoder.layer.9.output.dense.weight', 'base_model.encoder.layer.6.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.5.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.7.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.14.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.19.attention.self.value.weight', 'base_model.encoder.layer.22.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.5.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.5.attention.output.LayerNorm.bias', 'base_model.encoder.layer.5.attention.output.dense.bias', 'base_model.encoder.layer.2.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.11.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.11.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.6.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.17.attention.output.dense.bias', 'base_model.encoder.layer.18.intermediate.dense.weight', 'base_model.encoder.layer.20.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.21.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.4.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.18.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.17.output.dense.bias', 'base_model.encoder.layer.18.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.21.intermediate.dense.weight', 'base_model.encoder.layer.0.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.10.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.15.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.21.output.LayerNorm.weight', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.20.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.2.intermediate.dense.weight', 'base_model.encoder.layer.8.attention.self.value.bias', 'base_model.encoder.layer.4.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.3.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.23.output.dense.weight', 'base_model.encoder.layer.20.attention.output.dense.bias', 'base_model.encoder.layer.0.output.LayerNorm.bias', 'base_model.encoder.layer.0.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.9.attention.output.dense.bias', 'base_model.encoder.layer.13.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.18.attention.output.dense.weight', 'base_model.encoder.layer.8.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.13.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.19.attention.self.query.weight', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.23.attention.self.value.bias', 'base_model.encoder.layer.11.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.5.attention.self.key.bias', 'base_model.encoder.layer.11.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.1.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.7.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.11.attention.self.query.bias', 'base_model.encoder.layer.14.output.LayerNorm.bias', 'base_model.encoder.layer.14.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.3.output.adapters.ts.adapter_up.bias']
- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of XLMRobertaModel were not initialized from the model checkpoint at /cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//squad/xlm-KG_LR3e-5_EPOCH2.0_maxlen384_batchsize4_gradacc4 and are newly initialized: ['encoder.layer.10.attention.output.LayerNorm.bias', 'encoder.layer.1.output.dense.bias', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.6.attention.output.dense.bias', 'encoder.layer.5.attention.self.key.bias', 'encoder.layer.10.output.dense.weight', 'encoder.layer.4.attention.self.value.bias', 'encoder.layer.13.attention.output.LayerNorm.bias', 'encoder.layer.3.attention.self.query.bias', 'encoder.layer.22.attention.self.key.weight', 'encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.layer.1.output.dense.weight', 'encoder.layer.4.attention.output.LayerNorm.bias', 'encoder.layer.16.attention.self.query.bias', 'encoder.layer.4.attention.self.query.bias', 'encoder.layer.12.intermediate.dense.weight', 'encoder.layer.8.attention.self.key.weight', 'encoder.layer.17.attention.self.query.weight', 'encoder.layer.11.attention.output.dense.bias', 'encoder.layer.9.attention.self.value.bias', 'encoder.layer.6.attention.output.LayerNorm.weight', 'encoder.layer.20.output.LayerNorm.bias', 'encoder.layer.16.attention.output.LayerNorm.bias', 'encoder.layer.11.attention.self.key.weight', 'encoder.layer.14.attention.output.LayerNorm.weight', 'encoder.layer.10.attention.output.dense.weight', 'encoder.layer.5.output.dense.bias', 'encoder.layer.15.attention.self.query.weight', 'encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.layer.21.output.LayerNorm.weight', 'embeddings.LayerNorm.weight', 'encoder.layer.23.output.dense.weight', 'encoder.layer.8.output.dense.bias', 'encoder.layer.10.output.dense.bias', 'encoder.layer.10.output.LayerNorm.weight', 'encoder.layer.14.intermediate.dense.bias', 'encoder.layer.10.attention.self.key.weight', 'encoder.layer.22.output.dense.weight', 'encoder.layer.15.attention.self.value.weight', 'encoder.layer.14.output.dense.weight', 'embeddings.token_type_embeddings.weight', 'encoder.layer.12.attention.self.value.weight', 'encoder.layer.16.attention.self.query.weight', 'encoder.layer.18.output.LayerNorm.weight', 'embeddings.LayerNorm.bias', 'encoder.layer.7.output.LayerNorm.weight', 'encoder.layer.21.attention.self.key.bias', 'encoder.layer.8.attention.output.LayerNorm.weight', 'pooler.dense.bias', 'encoder.layer.18.output.dense.weight', 'encoder.layer.23.attention.self.value.weight', 'encoder.layer.11.attention.output.dense.weight', 'encoder.layer.11.attention.output.LayerNorm.weight', 'encoder.layer.6.output.LayerNorm.bias', 'encoder.layer.22.attention.self.value.weight', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.4.output.dense.bias', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.23.attention.output.LayerNorm.bias', 'encoder.layer.18.attention.output.dense.bias', 'encoder.layer.5.attention.self.query.weight', 'encoder.layer.5.attention.self.key.weight', 'encoder.layer.12.attention.self.query.bias', 'encoder.layer.3.output.dense.weight', 'encoder.layer.13.attention.self.query.bias', 'encoder.layer.17.output.LayerNorm.bias', 'encoder.layer.8.attention.output.dense.bias', 'encoder.layer.3.attention.self.query.weight', 'encoder.layer.9.output.LayerNorm.weight', 'encoder.layer.18.attention.self.value.weight', 'encoder.layer.22.attention.output.LayerNorm.bias', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.20.intermediate.dense.bias', 'encoder.layer.2.attention.self.value.bias', 'encoder.layer.7.attention.self.value.weight', 'encoder.layer.8.attention.self.key.bias', 'encoder.layer.22.attention.output.dense.bias', 'encoder.layer.8.output.dense.weight', 'encoder.layer.12.attention.self.query.weight', 'encoder.layer.4.attention.self.key.bias', 'encoder.layer.15.attention.self.value.bias', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.4.attention.self.query.weight', 'encoder.layer.21.intermediate.dense.bias', 'encoder.layer.23.output.LayerNorm.weight', 'encoder.layer.23.intermediate.dense.weight', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.8.output.LayerNorm.bias', 'encoder.layer.15.output.LayerNorm.weight', 'encoder.layer.8.attention.self.query.bias', 'encoder.layer.15.attention.self.key.bias', 'encoder.layer.22.output.LayerNorm.weight', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.19.attention.self.value.bias', 'encoder.layer.8.attention.output.dense.weight', 'encoder.layer.23.attention.self.query.bias', 'encoder.layer.12.attention.self.key.bias', 'encoder.layer.5.attention.output.LayerNorm.weight', 'encoder.layer.20.output.LayerNorm.weight', 'encoder.layer.5.attention.output.dense.weight', 'encoder.layer.15.attention.self.query.bias', 'encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.layer.19.attention.self.query.bias', 'encoder.layer.20.intermediate.dense.weight', 'encoder.layer.17.attention.output.dense.bias', 'encoder.layer.17.output.dense.weight', 'encoder.layer.19.output.LayerNorm.weight', 'encoder.layer.5.attention.output.dense.bias', 'encoder.layer.19.output.dense.bias', 'encoder.layer.14.attention.self.key.weight', 'encoder.layer.20.attention.self.key.weight', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.1.attention.self.query.weight', 'encoder.layer.4.output.dense.weight', 'encoder.layer.21.attention.self.query.bias', 'encoder.layer.13.attention.output.LayerNorm.weight', 'encoder.layer.17.attention.output.dense.weight', 'encoder.layer.10.attention.output.dense.bias', 'encoder.layer.18.attention.self.key.weight', 'encoder.layer.2.attention.self.key.weight', 'encoder.layer.20.output.dense.bias', 'encoder.layer.22.attention.self.key.bias', 'encoder.layer.18.attention.self.value.bias', 'encoder.layer.1.attention.self.value.bias', 'encoder.layer.18.attention.self.key.bias', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.4.attention.self.value.weight', 'encoder.layer.9.output.dense.bias', 'encoder.layer.23.attention.output.dense.bias', 'encoder.layer.13.attention.self.value.bias', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.12.attention.output.LayerNorm.bias', 'encoder.layer.22.attention.self.value.bias', 'encoder.layer.18.intermediate.dense.bias', 'encoder.layer.3.attention.self.key.bias', 'encoder.layer.10.intermediate.dense.weight', 'encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.layer.12.attention.self.key.weight', 'encoder.layer.7.output.dense.bias', 'encoder.layer.15.intermediate.dense.bias', 'encoder.layer.14.attention.self.query.weight', 'encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.19.attention.output.dense.weight', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.1.attention.self.query.bias', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.5.attention.self.value.weight', 'encoder.layer.13.intermediate.dense.weight', 'encoder.layer.19.attention.self.key.bias', 'encoder.layer.12.intermediate.dense.bias', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.11.output.LayerNorm.weight', 'encoder.layer.11.attention.self.value.bias', 'encoder.layer.0.attention.self.key.bias', 'encoder.layer.11.attention.self.key.bias', 'encoder.layer.9.attention.self.key.bias', 'encoder.layer.13.output.dense.bias', 'encoder.layer.6.attention.self.query.bias', 'encoder.layer.19.attention.output.LayerNorm.bias', 'encoder.layer.12.output.dense.weight', 'encoder.layer.16.attention.self.key.weight', 'encoder.layer.7.attention.output.LayerNorm.bias', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.17.attention.self.query.bias', 'encoder.layer.18.output.LayerNorm.bias', 'encoder.layer.15.output.LayerNorm.bias', 'encoder.layer.9.attention.self.query.weight', 'encoder.layer.22.intermediate.dense.bias', 'encoder.layer.8.attention.output.LayerNorm.bias', 'encoder.layer.18.attention.self.query.bias', 'encoder.layer.2.attention.self.value.weight', 'embeddings.position_embeddings.weight', 'encoder.layer.9.output.dense.weight', 'encoder.layer.3.attention.output.dense.weight', 'encoder.layer.11.output.dense.bias', 'encoder.layer.19.attention.self.key.weight', 'encoder.layer.21.attention.output.LayerNorm.bias', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.23.attention.self.value.bias', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.20.attention.output.dense.weight', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.15.intermediate.dense.weight', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.14.intermediate.dense.weight', 'encoder.layer.4.attention.output.dense.bias', 'encoder.layer.7.attention.self.value.bias', 'encoder.layer.22.attention.output.dense.weight', 'encoder.layer.23.intermediate.dense.bias', 'encoder.layer.7.attention.self.key.bias', 'encoder.layer.16.output.dense.bias', 'encoder.layer.8.attention.self.value.bias', 'encoder.layer.9.attention.self.key.weight', 'encoder.layer.0.attention.self.query.weight', 'encoder.layer.10.attention.self.value.weight', 'encoder.layer.12.attention.self.value.bias', 'encoder.layer.15.output.dense.weight', 'encoder.layer.23.attention.self.key.bias', 'encoder.layer.15.attention.self.key.weight', 'encoder.layer.20.output.dense.weight', 'encoder.layer.19.intermediate.dense.weight', 'encoder.layer.17.attention.self.value.weight', 'encoder.layer.3.attention.self.value.weight', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.7.intermediate.dense.bias', 'encoder.layer.15.attention.output.dense.bias', 'encoder.layer.21.intermediate.dense.weight', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.0.attention.self.key.weight', 'pooler.dense.weight', 'encoder.layer.14.attention.output.LayerNorm.bias', 'encoder.layer.0.attention.self.value.weight', 'encoder.layer.23.attention.output.LayerNorm.weight', 'encoder.layer.7.attention.output.dense.bias', 'encoder.layer.6.attention.output.LayerNorm.bias', 'encoder.layer.12.attention.output.LayerNorm.weight', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.12.output.LayerNorm.bias', 'encoder.layer.16.output.LayerNorm.bias', 'encoder.layer.0.attention.self.value.bias', 'encoder.layer.1.attention.self.key.weight', 'encoder.layer.16.output.LayerNorm.weight', 'encoder.layer.15.attention.output.LayerNorm.bias', 'encoder.layer.9.attention.self.value.weight', 'encoder.layer.20.attention.output.dense.bias', 'encoder.layer.17.attention.output.LayerNorm.weight', 'encoder.layer.1.attention.output.LayerNorm.weight', 'encoder.layer.22.output.dense.bias', 'encoder.layer.8.output.LayerNorm.weight', 'encoder.layer.17.intermediate.dense.bias', 'encoder.layer.14.attention.self.value.weight', 'encoder.layer.16.attention.self.value.bias', 'encoder.layer.16.attention.self.key.bias', 'encoder.layer.18.intermediate.dense.weight', 'encoder.layer.1.attention.self.key.bias', 'encoder.layer.21.attention.self.key.weight', 'encoder.layer.15.output.dense.bias', 'encoder.layer.8.attention.self.query.weight', 'encoder.layer.14.attention.self.query.bias', 'encoder.layer.6.attention.self.value.weight', 'encoder.layer.5.output.LayerNorm.bias', 'encoder.layer.7.attention.output.dense.weight', 'encoder.layer.0.output.dense.weight', 'encoder.layer.0.attention.output.dense.bias', 'encoder.layer.0.attention.output.LayerNorm.weight', 'encoder.layer.21.output.LayerNorm.bias', 'encoder.layer.7.output.dense.weight', 'encoder.layer.6.attention.output.dense.weight', 'encoder.layer.6.attention.self.key.weight', 'encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.layer.4.attention.output.dense.weight', 'encoder.layer.21.attention.output.dense.weight', 'encoder.layer.10.output.LayerNorm.bias', 'encoder.layer.17.attention.self.value.bias', 'encoder.layer.12.attention.output.dense.bias', 'encoder.layer.18.attention.output.LayerNorm.weight', 'encoder.layer.20.attention.output.LayerNorm.bias', 'encoder.layer.23.attention.self.key.weight', 'encoder.layer.23.output.dense.bias', 'encoder.layer.13.output.dense.weight', 'encoder.layer.10.attention.self.query.bias', 'encoder.layer.13.attention.self.query.weight', 'encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.layer.21.attention.self.value.bias', 'encoder.layer.2.output.dense.bias', 'encoder.layer.2.attention.self.key.bias', 'encoder.layer.9.attention.output.dense.weight', 'encoder.layer.13.attention.output.dense.weight', 'encoder.layer.19.attention.output.LayerNorm.weight', 'encoder.layer.7.output.LayerNorm.bias', 'encoder.layer.4.attention.self.key.weight', 'encoder.layer.10.attention.self.value.bias', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.20.attention.self.value.bias', 'encoder.layer.2.attention.output.dense.bias', 'encoder.layer.2.attention.self.query.weight', 'encoder.layer.18.output.dense.bias', 'embeddings.word_embeddings.weight', 'encoder.layer.14.output.LayerNorm.bias', 'encoder.layer.14.attention.output.dense.bias', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.21.attention.self.query.weight', 'encoder.layer.7.attention.self.query.weight', 'encoder.layer.16.attention.output.dense.bias', 'encoder.layer.23.output.LayerNorm.bias', 'encoder.layer.17.attention.self.key.bias', 'encoder.layer.1.attention.self.value.weight', 'encoder.layer.20.attention.self.value.weight', 'encoder.layer.7.attention.self.query.bias', 'encoder.layer.13.attention.self.key.bias', 'encoder.layer.0.attention.output.dense.weight', 'encoder.layer.14.attention.output.dense.weight', 'encoder.layer.11.output.LayerNorm.bias', 'encoder.layer.23.attention.output.dense.weight', 'encoder.layer.18.attention.self.query.weight', 'encoder.layer.13.attention.output.dense.bias', 'encoder.layer.6.attention.self.query.weight', 'encoder.layer.10.attention.self.query.weight', 'encoder.layer.6.attention.self.value.bias', 'encoder.layer.0.output.dense.bias', 'encoder.layer.22.attention.self.query.weight', 'encoder.layer.21.output.dense.weight', 'encoder.layer.7.attention.output.LayerNorm.weight', 'encoder.layer.18.attention.output.dense.weight', 'encoder.layer.14.output.dense.bias', 'encoder.layer.17.output.LayerNorm.weight', 'encoder.layer.1.attention.output.dense.weight', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.19.output.dense.weight', 'encoder.layer.8.attention.self.value.weight', 'encoder.layer.5.attention.self.query.bias', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.22.attention.output.LayerNorm.weight', 'encoder.layer.3.output.dense.bias', 'encoder.layer.20.attention.self.query.weight', 'encoder.layer.23.attention.self.query.weight', 'encoder.layer.20.attention.self.key.bias', 'encoder.layer.22.attention.self.query.bias', 'encoder.layer.21.attention.output.dense.bias', 'encoder.layer.2.attention.output.LayerNorm.weight', 'encoder.layer.13.attention.self.key.weight', 'encoder.layer.14.attention.self.key.bias', 'encoder.layer.1.attention.output.dense.bias', 'encoder.layer.9.output.LayerNorm.bias', 'encoder.layer.11.output.dense.weight', 'encoder.layer.13.output.LayerNorm.weight', 'encoder.layer.6.attention.self.key.bias', 'encoder.layer.15.attention.output.LayerNorm.weight', 'encoder.layer.22.intermediate.dense.weight', 'encoder.layer.17.attention.output.LayerNorm.bias', 'encoder.layer.21.output.dense.bias', 'encoder.layer.3.attention.self.value.bias', 'encoder.layer.17.output.dense.bias', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.12.output.LayerNorm.weight', 'encoder.layer.9.attention.output.LayerNorm.bias', 'encoder.layer.19.attention.self.value.weight', 'encoder.layer.11.attention.self.query.weight', 'encoder.layer.22.output.LayerNorm.bias', 'encoder.layer.19.intermediate.dense.bias', 'encoder.layer.13.output.LayerNorm.bias', 'encoder.layer.0.attention.self.query.bias', 'encoder.layer.2.attention.output.LayerNorm.bias', 'encoder.layer.11.attention.self.query.bias', 'encoder.layer.6.output.dense.weight', 'encoder.layer.16.attention.output.dense.weight', 'encoder.layer.10.attention.output.LayerNorm.weight', 'encoder.layer.17.attention.self.key.weight', 'encoder.layer.21.attention.output.LayerNorm.weight', 'encoder.layer.3.attention.output.dense.bias', 'encoder.layer.14.attention.self.value.bias', 'encoder.layer.20.attention.output.LayerNorm.weight', 'encoder.layer.9.attention.output.dense.bias', 'encoder.layer.17.intermediate.dense.weight', 'encoder.layer.14.output.LayerNorm.weight', 'encoder.layer.18.attention.output.LayerNorm.bias', 'encoder.layer.15.attention.output.dense.weight', 'encoder.layer.16.attention.self.value.weight', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.6.output.dense.bias', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.19.output.LayerNorm.bias', 'encoder.layer.11.attention.self.value.weight', 'encoder.layer.13.intermediate.dense.bias', 'encoder.layer.16.attention.output.LayerNorm.weight', 'encoder.layer.4.attention.output.LayerNorm.weight', 'encoder.layer.21.attention.self.value.weight', 'encoder.layer.5.attention.self.value.bias', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.12.output.dense.bias', 'encoder.layer.5.output.dense.weight', 'encoder.layer.19.attention.output.dense.bias', 'encoder.layer.20.attention.self.query.bias', 'encoder.layer.16.intermediate.dense.bias', 'encoder.layer.9.attention.output.LayerNorm.weight', 'encoder.layer.3.attention.self.key.weight', 'encoder.layer.2.attention.output.dense.weight', 'encoder.layer.2.attention.self.query.bias', 'encoder.layer.16.output.dense.weight', 'encoder.layer.12.attention.output.dense.weight', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.10.attention.self.key.bias', 'encoder.layer.2.output.dense.weight', 'encoder.layer.7.attention.self.key.weight', 'encoder.layer.16.intermediate.dense.weight', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.13.attention.self.value.weight', 'encoder.layer.19.attention.self.query.weight', 'encoder.layer.9.attention.self.query.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Overwriting existing adapter 'ep'.
Overwriting existing adapter 'tp'.
Overwriting existing adapter 'es'.
Overwriting existing adapter 'ts'.
Overwriting existing adapter fusion module 'ep,tp,es,ts'
05/09/2022 09:18:10 - INFO - __main__ -   lang2id = None
05/09/2022 09:18:15 - INFO - __main__ -   Training/evaluation parameters Namespace(adam_epsilon=1e-08, cache_dir='', config_name='', data_dir=None, device=device(type='cuda'), do_eval=True, do_lower_case=False, do_train=False, doc_stride=128, eval_all_checkpoints=False, eval_lang='zh', evaluate_during_training=False, fp16=False, fp16_opt_level='O1', gradient_accumulation_steps=1, learning_rate=5e-05, local_rank=-1, logging_steps=50, max_answer_length=30, max_grad_norm=1.0, max_query_length=64, max_seq_length=384, max_steps=-1, model_name='xlm-KG', model_name_or_path='/cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//squad/xlm-KG_LR3e-5_EPOCH2.0_maxlen384_batchsize4_gradacc4', model_type='xlm', modelkg_dir='/cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/adapter/xlmr_adapter', n_best_size=20, n_gpu=1, no_cuda=False, null_score_diff_threshold=0.0, num_train_epochs=3.0, output_dir='/cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//squad/xlm-KG_LR3e-5_EPOCH2.0_maxlen384_batchsize4_gradacc4/predictions/xquad/', overwrite_cache=False, overwrite_output_dir=False, per_gpu_eval_batch_size=8, per_gpu_train_batch_size=8, predict_file='/cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/download//xquad//xquad.zh.json', save_steps=50, seed=42, server_ip='', server_port='', threads=1, tokenizer_name='', train_file=None, train_lang='en', verbose_logging=False, version_2_with_negative=False, warmup_steps=0, weight_decay=0.0)
05/09/2022 09:18:15 - INFO - __main__ -   Loading checkpoint /cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//squad/xlm-KG_LR3e-5_EPOCH2.0_maxlen384_batchsize4_gradacc4 for evaluation
05/09/2022 09:18:15 - INFO - __main__ -   Evaluate the following checkpoints: ['/cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//squad/xlm-KG_LR3e-5_EPOCH2.0_maxlen384_batchsize4_gradacc4']
Some weights of the model checkpoint at /cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//squad/xlm-KG_LR3e-5_EPOCH2.0_maxlen384_batchsize4_gradacc4 were not used when initializing XLMRobertaModel: ['base_model.encoder.layer.23.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.7.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.16.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.9.attention.output.LayerNorm.weight', 'base_model.encoder.layer.2.attention.self.query.bias', 'base_model.encoder.layer.16.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.13.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.18.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.10.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.18.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.21.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.11.attention.self.query.weight', 'base_model.encoder.layer.23.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.19.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.12.attention.self.key.bias', 'base_model.encoder.layer.20.attention.output.LayerNorm.weight', 'base_model.encoder.layer.6.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.9.intermediate.dense.weight', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.10.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.18.output.LayerNorm.bias', 'base_model.encoder.layer.17.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.20.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.2.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.3.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.4.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.16.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.12.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.15.intermediate.dense.weight', 'base_model.encoder.layer.1.attention.output.LayerNorm.bias', 'base_model.encoder.layer.2.intermediate.dense.bias', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.6.output.dense.bias', 'base_model.encoder.layer.23.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.6.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.10.output.LayerNorm.weight', 'base_model.encoder.layer.16.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.3.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.10.attention.self.key.weight', 'base_model.encoder.layer.8.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.22.intermediate.dense.bias', 'base_model.encoder.layer.10.intermediate.dense.weight', 'base_model.encoder.layer.13.attention.output.LayerNorm.weight', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.14.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.7.attention.self.key.bias', 'base_model.encoder.layer.21.attention.output.LayerNorm.weight', 'base_model.encoder.layer.14.attention.output.LayerNorm.bias', 'base_model.encoder.layer.0.output.dense.weight', 'base_model.encoder.layer.22.attention.self.key.weight', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.16.attention.output.LayerNorm.weight', 'base_model.encoder.layer.16.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.19.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.15.output.dense.weight', 'base_model.encoder.layer.0.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.12.attention.output.LayerNorm.weight', 'base_model.encoder.layer.18.attention.self.key.bias', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.18.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.3.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.3.attention.output.dense.weight', 'base_model.encoder.layer.16.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.20.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.18.attention.self.query.bias', 'base_model.encoder.layer.19.output.LayerNorm.weight', 'base_model.encoder.layer.19.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.6.attention.self.value.weight', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.10.attention.self.value.bias', 'base_model.encoder.layer.20.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.7.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.11.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.2.attention.self.key.bias', 'base_model.encoder.layer.8.attention.self.query.bias', 'base_model.encoder.layer.8.intermediate.dense.weight', 'base_model.encoder.layer.22.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.4.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.14.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.7.intermediate.dense.bias', 'base_model.encoder.layer.22.attention.self.query.weight', 'base_model.encoder.layer.11.attention.self.value.weight', 'base_model.embeddings.token_type_embeddings.weight', 'base_model.encoder.layer.18.intermediate.dense.bias', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.18.attention.self.query.weight', 'base_model.encoder.layer.23.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.8.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.11.attention.self.value.bias', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.13.output.adapters.ep.adapter_down.0.weight', 'base_model.pooler.dense.bias', 'base_model.encoder.layer.1.output.dense.bias', 'base_model.encoder.layer.7.attention.self.query.weight', 'base_model.encoder.layer.12.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.23.attention.self.query.bias', 'base_model.encoder.layer.16.output.LayerNorm.weight', 'base_model.encoder.layer.8.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.1.attention.self.value.bias', 'base_model.encoder.layer.21.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.1.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.6.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.6.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.15.attention.self.key.weight', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.15.output.dense.bias', 'base_model.encoder.layer.11.attention.output.dense.weight', 'base_model.encoder.layer.15.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.3.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.16.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.22.output.dense.weight', 'base_model.encoder.layer.2.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.11.output.LayerNorm.weight', 'base_model.encoder.layer.13.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.21.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.7.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.0.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.13.attention.self.value.bias', 'base_model.encoder.layer.19.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.2.output.dense.bias', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.1.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.7.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.0.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.14.attention.self.query.bias', 'base_model.encoder.layer.4.output.dense.weight', 'base_model.encoder.layer.9.output.LayerNorm.bias', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.13.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.7.attention.output.dense.weight', 'base_model.encoder.layer.8.output.LayerNorm.bias', 'base_model.encoder.layer.17.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.17.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.18.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.embeddings.position_embeddings.weight', 'base_model.encoder.layer.9.attention.output.dense.weight', 'base_model.encoder.layer.12.attention.output.dense.weight', 'base_model.encoder.layer.8.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.2.output.LayerNorm.bias', 'base_model.encoder.layer.6.output.dense.weight', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.19.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.22.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.1.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.6.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.19.output.dense.weight', 'base_model.encoder.layer.23.attention.self.key.bias', 'base_model.encoder.layer.10.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.5.output.LayerNorm.bias', 'base_model.encoder.layer.15.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.11.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.17.attention.self.key.bias', 'base_model.encoder.layer.12.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.19.output.dense.bias', 'base_model.encoder.layer.23.output.LayerNorm.weight', 'base_model.encoder.layer.15.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.21.attention.self.query.weight', 'base_model.encoder.layer.14.attention.self.key.weight', 'base_model.encoder.layer.16.attention.self.value.bias', 'base_model.encoder.layer.13.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.4.attention.self.key.bias', 'base_model.encoder.layer.21.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.16.intermediate.dense.weight', 'base_model.encoder.layer.23.output.dense.bias', 'base_model.encoder.layer.3.attention.self.query.bias', 'base_model.encoder.layer.17.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.18.output.dense.weight', 'base_model.encoder.layer.8.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.1.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.5.output.dense.weight', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.19.attention.output.dense.bias', 'base_model.encoder.layer.19.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.12.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.18.attention.self.value.bias', 'base_model.encoder.layer.19.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.20.output.LayerNorm.bias', 'base_model.encoder.layer.19.output.LayerNorm.bias', 'base_model.encoder.layer.7.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.20.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.20.intermediate.dense.bias', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.11.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.9.attention.output.LayerNorm.bias', 'base_model.encoder.layer.17.attention.self.value.weight', 'base_model.encoder.layer.11.output.dense.weight', 'base_model.encoder.layer.20.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.22.attention.output.LayerNorm.weight', 'base_model.encoder.layer.12.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.22.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.5.intermediate.dense.bias', 'base_model.encoder.layer.9.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.12.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.10.output.dense.bias', 'base_model.encoder.layer.12.attention.self.query.bias', 'base_model.encoder.layer.15.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.4.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.17.attention.output.dense.weight', 'base_model.encoder.layer.6.output.LayerNorm.bias', 'base_model.encoder.layer.19.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.8.attention.output.LayerNorm.bias', 'base_model.encoder.layer.13.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.20.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.23.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.12.output.LayerNorm.weight', 'base_model.encoder.layer.6.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.7.output.LayerNorm.weight', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.4.attention.self.value.bias', 'base_model.encoder.layer.20.attention.self.value.weight', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.7.attention.self.key.weight', 'base_model.encoder.layer.10.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.23.attention.self.query.weight', 'base_model.encoder.layer.7.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.23.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.18.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.19.intermediate.dense.weight', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.13.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.17.output.LayerNorm.weight', 'base_model.encoder.layer.0.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.9.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.17.output.dense.weight', 'base_model.encoder.layer.19.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.19.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.20.output.dense.bias', 'base_model.encoder.layer.20.attention.self.key.weight', 'base_model.encoder.layer.4.intermediate.dense.bias', 'base_model.encoder.layer.15.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.17.attention.self.key.weight', 'base_model.encoder.layer.15.attention.self.value.bias', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.0.attention.output.LayerNorm.bias', 'base_model.encoder.layer.20.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.8.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.22.attention.output.LayerNorm.bias', 'base_model.encoder.layer.2.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.6.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.20.attention.output.dense.weight', 'base_model.encoder.layer.6.attention.self.query.weight', 'base_model.encoder.layer.20.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.6.attention.output.LayerNorm.weight', 'base_model.encoder.layer.13.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.18.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.16.intermediate.dense.bias', 'base_model.encoder.layer.5.attention.self.value.bias', 'base_model.encoder.layer.18.attention.output.LayerNorm.bias', 'base_model.encoder.layer.12.intermediate.dense.bias', 'base_model.encoder.layer.1.attention.self.query.bias', 'base_model.encoder.layer.10.output.LayerNorm.bias', 'base_model.encoder.layer.17.attention.output.LayerNorm.bias', 'base_model.encoder.layer.10.attention.output.LayerNorm.weight', 'base_model.encoder.layer.8.attention.output.dense.weight', 'base_model.encoder.layer.4.output.LayerNorm.weight', 'base_model.encoder.layer.0.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.22.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.15.attention.self.query.bias', 'base_model.encoder.layer.22.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.14.intermediate.dense.bias', 'base_model.encoder.layer.22.output.LayerNorm.bias', 'base_model.encoder.layer.21.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.21.attention.self.key.bias', 'base_model.encoder.layer.14.intermediate.dense.weight', 'base_model.encoder.layer.2.attention.output.dense.weight', 'base_model.encoder.layer.0.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.6.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.4.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.23.intermediate.dense.bias', 'base_model.encoder.layer.6.attention.output.LayerNorm.bias', 'base_model.encoder.layer.14.attention.output.dense.bias', 'base_model.encoder.layer.21.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.17.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.1.attention.self.query.weight', 'base_model.encoder.layer.7.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.7.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.14.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.7.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.18.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.3.attention.output.LayerNorm.weight', 'base_model.encoder.layer.22.attention.self.value.bias', 'base_model.encoder.layer.5.attention.output.LayerNorm.weight', 'base_model.encoder.layer.2.attention.output.LayerNorm.weight', 'base_model.encoder.layer.2.attention.self.query.weight', 'base_model.encoder.layer.8.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.12.attention.output.LayerNorm.bias', 'base_model.encoder.layer.17.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.21.attention.output.LayerNorm.bias', 'base_model.encoder.layer.5.attention.self.query.bias', 'base_model.encoder.layer.4.attention.self.query.weight', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.9.intermediate.dense.bias', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.11.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.16.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.15.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.13.attention.output.LayerNorm.bias', 'base_model.encoder.layer.12.output.dense.bias', 'base_model.encoder.layer.3.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.5.output.dense.bias', 'base_model.encoder.layer.23.output.LayerNorm.bias', 'base_model.encoder.layer.18.attention.output.LayerNorm.weight', 'base_model.encoder.layer.1.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.13.output.dense.weight', 'base_model.encoder.layer.1.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.16.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.4.attention.output.dense.bias', 'base_model.encoder.layer.3.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.5.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.21.attention.self.value.bias', 'base_model.encoder.layer.5.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.17.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.9.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.16.attention.self.query.weight', 'base_model.encoder.layer.20.attention.self.query.weight', 'base_model.encoder.layer.13.attention.self.value.weight', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.23.attention.output.dense.weight', 'base_model.encoder.layer.6.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.4.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.21.attention.output.dense.bias', 'base_model.encoder.layer.18.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.18.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.7.output.dense.bias', 'base_model.encoder.layer.23.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.17.intermediate.dense.weight', 'base_model.encoder.layer.6.attention.self.query.bias', 'base_model.encoder.layer.11.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.3.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.14.output.dense.bias', 'base_model.encoder.layer.16.output.LayerNorm.bias', 'base_model.encoder.layer.12.output.dense.weight', 'base_model.encoder.layer.1.output.LayerNorm.weight', 'base_model.encoder.layer.0.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.5.attention.output.dense.weight', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.16.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.19.attention.self.key.weight', 'base_model.encoder.layer.6.attention.self.value.bias', 'base_model.encoder.layer.15.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.6.attention.output.dense.bias', 'base_model.encoder.layer.13.output.adapters.es.adapter_up.bias', 'qa_outputs.bias', 'base_model.encoder.layer.3.attention.self.key.weight', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.14.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.20.attention.output.LayerNorm.bias', 'base_model.encoder.layer.2.attention.output.dense.bias', 'base_model.encoder.layer.3.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.5.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.17.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.5.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.6.output.LayerNorm.weight', 'base_model.encoder.layer.22.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.0.attention.output.dense.weight', 'base_model.encoder.layer.3.attention.output.dense.bias', 'base_model.encoder.layer.13.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.8.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.7.intermediate.dense.weight', 'base_model.encoder.layer.4.output.dense.bias', 'base_model.encoder.layer.1.intermediate.dense.bias', 'base_model.encoder.layer.1.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.19.intermediate.dense.bias', 'base_model.encoder.layer.10.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.9.attention.self.query.weight', 'base_model.encoder.layer.5.intermediate.dense.weight', 'base_model.encoder.layer.9.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.22.attention.output.dense.weight', 'base_model.encoder.layer.14.attention.self.value.weight', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.23.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.21.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.21.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.8.intermediate.dense.bias', 'base_model.encoder.layer.20.output.LayerNorm.weight', 'base_model.encoder.layer.2.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.7.attention.output.dense.bias', 'base_model.encoder.layer.22.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.13.attention.self.key.weight', 'base_model.encoder.layer.15.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.12.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.17.attention.self.value.bias', 'base_model.encoder.layer.16.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.17.attention.output.LayerNorm.weight', 'base_model.encoder.layer.10.attention.output.dense.weight', 'base_model.encoder.layer.17.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.21.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.7.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.1.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.7.output.LayerNorm.bias', 'base_model.encoder.layer.16.attention.self.key.bias', 'base_model.encoder.layer.10.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.10.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.20.attention.self.value.bias', 'base_model.encoder.layer.22.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.14.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.8.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.21.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.3.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.11.output.dense.bias', 'base_model.encoder.layer.3.attention.self.value.weight', 'base_model.encoder.layer.0.attention.self.value.weight', 'base_model.encoder.layer.12.attention.self.key.weight', 'base_model.encoder.layer.10.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.2.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.14.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.21.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.10.attention.output.LayerNorm.bias', 'base_model.encoder.layer.15.output.adapters.ts.adapter_up.weight', 'base_model.pooler.dense.weight', 'base_model.encoder.layer.0.attention.self.query.weight', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.23.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.6.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.20.attention.self.key.bias', 'base_model.encoder.layer.21.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.0.output.LayerNorm.weight', 'base_model.encoder.layer.10.intermediate.dense.bias', 'base_model.encoder.layer.12.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.10.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.13.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.13.output.LayerNorm.bias', 'base_model.encoder.layer.2.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.0.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.11.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.11.intermediate.dense.weight', 'base_model.encoder.layer.2.attention.self.value.bias', 'base_model.encoder.layer.14.attention.output.LayerNorm.weight', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.6.attention.self.key.bias', 'base_model.encoder.layer.7.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.17.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.18.attention.output.dense.bias', 'base_model.encoder.layer.20.output.dense.weight', 'base_model.encoder.layer.7.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.5.output.LayerNorm.weight', 'base_model.encoder.layer.5.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.17.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.8.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.21.output.dense.bias', 'base_model.encoder.layer.11.attention.output.LayerNorm.bias', 'base_model.encoder.layer.22.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.11.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.13.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.11.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.15.intermediate.dense.bias', 'base_model.encoder.layer.21.output.dense.weight', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.21.attention.output.dense.weight', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.19.attention.output.LayerNorm.weight', 'base_model.encoder.layer.1.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.10.attention.self.key.bias', 'base_model.encoder.layer.23.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.13.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.4.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.2.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.13.attention.output.dense.weight', 'base_model.encoder.layer.8.attention.self.key.weight', 'base_model.encoder.layer.8.attention.output.LayerNorm.weight', 'base_model.encoder.layer.9.output.dense.bias', 'base_model.encoder.layer.14.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.3.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.16.attention.output.dense.bias', 'base_model.encoder.layer.12.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.22.intermediate.dense.weight', 'base_model.encoder.layer.13.output.LayerNorm.weight', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.18.output.LayerNorm.weight', 'base_model.encoder.layer.0.attention.output.LayerNorm.weight', 'base_model.encoder.layer.7.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.4.attention.self.value.weight', 'base_model.encoder.layer.7.attention.self.value.bias', 'base_model.encoder.layer.1.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.8.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.9.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.9.attention.self.key.bias', 'base_model.encoder.layer.17.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.14.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.9.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.21.attention.self.query.bias', 'base_model.encoder.layer.8.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.8.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.21.output.LayerNorm.bias', 'base_model.embeddings.LayerNorm.weight', 'base_model.encoder.layer.0.attention.output.dense.bias', 'base_model.encoder.layer.5.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.9.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.11.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.4.attention.self.key.weight', 'base_model.encoder.layer.14.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.18.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.13.intermediate.dense.weight', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.5.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.5.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.1.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.2.attention.output.LayerNorm.bias', 'base_model.encoder.layer.1.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.11.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.20.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.9.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.23.attention.output.LayerNorm.bias', 'base_model.encoder.layer.2.output.LayerNorm.weight', 'base_model.encoder.layer.0.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.3.output.LayerNorm.bias', 'base_model.encoder.layer.9.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.4.attention.output.LayerNorm.weight', 'base_model.encoder.layer.13.attention.self.query.bias', 'base_model.encoder.layer.14.attention.self.key.bias', 'base_model.encoder.layer.15.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.22.output.dense.bias', 'base_model.encoder.layer.22.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.23.attention.self.key.weight', 'base_model.encoder.layer.8.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.0.output.dense.bias', 'base_model.encoder.layer.6.attention.self.key.weight', 'base_model.encoder.layer.6.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.5.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.2.attention.self.value.weight', 'base_model.encoder.layer.8.attention.self.value.weight', 'base_model.encoder.layer.12.attention.output.dense.bias', 'base_model.encoder.layer.17.output.LayerNorm.bias', 'base_model.encoder.layer.21.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.12.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.9.attention.self.value.bias', 'base_model.encoder.layer.12.output.LayerNorm.bias', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.1.attention.output.dense.weight', 'base_model.encoder.layer.7.attention.output.LayerNorm.bias', 'base_model.encoder.layer.8.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.14.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.15.output.LayerNorm.weight', 'base_model.encoder.layer.13.attention.self.query.weight', 'base_model.encoder.layer.5.attention.self.query.weight', 'base_model.encoder.layer.19.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.15.output.LayerNorm.bias', 'base_model.encoder.layer.3.intermediate.dense.weight', 'base_model.encoder.layer.17.attention.self.query.bias', 'base_model.encoder.layer.11.output.LayerNorm.bias', 'base_model.encoder.layer.20.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.10.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.4.intermediate.dense.weight', 'base_model.encoder.layer.12.attention.self.value.bias', 'base_model.encoder.layer.7.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.6.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.19.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.19.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.21.attention.self.key.weight', 'base_model.encoder.layer.12.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.18.output.dense.bias', 'base_model.encoder.layer.1.intermediate.dense.weight', 'base_model.encoder.layer.23.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.23.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.4.attention.self.query.bias', 'base_model.encoder.layer.1.output.LayerNorm.bias', 'base_model.encoder.layer.9.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.4.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.8.attention.self.query.weight', 'base_model.encoder.layer.8.attention.self.key.bias', 'base_model.encoder.layer.0.attention.self.query.bias', 'base_model.encoder.layer.23.attention.self.value.weight', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.15.attention.output.dense.bias', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.1.output.dense.weight', 'base_model.encoder.layer.14.attention.output.dense.weight', 'base_model.encoder.layer.4.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.22.attention.self.key.bias', 'base_model.encoder.layer.22.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.7.output.dense.weight', 'base_model.encoder.layer.11.attention.output.LayerNorm.weight', 'base_model.encoder.layer.14.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.4.attention.output.LayerNorm.bias', 'base_model.encoder.layer.0.attention.self.value.bias', 'base_model.encoder.layer.21.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.19.attention.output.LayerNorm.bias', 'base_model.encoder.layer.3.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.9.attention.self.value.weight', 'base_model.encoder.layer.18.attention.self.value.weight', 'base_model.encoder.layer.22.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.15.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.6.intermediate.dense.bias', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.0.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.1.attention.self.key.bias', 'base_model.encoder.layer.4.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.8.output.dense.bias', 'base_model.encoder.layer.6.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.1.attention.output.dense.bias', 'base_model.encoder.layer.19.output.adapters.es.adapter_down.0.bias', 'base_model.embeddings.LayerNorm.bias', 'base_model.encoder.layer.16.attention.self.query.bias', 'base_model.encoder.layer.23.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.16.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.1.attention.output.LayerNorm.weight', 'base_model.encoder.layer.19.attention.self.query.bias', 'base_model.encoder.layer.10.output.dense.weight', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.17.attention.self.query.weight', 'base_model.encoder.layer.22.attention.self.query.bias', 'base_model.encoder.layer.17.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.22.output.LayerNorm.weight', 'base_model.encoder.layer.13.attention.output.dense.bias', 'base_model.encoder.layer.18.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.3.output.LayerNorm.weight', 'base_model.encoder.layer.3.attention.self.value.bias', 'base_model.encoder.layer.14.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.4.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.17.intermediate.dense.bias', 'base_model.encoder.layer.12.attention.self.value.weight', 'base_model.encoder.layer.9.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.2.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.5.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.12.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.4.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.10.attention.self.query.weight', 'base_model.encoder.layer.16.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.21.intermediate.dense.bias', 'base_model.encoder.layer.11.attention.self.key.weight', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.0.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.12.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.1.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.10.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.14.output.LayerNorm.weight', 'base_model.encoder.layer.20.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.5.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.0.intermediate.dense.bias', 'base_model.encoder.layer.22.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.19.attention.self.value.bias', 'base_model.encoder.layer.15.attention.self.value.weight', 'base_model.encoder.layer.22.attention.self.value.weight', 'base_model.encoder.layer.4.attention.output.dense.weight', 'base_model.encoder.layer.3.attention.self.query.weight', 'base_model.encoder.layer.22.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.2.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.15.attention.self.query.weight', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.9.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.11.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.6.intermediate.dense.weight', 'base_model.encoder.layer.16.attention.self.value.weight', 'base_model.encoder.layer.20.intermediate.dense.weight', 'base_model.encoder.layer.2.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.12.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.3.intermediate.dense.bias', 'base_model.encoder.layer.13.intermediate.dense.bias', 'base_model.encoder.layer.7.attention.output.LayerNorm.weight', 'base_model.encoder.layer.0.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.2.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.13.attention.self.key.bias', 'base_model.encoder.layer.14.attention.self.query.weight', 'base_model.encoder.layer.10.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.14.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.13.output.dense.bias', 'base_model.encoder.layer.14.attention.self.value.bias', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.embeddings.word_embeddings.weight', 'base_model.encoder.layer.3.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.17.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.22.attention.output.dense.bias', 'base_model.encoder.layer.19.attention.self.key.bias', 'base_model.encoder.layer.15.attention.output.LayerNorm.weight', 'base_model.encoder.layer.5.attention.self.value.weight', 'base_model.encoder.layer.16.attention.output.dense.weight', 'base_model.encoder.layer.21.attention.self.value.weight', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.16.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.15.attention.output.dense.weight', 'base_model.encoder.layer.16.attention.self.key.weight', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.17.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.16.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.9.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.15.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.15.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.20.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.21.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.1.attention.self.value.weight', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.10.attention.self.query.bias', 'base_model.encoder.layer.10.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.10.attention.output.dense.bias', 'base_model.encoder.layer.1.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.19.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.9.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.15.attention.self.key.bias', 'base_model.encoder.layer.20.attention.self.query.bias', 'base_model.encoder.layer.3.attention.self.key.bias', 'base_model.encoder.layer.9.attention.self.query.bias', 'base_model.encoder.layer.16.output.dense.bias', 'base_model.encoder.layer.0.intermediate.dense.weight', 'base_model.encoder.layer.23.intermediate.dense.weight', 'base_model.encoder.layer.4.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.4.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.6.attention.output.dense.weight', 'base_model.encoder.layer.3.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.13.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.8.attention.output.dense.bias', 'base_model.embeddings.position_ids', 'base_model.encoder.layer.3.output.dense.weight', 'base_model.encoder.layer.3.output.dense.bias', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.20.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.1.attention.self.key.weight', 'base_model.encoder.layer.12.attention.self.query.weight', 'qa_outputs.weight', 'base_model.encoder.layer.2.attention.self.key.weight', 'base_model.encoder.layer.5.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.0.attention.self.key.bias', 'base_model.encoder.layer.4.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.16.output.dense.weight', 'base_model.encoder.layer.23.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.23.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.23.attention.output.LayerNorm.weight', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.2.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.2.output.dense.weight', 'base_model.encoder.layer.5.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.18.attention.self.key.weight', 'base_model.encoder.layer.10.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.19.attention.output.dense.weight', 'base_model.encoder.layer.11.intermediate.dense.bias', 'base_model.encoder.layer.2.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.9.output.LayerNorm.weight', 'base_model.encoder.layer.11.attention.self.key.bias', 'base_model.encoder.layer.14.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.16.attention.output.LayerNorm.bias', 'base_model.encoder.layer.15.attention.output.LayerNorm.bias', 'base_model.encoder.layer.23.attention.output.dense.bias', 'base_model.encoder.layer.10.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.8.output.dense.weight', 'base_model.encoder.layer.14.output.dense.weight', 'base_model.encoder.layer.0.attention.self.key.weight', 'base_model.encoder.layer.8.output.LayerNorm.weight', 'base_model.encoder.layer.12.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.18.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.9.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.16.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.18.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.10.attention.self.value.weight', 'base_model.encoder.layer.5.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.9.attention.self.key.weight', 'base_model.encoder.layer.6.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.11.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.5.attention.self.key.weight', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.11.attention.output.dense.bias', 'base_model.encoder.layer.15.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.18.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.23.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.2.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.4.output.LayerNorm.bias', 'base_model.encoder.layer.0.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.22.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.0.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.1.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.3.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.19.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.2.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.17.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.3.attention.output.LayerNorm.bias', 'base_model.encoder.layer.9.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.12.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.20.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.7.attention.self.value.weight', 'base_model.encoder.layer.12.intermediate.dense.weight', 'base_model.encoder.layer.15.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.7.attention.self.query.bias', 'base_model.encoder.layer.9.output.dense.weight', 'base_model.encoder.layer.6.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.5.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.7.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.14.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.19.attention.self.value.weight', 'base_model.encoder.layer.22.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.5.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.5.attention.output.LayerNorm.bias', 'base_model.encoder.layer.5.attention.output.dense.bias', 'base_model.encoder.layer.2.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.11.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.11.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.6.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.17.attention.output.dense.bias', 'base_model.encoder.layer.18.intermediate.dense.weight', 'base_model.encoder.layer.20.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.21.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.4.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.18.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.17.output.dense.bias', 'base_model.encoder.layer.18.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.21.intermediate.dense.weight', 'base_model.encoder.layer.0.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.10.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.15.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.21.output.LayerNorm.weight', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.20.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.2.intermediate.dense.weight', 'base_model.encoder.layer.8.attention.self.value.bias', 'base_model.encoder.layer.4.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.3.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.23.output.dense.weight', 'base_model.encoder.layer.20.attention.output.dense.bias', 'base_model.encoder.layer.0.output.LayerNorm.bias', 'base_model.encoder.layer.0.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.9.attention.output.dense.bias', 'base_model.encoder.layer.13.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.18.attention.output.dense.weight', 'base_model.encoder.layer.8.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.13.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.19.attention.self.query.weight', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.23.attention.self.value.bias', 'base_model.encoder.layer.11.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.5.attention.self.key.bias', 'base_model.encoder.layer.11.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.1.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.7.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.11.attention.self.query.bias', 'base_model.encoder.layer.14.output.LayerNorm.bias', 'base_model.encoder.layer.14.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.3.output.adapters.ts.adapter_up.bias']
- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of XLMRobertaModel were not initialized from the model checkpoint at /cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//squad/xlm-KG_LR3e-5_EPOCH2.0_maxlen384_batchsize4_gradacc4 and are newly initialized: ['encoder.layer.10.attention.output.LayerNorm.bias', 'encoder.layer.1.output.dense.bias', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.6.attention.output.dense.bias', 'encoder.layer.5.attention.self.key.bias', 'encoder.layer.10.output.dense.weight', 'encoder.layer.4.attention.self.value.bias', 'encoder.layer.13.attention.output.LayerNorm.bias', 'encoder.layer.3.attention.self.query.bias', 'encoder.layer.22.attention.self.key.weight', 'encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.layer.1.output.dense.weight', 'encoder.layer.4.attention.output.LayerNorm.bias', 'encoder.layer.16.attention.self.query.bias', 'encoder.layer.4.attention.self.query.bias', 'encoder.layer.12.intermediate.dense.weight', 'encoder.layer.8.attention.self.key.weight', 'encoder.layer.17.attention.self.query.weight', 'encoder.layer.11.attention.output.dense.bias', 'encoder.layer.9.attention.self.value.bias', 'encoder.layer.6.attention.output.LayerNorm.weight', 'encoder.layer.20.output.LayerNorm.bias', 'encoder.layer.16.attention.output.LayerNorm.bias', 'encoder.layer.11.attention.self.key.weight', 'encoder.layer.14.attention.output.LayerNorm.weight', 'encoder.layer.10.attention.output.dense.weight', 'encoder.layer.5.output.dense.bias', 'encoder.layer.15.attention.self.query.weight', 'encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.layer.21.output.LayerNorm.weight', 'embeddings.LayerNorm.weight', 'encoder.layer.23.output.dense.weight', 'encoder.layer.8.output.dense.bias', 'encoder.layer.10.output.dense.bias', 'encoder.layer.10.output.LayerNorm.weight', 'encoder.layer.14.intermediate.dense.bias', 'encoder.layer.10.attention.self.key.weight', 'encoder.layer.22.output.dense.weight', 'encoder.layer.15.attention.self.value.weight', 'encoder.layer.14.output.dense.weight', 'embeddings.token_type_embeddings.weight', 'encoder.layer.12.attention.self.value.weight', 'encoder.layer.16.attention.self.query.weight', 'encoder.layer.18.output.LayerNorm.weight', 'embeddings.LayerNorm.bias', 'encoder.layer.7.output.LayerNorm.weight', 'encoder.layer.21.attention.self.key.bias', 'encoder.layer.8.attention.output.LayerNorm.weight', 'pooler.dense.bias', 'encoder.layer.18.output.dense.weight', 'encoder.layer.23.attention.self.value.weight', 'encoder.layer.11.attention.output.dense.weight', 'encoder.layer.11.attention.output.LayerNorm.weight', 'encoder.layer.6.output.LayerNorm.bias', 'encoder.layer.22.attention.self.value.weight', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.4.output.dense.bias', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.23.attention.output.LayerNorm.bias', 'encoder.layer.18.attention.output.dense.bias', 'encoder.layer.5.attention.self.query.weight', 'encoder.layer.5.attention.self.key.weight', 'encoder.layer.12.attention.self.query.bias', 'encoder.layer.3.output.dense.weight', 'encoder.layer.13.attention.self.query.bias', 'encoder.layer.17.output.LayerNorm.bias', 'encoder.layer.8.attention.output.dense.bias', 'encoder.layer.3.attention.self.query.weight', 'encoder.layer.9.output.LayerNorm.weight', 'encoder.layer.18.attention.self.value.weight', 'encoder.layer.22.attention.output.LayerNorm.bias', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.20.intermediate.dense.bias', 'encoder.layer.2.attention.self.value.bias', 'encoder.layer.7.attention.self.value.weight', 'encoder.layer.8.attention.self.key.bias', 'encoder.layer.22.attention.output.dense.bias', 'encoder.layer.8.output.dense.weight', 'encoder.layer.12.attention.self.query.weight', 'encoder.layer.4.attention.self.key.bias', 'encoder.layer.15.attention.self.value.bias', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.4.attention.self.query.weight', 'encoder.layer.21.intermediate.dense.bias', 'encoder.layer.23.output.LayerNorm.weight', 'encoder.layer.23.intermediate.dense.weight', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.8.output.LayerNorm.bias', 'encoder.layer.15.output.LayerNorm.weight', 'encoder.layer.8.attention.self.query.bias', 'encoder.layer.15.attention.self.key.bias', 'encoder.layer.22.output.LayerNorm.weight', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.19.attention.self.value.bias', 'encoder.layer.8.attention.output.dense.weight', 'encoder.layer.23.attention.self.query.bias', 'encoder.layer.12.attention.self.key.bias', 'encoder.layer.5.attention.output.LayerNorm.weight', 'encoder.layer.20.output.LayerNorm.weight', 'encoder.layer.5.attention.output.dense.weight', 'encoder.layer.15.attention.self.query.bias', 'encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.layer.19.attention.self.query.bias', 'encoder.layer.20.intermediate.dense.weight', 'encoder.layer.17.attention.output.dense.bias', 'encoder.layer.17.output.dense.weight', 'encoder.layer.19.output.LayerNorm.weight', 'encoder.layer.5.attention.output.dense.bias', 'encoder.layer.19.output.dense.bias', 'encoder.layer.14.attention.self.key.weight', 'encoder.layer.20.attention.self.key.weight', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.1.attention.self.query.weight', 'encoder.layer.4.output.dense.weight', 'encoder.layer.21.attention.self.query.bias', 'encoder.layer.13.attention.output.LayerNorm.weight', 'encoder.layer.17.attention.output.dense.weight', 'encoder.layer.10.attention.output.dense.bias', 'encoder.layer.18.attention.self.key.weight', 'encoder.layer.2.attention.self.key.weight', 'encoder.layer.20.output.dense.bias', 'encoder.layer.22.attention.self.key.bias', 'encoder.layer.18.attention.self.value.bias', 'encoder.layer.1.attention.self.value.bias', 'encoder.layer.18.attention.self.key.bias', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.4.attention.self.value.weight', 'encoder.layer.9.output.dense.bias', 'encoder.layer.23.attention.output.dense.bias', 'encoder.layer.13.attention.self.value.bias', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.12.attention.output.LayerNorm.bias', 'encoder.layer.22.attention.self.value.bias', 'encoder.layer.18.intermediate.dense.bias', 'encoder.layer.3.attention.self.key.bias', 'encoder.layer.10.intermediate.dense.weight', 'encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.layer.12.attention.self.key.weight', 'encoder.layer.7.output.dense.bias', 'encoder.layer.15.intermediate.dense.bias', 'encoder.layer.14.attention.self.query.weight', 'encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.19.attention.output.dense.weight', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.1.attention.self.query.bias', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.5.attention.self.value.weight', 'encoder.layer.13.intermediate.dense.weight', 'encoder.layer.19.attention.self.key.bias', 'encoder.layer.12.intermediate.dense.bias', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.11.output.LayerNorm.weight', 'encoder.layer.11.attention.self.value.bias', 'encoder.layer.0.attention.self.key.bias', 'encoder.layer.11.attention.self.key.bias', 'encoder.layer.9.attention.self.key.bias', 'encoder.layer.13.output.dense.bias', 'encoder.layer.6.attention.self.query.bias', 'encoder.layer.19.attention.output.LayerNorm.bias', 'encoder.layer.12.output.dense.weight', 'encoder.layer.16.attention.self.key.weight', 'encoder.layer.7.attention.output.LayerNorm.bias', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.17.attention.self.query.bias', 'encoder.layer.18.output.LayerNorm.bias', 'encoder.layer.15.output.LayerNorm.bias', 'encoder.layer.9.attention.self.query.weight', 'encoder.layer.22.intermediate.dense.bias', 'encoder.layer.8.attention.output.LayerNorm.bias', 'encoder.layer.18.attention.self.query.bias', 'encoder.layer.2.attention.self.value.weight', 'embeddings.position_embeddings.weight', 'encoder.layer.9.output.dense.weight', 'encoder.layer.3.attention.output.dense.weight', 'encoder.layer.11.output.dense.bias', 'encoder.layer.19.attention.self.key.weight', 'encoder.layer.21.attention.output.LayerNorm.bias', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.23.attention.self.value.bias', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.20.attention.output.dense.weight', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.15.intermediate.dense.weight', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.14.intermediate.dense.weight', 'encoder.layer.4.attention.output.dense.bias', 'encoder.layer.7.attention.self.value.bias', 'encoder.layer.22.attention.output.dense.weight', 'encoder.layer.23.intermediate.dense.bias', 'encoder.layer.7.attention.self.key.bias', 'encoder.layer.16.output.dense.bias', 'encoder.layer.8.attention.self.value.bias', 'encoder.layer.9.attention.self.key.weight', 'encoder.layer.0.attention.self.query.weight', 'encoder.layer.10.attention.self.value.weight', 'encoder.layer.12.attention.self.value.bias', 'encoder.layer.15.output.dense.weight', 'encoder.layer.23.attention.self.key.bias', 'encoder.layer.15.attention.self.key.weight', 'encoder.layer.20.output.dense.weight', 'encoder.layer.19.intermediate.dense.weight', 'encoder.layer.17.attention.self.value.weight', 'encoder.layer.3.attention.self.value.weight', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.7.intermediate.dense.bias', 'encoder.layer.15.attention.output.dense.bias', 'encoder.layer.21.intermediate.dense.weight', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.0.attention.self.key.weight', 'pooler.dense.weight', 'encoder.layer.14.attention.output.LayerNorm.bias', 'encoder.layer.0.attention.self.value.weight', 'encoder.layer.23.attention.output.LayerNorm.weight', 'encoder.layer.7.attention.output.dense.bias', 'encoder.layer.6.attention.output.LayerNorm.bias', 'encoder.layer.12.attention.output.LayerNorm.weight', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.12.output.LayerNorm.bias', 'encoder.layer.16.output.LayerNorm.bias', 'encoder.layer.0.attention.self.value.bias', 'encoder.layer.1.attention.self.key.weight', 'encoder.layer.16.output.LayerNorm.weight', 'encoder.layer.15.attention.output.LayerNorm.bias', 'encoder.layer.9.attention.self.value.weight', 'encoder.layer.20.attention.output.dense.bias', 'encoder.layer.17.attention.output.LayerNorm.weight', 'encoder.layer.1.attention.output.LayerNorm.weight', 'encoder.layer.22.output.dense.bias', 'encoder.layer.8.output.LayerNorm.weight', 'encoder.layer.17.intermediate.dense.bias', 'encoder.layer.14.attention.self.value.weight', 'encoder.layer.16.attention.self.value.bias', 'encoder.layer.16.attention.self.key.bias', 'encoder.layer.18.intermediate.dense.weight', 'encoder.layer.1.attention.self.key.bias', 'encoder.layer.21.attention.self.key.weight', 'encoder.layer.15.output.dense.bias', 'encoder.layer.8.attention.self.query.weight', 'encoder.layer.14.attention.self.query.bias', 'encoder.layer.6.attention.self.value.weight', 'encoder.layer.5.output.LayerNorm.bias', 'encoder.layer.7.attention.output.dense.weight', 'encoder.layer.0.output.dense.weight', 'encoder.layer.0.attention.output.dense.bias', 'encoder.layer.0.attention.output.LayerNorm.weight', 'encoder.layer.21.output.LayerNorm.bias', 'encoder.layer.7.output.dense.weight', 'encoder.layer.6.attention.output.dense.weight', 'encoder.layer.6.attention.self.key.weight', 'encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.layer.4.attention.output.dense.weight', 'encoder.layer.21.attention.output.dense.weight', 'encoder.layer.10.output.LayerNorm.bias', 'encoder.layer.17.attention.self.value.bias', 'encoder.layer.12.attention.output.dense.bias', 'encoder.layer.18.attention.output.LayerNorm.weight', 'encoder.layer.20.attention.output.LayerNorm.bias', 'encoder.layer.23.attention.self.key.weight', 'encoder.layer.23.output.dense.bias', 'encoder.layer.13.output.dense.weight', 'encoder.layer.10.attention.self.query.bias', 'encoder.layer.13.attention.self.query.weight', 'encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.layer.21.attention.self.value.bias', 'encoder.layer.2.output.dense.bias', 'encoder.layer.2.attention.self.key.bias', 'encoder.layer.9.attention.output.dense.weight', 'encoder.layer.13.attention.output.dense.weight', 'encoder.layer.19.attention.output.LayerNorm.weight', 'encoder.layer.7.output.LayerNorm.bias', 'encoder.layer.4.attention.self.key.weight', 'encoder.layer.10.attention.self.value.bias', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.20.attention.self.value.bias', 'encoder.layer.2.attention.output.dense.bias', 'encoder.layer.2.attention.self.query.weight', 'encoder.layer.18.output.dense.bias', 'embeddings.word_embeddings.weight', 'encoder.layer.14.output.LayerNorm.bias', 'encoder.layer.14.attention.output.dense.bias', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.21.attention.self.query.weight', 'encoder.layer.7.attention.self.query.weight', 'encoder.layer.16.attention.output.dense.bias', 'encoder.layer.23.output.LayerNorm.bias', 'encoder.layer.17.attention.self.key.bias', 'encoder.layer.1.attention.self.value.weight', 'encoder.layer.20.attention.self.value.weight', 'encoder.layer.7.attention.self.query.bias', 'encoder.layer.13.attention.self.key.bias', 'encoder.layer.0.attention.output.dense.weight', 'encoder.layer.14.attention.output.dense.weight', 'encoder.layer.11.output.LayerNorm.bias', 'encoder.layer.23.attention.output.dense.weight', 'encoder.layer.18.attention.self.query.weight', 'encoder.layer.13.attention.output.dense.bias', 'encoder.layer.6.attention.self.query.weight', 'encoder.layer.10.attention.self.query.weight', 'encoder.layer.6.attention.self.value.bias', 'encoder.layer.0.output.dense.bias', 'encoder.layer.22.attention.self.query.weight', 'encoder.layer.21.output.dense.weight', 'encoder.layer.7.attention.output.LayerNorm.weight', 'encoder.layer.18.attention.output.dense.weight', 'encoder.layer.14.output.dense.bias', 'encoder.layer.17.output.LayerNorm.weight', 'encoder.layer.1.attention.output.dense.weight', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.19.output.dense.weight', 'encoder.layer.8.attention.self.value.weight', 'encoder.layer.5.attention.self.query.bias', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.22.attention.output.LayerNorm.weight', 'encoder.layer.3.output.dense.bias', 'encoder.layer.20.attention.self.query.weight', 'encoder.layer.23.attention.self.query.weight', 'encoder.layer.20.attention.self.key.bias', 'encoder.layer.22.attention.self.query.bias', 'encoder.layer.21.attention.output.dense.bias', 'encoder.layer.2.attention.output.LayerNorm.weight', 'encoder.layer.13.attention.self.key.weight', 'encoder.layer.14.attention.self.key.bias', 'encoder.layer.1.attention.output.dense.bias', 'encoder.layer.9.output.LayerNorm.bias', 'encoder.layer.11.output.dense.weight', 'encoder.layer.13.output.LayerNorm.weight', 'encoder.layer.6.attention.self.key.bias', 'encoder.layer.15.attention.output.LayerNorm.weight', 'encoder.layer.22.intermediate.dense.weight', 'encoder.layer.17.attention.output.LayerNorm.bias', 'encoder.layer.21.output.dense.bias', 'encoder.layer.3.attention.self.value.bias', 'encoder.layer.17.output.dense.bias', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.12.output.LayerNorm.weight', 'encoder.layer.9.attention.output.LayerNorm.bias', 'encoder.layer.19.attention.self.value.weight', 'encoder.layer.11.attention.self.query.weight', 'encoder.layer.22.output.LayerNorm.bias', 'encoder.layer.19.intermediate.dense.bias', 'encoder.layer.13.output.LayerNorm.bias', 'encoder.layer.0.attention.self.query.bias', 'encoder.layer.2.attention.output.LayerNorm.bias', 'encoder.layer.11.attention.self.query.bias', 'encoder.layer.6.output.dense.weight', 'encoder.layer.16.attention.output.dense.weight', 'encoder.layer.10.attention.output.LayerNorm.weight', 'encoder.layer.17.attention.self.key.weight', 'encoder.layer.21.attention.output.LayerNorm.weight', 'encoder.layer.3.attention.output.dense.bias', 'encoder.layer.14.attention.self.value.bias', 'encoder.layer.20.attention.output.LayerNorm.weight', 'encoder.layer.9.attention.output.dense.bias', 'encoder.layer.17.intermediate.dense.weight', 'encoder.layer.14.output.LayerNorm.weight', 'encoder.layer.18.attention.output.LayerNorm.bias', 'encoder.layer.15.attention.output.dense.weight', 'encoder.layer.16.attention.self.value.weight', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.6.output.dense.bias', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.19.output.LayerNorm.bias', 'encoder.layer.11.attention.self.value.weight', 'encoder.layer.13.intermediate.dense.bias', 'encoder.layer.16.attention.output.LayerNorm.weight', 'encoder.layer.4.attention.output.LayerNorm.weight', 'encoder.layer.21.attention.self.value.weight', 'encoder.layer.5.attention.self.value.bias', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.12.output.dense.bias', 'encoder.layer.5.output.dense.weight', 'encoder.layer.19.attention.output.dense.bias', 'encoder.layer.20.attention.self.query.bias', 'encoder.layer.16.intermediate.dense.bias', 'encoder.layer.9.attention.output.LayerNorm.weight', 'encoder.layer.3.attention.self.key.weight', 'encoder.layer.2.attention.output.dense.weight', 'encoder.layer.2.attention.self.query.bias', 'encoder.layer.16.output.dense.weight', 'encoder.layer.12.attention.output.dense.weight', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.10.attention.self.key.bias', 'encoder.layer.2.output.dense.weight', 'encoder.layer.7.attention.self.key.weight', 'encoder.layer.16.intermediate.dense.weight', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.13.attention.self.value.weight', 'encoder.layer.19.attention.self.query.weight', 'encoder.layer.9.attention.self.query.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Overwriting existing adapter 'ep'.
Overwriting existing adapter 'tp'.
Overwriting existing adapter 'es'.
Overwriting existing adapter 'ts'.
Overwriting existing adapter fusion module 'ep,tp,es,ts'
05/09/2022 09:18:44 - INFO - __main__ -   Creating features from dataset file at .
/cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//squad/xlm-KG_LR3e-5_EPOCH2.0_maxlen384_batchsize4_gradacc4
XLMConfig {
  "architectures": [
    "XLMRobertaForMaskedLM"
  ],
  "asm": false,
  "attention_dropout": 0.1,
  "attention_probs_dropout_prob": 0.1,
  "bos_index": 0,
  "bos_token_id": 0,
  "causal": false,
  "dropout": 0.1,
  "emb_dim": 1024,
  "embed_init_std": 0.02209708691207961,
  "end_n_top": 5,
  "eos_index": 1,
  "eos_token_id": 2,
  "gelu_activation": true,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "init_std": 0.02,
  "initializer_range": 0.02,
  "intermediate_size": 4096,
  "is_encoder": true,
  "lang_id": 0,
  "layer_norm_eps": 1e-05,
  "mask_index": 5,
  "mask_token_id": 0,
  "max_position_embeddings": 514,
  "model_type": "xlm",
  "n_heads": 16,
  "n_langs": 1,
  "n_layers": 24,
  "output_past": true,
  "pad_index": 2,
  "pad_token_id": 1,
  "sinusoidal_embeddings": false,
  "start_n_top": 5,
  "summary_activation": null,
  "summary_first_dropout": 0.1,
  "summary_proj_to_labels": true,
  "summary_type": "first",
  "summary_use_proj": true,
  "transformers_version": "4.17.0",
  "type_vocab_size": 1,
  "unk_index": 3,
  "use_lang_emb": false,
  "vocab_size": 250002
}

  0%|          | 0/48 [00:00<?, ?it/s] 38%|███▊      | 18/48 [00:00<00:00, 174.75it/s] 85%|████████▌ | 41/48 [00:00<00:00, 204.23it/s]100%|██████████| 48/48 [00:00<00:00, 207.02it/s]
convert squad examples to features:   0%|          | 0/1190 [00:00<?, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.
convert squad examples to features:   0%|          | 1/1190 [00:00<02:32,  7.78it/s]convert squad examples to features:   5%|▌         | 65/1190 [00:00<00:03, 326.35it/s]convert squad examples to features:  11%|█         | 129/1190 [00:00<00:02, 390.68it/s]convert squad examples to features:  16%|█▌        | 193/1190 [00:00<00:02, 456.58it/s]convert squad examples to features:  22%|██▏       | 257/1190 [00:00<00:01, 500.83it/s]convert squad examples to features:  26%|██▌       | 309/1190 [00:00<00:01, 446.92it/s]convert squad examples to features:  30%|██▉       | 356/1190 [00:00<00:02, 373.43it/s]convert squad examples to features:  33%|███▎      | 396/1190 [00:01<00:02, 279.08it/s]convert squad examples to features:  38%|███▊      | 449/1190 [00:01<00:02, 298.23it/s]convert squad examples to features:  43%|████▎     | 513/1190 [00:01<00:02, 324.38it/s]convert squad examples to features:  46%|████▌     | 548/1190 [00:01<00:02, 314.87it/s]convert squad examples to features:  51%|█████     | 609/1190 [00:01<00:01, 312.99it/s]convert squad examples to features:  57%|█████▋    | 673/1190 [00:02<00:01, 314.63it/s]convert squad examples to features:  59%|█████▉    | 706/1190 [00:02<00:01, 310.66it/s]convert squad examples to features:  65%|██████▍   | 769/1190 [00:02<00:01, 346.80it/s]convert squad examples to features:  70%|███████   | 833/1190 [00:02<00:01, 342.21it/s]convert squad examples to features:  75%|███████▌  | 897/1190 [00:02<00:00, 342.23it/s]convert squad examples to features:  81%|████████  | 961/1190 [00:02<00:00, 337.11it/s]convert squad examples to features:  84%|████████▎ | 995/1190 [00:02<00:00, 330.75it/s]convert squad examples to features:  89%|████████▉ | 1057/1190 [00:03<00:00, 384.47it/s]convert squad examples to features:  94%|█████████▍| 1121/1190 [00:03<00:00, 390.82it/s]convert squad examples to features:  98%|█████████▊| 1162/1190 [00:03<00:00, 393.37it/s]convert squad examples to features: 100%|██████████| 1190/1190 [00:03<00:00, 357.92it/s]
add example index and unique id:   0%|          | 0/1190 [00:00<?, ?it/s]add example index and unique id: 100%|██████████| 1190/1190 [00:00<00:00, 443034.06it/s]
05/09/2022 09:18:48 - INFO - __main__ -   Saving features into cached file ./cached_xquad.zh.json_xlm-KG_LR3e-5_EPOCH2.0_maxlen384_batchsize4_gradacc4_384_zh
05/09/2022 09:18:50 - INFO - __main__ -   ***** Running evaluation  *****
05/09/2022 09:18:50 - INFO - __main__ -     Num examples = 1246
05/09/2022 09:18:50 - INFO - __main__ -     Batch size = 8
Evaluating:   0%|          | 0/156 [00:00<?, ?it/s]Evaluating:   1%|          | 1/156 [00:00<02:24,  1.07it/s]Evaluating:   1%|▏         | 2/156 [00:01<01:29,  1.71it/s]Evaluating:   2%|▏         | 3/156 [00:01<01:12,  2.11it/s]Evaluating:   3%|▎         | 4/156 [00:01<01:04,  2.37it/s]Evaluating:   3%|▎         | 5/156 [00:02<00:59,  2.53it/s]Evaluating:   4%|▍         | 6/156 [00:02<00:56,  2.65it/s]Evaluating:   4%|▍         | 7/156 [00:02<00:54,  2.74it/s]Evaluating:   5%|▌         | 8/156 [00:03<00:52,  2.80it/s]Evaluating:   6%|▌         | 9/156 [00:03<00:51,  2.83it/s]Evaluating:   6%|▋         | 10/156 [00:04<00:51,  2.85it/s]Evaluating:   7%|▋         | 11/156 [00:04<00:50,  2.87it/s]Evaluating:   8%|▊         | 12/156 [00:04<00:49,  2.89it/s]Evaluating:   8%|▊         | 13/156 [00:05<00:49,  2.90it/s]Evaluating:   9%|▉         | 14/156 [00:05<00:48,  2.91it/s]Evaluating:  10%|▉         | 15/156 [00:05<00:48,  2.91it/s]Evaluating:  10%|█         | 16/156 [00:06<00:47,  2.92it/s]Evaluating:  11%|█         | 17/156 [00:06<00:47,  2.93it/s]Evaluating:  12%|█▏        | 18/156 [00:06<00:47,  2.93it/s]Evaluating:  12%|█▏        | 19/156 [00:07<00:46,  2.93it/s]Evaluating:  13%|█▎        | 20/156 [00:07<00:46,  2.92it/s]Evaluating:  13%|█▎        | 21/156 [00:07<00:46,  2.92it/s]Evaluating:  14%|█▍        | 22/156 [00:08<00:45,  2.92it/s]Evaluating:  15%|█▍        | 23/156 [00:08<00:45,  2.93it/s]Evaluating:  15%|█▌        | 24/156 [00:08<00:45,  2.92it/s]Evaluating:  16%|█▌        | 25/156 [00:09<00:44,  2.92it/s]Evaluating:  17%|█▋        | 26/156 [00:09<00:44,  2.92it/s]Evaluating:  17%|█▋        | 27/156 [00:09<00:44,  2.92it/s]Evaluating:  18%|█▊        | 28/156 [00:10<00:43,  2.92it/s]Evaluating:  19%|█▊        | 29/156 [00:10<00:43,  2.92it/s]Evaluating:  19%|█▉        | 30/156 [00:10<00:43,  2.93it/s]Evaluating:  20%|█▉        | 31/156 [00:11<00:42,  2.93it/s]Evaluating:  21%|██        | 32/156 [00:11<00:42,  2.92it/s]Evaluating:  21%|██        | 33/156 [00:11<00:42,  2.91it/s]Evaluating:  22%|██▏       | 34/156 [00:12<00:41,  2.91it/s]Evaluating:  22%|██▏       | 35/156 [00:12<00:41,  2.92it/s]Evaluating:  23%|██▎       | 36/156 [00:12<00:41,  2.92it/s]Evaluating:  24%|██▎       | 37/156 [00:13<00:40,  2.92it/s]Evaluating:  24%|██▍       | 38/156 [00:13<00:40,  2.92it/s]Evaluating:  25%|██▌       | 39/156 [00:13<00:40,  2.92it/s]Evaluating:  26%|██▌       | 40/156 [00:14<00:39,  2.92it/s]Evaluating:  26%|██▋       | 41/156 [00:14<00:39,  2.92it/s]Evaluating:  27%|██▋       | 42/156 [00:14<00:39,  2.92it/s]Evaluating:  28%|██▊       | 43/156 [00:15<00:38,  2.92it/s]Evaluating:  28%|██▊       | 44/156 [00:15<00:38,  2.92it/s]Evaluating:  29%|██▉       | 45/156 [00:15<00:38,  2.92it/s]Evaluating:  29%|██▉       | 46/156 [00:16<00:37,  2.92it/s]Evaluating:  30%|███       | 47/156 [00:16<00:37,  2.92it/s]Evaluating:  31%|███       | 48/156 [00:17<00:37,  2.92it/s]Evaluating:  31%|███▏      | 49/156 [00:17<00:36,  2.91it/s]Evaluating:  32%|███▏      | 50/156 [00:17<00:36,  2.91it/s]Evaluating:  33%|███▎      | 51/156 [00:18<00:36,  2.89it/s]Evaluating:  33%|███▎      | 52/156 [00:18<00:36,  2.89it/s]Evaluating:  34%|███▍      | 53/156 [00:18<00:35,  2.89it/s]Evaluating:  35%|███▍      | 54/156 [00:19<00:35,  2.88it/s]Evaluating:  35%|███▌      | 55/156 [00:19<00:35,  2.87it/s]Evaluating:  36%|███▌      | 56/156 [00:19<00:34,  2.86it/s]Evaluating:  37%|███▋      | 57/156 [00:20<00:34,  2.87it/s]Evaluating:  37%|███▋      | 58/156 [00:20<00:33,  2.89it/s]Evaluating:  38%|███▊      | 59/156 [00:20<00:33,  2.90it/s]Evaluating:  38%|███▊      | 60/156 [00:21<00:33,  2.89it/s]Evaluating:  39%|███▉      | 61/156 [00:21<00:32,  2.90it/s]Evaluating:  40%|███▉      | 62/156 [00:21<00:32,  2.90it/s]Evaluating:  40%|████      | 63/156 [00:22<00:32,  2.90it/s]Evaluating:  41%|████      | 64/156 [00:22<00:31,  2.91it/s]Evaluating:  42%|████▏     | 65/156 [00:22<00:31,  2.91it/s]Evaluating:  42%|████▏     | 66/156 [00:23<00:30,  2.91it/s]Evaluating:  43%|████▎     | 67/156 [00:23<00:30,  2.91it/s]Evaluating:  44%|████▎     | 68/156 [00:23<00:30,  2.91it/s]Evaluating:  44%|████▍     | 69/156 [00:24<00:29,  2.91it/s]Evaluating:  45%|████▍     | 70/156 [00:24<00:29,  2.91it/s]Evaluating:  46%|████▌     | 71/156 [00:24<00:29,  2.91it/s]Evaluating:  46%|████▌     | 72/156 [00:25<00:28,  2.91it/s]Evaluating:  47%|████▋     | 73/156 [00:25<00:28,  2.91it/s]Evaluating:  47%|████▋     | 74/156 [00:25<00:28,  2.91it/s]Evaluating:  48%|████▊     | 75/156 [00:26<00:27,  2.91it/s]Evaluating:  49%|████▊     | 76/156 [00:26<00:27,  2.91it/s]Evaluating:  49%|████▉     | 77/156 [00:27<00:27,  2.91it/s]Evaluating:  50%|█████     | 78/156 [00:27<00:26,  2.91it/s]Evaluating:  51%|█████     | 79/156 [00:27<00:26,  2.90it/s]Evaluating:  51%|█████▏    | 80/156 [00:28<00:26,  2.91it/s]Evaluating:  52%|█████▏    | 81/156 [00:28<00:25,  2.91it/s]Evaluating:  53%|█████▎    | 82/156 [00:28<00:25,  2.92it/s]Evaluating:  53%|█████▎    | 83/156 [00:29<00:25,  2.91it/s]Evaluating:  54%|█████▍    | 84/156 [00:29<00:24,  2.90it/s]Evaluating:  54%|█████▍    | 85/156 [00:29<00:24,  2.90it/s]Evaluating:  55%|█████▌    | 86/156 [00:30<00:24,  2.90it/s]Evaluating:  56%|█████▌    | 87/156 [00:30<00:23,  2.90it/s]Evaluating:  56%|█████▋    | 88/156 [00:30<00:23,  2.91it/s]Evaluating:  57%|█████▋    | 89/156 [00:31<00:23,  2.91it/s]Evaluating:  58%|█████▊    | 90/156 [00:31<00:22,  2.90it/s]Evaluating:  58%|█████▊    | 91/156 [00:31<00:22,  2.88it/s]Evaluating:  59%|█████▉    | 92/156 [00:32<00:22,  2.89it/s]Evaluating:  60%|█████▉    | 93/156 [00:32<00:21,  2.90it/s]Evaluating:  60%|██████    | 94/156 [00:32<00:21,  2.91it/s]Evaluating:  61%|██████    | 95/156 [00:33<00:20,  2.91it/s]Evaluating:  62%|██████▏   | 96/156 [00:33<00:20,  2.92it/s]Evaluating:  62%|██████▏   | 97/156 [00:33<00:20,  2.91it/s]Evaluating:  63%|██████▎   | 98/156 [00:34<00:19,  2.91it/s]Evaluating:  63%|██████▎   | 99/156 [00:34<00:19,  2.90it/s]Evaluating:  64%|██████▍   | 100/156 [00:34<00:19,  2.90it/s]Evaluating:  65%|██████▍   | 101/156 [00:35<00:18,  2.90it/s]Evaluating:  65%|██████▌   | 102/156 [00:35<00:18,  2.89it/s]Evaluating:  66%|██████▌   | 103/156 [00:35<00:18,  2.90it/s]Evaluating:  67%|██████▋   | 104/156 [00:36<00:17,  2.91it/s]Evaluating:  67%|██████▋   | 105/156 [00:36<00:17,  2.90it/s]Evaluating:  68%|██████▊   | 106/156 [00:37<00:17,  2.91it/s]Evaluating:  69%|██████▊   | 107/156 [00:37<00:16,  2.91it/s]Evaluating:  69%|██████▉   | 108/156 [00:37<00:16,  2.90it/s]Evaluating:  70%|██████▉   | 109/156 [00:38<00:16,  2.90it/s]Evaluating:  71%|███████   | 110/156 [00:38<00:15,  2.91it/s]Evaluating:  71%|███████   | 111/156 [00:38<00:15,  2.91it/s]Evaluating:  72%|███████▏  | 112/156 [00:39<00:15,  2.91it/s]Evaluating:  72%|███████▏  | 113/156 [00:39<00:14,  2.90it/s]Evaluating:  73%|███████▎  | 114/156 [00:39<00:14,  2.90it/s]Evaluating:  74%|███████▎  | 115/156 [00:40<00:14,  2.90it/s]Evaluating:  74%|███████▍  | 116/156 [00:40<00:13,  2.90it/s]Evaluating:  75%|███████▌  | 117/156 [00:40<00:13,  2.91it/s]Evaluating:  76%|███████▌  | 118/156 [00:41<00:13,  2.91it/s]Evaluating:  76%|███████▋  | 119/156 [00:41<00:12,  2.92it/s]Evaluating:  77%|███████▋  | 120/156 [00:41<00:12,  2.92it/s]Evaluating:  78%|███████▊  | 121/156 [00:42<00:12,  2.91it/s]Evaluating:  78%|███████▊  | 122/156 [00:42<00:11,  2.91it/s]Evaluating:  79%|███████▉  | 123/156 [00:42<00:11,  2.90it/s]Evaluating:  79%|███████▉  | 124/156 [00:43<00:11,  2.90it/s]Evaluating:  80%|████████  | 125/156 [00:43<00:10,  2.90it/s]Evaluating:  81%|████████  | 126/156 [00:43<00:10,  2.90it/s]Evaluating:  81%|████████▏ | 127/156 [00:44<00:09,  2.91it/s]Evaluating:  82%|████████▏ | 128/156 [00:44<00:09,  2.91it/s]Evaluating:  83%|████████▎ | 129/156 [00:44<00:09,  2.91it/s]Evaluating:  83%|████████▎ | 130/156 [00:45<00:08,  2.89it/s]Evaluating:  84%|████████▍ | 131/156 [00:45<00:08,  2.90it/s]Evaluating:  85%|████████▍ | 132/156 [00:45<00:08,  2.91it/s]Evaluating:  85%|████████▌ | 133/156 [00:46<00:07,  2.91it/s]Evaluating:  86%|████████▌ | 134/156 [00:46<00:07,  2.91it/s]Evaluating:  87%|████████▋ | 135/156 [00:46<00:07,  2.92it/s]Evaluating:  87%|████████▋ | 136/156 [00:47<00:06,  2.92it/s]Evaluating:  88%|████████▊ | 137/156 [00:47<00:06,  2.91it/s]Evaluating:  88%|████████▊ | 138/156 [00:48<00:06,  2.91it/s]Evaluating:  89%|████████▉ | 139/156 [00:48<00:05,  2.91it/s]Evaluating:  90%|████████▉ | 140/156 [00:48<00:05,  2.91it/s]Evaluating:  90%|█████████ | 141/156 [00:49<00:05,  2.90it/s]Evaluating:  91%|█████████ | 142/156 [00:49<00:04,  2.91it/s]Evaluating:  92%|█████████▏| 143/156 [00:49<00:04,  2.92it/s]Evaluating:  92%|█████████▏| 144/156 [00:50<00:04,  2.82it/s]Evaluating:  93%|█████████▎| 145/156 [00:50<00:03,  2.85it/s]Evaluating:  94%|█████████▎| 146/156 [00:50<00:03,  2.86it/s]Evaluating:  94%|█████████▍| 147/156 [00:51<00:03,  2.89it/s]Evaluating:  95%|█████████▍| 148/156 [00:51<00:02,  2.89it/s]Evaluating:  96%|█████████▌| 149/156 [00:51<00:02,  2.90it/s]Evaluating:  96%|█████████▌| 150/156 [00:52<00:02,  2.91it/s]Evaluating:  97%|█████████▋| 151/156 [00:52<00:01,  2.90it/s]Evaluating:  97%|█████████▋| 152/156 [00:52<00:01,  2.90it/s]Evaluating:  98%|█████████▊| 153/156 [00:53<00:01,  2.90it/s]Evaluating:  99%|█████████▊| 154/156 [00:53<00:00,  2.90it/s]Evaluating:  99%|█████████▉| 155/156 [00:53<00:00,  2.90it/s]Evaluating: 100%|██████████| 156/156 [00:54<00:00,  3.11it/s]Evaluating: 100%|██████████| 156/156 [00:54<00:00,  2.88it/s]
05/09/2022 09:19:44 - INFO - __main__ -     Evaluation done in total 54.168271 secs (0.043474 sec per example)
05/09/2022 09:20:24 - INFO - __main__ -   Results: {'exact': 45.96638655462185, 'f1': 55.269174336401186, 'total': 1190, 'HasAns_exact': 45.96638655462185, 'HasAns_f1': 55.269174336401186, 'HasAns_total': 1190, 'best_exact': 45.96638655462185, 'best_exact_thresh': 0.0, 'best_f1': 55.269174336401186, 'best_f1_thresh': 0.0}
  hi 
2022-05-09 09:20:28.133116: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0
05/09/2022 09:20:32 - WARNING - __main__ -   Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, 16-bits training: False
You are using a model of type xlm-roberta to instantiate a model of type xlm. This is not supported for all configurations of models and can yield errors.
Some weights of the model checkpoint at /cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//squad/xlm-KG_LR3e-5_EPOCH2.0_maxlen384_batchsize4_gradacc4 were not used when initializing XLMRobertaModel: ['base_model.encoder.layer.14.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.13.attention.self.query.weight', 'base_model.encoder.layer.19.attention.self.key.bias', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.18.output.dense.bias', 'base_model.encoder.layer.12.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.14.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.19.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.5.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.7.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.15.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.5.output.LayerNorm.weight', 'base_model.encoder.layer.7.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.17.attention.self.value.bias', 'base_model.encoder.layer.5.attention.output.LayerNorm.bias', 'base_model.encoder.layer.13.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.5.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.13.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.4.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.3.attention.output.LayerNorm.weight', 'base_model.encoder.layer.22.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.4.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.10.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.3.attention.self.query.weight', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.2.attention.output.LayerNorm.weight', 'base_model.encoder.layer.23.output.LayerNorm.bias', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.6.attention.output.LayerNorm.bias', 'base_model.encoder.layer.9.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.20.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.10.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.11.output.dense.weight', 'base_model.encoder.layer.1.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.3.attention.output.dense.weight', 'base_model.encoder.layer.1.attention.self.key.weight', 'base_model.encoder.layer.12.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.0.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.23.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.23.intermediate.dense.weight', 'base_model.encoder.layer.2.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.17.attention.output.LayerNorm.bias', 'base_model.encoder.layer.17.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.10.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.19.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.15.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.9.output.LayerNorm.bias', 'base_model.encoder.layer.21.attention.self.query.bias', 'base_model.encoder.layer.6.attention.self.value.bias', 'base_model.encoder.layer.15.output.LayerNorm.weight', 'base_model.encoder.layer.6.attention.self.value.weight', 'base_model.encoder.layer.17.attention.self.value.weight', 'base_model.encoder.layer.18.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.14.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.18.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.11.attention.self.value.weight', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.6.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.9.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.22.attention.output.dense.weight', 'base_model.encoder.layer.7.output.LayerNorm.bias', 'base_model.encoder.layer.20.attention.self.query.bias', 'base_model.encoder.layer.1.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.15.intermediate.dense.bias', 'base_model.encoder.layer.22.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.8.attention.self.value.bias', 'base_model.encoder.layer.19.intermediate.dense.weight', 'base_model.encoder.layer.19.attention.output.LayerNorm.bias', 'base_model.encoder.layer.5.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.13.attention.self.query.bias', 'base_model.encoder.layer.13.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.11.output.LayerNorm.bias', 'base_model.encoder.layer.17.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.23.intermediate.dense.bias', 'base_model.encoder.layer.10.output.dense.bias', 'base_model.encoder.layer.1.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.18.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.9.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.19.attention.self.query.bias', 'base_model.encoder.layer.20.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.9.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.12.attention.self.key.weight', 'base_model.encoder.layer.11.intermediate.dense.weight', 'base_model.encoder.layer.6.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.4.attention.output.dense.weight', 'base_model.encoder.layer.14.attention.self.key.bias', 'base_model.encoder.layer.22.attention.output.dense.bias', 'base_model.encoder.layer.10.attention.output.dense.bias', 'base_model.encoder.layer.22.attention.self.key.weight', 'base_model.encoder.layer.10.output.adapters.ts.adapter_up.weight', 'base_model.embeddings.token_type_embeddings.weight', 'base_model.encoder.layer.23.output.dense.weight', 'base_model.encoder.layer.10.output.LayerNorm.weight', 'base_model.encoder.layer.17.attention.output.dense.bias', 'base_model.encoder.layer.0.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.16.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.6.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.0.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.18.attention.output.LayerNorm.weight', 'base_model.encoder.layer.21.intermediate.dense.bias', 'base_model.encoder.layer.15.output.LayerNorm.bias', 'base_model.encoder.layer.17.output.LayerNorm.weight', 'base_model.encoder.layer.23.attention.self.query.bias', 'base_model.encoder.layer.6.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.10.intermediate.dense.bias', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.2.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.20.output.LayerNorm.weight', 'base_model.encoder.layer.4.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.4.attention.self.value.bias', 'base_model.encoder.layer.17.attention.self.key.bias', 'base_model.encoder.layer.0.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.19.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.22.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.0.intermediate.dense.bias', 'base_model.encoder.layer.4.attention.output.dense.bias', 'base_model.encoder.layer.20.attention.self.value.bias', 'base_model.encoder.layer.1.output.LayerNorm.weight', 'base_model.encoder.layer.5.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.14.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.16.intermediate.dense.bias', 'base_model.encoder.layer.15.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.0.output.LayerNorm.weight', 'base_model.encoder.layer.15.attention.self.query.bias', 'base_model.encoder.layer.20.output.LayerNorm.bias', 'base_model.encoder.layer.20.attention.output.dense.weight', 'base_model.encoder.layer.14.attention.output.LayerNorm.weight', 'base_model.encoder.layer.13.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.11.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.1.attention.output.dense.weight', 'base_model.encoder.layer.18.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.3.intermediate.dense.weight', 'base_model.encoder.layer.17.output.LayerNorm.bias', 'base_model.encoder.layer.6.attention.output.dense.weight', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.6.intermediate.dense.weight', 'base_model.encoder.layer.20.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.19.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.0.attention.output.dense.weight', 'base_model.encoder.layer.15.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.3.output.dense.bias', 'base_model.encoder.layer.4.attention.self.value.weight', 'base_model.encoder.layer.5.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.16.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.12.output.LayerNorm.weight', 'base_model.encoder.layer.12.attention.self.value.weight', 'base_model.encoder.layer.13.attention.self.key.weight', 'base_model.encoder.layer.5.intermediate.dense.bias', 'base_model.encoder.layer.5.attention.self.value.weight', 'base_model.encoder.layer.1.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.13.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.18.attention.self.value.weight', 'base_model.encoder.layer.14.output.LayerNorm.weight', 'base_model.encoder.layer.23.attention.output.dense.weight', 'base_model.encoder.layer.1.attention.self.query.weight', 'base_model.encoder.layer.21.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.17.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.3.attention.self.key.bias', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.15.attention.self.key.bias', 'base_model.encoder.layer.8.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.20.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.3.output.dense.weight', 'base_model.encoder.layer.20.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.22.output.LayerNorm.bias', 'base_model.encoder.layer.4.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.7.output.dense.bias', 'base_model.encoder.layer.8.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.7.attention.self.value.weight', 'base_model.encoder.layer.13.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.11.attention.self.value.bias', 'base_model.encoder.layer.15.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.5.attention.output.dense.bias', 'base_model.encoder.layer.16.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.0.output.LayerNorm.bias', 'base_model.encoder.layer.16.attention.output.LayerNorm.weight', 'base_model.encoder.layer.21.output.LayerNorm.bias', 'base_model.encoder.layer.13.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.22.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.3.output.LayerNorm.weight', 'base_model.encoder.layer.14.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.21.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.8.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.11.attention.output.dense.bias', 'base_model.encoder.layer.18.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.22.output.dense.weight', 'base_model.encoder.layer.13.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.3.attention.self.value.weight', 'base_model.encoder.layer.9.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.23.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.22.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.3.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.0.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.11.attention.self.key.bias', 'base_model.encoder.layer.4.output.LayerNorm.bias', 'base_model.encoder.layer.18.output.LayerNorm.bias', 'base_model.encoder.layer.7.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.5.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.21.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.12.attention.self.key.bias', 'base_model.encoder.layer.23.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.14.attention.self.value.bias', 'base_model.encoder.layer.11.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.14.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.1.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.23.attention.self.key.bias', 'base_model.encoder.layer.21.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.8.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.22.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.pooler.dense.bias', 'base_model.encoder.layer.17.intermediate.dense.weight', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.2.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.16.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.22.intermediate.dense.weight', 'base_model.encoder.layer.1.attention.self.value.weight', 'base_model.encoder.layer.3.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.11.output.dense.bias', 'base_model.encoder.layer.16.attention.self.query.weight', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.5.output.dense.bias', 'base_model.encoder.layer.8.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.15.attention.self.key.weight', 'base_model.encoder.layer.12.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.2.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.4.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.10.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.15.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.7.attention.self.key.weight', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.8.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.2.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.0.attention.output.LayerNorm.weight', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.19.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.10.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.4.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.1.intermediate.dense.bias', 'base_model.encoder.layer.16.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.22.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.0.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.11.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.23.attention.self.value.weight', 'base_model.encoder.layer.23.output.LayerNorm.weight', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.19.attention.self.value.weight', 'base_model.encoder.layer.20.output.dense.weight', 'base_model.encoder.layer.5.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.12.output.LayerNorm.bias', 'base_model.encoder.layer.9.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.9.intermediate.dense.bias', 'base_model.encoder.layer.21.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.6.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.16.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.9.attention.self.query.bias', 'base_model.encoder.layer.21.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.9.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.18.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.4.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.23.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.3.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.11.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.18.attention.self.value.bias', 'base_model.encoder.layer.16.output.adapters.tp.adapter_down.0.weight', 'base_model.embeddings.LayerNorm.weight', 'base_model.encoder.layer.21.attention.self.value.weight', 'base_model.encoder.layer.4.intermediate.dense.weight', 'base_model.encoder.layer.12.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.4.attention.output.LayerNorm.bias', 'base_model.encoder.layer.23.attention.output.LayerNorm.weight', 'base_model.encoder.layer.15.attention.output.dense.bias', 'base_model.encoder.layer.17.output.dense.bias', 'base_model.encoder.layer.19.attention.self.value.bias', 'base_model.encoder.layer.18.intermediate.dense.weight', 'base_model.encoder.layer.7.output.LayerNorm.weight', 'base_model.encoder.layer.4.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.6.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.1.attention.self.key.bias', 'base_model.encoder.layer.2.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.2.attention.output.dense.weight', 'base_model.encoder.layer.9.attention.output.dense.weight', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.9.attention.self.value.bias', 'base_model.encoder.layer.9.attention.self.key.weight', 'base_model.encoder.layer.0.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.19.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.10.attention.self.key.weight', 'base_model.encoder.layer.0.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.13.attention.self.value.weight', 'base_model.encoder.layer.4.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.5.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.6.output.LayerNorm.bias', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.5.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.17.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.3.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.0.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.12.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.9.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.8.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.17.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.11.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.18.attention.output.LayerNorm.bias', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.1.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.6.output.dense.bias', 'base_model.encoder.layer.22.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.11.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.11.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.14.output.dense.bias', 'base_model.encoder.layer.16.output.LayerNorm.weight', 'base_model.encoder.layer.15.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.7.attention.self.key.bias', 'base_model.encoder.layer.19.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.20.attention.output.LayerNorm.weight', 'base_model.encoder.layer.21.attention.self.query.weight', 'base_model.encoder.layer.18.output.LayerNorm.weight', 'base_model.encoder.layer.19.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.14.output.dense.weight', 'base_model.encoder.layer.9.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.15.attention.self.value.weight', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.1.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.9.attention.output.dense.bias', 'base_model.encoder.layer.1.intermediate.dense.weight', 'base_model.encoder.layer.1.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.11.intermediate.dense.bias', 'base_model.encoder.layer.17.attention.output.LayerNorm.weight', 'base_model.encoder.layer.20.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.1.attention.self.query.bias', 'base_model.encoder.layer.7.attention.self.query.bias', 'base_model.encoder.layer.1.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.0.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.9.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.0.intermediate.dense.weight', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.20.output.dense.bias', 'base_model.encoder.layer.12.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.23.attention.self.value.bias', 'base_model.encoder.layer.14.attention.self.key.weight', 'base_model.encoder.layer.8.output.adapters.es.adapter_down.0.weight', 'base_model.embeddings.word_embeddings.weight', 'base_model.encoder.layer.2.attention.self.value.bias', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.20.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.2.attention.self.value.weight', 'base_model.encoder.layer.13.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.6.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.14.attention.self.query.bias', 'base_model.encoder.layer.16.attention.self.value.bias', 'base_model.encoder.layer.19.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.13.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.3.attention.self.value.bias', 'base_model.encoder.layer.11.attention.output.dense.weight', 'base_model.encoder.layer.7.attention.output.LayerNorm.bias', 'base_model.encoder.layer.6.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.23.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.15.attention.self.query.weight', 'base_model.encoder.layer.15.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.2.output.dense.bias', 'base_model.encoder.layer.7.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.12.attention.self.value.bias', 'base_model.encoder.layer.13.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.17.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.15.attention.output.LayerNorm.weight', 'base_model.encoder.layer.11.attention.self.key.weight', 'base_model.encoder.layer.22.attention.self.value.bias', 'base_model.encoder.layer.12.intermediate.dense.bias', 'base_model.encoder.layer.20.attention.self.key.weight', 'base_model.encoder.layer.22.attention.self.query.bias', 'base_model.encoder.layer.15.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.2.output.LayerNorm.bias', 'base_model.encoder.layer.2.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.2.attention.output.LayerNorm.bias', 'base_model.encoder.layer.3.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.4.intermediate.dense.bias', 'base_model.encoder.layer.9.attention.output.LayerNorm.weight', 'base_model.encoder.layer.9.attention.self.value.weight', 'base_model.encoder.layer.7.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.2.attention.self.key.bias', 'base_model.encoder.layer.14.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.16.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.5.intermediate.dense.weight', 'base_model.encoder.layer.16.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.18.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.11.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.10.output.dense.weight', 'base_model.encoder.layer.20.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.13.intermediate.dense.weight', 'base_model.encoder.layer.16.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.7.output.dense.weight', 'base_model.encoder.layer.0.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.9.attention.self.key.bias', 'base_model.encoder.layer.5.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.10.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.4.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.20.attention.self.value.weight', 'base_model.encoder.layer.16.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.8.output.dense.weight', 'base_model.encoder.layer.3.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.9.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.18.intermediate.dense.bias', 'base_model.encoder.layer.23.attention.self.key.weight', 'base_model.encoder.layer.16.attention.self.value.weight', 'base_model.encoder.layer.8.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.2.attention.self.query.weight', 'base_model.encoder.layer.5.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.4.attention.self.query.weight', 'base_model.encoder.layer.21.attention.self.key.bias', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.0.attention.output.dense.bias', 'base_model.encoder.layer.14.output.adapters.tp.adapter_down.0.bias', 'base_model.embeddings.position_ids', 'base_model.encoder.layer.2.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.6.output.LayerNorm.weight', 'base_model.encoder.layer.15.attention.self.value.bias', 'base_model.encoder.layer.7.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.11.attention.self.query.bias', 'base_model.encoder.layer.17.output.dense.weight', 'base_model.encoder.layer.21.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.8.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.23.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.14.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.10.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.10.attention.output.LayerNorm.bias', 'base_model.encoder.layer.18.attention.self.query.bias', 'qa_outputs.bias', 'base_model.encoder.layer.0.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.7.attention.output.dense.weight', 'base_model.encoder.layer.0.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.10.attention.self.value.weight', 'base_model.encoder.layer.23.output.dense.bias', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.18.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.20.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.8.attention.self.key.bias', 'base_model.encoder.layer.18.attention.output.dense.bias', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.embeddings.LayerNorm.bias', 'base_model.encoder.layer.19.attention.self.query.weight', 'base_model.encoder.layer.3.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.17.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.18.attention.output.dense.weight', 'base_model.encoder.layer.12.attention.output.dense.bias', 'base_model.encoder.layer.5.output.dense.weight', 'base_model.encoder.layer.11.attention.output.LayerNorm.weight', 'base_model.encoder.layer.19.output.LayerNorm.bias', 'base_model.encoder.layer.4.attention.self.key.weight', 'base_model.encoder.layer.19.attention.self.key.weight', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.20.intermediate.dense.weight', 'base_model.encoder.layer.13.attention.self.value.bias', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.15.output.dense.bias', 'base_model.encoder.layer.8.output.dense.bias', 'base_model.encoder.layer.2.attention.output.dense.bias', 'base_model.encoder.layer.15.attention.output.LayerNorm.bias', 'base_model.encoder.layer.4.attention.output.LayerNorm.weight', 'base_model.encoder.layer.10.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.9.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.6.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.19.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.14.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.20.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.21.output.dense.bias', 'base_model.encoder.layer.22.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.0.attention.output.LayerNorm.bias', 'base_model.encoder.layer.3.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.21.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.7.attention.output.dense.bias', 'base_model.encoder.layer.23.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.22.intermediate.dense.bias', 'base_model.encoder.layer.5.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.6.attention.self.query.bias', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.18.output.adapters.tp.adapter_up.bias', 'base_model.embeddings.position_embeddings.weight', 'base_model.encoder.layer.0.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.9.output.LayerNorm.weight', 'base_model.encoder.layer.21.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.11.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.13.output.LayerNorm.bias', 'base_model.encoder.layer.16.output.dense.weight', 'base_model.encoder.layer.6.attention.output.LayerNorm.weight', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.4.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.5.attention.self.key.bias', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.10.output.LayerNorm.bias', 'base_model.encoder.layer.7.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.6.attention.self.key.bias', 'base_model.encoder.layer.21.attention.output.LayerNorm.bias', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.12.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.9.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.10.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.12.attention.output.LayerNorm.bias', 'base_model.encoder.layer.22.attention.self.query.weight', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.12.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.4.output.dense.weight', 'base_model.encoder.layer.12.output.dense.bias', 'base_model.encoder.layer.10.intermediate.dense.weight', 'base_model.encoder.layer.19.attention.output.dense.weight', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.3.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.6.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.8.attention.self.query.bias', 'base_model.encoder.layer.16.output.dense.bias', 'base_model.encoder.layer.22.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.9.intermediate.dense.weight', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.2.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.8.attention.output.dense.weight', 'base_model.encoder.layer.2.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.23.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.23.attention.output.LayerNorm.bias', 'base_model.encoder.layer.5.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.18.attention.self.key.weight', 'base_model.encoder.layer.3.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.11.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.14.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.23.attention.output.dense.bias', 'base_model.encoder.layer.6.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.12.attention.self.query.weight', 'base_model.encoder.layer.22.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.10.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.2.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.12.attention.output.LayerNorm.weight', 'base_model.encoder.layer.1.attention.output.LayerNorm.bias', 'base_model.encoder.layer.19.attention.output.dense.bias', 'base_model.encoder.layer.7.intermediate.dense.bias', 'base_model.encoder.layer.3.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.4.attention.self.key.bias', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.23.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.12.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.11.output.LayerNorm.weight', 'base_model.encoder.layer.16.attention.self.key.weight', 'base_model.encoder.layer.15.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.13.output.dense.weight', 'base_model.encoder.layer.15.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.7.intermediate.dense.weight', 'base_model.encoder.layer.7.attention.self.value.bias', 'base_model.encoder.layer.19.intermediate.dense.bias', 'base_model.encoder.layer.21.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.8.attention.output.LayerNorm.weight', 'base_model.encoder.layer.9.attention.self.query.weight', 'base_model.encoder.layer.14.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.2.attention.self.query.bias', 'base_model.encoder.layer.1.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.10.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.13.intermediate.dense.bias', 'base_model.encoder.layer.21.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.14.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.1.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.10.attention.self.query.weight', 'base_model.encoder.layer.19.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.18.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.21.output.LayerNorm.weight', 'base_model.encoder.layer.13.attention.output.LayerNorm.weight', 'base_model.encoder.layer.10.attention.output.LayerNorm.weight', 'base_model.encoder.layer.12.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.21.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.2.intermediate.dense.weight', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.21.attention.output.dense.bias', 'base_model.encoder.layer.2.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.23.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.4.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.16.attention.self.key.bias', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.19.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.13.attention.output.LayerNorm.bias', 'base_model.encoder.layer.5.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.2.intermediate.dense.bias', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.16.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.16.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.20.attention.output.dense.bias', 'base_model.encoder.layer.23.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.10.attention.self.query.bias', 'qa_outputs.weight', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.6.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.2.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.6.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.21.attention.self.value.bias', 'base_model.encoder.layer.20.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.10.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.20.intermediate.dense.bias', 'base_model.encoder.layer.0.output.dense.weight', 'base_model.encoder.layer.1.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.12.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.7.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.17.intermediate.dense.bias', 'base_model.encoder.layer.4.output.LayerNorm.weight', 'base_model.encoder.layer.17.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.8.attention.output.dense.bias', 'base_model.encoder.layer.14.intermediate.dense.weight', 'base_model.encoder.layer.15.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.16.attention.output.dense.weight', 'base_model.encoder.layer.16.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.22.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.23.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.23.attention.self.query.weight', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.6.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.11.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.21.attention.output.dense.weight', 'base_model.encoder.layer.14.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.22.output.dense.bias', 'base_model.encoder.layer.1.attention.output.dense.bias', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.18.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.1.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.3.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.20.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.9.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.2.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.2.attention.self.key.weight', 'base_model.encoder.layer.13.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.16.output.LayerNorm.bias', 'base_model.encoder.layer.11.attention.output.LayerNorm.bias', 'base_model.encoder.layer.23.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.1.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.8.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.4.attention.self.query.bias', 'base_model.encoder.layer.1.output.dense.weight', 'base_model.encoder.layer.16.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.9.output.dense.bias', 'base_model.encoder.layer.19.output.dense.weight', 'base_model.encoder.layer.2.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.12.intermediate.dense.weight', 'base_model.encoder.layer.7.attention.self.query.weight', 'base_model.encoder.layer.3.output.LayerNorm.bias', 'base_model.encoder.layer.14.intermediate.dense.bias', 'base_model.encoder.layer.12.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.14.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.22.attention.output.LayerNorm.bias', 'base_model.encoder.layer.3.intermediate.dense.bias', 'base_model.encoder.layer.17.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.8.attention.output.LayerNorm.bias', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.18.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.1.output.dense.bias', 'base_model.encoder.layer.12.output.dense.weight', 'base_model.encoder.layer.4.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.19.output.LayerNorm.weight', 'base_model.encoder.layer.5.attention.self.query.weight', 'base_model.encoder.layer.20.attention.self.key.bias', 'base_model.encoder.layer.6.output.dense.weight', 'base_model.encoder.layer.8.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.17.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.1.attention.output.LayerNorm.weight', 'base_model.encoder.layer.0.attention.self.key.bias', 'base_model.encoder.layer.14.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.21.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.3.attention.self.key.weight', 'base_model.encoder.layer.12.attention.output.dense.weight', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.16.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.20.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.0.attention.self.value.weight', 'base_model.encoder.layer.0.attention.self.query.weight', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.10.attention.self.value.bias', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.20.attention.self.query.weight', 'base_model.encoder.layer.18.attention.self.key.bias', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.19.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.9.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.14.attention.self.query.weight', 'base_model.encoder.layer.21.intermediate.dense.weight', 'base_model.encoder.layer.11.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.14.attention.self.value.weight', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.17.attention.self.query.bias', 'base_model.encoder.layer.5.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.18.attention.self.query.weight', 'base_model.encoder.layer.0.output.dense.bias', 'base_model.encoder.layer.8.intermediate.dense.bias', 'base_model.encoder.layer.13.output.LayerNorm.weight', 'base_model.encoder.layer.0.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.23.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.4.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.21.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.11.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.22.output.LayerNorm.weight', 'base_model.encoder.layer.12.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.8.intermediate.dense.weight', 'base_model.encoder.layer.6.attention.self.query.weight', 'base_model.encoder.layer.8.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.16.intermediate.dense.weight', 'base_model.encoder.layer.7.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.14.output.LayerNorm.bias', 'base_model.encoder.layer.19.attention.output.LayerNorm.weight', 'base_model.encoder.layer.5.attention.self.key.weight', 'base_model.encoder.layer.13.output.dense.bias', 'base_model.encoder.layer.19.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.6.attention.self.key.weight', 'base_model.encoder.layer.10.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.2.output.dense.weight', 'base_model.encoder.layer.8.output.LayerNorm.weight', 'base_model.encoder.layer.1.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.13.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.13.attention.self.key.bias', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.14.attention.output.LayerNorm.bias', 'base_model.encoder.layer.5.attention.self.value.bias', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.10.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.17.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.22.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.0.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.18.output.dense.weight', 'base_model.encoder.layer.3.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.17.attention.self.query.weight', 'base_model.encoder.layer.3.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.7.attention.output.LayerNorm.weight', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.18.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.10.attention.self.key.bias', 'base_model.encoder.layer.20.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.13.attention.output.dense.weight', 'base_model.encoder.layer.13.attention.output.dense.bias', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.13.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.7.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.5.attention.output.dense.weight', 'base_model.encoder.layer.12.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.8.output.LayerNorm.bias', 'base_model.encoder.layer.8.attention.self.key.weight', 'base_model.encoder.layer.15.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.3.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.8.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.17.attention.self.key.weight', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.22.attention.self.key.bias', 'base_model.encoder.layer.8.attention.self.value.weight', 'base_model.encoder.layer.17.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.11.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.17.attention.output.dense.weight', 'base_model.encoder.layer.21.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.21.output.dense.weight', 'base_model.encoder.layer.0.attention.self.query.bias', 'base_model.encoder.layer.12.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.0.attention.self.value.bias', 'base_model.encoder.layer.3.attention.output.LayerNorm.bias', 'base_model.encoder.layer.5.attention.output.LayerNorm.weight', 'base_model.encoder.layer.6.attention.output.dense.bias', 'base_model.encoder.layer.23.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.20.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.7.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.2.output.LayerNorm.weight', 'base_model.encoder.layer.12.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.22.attention.output.LayerNorm.weight', 'base_model.encoder.layer.6.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.7.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.5.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.22.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.4.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.17.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.10.attention.output.dense.weight', 'base_model.encoder.layer.5.attention.self.query.bias', 'base_model.encoder.layer.19.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.16.attention.output.dense.bias', 'base_model.encoder.layer.11.attention.self.query.weight', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.9.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.11.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.15.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.1.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.3.attention.self.query.bias', 'base_model.encoder.layer.5.output.LayerNorm.bias', 'base_model.encoder.layer.9.attention.output.LayerNorm.bias', 'base_model.encoder.layer.11.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.22.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.6.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.14.attention.output.dense.weight', 'base_model.encoder.layer.8.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.6.intermediate.dense.bias', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.22.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.17.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.23.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.4.output.dense.bias', 'base_model.encoder.layer.3.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.8.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.7.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.10.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.7.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.2.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.13.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.16.attention.self.query.bias', 'base_model.encoder.layer.1.output.LayerNorm.bias', 'base_model.encoder.layer.15.attention.output.dense.weight', 'base_model.encoder.layer.7.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.17.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.1.attention.self.value.bias', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.17.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.20.attention.output.LayerNorm.bias', 'base_model.encoder.layer.9.output.dense.weight', 'base_model.encoder.layer.15.intermediate.dense.weight', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.16.attention.output.LayerNorm.bias', 'base_model.encoder.layer.14.attention.output.dense.bias', 'base_model.encoder.layer.15.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.20.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.19.output.dense.bias', 'base_model.encoder.layer.21.attention.self.key.weight', 'base_model.encoder.layer.22.attention.self.value.weight', 'base_model.encoder.layer.13.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.21.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.3.attention.output.dense.bias', 'base_model.encoder.layer.4.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.12.attention.self.query.bias', 'base_model.encoder.layer.21.attention.output.LayerNorm.weight', 'base_model.encoder.layer.15.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.0.attention.self.key.weight', 'base_model.encoder.layer.18.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.18.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.18.output.adapters.es.adapter_down.0.weight', 'base_model.pooler.dense.weight', 'base_model.encoder.layer.7.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.15.output.dense.weight', 'base_model.encoder.layer.8.attention.self.query.weight', 'base_model.encoder.layer.19.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.query.bias']
- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of XLMRobertaModel were not initialized from the model checkpoint at /cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//squad/xlm-KG_LR3e-5_EPOCH2.0_maxlen384_batchsize4_gradacc4 and are newly initialized: ['encoder.layer.13.attention.self.key.weight', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.4.attention.self.query.bias', 'encoder.layer.1.attention.output.LayerNorm.weight', 'encoder.layer.2.attention.self.query.bias', 'encoder.layer.14.attention.self.value.weight', 'encoder.layer.18.attention.self.query.bias', 'encoder.layer.13.intermediate.dense.bias', 'encoder.layer.21.output.LayerNorm.bias', 'encoder.layer.15.intermediate.dense.weight', 'encoder.layer.23.output.LayerNorm.bias', 'encoder.layer.17.output.dense.weight', 'encoder.layer.7.attention.output.LayerNorm.bias', 'encoder.layer.16.intermediate.dense.bias', 'encoder.layer.2.attention.output.dense.weight', 'encoder.layer.6.attention.self.value.weight', 'encoder.layer.17.attention.self.value.bias', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.16.attention.output.dense.bias', 'encoder.layer.3.attention.self.value.bias', 'encoder.layer.0.attention.output.LayerNorm.weight', 'encoder.layer.19.output.dense.weight', 'encoder.layer.21.attention.output.LayerNorm.weight', 'encoder.layer.6.attention.self.key.bias', 'encoder.layer.9.output.LayerNorm.bias', 'encoder.layer.21.attention.self.query.weight', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.6.output.dense.bias', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.19.attention.output.LayerNorm.bias', 'encoder.layer.8.attention.output.LayerNorm.bias', 'encoder.layer.20.output.LayerNorm.weight', 'encoder.layer.16.attention.self.query.weight', 'encoder.layer.4.attention.output.LayerNorm.weight', 'encoder.layer.19.attention.self.value.weight', 'encoder.layer.14.output.LayerNorm.bias', 'encoder.layer.14.intermediate.dense.bias', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.7.attention.self.query.weight', 'encoder.layer.17.intermediate.dense.weight', 'encoder.layer.12.attention.output.LayerNorm.bias', 'encoder.layer.11.output.LayerNorm.weight', 'encoder.layer.12.attention.output.dense.weight', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.15.attention.self.value.bias', 'encoder.layer.20.attention.self.query.weight', 'encoder.layer.20.intermediate.dense.weight', 'encoder.layer.12.output.dense.bias', 'encoder.layer.17.attention.output.dense.bias', 'encoder.layer.5.output.dense.bias', 'encoder.layer.9.attention.output.dense.bias', 'encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.layer.18.attention.output.dense.weight', 'encoder.layer.8.output.dense.bias', 'encoder.layer.0.output.dense.bias', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.14.attention.output.LayerNorm.weight', 'encoder.layer.6.attention.output.dense.bias', 'encoder.layer.9.attention.output.dense.weight', 'encoder.layer.2.attention.self.value.weight', 'encoder.layer.21.intermediate.dense.weight', 'encoder.layer.1.output.dense.weight', 'encoder.layer.4.attention.output.LayerNorm.bias', 'encoder.layer.21.attention.self.key.weight', 'encoder.layer.6.attention.self.query.bias', 'encoder.layer.15.attention.self.value.weight', 'encoder.layer.2.attention.self.value.bias', 'encoder.layer.7.attention.self.key.bias', 'encoder.layer.11.attention.output.dense.bias', 'encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.layer.11.output.LayerNorm.bias', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.7.attention.output.dense.weight', 'encoder.layer.3.attention.output.dense.bias', 'encoder.layer.12.output.dense.weight', 'encoder.layer.7.output.dense.bias', 'encoder.layer.5.attention.output.dense.bias', 'encoder.layer.15.output.LayerNorm.bias', 'embeddings.token_type_embeddings.weight', 'encoder.layer.7.attention.self.value.weight', 'encoder.layer.18.output.LayerNorm.bias', 'encoder.layer.23.attention.output.LayerNorm.weight', 'encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.layer.2.attention.output.LayerNorm.bias', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.21.output.dense.weight', 'encoder.layer.7.attention.output.dense.bias', 'encoder.layer.23.attention.output.dense.bias', 'encoder.layer.23.attention.self.key.bias', 'embeddings.word_embeddings.weight', 'encoder.layer.21.attention.output.dense.weight', 'encoder.layer.9.output.LayerNorm.weight', 'encoder.layer.13.attention.output.dense.bias', 'encoder.layer.22.intermediate.dense.weight', 'encoder.layer.18.attention.output.LayerNorm.bias', 'encoder.layer.8.output.dense.weight', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.7.output.dense.weight', 'encoder.layer.20.output.LayerNorm.bias', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.16.attention.output.dense.weight', 'encoder.layer.5.attention.output.LayerNorm.weight', 'encoder.layer.22.attention.output.LayerNorm.weight', 'encoder.layer.21.attention.self.value.weight', 'embeddings.position_embeddings.weight', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.10.attention.self.key.weight', 'encoder.layer.18.attention.output.LayerNorm.weight', 'encoder.layer.15.output.LayerNorm.weight', 'pooler.dense.bias', 'encoder.layer.18.attention.self.key.bias', 'encoder.layer.8.attention.self.query.weight', 'encoder.layer.7.output.LayerNorm.bias', 'encoder.layer.19.attention.output.dense.bias', 'encoder.layer.23.output.LayerNorm.weight', 'encoder.layer.18.output.dense.weight', 'encoder.layer.18.intermediate.dense.bias', 'encoder.layer.17.output.dense.bias', 'encoder.layer.12.output.LayerNorm.weight', 'encoder.layer.19.attention.self.query.bias', 'encoder.layer.14.attention.self.key.weight', 'encoder.layer.10.intermediate.dense.weight', 'encoder.layer.1.attention.output.dense.bias', 'encoder.layer.16.output.dense.weight', 'encoder.layer.2.attention.output.dense.bias', 'encoder.layer.8.attention.self.query.bias', 'encoder.layer.22.attention.self.query.bias', 'encoder.layer.7.attention.self.value.bias', 'encoder.layer.4.attention.self.key.weight', 'encoder.layer.14.attention.output.dense.bias', 'encoder.layer.19.attention.self.value.bias', 'encoder.layer.1.attention.self.key.bias', 'encoder.layer.7.attention.self.key.weight', 'encoder.layer.10.attention.self.value.weight', 'encoder.layer.12.intermediate.dense.weight', 'encoder.layer.5.attention.self.key.bias', 'encoder.layer.9.attention.self.key.bias', 'encoder.layer.8.attention.output.dense.bias', 'encoder.layer.17.attention.output.LayerNorm.weight', 'encoder.layer.4.attention.self.value.weight', 'encoder.layer.12.attention.output.dense.bias', 'encoder.layer.0.attention.self.value.weight', 'encoder.layer.6.output.LayerNorm.bias', 'encoder.layer.10.attention.self.key.bias', 'encoder.layer.23.intermediate.dense.weight', 'encoder.layer.13.attention.self.value.weight', 'encoder.layer.14.output.dense.bias', 'encoder.layer.12.attention.self.value.weight', 'encoder.layer.20.attention.self.query.bias', 'encoder.layer.14.attention.self.key.bias', 'encoder.layer.19.output.LayerNorm.weight', 'encoder.layer.19.attention.self.key.weight', 'encoder.layer.2.attention.output.LayerNorm.weight', 'encoder.layer.5.attention.self.key.weight', 'encoder.layer.16.attention.self.value.weight', 'encoder.layer.16.attention.self.key.weight', 'encoder.layer.1.attention.self.key.weight', 'encoder.layer.22.output.dense.bias', 'encoder.layer.15.output.dense.bias', 'encoder.layer.23.attention.self.key.weight', 'encoder.layer.21.output.dense.bias', 'encoder.layer.11.output.dense.weight', 'encoder.layer.4.attention.self.query.weight', 'encoder.layer.13.attention.output.dense.weight', 'encoder.layer.22.intermediate.dense.bias', 'encoder.layer.3.attention.output.dense.weight', 'encoder.layer.12.attention.self.key.weight', 'encoder.layer.6.attention.self.value.bias', 'encoder.layer.7.attention.output.LayerNorm.weight', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.13.attention.self.value.bias', 'encoder.layer.5.attention.self.value.weight', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.11.attention.self.query.bias', 'encoder.layer.10.output.dense.weight', 'encoder.layer.4.attention.output.dense.weight', 'encoder.layer.23.intermediate.dense.bias', 'encoder.layer.9.attention.self.query.bias', 'encoder.layer.16.output.dense.bias', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.23.attention.self.value.weight', 'encoder.layer.16.intermediate.dense.weight', 'encoder.layer.4.output.dense.weight', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.9.attention.output.LayerNorm.weight', 'encoder.layer.9.attention.self.key.weight', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.18.attention.self.key.weight', 'encoder.layer.18.attention.self.value.bias', 'encoder.layer.4.attention.output.dense.bias', 'embeddings.LayerNorm.bias', 'pooler.dense.weight', 'encoder.layer.6.attention.self.query.weight', 'encoder.layer.0.attention.self.key.bias', 'encoder.layer.20.attention.self.value.weight', 'encoder.layer.16.attention.output.LayerNorm.weight', 'encoder.layer.17.attention.self.key.bias', 'encoder.layer.17.attention.self.value.weight', 'encoder.layer.6.output.dense.weight', 'encoder.layer.21.intermediate.dense.bias', 'encoder.layer.13.attention.self.key.bias', 'encoder.layer.9.attention.self.query.weight', 'encoder.layer.19.attention.self.key.bias', 'encoder.layer.18.attention.output.dense.bias', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.11.attention.output.dense.weight', 'encoder.layer.17.intermediate.dense.bias', 'encoder.layer.7.intermediate.dense.bias', 'encoder.layer.1.attention.self.query.bias', 'encoder.layer.9.output.dense.weight', 'encoder.layer.16.output.LayerNorm.bias', 'encoder.layer.0.attention.self.query.bias', 'encoder.layer.8.attention.self.value.weight', 'encoder.layer.16.output.LayerNorm.weight', 'encoder.layer.15.intermediate.dense.bias', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.19.intermediate.dense.weight', 'encoder.layer.10.attention.output.LayerNorm.weight', 'encoder.layer.19.attention.output.LayerNorm.weight', 'encoder.layer.8.attention.self.key.bias', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.4.attention.self.key.bias', 'encoder.layer.0.attention.self.key.weight', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.16.attention.self.query.bias', 'encoder.layer.8.attention.output.dense.weight', 'encoder.layer.12.attention.self.key.bias', 'encoder.layer.18.output.LayerNorm.weight', 'encoder.layer.21.attention.self.query.bias', 'encoder.layer.0.attention.output.dense.bias', 'encoder.layer.22.attention.self.value.bias', 'encoder.layer.1.attention.self.value.weight', 'encoder.layer.19.attention.self.query.weight', 'encoder.layer.17.attention.output.dense.weight', 'encoder.layer.2.output.dense.weight', 'encoder.layer.11.attention.self.query.weight', 'encoder.layer.18.output.dense.bias', 'encoder.layer.20.output.dense.weight', 'encoder.layer.20.intermediate.dense.bias', 'encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.layer.1.output.dense.bias', 'encoder.layer.3.attention.self.query.bias', 'encoder.layer.23.attention.self.query.bias', 'encoder.layer.15.attention.self.key.weight', 'encoder.layer.1.attention.self.query.weight', 'encoder.layer.5.output.LayerNorm.bias', 'encoder.layer.3.output.dense.bias', 'encoder.layer.23.attention.output.dense.weight', 'encoder.layer.20.attention.output.dense.weight', 'encoder.layer.21.attention.self.value.bias', 'encoder.layer.23.attention.output.LayerNorm.bias', 'encoder.layer.14.output.dense.weight', 'encoder.layer.20.attention.output.dense.bias', 'encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.3.attention.self.key.bias', 'encoder.layer.20.attention.output.LayerNorm.weight', 'encoder.layer.10.attention.output.dense.weight', 'encoder.layer.10.attention.self.query.weight', 'encoder.layer.15.output.dense.weight', 'encoder.layer.16.attention.self.value.bias', 'encoder.layer.10.attention.output.LayerNorm.bias', 'encoder.layer.8.output.LayerNorm.weight', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.0.attention.output.dense.weight', 'encoder.layer.20.attention.self.value.bias', 'encoder.layer.9.attention.self.value.bias', 'encoder.layer.13.output.dense.weight', 'encoder.layer.14.output.LayerNorm.weight', 'encoder.layer.22.attention.output.dense.bias', 'encoder.layer.13.attention.output.LayerNorm.bias', 'encoder.layer.22.attention.self.value.weight', 'encoder.layer.10.output.LayerNorm.weight', 'encoder.layer.9.attention.output.LayerNorm.bias', 'encoder.layer.8.output.LayerNorm.bias', 'encoder.layer.20.output.dense.bias', 'encoder.layer.14.attention.output.dense.weight', 'encoder.layer.17.attention.self.query.bias', 'encoder.layer.8.attention.output.LayerNorm.weight', 'encoder.layer.22.output.LayerNorm.bias', 'encoder.layer.10.output.dense.bias', 'encoder.layer.22.output.dense.weight', 'encoder.layer.3.attention.self.value.weight', 'encoder.layer.9.output.dense.bias', 'encoder.layer.2.output.dense.bias', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.22.attention.self.query.weight', 'encoder.layer.21.attention.output.dense.bias', 'encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.layer.14.attention.self.value.bias', 'encoder.layer.15.attention.self.key.bias', 'encoder.layer.17.output.LayerNorm.bias', 'encoder.layer.5.attention.self.value.bias', 'encoder.layer.12.attention.self.query.bias', 'encoder.layer.19.output.LayerNorm.bias', 'encoder.layer.6.attention.output.LayerNorm.weight', 'encoder.layer.10.attention.self.query.bias', 'encoder.layer.4.attention.self.value.bias', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.13.output.LayerNorm.weight', 'encoder.layer.3.attention.self.query.weight', 'encoder.layer.19.intermediate.dense.bias', 'encoder.layer.17.attention.output.LayerNorm.bias', 'encoder.layer.13.attention.output.LayerNorm.weight', 'encoder.layer.14.attention.self.query.weight', 'encoder.layer.23.attention.self.query.weight', 'encoder.layer.13.intermediate.dense.weight', 'encoder.layer.17.attention.self.key.weight', 'encoder.layer.15.attention.output.LayerNorm.weight', 'encoder.layer.22.attention.output.dense.weight', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.20.attention.self.key.bias', 'encoder.layer.20.attention.output.LayerNorm.bias', 'encoder.layer.19.attention.output.dense.weight', 'encoder.layer.8.attention.self.value.bias', 'encoder.layer.9.attention.self.value.weight', 'encoder.layer.14.attention.self.query.bias', 'encoder.layer.23.attention.self.value.bias', 'encoder.layer.2.attention.self.key.bias', 'encoder.layer.3.output.dense.weight', 'encoder.layer.8.attention.self.key.weight', 'encoder.layer.11.attention.self.key.bias', 'encoder.layer.12.attention.output.LayerNorm.weight', 'encoder.layer.19.output.dense.bias', 'encoder.layer.0.attention.self.value.bias', 'encoder.layer.0.output.dense.weight', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.10.output.LayerNorm.bias', 'encoder.layer.15.attention.self.query.weight', 'encoder.layer.12.output.LayerNorm.bias', 'encoder.layer.13.attention.self.query.weight', 'encoder.layer.6.attention.self.key.weight', 'encoder.layer.6.attention.output.dense.weight', 'encoder.layer.0.attention.self.query.weight', 'encoder.layer.10.attention.self.value.bias', 'encoder.layer.11.attention.self.value.bias', 'encoder.layer.15.attention.output.dense.bias', 'encoder.layer.22.attention.self.key.weight', 'encoder.layer.5.attention.self.query.weight', 'encoder.layer.17.output.LayerNorm.weight', 'encoder.layer.14.attention.output.LayerNorm.bias', 'encoder.layer.11.attention.self.key.weight', 'encoder.layer.23.output.dense.bias', 'encoder.layer.6.attention.output.LayerNorm.bias', 'encoder.layer.12.attention.self.value.bias', 'encoder.layer.16.attention.self.key.bias', 'encoder.layer.7.attention.self.query.bias', 'encoder.layer.20.attention.self.key.weight', 'encoder.layer.10.attention.output.dense.bias', 'encoder.layer.15.attention.self.query.bias', 'encoder.layer.21.attention.self.key.bias', 'encoder.layer.13.output.dense.bias', 'encoder.layer.11.attention.output.LayerNorm.weight', 'encoder.layer.5.attention.output.dense.weight', 'encoder.layer.13.attention.self.query.bias', 'encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.1.attention.self.value.bias', 'encoder.layer.1.attention.output.dense.weight', 'encoder.layer.15.attention.output.dense.weight', 'encoder.layer.22.attention.output.LayerNorm.bias', 'encoder.layer.12.intermediate.dense.bias', 'encoder.layer.17.attention.self.query.weight', 'encoder.layer.5.output.dense.weight', 'encoder.layer.18.attention.self.value.weight', 'encoder.layer.23.output.dense.weight', 'encoder.layer.18.intermediate.dense.weight', 'encoder.layer.16.attention.output.LayerNorm.bias', 'embeddings.LayerNorm.weight', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.11.output.dense.bias', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.13.output.LayerNorm.bias', 'encoder.layer.15.attention.output.LayerNorm.bias', 'encoder.layer.11.attention.self.value.weight', 'encoder.layer.2.attention.self.query.weight', 'encoder.layer.7.output.LayerNorm.weight', 'encoder.layer.22.attention.self.key.bias', 'encoder.layer.3.attention.self.key.weight', 'encoder.layer.2.attention.self.key.weight', 'encoder.layer.21.output.LayerNorm.weight', 'encoder.layer.12.attention.self.query.weight', 'encoder.layer.5.attention.self.query.bias', 'encoder.layer.22.output.LayerNorm.weight', 'encoder.layer.18.attention.self.query.weight', 'encoder.layer.21.attention.output.LayerNorm.bias', 'encoder.layer.14.intermediate.dense.weight', 'encoder.layer.4.output.dense.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Overwriting existing adapter 'ep'.
Overwriting existing adapter 'tp'.
Overwriting existing adapter 'es'.
Overwriting existing adapter 'ts'.
Overwriting existing adapter fusion module 'ep,tp,es,ts'
05/09/2022 09:20:58 - INFO - __main__ -   lang2id = None
05/09/2022 09:21:03 - INFO - __main__ -   Training/evaluation parameters Namespace(adam_epsilon=1e-08, cache_dir='', config_name='', data_dir=None, device=device(type='cuda'), do_eval=True, do_lower_case=False, do_train=False, doc_stride=128, eval_all_checkpoints=False, eval_lang='hi', evaluate_during_training=False, fp16=False, fp16_opt_level='O1', gradient_accumulation_steps=1, learning_rate=5e-05, local_rank=-1, logging_steps=50, max_answer_length=30, max_grad_norm=1.0, max_query_length=64, max_seq_length=384, max_steps=-1, model_name='xlm-KG', model_name_or_path='/cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//squad/xlm-KG_LR3e-5_EPOCH2.0_maxlen384_batchsize4_gradacc4', model_type='xlm', modelkg_dir='/cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/adapter/xlmr_adapter', n_best_size=20, n_gpu=1, no_cuda=False, null_score_diff_threshold=0.0, num_train_epochs=3.0, output_dir='/cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//squad/xlm-KG_LR3e-5_EPOCH2.0_maxlen384_batchsize4_gradacc4/predictions/xquad/', overwrite_cache=False, overwrite_output_dir=False, per_gpu_eval_batch_size=8, per_gpu_train_batch_size=8, predict_file='/cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/download//xquad//xquad.hi.json', save_steps=50, seed=42, server_ip='', server_port='', threads=1, tokenizer_name='', train_file=None, train_lang='en', verbose_logging=False, version_2_with_negative=False, warmup_steps=0, weight_decay=0.0)
05/09/2022 09:21:03 - INFO - __main__ -   Loading checkpoint /cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//squad/xlm-KG_LR3e-5_EPOCH2.0_maxlen384_batchsize4_gradacc4 for evaluation
05/09/2022 09:21:03 - INFO - __main__ -   Evaluate the following checkpoints: ['/cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//squad/xlm-KG_LR3e-5_EPOCH2.0_maxlen384_batchsize4_gradacc4']
Some weights of the model checkpoint at /cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//squad/xlm-KG_LR3e-5_EPOCH2.0_maxlen384_batchsize4_gradacc4 were not used when initializing XLMRobertaModel: ['base_model.encoder.layer.14.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.13.attention.self.query.weight', 'base_model.encoder.layer.19.attention.self.key.bias', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.18.output.dense.bias', 'base_model.encoder.layer.12.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.14.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.19.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.5.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.7.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.15.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.5.output.LayerNorm.weight', 'base_model.encoder.layer.7.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.17.attention.self.value.bias', 'base_model.encoder.layer.5.attention.output.LayerNorm.bias', 'base_model.encoder.layer.13.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.5.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.13.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.4.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.3.attention.output.LayerNorm.weight', 'base_model.encoder.layer.22.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.4.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.10.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.3.attention.self.query.weight', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.2.attention.output.LayerNorm.weight', 'base_model.encoder.layer.23.output.LayerNorm.bias', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.6.attention.output.LayerNorm.bias', 'base_model.encoder.layer.9.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.20.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.10.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.11.output.dense.weight', 'base_model.encoder.layer.1.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.3.attention.output.dense.weight', 'base_model.encoder.layer.1.attention.self.key.weight', 'base_model.encoder.layer.12.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.0.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.23.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.23.intermediate.dense.weight', 'base_model.encoder.layer.2.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.17.attention.output.LayerNorm.bias', 'base_model.encoder.layer.17.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.10.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.19.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.15.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.9.output.LayerNorm.bias', 'base_model.encoder.layer.21.attention.self.query.bias', 'base_model.encoder.layer.6.attention.self.value.bias', 'base_model.encoder.layer.15.output.LayerNorm.weight', 'base_model.encoder.layer.6.attention.self.value.weight', 'base_model.encoder.layer.17.attention.self.value.weight', 'base_model.encoder.layer.18.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.14.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.18.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.11.attention.self.value.weight', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.6.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.9.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.22.attention.output.dense.weight', 'base_model.encoder.layer.7.output.LayerNorm.bias', 'base_model.encoder.layer.20.attention.self.query.bias', 'base_model.encoder.layer.1.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.15.intermediate.dense.bias', 'base_model.encoder.layer.22.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.8.attention.self.value.bias', 'base_model.encoder.layer.19.intermediate.dense.weight', 'base_model.encoder.layer.19.attention.output.LayerNorm.bias', 'base_model.encoder.layer.5.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.13.attention.self.query.bias', 'base_model.encoder.layer.13.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.11.output.LayerNorm.bias', 'base_model.encoder.layer.17.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.23.intermediate.dense.bias', 'base_model.encoder.layer.10.output.dense.bias', 'base_model.encoder.layer.1.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.18.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.9.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.19.attention.self.query.bias', 'base_model.encoder.layer.20.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.9.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.12.attention.self.key.weight', 'base_model.encoder.layer.11.intermediate.dense.weight', 'base_model.encoder.layer.6.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.4.attention.output.dense.weight', 'base_model.encoder.layer.14.attention.self.key.bias', 'base_model.encoder.layer.22.attention.output.dense.bias', 'base_model.encoder.layer.10.attention.output.dense.bias', 'base_model.encoder.layer.22.attention.self.key.weight', 'base_model.encoder.layer.10.output.adapters.ts.adapter_up.weight', 'base_model.embeddings.token_type_embeddings.weight', 'base_model.encoder.layer.23.output.dense.weight', 'base_model.encoder.layer.10.output.LayerNorm.weight', 'base_model.encoder.layer.17.attention.output.dense.bias', 'base_model.encoder.layer.0.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.16.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.6.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.0.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.18.attention.output.LayerNorm.weight', 'base_model.encoder.layer.21.intermediate.dense.bias', 'base_model.encoder.layer.15.output.LayerNorm.bias', 'base_model.encoder.layer.17.output.LayerNorm.weight', 'base_model.encoder.layer.23.attention.self.query.bias', 'base_model.encoder.layer.6.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.10.intermediate.dense.bias', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.2.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.20.output.LayerNorm.weight', 'base_model.encoder.layer.4.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.4.attention.self.value.bias', 'base_model.encoder.layer.17.attention.self.key.bias', 'base_model.encoder.layer.0.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.19.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.22.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.0.intermediate.dense.bias', 'base_model.encoder.layer.4.attention.output.dense.bias', 'base_model.encoder.layer.20.attention.self.value.bias', 'base_model.encoder.layer.1.output.LayerNorm.weight', 'base_model.encoder.layer.5.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.14.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.16.intermediate.dense.bias', 'base_model.encoder.layer.15.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.0.output.LayerNorm.weight', 'base_model.encoder.layer.15.attention.self.query.bias', 'base_model.encoder.layer.20.output.LayerNorm.bias', 'base_model.encoder.layer.20.attention.output.dense.weight', 'base_model.encoder.layer.14.attention.output.LayerNorm.weight', 'base_model.encoder.layer.13.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.11.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.1.attention.output.dense.weight', 'base_model.encoder.layer.18.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.3.intermediate.dense.weight', 'base_model.encoder.layer.17.output.LayerNorm.bias', 'base_model.encoder.layer.6.attention.output.dense.weight', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.6.intermediate.dense.weight', 'base_model.encoder.layer.20.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.19.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.0.attention.output.dense.weight', 'base_model.encoder.layer.15.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.3.output.dense.bias', 'base_model.encoder.layer.4.attention.self.value.weight', 'base_model.encoder.layer.5.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.16.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.12.output.LayerNorm.weight', 'base_model.encoder.layer.12.attention.self.value.weight', 'base_model.encoder.layer.13.attention.self.key.weight', 'base_model.encoder.layer.5.intermediate.dense.bias', 'base_model.encoder.layer.5.attention.self.value.weight', 'base_model.encoder.layer.1.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.13.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.18.attention.self.value.weight', 'base_model.encoder.layer.14.output.LayerNorm.weight', 'base_model.encoder.layer.23.attention.output.dense.weight', 'base_model.encoder.layer.1.attention.self.query.weight', 'base_model.encoder.layer.21.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.17.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.3.attention.self.key.bias', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.15.attention.self.key.bias', 'base_model.encoder.layer.8.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.20.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.3.output.dense.weight', 'base_model.encoder.layer.20.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.22.output.LayerNorm.bias', 'base_model.encoder.layer.4.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.7.output.dense.bias', 'base_model.encoder.layer.8.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.7.attention.self.value.weight', 'base_model.encoder.layer.13.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.11.attention.self.value.bias', 'base_model.encoder.layer.15.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.5.attention.output.dense.bias', 'base_model.encoder.layer.16.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.0.output.LayerNorm.bias', 'base_model.encoder.layer.16.attention.output.LayerNorm.weight', 'base_model.encoder.layer.21.output.LayerNorm.bias', 'base_model.encoder.layer.13.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.22.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.3.output.LayerNorm.weight', 'base_model.encoder.layer.14.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.21.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.8.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.11.attention.output.dense.bias', 'base_model.encoder.layer.18.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.22.output.dense.weight', 'base_model.encoder.layer.13.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.3.attention.self.value.weight', 'base_model.encoder.layer.9.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.23.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.22.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.3.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.0.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.11.attention.self.key.bias', 'base_model.encoder.layer.4.output.LayerNorm.bias', 'base_model.encoder.layer.18.output.LayerNorm.bias', 'base_model.encoder.layer.7.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.5.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.21.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.12.attention.self.key.bias', 'base_model.encoder.layer.23.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.14.attention.self.value.bias', 'base_model.encoder.layer.11.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.14.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.1.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.23.attention.self.key.bias', 'base_model.encoder.layer.21.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.8.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.22.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.pooler.dense.bias', 'base_model.encoder.layer.17.intermediate.dense.weight', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.2.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.16.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.22.intermediate.dense.weight', 'base_model.encoder.layer.1.attention.self.value.weight', 'base_model.encoder.layer.3.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.11.output.dense.bias', 'base_model.encoder.layer.16.attention.self.query.weight', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.5.output.dense.bias', 'base_model.encoder.layer.8.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.15.attention.self.key.weight', 'base_model.encoder.layer.12.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.2.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.4.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.10.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.15.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.7.attention.self.key.weight', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.8.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.2.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.0.attention.output.LayerNorm.weight', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.19.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.10.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.4.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.1.intermediate.dense.bias', 'base_model.encoder.layer.16.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.22.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.0.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.11.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.23.attention.self.value.weight', 'base_model.encoder.layer.23.output.LayerNorm.weight', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.19.attention.self.value.weight', 'base_model.encoder.layer.20.output.dense.weight', 'base_model.encoder.layer.5.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.12.output.LayerNorm.bias', 'base_model.encoder.layer.9.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.9.intermediate.dense.bias', 'base_model.encoder.layer.21.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.6.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.16.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.9.attention.self.query.bias', 'base_model.encoder.layer.21.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.9.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.18.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.4.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.23.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.3.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.11.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.18.attention.self.value.bias', 'base_model.encoder.layer.16.output.adapters.tp.adapter_down.0.weight', 'base_model.embeddings.LayerNorm.weight', 'base_model.encoder.layer.21.attention.self.value.weight', 'base_model.encoder.layer.4.intermediate.dense.weight', 'base_model.encoder.layer.12.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.4.attention.output.LayerNorm.bias', 'base_model.encoder.layer.23.attention.output.LayerNorm.weight', 'base_model.encoder.layer.15.attention.output.dense.bias', 'base_model.encoder.layer.17.output.dense.bias', 'base_model.encoder.layer.19.attention.self.value.bias', 'base_model.encoder.layer.18.intermediate.dense.weight', 'base_model.encoder.layer.7.output.LayerNorm.weight', 'base_model.encoder.layer.4.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.6.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.1.attention.self.key.bias', 'base_model.encoder.layer.2.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.2.attention.output.dense.weight', 'base_model.encoder.layer.9.attention.output.dense.weight', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.9.attention.self.value.bias', 'base_model.encoder.layer.9.attention.self.key.weight', 'base_model.encoder.layer.0.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.19.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.10.attention.self.key.weight', 'base_model.encoder.layer.0.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.13.attention.self.value.weight', 'base_model.encoder.layer.4.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.5.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.6.output.LayerNorm.bias', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.5.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.17.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.3.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.0.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.12.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.9.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.8.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.17.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.11.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.18.attention.output.LayerNorm.bias', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.1.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.6.output.dense.bias', 'base_model.encoder.layer.22.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.11.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.11.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.14.output.dense.bias', 'base_model.encoder.layer.16.output.LayerNorm.weight', 'base_model.encoder.layer.15.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.7.attention.self.key.bias', 'base_model.encoder.layer.19.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.20.attention.output.LayerNorm.weight', 'base_model.encoder.layer.21.attention.self.query.weight', 'base_model.encoder.layer.18.output.LayerNorm.weight', 'base_model.encoder.layer.19.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.14.output.dense.weight', 'base_model.encoder.layer.9.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.15.attention.self.value.weight', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.1.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.9.attention.output.dense.bias', 'base_model.encoder.layer.1.intermediate.dense.weight', 'base_model.encoder.layer.1.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.11.intermediate.dense.bias', 'base_model.encoder.layer.17.attention.output.LayerNorm.weight', 'base_model.encoder.layer.20.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.1.attention.self.query.bias', 'base_model.encoder.layer.7.attention.self.query.bias', 'base_model.encoder.layer.1.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.0.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.9.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.0.intermediate.dense.weight', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.20.output.dense.bias', 'base_model.encoder.layer.12.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.23.attention.self.value.bias', 'base_model.encoder.layer.14.attention.self.key.weight', 'base_model.encoder.layer.8.output.adapters.es.adapter_down.0.weight', 'base_model.embeddings.word_embeddings.weight', 'base_model.encoder.layer.2.attention.self.value.bias', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.20.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.2.attention.self.value.weight', 'base_model.encoder.layer.13.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.6.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.14.attention.self.query.bias', 'base_model.encoder.layer.16.attention.self.value.bias', 'base_model.encoder.layer.19.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.13.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.3.attention.self.value.bias', 'base_model.encoder.layer.11.attention.output.dense.weight', 'base_model.encoder.layer.7.attention.output.LayerNorm.bias', 'base_model.encoder.layer.6.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.23.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.15.attention.self.query.weight', 'base_model.encoder.layer.15.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.2.output.dense.bias', 'base_model.encoder.layer.7.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.12.attention.self.value.bias', 'base_model.encoder.layer.13.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.17.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.15.attention.output.LayerNorm.weight', 'base_model.encoder.layer.11.attention.self.key.weight', 'base_model.encoder.layer.22.attention.self.value.bias', 'base_model.encoder.layer.12.intermediate.dense.bias', 'base_model.encoder.layer.20.attention.self.key.weight', 'base_model.encoder.layer.22.attention.self.query.bias', 'base_model.encoder.layer.15.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.2.output.LayerNorm.bias', 'base_model.encoder.layer.2.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.2.attention.output.LayerNorm.bias', 'base_model.encoder.layer.3.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.4.intermediate.dense.bias', 'base_model.encoder.layer.9.attention.output.LayerNorm.weight', 'base_model.encoder.layer.9.attention.self.value.weight', 'base_model.encoder.layer.7.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.2.attention.self.key.bias', 'base_model.encoder.layer.14.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.16.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.5.intermediate.dense.weight', 'base_model.encoder.layer.16.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.18.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.11.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.10.output.dense.weight', 'base_model.encoder.layer.20.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.13.intermediate.dense.weight', 'base_model.encoder.layer.16.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.7.output.dense.weight', 'base_model.encoder.layer.0.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.9.attention.self.key.bias', 'base_model.encoder.layer.5.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.10.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.4.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.20.attention.self.value.weight', 'base_model.encoder.layer.16.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.8.output.dense.weight', 'base_model.encoder.layer.3.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.9.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.18.intermediate.dense.bias', 'base_model.encoder.layer.23.attention.self.key.weight', 'base_model.encoder.layer.16.attention.self.value.weight', 'base_model.encoder.layer.8.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.2.attention.self.query.weight', 'base_model.encoder.layer.5.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.4.attention.self.query.weight', 'base_model.encoder.layer.21.attention.self.key.bias', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.0.attention.output.dense.bias', 'base_model.encoder.layer.14.output.adapters.tp.adapter_down.0.bias', 'base_model.embeddings.position_ids', 'base_model.encoder.layer.2.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.6.output.LayerNorm.weight', 'base_model.encoder.layer.15.attention.self.value.bias', 'base_model.encoder.layer.7.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.11.attention.self.query.bias', 'base_model.encoder.layer.17.output.dense.weight', 'base_model.encoder.layer.21.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.8.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.23.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.14.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.10.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.10.attention.output.LayerNorm.bias', 'base_model.encoder.layer.18.attention.self.query.bias', 'qa_outputs.bias', 'base_model.encoder.layer.0.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.7.attention.output.dense.weight', 'base_model.encoder.layer.0.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.10.attention.self.value.weight', 'base_model.encoder.layer.23.output.dense.bias', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.18.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.20.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.8.attention.self.key.bias', 'base_model.encoder.layer.18.attention.output.dense.bias', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.embeddings.LayerNorm.bias', 'base_model.encoder.layer.19.attention.self.query.weight', 'base_model.encoder.layer.3.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.17.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.18.attention.output.dense.weight', 'base_model.encoder.layer.12.attention.output.dense.bias', 'base_model.encoder.layer.5.output.dense.weight', 'base_model.encoder.layer.11.attention.output.LayerNorm.weight', 'base_model.encoder.layer.19.output.LayerNorm.bias', 'base_model.encoder.layer.4.attention.self.key.weight', 'base_model.encoder.layer.19.attention.self.key.weight', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.20.intermediate.dense.weight', 'base_model.encoder.layer.13.attention.self.value.bias', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.15.output.dense.bias', 'base_model.encoder.layer.8.output.dense.bias', 'base_model.encoder.layer.2.attention.output.dense.bias', 'base_model.encoder.layer.15.attention.output.LayerNorm.bias', 'base_model.encoder.layer.4.attention.output.LayerNorm.weight', 'base_model.encoder.layer.10.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.9.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.6.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.19.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.14.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.20.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.21.output.dense.bias', 'base_model.encoder.layer.22.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.0.attention.output.LayerNorm.bias', 'base_model.encoder.layer.3.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.21.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.7.attention.output.dense.bias', 'base_model.encoder.layer.23.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.22.intermediate.dense.bias', 'base_model.encoder.layer.5.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.6.attention.self.query.bias', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.18.output.adapters.tp.adapter_up.bias', 'base_model.embeddings.position_embeddings.weight', 'base_model.encoder.layer.0.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.9.output.LayerNorm.weight', 'base_model.encoder.layer.21.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.11.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.13.output.LayerNorm.bias', 'base_model.encoder.layer.16.output.dense.weight', 'base_model.encoder.layer.6.attention.output.LayerNorm.weight', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.4.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.5.attention.self.key.bias', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.10.output.LayerNorm.bias', 'base_model.encoder.layer.7.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.6.attention.self.key.bias', 'base_model.encoder.layer.21.attention.output.LayerNorm.bias', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.12.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.9.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.10.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.12.attention.output.LayerNorm.bias', 'base_model.encoder.layer.22.attention.self.query.weight', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.12.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.4.output.dense.weight', 'base_model.encoder.layer.12.output.dense.bias', 'base_model.encoder.layer.10.intermediate.dense.weight', 'base_model.encoder.layer.19.attention.output.dense.weight', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.3.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.6.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.8.attention.self.query.bias', 'base_model.encoder.layer.16.output.dense.bias', 'base_model.encoder.layer.22.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.9.intermediate.dense.weight', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.2.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.8.attention.output.dense.weight', 'base_model.encoder.layer.2.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.23.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.23.attention.output.LayerNorm.bias', 'base_model.encoder.layer.5.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.18.attention.self.key.weight', 'base_model.encoder.layer.3.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.11.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.14.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.23.attention.output.dense.bias', 'base_model.encoder.layer.6.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.12.attention.self.query.weight', 'base_model.encoder.layer.22.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.10.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.2.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.12.attention.output.LayerNorm.weight', 'base_model.encoder.layer.1.attention.output.LayerNorm.bias', 'base_model.encoder.layer.19.attention.output.dense.bias', 'base_model.encoder.layer.7.intermediate.dense.bias', 'base_model.encoder.layer.3.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.4.attention.self.key.bias', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.23.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.12.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.11.output.LayerNorm.weight', 'base_model.encoder.layer.16.attention.self.key.weight', 'base_model.encoder.layer.15.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.13.output.dense.weight', 'base_model.encoder.layer.15.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.7.intermediate.dense.weight', 'base_model.encoder.layer.7.attention.self.value.bias', 'base_model.encoder.layer.19.intermediate.dense.bias', 'base_model.encoder.layer.21.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.8.attention.output.LayerNorm.weight', 'base_model.encoder.layer.9.attention.self.query.weight', 'base_model.encoder.layer.14.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.2.attention.self.query.bias', 'base_model.encoder.layer.1.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.10.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.13.intermediate.dense.bias', 'base_model.encoder.layer.21.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.14.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.1.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.10.attention.self.query.weight', 'base_model.encoder.layer.19.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.18.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.21.output.LayerNorm.weight', 'base_model.encoder.layer.13.attention.output.LayerNorm.weight', 'base_model.encoder.layer.10.attention.output.LayerNorm.weight', 'base_model.encoder.layer.12.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.21.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.2.intermediate.dense.weight', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.21.attention.output.dense.bias', 'base_model.encoder.layer.2.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.23.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.4.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.16.attention.self.key.bias', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.19.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.13.attention.output.LayerNorm.bias', 'base_model.encoder.layer.5.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.2.intermediate.dense.bias', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.16.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.16.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.20.attention.output.dense.bias', 'base_model.encoder.layer.23.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.10.attention.self.query.bias', 'qa_outputs.weight', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.6.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.2.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.6.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.21.attention.self.value.bias', 'base_model.encoder.layer.20.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.10.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.20.intermediate.dense.bias', 'base_model.encoder.layer.0.output.dense.weight', 'base_model.encoder.layer.1.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.12.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.7.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.17.intermediate.dense.bias', 'base_model.encoder.layer.4.output.LayerNorm.weight', 'base_model.encoder.layer.17.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.8.attention.output.dense.bias', 'base_model.encoder.layer.14.intermediate.dense.weight', 'base_model.encoder.layer.15.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.16.attention.output.dense.weight', 'base_model.encoder.layer.16.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.22.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.23.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.23.attention.self.query.weight', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.6.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.11.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.21.attention.output.dense.weight', 'base_model.encoder.layer.14.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.22.output.dense.bias', 'base_model.encoder.layer.1.attention.output.dense.bias', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.18.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.1.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.3.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.20.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.9.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.2.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.2.attention.self.key.weight', 'base_model.encoder.layer.13.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.16.output.LayerNorm.bias', 'base_model.encoder.layer.11.attention.output.LayerNorm.bias', 'base_model.encoder.layer.23.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.1.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.8.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.4.attention.self.query.bias', 'base_model.encoder.layer.1.output.dense.weight', 'base_model.encoder.layer.16.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.9.output.dense.bias', 'base_model.encoder.layer.19.output.dense.weight', 'base_model.encoder.layer.2.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.12.intermediate.dense.weight', 'base_model.encoder.layer.7.attention.self.query.weight', 'base_model.encoder.layer.3.output.LayerNorm.bias', 'base_model.encoder.layer.14.intermediate.dense.bias', 'base_model.encoder.layer.12.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.14.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.22.attention.output.LayerNorm.bias', 'base_model.encoder.layer.3.intermediate.dense.bias', 'base_model.encoder.layer.17.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.8.attention.output.LayerNorm.bias', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.18.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.1.output.dense.bias', 'base_model.encoder.layer.12.output.dense.weight', 'base_model.encoder.layer.4.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.19.output.LayerNorm.weight', 'base_model.encoder.layer.5.attention.self.query.weight', 'base_model.encoder.layer.20.attention.self.key.bias', 'base_model.encoder.layer.6.output.dense.weight', 'base_model.encoder.layer.8.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.17.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.1.attention.output.LayerNorm.weight', 'base_model.encoder.layer.0.attention.self.key.bias', 'base_model.encoder.layer.14.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.21.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.3.attention.self.key.weight', 'base_model.encoder.layer.12.attention.output.dense.weight', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.16.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.20.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.0.attention.self.value.weight', 'base_model.encoder.layer.0.attention.self.query.weight', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.10.attention.self.value.bias', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.20.attention.self.query.weight', 'base_model.encoder.layer.18.attention.self.key.bias', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.19.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.9.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.14.attention.self.query.weight', 'base_model.encoder.layer.21.intermediate.dense.weight', 'base_model.encoder.layer.11.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.14.attention.self.value.weight', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.17.attention.self.query.bias', 'base_model.encoder.layer.5.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.18.attention.self.query.weight', 'base_model.encoder.layer.0.output.dense.bias', 'base_model.encoder.layer.8.intermediate.dense.bias', 'base_model.encoder.layer.13.output.LayerNorm.weight', 'base_model.encoder.layer.0.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.23.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.4.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.21.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.11.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.22.output.LayerNorm.weight', 'base_model.encoder.layer.12.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.8.intermediate.dense.weight', 'base_model.encoder.layer.6.attention.self.query.weight', 'base_model.encoder.layer.8.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.16.intermediate.dense.weight', 'base_model.encoder.layer.7.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.14.output.LayerNorm.bias', 'base_model.encoder.layer.19.attention.output.LayerNorm.weight', 'base_model.encoder.layer.5.attention.self.key.weight', 'base_model.encoder.layer.13.output.dense.bias', 'base_model.encoder.layer.19.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.6.attention.self.key.weight', 'base_model.encoder.layer.10.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.2.output.dense.weight', 'base_model.encoder.layer.8.output.LayerNorm.weight', 'base_model.encoder.layer.1.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.13.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.13.attention.self.key.bias', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.14.attention.output.LayerNorm.bias', 'base_model.encoder.layer.5.attention.self.value.bias', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.10.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.17.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.22.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.0.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.18.output.dense.weight', 'base_model.encoder.layer.3.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.17.attention.self.query.weight', 'base_model.encoder.layer.3.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.7.attention.output.LayerNorm.weight', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.18.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.10.attention.self.key.bias', 'base_model.encoder.layer.20.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.13.attention.output.dense.weight', 'base_model.encoder.layer.13.attention.output.dense.bias', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.13.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.7.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.5.attention.output.dense.weight', 'base_model.encoder.layer.12.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.8.output.LayerNorm.bias', 'base_model.encoder.layer.8.attention.self.key.weight', 'base_model.encoder.layer.15.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.3.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.8.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.17.attention.self.key.weight', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.22.attention.self.key.bias', 'base_model.encoder.layer.8.attention.self.value.weight', 'base_model.encoder.layer.17.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.11.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.17.attention.output.dense.weight', 'base_model.encoder.layer.21.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.21.output.dense.weight', 'base_model.encoder.layer.0.attention.self.query.bias', 'base_model.encoder.layer.12.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.0.attention.self.value.bias', 'base_model.encoder.layer.3.attention.output.LayerNorm.bias', 'base_model.encoder.layer.5.attention.output.LayerNorm.weight', 'base_model.encoder.layer.6.attention.output.dense.bias', 'base_model.encoder.layer.23.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.20.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.7.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.2.output.LayerNorm.weight', 'base_model.encoder.layer.12.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.22.attention.output.LayerNorm.weight', 'base_model.encoder.layer.6.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.7.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.5.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.22.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.4.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.17.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.10.attention.output.dense.weight', 'base_model.encoder.layer.5.attention.self.query.bias', 'base_model.encoder.layer.19.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.16.attention.output.dense.bias', 'base_model.encoder.layer.11.attention.self.query.weight', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.9.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.11.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.15.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.1.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.3.attention.self.query.bias', 'base_model.encoder.layer.5.output.LayerNorm.bias', 'base_model.encoder.layer.9.attention.output.LayerNorm.bias', 'base_model.encoder.layer.11.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.22.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.6.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.14.attention.output.dense.weight', 'base_model.encoder.layer.8.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.6.intermediate.dense.bias', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.22.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.17.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.23.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.4.output.dense.bias', 'base_model.encoder.layer.3.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.8.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.7.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.10.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.7.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.2.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.13.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.16.attention.self.query.bias', 'base_model.encoder.layer.1.output.LayerNorm.bias', 'base_model.encoder.layer.15.attention.output.dense.weight', 'base_model.encoder.layer.7.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.17.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.1.attention.self.value.bias', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.17.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.20.attention.output.LayerNorm.bias', 'base_model.encoder.layer.9.output.dense.weight', 'base_model.encoder.layer.15.intermediate.dense.weight', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.16.attention.output.LayerNorm.bias', 'base_model.encoder.layer.14.attention.output.dense.bias', 'base_model.encoder.layer.15.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.20.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.19.output.dense.bias', 'base_model.encoder.layer.21.attention.self.key.weight', 'base_model.encoder.layer.22.attention.self.value.weight', 'base_model.encoder.layer.13.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.21.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.3.attention.output.dense.bias', 'base_model.encoder.layer.4.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.12.attention.self.query.bias', 'base_model.encoder.layer.21.attention.output.LayerNorm.weight', 'base_model.encoder.layer.15.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.0.attention.self.key.weight', 'base_model.encoder.layer.18.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.18.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.18.output.adapters.es.adapter_down.0.weight', 'base_model.pooler.dense.weight', 'base_model.encoder.layer.7.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.15.output.dense.weight', 'base_model.encoder.layer.8.attention.self.query.weight', 'base_model.encoder.layer.19.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.query.bias']
- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of XLMRobertaModel were not initialized from the model checkpoint at /cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//squad/xlm-KG_LR3e-5_EPOCH2.0_maxlen384_batchsize4_gradacc4 and are newly initialized: ['encoder.layer.13.attention.self.key.weight', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.4.attention.self.query.bias', 'encoder.layer.1.attention.output.LayerNorm.weight', 'encoder.layer.2.attention.self.query.bias', 'encoder.layer.14.attention.self.value.weight', 'encoder.layer.18.attention.self.query.bias', 'encoder.layer.13.intermediate.dense.bias', 'encoder.layer.21.output.LayerNorm.bias', 'encoder.layer.15.intermediate.dense.weight', 'encoder.layer.23.output.LayerNorm.bias', 'encoder.layer.17.output.dense.weight', 'encoder.layer.7.attention.output.LayerNorm.bias', 'encoder.layer.16.intermediate.dense.bias', 'encoder.layer.2.attention.output.dense.weight', 'encoder.layer.6.attention.self.value.weight', 'encoder.layer.17.attention.self.value.bias', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.16.attention.output.dense.bias', 'encoder.layer.3.attention.self.value.bias', 'encoder.layer.0.attention.output.LayerNorm.weight', 'encoder.layer.19.output.dense.weight', 'encoder.layer.21.attention.output.LayerNorm.weight', 'encoder.layer.6.attention.self.key.bias', 'encoder.layer.9.output.LayerNorm.bias', 'encoder.layer.21.attention.self.query.weight', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.6.output.dense.bias', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.19.attention.output.LayerNorm.bias', 'encoder.layer.8.attention.output.LayerNorm.bias', 'encoder.layer.20.output.LayerNorm.weight', 'encoder.layer.16.attention.self.query.weight', 'encoder.layer.4.attention.output.LayerNorm.weight', 'encoder.layer.19.attention.self.value.weight', 'encoder.layer.14.output.LayerNorm.bias', 'encoder.layer.14.intermediate.dense.bias', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.7.attention.self.query.weight', 'encoder.layer.17.intermediate.dense.weight', 'encoder.layer.12.attention.output.LayerNorm.bias', 'encoder.layer.11.output.LayerNorm.weight', 'encoder.layer.12.attention.output.dense.weight', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.15.attention.self.value.bias', 'encoder.layer.20.attention.self.query.weight', 'encoder.layer.20.intermediate.dense.weight', 'encoder.layer.12.output.dense.bias', 'encoder.layer.17.attention.output.dense.bias', 'encoder.layer.5.output.dense.bias', 'encoder.layer.9.attention.output.dense.bias', 'encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.layer.18.attention.output.dense.weight', 'encoder.layer.8.output.dense.bias', 'encoder.layer.0.output.dense.bias', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.14.attention.output.LayerNorm.weight', 'encoder.layer.6.attention.output.dense.bias', 'encoder.layer.9.attention.output.dense.weight', 'encoder.layer.2.attention.self.value.weight', 'encoder.layer.21.intermediate.dense.weight', 'encoder.layer.1.output.dense.weight', 'encoder.layer.4.attention.output.LayerNorm.bias', 'encoder.layer.21.attention.self.key.weight', 'encoder.layer.6.attention.self.query.bias', 'encoder.layer.15.attention.self.value.weight', 'encoder.layer.2.attention.self.value.bias', 'encoder.layer.7.attention.self.key.bias', 'encoder.layer.11.attention.output.dense.bias', 'encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.layer.11.output.LayerNorm.bias', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.7.attention.output.dense.weight', 'encoder.layer.3.attention.output.dense.bias', 'encoder.layer.12.output.dense.weight', 'encoder.layer.7.output.dense.bias', 'encoder.layer.5.attention.output.dense.bias', 'encoder.layer.15.output.LayerNorm.bias', 'embeddings.token_type_embeddings.weight', 'encoder.layer.7.attention.self.value.weight', 'encoder.layer.18.output.LayerNorm.bias', 'encoder.layer.23.attention.output.LayerNorm.weight', 'encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.layer.2.attention.output.LayerNorm.bias', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.21.output.dense.weight', 'encoder.layer.7.attention.output.dense.bias', 'encoder.layer.23.attention.output.dense.bias', 'encoder.layer.23.attention.self.key.bias', 'embeddings.word_embeddings.weight', 'encoder.layer.21.attention.output.dense.weight', 'encoder.layer.9.output.LayerNorm.weight', 'encoder.layer.13.attention.output.dense.bias', 'encoder.layer.22.intermediate.dense.weight', 'encoder.layer.18.attention.output.LayerNorm.bias', 'encoder.layer.8.output.dense.weight', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.7.output.dense.weight', 'encoder.layer.20.output.LayerNorm.bias', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.16.attention.output.dense.weight', 'encoder.layer.5.attention.output.LayerNorm.weight', 'encoder.layer.22.attention.output.LayerNorm.weight', 'encoder.layer.21.attention.self.value.weight', 'embeddings.position_embeddings.weight', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.10.attention.self.key.weight', 'encoder.layer.18.attention.output.LayerNorm.weight', 'encoder.layer.15.output.LayerNorm.weight', 'pooler.dense.bias', 'encoder.layer.18.attention.self.key.bias', 'encoder.layer.8.attention.self.query.weight', 'encoder.layer.7.output.LayerNorm.bias', 'encoder.layer.19.attention.output.dense.bias', 'encoder.layer.23.output.LayerNorm.weight', 'encoder.layer.18.output.dense.weight', 'encoder.layer.18.intermediate.dense.bias', 'encoder.layer.17.output.dense.bias', 'encoder.layer.12.output.LayerNorm.weight', 'encoder.layer.19.attention.self.query.bias', 'encoder.layer.14.attention.self.key.weight', 'encoder.layer.10.intermediate.dense.weight', 'encoder.layer.1.attention.output.dense.bias', 'encoder.layer.16.output.dense.weight', 'encoder.layer.2.attention.output.dense.bias', 'encoder.layer.8.attention.self.query.bias', 'encoder.layer.22.attention.self.query.bias', 'encoder.layer.7.attention.self.value.bias', 'encoder.layer.4.attention.self.key.weight', 'encoder.layer.14.attention.output.dense.bias', 'encoder.layer.19.attention.self.value.bias', 'encoder.layer.1.attention.self.key.bias', 'encoder.layer.7.attention.self.key.weight', 'encoder.layer.10.attention.self.value.weight', 'encoder.layer.12.intermediate.dense.weight', 'encoder.layer.5.attention.self.key.bias', 'encoder.layer.9.attention.self.key.bias', 'encoder.layer.8.attention.output.dense.bias', 'encoder.layer.17.attention.output.LayerNorm.weight', 'encoder.layer.4.attention.self.value.weight', 'encoder.layer.12.attention.output.dense.bias', 'encoder.layer.0.attention.self.value.weight', 'encoder.layer.6.output.LayerNorm.bias', 'encoder.layer.10.attention.self.key.bias', 'encoder.layer.23.intermediate.dense.weight', 'encoder.layer.13.attention.self.value.weight', 'encoder.layer.14.output.dense.bias', 'encoder.layer.12.attention.self.value.weight', 'encoder.layer.20.attention.self.query.bias', 'encoder.layer.14.attention.self.key.bias', 'encoder.layer.19.output.LayerNorm.weight', 'encoder.layer.19.attention.self.key.weight', 'encoder.layer.2.attention.output.LayerNorm.weight', 'encoder.layer.5.attention.self.key.weight', 'encoder.layer.16.attention.self.value.weight', 'encoder.layer.16.attention.self.key.weight', 'encoder.layer.1.attention.self.key.weight', 'encoder.layer.22.output.dense.bias', 'encoder.layer.15.output.dense.bias', 'encoder.layer.23.attention.self.key.weight', 'encoder.layer.21.output.dense.bias', 'encoder.layer.11.output.dense.weight', 'encoder.layer.4.attention.self.query.weight', 'encoder.layer.13.attention.output.dense.weight', 'encoder.layer.22.intermediate.dense.bias', 'encoder.layer.3.attention.output.dense.weight', 'encoder.layer.12.attention.self.key.weight', 'encoder.layer.6.attention.self.value.bias', 'encoder.layer.7.attention.output.LayerNorm.weight', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.13.attention.self.value.bias', 'encoder.layer.5.attention.self.value.weight', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.11.attention.self.query.bias', 'encoder.layer.10.output.dense.weight', 'encoder.layer.4.attention.output.dense.weight', 'encoder.layer.23.intermediate.dense.bias', 'encoder.layer.9.attention.self.query.bias', 'encoder.layer.16.output.dense.bias', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.23.attention.self.value.weight', 'encoder.layer.16.intermediate.dense.weight', 'encoder.layer.4.output.dense.weight', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.9.attention.output.LayerNorm.weight', 'encoder.layer.9.attention.self.key.weight', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.18.attention.self.key.weight', 'encoder.layer.18.attention.self.value.bias', 'encoder.layer.4.attention.output.dense.bias', 'embeddings.LayerNorm.bias', 'pooler.dense.weight', 'encoder.layer.6.attention.self.query.weight', 'encoder.layer.0.attention.self.key.bias', 'encoder.layer.20.attention.self.value.weight', 'encoder.layer.16.attention.output.LayerNorm.weight', 'encoder.layer.17.attention.self.key.bias', 'encoder.layer.17.attention.self.value.weight', 'encoder.layer.6.output.dense.weight', 'encoder.layer.21.intermediate.dense.bias', 'encoder.layer.13.attention.self.key.bias', 'encoder.layer.9.attention.self.query.weight', 'encoder.layer.19.attention.self.key.bias', 'encoder.layer.18.attention.output.dense.bias', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.11.attention.output.dense.weight', 'encoder.layer.17.intermediate.dense.bias', 'encoder.layer.7.intermediate.dense.bias', 'encoder.layer.1.attention.self.query.bias', 'encoder.layer.9.output.dense.weight', 'encoder.layer.16.output.LayerNorm.bias', 'encoder.layer.0.attention.self.query.bias', 'encoder.layer.8.attention.self.value.weight', 'encoder.layer.16.output.LayerNorm.weight', 'encoder.layer.15.intermediate.dense.bias', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.19.intermediate.dense.weight', 'encoder.layer.10.attention.output.LayerNorm.weight', 'encoder.layer.19.attention.output.LayerNorm.weight', 'encoder.layer.8.attention.self.key.bias', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.4.attention.self.key.bias', 'encoder.layer.0.attention.self.key.weight', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.16.attention.self.query.bias', 'encoder.layer.8.attention.output.dense.weight', 'encoder.layer.12.attention.self.key.bias', 'encoder.layer.18.output.LayerNorm.weight', 'encoder.layer.21.attention.self.query.bias', 'encoder.layer.0.attention.output.dense.bias', 'encoder.layer.22.attention.self.value.bias', 'encoder.layer.1.attention.self.value.weight', 'encoder.layer.19.attention.self.query.weight', 'encoder.layer.17.attention.output.dense.weight', 'encoder.layer.2.output.dense.weight', 'encoder.layer.11.attention.self.query.weight', 'encoder.layer.18.output.dense.bias', 'encoder.layer.20.output.dense.weight', 'encoder.layer.20.intermediate.dense.bias', 'encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.layer.1.output.dense.bias', 'encoder.layer.3.attention.self.query.bias', 'encoder.layer.23.attention.self.query.bias', 'encoder.layer.15.attention.self.key.weight', 'encoder.layer.1.attention.self.query.weight', 'encoder.layer.5.output.LayerNorm.bias', 'encoder.layer.3.output.dense.bias', 'encoder.layer.23.attention.output.dense.weight', 'encoder.layer.20.attention.output.dense.weight', 'encoder.layer.21.attention.self.value.bias', 'encoder.layer.23.attention.output.LayerNorm.bias', 'encoder.layer.14.output.dense.weight', 'encoder.layer.20.attention.output.dense.bias', 'encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.3.attention.self.key.bias', 'encoder.layer.20.attention.output.LayerNorm.weight', 'encoder.layer.10.attention.output.dense.weight', 'encoder.layer.10.attention.self.query.weight', 'encoder.layer.15.output.dense.weight', 'encoder.layer.16.attention.self.value.bias', 'encoder.layer.10.attention.output.LayerNorm.bias', 'encoder.layer.8.output.LayerNorm.weight', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.0.attention.output.dense.weight', 'encoder.layer.20.attention.self.value.bias', 'encoder.layer.9.attention.self.value.bias', 'encoder.layer.13.output.dense.weight', 'encoder.layer.14.output.LayerNorm.weight', 'encoder.layer.22.attention.output.dense.bias', 'encoder.layer.13.attention.output.LayerNorm.bias', 'encoder.layer.22.attention.self.value.weight', 'encoder.layer.10.output.LayerNorm.weight', 'encoder.layer.9.attention.output.LayerNorm.bias', 'encoder.layer.8.output.LayerNorm.bias', 'encoder.layer.20.output.dense.bias', 'encoder.layer.14.attention.output.dense.weight', 'encoder.layer.17.attention.self.query.bias', 'encoder.layer.8.attention.output.LayerNorm.weight', 'encoder.layer.22.output.LayerNorm.bias', 'encoder.layer.10.output.dense.bias', 'encoder.layer.22.output.dense.weight', 'encoder.layer.3.attention.self.value.weight', 'encoder.layer.9.output.dense.bias', 'encoder.layer.2.output.dense.bias', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.22.attention.self.query.weight', 'encoder.layer.21.attention.output.dense.bias', 'encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.layer.14.attention.self.value.bias', 'encoder.layer.15.attention.self.key.bias', 'encoder.layer.17.output.LayerNorm.bias', 'encoder.layer.5.attention.self.value.bias', 'encoder.layer.12.attention.self.query.bias', 'encoder.layer.19.output.LayerNorm.bias', 'encoder.layer.6.attention.output.LayerNorm.weight', 'encoder.layer.10.attention.self.query.bias', 'encoder.layer.4.attention.self.value.bias', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.13.output.LayerNorm.weight', 'encoder.layer.3.attention.self.query.weight', 'encoder.layer.19.intermediate.dense.bias', 'encoder.layer.17.attention.output.LayerNorm.bias', 'encoder.layer.13.attention.output.LayerNorm.weight', 'encoder.layer.14.attention.self.query.weight', 'encoder.layer.23.attention.self.query.weight', 'encoder.layer.13.intermediate.dense.weight', 'encoder.layer.17.attention.self.key.weight', 'encoder.layer.15.attention.output.LayerNorm.weight', 'encoder.layer.22.attention.output.dense.weight', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.20.attention.self.key.bias', 'encoder.layer.20.attention.output.LayerNorm.bias', 'encoder.layer.19.attention.output.dense.weight', 'encoder.layer.8.attention.self.value.bias', 'encoder.layer.9.attention.self.value.weight', 'encoder.layer.14.attention.self.query.bias', 'encoder.layer.23.attention.self.value.bias', 'encoder.layer.2.attention.self.key.bias', 'encoder.layer.3.output.dense.weight', 'encoder.layer.8.attention.self.key.weight', 'encoder.layer.11.attention.self.key.bias', 'encoder.layer.12.attention.output.LayerNorm.weight', 'encoder.layer.19.output.dense.bias', 'encoder.layer.0.attention.self.value.bias', 'encoder.layer.0.output.dense.weight', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.10.output.LayerNorm.bias', 'encoder.layer.15.attention.self.query.weight', 'encoder.layer.12.output.LayerNorm.bias', 'encoder.layer.13.attention.self.query.weight', 'encoder.layer.6.attention.self.key.weight', 'encoder.layer.6.attention.output.dense.weight', 'encoder.layer.0.attention.self.query.weight', 'encoder.layer.10.attention.self.value.bias', 'encoder.layer.11.attention.self.value.bias', 'encoder.layer.15.attention.output.dense.bias', 'encoder.layer.22.attention.self.key.weight', 'encoder.layer.5.attention.self.query.weight', 'encoder.layer.17.output.LayerNorm.weight', 'encoder.layer.14.attention.output.LayerNorm.bias', 'encoder.layer.11.attention.self.key.weight', 'encoder.layer.23.output.dense.bias', 'encoder.layer.6.attention.output.LayerNorm.bias', 'encoder.layer.12.attention.self.value.bias', 'encoder.layer.16.attention.self.key.bias', 'encoder.layer.7.attention.self.query.bias', 'encoder.layer.20.attention.self.key.weight', 'encoder.layer.10.attention.output.dense.bias', 'encoder.layer.15.attention.self.query.bias', 'encoder.layer.21.attention.self.key.bias', 'encoder.layer.13.output.dense.bias', 'encoder.layer.11.attention.output.LayerNorm.weight', 'encoder.layer.5.attention.output.dense.weight', 'encoder.layer.13.attention.self.query.bias', 'encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.1.attention.self.value.bias', 'encoder.layer.1.attention.output.dense.weight', 'encoder.layer.15.attention.output.dense.weight', 'encoder.layer.22.attention.output.LayerNorm.bias', 'encoder.layer.12.intermediate.dense.bias', 'encoder.layer.17.attention.self.query.weight', 'encoder.layer.5.output.dense.weight', 'encoder.layer.18.attention.self.value.weight', 'encoder.layer.23.output.dense.weight', 'encoder.layer.18.intermediate.dense.weight', 'encoder.layer.16.attention.output.LayerNorm.bias', 'embeddings.LayerNorm.weight', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.11.output.dense.bias', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.13.output.LayerNorm.bias', 'encoder.layer.15.attention.output.LayerNorm.bias', 'encoder.layer.11.attention.self.value.weight', 'encoder.layer.2.attention.self.query.weight', 'encoder.layer.7.output.LayerNorm.weight', 'encoder.layer.22.attention.self.key.bias', 'encoder.layer.3.attention.self.key.weight', 'encoder.layer.2.attention.self.key.weight', 'encoder.layer.21.output.LayerNorm.weight', 'encoder.layer.12.attention.self.query.weight', 'encoder.layer.5.attention.self.query.bias', 'encoder.layer.22.output.LayerNorm.weight', 'encoder.layer.18.attention.self.query.weight', 'encoder.layer.21.attention.output.LayerNorm.bias', 'encoder.layer.14.intermediate.dense.weight', 'encoder.layer.4.output.dense.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Overwriting existing adapter 'ep'.
Overwriting existing adapter 'tp'.
Overwriting existing adapter 'es'.
Overwriting existing adapter 'ts'.
Overwriting existing adapter fusion module 'ep,tp,es,ts'
05/09/2022 09:21:31 - INFO - __main__ -   Creating features from dataset file at .
/cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//squad/xlm-KG_LR3e-5_EPOCH2.0_maxlen384_batchsize4_gradacc4
XLMConfig {
  "architectures": [
    "XLMRobertaForMaskedLM"
  ],
  "asm": false,
  "attention_dropout": 0.1,
  "attention_probs_dropout_prob": 0.1,
  "bos_index": 0,
  "bos_token_id": 0,
  "causal": false,
  "dropout": 0.1,
  "emb_dim": 1024,
  "embed_init_std": 0.02209708691207961,
  "end_n_top": 5,
  "eos_index": 1,
  "eos_token_id": 2,
  "gelu_activation": true,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "init_std": 0.02,
  "initializer_range": 0.02,
  "intermediate_size": 4096,
  "is_encoder": true,
  "lang_id": 0,
  "layer_norm_eps": 1e-05,
  "mask_index": 5,
  "mask_token_id": 0,
  "max_position_embeddings": 514,
  "model_type": "xlm",
  "n_heads": 16,
  "n_langs": 1,
  "n_layers": 24,
  "output_past": true,
  "pad_index": 2,
  "pad_token_id": 1,
  "sinusoidal_embeddings": false,
  "start_n_top": 5,
  "summary_activation": null,
  "summary_first_dropout": 0.1,
  "summary_proj_to_labels": true,
  "summary_type": "first",
  "summary_use_proj": true,
  "transformers_version": "4.17.0",
  "type_vocab_size": 1,
  "unk_index": 3,
  "use_lang_emb": false,
  "vocab_size": 250002
}

  0%|          | 0/48 [00:00<?, ?it/s] 19%|█▉        | 9/48 [00:00<00:00, 82.53it/s] 38%|███▊      | 18/48 [00:00<00:00, 61.87it/s] 52%|█████▏    | 25/48 [00:00<00:00, 60.67it/s] 67%|██████▋   | 32/48 [00:00<00:00, 58.47it/s] 79%|███████▉  | 38/48 [00:00<00:00, 57.33it/s] 98%|█████████▊| 47/48 [00:00<00:00, 66.60it/s]100%|██████████| 48/48 [00:00<00:00, 63.43it/s]
convert squad examples to features:   0%|          | 0/1190 [00:00<?, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.
convert squad examples to features:   0%|          | 1/1190 [00:00<06:36,  2.99it/s]convert squad examples to features:   3%|▎         | 33/1190 [00:00<00:14, 81.16it/s]convert squad examples to features:   5%|▌         | 65/1190 [00:00<00:11, 97.48it/s]convert squad examples to features:   8%|▊         | 97/1190 [00:00<00:09, 117.45it/s]convert squad examples to features:  11%|█         | 129/1190 [00:01<00:07, 134.92it/s]convert squad examples to features:  14%|█▎        | 161/1190 [00:01<00:06, 152.81it/s]convert squad examples to features:  16%|█▌        | 193/1190 [00:01<00:06, 164.98it/s]convert squad examples to features:  19%|█▉        | 225/1190 [00:01<00:05, 181.82it/s]convert squad examples to features:  22%|██▏       | 257/1190 [00:01<00:06, 140.58it/s]convert squad examples to features:  24%|██▍       | 289/1190 [00:02<00:06, 146.94it/s]convert squad examples to features:  27%|██▋       | 321/1190 [00:02<00:06, 136.57it/s]convert squad examples to features:  30%|██▉       | 353/1190 [00:02<00:05, 145.15it/s]convert squad examples to features:  32%|███▏      | 385/1190 [00:03<00:09, 82.88it/s] convert squad examples to features:  35%|███▌      | 417/1190 [00:03<00:08, 94.91it/s]convert squad examples to features:  38%|███▊      | 449/1190 [00:03<00:07, 96.43it/s]convert squad examples to features:  40%|████      | 481/1190 [00:04<00:07, 100.91it/s]convert squad examples to features:  43%|████▎     | 513/1190 [00:04<00:05, 117.40it/s]convert squad examples to features:  46%|████▌     | 545/1190 [00:04<00:05, 114.45it/s]convert squad examples to features:  48%|████▊     | 577/1190 [00:04<00:04, 123.25it/s]convert squad examples to features:  51%|█████     | 609/1190 [00:05<00:04, 123.86it/s]convert squad examples to features:  54%|█████▍    | 641/1190 [00:05<00:04, 118.83it/s]convert squad examples to features:  57%|█████▋    | 673/1190 [00:05<00:04, 115.68it/s]convert squad examples to features:  59%|█████▉    | 705/1190 [00:05<00:04, 119.60it/s]convert squad examples to features:  62%|██████▏   | 737/1190 [00:06<00:03, 124.92it/s]convert squad examples to features:  65%|██████▍   | 769/1190 [00:06<00:03, 134.73it/s]convert squad examples to features:  67%|██████▋   | 801/1190 [00:06<00:02, 150.28it/s]convert squad examples to features:  70%|███████   | 833/1190 [00:06<00:02, 130.56it/s]convert squad examples to features:  73%|███████▎  | 865/1190 [00:07<00:02, 129.92it/s]convert squad examples to features:  75%|███████▌  | 897/1190 [00:07<00:02, 119.37it/s]convert squad examples to features:  78%|███████▊  | 929/1190 [00:07<00:02, 127.08it/s]convert squad examples to features:  81%|████████  | 961/1190 [00:07<00:01, 133.32it/s]convert squad examples to features:  83%|████████▎ | 993/1190 [00:08<00:01, 139.23it/s]convert squad examples to features:  86%|████████▌ | 1025/1190 [00:08<00:01, 145.63it/s]convert squad examples to features:  89%|████████▉ | 1057/1190 [00:08<00:00, 151.07it/s]convert squad examples to features:  92%|█████████▏| 1089/1190 [00:08<00:00, 158.06it/s]convert squad examples to features:  94%|█████████▍| 1121/1190 [00:08<00:00, 143.80it/s]convert squad examples to features:  97%|█████████▋| 1153/1190 [00:09<00:00, 126.57it/s]convert squad examples to features: 100%|██████████| 1190/1190 [00:09<00:00, 128.45it/s]/cluster/project/sachan/yifan/softwares/anaconda/anaconda3/envs/xfactr/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2272: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

add example index and unique id:   0%|          | 0/1190 [00:00<?, ?it/s]add example index and unique id: 100%|██████████| 1190/1190 [00:00<00:00, 395375.61it/s]
05/09/2022 09:21:41 - INFO - __main__ -   Saving features into cached file ./cached_xquad.hi.json_xlm-KG_LR3e-5_EPOCH2.0_maxlen384_batchsize4_gradacc4_384_hi
05/09/2022 09:21:43 - INFO - __main__ -   ***** Running evaluation  *****
05/09/2022 09:21:43 - INFO - __main__ -     Num examples = 1382
05/09/2022 09:21:43 - INFO - __main__ -     Batch size = 8
Evaluating:   0%|          | 0/173 [00:00<?, ?it/s]Evaluating:   1%|          | 1/173 [00:00<02:33,  1.12it/s]Evaluating:   1%|          | 2/173 [00:01<01:37,  1.75it/s]Evaluating:   2%|▏         | 3/173 [00:01<01:19,  2.15it/s]Evaluating:   2%|▏         | 4/173 [00:01<01:10,  2.40it/s]Evaluating:   3%|▎         | 5/173 [00:02<01:05,  2.57it/s]Evaluating:   3%|▎         | 6/173 [00:02<01:02,  2.68it/s]Evaluating:   4%|▍         | 7/173 [00:02<01:00,  2.75it/s]Evaluating:   5%|▍         | 8/173 [00:03<00:58,  2.80it/s]Evaluating:   5%|▌         | 9/173 [00:03<00:57,  2.84it/s]Evaluating:   6%|▌         | 10/173 [00:03<00:56,  2.87it/s]Evaluating:   6%|▋         | 11/173 [00:04<00:56,  2.88it/s]Evaluating:   7%|▋         | 12/173 [00:04<00:55,  2.89it/s]Evaluating:   8%|▊         | 13/173 [00:04<00:55,  2.90it/s]Evaluating:   8%|▊         | 14/173 [00:05<00:54,  2.90it/s]Evaluating:   9%|▊         | 15/173 [00:05<00:54,  2.89it/s]Evaluating:   9%|▉         | 16/173 [00:06<00:54,  2.91it/s]Evaluating:  10%|▉         | 17/173 [00:06<00:53,  2.91it/s]Evaluating:  10%|█         | 18/173 [00:06<00:53,  2.91it/s]Evaluating:  11%|█         | 19/173 [00:07<00:52,  2.91it/s]Evaluating:  12%|█▏        | 20/173 [00:07<00:52,  2.92it/s]Evaluating:  12%|█▏        | 21/173 [00:07<00:52,  2.92it/s]Evaluating:  13%|█▎        | 22/173 [00:08<00:51,  2.91it/s]Evaluating:  13%|█▎        | 23/173 [00:08<00:51,  2.91it/s]Evaluating:  14%|█▍        | 24/173 [00:08<00:51,  2.90it/s]Evaluating:  14%|█▍        | 25/173 [00:09<00:51,  2.90it/s]Evaluating:  15%|█▌        | 26/173 [00:09<00:50,  2.89it/s]Evaluating:  16%|█▌        | 27/173 [00:09<00:50,  2.90it/s]Evaluating:  16%|█▌        | 28/173 [00:10<00:50,  2.89it/s]Evaluating:  17%|█▋        | 29/173 [00:10<00:49,  2.89it/s]Evaluating:  17%|█▋        | 30/173 [00:10<00:49,  2.89it/s]Evaluating:  18%|█▊        | 31/173 [00:11<00:49,  2.89it/s]Evaluating:  18%|█▊        | 32/173 [00:11<00:48,  2.90it/s]Evaluating:  19%|█▉        | 33/173 [00:11<00:48,  2.91it/s]Evaluating:  20%|█▉        | 34/173 [00:12<00:47,  2.91it/s]Evaluating:  20%|██        | 35/173 [00:12<00:47,  2.91it/s]Evaluating:  21%|██        | 36/173 [00:12<00:47,  2.91it/s]Evaluating:  21%|██▏       | 37/173 [00:13<00:46,  2.90it/s]Evaluating:  22%|██▏       | 38/173 [00:13<00:46,  2.90it/s]Evaluating:  23%|██▎       | 39/173 [00:13<00:46,  2.89it/s]Evaluating:  23%|██▎       | 40/173 [00:14<00:45,  2.90it/s]Evaluating:  24%|██▎       | 41/173 [00:14<00:45,  2.89it/s]Evaluating:  24%|██▍       | 42/173 [00:14<00:45,  2.89it/s]Evaluating:  25%|██▍       | 43/173 [00:15<00:44,  2.90it/s]Evaluating:  25%|██▌       | 44/173 [00:15<00:44,  2.90it/s]Evaluating:  26%|██▌       | 45/173 [00:16<00:44,  2.90it/s]Evaluating:  27%|██▋       | 46/173 [00:16<00:43,  2.91it/s]Evaluating:  27%|██▋       | 47/173 [00:16<00:43,  2.91it/s]Evaluating:  28%|██▊       | 48/173 [00:17<00:42,  2.91it/s]Evaluating:  28%|██▊       | 49/173 [00:17<00:42,  2.92it/s]Evaluating:  29%|██▉       | 50/173 [00:17<00:42,  2.91it/s]Evaluating:  29%|██▉       | 51/173 [00:18<00:42,  2.90it/s]Evaluating:  30%|███       | 52/173 [00:18<00:41,  2.90it/s]Evaluating:  31%|███       | 53/173 [00:18<00:41,  2.91it/s]Evaluating:  31%|███       | 54/173 [00:19<00:40,  2.91it/s]Evaluating:  32%|███▏      | 55/173 [00:19<00:40,  2.91it/s]Evaluating:  32%|███▏      | 56/173 [00:19<00:40,  2.90it/s]Evaluating:  33%|███▎      | 57/173 [00:20<00:40,  2.90it/s]Evaluating:  34%|███▎      | 58/173 [00:20<00:39,  2.89it/s]Evaluating:  34%|███▍      | 59/173 [00:20<00:39,  2.89it/s]Evaluating:  35%|███▍      | 60/173 [00:21<00:39,  2.89it/s]Evaluating:  35%|███▌      | 61/173 [00:21<00:38,  2.89it/s]Evaluating:  36%|███▌      | 62/173 [00:21<00:38,  2.89it/s]Evaluating:  36%|███▋      | 63/173 [00:22<00:38,  2.88it/s]Evaluating:  37%|███▋      | 64/173 [00:22<00:37,  2.88it/s]Evaluating:  38%|███▊      | 65/173 [00:22<00:37,  2.89it/s]Evaluating:  38%|███▊      | 66/173 [00:23<00:36,  2.90it/s]Evaluating:  39%|███▊      | 67/173 [00:23<00:36,  2.90it/s]Evaluating:  39%|███▉      | 68/173 [00:23<00:36,  2.90it/s]Evaluating:  40%|███▉      | 69/173 [00:24<00:36,  2.89it/s]Evaluating:  40%|████      | 70/173 [00:24<00:35,  2.88it/s]Evaluating:  41%|████      | 71/173 [00:25<00:35,  2.88it/s]Evaluating:  42%|████▏     | 72/173 [00:25<00:35,  2.88it/s]Evaluating:  42%|████▏     | 73/173 [00:25<00:34,  2.89it/s]Evaluating:  43%|████▎     | 74/173 [00:26<00:34,  2.89it/s]Evaluating:  43%|████▎     | 75/173 [00:26<00:33,  2.89it/s]Evaluating:  44%|████▍     | 76/173 [00:26<00:33,  2.89it/s]Evaluating:  45%|████▍     | 77/173 [00:27<00:33,  2.89it/s]Evaluating:  45%|████▌     | 78/173 [00:27<00:32,  2.89it/s]Evaluating:  46%|████▌     | 79/173 [00:27<00:32,  2.90it/s]Evaluating:  46%|████▌     | 80/173 [00:28<00:31,  2.91it/s]Evaluating:  47%|████▋     | 81/173 [00:28<00:31,  2.90it/s]Evaluating:  47%|████▋     | 82/173 [00:28<00:31,  2.90it/s]Evaluating:  48%|████▊     | 83/173 [00:29<00:30,  2.91it/s]Evaluating:  49%|████▊     | 84/173 [00:29<00:30,  2.90it/s]Evaluating:  49%|████▉     | 85/173 [00:29<00:30,  2.90it/s]Evaluating:  50%|████▉     | 86/173 [00:30<00:30,  2.90it/s]Evaluating:  50%|█████     | 87/173 [00:30<00:29,  2.91it/s]Evaluating:  51%|█████     | 88/173 [00:30<00:29,  2.91it/s]Evaluating:  51%|█████▏    | 89/173 [00:31<00:28,  2.92it/s]Evaluating:  52%|█████▏    | 90/173 [00:31<00:28,  2.92it/s]Evaluating:  53%|█████▎    | 91/173 [00:31<00:28,  2.92it/s]Evaluating:  53%|█████▎    | 92/173 [00:32<00:27,  2.91it/s]Evaluating:  54%|█████▍    | 93/173 [00:32<00:27,  2.91it/s]Evaluating:  54%|█████▍    | 94/173 [00:32<00:27,  2.91it/s]Evaluating:  55%|█████▍    | 95/173 [00:33<00:26,  2.91it/s]Evaluating:  55%|█████▌    | 96/173 [00:33<00:26,  2.91it/s]Evaluating:  56%|█████▌    | 97/173 [00:33<00:26,  2.91it/s]Evaluating:  57%|█████▋    | 98/173 [00:34<00:25,  2.91it/s]Evaluating:  57%|█████▋    | 99/173 [00:34<00:25,  2.91it/s]Evaluating:  58%|█████▊    | 100/173 [00:34<00:25,  2.91it/s]Evaluating:  58%|█████▊    | 101/173 [00:35<00:24,  2.89it/s]Evaluating:  59%|█████▉    | 102/173 [00:35<00:24,  2.89it/s]Evaluating:  60%|█████▉    | 103/173 [00:36<00:24,  2.89it/s]Evaluating:  60%|██████    | 104/173 [00:36<00:23,  2.89it/s]Evaluating:  61%|██████    | 105/173 [00:36<00:23,  2.90it/s]Evaluating:  61%|██████▏   | 106/173 [00:37<00:23,  2.91it/s]Evaluating:  62%|██████▏   | 107/173 [00:37<00:22,  2.92it/s]Evaluating:  62%|██████▏   | 108/173 [00:37<00:22,  2.93it/s]Evaluating:  63%|██████▎   | 109/173 [00:38<00:21,  2.92it/s]Evaluating:  64%|██████▎   | 110/173 [00:38<00:21,  2.91it/s]Evaluating:  64%|██████▍   | 111/173 [00:38<00:21,  2.91it/s]Evaluating:  65%|██████▍   | 112/173 [00:39<00:20,  2.91it/s]Evaluating:  65%|██████▌   | 113/173 [00:39<00:20,  2.90it/s]Evaluating:  66%|██████▌   | 114/173 [00:39<00:20,  2.90it/s]Evaluating:  66%|██████▋   | 115/173 [00:40<00:19,  2.91it/s]Evaluating:  67%|██████▋   | 116/173 [00:40<00:19,  2.86it/s]Evaluating:  68%|██████▊   | 117/173 [00:40<00:19,  2.87it/s]Evaluating:  68%|██████▊   | 118/173 [00:41<00:19,  2.89it/s]Evaluating:  69%|██████▉   | 119/173 [00:41<00:18,  2.90it/s]Evaluating:  69%|██████▉   | 120/173 [00:41<00:18,  2.91it/s]Evaluating:  70%|██████▉   | 121/173 [00:42<00:17,  2.90it/s]Evaluating:  71%|███████   | 122/173 [00:42<00:17,  2.90it/s]Evaluating:  71%|███████   | 123/173 [00:42<00:17,  2.91it/s]Evaluating:  72%|███████▏  | 124/173 [00:43<00:16,  2.90it/s]Evaluating:  72%|███████▏  | 125/173 [00:43<00:16,  2.90it/s]Evaluating:  73%|███████▎  | 126/173 [00:43<00:16,  2.90it/s]Evaluating:  73%|███████▎  | 127/173 [00:44<00:15,  2.90it/s]Evaluating:  74%|███████▍  | 128/173 [00:44<00:15,  2.90it/s]Evaluating:  75%|███████▍  | 129/173 [00:44<00:15,  2.90it/s]Evaluating:  75%|███████▌  | 130/173 [00:45<00:14,  2.91it/s]Evaluating:  76%|███████▌  | 131/173 [00:45<00:14,  2.91it/s]Evaluating:  76%|███████▋  | 132/173 [00:46<00:14,  2.91it/s]Evaluating:  77%|███████▋  | 133/173 [00:46<00:13,  2.90it/s]Evaluating:  77%|███████▋  | 134/173 [00:46<00:13,  2.91it/s]Evaluating:  78%|███████▊  | 135/173 [00:47<00:13,  2.91it/s]Evaluating:  79%|███████▊  | 136/173 [00:47<00:12,  2.91it/s]Evaluating:  79%|███████▉  | 137/173 [00:47<00:12,  2.91it/s]Evaluating:  80%|███████▉  | 138/173 [00:48<00:12,  2.91it/s]Evaluating:  80%|████████  | 139/173 [00:48<00:11,  2.90it/s]Evaluating:  81%|████████  | 140/173 [00:48<00:11,  2.90it/s]Evaluating:  82%|████████▏ | 141/173 [00:49<00:11,  2.88it/s]Evaluating:  82%|████████▏ | 142/173 [00:49<00:10,  2.90it/s]Evaluating:  83%|████████▎ | 143/173 [00:49<00:10,  2.90it/s]Evaluating:  83%|████████▎ | 144/173 [00:50<00:09,  2.91it/s]Evaluating:  84%|████████▍ | 145/173 [00:50<00:09,  2.91it/s]Evaluating:  84%|████████▍ | 146/173 [00:50<00:09,  2.91it/s]Evaluating:  85%|████████▍ | 147/173 [00:51<00:08,  2.90it/s]Evaluating:  86%|████████▌ | 148/173 [00:51<00:08,  2.90it/s]Evaluating:  86%|████████▌ | 149/173 [00:51<00:08,  2.89it/s]Evaluating:  87%|████████▋ | 150/173 [00:52<00:07,  2.90it/s]Evaluating:  87%|████████▋ | 151/173 [00:52<00:07,  2.91it/s]Evaluating:  88%|████████▊ | 152/173 [00:52<00:07,  2.91it/s]Evaluating:  88%|████████▊ | 153/173 [00:53<00:06,  2.90it/s]Evaluating:  89%|████████▉ | 154/173 [00:53<00:06,  2.90it/s]Evaluating:  90%|████████▉ | 155/173 [00:53<00:06,  2.91it/s]Evaluating:  90%|█████████ | 156/173 [00:54<00:05,  2.91it/s]Evaluating:  91%|█████████ | 157/173 [00:54<00:05,  2.91it/s]Evaluating:  91%|█████████▏| 158/173 [00:54<00:05,  2.91it/s]Evaluating:  92%|█████████▏| 159/173 [00:55<00:04,  2.92it/s]Evaluating:  92%|█████████▏| 160/173 [00:55<00:04,  2.92it/s]Evaluating:  93%|█████████▎| 161/173 [00:55<00:04,  2.92it/s]Evaluating:  94%|█████████▎| 162/173 [00:56<00:03,  2.92it/s]Evaluating:  94%|█████████▍| 163/173 [00:56<00:03,  2.92it/s]Evaluating:  95%|█████████▍| 164/173 [00:57<00:03,  2.91it/s]Evaluating:  95%|█████████▌| 165/173 [00:57<00:02,  2.91it/s]Evaluating:  96%|█████████▌| 166/173 [00:57<00:02,  2.92it/s]Evaluating:  97%|█████████▋| 167/173 [00:58<00:02,  2.91it/s]Evaluating:  97%|█████████▋| 168/173 [00:58<00:01,  2.91it/s]Evaluating:  98%|█████████▊| 169/173 [00:58<00:01,  2.92it/s]Evaluating:  98%|█████████▊| 170/173 [00:59<00:01,  2.91it/s]Evaluating:  99%|█████████▉| 171/173 [00:59<00:00,  2.90it/s]Evaluating:  99%|█████████▉| 172/173 [00:59<00:00,  2.90it/s]Evaluating: 100%|██████████| 173/173 [01:00<00:00,  3.10it/s]Evaluating: 100%|██████████| 173/173 [01:00<00:00,  2.88it/s]
05/09/2022 09:22:43 - INFO - __main__ -     Evaluation done in total 60.047334 secs (0.043450 sec per example)
05/09/2022 09:22:49 - INFO - __main__ -   Results: {'exact': 58.319327731092436, 'f1': 75.42382252305619, 'total': 1190, 'HasAns_exact': 58.319327731092436, 'HasAns_f1': 75.42382252305619, 'HasAns_total': 1190, 'best_exact': 58.319327731092436, 'best_exact_thresh': 0.0, 'best_f1': 75.42382252305619, 'best_f1_thresh': 0.0}
