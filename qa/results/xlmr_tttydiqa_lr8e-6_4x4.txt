Fine-tuning /cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/xlm-roberta-large on tydiqa using GPU 1
Load data from /cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/download/, and save models to /cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter/
************************
/cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/xlm-roberta-large
************************

Predictions on tydiqa
  en 
2022-05-09 22:48:24.972366: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0
05/09/2022 22:48:28 - WARNING - __main__ -   Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, 16-bits training: False
You are using a model of type xlm-roberta to instantiate a model of type xlm. This is not supported for all configurations of models and can yield errors.
Some weights of the model checkpoint at /cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//tydiqa/xlm-KG_LR8e-6_EPOCH2.0_maxlen384_batchsize4_gradacc4 were not used when initializing XLMRobertaModel: ['base_model.encoder.layer.20.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.13.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.11.output.dense.bias', 'base_model.encoder.layer.16.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.0.attention.output.LayerNorm.weight', 'base_model.encoder.layer.2.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.3.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.2.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.18.attention.self.key.bias', 'base_model.encoder.layer.6.output.LayerNorm.bias', 'base_model.encoder.layer.0.attention.self.key.weight', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.21.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.2.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.7.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.13.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.15.attention.self.query.bias', 'base_model.encoder.layer.14.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.19.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.21.attention.output.dense.weight', 'base_model.encoder.layer.0.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.20.output.dense.weight', 'base_model.encoder.layer.20.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.1.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.11.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.16.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.4.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.6.attention.output.dense.bias', 'base_model.encoder.layer.1.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.20.attention.output.dense.weight', 'base_model.encoder.layer.13.intermediate.dense.bias', 'base_model.encoder.layer.17.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.4.attention.output.dense.bias', 'base_model.encoder.layer.16.attention.output.dense.bias', 'base_model.encoder.layer.12.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.0.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.9.output.LayerNorm.weight', 'base_model.encoder.layer.3.output.LayerNorm.weight', 'base_model.encoder.layer.9.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.21.output.dense.weight', 'base_model.encoder.layer.1.attention.output.LayerNorm.weight', 'base_model.encoder.layer.10.intermediate.dense.bias', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.13.attention.output.LayerNorm.weight', 'base_model.encoder.layer.15.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.9.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.14.attention.output.LayerNorm.weight', 'base_model.encoder.layer.16.attention.self.query.weight', 'base_model.encoder.layer.23.attention.output.dense.bias', 'base_model.encoder.layer.4.intermediate.dense.weight', 'base_model.encoder.layer.5.attention.self.query.weight', 'base_model.encoder.layer.5.attention.self.key.weight', 'base_model.encoder.layer.8.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.9.output.dense.bias', 'base_model.encoder.layer.12.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.8.attention.output.dense.weight', 'base_model.encoder.layer.20.attention.self.query.bias', 'base_model.encoder.layer.22.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.9.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.23.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.11.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.22.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.10.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.2.output.adapters.ep.adapter_down.0.weight', 'base_model.embeddings.word_embeddings.weight', 'base_model.encoder.layer.18.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.23.output.LayerNorm.weight', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.0.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.3.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.1.attention.self.key.bias', 'base_model.encoder.layer.12.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.12.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.13.attention.self.value.weight', 'base_model.encoder.layer.16.attention.output.LayerNorm.bias', 'base_model.encoder.layer.22.intermediate.dense.weight', 'base_model.encoder.layer.20.attention.self.key.bias', 'base_model.encoder.layer.22.attention.self.query.bias', 'base_model.encoder.layer.3.attention.self.query.weight', 'base_model.encoder.layer.3.attention.self.key.bias', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.15.attention.self.value.weight', 'base_model.encoder.layer.5.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.11.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.7.output.LayerNorm.weight', 'base_model.encoder.layer.8.attention.self.value.bias', 'base_model.encoder.layer.12.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.16.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.15.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.8.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.18.attention.output.LayerNorm.bias', 'base_model.encoder.layer.6.intermediate.dense.weight', 'base_model.encoder.layer.22.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.10.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.7.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.15.attention.output.dense.bias', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.21.attention.self.query.bias', 'base_model.encoder.layer.2.attention.output.LayerNorm.weight', 'base_model.encoder.layer.7.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.1.intermediate.dense.bias', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.6.attention.self.value.weight', 'base_model.encoder.layer.3.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.4.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.7.attention.self.query.bias', 'base_model.encoder.layer.11.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.10.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.10.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.21.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.12.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.2.intermediate.dense.weight', 'base_model.encoder.layer.6.output.LayerNorm.weight', 'base_model.encoder.layer.1.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.13.intermediate.dense.weight', 'base_model.encoder.layer.0.intermediate.dense.weight', 'base_model.encoder.layer.19.attention.output.dense.weight', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.17.attention.self.value.bias', 'base_model.encoder.layer.23.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.17.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.0.attention.output.dense.weight', 'base_model.encoder.layer.1.output.dense.weight', 'base_model.encoder.layer.20.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.3.attention.self.value.bias', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.5.attention.self.key.bias', 'base_model.encoder.layer.0.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.7.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.1.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.23.intermediate.dense.weight', 'base_model.embeddings.position_embeddings.weight', 'base_model.encoder.layer.8.attention.self.query.weight', 'base_model.encoder.layer.12.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.16.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.0.output.LayerNorm.bias', 'base_model.encoder.layer.7.attention.self.value.bias', 'base_model.encoder.layer.7.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.19.attention.self.query.weight', 'base_model.encoder.layer.22.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.11.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.19.attention.self.value.bias', 'base_model.encoder.layer.14.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.17.output.dense.weight', 'base_model.encoder.layer.13.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.17.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.5.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.11.intermediate.dense.bias', 'base_model.encoder.layer.10.output.dense.weight', 'base_model.encoder.layer.11.output.LayerNorm.weight', 'base_model.encoder.layer.10.intermediate.dense.weight', 'base_model.encoder.layer.15.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.12.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.16.intermediate.dense.weight', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.0.attention.output.dense.bias', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.0.output.LayerNorm.weight', 'base_model.encoder.layer.23.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.8.intermediate.dense.bias', 'base_model.encoder.layer.22.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.12.output.LayerNorm.weight', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.15.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.6.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.8.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.0.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.9.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.10.attention.self.query.weight', 'base_model.encoder.layer.7.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.7.attention.self.key.weight', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.19.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.4.output.LayerNorm.weight', 'base_model.encoder.layer.15.attention.output.LayerNorm.bias', 'base_model.encoder.layer.6.attention.self.query.weight', 'base_model.encoder.layer.22.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.20.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.19.intermediate.dense.bias', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.20.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.20.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.5.intermediate.dense.weight', 'base_model.encoder.layer.13.attention.self.key.weight', 'base_model.encoder.layer.17.intermediate.dense.weight', 'base_model.encoder.layer.11.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.18.output.dense.weight', 'base_model.encoder.layer.4.attention.self.value.bias', 'base_model.encoder.layer.4.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.4.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.18.output.dense.bias', 'base_model.encoder.layer.1.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.1.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.4.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.6.output.dense.weight', 'base_model.encoder.layer.16.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.11.output.LayerNorm.bias', 'base_model.encoder.layer.18.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.13.attention.self.value.bias', 'base_model.encoder.layer.2.attention.self.key.weight', 'base_model.encoder.layer.18.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.18.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.18.output.LayerNorm.weight', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.17.intermediate.dense.bias', 'base_model.encoder.layer.3.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.7.attention.self.query.weight', 'base_model.encoder.layer.4.attention.self.query.weight', 'base_model.encoder.layer.3.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.8.output.dense.bias', 'base_model.encoder.layer.3.attention.output.dense.bias', 'base_model.encoder.layer.7.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.13.output.dense.weight', 'base_model.encoder.layer.19.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.16.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.20.attention.self.value.bias', 'base_model.encoder.layer.23.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.4.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.6.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.6.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.14.output.LayerNorm.weight', 'base_model.encoder.layer.23.attention.self.query.bias', 'base_model.embeddings.LayerNorm.weight', 'base_model.encoder.layer.22.output.dense.bias', 'base_model.encoder.layer.8.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.20.output.LayerNorm.bias', 'base_model.encoder.layer.22.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.21.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.2.attention.self.query.weight', 'base_model.encoder.layer.9.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.14.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.18.attention.self.value.weight', 'base_model.encoder.layer.16.attention.self.key.weight', 'base_model.encoder.layer.4.output.adapters.ep.adapter_down.0.bias', 'base_model.embeddings.token_type_embeddings.weight', 'base_model.encoder.layer.8.attention.output.dense.bias', 'base_model.encoder.layer.20.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.7.attention.output.LayerNorm.bias', 'base_model.encoder.layer.16.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.19.output.LayerNorm.bias', 'base_model.encoder.layer.0.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.12.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.10.attention.self.key.bias', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.19.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.0.attention.self.query.weight', 'base_model.encoder.layer.23.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.9.attention.self.value.bias', 'base_model.encoder.layer.9.attention.output.LayerNorm.bias', 'base_model.encoder.layer.4.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.14.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.20.attention.output.dense.bias', 'base_model.encoder.layer.9.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.4.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.2.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.21.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.16.output.dense.bias', 'base_model.encoder.layer.5.attention.output.dense.weight', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.13.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.8.output.dense.weight', 'base_model.encoder.layer.3.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.22.attention.self.key.bias', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.0.output.dense.bias', 'base_model.encoder.layer.0.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.19.attention.self.value.weight', 'base_model.encoder.layer.22.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.2.output.LayerNorm.bias', 'base_model.encoder.layer.12.attention.output.LayerNorm.bias', 'base_model.encoder.layer.23.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.6.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.0.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.0.intermediate.dense.bias', 'base_model.encoder.layer.15.attention.self.key.bias', 'base_model.encoder.layer.7.output.LayerNorm.bias', 'base_model.encoder.layer.22.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.6.attention.output.LayerNorm.weight', 'base_model.encoder.layer.7.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.3.output.dense.weight', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.19.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.20.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.3.output.dense.bias', 'base_model.encoder.layer.2.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.15.output.adapters.ep.adapter_down.0.weight', 'qa_outputs.bias', 'base_model.encoder.layer.19.attention.output.LayerNorm.weight', 'base_model.encoder.layer.15.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.4.attention.self.key.weight', 'base_model.encoder.layer.7.attention.output.dense.bias', 'base_model.encoder.layer.0.attention.self.value.weight', 'base_model.encoder.layer.14.output.dense.weight', 'base_model.encoder.layer.21.output.LayerNorm.weight', 'base_model.encoder.layer.16.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.13.attention.output.dense.bias', 'base_model.encoder.layer.17.attention.self.value.weight', 'base_model.encoder.layer.1.attention.self.value.weight', 'base_model.encoder.layer.23.output.dense.weight', 'base_model.encoder.layer.6.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.10.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.12.attention.output.dense.bias', 'base_model.encoder.layer.23.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.15.output.dense.bias', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.10.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.4.attention.self.key.bias', 'base_model.encoder.layer.3.intermediate.dense.bias', 'base_model.encoder.layer.18.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.3.attention.output.LayerNorm.weight', 'base_model.encoder.layer.17.output.dense.bias', 'base_model.encoder.layer.12.attention.self.value.weight', 'base_model.encoder.layer.9.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.10.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.8.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.14.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.14.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.14.output.adapters.tp.adapter_down.0.weight', 'base_model.embeddings.position_ids', 'base_model.encoder.layer.4.output.dense.bias', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.17.attention.output.LayerNorm.bias', 'base_model.encoder.layer.19.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.6.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.9.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.12.output.LayerNorm.bias', 'base_model.encoder.layer.5.output.LayerNorm.weight', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.18.attention.self.query.bias', 'base_model.encoder.layer.22.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.1.attention.output.dense.weight', 'base_model.encoder.layer.16.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.16.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.14.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.9.attention.self.key.weight', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.14.output.dense.bias', 'base_model.encoder.layer.7.attention.output.dense.weight', 'base_model.encoder.layer.2.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.20.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.18.attention.output.dense.weight', 'base_model.encoder.layer.21.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.12.attention.output.LayerNorm.weight', 'base_model.encoder.layer.23.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.20.intermediate.dense.weight', 'base_model.encoder.layer.1.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.6.output.dense.bias', 'base_model.encoder.layer.17.attention.self.query.bias', 'base_model.encoder.layer.19.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.13.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.7.attention.self.key.bias', 'base_model.encoder.layer.20.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.9.output.dense.weight', 'base_model.encoder.layer.12.intermediate.dense.weight', 'base_model.encoder.layer.5.output.dense.bias', 'base_model.encoder.layer.15.attention.self.query.weight', 'base_model.encoder.layer.11.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.15.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.22.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.16.attention.self.query.bias', 'base_model.encoder.layer.22.attention.output.dense.weight', 'base_model.encoder.layer.1.attention.output.dense.bias', 'base_model.encoder.layer.3.attention.output.dense.weight', 'base_model.encoder.layer.6.attention.self.key.bias', 'base_model.encoder.layer.8.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.17.attention.output.dense.bias', 'base_model.encoder.layer.1.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.9.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.6.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.1.attention.self.query.bias', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.0.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.21.attention.output.dense.bias', 'base_model.encoder.layer.22.output.dense.weight', 'base_model.encoder.layer.7.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.1.intermediate.dense.weight', 'base_model.encoder.layer.13.attention.self.key.bias', 'base_model.encoder.layer.18.output.adapters.es.adapter_down.0.weight', 'base_model.embeddings.LayerNorm.bias', 'base_model.encoder.layer.17.output.LayerNorm.weight', 'base_model.encoder.layer.3.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.3.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.22.output.LayerNorm.weight', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.16.attention.output.LayerNorm.weight', 'base_model.encoder.layer.8.output.LayerNorm.weight', 'base_model.encoder.layer.11.attention.output.LayerNorm.weight', 'base_model.encoder.layer.3.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.0.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.18.attention.self.value.bias', 'base_model.encoder.layer.8.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.7.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.0.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.23.output.dense.bias', 'base_model.encoder.layer.23.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.13.attention.output.dense.weight', 'base_model.encoder.layer.15.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.11.attention.self.key.weight', 'base_model.encoder.layer.21.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.22.attention.output.LayerNorm.weight', 'base_model.encoder.layer.7.output.dense.bias', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.19.intermediate.dense.weight', 'base_model.encoder.layer.1.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.9.intermediate.dense.bias', 'base_model.encoder.layer.23.attention.self.value.weight', 'base_model.encoder.layer.17.output.LayerNorm.bias', 'base_model.encoder.layer.20.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.23.attention.self.query.weight', 'base_model.encoder.layer.11.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.4.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.22.output.LayerNorm.bias', 'base_model.encoder.layer.9.attention.output.dense.bias', 'base_model.encoder.layer.13.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.3.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.9.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.7.output.dense.weight', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.20.attention.self.query.weight', 'base_model.encoder.layer.1.attention.self.value.bias', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.9.attention.self.key.bias', 'base_model.encoder.layer.14.intermediate.dense.bias', 'base_model.encoder.layer.6.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.13.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.10.attention.output.LayerNorm.bias', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.5.attention.output.LayerNorm.bias', 'base_model.encoder.layer.9.attention.self.query.weight', 'base_model.encoder.layer.16.attention.output.dense.weight', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.23.attention.self.key.weight', 'base_model.encoder.layer.11.attention.output.dense.weight', 'base_model.encoder.layer.20.attention.self.key.weight', 'base_model.encoder.layer.5.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.3.output.LayerNorm.bias', 'base_model.encoder.layer.14.attention.self.query.weight', 'base_model.encoder.layer.15.attention.output.LayerNorm.weight', 'base_model.encoder.layer.21.output.dense.bias', 'base_model.encoder.layer.13.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.13.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.16.attention.self.value.weight', 'base_model.encoder.layer.11.attention.output.dense.bias', 'base_model.encoder.layer.13.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.18.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.15.attention.self.value.bias', 'base_model.encoder.layer.7.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.0.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.3.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.11.attention.self.query.bias', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.14.attention.self.key.weight', 'base_model.encoder.layer.9.attention.self.query.bias', 'base_model.encoder.layer.12.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.4.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.8.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.11.attention.output.LayerNorm.bias', 'base_model.encoder.layer.5.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.12.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.15.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.21.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.13.attention.self.query.bias', 'base_model.encoder.layer.2.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.4.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.13.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.4.attention.output.LayerNorm.bias', 'base_model.encoder.layer.21.attention.self.key.weight', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.21.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.16.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.19.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.22.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.16.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.9.attention.output.dense.weight', 'base_model.encoder.layer.8.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.12.attention.self.query.bias', 'base_model.encoder.layer.14.attention.self.key.bias', 'base_model.encoder.layer.7.intermediate.dense.bias', 'base_model.encoder.layer.14.attention.self.value.weight', 'base_model.encoder.layer.8.attention.output.LayerNorm.weight', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.6.attention.self.value.bias', 'base_model.encoder.layer.2.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.8.intermediate.dense.weight', 'base_model.encoder.layer.12.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.18.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.21.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.9.attention.output.LayerNorm.weight', 'base_model.encoder.layer.23.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.13.output.LayerNorm.bias', 'base_model.encoder.layer.12.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.10.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.22.attention.output.LayerNorm.bias', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.10.output.LayerNorm.bias', 'base_model.encoder.layer.18.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.11.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.19.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.4.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.15.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.21.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.21.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.7.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.8.attention.self.key.weight', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.16.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.22.attention.self.value.weight', 'base_model.encoder.layer.5.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.11.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.14.attention.output.dense.bias', 'base_model.encoder.layer.19.attention.self.key.weight', 'base_model.encoder.layer.1.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.10.attention.self.key.weight', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.20.attention.output.LayerNorm.weight', 'base_model.encoder.layer.4.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.5.attention.output.LayerNorm.weight', 'base_model.encoder.layer.3.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.11.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.18.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.23.attention.output.LayerNorm.bias', 'base_model.encoder.layer.9.output.LayerNorm.bias', 'base_model.encoder.layer.10.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.17.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.18.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.20.attention.self.value.weight', 'base_model.encoder.layer.0.attention.self.key.bias', 'base_model.encoder.layer.19.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.1.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.14.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.22.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.10.attention.output.dense.bias', 'base_model.encoder.layer.9.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.2.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.5.intermediate.dense.bias', 'base_model.encoder.layer.23.attention.self.value.bias', 'base_model.encoder.layer.18.attention.output.dense.bias', 'base_model.encoder.layer.19.output.LayerNorm.weight', 'base_model.encoder.layer.15.output.LayerNorm.bias', 'base_model.encoder.layer.3.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.14.intermediate.dense.weight', 'base_model.encoder.layer.22.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.8.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.19.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.10.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.1.output.LayerNorm.bias', 'base_model.encoder.layer.2.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.8.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.18.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.19.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.4.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.17.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.6.attention.output.dense.weight', 'base_model.encoder.layer.4.attention.self.query.bias', 'base_model.encoder.layer.22.attention.self.key.weight', 'base_model.encoder.layer.13.output.dense.bias', 'base_model.encoder.layer.12.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.7.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.23.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.11.attention.self.value.bias', 'base_model.encoder.layer.17.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.20.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.3.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.10.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.9.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.21.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.0.attention.output.LayerNorm.bias', 'base_model.encoder.layer.5.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.7.intermediate.dense.weight', 'base_model.encoder.layer.15.attention.self.key.weight', 'base_model.encoder.layer.10.output.LayerNorm.weight', 'base_model.encoder.layer.18.attention.output.LayerNorm.weight', 'base_model.encoder.layer.23.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.21.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.12.output.dense.weight', 'base_model.encoder.layer.9.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.5.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.2.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.4.output.LayerNorm.bias', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.13.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.23.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.20.output.dense.bias', 'base_model.encoder.layer.7.attention.output.LayerNorm.weight', 'base_model.encoder.layer.0.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.0.attention.self.query.bias', 'base_model.encoder.layer.14.attention.self.query.bias', 'base_model.encoder.layer.20.attention.output.LayerNorm.bias', 'base_model.encoder.layer.0.output.dense.weight', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.pooler.dense.bias', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.17.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.12.attention.self.key.weight', 'base_model.encoder.layer.9.attention.self.value.weight', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.20.intermediate.dense.bias', 'base_model.encoder.layer.22.attention.self.value.bias', 'base_model.encoder.layer.15.output.dense.weight', 'base_model.encoder.layer.6.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.11.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.21.attention.self.query.weight', 'base_model.encoder.layer.7.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.16.attention.self.value.bias', 'base_model.encoder.layer.6.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.17.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.9.intermediate.dense.weight', 'base_model.encoder.layer.14.attention.output.LayerNorm.bias', 'base_model.encoder.layer.2.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.1.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.10.output.dense.bias', 'base_model.encoder.layer.15.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.4.attention.output.LayerNorm.weight', 'base_model.encoder.layer.14.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.17.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.7.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.17.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.8.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.5.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.9.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.5.output.dense.weight', 'base_model.encoder.layer.14.attention.self.value.bias', 'base_model.encoder.layer.14.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.11.attention.self.key.bias', 'base_model.encoder.layer.20.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.5.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.16.output.LayerNorm.weight', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.8.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.16.output.dense.weight', 'base_model.encoder.layer.6.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.5.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.11.output.dense.weight', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.13.output.LayerNorm.weight', 'base_model.encoder.layer.18.attention.self.key.weight', 'base_model.encoder.layer.10.attention.output.dense.weight', 'base_model.encoder.layer.14.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.15.intermediate.dense.weight', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.3.attention.output.LayerNorm.bias', 'base_model.encoder.layer.8.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.23.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.12.attention.self.key.bias', 'base_model.encoder.layer.19.attention.output.dense.bias', 'base_model.encoder.layer.6.attention.output.LayerNorm.bias', 'base_model.encoder.layer.19.attention.output.LayerNorm.bias', 'base_model.encoder.layer.3.attention.self.value.weight', 'base_model.encoder.layer.23.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.15.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.18.attention.self.query.weight', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.2.output.dense.weight', 'base_model.encoder.layer.8.attention.self.key.bias', 'base_model.encoder.layer.15.attention.output.dense.weight', 'base_model.encoder.layer.11.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.17.attention.output.LayerNorm.weight', 'base_model.encoder.layer.2.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.3.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.8.attention.output.LayerNorm.bias', 'base_model.encoder.layer.4.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.6.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.7.output.adapters.ts.adapter_down.0.bias', 'qa_outputs.weight', 'base_model.encoder.layer.2.attention.output.LayerNorm.bias', 'base_model.encoder.layer.17.attention.self.key.bias', 'base_model.encoder.layer.0.attention.self.value.bias', 'base_model.encoder.layer.16.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.3.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.11.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.23.intermediate.dense.bias', 'base_model.encoder.layer.15.intermediate.dense.bias', 'base_model.encoder.layer.21.output.LayerNorm.bias', 'base_model.encoder.layer.8.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.17.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.18.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.20.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.2.output.dense.bias', 'base_model.encoder.layer.23.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.12.output.dense.bias', 'base_model.encoder.layer.5.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.5.output.LayerNorm.bias', 'base_model.encoder.layer.21.intermediate.dense.weight', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.10.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.21.attention.self.key.bias', 'base_model.encoder.layer.16.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.21.attention.output.LayerNorm.weight', 'base_model.encoder.layer.12.attention.output.dense.weight', 'base_model.encoder.layer.6.attention.self.query.bias', 'base_model.encoder.layer.17.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.17.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.14.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.0.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.2.intermediate.dense.bias', 'base_model.encoder.layer.23.attention.self.key.bias', 'base_model.encoder.layer.22.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.19.attention.self.query.bias', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.16.attention.self.key.bias', 'base_model.encoder.layer.13.attention.output.LayerNorm.bias', 'base_model.encoder.layer.18.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.2.output.LayerNorm.weight', 'base_model.encoder.layer.19.output.dense.bias', 'base_model.encoder.layer.11.intermediate.dense.weight', 'base_model.encoder.layer.12.intermediate.dense.bias', 'base_model.encoder.layer.12.attention.self.query.weight', 'base_model.encoder.layer.15.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.4.attention.self.value.weight', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.0.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.17.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.12.attention.self.value.bias', 'base_model.encoder.layer.2.attention.self.query.bias', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.18.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.23.output.LayerNorm.bias', 'base_model.encoder.layer.1.attention.self.query.weight', 'base_model.encoder.layer.10.attention.self.query.bias', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.8.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.2.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.5.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.10.attention.self.value.bias', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.10.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.21.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.12.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.7.attention.self.value.weight', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.17.attention.self.key.weight', 'base_model.encoder.layer.19.attention.self.key.bias', 'base_model.encoder.layer.6.intermediate.dense.bias', 'base_model.encoder.layer.2.attention.output.dense.weight', 'base_model.encoder.layer.19.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.6.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.3.attention.self.key.weight', 'base_model.encoder.layer.12.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.11.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.3.attention.self.query.bias', 'base_model.encoder.layer.11.attention.self.query.weight', 'base_model.encoder.layer.22.intermediate.dense.bias', 'base_model.encoder.layer.2.attention.self.key.bias', 'base_model.encoder.layer.10.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.17.attention.self.query.weight', 'base_model.encoder.layer.23.attention.output.dense.weight', 'base_model.encoder.layer.17.attention.output.dense.weight', 'base_model.encoder.layer.13.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.1.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.4.output.dense.weight', 'base_model.encoder.layer.21.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.4.intermediate.dense.bias', 'base_model.encoder.layer.1.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.13.attention.self.query.weight', 'base_model.encoder.layer.1.output.LayerNorm.weight', 'base_model.encoder.layer.15.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.6.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.9.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.0.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.2.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.6.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.21.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.13.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.4.attention.output.dense.weight', 'base_model.encoder.layer.14.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.5.attention.self.value.bias', 'base_model.encoder.layer.15.output.LayerNorm.weight', 'base_model.encoder.layer.2.attention.self.value.weight', 'base_model.encoder.layer.13.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.5.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.3.intermediate.dense.weight', 'base_model.encoder.layer.5.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.20.output.LayerNorm.weight', 'base_model.encoder.layer.8.attention.self.value.weight', 'base_model.encoder.layer.10.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.17.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.21.attention.self.value.weight', 'base_model.encoder.layer.19.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.13.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.1.attention.output.LayerNorm.bias', 'base_model.encoder.layer.18.intermediate.dense.bias', 'base_model.encoder.layer.11.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.16.output.LayerNorm.bias', 'base_model.encoder.layer.18.output.LayerNorm.bias', 'base_model.encoder.layer.21.attention.output.LayerNorm.bias', 'base_model.encoder.layer.5.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.6.attention.self.key.weight', 'base_model.encoder.layer.5.attention.self.value.weight', 'base_model.encoder.layer.16.intermediate.dense.bias', 'base_model.pooler.dense.weight', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.19.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.1.attention.self.key.weight', 'base_model.encoder.layer.1.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.5.attention.output.dense.bias', 'base_model.encoder.layer.16.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.14.attention.output.dense.weight', 'base_model.encoder.layer.19.output.dense.weight', 'base_model.encoder.layer.5.attention.self.query.bias', 'base_model.encoder.layer.21.attention.self.value.bias', 'base_model.encoder.layer.9.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.15.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.5.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.14.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.11.attention.self.value.weight', 'base_model.encoder.layer.22.attention.self.query.weight', 'base_model.encoder.layer.8.attention.self.query.bias', 'base_model.encoder.layer.22.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.10.attention.output.LayerNorm.weight', 'base_model.encoder.layer.19.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.21.intermediate.dense.bias', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.17.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.20.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.10.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.14.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.22.attention.output.dense.bias', 'base_model.encoder.layer.18.intermediate.dense.weight', 'base_model.encoder.layer.1.output.dense.bias', 'base_model.encoder.layer.2.attention.output.dense.bias', 'base_model.encoder.layer.6.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.2.attention.self.value.bias', 'base_model.encoder.layer.23.attention.output.LayerNorm.weight', 'base_model.encoder.layer.15.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.20.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.8.output.LayerNorm.bias', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.1.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.10.attention.self.value.weight', 'base_model.encoder.layer.18.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.14.output.LayerNorm.bias']
- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of XLMRobertaModel were not initialized from the model checkpoint at /cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//tydiqa/xlm-KG_LR8e-6_EPOCH2.0_maxlen384_batchsize4_gradacc4 and are newly initialized: ['encoder.layer.7.attention.output.dense.bias', 'encoder.layer.17.output.dense.weight', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.7.attention.output.LayerNorm.bias', 'encoder.layer.8.attention.self.value.bias', 'encoder.layer.0.attention.self.value.weight', 'encoder.layer.5.output.dense.weight', 'encoder.layer.12.attention.output.LayerNorm.weight', 'encoder.layer.12.output.dense.weight', 'encoder.layer.7.intermediate.dense.bias', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.18.attention.output.LayerNorm.bias', 'encoder.layer.5.attention.self.key.weight', 'encoder.layer.22.attention.self.value.weight', 'encoder.layer.17.attention.output.LayerNorm.weight', 'encoder.layer.7.attention.self.key.weight', 'encoder.layer.18.attention.output.LayerNorm.weight', 'encoder.layer.3.attention.output.dense.weight', 'encoder.layer.0.attention.self.key.bias', 'encoder.layer.0.attention.self.query.bias', 'encoder.layer.9.attention.self.key.weight', 'encoder.layer.12.intermediate.dense.weight', 'encoder.layer.1.attention.self.key.bias', 'encoder.layer.18.output.dense.bias', 'encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.21.intermediate.dense.bias', 'encoder.layer.3.output.dense.bias', 'encoder.layer.13.attention.output.dense.bias', 'encoder.layer.11.attention.self.value.weight', 'encoder.layer.19.attention.self.key.bias', 'embeddings.position_embeddings.weight', 'encoder.layer.16.intermediate.dense.weight', 'encoder.layer.23.attention.self.key.weight', 'encoder.layer.23.output.LayerNorm.bias', 'encoder.layer.23.output.dense.bias', 'encoder.layer.22.output.LayerNorm.weight', 'encoder.layer.12.attention.output.dense.weight', 'encoder.layer.15.output.dense.weight', 'encoder.layer.13.output.dense.bias', 'encoder.layer.21.attention.output.LayerNorm.bias', 'encoder.layer.22.intermediate.dense.weight', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.6.attention.output.dense.bias', 'encoder.layer.16.attention.output.LayerNorm.weight', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.3.attention.self.query.weight', 'encoder.layer.23.attention.self.query.bias', 'encoder.layer.11.output.LayerNorm.bias', 'encoder.layer.16.attention.output.LayerNorm.bias', 'encoder.layer.12.attention.output.LayerNorm.bias', 'embeddings.LayerNorm.weight', 'encoder.layer.23.attention.output.LayerNorm.bias', 'encoder.layer.10.intermediate.dense.weight', 'encoder.layer.11.attention.output.dense.weight', 'encoder.layer.19.intermediate.dense.bias', 'encoder.layer.15.attention.self.query.bias', 'encoder.layer.10.attention.output.dense.bias', 'encoder.layer.18.attention.output.dense.bias', 'encoder.layer.0.attention.self.query.weight', 'encoder.layer.3.attention.self.value.bias', 'encoder.layer.18.attention.self.key.bias', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.10.output.dense.weight', 'encoder.layer.17.intermediate.dense.weight', 'encoder.layer.6.output.dense.weight', 'encoder.layer.10.output.dense.bias', 'encoder.layer.23.output.LayerNorm.weight', 'encoder.layer.17.output.LayerNorm.bias', 'encoder.layer.22.intermediate.dense.bias', 'encoder.layer.12.attention.self.query.weight', 'encoder.layer.10.attention.self.query.bias', 'encoder.layer.6.attention.output.LayerNorm.weight', 'encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.layer.14.attention.output.dense.bias', 'encoder.layer.17.intermediate.dense.bias', 'encoder.layer.14.output.LayerNorm.bias', 'encoder.layer.16.attention.self.value.bias', 'encoder.layer.13.intermediate.dense.weight', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.14.attention.self.query.bias', 'encoder.layer.22.output.dense.weight', 'encoder.layer.8.attention.self.key.weight', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.20.attention.output.LayerNorm.bias', 'encoder.layer.6.output.dense.bias', 'encoder.layer.11.output.LayerNorm.weight', 'encoder.layer.13.output.dense.weight', 'encoder.layer.22.attention.self.query.weight', 'encoder.layer.16.attention.self.query.weight', 'encoder.layer.1.attention.output.dense.bias', 'encoder.layer.23.intermediate.dense.bias', 'encoder.layer.9.attention.self.value.bias', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.17.output.LayerNorm.weight', 'encoder.layer.15.attention.output.LayerNorm.bias', 'encoder.layer.13.attention.self.value.weight', 'encoder.layer.5.attention.self.query.bias', 'encoder.layer.12.attention.self.key.weight', 'encoder.layer.8.output.LayerNorm.weight', 'encoder.layer.11.attention.output.dense.bias', 'encoder.layer.10.output.LayerNorm.bias', 'encoder.layer.2.attention.self.value.bias', 'encoder.layer.8.attention.self.query.bias', 'encoder.layer.15.attention.self.query.weight', 'encoder.layer.1.attention.output.dense.weight', 'encoder.layer.20.attention.output.dense.weight', 'encoder.layer.10.attention.self.key.bias', 'encoder.layer.15.intermediate.dense.weight', 'encoder.layer.7.output.dense.weight', 'encoder.layer.12.intermediate.dense.bias', 'encoder.layer.13.attention.self.query.weight', 'encoder.layer.22.attention.output.dense.bias', 'encoder.layer.0.attention.output.dense.bias', 'encoder.layer.17.attention.output.LayerNorm.bias', 'encoder.layer.10.attention.self.query.weight', 'encoder.layer.23.attention.self.key.bias', 'pooler.dense.bias', 'encoder.layer.3.attention.output.dense.bias', 'encoder.layer.12.output.LayerNorm.bias', 'encoder.layer.19.output.LayerNorm.weight', 'encoder.layer.11.attention.self.key.weight', 'embeddings.LayerNorm.bias', 'encoder.layer.22.attention.self.value.bias', 'encoder.layer.13.attention.output.LayerNorm.weight', 'encoder.layer.5.attention.output.dense.bias', 'encoder.layer.7.output.LayerNorm.bias', 'encoder.layer.21.attention.output.LayerNorm.weight', 'encoder.layer.15.attention.output.dense.weight', 'encoder.layer.9.attention.output.dense.bias', 'encoder.layer.13.output.LayerNorm.bias', 'encoder.layer.7.attention.self.value.weight', 'encoder.layer.7.attention.output.LayerNorm.weight', 'encoder.layer.4.attention.self.value.weight', 'encoder.layer.20.attention.self.value.weight', 'encoder.layer.0.attention.output.LayerNorm.weight', 'encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.layer.20.intermediate.dense.weight', 'encoder.layer.1.output.dense.bias', 'encoder.layer.4.output.dense.weight', 'encoder.layer.18.attention.self.value.weight', 'encoder.layer.19.attention.self.query.bias', 'encoder.layer.16.output.LayerNorm.bias', 'encoder.layer.19.output.dense.weight', 'encoder.layer.20.output.LayerNorm.weight', 'encoder.layer.23.attention.output.dense.weight', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.18.attention.self.value.bias', 'encoder.layer.11.output.dense.bias', 'encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.layer.12.output.LayerNorm.weight', 'encoder.layer.10.attention.output.LayerNorm.weight', 'encoder.layer.6.attention.self.key.bias', 'encoder.layer.12.attention.output.dense.bias', 'encoder.layer.8.attention.self.value.weight', 'encoder.layer.14.attention.self.value.weight', 'encoder.layer.4.attention.output.dense.weight', 'encoder.layer.12.attention.self.query.bias', 'encoder.layer.3.attention.self.query.bias', 'encoder.layer.15.attention.output.LayerNorm.weight', 'encoder.layer.8.attention.output.dense.weight', 'encoder.layer.19.attention.self.key.weight', 'encoder.layer.17.output.dense.bias', 'encoder.layer.15.output.dense.bias', 'encoder.layer.0.output.LayerNorm.weight', 'embeddings.word_embeddings.weight', 'encoder.layer.16.intermediate.dense.bias', 'encoder.layer.13.attention.output.dense.weight', 'encoder.layer.10.attention.self.value.bias', 'encoder.layer.7.attention.self.value.bias', 'encoder.layer.5.attention.self.key.bias', 'encoder.layer.1.attention.self.value.bias', 'encoder.layer.8.output.dense.weight', 'encoder.layer.15.attention.output.dense.bias', 'encoder.layer.14.attention.output.dense.weight', 'encoder.layer.10.attention.self.value.weight', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.23.attention.self.value.weight', 'encoder.layer.4.attention.output.LayerNorm.weight', 'encoder.layer.2.attention.self.query.bias', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.19.attention.output.LayerNorm.weight', 'encoder.layer.17.attention.output.dense.bias', 'encoder.layer.4.attention.output.LayerNorm.bias', 'encoder.layer.12.attention.self.value.weight', 'encoder.layer.21.attention.self.query.bias', 'encoder.layer.2.output.dense.bias', 'encoder.layer.18.attention.self.query.bias', 'encoder.layer.18.attention.output.dense.weight', 'encoder.layer.18.attention.self.key.weight', 'encoder.layer.21.output.LayerNorm.weight', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.9.attention.self.query.bias', 'encoder.layer.13.attention.self.key.weight', 'encoder.layer.2.attention.output.dense.bias', 'encoder.layer.7.output.dense.bias', 'encoder.layer.18.intermediate.dense.weight', 'encoder.layer.23.attention.output.LayerNorm.weight', 'encoder.layer.7.output.LayerNorm.weight', 'encoder.layer.20.attention.output.LayerNorm.weight', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.12.attention.self.key.bias', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.16.attention.output.dense.weight', 'encoder.layer.2.attention.output.dense.weight', 'encoder.layer.0.output.dense.bias', 'encoder.layer.9.output.LayerNorm.bias', 'encoder.layer.14.attention.self.value.bias', 'encoder.layer.1.output.dense.weight', 'encoder.layer.2.attention.self.value.weight', 'encoder.layer.12.output.dense.bias', 'encoder.layer.20.attention.output.dense.bias', 'encoder.layer.10.output.LayerNorm.weight', 'encoder.layer.14.attention.output.LayerNorm.weight', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.14.output.dense.weight', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.9.attention.self.value.weight', 'encoder.layer.6.attention.output.dense.weight', 'encoder.layer.16.attention.self.query.bias', 'encoder.layer.21.attention.output.dense.weight', 'encoder.layer.13.attention.self.key.bias', 'encoder.layer.8.attention.self.query.weight', 'encoder.layer.6.attention.output.LayerNorm.bias', 'encoder.layer.22.attention.output.dense.weight', 'encoder.layer.23.attention.output.dense.bias', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.22.attention.self.key.weight', 'encoder.layer.12.attention.self.value.bias', 'encoder.layer.1.attention.output.LayerNorm.weight', 'encoder.layer.0.attention.self.key.weight', 'encoder.layer.6.attention.self.query.bias', 'encoder.layer.9.attention.self.key.bias', 'encoder.layer.10.attention.output.LayerNorm.bias', 'encoder.layer.18.output.LayerNorm.bias', 'encoder.layer.4.attention.self.key.bias', 'encoder.layer.9.output.dense.weight', 'encoder.layer.2.attention.output.LayerNorm.bias', 'embeddings.token_type_embeddings.weight', 'encoder.layer.8.attention.output.dense.bias', 'encoder.layer.17.attention.self.key.bias', 'encoder.layer.22.attention.output.LayerNorm.bias', 'encoder.layer.21.attention.self.value.bias', 'encoder.layer.20.attention.self.query.weight', 'encoder.layer.9.attention.output.LayerNorm.weight', 'encoder.layer.14.output.LayerNorm.weight', 'encoder.layer.3.attention.self.key.weight', 'encoder.layer.0.output.dense.weight', 'encoder.layer.2.output.dense.weight', 'encoder.layer.15.output.LayerNorm.weight', 'encoder.layer.4.attention.output.dense.bias', 'encoder.layer.8.output.dense.bias', 'encoder.layer.20.attention.self.key.bias', 'encoder.layer.20.intermediate.dense.bias', 'encoder.layer.22.attention.output.LayerNorm.weight', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.15.attention.self.key.bias', 'encoder.layer.18.intermediate.dense.bias', 'encoder.layer.9.output.dense.bias', 'encoder.layer.10.attention.output.dense.weight', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.7.attention.self.query.bias', 'encoder.layer.20.output.dense.bias', 'encoder.layer.4.attention.self.query.weight', 'encoder.layer.6.attention.self.query.weight', 'encoder.layer.4.attention.self.key.weight', 'encoder.layer.21.attention.self.key.weight', 'encoder.layer.19.attention.self.query.weight', 'encoder.layer.19.attention.self.value.weight', 'encoder.layer.17.attention.self.query.weight', 'encoder.layer.21.output.LayerNorm.bias', 'encoder.layer.13.attention.self.query.bias', 'encoder.layer.0.attention.output.dense.weight', 'encoder.layer.0.attention.self.value.bias', 'encoder.layer.20.attention.self.value.bias', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.layer.16.attention.self.key.weight', 'encoder.layer.9.attention.self.query.weight', 'encoder.layer.13.intermediate.dense.bias', 'encoder.layer.22.attention.self.key.bias', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.17.attention.self.query.bias', 'encoder.layer.21.output.dense.weight', 'encoder.layer.5.attention.self.value.bias', 'pooler.dense.weight', 'encoder.layer.18.attention.self.query.weight', 'encoder.layer.14.intermediate.dense.weight', 'encoder.layer.5.attention.self.query.weight', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.9.output.LayerNorm.weight', 'encoder.layer.21.intermediate.dense.weight', 'encoder.layer.15.attention.self.value.bias', 'encoder.layer.17.attention.self.value.weight', 'encoder.layer.23.output.dense.weight', 'encoder.layer.16.attention.output.dense.bias', 'encoder.layer.10.attention.self.key.weight', 'encoder.layer.2.attention.self.query.weight', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.23.attention.self.value.bias', 'encoder.layer.16.output.dense.weight', 'encoder.layer.23.attention.self.query.weight', 'encoder.layer.16.output.LayerNorm.weight', 'encoder.layer.1.attention.self.query.weight', 'encoder.layer.6.output.LayerNorm.bias', 'encoder.layer.2.attention.self.key.weight', 'encoder.layer.15.attention.self.value.weight', 'encoder.layer.9.attention.output.LayerNorm.bias', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.16.attention.self.value.weight', 'encoder.layer.4.output.dense.bias', 'encoder.layer.5.output.LayerNorm.bias', 'encoder.layer.14.attention.self.key.weight', 'encoder.layer.15.intermediate.dense.bias', 'encoder.layer.7.attention.self.key.bias', 'encoder.layer.11.attention.self.query.bias', 'encoder.layer.17.attention.self.key.weight', 'encoder.layer.7.attention.self.query.weight', 'encoder.layer.4.attention.self.value.bias', 'encoder.layer.20.attention.self.key.weight', 'encoder.layer.21.output.dense.bias', 'encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.layer.15.attention.self.key.weight', 'encoder.layer.6.attention.self.key.weight', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.5.attention.self.value.weight', 'encoder.layer.22.output.LayerNorm.bias', 'encoder.layer.11.attention.output.LayerNorm.weight', 'encoder.layer.6.attention.self.value.weight', 'encoder.layer.8.attention.output.LayerNorm.weight', 'encoder.layer.11.attention.self.key.bias', 'encoder.layer.23.intermediate.dense.weight', 'encoder.layer.21.attention.self.value.weight', 'encoder.layer.11.attention.self.value.bias', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.1.attention.self.key.weight', 'encoder.layer.19.attention.output.LayerNorm.bias', 'encoder.layer.22.output.dense.bias', 'encoder.layer.14.output.dense.bias', 'encoder.layer.14.attention.self.key.bias', 'encoder.layer.5.output.dense.bias', 'encoder.layer.11.output.dense.weight', 'encoder.layer.2.attention.self.key.bias', 'encoder.layer.1.attention.self.value.weight', 'encoder.layer.5.attention.output.LayerNorm.weight', 'encoder.layer.20.output.dense.weight', 'encoder.layer.5.attention.output.dense.weight', 'encoder.layer.19.output.LayerNorm.bias', 'encoder.layer.14.attention.output.LayerNorm.bias', 'encoder.layer.7.attention.output.dense.weight', 'encoder.layer.8.attention.self.key.bias', 'encoder.layer.11.attention.self.query.weight', 'encoder.layer.21.attention.self.key.bias', 'encoder.layer.13.output.LayerNorm.weight', 'encoder.layer.3.output.dense.weight', 'encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.layer.14.intermediate.dense.bias', 'encoder.layer.22.attention.self.query.bias', 'encoder.layer.19.intermediate.dense.weight', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.16.output.dense.bias', 'encoder.layer.15.output.LayerNorm.bias', 'encoder.layer.13.attention.output.LayerNorm.bias', 'encoder.layer.17.attention.self.value.bias', 'encoder.layer.8.attention.output.LayerNorm.bias', 'encoder.layer.13.attention.self.value.bias', 'encoder.layer.20.attention.self.query.bias', 'encoder.layer.8.output.LayerNorm.bias', 'encoder.layer.9.attention.output.dense.weight', 'encoder.layer.18.output.LayerNorm.weight', 'encoder.layer.1.attention.self.query.bias', 'encoder.layer.2.attention.output.LayerNorm.weight', 'encoder.layer.17.attention.output.dense.weight', 'encoder.layer.18.output.dense.weight', 'encoder.layer.3.attention.self.value.weight', 'encoder.layer.21.attention.self.query.weight', 'encoder.layer.21.attention.output.dense.bias', 'encoder.layer.19.attention.output.dense.bias', 'encoder.layer.20.output.LayerNorm.bias', 'encoder.layer.14.attention.self.query.weight', 'encoder.layer.19.output.dense.bias', 'encoder.layer.6.attention.self.value.bias', 'encoder.layer.3.attention.self.key.bias', 'encoder.layer.16.attention.self.key.bias', 'encoder.layer.19.attention.self.value.bias', 'encoder.layer.19.attention.output.dense.weight', 'encoder.layer.4.attention.self.query.bias', 'encoder.layer.3.output.LayerNorm.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Overwriting existing adapter 'ep'.
Overwriting existing adapter 'tp'.
Overwriting existing adapter 'es'.
Overwriting existing adapter 'ts'.
Overwriting existing adapter fusion module 'ep,tp,es,ts'
05/09/2022 22:48:47 - INFO - __main__ -   lang2id = None
05/09/2022 22:48:50 - INFO - __main__ -   Training/evaluation parameters Namespace(adam_epsilon=1e-08, cache_dir='', config_name='', data_dir=None, device=device(type='cuda'), do_eval=True, do_lower_case=False, do_train=False, doc_stride=128, eval_all_checkpoints=False, eval_lang='en', evaluate_during_training=False, fp16=False, fp16_opt_level='O1', gradient_accumulation_steps=1, learning_rate=5e-05, local_rank=-1, logging_steps=50, max_answer_length=30, max_grad_norm=1.0, max_query_length=64, max_seq_length=384, max_steps=-1, model_name='xlm-KG', model_name_or_path='/cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//tydiqa/xlm-KG_LR8e-6_EPOCH2.0_maxlen384_batchsize4_gradacc4', model_type='xlm', modelkg_dir='/cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/adapter/xlmr_adapter', n_best_size=20, n_gpu=1, no_cuda=False, null_score_diff_threshold=0.0, num_train_epochs=3.0, output_dir='/cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//tydiqa/xlm-KG_LR8e-6_EPOCH2.0_maxlen384_batchsize4_gradacc4/predictions/tydiqa/', overwrite_cache=False, overwrite_output_dir=False, per_gpu_eval_batch_size=8, per_gpu_train_batch_size=8, predict_file='/cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/download//tydiqa//tydiqa-goldp-v1.1-dev/tydiqa.goldp.en.dev.json', save_steps=50, seed=42, server_ip='', server_port='', threads=1, tokenizer_name='', train_file=None, train_lang='en', verbose_logging=False, version_2_with_negative=False, warmup_steps=0, weight_decay=0.0)
05/09/2022 22:48:50 - INFO - __main__ -   Loading checkpoint /cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//tydiqa/xlm-KG_LR8e-6_EPOCH2.0_maxlen384_batchsize4_gradacc4 for evaluation
05/09/2022 22:48:50 - INFO - __main__ -   Evaluate the following checkpoints: ['/cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//tydiqa/xlm-KG_LR8e-6_EPOCH2.0_maxlen384_batchsize4_gradacc4']
Some weights of the model checkpoint at /cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//tydiqa/xlm-KG_LR8e-6_EPOCH2.0_maxlen384_batchsize4_gradacc4 were not used when initializing XLMRobertaModel: ['base_model.encoder.layer.20.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.13.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.11.output.dense.bias', 'base_model.encoder.layer.16.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.0.attention.output.LayerNorm.weight', 'base_model.encoder.layer.2.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.3.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.2.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.18.attention.self.key.bias', 'base_model.encoder.layer.6.output.LayerNorm.bias', 'base_model.encoder.layer.0.attention.self.key.weight', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.21.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.2.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.7.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.13.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.15.attention.self.query.bias', 'base_model.encoder.layer.14.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.19.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.21.attention.output.dense.weight', 'base_model.encoder.layer.0.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.20.output.dense.weight', 'base_model.encoder.layer.20.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.1.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.11.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.16.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.4.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.6.attention.output.dense.bias', 'base_model.encoder.layer.1.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.20.attention.output.dense.weight', 'base_model.encoder.layer.13.intermediate.dense.bias', 'base_model.encoder.layer.17.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.4.attention.output.dense.bias', 'base_model.encoder.layer.16.attention.output.dense.bias', 'base_model.encoder.layer.12.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.0.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.9.output.LayerNorm.weight', 'base_model.encoder.layer.3.output.LayerNorm.weight', 'base_model.encoder.layer.9.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.21.output.dense.weight', 'base_model.encoder.layer.1.attention.output.LayerNorm.weight', 'base_model.encoder.layer.10.intermediate.dense.bias', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.13.attention.output.LayerNorm.weight', 'base_model.encoder.layer.15.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.9.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.14.attention.output.LayerNorm.weight', 'base_model.encoder.layer.16.attention.self.query.weight', 'base_model.encoder.layer.23.attention.output.dense.bias', 'base_model.encoder.layer.4.intermediate.dense.weight', 'base_model.encoder.layer.5.attention.self.query.weight', 'base_model.encoder.layer.5.attention.self.key.weight', 'base_model.encoder.layer.8.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.9.output.dense.bias', 'base_model.encoder.layer.12.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.8.attention.output.dense.weight', 'base_model.encoder.layer.20.attention.self.query.bias', 'base_model.encoder.layer.22.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.9.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.23.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.11.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.22.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.10.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.2.output.adapters.ep.adapter_down.0.weight', 'base_model.embeddings.word_embeddings.weight', 'base_model.encoder.layer.18.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.23.output.LayerNorm.weight', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.0.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.3.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.1.attention.self.key.bias', 'base_model.encoder.layer.12.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.12.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.13.attention.self.value.weight', 'base_model.encoder.layer.16.attention.output.LayerNorm.bias', 'base_model.encoder.layer.22.intermediate.dense.weight', 'base_model.encoder.layer.20.attention.self.key.bias', 'base_model.encoder.layer.22.attention.self.query.bias', 'base_model.encoder.layer.3.attention.self.query.weight', 'base_model.encoder.layer.3.attention.self.key.bias', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.15.attention.self.value.weight', 'base_model.encoder.layer.5.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.11.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.7.output.LayerNorm.weight', 'base_model.encoder.layer.8.attention.self.value.bias', 'base_model.encoder.layer.12.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.16.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.15.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.8.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.18.attention.output.LayerNorm.bias', 'base_model.encoder.layer.6.intermediate.dense.weight', 'base_model.encoder.layer.22.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.10.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.7.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.15.attention.output.dense.bias', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.21.attention.self.query.bias', 'base_model.encoder.layer.2.attention.output.LayerNorm.weight', 'base_model.encoder.layer.7.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.1.intermediate.dense.bias', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.6.attention.self.value.weight', 'base_model.encoder.layer.3.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.4.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.7.attention.self.query.bias', 'base_model.encoder.layer.11.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.10.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.10.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.21.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.12.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.2.intermediate.dense.weight', 'base_model.encoder.layer.6.output.LayerNorm.weight', 'base_model.encoder.layer.1.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.13.intermediate.dense.weight', 'base_model.encoder.layer.0.intermediate.dense.weight', 'base_model.encoder.layer.19.attention.output.dense.weight', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.17.attention.self.value.bias', 'base_model.encoder.layer.23.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.17.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.0.attention.output.dense.weight', 'base_model.encoder.layer.1.output.dense.weight', 'base_model.encoder.layer.20.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.3.attention.self.value.bias', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.5.attention.self.key.bias', 'base_model.encoder.layer.0.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.7.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.1.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.23.intermediate.dense.weight', 'base_model.embeddings.position_embeddings.weight', 'base_model.encoder.layer.8.attention.self.query.weight', 'base_model.encoder.layer.12.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.16.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.0.output.LayerNorm.bias', 'base_model.encoder.layer.7.attention.self.value.bias', 'base_model.encoder.layer.7.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.19.attention.self.query.weight', 'base_model.encoder.layer.22.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.11.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.19.attention.self.value.bias', 'base_model.encoder.layer.14.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.17.output.dense.weight', 'base_model.encoder.layer.13.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.17.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.5.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.11.intermediate.dense.bias', 'base_model.encoder.layer.10.output.dense.weight', 'base_model.encoder.layer.11.output.LayerNorm.weight', 'base_model.encoder.layer.10.intermediate.dense.weight', 'base_model.encoder.layer.15.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.12.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.16.intermediate.dense.weight', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.0.attention.output.dense.bias', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.0.output.LayerNorm.weight', 'base_model.encoder.layer.23.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.8.intermediate.dense.bias', 'base_model.encoder.layer.22.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.12.output.LayerNorm.weight', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.15.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.6.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.8.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.0.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.9.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.10.attention.self.query.weight', 'base_model.encoder.layer.7.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.7.attention.self.key.weight', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.19.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.4.output.LayerNorm.weight', 'base_model.encoder.layer.15.attention.output.LayerNorm.bias', 'base_model.encoder.layer.6.attention.self.query.weight', 'base_model.encoder.layer.22.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.20.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.19.intermediate.dense.bias', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.20.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.20.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.5.intermediate.dense.weight', 'base_model.encoder.layer.13.attention.self.key.weight', 'base_model.encoder.layer.17.intermediate.dense.weight', 'base_model.encoder.layer.11.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.18.output.dense.weight', 'base_model.encoder.layer.4.attention.self.value.bias', 'base_model.encoder.layer.4.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.4.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.18.output.dense.bias', 'base_model.encoder.layer.1.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.1.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.4.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.6.output.dense.weight', 'base_model.encoder.layer.16.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.11.output.LayerNorm.bias', 'base_model.encoder.layer.18.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.13.attention.self.value.bias', 'base_model.encoder.layer.2.attention.self.key.weight', 'base_model.encoder.layer.18.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.18.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.18.output.LayerNorm.weight', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.17.intermediate.dense.bias', 'base_model.encoder.layer.3.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.7.attention.self.query.weight', 'base_model.encoder.layer.4.attention.self.query.weight', 'base_model.encoder.layer.3.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.8.output.dense.bias', 'base_model.encoder.layer.3.attention.output.dense.bias', 'base_model.encoder.layer.7.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.13.output.dense.weight', 'base_model.encoder.layer.19.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.16.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.20.attention.self.value.bias', 'base_model.encoder.layer.23.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.4.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.6.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.6.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.14.output.LayerNorm.weight', 'base_model.encoder.layer.23.attention.self.query.bias', 'base_model.embeddings.LayerNorm.weight', 'base_model.encoder.layer.22.output.dense.bias', 'base_model.encoder.layer.8.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.20.output.LayerNorm.bias', 'base_model.encoder.layer.22.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.21.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.2.attention.self.query.weight', 'base_model.encoder.layer.9.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.14.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.18.attention.self.value.weight', 'base_model.encoder.layer.16.attention.self.key.weight', 'base_model.encoder.layer.4.output.adapters.ep.adapter_down.0.bias', 'base_model.embeddings.token_type_embeddings.weight', 'base_model.encoder.layer.8.attention.output.dense.bias', 'base_model.encoder.layer.20.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.7.attention.output.LayerNorm.bias', 'base_model.encoder.layer.16.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.19.output.LayerNorm.bias', 'base_model.encoder.layer.0.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.12.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.10.attention.self.key.bias', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.19.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.0.attention.self.query.weight', 'base_model.encoder.layer.23.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.9.attention.self.value.bias', 'base_model.encoder.layer.9.attention.output.LayerNorm.bias', 'base_model.encoder.layer.4.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.14.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.20.attention.output.dense.bias', 'base_model.encoder.layer.9.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.4.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.2.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.21.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.16.output.dense.bias', 'base_model.encoder.layer.5.attention.output.dense.weight', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.13.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.8.output.dense.weight', 'base_model.encoder.layer.3.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.22.attention.self.key.bias', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.0.output.dense.bias', 'base_model.encoder.layer.0.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.19.attention.self.value.weight', 'base_model.encoder.layer.22.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.2.output.LayerNorm.bias', 'base_model.encoder.layer.12.attention.output.LayerNorm.bias', 'base_model.encoder.layer.23.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.6.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.0.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.0.intermediate.dense.bias', 'base_model.encoder.layer.15.attention.self.key.bias', 'base_model.encoder.layer.7.output.LayerNorm.bias', 'base_model.encoder.layer.22.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.6.attention.output.LayerNorm.weight', 'base_model.encoder.layer.7.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.3.output.dense.weight', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.19.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.20.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.3.output.dense.bias', 'base_model.encoder.layer.2.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.15.output.adapters.ep.adapter_down.0.weight', 'qa_outputs.bias', 'base_model.encoder.layer.19.attention.output.LayerNorm.weight', 'base_model.encoder.layer.15.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.4.attention.self.key.weight', 'base_model.encoder.layer.7.attention.output.dense.bias', 'base_model.encoder.layer.0.attention.self.value.weight', 'base_model.encoder.layer.14.output.dense.weight', 'base_model.encoder.layer.21.output.LayerNorm.weight', 'base_model.encoder.layer.16.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.13.attention.output.dense.bias', 'base_model.encoder.layer.17.attention.self.value.weight', 'base_model.encoder.layer.1.attention.self.value.weight', 'base_model.encoder.layer.23.output.dense.weight', 'base_model.encoder.layer.6.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.10.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.12.attention.output.dense.bias', 'base_model.encoder.layer.23.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.15.output.dense.bias', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.10.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.4.attention.self.key.bias', 'base_model.encoder.layer.3.intermediate.dense.bias', 'base_model.encoder.layer.18.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.3.attention.output.LayerNorm.weight', 'base_model.encoder.layer.17.output.dense.bias', 'base_model.encoder.layer.12.attention.self.value.weight', 'base_model.encoder.layer.9.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.10.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.8.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.14.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.14.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.14.output.adapters.tp.adapter_down.0.weight', 'base_model.embeddings.position_ids', 'base_model.encoder.layer.4.output.dense.bias', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.17.attention.output.LayerNorm.bias', 'base_model.encoder.layer.19.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.6.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.9.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.12.output.LayerNorm.bias', 'base_model.encoder.layer.5.output.LayerNorm.weight', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.18.attention.self.query.bias', 'base_model.encoder.layer.22.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.1.attention.output.dense.weight', 'base_model.encoder.layer.16.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.16.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.14.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.9.attention.self.key.weight', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.14.output.dense.bias', 'base_model.encoder.layer.7.attention.output.dense.weight', 'base_model.encoder.layer.2.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.20.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.18.attention.output.dense.weight', 'base_model.encoder.layer.21.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.12.attention.output.LayerNorm.weight', 'base_model.encoder.layer.23.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.20.intermediate.dense.weight', 'base_model.encoder.layer.1.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.6.output.dense.bias', 'base_model.encoder.layer.17.attention.self.query.bias', 'base_model.encoder.layer.19.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.13.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.7.attention.self.key.bias', 'base_model.encoder.layer.20.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.9.output.dense.weight', 'base_model.encoder.layer.12.intermediate.dense.weight', 'base_model.encoder.layer.5.output.dense.bias', 'base_model.encoder.layer.15.attention.self.query.weight', 'base_model.encoder.layer.11.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.15.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.22.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.16.attention.self.query.bias', 'base_model.encoder.layer.22.attention.output.dense.weight', 'base_model.encoder.layer.1.attention.output.dense.bias', 'base_model.encoder.layer.3.attention.output.dense.weight', 'base_model.encoder.layer.6.attention.self.key.bias', 'base_model.encoder.layer.8.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.17.attention.output.dense.bias', 'base_model.encoder.layer.1.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.9.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.6.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.1.attention.self.query.bias', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.0.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.21.attention.output.dense.bias', 'base_model.encoder.layer.22.output.dense.weight', 'base_model.encoder.layer.7.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.1.intermediate.dense.weight', 'base_model.encoder.layer.13.attention.self.key.bias', 'base_model.encoder.layer.18.output.adapters.es.adapter_down.0.weight', 'base_model.embeddings.LayerNorm.bias', 'base_model.encoder.layer.17.output.LayerNorm.weight', 'base_model.encoder.layer.3.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.3.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.22.output.LayerNorm.weight', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.16.attention.output.LayerNorm.weight', 'base_model.encoder.layer.8.output.LayerNorm.weight', 'base_model.encoder.layer.11.attention.output.LayerNorm.weight', 'base_model.encoder.layer.3.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.0.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.18.attention.self.value.bias', 'base_model.encoder.layer.8.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.7.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.0.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.23.output.dense.bias', 'base_model.encoder.layer.23.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.13.attention.output.dense.weight', 'base_model.encoder.layer.15.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.11.attention.self.key.weight', 'base_model.encoder.layer.21.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.22.attention.output.LayerNorm.weight', 'base_model.encoder.layer.7.output.dense.bias', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.19.intermediate.dense.weight', 'base_model.encoder.layer.1.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.9.intermediate.dense.bias', 'base_model.encoder.layer.23.attention.self.value.weight', 'base_model.encoder.layer.17.output.LayerNorm.bias', 'base_model.encoder.layer.20.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.23.attention.self.query.weight', 'base_model.encoder.layer.11.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.4.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.22.output.LayerNorm.bias', 'base_model.encoder.layer.9.attention.output.dense.bias', 'base_model.encoder.layer.13.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.3.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.9.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.7.output.dense.weight', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.20.attention.self.query.weight', 'base_model.encoder.layer.1.attention.self.value.bias', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.9.attention.self.key.bias', 'base_model.encoder.layer.14.intermediate.dense.bias', 'base_model.encoder.layer.6.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.13.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.10.attention.output.LayerNorm.bias', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.5.attention.output.LayerNorm.bias', 'base_model.encoder.layer.9.attention.self.query.weight', 'base_model.encoder.layer.16.attention.output.dense.weight', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.23.attention.self.key.weight', 'base_model.encoder.layer.11.attention.output.dense.weight', 'base_model.encoder.layer.20.attention.self.key.weight', 'base_model.encoder.layer.5.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.3.output.LayerNorm.bias', 'base_model.encoder.layer.14.attention.self.query.weight', 'base_model.encoder.layer.15.attention.output.LayerNorm.weight', 'base_model.encoder.layer.21.output.dense.bias', 'base_model.encoder.layer.13.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.13.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.16.attention.self.value.weight', 'base_model.encoder.layer.11.attention.output.dense.bias', 'base_model.encoder.layer.13.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.18.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.15.attention.self.value.bias', 'base_model.encoder.layer.7.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.0.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.3.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.11.attention.self.query.bias', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.14.attention.self.key.weight', 'base_model.encoder.layer.9.attention.self.query.bias', 'base_model.encoder.layer.12.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.4.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.8.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.11.attention.output.LayerNorm.bias', 'base_model.encoder.layer.5.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.12.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.15.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.21.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.13.attention.self.query.bias', 'base_model.encoder.layer.2.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.4.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.13.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.4.attention.output.LayerNorm.bias', 'base_model.encoder.layer.21.attention.self.key.weight', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.21.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.16.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.19.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.22.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.16.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.9.attention.output.dense.weight', 'base_model.encoder.layer.8.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.12.attention.self.query.bias', 'base_model.encoder.layer.14.attention.self.key.bias', 'base_model.encoder.layer.7.intermediate.dense.bias', 'base_model.encoder.layer.14.attention.self.value.weight', 'base_model.encoder.layer.8.attention.output.LayerNorm.weight', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.6.attention.self.value.bias', 'base_model.encoder.layer.2.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.8.intermediate.dense.weight', 'base_model.encoder.layer.12.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.18.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.21.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.9.attention.output.LayerNorm.weight', 'base_model.encoder.layer.23.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.13.output.LayerNorm.bias', 'base_model.encoder.layer.12.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.10.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.22.attention.output.LayerNorm.bias', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.10.output.LayerNorm.bias', 'base_model.encoder.layer.18.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.11.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.19.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.4.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.15.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.21.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.21.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.7.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.8.attention.self.key.weight', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.16.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.22.attention.self.value.weight', 'base_model.encoder.layer.5.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.11.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.14.attention.output.dense.bias', 'base_model.encoder.layer.19.attention.self.key.weight', 'base_model.encoder.layer.1.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.10.attention.self.key.weight', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.20.attention.output.LayerNorm.weight', 'base_model.encoder.layer.4.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.5.attention.output.LayerNorm.weight', 'base_model.encoder.layer.3.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.11.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.18.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.23.attention.output.LayerNorm.bias', 'base_model.encoder.layer.9.output.LayerNorm.bias', 'base_model.encoder.layer.10.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.17.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.18.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.20.attention.self.value.weight', 'base_model.encoder.layer.0.attention.self.key.bias', 'base_model.encoder.layer.19.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.1.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.14.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.22.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.10.attention.output.dense.bias', 'base_model.encoder.layer.9.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.2.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.5.intermediate.dense.bias', 'base_model.encoder.layer.23.attention.self.value.bias', 'base_model.encoder.layer.18.attention.output.dense.bias', 'base_model.encoder.layer.19.output.LayerNorm.weight', 'base_model.encoder.layer.15.output.LayerNorm.bias', 'base_model.encoder.layer.3.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.14.intermediate.dense.weight', 'base_model.encoder.layer.22.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.8.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.19.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.10.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.1.output.LayerNorm.bias', 'base_model.encoder.layer.2.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.8.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.18.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.19.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.4.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.17.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.6.attention.output.dense.weight', 'base_model.encoder.layer.4.attention.self.query.bias', 'base_model.encoder.layer.22.attention.self.key.weight', 'base_model.encoder.layer.13.output.dense.bias', 'base_model.encoder.layer.12.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.7.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.23.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.11.attention.self.value.bias', 'base_model.encoder.layer.17.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.20.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.3.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.10.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.9.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.21.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.0.attention.output.LayerNorm.bias', 'base_model.encoder.layer.5.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.7.intermediate.dense.weight', 'base_model.encoder.layer.15.attention.self.key.weight', 'base_model.encoder.layer.10.output.LayerNorm.weight', 'base_model.encoder.layer.18.attention.output.LayerNorm.weight', 'base_model.encoder.layer.23.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.21.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.12.output.dense.weight', 'base_model.encoder.layer.9.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.5.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.2.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.4.output.LayerNorm.bias', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.13.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.23.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.20.output.dense.bias', 'base_model.encoder.layer.7.attention.output.LayerNorm.weight', 'base_model.encoder.layer.0.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.0.attention.self.query.bias', 'base_model.encoder.layer.14.attention.self.query.bias', 'base_model.encoder.layer.20.attention.output.LayerNorm.bias', 'base_model.encoder.layer.0.output.dense.weight', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.pooler.dense.bias', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.17.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.12.attention.self.key.weight', 'base_model.encoder.layer.9.attention.self.value.weight', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.20.intermediate.dense.bias', 'base_model.encoder.layer.22.attention.self.value.bias', 'base_model.encoder.layer.15.output.dense.weight', 'base_model.encoder.layer.6.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.11.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.21.attention.self.query.weight', 'base_model.encoder.layer.7.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.16.attention.self.value.bias', 'base_model.encoder.layer.6.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.17.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.9.intermediate.dense.weight', 'base_model.encoder.layer.14.attention.output.LayerNorm.bias', 'base_model.encoder.layer.2.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.1.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.10.output.dense.bias', 'base_model.encoder.layer.15.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.4.attention.output.LayerNorm.weight', 'base_model.encoder.layer.14.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.17.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.7.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.17.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.8.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.5.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.9.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.5.output.dense.weight', 'base_model.encoder.layer.14.attention.self.value.bias', 'base_model.encoder.layer.14.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.11.attention.self.key.bias', 'base_model.encoder.layer.20.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.5.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.16.output.LayerNorm.weight', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.8.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.16.output.dense.weight', 'base_model.encoder.layer.6.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.5.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.11.output.dense.weight', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.13.output.LayerNorm.weight', 'base_model.encoder.layer.18.attention.self.key.weight', 'base_model.encoder.layer.10.attention.output.dense.weight', 'base_model.encoder.layer.14.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.15.intermediate.dense.weight', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.3.attention.output.LayerNorm.bias', 'base_model.encoder.layer.8.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.23.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.12.attention.self.key.bias', 'base_model.encoder.layer.19.attention.output.dense.bias', 'base_model.encoder.layer.6.attention.output.LayerNorm.bias', 'base_model.encoder.layer.19.attention.output.LayerNorm.bias', 'base_model.encoder.layer.3.attention.self.value.weight', 'base_model.encoder.layer.23.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.15.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.18.attention.self.query.weight', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.2.output.dense.weight', 'base_model.encoder.layer.8.attention.self.key.bias', 'base_model.encoder.layer.15.attention.output.dense.weight', 'base_model.encoder.layer.11.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.17.attention.output.LayerNorm.weight', 'base_model.encoder.layer.2.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.3.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.8.attention.output.LayerNorm.bias', 'base_model.encoder.layer.4.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.6.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.7.output.adapters.ts.adapter_down.0.bias', 'qa_outputs.weight', 'base_model.encoder.layer.2.attention.output.LayerNorm.bias', 'base_model.encoder.layer.17.attention.self.key.bias', 'base_model.encoder.layer.0.attention.self.value.bias', 'base_model.encoder.layer.16.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.3.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.11.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.23.intermediate.dense.bias', 'base_model.encoder.layer.15.intermediate.dense.bias', 'base_model.encoder.layer.21.output.LayerNorm.bias', 'base_model.encoder.layer.8.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.17.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.18.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.20.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.2.output.dense.bias', 'base_model.encoder.layer.23.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.12.output.dense.bias', 'base_model.encoder.layer.5.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.5.output.LayerNorm.bias', 'base_model.encoder.layer.21.intermediate.dense.weight', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.10.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.21.attention.self.key.bias', 'base_model.encoder.layer.16.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.21.attention.output.LayerNorm.weight', 'base_model.encoder.layer.12.attention.output.dense.weight', 'base_model.encoder.layer.6.attention.self.query.bias', 'base_model.encoder.layer.17.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.17.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.14.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.0.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.2.intermediate.dense.bias', 'base_model.encoder.layer.23.attention.self.key.bias', 'base_model.encoder.layer.22.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.19.attention.self.query.bias', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.16.attention.self.key.bias', 'base_model.encoder.layer.13.attention.output.LayerNorm.bias', 'base_model.encoder.layer.18.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.2.output.LayerNorm.weight', 'base_model.encoder.layer.19.output.dense.bias', 'base_model.encoder.layer.11.intermediate.dense.weight', 'base_model.encoder.layer.12.intermediate.dense.bias', 'base_model.encoder.layer.12.attention.self.query.weight', 'base_model.encoder.layer.15.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.4.attention.self.value.weight', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.0.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.17.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.12.attention.self.value.bias', 'base_model.encoder.layer.2.attention.self.query.bias', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.18.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.23.output.LayerNorm.bias', 'base_model.encoder.layer.1.attention.self.query.weight', 'base_model.encoder.layer.10.attention.self.query.bias', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.8.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.2.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.5.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.10.attention.self.value.bias', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.10.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.21.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.12.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.7.attention.self.value.weight', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.17.attention.self.key.weight', 'base_model.encoder.layer.19.attention.self.key.bias', 'base_model.encoder.layer.6.intermediate.dense.bias', 'base_model.encoder.layer.2.attention.output.dense.weight', 'base_model.encoder.layer.19.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.6.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.3.attention.self.key.weight', 'base_model.encoder.layer.12.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.11.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.3.attention.self.query.bias', 'base_model.encoder.layer.11.attention.self.query.weight', 'base_model.encoder.layer.22.intermediate.dense.bias', 'base_model.encoder.layer.2.attention.self.key.bias', 'base_model.encoder.layer.10.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.17.attention.self.query.weight', 'base_model.encoder.layer.23.attention.output.dense.weight', 'base_model.encoder.layer.17.attention.output.dense.weight', 'base_model.encoder.layer.13.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.1.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.4.output.dense.weight', 'base_model.encoder.layer.21.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.4.intermediate.dense.bias', 'base_model.encoder.layer.1.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.13.attention.self.query.weight', 'base_model.encoder.layer.1.output.LayerNorm.weight', 'base_model.encoder.layer.15.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.6.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.9.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.0.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.2.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.6.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.21.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.13.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.4.attention.output.dense.weight', 'base_model.encoder.layer.14.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.5.attention.self.value.bias', 'base_model.encoder.layer.15.output.LayerNorm.weight', 'base_model.encoder.layer.2.attention.self.value.weight', 'base_model.encoder.layer.13.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.5.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.3.intermediate.dense.weight', 'base_model.encoder.layer.5.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.20.output.LayerNorm.weight', 'base_model.encoder.layer.8.attention.self.value.weight', 'base_model.encoder.layer.10.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.17.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.21.attention.self.value.weight', 'base_model.encoder.layer.19.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.13.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.1.attention.output.LayerNorm.bias', 'base_model.encoder.layer.18.intermediate.dense.bias', 'base_model.encoder.layer.11.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.16.output.LayerNorm.bias', 'base_model.encoder.layer.18.output.LayerNorm.bias', 'base_model.encoder.layer.21.attention.output.LayerNorm.bias', 'base_model.encoder.layer.5.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.6.attention.self.key.weight', 'base_model.encoder.layer.5.attention.self.value.weight', 'base_model.encoder.layer.16.intermediate.dense.bias', 'base_model.pooler.dense.weight', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.19.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.1.attention.self.key.weight', 'base_model.encoder.layer.1.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.5.attention.output.dense.bias', 'base_model.encoder.layer.16.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.14.attention.output.dense.weight', 'base_model.encoder.layer.19.output.dense.weight', 'base_model.encoder.layer.5.attention.self.query.bias', 'base_model.encoder.layer.21.attention.self.value.bias', 'base_model.encoder.layer.9.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.15.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.5.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.14.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.11.attention.self.value.weight', 'base_model.encoder.layer.22.attention.self.query.weight', 'base_model.encoder.layer.8.attention.self.query.bias', 'base_model.encoder.layer.22.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.10.attention.output.LayerNorm.weight', 'base_model.encoder.layer.19.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.21.intermediate.dense.bias', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.17.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.20.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.10.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.14.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.22.attention.output.dense.bias', 'base_model.encoder.layer.18.intermediate.dense.weight', 'base_model.encoder.layer.1.output.dense.bias', 'base_model.encoder.layer.2.attention.output.dense.bias', 'base_model.encoder.layer.6.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.2.attention.self.value.bias', 'base_model.encoder.layer.23.attention.output.LayerNorm.weight', 'base_model.encoder.layer.15.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.20.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.8.output.LayerNorm.bias', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.1.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.10.attention.self.value.weight', 'base_model.encoder.layer.18.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.14.output.LayerNorm.bias']
- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of XLMRobertaModel were not initialized from the model checkpoint at /cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//tydiqa/xlm-KG_LR8e-6_EPOCH2.0_maxlen384_batchsize4_gradacc4 and are newly initialized: ['encoder.layer.7.attention.output.dense.bias', 'encoder.layer.17.output.dense.weight', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.7.attention.output.LayerNorm.bias', 'encoder.layer.8.attention.self.value.bias', 'encoder.layer.0.attention.self.value.weight', 'encoder.layer.5.output.dense.weight', 'encoder.layer.12.attention.output.LayerNorm.weight', 'encoder.layer.12.output.dense.weight', 'encoder.layer.7.intermediate.dense.bias', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.18.attention.output.LayerNorm.bias', 'encoder.layer.5.attention.self.key.weight', 'encoder.layer.22.attention.self.value.weight', 'encoder.layer.17.attention.output.LayerNorm.weight', 'encoder.layer.7.attention.self.key.weight', 'encoder.layer.18.attention.output.LayerNorm.weight', 'encoder.layer.3.attention.output.dense.weight', 'encoder.layer.0.attention.self.key.bias', 'encoder.layer.0.attention.self.query.bias', 'encoder.layer.9.attention.self.key.weight', 'encoder.layer.12.intermediate.dense.weight', 'encoder.layer.1.attention.self.key.bias', 'encoder.layer.18.output.dense.bias', 'encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.21.intermediate.dense.bias', 'encoder.layer.3.output.dense.bias', 'encoder.layer.13.attention.output.dense.bias', 'encoder.layer.11.attention.self.value.weight', 'encoder.layer.19.attention.self.key.bias', 'embeddings.position_embeddings.weight', 'encoder.layer.16.intermediate.dense.weight', 'encoder.layer.23.attention.self.key.weight', 'encoder.layer.23.output.LayerNorm.bias', 'encoder.layer.23.output.dense.bias', 'encoder.layer.22.output.LayerNorm.weight', 'encoder.layer.12.attention.output.dense.weight', 'encoder.layer.15.output.dense.weight', 'encoder.layer.13.output.dense.bias', 'encoder.layer.21.attention.output.LayerNorm.bias', 'encoder.layer.22.intermediate.dense.weight', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.6.attention.output.dense.bias', 'encoder.layer.16.attention.output.LayerNorm.weight', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.3.attention.self.query.weight', 'encoder.layer.23.attention.self.query.bias', 'encoder.layer.11.output.LayerNorm.bias', 'encoder.layer.16.attention.output.LayerNorm.bias', 'encoder.layer.12.attention.output.LayerNorm.bias', 'embeddings.LayerNorm.weight', 'encoder.layer.23.attention.output.LayerNorm.bias', 'encoder.layer.10.intermediate.dense.weight', 'encoder.layer.11.attention.output.dense.weight', 'encoder.layer.19.intermediate.dense.bias', 'encoder.layer.15.attention.self.query.bias', 'encoder.layer.10.attention.output.dense.bias', 'encoder.layer.18.attention.output.dense.bias', 'encoder.layer.0.attention.self.query.weight', 'encoder.layer.3.attention.self.value.bias', 'encoder.layer.18.attention.self.key.bias', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.10.output.dense.weight', 'encoder.layer.17.intermediate.dense.weight', 'encoder.layer.6.output.dense.weight', 'encoder.layer.10.output.dense.bias', 'encoder.layer.23.output.LayerNorm.weight', 'encoder.layer.17.output.LayerNorm.bias', 'encoder.layer.22.intermediate.dense.bias', 'encoder.layer.12.attention.self.query.weight', 'encoder.layer.10.attention.self.query.bias', 'encoder.layer.6.attention.output.LayerNorm.weight', 'encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.layer.14.attention.output.dense.bias', 'encoder.layer.17.intermediate.dense.bias', 'encoder.layer.14.output.LayerNorm.bias', 'encoder.layer.16.attention.self.value.bias', 'encoder.layer.13.intermediate.dense.weight', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.14.attention.self.query.bias', 'encoder.layer.22.output.dense.weight', 'encoder.layer.8.attention.self.key.weight', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.20.attention.output.LayerNorm.bias', 'encoder.layer.6.output.dense.bias', 'encoder.layer.11.output.LayerNorm.weight', 'encoder.layer.13.output.dense.weight', 'encoder.layer.22.attention.self.query.weight', 'encoder.layer.16.attention.self.query.weight', 'encoder.layer.1.attention.output.dense.bias', 'encoder.layer.23.intermediate.dense.bias', 'encoder.layer.9.attention.self.value.bias', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.17.output.LayerNorm.weight', 'encoder.layer.15.attention.output.LayerNorm.bias', 'encoder.layer.13.attention.self.value.weight', 'encoder.layer.5.attention.self.query.bias', 'encoder.layer.12.attention.self.key.weight', 'encoder.layer.8.output.LayerNorm.weight', 'encoder.layer.11.attention.output.dense.bias', 'encoder.layer.10.output.LayerNorm.bias', 'encoder.layer.2.attention.self.value.bias', 'encoder.layer.8.attention.self.query.bias', 'encoder.layer.15.attention.self.query.weight', 'encoder.layer.1.attention.output.dense.weight', 'encoder.layer.20.attention.output.dense.weight', 'encoder.layer.10.attention.self.key.bias', 'encoder.layer.15.intermediate.dense.weight', 'encoder.layer.7.output.dense.weight', 'encoder.layer.12.intermediate.dense.bias', 'encoder.layer.13.attention.self.query.weight', 'encoder.layer.22.attention.output.dense.bias', 'encoder.layer.0.attention.output.dense.bias', 'encoder.layer.17.attention.output.LayerNorm.bias', 'encoder.layer.10.attention.self.query.weight', 'encoder.layer.23.attention.self.key.bias', 'pooler.dense.bias', 'encoder.layer.3.attention.output.dense.bias', 'encoder.layer.12.output.LayerNorm.bias', 'encoder.layer.19.output.LayerNorm.weight', 'encoder.layer.11.attention.self.key.weight', 'embeddings.LayerNorm.bias', 'encoder.layer.22.attention.self.value.bias', 'encoder.layer.13.attention.output.LayerNorm.weight', 'encoder.layer.5.attention.output.dense.bias', 'encoder.layer.7.output.LayerNorm.bias', 'encoder.layer.21.attention.output.LayerNorm.weight', 'encoder.layer.15.attention.output.dense.weight', 'encoder.layer.9.attention.output.dense.bias', 'encoder.layer.13.output.LayerNorm.bias', 'encoder.layer.7.attention.self.value.weight', 'encoder.layer.7.attention.output.LayerNorm.weight', 'encoder.layer.4.attention.self.value.weight', 'encoder.layer.20.attention.self.value.weight', 'encoder.layer.0.attention.output.LayerNorm.weight', 'encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.layer.20.intermediate.dense.weight', 'encoder.layer.1.output.dense.bias', 'encoder.layer.4.output.dense.weight', 'encoder.layer.18.attention.self.value.weight', 'encoder.layer.19.attention.self.query.bias', 'encoder.layer.16.output.LayerNorm.bias', 'encoder.layer.19.output.dense.weight', 'encoder.layer.20.output.LayerNorm.weight', 'encoder.layer.23.attention.output.dense.weight', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.18.attention.self.value.bias', 'encoder.layer.11.output.dense.bias', 'encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.layer.12.output.LayerNorm.weight', 'encoder.layer.10.attention.output.LayerNorm.weight', 'encoder.layer.6.attention.self.key.bias', 'encoder.layer.12.attention.output.dense.bias', 'encoder.layer.8.attention.self.value.weight', 'encoder.layer.14.attention.self.value.weight', 'encoder.layer.4.attention.output.dense.weight', 'encoder.layer.12.attention.self.query.bias', 'encoder.layer.3.attention.self.query.bias', 'encoder.layer.15.attention.output.LayerNorm.weight', 'encoder.layer.8.attention.output.dense.weight', 'encoder.layer.19.attention.self.key.weight', 'encoder.layer.17.output.dense.bias', 'encoder.layer.15.output.dense.bias', 'encoder.layer.0.output.LayerNorm.weight', 'embeddings.word_embeddings.weight', 'encoder.layer.16.intermediate.dense.bias', 'encoder.layer.13.attention.output.dense.weight', 'encoder.layer.10.attention.self.value.bias', 'encoder.layer.7.attention.self.value.bias', 'encoder.layer.5.attention.self.key.bias', 'encoder.layer.1.attention.self.value.bias', 'encoder.layer.8.output.dense.weight', 'encoder.layer.15.attention.output.dense.bias', 'encoder.layer.14.attention.output.dense.weight', 'encoder.layer.10.attention.self.value.weight', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.23.attention.self.value.weight', 'encoder.layer.4.attention.output.LayerNorm.weight', 'encoder.layer.2.attention.self.query.bias', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.19.attention.output.LayerNorm.weight', 'encoder.layer.17.attention.output.dense.bias', 'encoder.layer.4.attention.output.LayerNorm.bias', 'encoder.layer.12.attention.self.value.weight', 'encoder.layer.21.attention.self.query.bias', 'encoder.layer.2.output.dense.bias', 'encoder.layer.18.attention.self.query.bias', 'encoder.layer.18.attention.output.dense.weight', 'encoder.layer.18.attention.self.key.weight', 'encoder.layer.21.output.LayerNorm.weight', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.9.attention.self.query.bias', 'encoder.layer.13.attention.self.key.weight', 'encoder.layer.2.attention.output.dense.bias', 'encoder.layer.7.output.dense.bias', 'encoder.layer.18.intermediate.dense.weight', 'encoder.layer.23.attention.output.LayerNorm.weight', 'encoder.layer.7.output.LayerNorm.weight', 'encoder.layer.20.attention.output.LayerNorm.weight', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.12.attention.self.key.bias', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.16.attention.output.dense.weight', 'encoder.layer.2.attention.output.dense.weight', 'encoder.layer.0.output.dense.bias', 'encoder.layer.9.output.LayerNorm.bias', 'encoder.layer.14.attention.self.value.bias', 'encoder.layer.1.output.dense.weight', 'encoder.layer.2.attention.self.value.weight', 'encoder.layer.12.output.dense.bias', 'encoder.layer.20.attention.output.dense.bias', 'encoder.layer.10.output.LayerNorm.weight', 'encoder.layer.14.attention.output.LayerNorm.weight', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.14.output.dense.weight', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.9.attention.self.value.weight', 'encoder.layer.6.attention.output.dense.weight', 'encoder.layer.16.attention.self.query.bias', 'encoder.layer.21.attention.output.dense.weight', 'encoder.layer.13.attention.self.key.bias', 'encoder.layer.8.attention.self.query.weight', 'encoder.layer.6.attention.output.LayerNorm.bias', 'encoder.layer.22.attention.output.dense.weight', 'encoder.layer.23.attention.output.dense.bias', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.22.attention.self.key.weight', 'encoder.layer.12.attention.self.value.bias', 'encoder.layer.1.attention.output.LayerNorm.weight', 'encoder.layer.0.attention.self.key.weight', 'encoder.layer.6.attention.self.query.bias', 'encoder.layer.9.attention.self.key.bias', 'encoder.layer.10.attention.output.LayerNorm.bias', 'encoder.layer.18.output.LayerNorm.bias', 'encoder.layer.4.attention.self.key.bias', 'encoder.layer.9.output.dense.weight', 'encoder.layer.2.attention.output.LayerNorm.bias', 'embeddings.token_type_embeddings.weight', 'encoder.layer.8.attention.output.dense.bias', 'encoder.layer.17.attention.self.key.bias', 'encoder.layer.22.attention.output.LayerNorm.bias', 'encoder.layer.21.attention.self.value.bias', 'encoder.layer.20.attention.self.query.weight', 'encoder.layer.9.attention.output.LayerNorm.weight', 'encoder.layer.14.output.LayerNorm.weight', 'encoder.layer.3.attention.self.key.weight', 'encoder.layer.0.output.dense.weight', 'encoder.layer.2.output.dense.weight', 'encoder.layer.15.output.LayerNorm.weight', 'encoder.layer.4.attention.output.dense.bias', 'encoder.layer.8.output.dense.bias', 'encoder.layer.20.attention.self.key.bias', 'encoder.layer.20.intermediate.dense.bias', 'encoder.layer.22.attention.output.LayerNorm.weight', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.15.attention.self.key.bias', 'encoder.layer.18.intermediate.dense.bias', 'encoder.layer.9.output.dense.bias', 'encoder.layer.10.attention.output.dense.weight', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.7.attention.self.query.bias', 'encoder.layer.20.output.dense.bias', 'encoder.layer.4.attention.self.query.weight', 'encoder.layer.6.attention.self.query.weight', 'encoder.layer.4.attention.self.key.weight', 'encoder.layer.21.attention.self.key.weight', 'encoder.layer.19.attention.self.query.weight', 'encoder.layer.19.attention.self.value.weight', 'encoder.layer.17.attention.self.query.weight', 'encoder.layer.21.output.LayerNorm.bias', 'encoder.layer.13.attention.self.query.bias', 'encoder.layer.0.attention.output.dense.weight', 'encoder.layer.0.attention.self.value.bias', 'encoder.layer.20.attention.self.value.bias', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.layer.16.attention.self.key.weight', 'encoder.layer.9.attention.self.query.weight', 'encoder.layer.13.intermediate.dense.bias', 'encoder.layer.22.attention.self.key.bias', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.17.attention.self.query.bias', 'encoder.layer.21.output.dense.weight', 'encoder.layer.5.attention.self.value.bias', 'pooler.dense.weight', 'encoder.layer.18.attention.self.query.weight', 'encoder.layer.14.intermediate.dense.weight', 'encoder.layer.5.attention.self.query.weight', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.9.output.LayerNorm.weight', 'encoder.layer.21.intermediate.dense.weight', 'encoder.layer.15.attention.self.value.bias', 'encoder.layer.17.attention.self.value.weight', 'encoder.layer.23.output.dense.weight', 'encoder.layer.16.attention.output.dense.bias', 'encoder.layer.10.attention.self.key.weight', 'encoder.layer.2.attention.self.query.weight', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.23.attention.self.value.bias', 'encoder.layer.16.output.dense.weight', 'encoder.layer.23.attention.self.query.weight', 'encoder.layer.16.output.LayerNorm.weight', 'encoder.layer.1.attention.self.query.weight', 'encoder.layer.6.output.LayerNorm.bias', 'encoder.layer.2.attention.self.key.weight', 'encoder.layer.15.attention.self.value.weight', 'encoder.layer.9.attention.output.LayerNorm.bias', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.16.attention.self.value.weight', 'encoder.layer.4.output.dense.bias', 'encoder.layer.5.output.LayerNorm.bias', 'encoder.layer.14.attention.self.key.weight', 'encoder.layer.15.intermediate.dense.bias', 'encoder.layer.7.attention.self.key.bias', 'encoder.layer.11.attention.self.query.bias', 'encoder.layer.17.attention.self.key.weight', 'encoder.layer.7.attention.self.query.weight', 'encoder.layer.4.attention.self.value.bias', 'encoder.layer.20.attention.self.key.weight', 'encoder.layer.21.output.dense.bias', 'encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.layer.15.attention.self.key.weight', 'encoder.layer.6.attention.self.key.weight', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.5.attention.self.value.weight', 'encoder.layer.22.output.LayerNorm.bias', 'encoder.layer.11.attention.output.LayerNorm.weight', 'encoder.layer.6.attention.self.value.weight', 'encoder.layer.8.attention.output.LayerNorm.weight', 'encoder.layer.11.attention.self.key.bias', 'encoder.layer.23.intermediate.dense.weight', 'encoder.layer.21.attention.self.value.weight', 'encoder.layer.11.attention.self.value.bias', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.1.attention.self.key.weight', 'encoder.layer.19.attention.output.LayerNorm.bias', 'encoder.layer.22.output.dense.bias', 'encoder.layer.14.output.dense.bias', 'encoder.layer.14.attention.self.key.bias', 'encoder.layer.5.output.dense.bias', 'encoder.layer.11.output.dense.weight', 'encoder.layer.2.attention.self.key.bias', 'encoder.layer.1.attention.self.value.weight', 'encoder.layer.5.attention.output.LayerNorm.weight', 'encoder.layer.20.output.dense.weight', 'encoder.layer.5.attention.output.dense.weight', 'encoder.layer.19.output.LayerNorm.bias', 'encoder.layer.14.attention.output.LayerNorm.bias', 'encoder.layer.7.attention.output.dense.weight', 'encoder.layer.8.attention.self.key.bias', 'encoder.layer.11.attention.self.query.weight', 'encoder.layer.21.attention.self.key.bias', 'encoder.layer.13.output.LayerNorm.weight', 'encoder.layer.3.output.dense.weight', 'encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.layer.14.intermediate.dense.bias', 'encoder.layer.22.attention.self.query.bias', 'encoder.layer.19.intermediate.dense.weight', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.16.output.dense.bias', 'encoder.layer.15.output.LayerNorm.bias', 'encoder.layer.13.attention.output.LayerNorm.bias', 'encoder.layer.17.attention.self.value.bias', 'encoder.layer.8.attention.output.LayerNorm.bias', 'encoder.layer.13.attention.self.value.bias', 'encoder.layer.20.attention.self.query.bias', 'encoder.layer.8.output.LayerNorm.bias', 'encoder.layer.9.attention.output.dense.weight', 'encoder.layer.18.output.LayerNorm.weight', 'encoder.layer.1.attention.self.query.bias', 'encoder.layer.2.attention.output.LayerNorm.weight', 'encoder.layer.17.attention.output.dense.weight', 'encoder.layer.18.output.dense.weight', 'encoder.layer.3.attention.self.value.weight', 'encoder.layer.21.attention.self.query.weight', 'encoder.layer.21.attention.output.dense.bias', 'encoder.layer.19.attention.output.dense.bias', 'encoder.layer.20.output.LayerNorm.bias', 'encoder.layer.14.attention.self.query.weight', 'encoder.layer.19.output.dense.bias', 'encoder.layer.6.attention.self.value.bias', 'encoder.layer.3.attention.self.key.bias', 'encoder.layer.16.attention.self.key.bias', 'encoder.layer.19.attention.self.value.bias', 'encoder.layer.19.attention.output.dense.weight', 'encoder.layer.4.attention.self.query.bias', 'encoder.layer.3.output.LayerNorm.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Overwriting existing adapter 'ep'.
Overwriting existing adapter 'tp'.
Overwriting existing adapter 'es'.
Overwriting existing adapter 'ts'.
Overwriting existing adapter fusion module 'ep,tp,es,ts'
05/09/2022 22:49:22 - INFO - __main__ -   Creating features from dataset file at .
/cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//tydiqa/xlm-KG_LR8e-6_EPOCH2.0_maxlen384_batchsize4_gradacc4
XLMConfig {
  "architectures": [
    "XLMRobertaForMaskedLM"
  ],
  "asm": false,
  "attention_dropout": 0.1,
  "attention_probs_dropout_prob": 0.1,
  "bos_index": 0,
  "bos_token_id": 0,
  "causal": false,
  "dropout": 0.1,
  "emb_dim": 1024,
  "embed_init_std": 0.02209708691207961,
  "end_n_top": 5,
  "eos_index": 1,
  "eos_token_id": 2,
  "gelu_activation": true,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "init_std": 0.02,
  "initializer_range": 0.02,
  "intermediate_size": 4096,
  "is_encoder": true,
  "lang_id": 0,
  "layer_norm_eps": 1e-05,
  "mask_index": 5,
  "mask_token_id": 0,
  "max_position_embeddings": 514,
  "model_type": "xlm",
  "n_heads": 16,
  "n_langs": 1,
  "n_layers": 24,
  "output_past": true,
  "pad_index": 2,
  "pad_token_id": 1,
  "sinusoidal_embeddings": false,
  "start_n_top": 5,
  "summary_activation": null,
  "summary_first_dropout": 0.1,
  "summary_proj_to_labels": true,
  "summary_type": "first",
  "summary_use_proj": true,
  "transformers_version": "4.17.0",
  "type_vocab_size": 1,
  "unk_index": 3,
  "use_lang_emb": false,
  "vocab_size": 250002
}

  0%|          | 0/440 [00:00<?, ?it/s] 93%|█████████▎| 411/440 [00:00<00:00, 4105.24it/s]100%|██████████| 440/440 [00:00<00:00, 4087.20it/s]
convert squad examples to features:   0%|          | 0/440 [00:00<?, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.
convert squad examples to features:   0%|          | 1/440 [00:00<00:51,  8.56it/s]convert squad examples to features:  15%|█▍        | 65/440 [00:00<00:01, 212.40it/s]convert squad examples to features:  29%|██▉       | 129/440 [00:00<00:01, 260.10it/s]convert squad examples to features:  44%|████▍     | 193/440 [00:00<00:00, 297.36it/s]convert squad examples to features:  58%|█████▊    | 257/440 [00:00<00:00, 306.17it/s]convert squad examples to features:  73%|███████▎  | 321/440 [00:01<00:00, 326.47it/s]convert squad examples to features:  88%|████████▊ | 385/440 [00:01<00:00, 321.52it/s]convert squad examples to features: 100%|██████████| 440/440 [00:01<00:00, 320.01it/s]/cluster/project/sachan/yifan/softwares/anaconda/anaconda3/envs/xfactr/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2272: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

add example index and unique id:   0%|          | 0/440 [00:00<?, ?it/s]add example index and unique id: 100%|██████████| 440/440 [00:00<00:00, 696150.04it/s]
05/09/2022 22:49:23 - INFO - __main__ -   Saving features into cached file ./cached_tydiqa.goldp.en.dev.json_xlm-KG_LR8e-6_EPOCH2.0_maxlen384_batchsize4_gradacc4_384_en
05/09/2022 22:49:24 - INFO - __main__ -   ***** Running evaluation  *****
05/09/2022 22:49:24 - INFO - __main__ -     Num examples = 449
05/09/2022 22:49:24 - INFO - __main__ -     Batch size = 8
Evaluating:   0%|          | 0/57 [00:00<?, ?it/s]Evaluating:   2%|▏         | 1/57 [00:00<00:46,  1.21it/s]Evaluating:   4%|▎         | 2/57 [00:01<00:30,  1.83it/s]Evaluating:   5%|▌         | 3/57 [00:01<00:24,  2.18it/s]Evaluating:   7%|▋         | 4/57 [00:01<00:22,  2.39it/s]Evaluating:   9%|▉         | 5/57 [00:02<00:20,  2.51it/s]Evaluating:  11%|█         | 6/57 [00:02<00:19,  2.60it/s]Evaluating:  12%|█▏        | 7/57 [00:02<00:18,  2.67it/s]Evaluating:  14%|█▍        | 8/57 [00:03<00:18,  2.71it/s]Evaluating:  16%|█▌        | 9/57 [00:03<00:17,  2.74it/s]Evaluating:  18%|█▊        | 10/57 [00:04<00:17,  2.73it/s]Evaluating:  19%|█▉        | 11/57 [00:04<00:16,  2.76it/s]Evaluating:  21%|██        | 12/57 [00:04<00:16,  2.77it/s]Evaluating:  23%|██▎       | 13/57 [00:05<00:15,  2.79it/s]Evaluating:  25%|██▍       | 14/57 [00:05<00:15,  2.80it/s]Evaluating:  26%|██▋       | 15/57 [00:05<00:15,  2.80it/s]Evaluating:  28%|██▊       | 16/57 [00:06<00:14,  2.79it/s]Evaluating:  30%|██▉       | 17/57 [00:06<00:14,  2.80it/s]Evaluating:  32%|███▏      | 18/57 [00:06<00:13,  2.80it/s]Evaluating:  33%|███▎      | 19/57 [00:07<00:13,  2.77it/s]Evaluating:  35%|███▌      | 20/57 [00:07<00:13,  2.78it/s]Evaluating:  37%|███▋      | 21/57 [00:07<00:12,  2.79it/s]Evaluating:  39%|███▊      | 22/57 [00:08<00:12,  2.79it/s]Evaluating:  40%|████      | 23/57 [00:08<00:12,  2.78it/s]Evaluating:  42%|████▏     | 24/57 [00:09<00:11,  2.79it/s]Evaluating:  44%|████▍     | 25/57 [00:09<00:11,  2.79it/s]Evaluating:  46%|████▌     | 26/57 [00:09<00:11,  2.78it/s]Evaluating:  47%|████▋     | 27/57 [00:10<00:10,  2.79it/s]Evaluating:  49%|████▉     | 28/57 [00:10<00:10,  2.78it/s]Evaluating:  51%|█████     | 29/57 [00:10<00:10,  2.79it/s]Evaluating:  53%|█████▎    | 30/57 [00:11<00:09,  2.80it/s]Evaluating:  54%|█████▍    | 31/57 [00:11<00:09,  2.79it/s]Evaluating:  56%|█████▌    | 32/57 [00:11<00:08,  2.80it/s]Evaluating:  58%|█████▊    | 33/57 [00:12<00:08,  2.80it/s]Evaluating:  60%|█████▉    | 34/57 [00:12<00:08,  2.80it/s]Evaluating:  61%|██████▏   | 35/57 [00:12<00:07,  2.81it/s]Evaluating:  63%|██████▎   | 36/57 [00:13<00:07,  2.81it/s]Evaluating:  65%|██████▍   | 37/57 [00:13<00:07,  2.79it/s]Evaluating:  67%|██████▋   | 38/57 [00:14<00:06,  2.80it/s]Evaluating:  68%|██████▊   | 39/57 [00:14<00:06,  2.81it/s]Evaluating:  70%|███████   | 40/57 [00:14<00:06,  2.80it/s]Evaluating:  72%|███████▏  | 41/57 [00:15<00:05,  2.80it/s]Evaluating:  74%|███████▎  | 42/57 [00:15<00:05,  2.80it/s]Evaluating:  75%|███████▌  | 43/57 [00:15<00:05,  2.80it/s]Evaluating:  77%|███████▋  | 44/57 [00:16<00:04,  2.80it/s]Evaluating:  79%|███████▉  | 45/57 [00:16<00:04,  2.80it/s]Evaluating:  81%|████████  | 46/57 [00:16<00:03,  2.80it/s]Evaluating:  82%|████████▏ | 47/57 [00:17<00:03,  2.76it/s]Evaluating:  84%|████████▍ | 48/57 [00:17<00:03,  2.78it/s]Evaluating:  86%|████████▌ | 49/57 [00:17<00:02,  2.79it/s]Evaluating:  88%|████████▊ | 50/57 [00:18<00:02,  2.78it/s]Evaluating:  89%|████████▉ | 51/57 [00:18<00:02,  2.79it/s]Evaluating:  91%|█████████ | 52/57 [00:19<00:01,  2.79it/s]Evaluating:  93%|█████████▎| 53/57 [00:19<00:01,  2.80it/s]Evaluating:  95%|█████████▍| 54/57 [00:19<00:01,  2.80it/s]Evaluating:  96%|█████████▋| 55/57 [00:20<00:00,  2.77it/s]Evaluating:  98%|█████████▊| 56/57 [00:20<00:00,  2.78it/s]Evaluating: 100%|██████████| 57/57 [00:20<00:00,  2.77it/s]
05/09/2022 22:49:44 - INFO - __main__ -     Evaluation done in total 20.572737 secs (0.045819 sec per example)
05/09/2022 22:49:46 - INFO - __main__ -   Results: {'exact': 62.72727272727273, 'f1': 74.65599416582808, 'total': 440, 'HasAns_exact': 62.72727272727273, 'HasAns_f1': 74.65599416582808, 'HasAns_total': 440, 'best_exact': 62.72727272727273, 'best_exact_thresh': 0.0, 'best_f1': 74.65599416582808, 'best_f1_thresh': 0.0}
  ar 
2022-05-09 22:49:49.056656: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0
05/09/2022 22:49:54 - WARNING - __main__ -   Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, 16-bits training: False
You are using a model of type xlm-roberta to instantiate a model of type xlm. This is not supported for all configurations of models and can yield errors.
Some weights of the model checkpoint at /cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//tydiqa/xlm-KG_LR8e-6_EPOCH2.0_maxlen384_batchsize4_gradacc4 were not used when initializing XLMRobertaModel: ['base_model.encoder.layer.8.output.LayerNorm.bias', 'base_model.encoder.layer.13.attention.self.value.bias', 'base_model.encoder.layer.16.intermediate.dense.bias', 'base_model.encoder.layer.16.attention.self.value.weight', 'base_model.encoder.layer.7.output.LayerNorm.bias', 'base_model.encoder.layer.3.output.dense.bias', 'base_model.encoder.layer.16.output.dense.weight', 'base_model.encoder.layer.20.attention.output.dense.bias', 'base_model.encoder.layer.10.output.dense.bias', 'base_model.encoder.layer.12.attention.self.query.bias', 'base_model.encoder.layer.9.attention.self.key.weight', 'base_model.encoder.layer.10.intermediate.dense.weight', 'base_model.encoder.layer.8.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.3.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.12.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.21.attention.output.dense.weight', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.0.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.19.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.14.attention.output.dense.bias', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.0.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.3.attention.output.LayerNorm.weight', 'base_model.encoder.layer.3.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.17.attention.output.LayerNorm.weight', 'base_model.encoder.layer.10.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.22.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.2.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.16.attention.output.LayerNorm.weight', 'base_model.encoder.layer.16.output.LayerNorm.bias', 'base_model.encoder.layer.12.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.17.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.20.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.2.attention.self.key.weight', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.10.output.dense.weight', 'base_model.encoder.layer.0.output.dense.weight', 'base_model.encoder.layer.5.intermediate.dense.weight', 'base_model.encoder.layer.23.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.4.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.10.attention.self.value.bias', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.4.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.1.attention.self.value.weight', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.22.attention.output.LayerNorm.weight', 'base_model.encoder.layer.11.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.10.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.5.attention.self.value.bias', 'base_model.encoder.layer.13.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.2.attention.self.query.weight', 'base_model.encoder.layer.9.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.10.attention.output.LayerNorm.weight', 'base_model.encoder.layer.2.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.17.output.dense.bias', 'base_model.encoder.layer.20.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.21.attention.output.dense.bias', 'base_model.encoder.layer.21.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.23.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.3.attention.output.dense.bias', 'base_model.encoder.layer.16.attention.self.query.bias', 'base_model.encoder.layer.5.attention.output.LayerNorm.weight', 'base_model.encoder.layer.8.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.11.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.12.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.8.output.LayerNorm.weight', 'base_model.encoder.layer.14.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.19.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.7.intermediate.dense.bias', 'base_model.encoder.layer.22.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.16.intermediate.dense.weight', 'base_model.encoder.layer.17.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.3.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.14.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.8.attention.self.key.weight', 'base_model.encoder.layer.13.output.dense.bias', 'base_model.encoder.layer.14.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.15.attention.output.dense.bias', 'base_model.encoder.layer.22.attention.output.dense.bias', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.22.output.dense.bias', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.6.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.8.attention.output.LayerNorm.bias', 'base_model.encoder.layer.21.attention.self.key.bias', 'base_model.encoder.layer.13.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.6.attention.self.value.weight', 'base_model.encoder.layer.8.attention.self.query.bias', 'base_model.encoder.layer.11.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.0.attention.output.LayerNorm.weight', 'base_model.encoder.layer.15.attention.self.query.bias', 'base_model.encoder.layer.15.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.19.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.18.intermediate.dense.weight', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.15.output.dense.bias', 'base_model.encoder.layer.18.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.8.output.dense.bias', 'base_model.encoder.layer.15.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.1.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.18.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.17.attention.self.value.bias', 'base_model.encoder.layer.3.attention.self.query.weight', 'base_model.encoder.layer.22.output.dense.weight', 'base_model.encoder.layer.11.attention.self.key.weight', 'base_model.encoder.layer.17.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.7.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.9.attention.self.query.weight', 'base_model.encoder.layer.15.intermediate.dense.bias', 'base_model.encoder.layer.4.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.23.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.17.attention.self.query.bias', 'base_model.encoder.layer.19.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.12.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.2.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.0.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.20.attention.output.LayerNorm.weight', 'base_model.encoder.layer.10.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.23.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.0.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.14.attention.output.LayerNorm.bias', 'base_model.encoder.layer.15.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.15.attention.self.value.bias', 'base_model.encoder.layer.19.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.6.attention.self.value.bias', 'base_model.encoder.layer.2.attention.output.LayerNorm.bias', 'base_model.encoder.layer.15.intermediate.dense.weight', 'base_model.pooler.dense.weight', 'base_model.encoder.layer.23.attention.self.query.weight', 'base_model.encoder.layer.1.attention.output.dense.bias', 'base_model.encoder.layer.0.attention.self.query.weight', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.23.attention.output.dense.bias', 'base_model.encoder.layer.18.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.21.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.18.attention.self.value.bias', 'base_model.encoder.layer.4.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.8.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.2.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.23.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.1.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.10.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.5.output.LayerNorm.weight', 'base_model.encoder.layer.5.intermediate.dense.bias', 'base_model.encoder.layer.9.attention.self.key.bias', 'base_model.encoder.layer.0.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.6.attention.self.key.weight', 'base_model.encoder.layer.0.intermediate.dense.bias', 'base_model.encoder.layer.3.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.2.attention.self.value.weight', 'base_model.encoder.layer.9.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.14.attention.self.value.bias', 'base_model.encoder.layer.18.attention.output.LayerNorm.weight', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.8.output.dense.weight', 'base_model.encoder.layer.6.output.dense.weight', 'base_model.encoder.layer.16.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.22.intermediate.dense.weight', 'base_model.encoder.layer.15.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.19.attention.output.dense.weight', 'base_model.encoder.layer.3.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.1.intermediate.dense.weight', 'base_model.encoder.layer.3.attention.self.query.bias', 'base_model.encoder.layer.21.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.19.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.13.intermediate.dense.weight', 'base_model.encoder.layer.16.attention.self.key.bias', 'base_model.encoder.layer.6.attention.self.query.bias', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.21.output.dense.weight', 'base_model.encoder.layer.4.attention.self.query.weight', 'base_model.encoder.layer.16.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.9.output.LayerNorm.bias', 'base_model.encoder.layer.11.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.9.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.19.attention.self.key.weight', 'base_model.encoder.layer.14.output.LayerNorm.bias', 'base_model.encoder.layer.21.intermediate.dense.bias', 'base_model.embeddings.token_type_embeddings.weight', 'base_model.encoder.layer.3.attention.self.value.weight', 'base_model.encoder.layer.9.attention.self.query.bias', 'base_model.encoder.layer.17.output.dense.weight', 'base_model.encoder.layer.11.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.20.attention.output.dense.weight', 'base_model.encoder.layer.11.output.LayerNorm.weight', 'base_model.encoder.layer.23.attention.self.key.bias', 'base_model.encoder.layer.17.attention.output.LayerNorm.bias', 'base_model.encoder.layer.21.output.dense.bias', 'base_model.encoder.layer.9.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.19.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.2.attention.self.query.bias', 'base_model.encoder.layer.2.output.dense.weight', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.19.attention.output.LayerNorm.bias', 'base_model.encoder.layer.22.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.19.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.4.attention.self.key.weight', 'base_model.encoder.layer.10.output.LayerNorm.weight', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.7.attention.self.key.bias', 'base_model.encoder.layer.12.output.dense.bias', 'base_model.encoder.layer.8.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.4.attention.self.value.bias', 'base_model.encoder.layer.1.output.dense.bias', 'base_model.encoder.layer.20.attention.self.query.bias', 'base_model.encoder.layer.20.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.7.attention.self.value.bias', 'base_model.encoder.layer.21.attention.self.value.weight', 'base_model.encoder.layer.16.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.17.attention.output.dense.bias', 'base_model.encoder.layer.1.attention.output.LayerNorm.bias', 'base_model.encoder.layer.2.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.23.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.6.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.10.output.LayerNorm.bias', 'base_model.encoder.layer.2.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.19.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.1.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.21.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.16.attention.output.LayerNorm.bias', 'base_model.encoder.layer.9.output.LayerNorm.weight', 'base_model.encoder.layer.13.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.12.attention.self.query.weight', 'base_model.encoder.layer.16.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.23.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.17.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.12.attention.self.key.bias', 'base_model.encoder.layer.18.output.dense.weight', 'base_model.encoder.layer.21.output.LayerNorm.bias', 'base_model.encoder.layer.20.attention.self.key.weight', 'base_model.encoder.layer.20.output.dense.bias', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.14.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.2.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.0.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.1.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.10.intermediate.dense.bias', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.15.output.LayerNorm.bias', 'base_model.encoder.layer.22.attention.output.LayerNorm.bias', 'base_model.encoder.layer.12.output.dense.weight', 'base_model.encoder.layer.2.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.15.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.17.attention.self.key.weight', 'base_model.encoder.layer.4.attention.output.dense.weight', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.19.attention.self.query.weight', 'base_model.encoder.layer.6.attention.output.LayerNorm.weight', 'base_model.encoder.layer.14.output.dense.bias', 'base_model.encoder.layer.15.attention.self.query.weight', 'base_model.encoder.layer.13.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.0.output.LayerNorm.weight', 'base_model.encoder.layer.0.attention.output.dense.weight', 'base_model.encoder.layer.23.intermediate.dense.weight', 'base_model.encoder.layer.7.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.18.output.dense.bias', 'base_model.encoder.layer.12.attention.output.dense.bias', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.13.output.dense.weight', 'base_model.encoder.layer.23.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.13.attention.output.dense.weight', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.0.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.12.output.LayerNorm.bias', 'base_model.encoder.layer.21.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.18.attention.output.dense.bias', 'base_model.encoder.layer.4.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.20.attention.output.LayerNorm.bias', 'base_model.pooler.dense.bias', 'base_model.encoder.layer.9.attention.output.LayerNorm.bias', 'base_model.encoder.layer.6.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.21.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.2.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.18.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.21.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.10.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.10.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.23.intermediate.dense.bias', 'base_model.encoder.layer.9.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.18.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.17.output.LayerNorm.weight', 'base_model.encoder.layer.15.output.LayerNorm.weight', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.0.attention.self.query.bias', 'base_model.encoder.layer.6.intermediate.dense.bias', 'base_model.encoder.layer.9.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.15.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.20.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.12.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.2.attention.output.dense.bias', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.17.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.embeddings.position_embeddings.weight', 'base_model.embeddings.word_embeddings.weight', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.5.output.LayerNorm.bias', 'base_model.encoder.layer.13.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.20.attention.self.query.weight', 'base_model.encoder.layer.14.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.17.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.2.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.21.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.23.output.LayerNorm.bias', 'base_model.encoder.layer.23.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.7.attention.self.key.weight', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.0.attention.self.key.bias', 'base_model.encoder.layer.19.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.7.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.8.attention.self.value.bias', 'base_model.encoder.layer.2.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.23.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.16.attention.self.key.weight', 'base_model.encoder.layer.10.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.18.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.0.attention.output.dense.bias', 'base_model.encoder.layer.14.attention.self.query.bias', 'base_model.encoder.layer.6.output.LayerNorm.weight', 'base_model.encoder.layer.11.attention.output.dense.weight', 'base_model.encoder.layer.7.attention.self.query.weight', 'base_model.encoder.layer.15.attention.self.key.weight', 'base_model.encoder.layer.1.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.19.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.17.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.19.attention.self.key.bias', 'base_model.encoder.layer.13.output.LayerNorm.weight', 'base_model.encoder.layer.0.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.6.output.dense.bias', 'base_model.encoder.layer.6.attention.self.key.bias', 'base_model.encoder.layer.1.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.16.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.21.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.15.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.16.output.LayerNorm.weight', 'base_model.encoder.layer.8.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.13.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.19.output.LayerNorm.weight', 'base_model.encoder.layer.2.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.5.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.12.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.23.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.2.intermediate.dense.bias', 'base_model.encoder.layer.3.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.20.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.14.attention.self.query.weight', 'base_model.encoder.layer.1.attention.output.dense.weight', 'base_model.encoder.layer.14.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.14.intermediate.dense.bias', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.12.attention.self.key.weight', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.10.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.22.output.LayerNorm.bias', 'base_model.encoder.layer.16.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.22.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.3.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.2.attention.self.key.bias', 'base_model.encoder.layer.12.intermediate.dense.bias', 'base_model.encoder.layer.16.attention.output.dense.bias', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.21.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.1.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.4.attention.output.LayerNorm.weight', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.8.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.18.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.21.attention.self.value.bias', 'base_model.encoder.layer.13.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.4.intermediate.dense.bias', 'base_model.encoder.layer.7.output.dense.weight', 'base_model.encoder.layer.16.output.dense.bias', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.5.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.6.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.4.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.13.attention.self.query.bias', 'base_model.encoder.layer.20.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.11.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.19.attention.self.value.bias', 'base_model.encoder.layer.0.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.18.attention.self.value.weight', 'base_model.encoder.layer.22.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.16.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.4.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.19.output.LayerNorm.bias', 'base_model.encoder.layer.18.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.1.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.12.intermediate.dense.weight', 'base_model.encoder.layer.21.intermediate.dense.weight', 'base_model.encoder.layer.4.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.0.attention.self.key.weight', 'base_model.encoder.layer.14.attention.output.LayerNorm.weight', 'base_model.encoder.layer.23.attention.output.LayerNorm.bias', 'base_model.encoder.layer.21.attention.output.LayerNorm.bias', 'base_model.encoder.layer.10.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.11.output.dense.weight', 'base_model.encoder.layer.17.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.7.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.10.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.2.output.LayerNorm.weight', 'base_model.encoder.layer.8.attention.self.key.bias', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.4.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.9.attention.self.value.bias', 'base_model.encoder.layer.12.output.LayerNorm.weight', 'base_model.encoder.layer.7.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.16.attention.output.dense.weight', 'base_model.encoder.layer.20.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.13.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.22.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.14.attention.self.key.bias', 'base_model.encoder.layer.22.attention.self.value.bias', 'base_model.encoder.layer.1.attention.self.key.bias', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.15.attention.self.key.bias', 'base_model.encoder.layer.1.attention.output.LayerNorm.weight', 'base_model.encoder.layer.11.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.2.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.18.attention.output.dense.weight', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.7.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.9.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.20.output.LayerNorm.bias', 'base_model.encoder.layer.20.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.23.attention.self.value.weight', 'base_model.encoder.layer.7.attention.output.LayerNorm.bias', 'base_model.encoder.layer.5.attention.self.key.bias', 'base_model.encoder.layer.11.attention.output.dense.bias', 'base_model.encoder.layer.19.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.21.output.LayerNorm.weight', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.13.attention.output.LayerNorm.weight', 'base_model.encoder.layer.4.output.LayerNorm.weight', 'base_model.encoder.layer.21.attention.self.query.weight', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.12.attention.output.LayerNorm.bias', 'base_model.encoder.layer.11.attention.self.key.bias', 'base_model.encoder.layer.18.attention.self.key.bias', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.15.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.16.attention.self.value.bias', 'base_model.encoder.layer.4.attention.output.dense.bias', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.6.attention.output.dense.weight', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.14.output.adapters.ep.adapter_down.0.bias', 'base_model.embeddings.LayerNorm.weight', 'base_model.encoder.layer.9.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.0.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.1.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.4.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.5.attention.self.value.weight', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.14.attention.self.value.weight', 'base_model.encoder.layer.18.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.19.intermediate.dense.bias', 'base_model.encoder.layer.9.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.7.attention.self.query.bias', 'base_model.encoder.layer.5.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.12.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.22.intermediate.dense.bias', 'base_model.encoder.layer.8.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.8.attention.output.dense.bias', 'base_model.encoder.layer.7.attention.output.LayerNorm.weight', 'base_model.encoder.layer.0.output.dense.bias', 'base_model.encoder.layer.6.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.21.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.23.attention.self.query.bias', 'base_model.encoder.layer.1.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.7.output.dense.bias', 'base_model.encoder.layer.11.output.LayerNorm.bias', 'base_model.encoder.layer.17.attention.self.query.weight', 'base_model.encoder.layer.21.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.6.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.7.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.23.output.dense.weight', 'base_model.encoder.layer.17.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.13.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.14.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.5.output.dense.weight', 'base_model.encoder.layer.5.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.9.output.dense.weight', 'base_model.encoder.layer.7.attention.output.dense.weight', 'base_model.encoder.layer.3.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.6.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.3.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.18.intermediate.dense.bias', 'base_model.encoder.layer.18.attention.output.LayerNorm.bias', 'base_model.encoder.layer.6.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.8.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.11.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.10.attention.self.key.weight', 'base_model.encoder.layer.3.attention.output.LayerNorm.bias', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.11.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.0.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.16.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.14.attention.output.dense.weight', 'base_model.encoder.layer.16.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.14.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.0.intermediate.dense.weight', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.11.attention.output.LayerNorm.bias', 'base_model.encoder.layer.18.attention.self.key.weight', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.8.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.22.attention.self.query.bias', 'base_model.encoder.layer.13.attention.output.dense.bias', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.5.attention.output.dense.weight', 'base_model.encoder.layer.6.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.23.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.13.attention.self.key.weight', 'base_model.encoder.layer.6.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.10.attention.self.key.bias', 'base_model.encoder.layer.10.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.13.output.LayerNorm.bias', 'base_model.encoder.layer.17.attention.self.key.bias', 'base_model.encoder.layer.19.attention.self.value.weight', 'base_model.encoder.layer.22.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.4.output.dense.weight', 'base_model.encoder.layer.14.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.5.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.19.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.11.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.22.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.16.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.18.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.23.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.5.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.14.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.3.output.dense.weight', 'base_model.encoder.layer.5.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.5.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.5.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.15.attention.output.LayerNorm.bias', 'base_model.encoder.layer.17.intermediate.dense.weight', 'base_model.encoder.layer.20.intermediate.dense.weight', 'base_model.encoder.layer.5.attention.output.LayerNorm.bias', 'base_model.encoder.layer.20.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.19.output.dense.weight', 'base_model.encoder.layer.5.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.12.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.4.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.22.attention.output.dense.weight', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.15.attention.self.value.weight', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.20.output.dense.weight', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.20.attention.self.value.weight', 'base_model.encoder.layer.2.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.18.output.LayerNorm.weight', 'base_model.encoder.layer.18.attention.self.query.weight', 'base_model.encoder.layer.11.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.2.attention.output.dense.weight', 'base_model.encoder.layer.1.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.1.attention.self.key.weight', 'base_model.encoder.layer.7.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.6.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.8.attention.self.value.weight', 'base_model.encoder.layer.7.attention.self.value.weight', 'base_model.encoder.layer.7.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.11.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.16.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.1.attention.self.query.bias', 'base_model.encoder.layer.7.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.12.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.11.attention.self.value.weight', 'base_model.encoder.layer.19.attention.output.LayerNorm.weight', 'base_model.encoder.layer.2.attention.self.value.bias', 'base_model.encoder.layer.9.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.23.attention.output.dense.weight', 'base_model.encoder.layer.13.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.14.attention.self.key.weight', 'base_model.encoder.layer.12.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.9.intermediate.dense.weight', 'base_model.encoder.layer.17.intermediate.dense.bias', 'base_model.encoder.layer.18.output.LayerNorm.bias', 'base_model.encoder.layer.4.attention.output.LayerNorm.bias', 'base_model.encoder.layer.6.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.14.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.8.attention.output.dense.weight', 'base_model.encoder.layer.17.attention.self.value.weight', 'base_model.encoder.layer.15.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.15.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.23.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.15.attention.output.dense.weight', 'base_model.encoder.layer.17.output.LayerNorm.bias', 'base_model.encoder.layer.13.intermediate.dense.bias', 'base_model.encoder.layer.4.attention.self.key.bias', 'base_model.encoder.layer.19.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.9.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.21.attention.output.LayerNorm.weight', 'base_model.encoder.layer.19.attention.output.dense.bias', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.13.attention.self.value.weight', 'base_model.encoder.layer.0.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.18.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.2.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.1.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.15.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.11.attention.self.query.weight', 'base_model.encoder.layer.4.output.dense.bias', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.12.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.15.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.17.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.9.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.11.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.7.intermediate.dense.weight', 'base_model.encoder.layer.8.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.3.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.2.output.LayerNorm.bias', 'base_model.encoder.layer.11.intermediate.dense.weight', 'base_model.encoder.layer.5.attention.self.query.weight', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.10.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.8.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.13.attention.self.key.bias', 'base_model.encoder.layer.12.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.22.output.LayerNorm.weight', 'qa_outputs.bias', 'base_model.encoder.layer.6.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.14.intermediate.dense.weight', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.13.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.21.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.21.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.12.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.19.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.1.attention.self.value.bias', 'base_model.encoder.layer.0.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.1.intermediate.dense.bias', 'base_model.encoder.layer.3.output.LayerNorm.bias', 'base_model.encoder.layer.16.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.1.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.22.attention.self.value.weight', 'base_model.encoder.layer.17.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.11.attention.self.value.bias', 'base_model.encoder.layer.23.output.dense.bias', 'base_model.encoder.layer.0.attention.output.LayerNorm.bias', 'base_model.encoder.layer.18.attention.self.query.bias', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.22.attention.self.key.weight', 'base_model.encoder.layer.9.intermediate.dense.bias', 'base_model.encoder.layer.7.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.6.attention.output.dense.bias', 'base_model.encoder.layer.5.attention.self.key.weight', 'base_model.encoder.layer.0.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.7.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.21.attention.self.query.bias', 'base_model.encoder.layer.0.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.17.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.14.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.8.attention.self.query.weight', 'base_model.encoder.layer.10.attention.output.dense.bias', 'base_model.encoder.layer.3.output.LayerNorm.weight', 'base_model.encoder.layer.5.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.10.attention.self.value.weight', 'base_model.encoder.layer.12.attention.output.LayerNorm.weight', 'base_model.encoder.layer.7.output.LayerNorm.weight', 'base_model.encoder.layer.12.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.15.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.19.intermediate.dense.weight', 'qa_outputs.weight', 'base_model.encoder.layer.3.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.4.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.2.intermediate.dense.weight', 'base_model.encoder.layer.5.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.5.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.13.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.3.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.22.attention.self.key.bias', 'base_model.encoder.layer.6.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.16.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.18.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.6.intermediate.dense.weight', 'base_model.encoder.layer.20.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.14.output.LayerNorm.weight', 'base_model.encoder.layer.1.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.1.output.LayerNorm.weight', 'base_model.encoder.layer.20.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.19.output.dense.bias', 'base_model.encoder.layer.10.attention.self.query.weight', 'base_model.encoder.layer.18.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.22.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.20.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.22.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.14.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.10.attention.output.dense.weight', 'base_model.encoder.layer.22.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.4.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.17.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.22.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.10.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.20.attention.self.key.bias', 'base_model.encoder.layer.3.attention.self.key.weight', 'base_model.encoder.layer.17.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.8.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.11.intermediate.dense.bias', 'base_model.encoder.layer.4.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.4.output.LayerNorm.bias', 'base_model.encoder.layer.17.attention.output.dense.weight', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.3.attention.output.dense.weight', 'base_model.encoder.layer.6.attention.output.LayerNorm.bias', 'base_model.encoder.layer.6.output.LayerNorm.bias', 'base_model.encoder.layer.16.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.10.attention.output.LayerNorm.bias', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.22.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.14.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.2.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.3.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.2.output.dense.bias', 'base_model.encoder.layer.11.attention.self.query.bias', 'base_model.encoder.layer.1.output.LayerNorm.bias', 'base_model.encoder.layer.4.attention.self.query.bias', 'base_model.encoder.layer.7.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.11.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.8.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.21.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.0.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.6.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.13.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.9.attention.self.value.weight', 'base_model.encoder.layer.16.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.15.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.13.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.0.output.LayerNorm.bias', 'base_model.encoder.layer.8.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.9.attention.output.LayerNorm.weight', 'base_model.encoder.layer.5.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.12.attention.output.dense.weight', 'base_model.encoder.layer.20.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.15.output.dense.weight', 'base_model.encoder.layer.2.attention.output.LayerNorm.weight', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.4.attention.self.value.weight', 'base_model.encoder.layer.4.intermediate.dense.weight', 'base_model.encoder.layer.5.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.13.attention.output.LayerNorm.bias', 'base_model.encoder.layer.19.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.3.intermediate.dense.bias', 'base_model.encoder.layer.13.attention.self.query.weight', 'base_model.encoder.layer.17.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.6.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.3.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.5.output.dense.bias', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.18.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.13.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.17.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.18.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.7.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.23.attention.self.value.bias', 'base_model.encoder.layer.22.attention.self.query.weight', 'base_model.encoder.layer.1.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.12.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.22.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.8.intermediate.dense.bias', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.22.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.3.attention.self.value.bias', 'base_model.encoder.layer.7.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.1.attention.self.query.weight', 'base_model.encoder.layer.5.attention.self.query.bias', 'base_model.encoder.layer.19.attention.self.query.bias', 'base_model.encoder.layer.8.intermediate.dense.weight', 'base_model.encoder.layer.20.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.14.output.dense.weight', 'base_model.encoder.layer.22.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.4.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.12.attention.self.value.bias', 'base_model.encoder.layer.23.output.adapters.tp.adapter_down.0.bias', 'base_model.embeddings.LayerNorm.bias', 'base_model.encoder.layer.0.attention.self.value.bias', 'base_model.encoder.layer.20.intermediate.dense.bias', 'base_model.embeddings.position_ids', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.10.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.3.attention.self.key.bias', 'base_model.encoder.layer.8.attention.output.LayerNorm.weight', 'base_model.encoder.layer.13.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.9.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.20.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.5.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.18.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.20.attention.self.value.bias', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.9.attention.output.dense.bias', 'base_model.encoder.layer.16.attention.self.query.weight', 'base_model.encoder.layer.20.output.LayerNorm.weight', 'base_model.encoder.layer.21.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.9.attention.output.dense.weight', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.3.intermediate.dense.weight', 'base_model.encoder.layer.14.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.3.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.0.attention.self.value.weight', 'base_model.encoder.layer.7.attention.output.dense.bias', 'base_model.encoder.layer.11.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.15.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.23.attention.output.LayerNorm.weight', 'base_model.encoder.layer.7.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.9.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.11.attention.output.LayerNorm.weight', 'base_model.encoder.layer.8.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.9.output.dense.bias', 'base_model.encoder.layer.15.attention.output.LayerNorm.weight', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.12.attention.self.value.weight', 'base_model.encoder.layer.23.attention.self.key.weight', 'base_model.encoder.layer.3.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.6.attention.self.query.weight', 'base_model.encoder.layer.8.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.11.output.dense.bias', 'base_model.encoder.layer.20.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.9.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.16.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.9.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.4.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.15.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.1.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.5.attention.output.dense.bias', 'base_model.encoder.layer.23.output.LayerNorm.weight', 'base_model.encoder.layer.10.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.11.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.10.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.23.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.21.attention.self.key.weight', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.12.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.1.output.dense.weight', 'base_model.encoder.layer.10.attention.self.query.bias']
- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of XLMRobertaModel were not initialized from the model checkpoint at /cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//tydiqa/xlm-KG_LR8e-6_EPOCH2.0_maxlen384_batchsize4_gradacc4 and are newly initialized: ['encoder.layer.3.output.dense.weight', 'encoder.layer.19.attention.self.value.weight', 'encoder.layer.20.intermediate.dense.weight', 'encoder.layer.19.attention.output.LayerNorm.bias', 'encoder.layer.21.attention.self.query.weight', 'encoder.layer.14.attention.output.dense.bias', 'encoder.layer.0.attention.self.key.bias', 'encoder.layer.22.attention.output.dense.bias', 'encoder.layer.9.attention.self.query.weight', 'encoder.layer.12.attention.self.value.bias', 'encoder.layer.17.attention.self.query.bias', 'encoder.layer.5.attention.self.value.bias', 'encoder.layer.15.attention.self.value.weight', 'encoder.layer.3.attention.self.key.weight', 'encoder.layer.21.attention.output.dense.weight', 'encoder.layer.2.attention.output.LayerNorm.bias', 'encoder.layer.14.attention.output.LayerNorm.weight', 'encoder.layer.18.attention.output.dense.weight', 'encoder.layer.17.attention.output.LayerNorm.weight', 'encoder.layer.11.attention.output.LayerNorm.weight', 'encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.layer.11.attention.self.query.bias', 'encoder.layer.5.attention.self.key.bias', 'encoder.layer.2.attention.self.value.bias', 'encoder.layer.16.attention.self.key.bias', 'encoder.layer.10.attention.output.LayerNorm.weight', 'encoder.layer.23.output.LayerNorm.bias', 'encoder.layer.13.attention.self.key.weight', 'encoder.layer.18.attention.self.key.weight', 'encoder.layer.16.intermediate.dense.bias', 'encoder.layer.2.output.dense.bias', 'encoder.layer.15.attention.self.key.weight', 'encoder.layer.14.output.LayerNorm.weight', 'encoder.layer.17.output.dense.weight', 'encoder.layer.2.attention.output.dense.bias', 'encoder.layer.1.attention.output.dense.weight', 'encoder.layer.10.attention.output.dense.bias', 'encoder.layer.15.attention.output.LayerNorm.weight', 'encoder.layer.17.output.dense.bias', 'encoder.layer.18.intermediate.dense.bias', 'encoder.layer.9.attention.output.dense.weight', 'encoder.layer.23.attention.self.value.weight', 'encoder.layer.17.attention.output.LayerNorm.bias', 'encoder.layer.8.attention.output.LayerNorm.bias', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.5.output.dense.weight', 'encoder.layer.19.output.dense.bias', 'encoder.layer.13.attention.output.dense.weight', 'encoder.layer.20.attention.self.key.weight', 'encoder.layer.23.output.dense.bias', 'encoder.layer.9.attention.self.key.weight', 'encoder.layer.21.output.dense.weight', 'encoder.layer.19.attention.self.key.bias', 'encoder.layer.19.attention.self.key.weight', 'encoder.layer.22.output.dense.weight', 'encoder.layer.7.output.LayerNorm.weight', 'encoder.layer.19.output.LayerNorm.bias', 'encoder.layer.14.output.dense.weight', 'encoder.layer.1.output.dense.weight', 'encoder.layer.22.output.dense.bias', 'encoder.layer.10.attention.self.query.bias', 'encoder.layer.12.attention.self.key.weight', 'encoder.layer.7.attention.output.LayerNorm.bias', 'encoder.layer.8.attention.self.query.weight', 'encoder.layer.22.attention.output.LayerNorm.weight', 'encoder.layer.8.output.LayerNorm.bias', 'encoder.layer.4.attention.output.dense.bias', 'encoder.layer.16.output.LayerNorm.weight', 'encoder.layer.10.output.LayerNorm.weight', 'encoder.layer.3.output.dense.bias', 'encoder.layer.10.attention.self.value.bias', 'encoder.layer.10.attention.self.key.weight', 'encoder.layer.11.attention.self.key.bias', 'encoder.layer.20.output.LayerNorm.bias', 'encoder.layer.13.attention.self.key.bias', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.14.attention.self.value.bias', 'encoder.layer.7.attention.self.query.bias', 'encoder.layer.17.attention.self.key.bias', 'encoder.layer.13.output.LayerNorm.weight', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.0.attention.self.key.weight', 'encoder.layer.1.attention.self.value.weight', 'encoder.layer.17.attention.self.value.weight', 'encoder.layer.16.attention.self.value.weight', 'encoder.layer.7.attention.output.dense.bias', 'encoder.layer.0.output.dense.weight', 'encoder.layer.11.attention.self.value.bias', 'encoder.layer.17.attention.self.query.weight', 'encoder.layer.12.attention.self.key.bias', 'encoder.layer.9.attention.output.LayerNorm.bias', 'encoder.layer.14.attention.self.query.bias', 'encoder.layer.9.attention.output.dense.bias', 'encoder.layer.22.attention.self.key.bias', 'encoder.layer.20.attention.self.value.weight', 'encoder.layer.15.output.LayerNorm.bias', 'encoder.layer.3.attention.self.query.bias', 'encoder.layer.23.attention.self.key.weight', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.8.attention.self.key.bias', 'encoder.layer.4.attention.self.value.weight', 'encoder.layer.23.attention.output.LayerNorm.bias', 'encoder.layer.7.attention.self.value.bias', 'encoder.layer.6.attention.self.query.weight', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.14.intermediate.dense.bias', 'encoder.layer.19.attention.self.query.weight', 'encoder.layer.17.output.LayerNorm.bias', 'encoder.layer.21.output.LayerNorm.bias', 'encoder.layer.12.output.dense.bias', 'encoder.layer.5.attention.output.dense.weight', 'encoder.layer.8.attention.self.value.bias', 'encoder.layer.12.output.LayerNorm.weight', 'encoder.layer.12.intermediate.dense.bias', 'encoder.layer.18.attention.output.LayerNorm.weight', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.14.intermediate.dense.weight', 'encoder.layer.15.attention.output.LayerNorm.bias', 'encoder.layer.6.attention.self.key.bias', 'encoder.layer.8.attention.self.query.bias', 'encoder.layer.7.intermediate.dense.bias', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.21.attention.self.key.bias', 'embeddings.token_type_embeddings.weight', 'encoder.layer.22.attention.output.dense.weight', 'encoder.layer.9.output.dense.weight', 'encoder.layer.3.attention.self.query.weight', 'encoder.layer.14.attention.self.key.bias', 'encoder.layer.4.attention.self.key.weight', 'encoder.layer.2.attention.output.LayerNorm.weight', 'encoder.layer.15.attention.output.dense.bias', 'encoder.layer.18.attention.self.value.weight', 'encoder.layer.13.attention.output.LayerNorm.weight', 'encoder.layer.18.attention.output.LayerNorm.bias', 'encoder.layer.4.attention.self.key.bias', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.16.attention.output.LayerNorm.bias', 'encoder.layer.19.intermediate.dense.weight', 'encoder.layer.10.attention.self.key.bias', 'encoder.layer.20.output.dense.bias', 'encoder.layer.14.output.LayerNorm.bias', 'encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.layer.0.output.dense.bias', 'encoder.layer.13.attention.output.dense.bias', 'encoder.layer.15.attention.self.query.bias', 'encoder.layer.4.attention.output.dense.weight', 'encoder.layer.20.attention.self.query.bias', 'embeddings.LayerNorm.bias', 'encoder.layer.0.attention.self.query.bias', 'encoder.layer.23.attention.self.query.bias', 'encoder.layer.5.attention.output.dense.bias', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.18.attention.self.value.bias', 'encoder.layer.2.attention.self.query.weight', 'encoder.layer.15.attention.self.query.weight', 'encoder.layer.10.output.LayerNorm.bias', 'encoder.layer.15.attention.self.key.bias', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.22.output.LayerNorm.weight', 'encoder.layer.7.attention.output.dense.weight', 'encoder.layer.19.attention.self.query.bias', 'encoder.layer.6.attention.output.LayerNorm.bias', 'encoder.layer.1.attention.output.LayerNorm.weight', 'encoder.layer.23.attention.output.dense.weight', 'pooler.dense.weight', 'embeddings.position_embeddings.weight', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.9.attention.self.value.bias', 'encoder.layer.3.attention.self.value.weight', 'encoder.layer.20.attention.output.dense.bias', 'encoder.layer.21.attention.self.value.bias', 'encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.layer.6.output.LayerNorm.bias', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.9.attention.output.LayerNorm.weight', 'encoder.layer.22.output.LayerNorm.bias', 'encoder.layer.7.attention.output.LayerNorm.weight', 'encoder.layer.19.output.LayerNorm.weight', 'encoder.layer.20.attention.output.LayerNorm.weight', 'encoder.layer.22.attention.self.query.weight', 'encoder.layer.7.output.dense.weight', 'encoder.layer.19.attention.self.value.bias', 'encoder.layer.17.attention.self.value.bias', 'encoder.layer.21.output.LayerNorm.weight', 'encoder.layer.10.output.dense.bias', 'encoder.layer.17.attention.self.key.weight', 'encoder.layer.19.attention.output.dense.bias', 'encoder.layer.22.attention.output.LayerNorm.bias', 'encoder.layer.23.attention.output.dense.bias', 'encoder.layer.6.attention.output.LayerNorm.weight', 'encoder.layer.20.attention.self.key.bias', 'encoder.layer.7.attention.self.value.weight', 'encoder.layer.19.attention.output.dense.weight', 'encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.layer.20.attention.output.LayerNorm.bias', 'encoder.layer.10.attention.output.dense.weight', 'encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.layer.0.attention.self.query.weight', 'encoder.layer.9.output.dense.bias', 'encoder.layer.12.attention.output.dense.bias', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.13.attention.self.value.bias', 'encoder.layer.20.attention.output.dense.weight', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.10.attention.output.LayerNorm.bias', 'encoder.layer.15.output.dense.weight', 'encoder.layer.22.attention.self.key.weight', 'encoder.layer.8.attention.output.LayerNorm.weight', 'encoder.layer.16.output.dense.bias', 'encoder.layer.21.intermediate.dense.bias', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.22.attention.self.value.bias', 'encoder.layer.21.attention.output.LayerNorm.weight', 'encoder.layer.18.attention.self.query.weight', 'encoder.layer.18.attention.self.query.bias', 'encoder.layer.7.output.LayerNorm.bias', 'encoder.layer.11.attention.self.value.weight', 'encoder.layer.12.attention.output.LayerNorm.weight', 'encoder.layer.5.output.LayerNorm.bias', 'encoder.layer.21.intermediate.dense.weight', 'encoder.layer.23.attention.output.LayerNorm.weight', 'encoder.layer.17.output.LayerNorm.weight', 'encoder.layer.21.attention.output.LayerNorm.bias', 'encoder.layer.14.attention.output.dense.weight', 'encoder.layer.23.output.dense.weight', 'encoder.layer.11.output.LayerNorm.weight', 'encoder.layer.20.output.LayerNorm.weight', 'encoder.layer.21.attention.self.key.weight', 'encoder.layer.12.attention.self.query.weight', 'encoder.layer.21.output.dense.bias', 'encoder.layer.15.attention.output.dense.weight', 'encoder.layer.11.output.dense.bias', 'encoder.layer.8.attention.output.dense.weight', 'encoder.layer.5.attention.self.query.bias', 'encoder.layer.13.attention.self.value.weight', 'encoder.layer.13.attention.self.query.weight', 'encoder.layer.6.attention.output.dense.bias', 'encoder.layer.23.intermediate.dense.weight', 'encoder.layer.5.attention.self.key.weight', 'encoder.layer.4.attention.self.value.bias', 'encoder.layer.15.output.LayerNorm.weight', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.10.intermediate.dense.weight', 'encoder.layer.18.attention.self.key.bias', 'encoder.layer.2.attention.self.query.bias', 'encoder.layer.6.attention.self.query.bias', 'encoder.layer.0.attention.output.dense.weight', 'encoder.layer.12.intermediate.dense.weight', 'encoder.layer.19.intermediate.dense.bias', 'encoder.layer.22.intermediate.dense.bias', 'encoder.layer.5.output.dense.bias', 'encoder.layer.7.attention.self.query.weight', 'encoder.layer.16.attention.output.dense.weight', 'encoder.layer.9.attention.self.query.bias', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.20.attention.self.value.bias', 'encoder.layer.13.attention.output.LayerNorm.bias', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.9.output.LayerNorm.weight', 'encoder.layer.18.output.dense.bias', 'encoder.layer.17.attention.output.dense.bias', 'encoder.layer.6.attention.self.value.weight', 'encoder.layer.10.attention.self.query.weight', 'encoder.layer.11.attention.output.dense.weight', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.16.attention.self.key.weight', 'encoder.layer.12.attention.self.value.weight', 'embeddings.LayerNorm.weight', 'encoder.layer.14.attention.self.value.weight', 'encoder.layer.1.attention.self.value.bias', 'encoder.layer.3.attention.output.dense.bias', 'encoder.layer.11.attention.self.key.weight', 'encoder.layer.17.intermediate.dense.bias', 'encoder.layer.2.attention.self.value.weight', 'encoder.layer.16.attention.output.dense.bias', 'encoder.layer.12.attention.output.dense.weight', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.15.attention.self.value.bias', 'encoder.layer.13.intermediate.dense.weight', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.20.intermediate.dense.bias', 'encoder.layer.21.attention.self.value.weight', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.16.output.LayerNorm.bias', 'encoder.layer.18.output.LayerNorm.bias', 'encoder.layer.4.attention.output.LayerNorm.weight', 'encoder.layer.15.intermediate.dense.bias', 'encoder.layer.1.attention.self.key.weight', 'encoder.layer.22.attention.self.value.weight', 'encoder.layer.20.output.dense.weight', 'encoder.layer.4.attention.output.LayerNorm.bias', 'encoder.layer.6.output.dense.bias', 'encoder.layer.6.attention.self.key.weight', 'encoder.layer.13.output.LayerNorm.bias', 'encoder.layer.23.attention.self.key.bias', 'encoder.layer.18.attention.output.dense.bias', 'encoder.layer.1.attention.self.query.weight', 'encoder.layer.14.attention.self.key.weight', 'encoder.layer.8.attention.output.dense.bias', 'encoder.layer.2.attention.self.key.weight', 'encoder.layer.12.attention.output.LayerNorm.bias', 'encoder.layer.3.attention.output.dense.weight', 'encoder.layer.16.attention.output.LayerNorm.weight', 'encoder.layer.8.output.dense.bias', 'encoder.layer.14.attention.self.query.weight', 'encoder.layer.15.output.dense.bias', 'encoder.layer.18.output.dense.weight', 'encoder.layer.13.output.dense.bias', 'encoder.layer.0.attention.self.value.bias', 'encoder.layer.21.attention.output.dense.bias', 'encoder.layer.0.attention.output.LayerNorm.weight', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.11.attention.output.dense.bias', 'encoder.layer.0.attention.output.dense.bias', 'encoder.layer.3.attention.output.LayerNorm.bias', 'embeddings.word_embeddings.weight', 'encoder.layer.14.output.dense.bias', 'encoder.layer.7.attention.self.key.bias', 'encoder.layer.2.attention.self.key.bias', 'encoder.layer.16.attention.self.query.bias', 'encoder.layer.5.attention.output.LayerNorm.weight', 'encoder.layer.10.output.dense.weight', 'encoder.layer.12.output.LayerNorm.bias', 'encoder.layer.1.output.dense.bias', 'encoder.layer.18.output.LayerNorm.weight', 'encoder.layer.1.attention.output.dense.bias', 'encoder.layer.8.output.dense.weight', 'encoder.layer.9.output.LayerNorm.bias', 'encoder.layer.13.intermediate.dense.bias', 'encoder.layer.8.output.LayerNorm.weight', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.22.attention.self.query.bias', 'pooler.dense.bias', 'encoder.layer.6.output.dense.weight', 'encoder.layer.3.attention.self.value.bias', 'encoder.layer.18.intermediate.dense.weight', 'encoder.layer.6.attention.output.dense.weight', 'encoder.layer.19.output.dense.weight', 'encoder.layer.23.intermediate.dense.bias', 'encoder.layer.23.attention.self.value.bias', 'encoder.layer.23.attention.self.query.weight', 'encoder.layer.7.attention.self.key.weight', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.11.output.LayerNorm.bias', 'encoder.layer.19.attention.output.LayerNorm.weight', 'encoder.layer.0.attention.self.value.weight', 'encoder.layer.4.output.dense.weight', 'encoder.layer.9.attention.self.key.bias', 'encoder.layer.3.attention.self.key.bias', 'encoder.layer.5.attention.self.query.weight', 'encoder.layer.13.output.dense.weight', 'encoder.layer.8.attention.self.key.weight', 'encoder.layer.10.attention.self.value.weight', 'encoder.layer.2.attention.output.dense.weight', 'encoder.layer.13.attention.self.query.bias', 'encoder.layer.15.intermediate.dense.weight', 'encoder.layer.8.attention.self.value.weight', 'encoder.layer.16.output.dense.weight', 'encoder.layer.16.intermediate.dense.weight', 'encoder.layer.4.attention.self.query.bias', 'encoder.layer.6.attention.self.value.bias', 'encoder.layer.7.output.dense.bias', 'encoder.layer.11.attention.self.query.weight', 'encoder.layer.16.attention.self.value.bias', 'encoder.layer.11.output.dense.weight', 'encoder.layer.9.attention.self.value.weight', 'encoder.layer.23.output.LayerNorm.weight', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.21.attention.self.query.bias', 'encoder.layer.4.output.dense.bias', 'encoder.layer.1.attention.self.query.bias', 'encoder.layer.14.attention.output.LayerNorm.bias', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.17.intermediate.dense.weight', 'encoder.layer.20.attention.self.query.weight', 'encoder.layer.17.attention.output.dense.weight', 'encoder.layer.12.attention.self.query.bias', 'encoder.layer.1.attention.self.key.bias', 'encoder.layer.5.attention.self.value.weight', 'encoder.layer.2.output.dense.weight', 'encoder.layer.12.output.dense.weight', 'encoder.layer.16.attention.self.query.weight', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.4.attention.self.query.weight', 'encoder.layer.22.intermediate.dense.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Overwriting existing adapter 'ep'.
Overwriting existing adapter 'tp'.
Overwriting existing adapter 'es'.
Overwriting existing adapter 'ts'.
Overwriting existing adapter fusion module 'ep,tp,es,ts'
05/09/2022 22:50:15 - INFO - __main__ -   lang2id = None
05/09/2022 22:50:18 - INFO - __main__ -   Training/evaluation parameters Namespace(adam_epsilon=1e-08, cache_dir='', config_name='', data_dir=None, device=device(type='cuda'), do_eval=True, do_lower_case=False, do_train=False, doc_stride=128, eval_all_checkpoints=False, eval_lang='ar', evaluate_during_training=False, fp16=False, fp16_opt_level='O1', gradient_accumulation_steps=1, learning_rate=5e-05, local_rank=-1, logging_steps=50, max_answer_length=30, max_grad_norm=1.0, max_query_length=64, max_seq_length=384, max_steps=-1, model_name='xlm-KG', model_name_or_path='/cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//tydiqa/xlm-KG_LR8e-6_EPOCH2.0_maxlen384_batchsize4_gradacc4', model_type='xlm', modelkg_dir='/cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/adapter/xlmr_adapter', n_best_size=20, n_gpu=1, no_cuda=False, null_score_diff_threshold=0.0, num_train_epochs=3.0, output_dir='/cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//tydiqa/xlm-KG_LR8e-6_EPOCH2.0_maxlen384_batchsize4_gradacc4/predictions/tydiqa/', overwrite_cache=False, overwrite_output_dir=False, per_gpu_eval_batch_size=8, per_gpu_train_batch_size=8, predict_file='/cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/download//tydiqa//tydiqa-goldp-v1.1-dev/tydiqa.goldp.ar.dev.json', save_steps=50, seed=42, server_ip='', server_port='', threads=1, tokenizer_name='', train_file=None, train_lang='en', verbose_logging=False, version_2_with_negative=False, warmup_steps=0, weight_decay=0.0)
05/09/2022 22:50:18 - INFO - __main__ -   Loading checkpoint /cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//tydiqa/xlm-KG_LR8e-6_EPOCH2.0_maxlen384_batchsize4_gradacc4 for evaluation
05/09/2022 22:50:18 - INFO - __main__ -   Evaluate the following checkpoints: ['/cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//tydiqa/xlm-KG_LR8e-6_EPOCH2.0_maxlen384_batchsize4_gradacc4']
Some weights of the model checkpoint at /cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//tydiqa/xlm-KG_LR8e-6_EPOCH2.0_maxlen384_batchsize4_gradacc4 were not used when initializing XLMRobertaModel: ['base_model.encoder.layer.8.output.LayerNorm.bias', 'base_model.encoder.layer.13.attention.self.value.bias', 'base_model.encoder.layer.16.intermediate.dense.bias', 'base_model.encoder.layer.16.attention.self.value.weight', 'base_model.encoder.layer.7.output.LayerNorm.bias', 'base_model.encoder.layer.3.output.dense.bias', 'base_model.encoder.layer.16.output.dense.weight', 'base_model.encoder.layer.20.attention.output.dense.bias', 'base_model.encoder.layer.10.output.dense.bias', 'base_model.encoder.layer.12.attention.self.query.bias', 'base_model.encoder.layer.9.attention.self.key.weight', 'base_model.encoder.layer.10.intermediate.dense.weight', 'base_model.encoder.layer.8.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.3.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.12.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.21.attention.output.dense.weight', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.0.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.19.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.14.attention.output.dense.bias', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.0.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.3.attention.output.LayerNorm.weight', 'base_model.encoder.layer.3.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.17.attention.output.LayerNorm.weight', 'base_model.encoder.layer.10.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.22.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.2.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.16.attention.output.LayerNorm.weight', 'base_model.encoder.layer.16.output.LayerNorm.bias', 'base_model.encoder.layer.12.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.17.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.20.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.2.attention.self.key.weight', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.10.output.dense.weight', 'base_model.encoder.layer.0.output.dense.weight', 'base_model.encoder.layer.5.intermediate.dense.weight', 'base_model.encoder.layer.23.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.4.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.10.attention.self.value.bias', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.4.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.1.attention.self.value.weight', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.22.attention.output.LayerNorm.weight', 'base_model.encoder.layer.11.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.10.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.5.attention.self.value.bias', 'base_model.encoder.layer.13.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.2.attention.self.query.weight', 'base_model.encoder.layer.9.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.10.attention.output.LayerNorm.weight', 'base_model.encoder.layer.2.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.17.output.dense.bias', 'base_model.encoder.layer.20.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.21.attention.output.dense.bias', 'base_model.encoder.layer.21.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.23.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.3.attention.output.dense.bias', 'base_model.encoder.layer.16.attention.self.query.bias', 'base_model.encoder.layer.5.attention.output.LayerNorm.weight', 'base_model.encoder.layer.8.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.11.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.12.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.8.output.LayerNorm.weight', 'base_model.encoder.layer.14.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.19.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.7.intermediate.dense.bias', 'base_model.encoder.layer.22.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.16.intermediate.dense.weight', 'base_model.encoder.layer.17.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.3.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.14.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.8.attention.self.key.weight', 'base_model.encoder.layer.13.output.dense.bias', 'base_model.encoder.layer.14.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.15.attention.output.dense.bias', 'base_model.encoder.layer.22.attention.output.dense.bias', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.22.output.dense.bias', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.6.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.8.attention.output.LayerNorm.bias', 'base_model.encoder.layer.21.attention.self.key.bias', 'base_model.encoder.layer.13.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.6.attention.self.value.weight', 'base_model.encoder.layer.8.attention.self.query.bias', 'base_model.encoder.layer.11.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.0.attention.output.LayerNorm.weight', 'base_model.encoder.layer.15.attention.self.query.bias', 'base_model.encoder.layer.15.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.19.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.18.intermediate.dense.weight', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.15.output.dense.bias', 'base_model.encoder.layer.18.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.8.output.dense.bias', 'base_model.encoder.layer.15.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.1.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.18.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.17.attention.self.value.bias', 'base_model.encoder.layer.3.attention.self.query.weight', 'base_model.encoder.layer.22.output.dense.weight', 'base_model.encoder.layer.11.attention.self.key.weight', 'base_model.encoder.layer.17.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.7.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.9.attention.self.query.weight', 'base_model.encoder.layer.15.intermediate.dense.bias', 'base_model.encoder.layer.4.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.23.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.17.attention.self.query.bias', 'base_model.encoder.layer.19.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.12.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.2.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.0.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.20.attention.output.LayerNorm.weight', 'base_model.encoder.layer.10.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.23.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.0.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.14.attention.output.LayerNorm.bias', 'base_model.encoder.layer.15.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.15.attention.self.value.bias', 'base_model.encoder.layer.19.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.6.attention.self.value.bias', 'base_model.encoder.layer.2.attention.output.LayerNorm.bias', 'base_model.encoder.layer.15.intermediate.dense.weight', 'base_model.pooler.dense.weight', 'base_model.encoder.layer.23.attention.self.query.weight', 'base_model.encoder.layer.1.attention.output.dense.bias', 'base_model.encoder.layer.0.attention.self.query.weight', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.23.attention.output.dense.bias', 'base_model.encoder.layer.18.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.21.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.18.attention.self.value.bias', 'base_model.encoder.layer.4.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.8.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.2.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.23.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.1.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.10.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.5.output.LayerNorm.weight', 'base_model.encoder.layer.5.intermediate.dense.bias', 'base_model.encoder.layer.9.attention.self.key.bias', 'base_model.encoder.layer.0.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.6.attention.self.key.weight', 'base_model.encoder.layer.0.intermediate.dense.bias', 'base_model.encoder.layer.3.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.2.attention.self.value.weight', 'base_model.encoder.layer.9.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.14.attention.self.value.bias', 'base_model.encoder.layer.18.attention.output.LayerNorm.weight', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.8.output.dense.weight', 'base_model.encoder.layer.6.output.dense.weight', 'base_model.encoder.layer.16.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.22.intermediate.dense.weight', 'base_model.encoder.layer.15.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.19.attention.output.dense.weight', 'base_model.encoder.layer.3.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.1.intermediate.dense.weight', 'base_model.encoder.layer.3.attention.self.query.bias', 'base_model.encoder.layer.21.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.19.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.13.intermediate.dense.weight', 'base_model.encoder.layer.16.attention.self.key.bias', 'base_model.encoder.layer.6.attention.self.query.bias', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.21.output.dense.weight', 'base_model.encoder.layer.4.attention.self.query.weight', 'base_model.encoder.layer.16.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.9.output.LayerNorm.bias', 'base_model.encoder.layer.11.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.9.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.19.attention.self.key.weight', 'base_model.encoder.layer.14.output.LayerNorm.bias', 'base_model.encoder.layer.21.intermediate.dense.bias', 'base_model.embeddings.token_type_embeddings.weight', 'base_model.encoder.layer.3.attention.self.value.weight', 'base_model.encoder.layer.9.attention.self.query.bias', 'base_model.encoder.layer.17.output.dense.weight', 'base_model.encoder.layer.11.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.20.attention.output.dense.weight', 'base_model.encoder.layer.11.output.LayerNorm.weight', 'base_model.encoder.layer.23.attention.self.key.bias', 'base_model.encoder.layer.17.attention.output.LayerNorm.bias', 'base_model.encoder.layer.21.output.dense.bias', 'base_model.encoder.layer.9.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.19.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.2.attention.self.query.bias', 'base_model.encoder.layer.2.output.dense.weight', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.19.attention.output.LayerNorm.bias', 'base_model.encoder.layer.22.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.19.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.4.attention.self.key.weight', 'base_model.encoder.layer.10.output.LayerNorm.weight', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.7.attention.self.key.bias', 'base_model.encoder.layer.12.output.dense.bias', 'base_model.encoder.layer.8.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.4.attention.self.value.bias', 'base_model.encoder.layer.1.output.dense.bias', 'base_model.encoder.layer.20.attention.self.query.bias', 'base_model.encoder.layer.20.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.7.attention.self.value.bias', 'base_model.encoder.layer.21.attention.self.value.weight', 'base_model.encoder.layer.16.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.17.attention.output.dense.bias', 'base_model.encoder.layer.1.attention.output.LayerNorm.bias', 'base_model.encoder.layer.2.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.23.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.6.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.10.output.LayerNorm.bias', 'base_model.encoder.layer.2.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.19.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.1.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.21.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.16.attention.output.LayerNorm.bias', 'base_model.encoder.layer.9.output.LayerNorm.weight', 'base_model.encoder.layer.13.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.12.attention.self.query.weight', 'base_model.encoder.layer.16.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.23.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.17.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.12.attention.self.key.bias', 'base_model.encoder.layer.18.output.dense.weight', 'base_model.encoder.layer.21.output.LayerNorm.bias', 'base_model.encoder.layer.20.attention.self.key.weight', 'base_model.encoder.layer.20.output.dense.bias', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.14.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.2.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.0.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.1.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.10.intermediate.dense.bias', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.15.output.LayerNorm.bias', 'base_model.encoder.layer.22.attention.output.LayerNorm.bias', 'base_model.encoder.layer.12.output.dense.weight', 'base_model.encoder.layer.2.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.15.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.17.attention.self.key.weight', 'base_model.encoder.layer.4.attention.output.dense.weight', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.19.attention.self.query.weight', 'base_model.encoder.layer.6.attention.output.LayerNorm.weight', 'base_model.encoder.layer.14.output.dense.bias', 'base_model.encoder.layer.15.attention.self.query.weight', 'base_model.encoder.layer.13.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.0.output.LayerNorm.weight', 'base_model.encoder.layer.0.attention.output.dense.weight', 'base_model.encoder.layer.23.intermediate.dense.weight', 'base_model.encoder.layer.7.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.18.output.dense.bias', 'base_model.encoder.layer.12.attention.output.dense.bias', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.13.output.dense.weight', 'base_model.encoder.layer.23.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.13.attention.output.dense.weight', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.0.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.12.output.LayerNorm.bias', 'base_model.encoder.layer.21.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.18.attention.output.dense.bias', 'base_model.encoder.layer.4.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.20.attention.output.LayerNorm.bias', 'base_model.pooler.dense.bias', 'base_model.encoder.layer.9.attention.output.LayerNorm.bias', 'base_model.encoder.layer.6.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.21.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.2.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.18.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.21.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.10.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.10.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.23.intermediate.dense.bias', 'base_model.encoder.layer.9.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.18.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.17.output.LayerNorm.weight', 'base_model.encoder.layer.15.output.LayerNorm.weight', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.0.attention.self.query.bias', 'base_model.encoder.layer.6.intermediate.dense.bias', 'base_model.encoder.layer.9.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.15.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.20.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.12.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.2.attention.output.dense.bias', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.17.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.embeddings.position_embeddings.weight', 'base_model.embeddings.word_embeddings.weight', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.5.output.LayerNorm.bias', 'base_model.encoder.layer.13.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.20.attention.self.query.weight', 'base_model.encoder.layer.14.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.17.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.2.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.21.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.23.output.LayerNorm.bias', 'base_model.encoder.layer.23.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.7.attention.self.key.weight', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.0.attention.self.key.bias', 'base_model.encoder.layer.19.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.7.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.8.attention.self.value.bias', 'base_model.encoder.layer.2.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.23.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.16.attention.self.key.weight', 'base_model.encoder.layer.10.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.18.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.0.attention.output.dense.bias', 'base_model.encoder.layer.14.attention.self.query.bias', 'base_model.encoder.layer.6.output.LayerNorm.weight', 'base_model.encoder.layer.11.attention.output.dense.weight', 'base_model.encoder.layer.7.attention.self.query.weight', 'base_model.encoder.layer.15.attention.self.key.weight', 'base_model.encoder.layer.1.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.19.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.17.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.19.attention.self.key.bias', 'base_model.encoder.layer.13.output.LayerNorm.weight', 'base_model.encoder.layer.0.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.6.output.dense.bias', 'base_model.encoder.layer.6.attention.self.key.bias', 'base_model.encoder.layer.1.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.16.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.21.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.15.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.16.output.LayerNorm.weight', 'base_model.encoder.layer.8.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.13.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.19.output.LayerNorm.weight', 'base_model.encoder.layer.2.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.5.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.12.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.23.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.2.intermediate.dense.bias', 'base_model.encoder.layer.3.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.20.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.14.attention.self.query.weight', 'base_model.encoder.layer.1.attention.output.dense.weight', 'base_model.encoder.layer.14.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.14.intermediate.dense.bias', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.12.attention.self.key.weight', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.10.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.22.output.LayerNorm.bias', 'base_model.encoder.layer.16.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.22.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.3.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.2.attention.self.key.bias', 'base_model.encoder.layer.12.intermediate.dense.bias', 'base_model.encoder.layer.16.attention.output.dense.bias', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.21.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.1.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.4.attention.output.LayerNorm.weight', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.8.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.18.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.21.attention.self.value.bias', 'base_model.encoder.layer.13.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.4.intermediate.dense.bias', 'base_model.encoder.layer.7.output.dense.weight', 'base_model.encoder.layer.16.output.dense.bias', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.5.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.6.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.4.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.13.attention.self.query.bias', 'base_model.encoder.layer.20.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.11.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.19.attention.self.value.bias', 'base_model.encoder.layer.0.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.18.attention.self.value.weight', 'base_model.encoder.layer.22.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.16.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.4.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.19.output.LayerNorm.bias', 'base_model.encoder.layer.18.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.1.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.12.intermediate.dense.weight', 'base_model.encoder.layer.21.intermediate.dense.weight', 'base_model.encoder.layer.4.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.0.attention.self.key.weight', 'base_model.encoder.layer.14.attention.output.LayerNorm.weight', 'base_model.encoder.layer.23.attention.output.LayerNorm.bias', 'base_model.encoder.layer.21.attention.output.LayerNorm.bias', 'base_model.encoder.layer.10.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.11.output.dense.weight', 'base_model.encoder.layer.17.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.7.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.10.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.2.output.LayerNorm.weight', 'base_model.encoder.layer.8.attention.self.key.bias', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.4.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.9.attention.self.value.bias', 'base_model.encoder.layer.12.output.LayerNorm.weight', 'base_model.encoder.layer.7.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.16.attention.output.dense.weight', 'base_model.encoder.layer.20.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.13.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.22.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.14.attention.self.key.bias', 'base_model.encoder.layer.22.attention.self.value.bias', 'base_model.encoder.layer.1.attention.self.key.bias', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.15.attention.self.key.bias', 'base_model.encoder.layer.1.attention.output.LayerNorm.weight', 'base_model.encoder.layer.11.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.2.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.18.attention.output.dense.weight', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.7.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.9.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.20.output.LayerNorm.bias', 'base_model.encoder.layer.20.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.23.attention.self.value.weight', 'base_model.encoder.layer.7.attention.output.LayerNorm.bias', 'base_model.encoder.layer.5.attention.self.key.bias', 'base_model.encoder.layer.11.attention.output.dense.bias', 'base_model.encoder.layer.19.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.21.output.LayerNorm.weight', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.13.attention.output.LayerNorm.weight', 'base_model.encoder.layer.4.output.LayerNorm.weight', 'base_model.encoder.layer.21.attention.self.query.weight', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.12.attention.output.LayerNorm.bias', 'base_model.encoder.layer.11.attention.self.key.bias', 'base_model.encoder.layer.18.attention.self.key.bias', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.15.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.16.attention.self.value.bias', 'base_model.encoder.layer.4.attention.output.dense.bias', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.6.attention.output.dense.weight', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.14.output.adapters.ep.adapter_down.0.bias', 'base_model.embeddings.LayerNorm.weight', 'base_model.encoder.layer.9.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.0.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.1.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.4.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.5.attention.self.value.weight', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.14.attention.self.value.weight', 'base_model.encoder.layer.18.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.19.intermediate.dense.bias', 'base_model.encoder.layer.9.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.7.attention.self.query.bias', 'base_model.encoder.layer.5.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.12.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.22.intermediate.dense.bias', 'base_model.encoder.layer.8.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.8.attention.output.dense.bias', 'base_model.encoder.layer.7.attention.output.LayerNorm.weight', 'base_model.encoder.layer.0.output.dense.bias', 'base_model.encoder.layer.6.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.21.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.23.attention.self.query.bias', 'base_model.encoder.layer.1.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.7.output.dense.bias', 'base_model.encoder.layer.11.output.LayerNorm.bias', 'base_model.encoder.layer.17.attention.self.query.weight', 'base_model.encoder.layer.21.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.6.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.7.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.23.output.dense.weight', 'base_model.encoder.layer.17.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.13.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.14.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.5.output.dense.weight', 'base_model.encoder.layer.5.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.9.output.dense.weight', 'base_model.encoder.layer.7.attention.output.dense.weight', 'base_model.encoder.layer.3.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.6.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.3.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.18.intermediate.dense.bias', 'base_model.encoder.layer.18.attention.output.LayerNorm.bias', 'base_model.encoder.layer.6.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.8.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.11.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.10.attention.self.key.weight', 'base_model.encoder.layer.3.attention.output.LayerNorm.bias', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.11.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.0.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.16.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.14.attention.output.dense.weight', 'base_model.encoder.layer.16.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.14.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.0.intermediate.dense.weight', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.11.attention.output.LayerNorm.bias', 'base_model.encoder.layer.18.attention.self.key.weight', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.8.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.22.attention.self.query.bias', 'base_model.encoder.layer.13.attention.output.dense.bias', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.5.attention.output.dense.weight', 'base_model.encoder.layer.6.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.23.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.13.attention.self.key.weight', 'base_model.encoder.layer.6.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.10.attention.self.key.bias', 'base_model.encoder.layer.10.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.13.output.LayerNorm.bias', 'base_model.encoder.layer.17.attention.self.key.bias', 'base_model.encoder.layer.19.attention.self.value.weight', 'base_model.encoder.layer.22.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.4.output.dense.weight', 'base_model.encoder.layer.14.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.5.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.19.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.11.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.22.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.16.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.18.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.23.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.5.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.14.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.3.output.dense.weight', 'base_model.encoder.layer.5.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.5.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.5.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.15.attention.output.LayerNorm.bias', 'base_model.encoder.layer.17.intermediate.dense.weight', 'base_model.encoder.layer.20.intermediate.dense.weight', 'base_model.encoder.layer.5.attention.output.LayerNorm.bias', 'base_model.encoder.layer.20.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.19.output.dense.weight', 'base_model.encoder.layer.5.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.12.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.4.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.22.attention.output.dense.weight', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.15.attention.self.value.weight', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.20.output.dense.weight', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.20.attention.self.value.weight', 'base_model.encoder.layer.2.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.18.output.LayerNorm.weight', 'base_model.encoder.layer.18.attention.self.query.weight', 'base_model.encoder.layer.11.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.2.attention.output.dense.weight', 'base_model.encoder.layer.1.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.1.attention.self.key.weight', 'base_model.encoder.layer.7.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.6.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.8.attention.self.value.weight', 'base_model.encoder.layer.7.attention.self.value.weight', 'base_model.encoder.layer.7.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.11.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.16.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.1.attention.self.query.bias', 'base_model.encoder.layer.7.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.12.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.11.attention.self.value.weight', 'base_model.encoder.layer.19.attention.output.LayerNorm.weight', 'base_model.encoder.layer.2.attention.self.value.bias', 'base_model.encoder.layer.9.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.23.attention.output.dense.weight', 'base_model.encoder.layer.13.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.14.attention.self.key.weight', 'base_model.encoder.layer.12.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.9.intermediate.dense.weight', 'base_model.encoder.layer.17.intermediate.dense.bias', 'base_model.encoder.layer.18.output.LayerNorm.bias', 'base_model.encoder.layer.4.attention.output.LayerNorm.bias', 'base_model.encoder.layer.6.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.14.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.8.attention.output.dense.weight', 'base_model.encoder.layer.17.attention.self.value.weight', 'base_model.encoder.layer.15.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.15.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.23.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.15.attention.output.dense.weight', 'base_model.encoder.layer.17.output.LayerNorm.bias', 'base_model.encoder.layer.13.intermediate.dense.bias', 'base_model.encoder.layer.4.attention.self.key.bias', 'base_model.encoder.layer.19.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.9.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.21.attention.output.LayerNorm.weight', 'base_model.encoder.layer.19.attention.output.dense.bias', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.13.attention.self.value.weight', 'base_model.encoder.layer.0.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.18.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.2.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.1.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.15.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.11.attention.self.query.weight', 'base_model.encoder.layer.4.output.dense.bias', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.12.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.15.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.17.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.9.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.11.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.7.intermediate.dense.weight', 'base_model.encoder.layer.8.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.3.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.2.output.LayerNorm.bias', 'base_model.encoder.layer.11.intermediate.dense.weight', 'base_model.encoder.layer.5.attention.self.query.weight', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.10.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.8.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.13.attention.self.key.bias', 'base_model.encoder.layer.12.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.22.output.LayerNorm.weight', 'qa_outputs.bias', 'base_model.encoder.layer.6.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.14.intermediate.dense.weight', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.13.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.21.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.21.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.12.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.19.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.1.attention.self.value.bias', 'base_model.encoder.layer.0.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.1.intermediate.dense.bias', 'base_model.encoder.layer.3.output.LayerNorm.bias', 'base_model.encoder.layer.16.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.1.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.22.attention.self.value.weight', 'base_model.encoder.layer.17.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.11.attention.self.value.bias', 'base_model.encoder.layer.23.output.dense.bias', 'base_model.encoder.layer.0.attention.output.LayerNorm.bias', 'base_model.encoder.layer.18.attention.self.query.bias', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.22.attention.self.key.weight', 'base_model.encoder.layer.9.intermediate.dense.bias', 'base_model.encoder.layer.7.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.6.attention.output.dense.bias', 'base_model.encoder.layer.5.attention.self.key.weight', 'base_model.encoder.layer.0.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.7.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.21.attention.self.query.bias', 'base_model.encoder.layer.0.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.17.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.14.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.8.attention.self.query.weight', 'base_model.encoder.layer.10.attention.output.dense.bias', 'base_model.encoder.layer.3.output.LayerNorm.weight', 'base_model.encoder.layer.5.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.10.attention.self.value.weight', 'base_model.encoder.layer.12.attention.output.LayerNorm.weight', 'base_model.encoder.layer.7.output.LayerNorm.weight', 'base_model.encoder.layer.12.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.15.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.19.intermediate.dense.weight', 'qa_outputs.weight', 'base_model.encoder.layer.3.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.4.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.2.intermediate.dense.weight', 'base_model.encoder.layer.5.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.5.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.13.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.3.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.22.attention.self.key.bias', 'base_model.encoder.layer.6.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.16.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.18.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.6.intermediate.dense.weight', 'base_model.encoder.layer.20.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.14.output.LayerNorm.weight', 'base_model.encoder.layer.1.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.1.output.LayerNorm.weight', 'base_model.encoder.layer.20.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.19.output.dense.bias', 'base_model.encoder.layer.10.attention.self.query.weight', 'base_model.encoder.layer.18.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.22.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.20.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.22.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.14.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.10.attention.output.dense.weight', 'base_model.encoder.layer.22.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.4.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.17.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.22.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.10.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.20.attention.self.key.bias', 'base_model.encoder.layer.3.attention.self.key.weight', 'base_model.encoder.layer.17.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.8.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.11.intermediate.dense.bias', 'base_model.encoder.layer.4.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.4.output.LayerNorm.bias', 'base_model.encoder.layer.17.attention.output.dense.weight', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.3.attention.output.dense.weight', 'base_model.encoder.layer.6.attention.output.LayerNorm.bias', 'base_model.encoder.layer.6.output.LayerNorm.bias', 'base_model.encoder.layer.16.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.10.attention.output.LayerNorm.bias', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.22.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.14.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.2.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.3.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.2.output.dense.bias', 'base_model.encoder.layer.11.attention.self.query.bias', 'base_model.encoder.layer.1.output.LayerNorm.bias', 'base_model.encoder.layer.4.attention.self.query.bias', 'base_model.encoder.layer.7.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.11.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.8.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.21.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.0.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.6.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.13.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.9.attention.self.value.weight', 'base_model.encoder.layer.16.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.15.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.13.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.0.output.LayerNorm.bias', 'base_model.encoder.layer.8.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.9.attention.output.LayerNorm.weight', 'base_model.encoder.layer.5.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.12.attention.output.dense.weight', 'base_model.encoder.layer.20.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.15.output.dense.weight', 'base_model.encoder.layer.2.attention.output.LayerNorm.weight', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.4.attention.self.value.weight', 'base_model.encoder.layer.4.intermediate.dense.weight', 'base_model.encoder.layer.5.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.13.attention.output.LayerNorm.bias', 'base_model.encoder.layer.19.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.3.intermediate.dense.bias', 'base_model.encoder.layer.13.attention.self.query.weight', 'base_model.encoder.layer.17.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.6.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.3.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.5.output.dense.bias', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.18.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.13.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.17.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.18.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.7.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.23.attention.self.value.bias', 'base_model.encoder.layer.22.attention.self.query.weight', 'base_model.encoder.layer.1.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.12.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.22.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.8.intermediate.dense.bias', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.22.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.3.attention.self.value.bias', 'base_model.encoder.layer.7.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.1.attention.self.query.weight', 'base_model.encoder.layer.5.attention.self.query.bias', 'base_model.encoder.layer.19.attention.self.query.bias', 'base_model.encoder.layer.8.intermediate.dense.weight', 'base_model.encoder.layer.20.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.14.output.dense.weight', 'base_model.encoder.layer.22.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.4.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.12.attention.self.value.bias', 'base_model.encoder.layer.23.output.adapters.tp.adapter_down.0.bias', 'base_model.embeddings.LayerNorm.bias', 'base_model.encoder.layer.0.attention.self.value.bias', 'base_model.encoder.layer.20.intermediate.dense.bias', 'base_model.embeddings.position_ids', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.10.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.3.attention.self.key.bias', 'base_model.encoder.layer.8.attention.output.LayerNorm.weight', 'base_model.encoder.layer.13.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.9.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.20.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.5.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.18.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.20.attention.self.value.bias', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.9.attention.output.dense.bias', 'base_model.encoder.layer.16.attention.self.query.weight', 'base_model.encoder.layer.20.output.LayerNorm.weight', 'base_model.encoder.layer.21.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.9.attention.output.dense.weight', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.3.intermediate.dense.weight', 'base_model.encoder.layer.14.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.3.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.0.attention.self.value.weight', 'base_model.encoder.layer.7.attention.output.dense.bias', 'base_model.encoder.layer.11.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.15.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.23.attention.output.LayerNorm.weight', 'base_model.encoder.layer.7.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.9.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.11.attention.output.LayerNorm.weight', 'base_model.encoder.layer.8.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.9.output.dense.bias', 'base_model.encoder.layer.15.attention.output.LayerNorm.weight', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.12.attention.self.value.weight', 'base_model.encoder.layer.23.attention.self.key.weight', 'base_model.encoder.layer.3.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.6.attention.self.query.weight', 'base_model.encoder.layer.8.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.11.output.dense.bias', 'base_model.encoder.layer.20.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.9.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.16.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.9.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.4.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.15.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.1.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.5.attention.output.dense.bias', 'base_model.encoder.layer.23.output.LayerNorm.weight', 'base_model.encoder.layer.10.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.11.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.10.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.23.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.21.attention.self.key.weight', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.12.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.1.output.dense.weight', 'base_model.encoder.layer.10.attention.self.query.bias']
- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of XLMRobertaModel were not initialized from the model checkpoint at /cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//tydiqa/xlm-KG_LR8e-6_EPOCH2.0_maxlen384_batchsize4_gradacc4 and are newly initialized: ['encoder.layer.3.output.dense.weight', 'encoder.layer.19.attention.self.value.weight', 'encoder.layer.20.intermediate.dense.weight', 'encoder.layer.19.attention.output.LayerNorm.bias', 'encoder.layer.21.attention.self.query.weight', 'encoder.layer.14.attention.output.dense.bias', 'encoder.layer.0.attention.self.key.bias', 'encoder.layer.22.attention.output.dense.bias', 'encoder.layer.9.attention.self.query.weight', 'encoder.layer.12.attention.self.value.bias', 'encoder.layer.17.attention.self.query.bias', 'encoder.layer.5.attention.self.value.bias', 'encoder.layer.15.attention.self.value.weight', 'encoder.layer.3.attention.self.key.weight', 'encoder.layer.21.attention.output.dense.weight', 'encoder.layer.2.attention.output.LayerNorm.bias', 'encoder.layer.14.attention.output.LayerNorm.weight', 'encoder.layer.18.attention.output.dense.weight', 'encoder.layer.17.attention.output.LayerNorm.weight', 'encoder.layer.11.attention.output.LayerNorm.weight', 'encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.layer.11.attention.self.query.bias', 'encoder.layer.5.attention.self.key.bias', 'encoder.layer.2.attention.self.value.bias', 'encoder.layer.16.attention.self.key.bias', 'encoder.layer.10.attention.output.LayerNorm.weight', 'encoder.layer.23.output.LayerNorm.bias', 'encoder.layer.13.attention.self.key.weight', 'encoder.layer.18.attention.self.key.weight', 'encoder.layer.16.intermediate.dense.bias', 'encoder.layer.2.output.dense.bias', 'encoder.layer.15.attention.self.key.weight', 'encoder.layer.14.output.LayerNorm.weight', 'encoder.layer.17.output.dense.weight', 'encoder.layer.2.attention.output.dense.bias', 'encoder.layer.1.attention.output.dense.weight', 'encoder.layer.10.attention.output.dense.bias', 'encoder.layer.15.attention.output.LayerNorm.weight', 'encoder.layer.17.output.dense.bias', 'encoder.layer.18.intermediate.dense.bias', 'encoder.layer.9.attention.output.dense.weight', 'encoder.layer.23.attention.self.value.weight', 'encoder.layer.17.attention.output.LayerNorm.bias', 'encoder.layer.8.attention.output.LayerNorm.bias', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.5.output.dense.weight', 'encoder.layer.19.output.dense.bias', 'encoder.layer.13.attention.output.dense.weight', 'encoder.layer.20.attention.self.key.weight', 'encoder.layer.23.output.dense.bias', 'encoder.layer.9.attention.self.key.weight', 'encoder.layer.21.output.dense.weight', 'encoder.layer.19.attention.self.key.bias', 'encoder.layer.19.attention.self.key.weight', 'encoder.layer.22.output.dense.weight', 'encoder.layer.7.output.LayerNorm.weight', 'encoder.layer.19.output.LayerNorm.bias', 'encoder.layer.14.output.dense.weight', 'encoder.layer.1.output.dense.weight', 'encoder.layer.22.output.dense.bias', 'encoder.layer.10.attention.self.query.bias', 'encoder.layer.12.attention.self.key.weight', 'encoder.layer.7.attention.output.LayerNorm.bias', 'encoder.layer.8.attention.self.query.weight', 'encoder.layer.22.attention.output.LayerNorm.weight', 'encoder.layer.8.output.LayerNorm.bias', 'encoder.layer.4.attention.output.dense.bias', 'encoder.layer.16.output.LayerNorm.weight', 'encoder.layer.10.output.LayerNorm.weight', 'encoder.layer.3.output.dense.bias', 'encoder.layer.10.attention.self.value.bias', 'encoder.layer.10.attention.self.key.weight', 'encoder.layer.11.attention.self.key.bias', 'encoder.layer.20.output.LayerNorm.bias', 'encoder.layer.13.attention.self.key.bias', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.14.attention.self.value.bias', 'encoder.layer.7.attention.self.query.bias', 'encoder.layer.17.attention.self.key.bias', 'encoder.layer.13.output.LayerNorm.weight', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.0.attention.self.key.weight', 'encoder.layer.1.attention.self.value.weight', 'encoder.layer.17.attention.self.value.weight', 'encoder.layer.16.attention.self.value.weight', 'encoder.layer.7.attention.output.dense.bias', 'encoder.layer.0.output.dense.weight', 'encoder.layer.11.attention.self.value.bias', 'encoder.layer.17.attention.self.query.weight', 'encoder.layer.12.attention.self.key.bias', 'encoder.layer.9.attention.output.LayerNorm.bias', 'encoder.layer.14.attention.self.query.bias', 'encoder.layer.9.attention.output.dense.bias', 'encoder.layer.22.attention.self.key.bias', 'encoder.layer.20.attention.self.value.weight', 'encoder.layer.15.output.LayerNorm.bias', 'encoder.layer.3.attention.self.query.bias', 'encoder.layer.23.attention.self.key.weight', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.8.attention.self.key.bias', 'encoder.layer.4.attention.self.value.weight', 'encoder.layer.23.attention.output.LayerNorm.bias', 'encoder.layer.7.attention.self.value.bias', 'encoder.layer.6.attention.self.query.weight', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.14.intermediate.dense.bias', 'encoder.layer.19.attention.self.query.weight', 'encoder.layer.17.output.LayerNorm.bias', 'encoder.layer.21.output.LayerNorm.bias', 'encoder.layer.12.output.dense.bias', 'encoder.layer.5.attention.output.dense.weight', 'encoder.layer.8.attention.self.value.bias', 'encoder.layer.12.output.LayerNorm.weight', 'encoder.layer.12.intermediate.dense.bias', 'encoder.layer.18.attention.output.LayerNorm.weight', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.14.intermediate.dense.weight', 'encoder.layer.15.attention.output.LayerNorm.bias', 'encoder.layer.6.attention.self.key.bias', 'encoder.layer.8.attention.self.query.bias', 'encoder.layer.7.intermediate.dense.bias', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.21.attention.self.key.bias', 'embeddings.token_type_embeddings.weight', 'encoder.layer.22.attention.output.dense.weight', 'encoder.layer.9.output.dense.weight', 'encoder.layer.3.attention.self.query.weight', 'encoder.layer.14.attention.self.key.bias', 'encoder.layer.4.attention.self.key.weight', 'encoder.layer.2.attention.output.LayerNorm.weight', 'encoder.layer.15.attention.output.dense.bias', 'encoder.layer.18.attention.self.value.weight', 'encoder.layer.13.attention.output.LayerNorm.weight', 'encoder.layer.18.attention.output.LayerNorm.bias', 'encoder.layer.4.attention.self.key.bias', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.16.attention.output.LayerNorm.bias', 'encoder.layer.19.intermediate.dense.weight', 'encoder.layer.10.attention.self.key.bias', 'encoder.layer.20.output.dense.bias', 'encoder.layer.14.output.LayerNorm.bias', 'encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.layer.0.output.dense.bias', 'encoder.layer.13.attention.output.dense.bias', 'encoder.layer.15.attention.self.query.bias', 'encoder.layer.4.attention.output.dense.weight', 'encoder.layer.20.attention.self.query.bias', 'embeddings.LayerNorm.bias', 'encoder.layer.0.attention.self.query.bias', 'encoder.layer.23.attention.self.query.bias', 'encoder.layer.5.attention.output.dense.bias', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.18.attention.self.value.bias', 'encoder.layer.2.attention.self.query.weight', 'encoder.layer.15.attention.self.query.weight', 'encoder.layer.10.output.LayerNorm.bias', 'encoder.layer.15.attention.self.key.bias', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.22.output.LayerNorm.weight', 'encoder.layer.7.attention.output.dense.weight', 'encoder.layer.19.attention.self.query.bias', 'encoder.layer.6.attention.output.LayerNorm.bias', 'encoder.layer.1.attention.output.LayerNorm.weight', 'encoder.layer.23.attention.output.dense.weight', 'pooler.dense.weight', 'embeddings.position_embeddings.weight', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.9.attention.self.value.bias', 'encoder.layer.3.attention.self.value.weight', 'encoder.layer.20.attention.output.dense.bias', 'encoder.layer.21.attention.self.value.bias', 'encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.layer.6.output.LayerNorm.bias', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.9.attention.output.LayerNorm.weight', 'encoder.layer.22.output.LayerNorm.bias', 'encoder.layer.7.attention.output.LayerNorm.weight', 'encoder.layer.19.output.LayerNorm.weight', 'encoder.layer.20.attention.output.LayerNorm.weight', 'encoder.layer.22.attention.self.query.weight', 'encoder.layer.7.output.dense.weight', 'encoder.layer.19.attention.self.value.bias', 'encoder.layer.17.attention.self.value.bias', 'encoder.layer.21.output.LayerNorm.weight', 'encoder.layer.10.output.dense.bias', 'encoder.layer.17.attention.self.key.weight', 'encoder.layer.19.attention.output.dense.bias', 'encoder.layer.22.attention.output.LayerNorm.bias', 'encoder.layer.23.attention.output.dense.bias', 'encoder.layer.6.attention.output.LayerNorm.weight', 'encoder.layer.20.attention.self.key.bias', 'encoder.layer.7.attention.self.value.weight', 'encoder.layer.19.attention.output.dense.weight', 'encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.layer.20.attention.output.LayerNorm.bias', 'encoder.layer.10.attention.output.dense.weight', 'encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.layer.0.attention.self.query.weight', 'encoder.layer.9.output.dense.bias', 'encoder.layer.12.attention.output.dense.bias', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.13.attention.self.value.bias', 'encoder.layer.20.attention.output.dense.weight', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.10.attention.output.LayerNorm.bias', 'encoder.layer.15.output.dense.weight', 'encoder.layer.22.attention.self.key.weight', 'encoder.layer.8.attention.output.LayerNorm.weight', 'encoder.layer.16.output.dense.bias', 'encoder.layer.21.intermediate.dense.bias', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.22.attention.self.value.bias', 'encoder.layer.21.attention.output.LayerNorm.weight', 'encoder.layer.18.attention.self.query.weight', 'encoder.layer.18.attention.self.query.bias', 'encoder.layer.7.output.LayerNorm.bias', 'encoder.layer.11.attention.self.value.weight', 'encoder.layer.12.attention.output.LayerNorm.weight', 'encoder.layer.5.output.LayerNorm.bias', 'encoder.layer.21.intermediate.dense.weight', 'encoder.layer.23.attention.output.LayerNorm.weight', 'encoder.layer.17.output.LayerNorm.weight', 'encoder.layer.21.attention.output.LayerNorm.bias', 'encoder.layer.14.attention.output.dense.weight', 'encoder.layer.23.output.dense.weight', 'encoder.layer.11.output.LayerNorm.weight', 'encoder.layer.20.output.LayerNorm.weight', 'encoder.layer.21.attention.self.key.weight', 'encoder.layer.12.attention.self.query.weight', 'encoder.layer.21.output.dense.bias', 'encoder.layer.15.attention.output.dense.weight', 'encoder.layer.11.output.dense.bias', 'encoder.layer.8.attention.output.dense.weight', 'encoder.layer.5.attention.self.query.bias', 'encoder.layer.13.attention.self.value.weight', 'encoder.layer.13.attention.self.query.weight', 'encoder.layer.6.attention.output.dense.bias', 'encoder.layer.23.intermediate.dense.weight', 'encoder.layer.5.attention.self.key.weight', 'encoder.layer.4.attention.self.value.bias', 'encoder.layer.15.output.LayerNorm.weight', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.10.intermediate.dense.weight', 'encoder.layer.18.attention.self.key.bias', 'encoder.layer.2.attention.self.query.bias', 'encoder.layer.6.attention.self.query.bias', 'encoder.layer.0.attention.output.dense.weight', 'encoder.layer.12.intermediate.dense.weight', 'encoder.layer.19.intermediate.dense.bias', 'encoder.layer.22.intermediate.dense.bias', 'encoder.layer.5.output.dense.bias', 'encoder.layer.7.attention.self.query.weight', 'encoder.layer.16.attention.output.dense.weight', 'encoder.layer.9.attention.self.query.bias', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.20.attention.self.value.bias', 'encoder.layer.13.attention.output.LayerNorm.bias', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.9.output.LayerNorm.weight', 'encoder.layer.18.output.dense.bias', 'encoder.layer.17.attention.output.dense.bias', 'encoder.layer.6.attention.self.value.weight', 'encoder.layer.10.attention.self.query.weight', 'encoder.layer.11.attention.output.dense.weight', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.16.attention.self.key.weight', 'encoder.layer.12.attention.self.value.weight', 'embeddings.LayerNorm.weight', 'encoder.layer.14.attention.self.value.weight', 'encoder.layer.1.attention.self.value.bias', 'encoder.layer.3.attention.output.dense.bias', 'encoder.layer.11.attention.self.key.weight', 'encoder.layer.17.intermediate.dense.bias', 'encoder.layer.2.attention.self.value.weight', 'encoder.layer.16.attention.output.dense.bias', 'encoder.layer.12.attention.output.dense.weight', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.15.attention.self.value.bias', 'encoder.layer.13.intermediate.dense.weight', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.20.intermediate.dense.bias', 'encoder.layer.21.attention.self.value.weight', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.16.output.LayerNorm.bias', 'encoder.layer.18.output.LayerNorm.bias', 'encoder.layer.4.attention.output.LayerNorm.weight', 'encoder.layer.15.intermediate.dense.bias', 'encoder.layer.1.attention.self.key.weight', 'encoder.layer.22.attention.self.value.weight', 'encoder.layer.20.output.dense.weight', 'encoder.layer.4.attention.output.LayerNorm.bias', 'encoder.layer.6.output.dense.bias', 'encoder.layer.6.attention.self.key.weight', 'encoder.layer.13.output.LayerNorm.bias', 'encoder.layer.23.attention.self.key.bias', 'encoder.layer.18.attention.output.dense.bias', 'encoder.layer.1.attention.self.query.weight', 'encoder.layer.14.attention.self.key.weight', 'encoder.layer.8.attention.output.dense.bias', 'encoder.layer.2.attention.self.key.weight', 'encoder.layer.12.attention.output.LayerNorm.bias', 'encoder.layer.3.attention.output.dense.weight', 'encoder.layer.16.attention.output.LayerNorm.weight', 'encoder.layer.8.output.dense.bias', 'encoder.layer.14.attention.self.query.weight', 'encoder.layer.15.output.dense.bias', 'encoder.layer.18.output.dense.weight', 'encoder.layer.13.output.dense.bias', 'encoder.layer.0.attention.self.value.bias', 'encoder.layer.21.attention.output.dense.bias', 'encoder.layer.0.attention.output.LayerNorm.weight', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.11.attention.output.dense.bias', 'encoder.layer.0.attention.output.dense.bias', 'encoder.layer.3.attention.output.LayerNorm.bias', 'embeddings.word_embeddings.weight', 'encoder.layer.14.output.dense.bias', 'encoder.layer.7.attention.self.key.bias', 'encoder.layer.2.attention.self.key.bias', 'encoder.layer.16.attention.self.query.bias', 'encoder.layer.5.attention.output.LayerNorm.weight', 'encoder.layer.10.output.dense.weight', 'encoder.layer.12.output.LayerNorm.bias', 'encoder.layer.1.output.dense.bias', 'encoder.layer.18.output.LayerNorm.weight', 'encoder.layer.1.attention.output.dense.bias', 'encoder.layer.8.output.dense.weight', 'encoder.layer.9.output.LayerNorm.bias', 'encoder.layer.13.intermediate.dense.bias', 'encoder.layer.8.output.LayerNorm.weight', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.22.attention.self.query.bias', 'pooler.dense.bias', 'encoder.layer.6.output.dense.weight', 'encoder.layer.3.attention.self.value.bias', 'encoder.layer.18.intermediate.dense.weight', 'encoder.layer.6.attention.output.dense.weight', 'encoder.layer.19.output.dense.weight', 'encoder.layer.23.intermediate.dense.bias', 'encoder.layer.23.attention.self.value.bias', 'encoder.layer.23.attention.self.query.weight', 'encoder.layer.7.attention.self.key.weight', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.11.output.LayerNorm.bias', 'encoder.layer.19.attention.output.LayerNorm.weight', 'encoder.layer.0.attention.self.value.weight', 'encoder.layer.4.output.dense.weight', 'encoder.layer.9.attention.self.key.bias', 'encoder.layer.3.attention.self.key.bias', 'encoder.layer.5.attention.self.query.weight', 'encoder.layer.13.output.dense.weight', 'encoder.layer.8.attention.self.key.weight', 'encoder.layer.10.attention.self.value.weight', 'encoder.layer.2.attention.output.dense.weight', 'encoder.layer.13.attention.self.query.bias', 'encoder.layer.15.intermediate.dense.weight', 'encoder.layer.8.attention.self.value.weight', 'encoder.layer.16.output.dense.weight', 'encoder.layer.16.intermediate.dense.weight', 'encoder.layer.4.attention.self.query.bias', 'encoder.layer.6.attention.self.value.bias', 'encoder.layer.7.output.dense.bias', 'encoder.layer.11.attention.self.query.weight', 'encoder.layer.16.attention.self.value.bias', 'encoder.layer.11.output.dense.weight', 'encoder.layer.9.attention.self.value.weight', 'encoder.layer.23.output.LayerNorm.weight', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.21.attention.self.query.bias', 'encoder.layer.4.output.dense.bias', 'encoder.layer.1.attention.self.query.bias', 'encoder.layer.14.attention.output.LayerNorm.bias', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.17.intermediate.dense.weight', 'encoder.layer.20.attention.self.query.weight', 'encoder.layer.17.attention.output.dense.weight', 'encoder.layer.12.attention.self.query.bias', 'encoder.layer.1.attention.self.key.bias', 'encoder.layer.5.attention.self.value.weight', 'encoder.layer.2.output.dense.weight', 'encoder.layer.12.output.dense.weight', 'encoder.layer.16.attention.self.query.weight', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.4.attention.self.query.weight', 'encoder.layer.22.intermediate.dense.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Overwriting existing adapter 'ep'.
Overwriting existing adapter 'tp'.
Overwriting existing adapter 'es'.
Overwriting existing adapter 'ts'.
Overwriting existing adapter fusion module 'ep,tp,es,ts'
05/09/2022 22:50:52 - INFO - __main__ -   Creating features from dataset file at .
/cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//tydiqa/xlm-KG_LR8e-6_EPOCH2.0_maxlen384_batchsize4_gradacc4
XLMConfig {
  "architectures": [
    "XLMRobertaForMaskedLM"
  ],
  "asm": false,
  "attention_dropout": 0.1,
  "attention_probs_dropout_prob": 0.1,
  "bos_index": 0,
  "bos_token_id": 0,
  "causal": false,
  "dropout": 0.1,
  "emb_dim": 1024,
  "embed_init_std": 0.02209708691207961,
  "end_n_top": 5,
  "eos_index": 1,
  "eos_token_id": 2,
  "gelu_activation": true,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "init_std": 0.02,
  "initializer_range": 0.02,
  "intermediate_size": 4096,
  "is_encoder": true,
  "lang_id": 0,
  "layer_norm_eps": 1e-05,
  "mask_index": 5,
  "mask_token_id": 0,
  "max_position_embeddings": 514,
  "model_type": "xlm",
  "n_heads": 16,
  "n_langs": 1,
  "n_layers": 24,
  "output_past": true,
  "pad_index": 2,
  "pad_token_id": 1,
  "sinusoidal_embeddings": false,
  "start_n_top": 5,
  "summary_activation": null,
  "summary_first_dropout": 0.1,
  "summary_proj_to_labels": true,
  "summary_type": "first",
  "summary_use_proj": true,
  "transformers_version": "4.17.0",
  "type_vocab_size": 1,
  "unk_index": 3,
  "use_lang_emb": false,
  "vocab_size": 250002
}

  0%|          | 0/921 [00:00<?, ?it/s] 53%|█████▎    | 489/921 [00:00<00:00, 4879.14it/s]100%|██████████| 921/921 [00:00<00:00, 4890.42it/s]
convert squad examples to features:   0%|          | 0/921 [00:00<?, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.
convert squad examples to features:   0%|          | 1/921 [00:00<02:24,  6.37it/s]convert squad examples to features:   7%|▋         | 65/921 [00:00<00:03, 227.05it/s]convert squad examples to features:  11%|█         | 97/921 [00:00<00:03, 254.81it/s]convert squad examples to features:  14%|█▍        | 129/921 [00:00<00:02, 270.21it/s]convert squad examples to features:  17%|█▋        | 161/921 [00:00<00:02, 281.41it/s]convert squad examples to features:  24%|██▍       | 225/921 [00:00<00:02, 325.11it/s]convert squad examples to features:  31%|███▏      | 289/921 [00:00<00:01, 360.75it/s]convert squad examples to features:  38%|███▊      | 353/921 [00:01<00:01, 376.70it/s]convert squad examples to features:  42%|████▏     | 391/921 [00:01<00:01, 370.75it/s]convert squad examples to features:  49%|████▉     | 449/921 [00:01<00:01, 347.71it/s]convert squad examples to features:  56%|█████▌    | 513/921 [00:01<00:01, 359.86it/s]convert squad examples to features:  60%|█████▉    | 549/921 [00:01<00:01, 310.77it/s]convert squad examples to features:  66%|██████▌   | 609/921 [00:01<00:00, 313.00it/s]convert squad examples to features:  70%|██████▉   | 641/921 [00:02<00:00, 301.42it/s]convert squad examples to features:  77%|███████▋  | 705/921 [00:02<00:00, 311.31it/s]convert squad examples to features:  83%|████████▎ | 769/921 [00:02<00:00, 349.73it/s]convert squad examples to features:  90%|█████████ | 833/921 [00:02<00:00, 352.72it/s]convert squad examples to features:  97%|█████████▋| 897/921 [00:02<00:00, 353.85it/s]convert squad examples to features: 100%|██████████| 921/921 [00:02<00:00, 334.17it/s]/cluster/project/sachan/yifan/softwares/anaconda/anaconda3/envs/xfactr/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2272: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

add example index and unique id:   0%|          | 0/921 [00:00<?, ?it/s]add example index and unique id: 100%|██████████| 921/921 [00:00<00:00, 732869.28it/s]
05/09/2022 22:50:55 - INFO - __main__ -   Saving features into cached file ./cached_tydiqa.goldp.ar.dev.json_xlm-KG_LR8e-6_EPOCH2.0_maxlen384_batchsize4_gradacc4_384_ar
05/09/2022 22:50:56 - INFO - __main__ -   ***** Running evaluation  *****
05/09/2022 22:50:56 - INFO - __main__ -     Num examples = 985
05/09/2022 22:50:56 - INFO - __main__ -     Batch size = 8
Evaluating:   0%|          | 0/124 [00:00<?, ?it/s]Evaluating:   1%|          | 1/124 [00:00<01:33,  1.31it/s]Evaluating:   2%|▏         | 2/124 [00:01<01:03,  1.92it/s]Evaluating:   2%|▏         | 3/124 [00:01<00:53,  2.25it/s]Evaluating:   3%|▎         | 4/124 [00:01<00:49,  2.44it/s]Evaluating:   4%|▍         | 5/124 [00:02<00:46,  2.56it/s]Evaluating:   5%|▍         | 6/124 [00:02<00:44,  2.63it/s]Evaluating:   6%|▌         | 7/124 [00:02<00:43,  2.70it/s]Evaluating:   6%|▋         | 8/124 [00:03<00:42,  2.74it/s]Evaluating:   7%|▋         | 9/124 [00:03<00:41,  2.76it/s]Evaluating:   8%|▊         | 10/124 [00:03<00:41,  2.77it/s]Evaluating:   9%|▉         | 11/124 [00:04<00:40,  2.78it/s]Evaluating:  10%|▉         | 12/124 [00:04<00:40,  2.78it/s]Evaluating:  10%|█         | 13/124 [00:05<00:39,  2.79it/s]Evaluating:  11%|█▏        | 14/124 [00:05<00:39,  2.80it/s]Evaluating:  12%|█▏        | 15/124 [00:05<00:38,  2.81it/s]Evaluating:  13%|█▎        | 16/124 [00:06<00:38,  2.81it/s]Evaluating:  14%|█▎        | 17/124 [00:06<00:38,  2.80it/s]Evaluating:  15%|█▍        | 18/124 [00:06<00:37,  2.80it/s]Evaluating:  15%|█▌        | 19/124 [00:07<00:37,  2.80it/s]Evaluating:  16%|█▌        | 20/124 [00:07<00:37,  2.81it/s]Evaluating:  17%|█▋        | 21/124 [00:07<00:36,  2.81it/s]Evaluating:  18%|█▊        | 22/124 [00:08<00:36,  2.80it/s]Evaluating:  19%|█▊        | 23/124 [00:08<00:35,  2.81it/s]Evaluating:  19%|█▉        | 24/124 [00:08<00:35,  2.80it/s]Evaluating:  20%|██        | 25/124 [00:09<00:35,  2.78it/s]Evaluating:  21%|██        | 26/124 [00:09<00:35,  2.79it/s]Evaluating:  22%|██▏       | 27/124 [00:10<00:34,  2.79it/s]Evaluating:  23%|██▎       | 28/124 [00:10<00:34,  2.80it/s]Evaluating:  23%|██▎       | 29/124 [00:10<00:33,  2.81it/s]Evaluating:  24%|██▍       | 30/124 [00:11<00:33,  2.80it/s]Evaluating:  25%|██▌       | 31/124 [00:11<00:33,  2.80it/s]Evaluating:  26%|██▌       | 32/124 [00:11<00:32,  2.79it/s]Evaluating:  27%|██▋       | 33/124 [00:12<00:32,  2.80it/s]Evaluating:  27%|██▋       | 34/124 [00:12<00:32,  2.80it/s]Evaluating:  28%|██▊       | 35/124 [00:12<00:31,  2.81it/s]Evaluating:  29%|██▉       | 36/124 [00:13<00:31,  2.81it/s]Evaluating:  30%|██▉       | 37/124 [00:13<00:31,  2.81it/s]Evaluating:  31%|███       | 38/124 [00:13<00:30,  2.80it/s]Evaluating:  31%|███▏      | 39/124 [00:14<00:30,  2.81it/s]Evaluating:  32%|███▏      | 40/124 [00:14<00:29,  2.80it/s]Evaluating:  33%|███▎      | 41/124 [00:15<00:29,  2.80it/s]Evaluating:  34%|███▍      | 42/124 [00:15<00:29,  2.80it/s]Evaluating:  35%|███▍      | 43/124 [00:15<00:28,  2.81it/s]Evaluating:  35%|███▌      | 44/124 [00:16<00:28,  2.81it/s]Evaluating:  36%|███▋      | 45/124 [00:16<00:28,  2.81it/s]Evaluating:  37%|███▋      | 46/124 [00:16<00:27,  2.81it/s]Evaluating:  38%|███▊      | 47/124 [00:17<00:27,  2.81it/s]Evaluating:  39%|███▊      | 48/124 [00:17<00:27,  2.80it/s]Evaluating:  40%|███▉      | 49/124 [00:17<00:26,  2.80it/s]Evaluating:  40%|████      | 50/124 [00:18<00:26,  2.80it/s]Evaluating:  41%|████      | 51/124 [00:18<00:26,  2.80it/s]Evaluating:  42%|████▏     | 52/124 [00:18<00:25,  2.80it/s]Evaluating:  43%|████▎     | 53/124 [00:19<00:25,  2.80it/s]Evaluating:  44%|████▎     | 54/124 [00:19<00:25,  2.78it/s]Evaluating:  44%|████▍     | 55/124 [00:20<00:25,  2.73it/s]Evaluating:  45%|████▌     | 56/124 [00:20<00:24,  2.75it/s]Evaluating:  46%|████▌     | 57/124 [00:20<00:24,  2.76it/s]Evaluating:  47%|████▋     | 58/124 [00:21<00:23,  2.75it/s]Evaluating:  48%|████▊     | 59/124 [00:21<00:23,  2.77it/s]Evaluating:  48%|████▊     | 60/124 [00:21<00:23,  2.78it/s]Evaluating:  49%|████▉     | 61/124 [00:22<00:22,  2.79it/s]Evaluating:  50%|█████     | 62/124 [00:22<00:22,  2.80it/s]Evaluating:  51%|█████     | 63/124 [00:22<00:21,  2.80it/s]Evaluating:  52%|█████▏    | 64/124 [00:23<00:21,  2.81it/s]Evaluating:  52%|█████▏    | 65/124 [00:23<00:21,  2.81it/s]Evaluating:  53%|█████▎    | 66/124 [00:23<00:20,  2.81it/s]Evaluating:  54%|█████▍    | 67/124 [00:24<00:20,  2.81it/s]Evaluating:  55%|█████▍    | 68/124 [00:24<00:20,  2.80it/s]Evaluating:  56%|█████▌    | 69/124 [00:25<00:19,  2.80it/s]Evaluating:  56%|█████▋    | 70/124 [00:25<00:19,  2.80it/s]Evaluating:  57%|█████▋    | 71/124 [00:25<00:18,  2.80it/s]Evaluating:  58%|█████▊    | 72/124 [00:26<00:18,  2.80it/s]Evaluating:  59%|█████▉    | 73/124 [00:26<00:18,  2.81it/s]Evaluating:  60%|█████▉    | 74/124 [00:26<00:17,  2.81it/s]Evaluating:  60%|██████    | 75/124 [00:27<00:17,  2.78it/s]Evaluating:  61%|██████▏   | 76/124 [00:27<00:17,  2.77it/s]Evaluating:  62%|██████▏   | 77/124 [00:27<00:16,  2.78it/s]Evaluating:  63%|██████▎   | 78/124 [00:28<00:16,  2.77it/s]Evaluating:  64%|██████▎   | 79/124 [00:28<00:16,  2.77it/s]Evaluating:  65%|██████▍   | 80/124 [00:28<00:15,  2.78it/s]Evaluating:  65%|██████▌   | 81/124 [00:29<00:15,  2.78it/s]Evaluating:  66%|██████▌   | 82/124 [00:29<00:15,  2.77it/s]Evaluating:  67%|██████▋   | 83/124 [00:30<00:14,  2.77it/s]Evaluating:  68%|██████▊   | 84/124 [00:30<00:14,  2.77it/s]Evaluating:  69%|██████▊   | 85/124 [00:30<00:14,  2.78it/s]Evaluating:  69%|██████▉   | 86/124 [00:31<00:13,  2.78it/s]Evaluating:  70%|███████   | 87/124 [00:31<00:13,  2.78it/s]Evaluating:  71%|███████   | 88/124 [00:31<00:12,  2.78it/s]Evaluating:  72%|███████▏  | 89/124 [00:32<00:12,  2.77it/s]Evaluating:  73%|███████▎  | 90/124 [00:32<00:12,  2.77it/s]Evaluating:  73%|███████▎  | 91/124 [00:32<00:11,  2.78it/s]Evaluating:  74%|███████▍  | 92/124 [00:33<00:11,  2.79it/s]Evaluating:  75%|███████▌  | 93/124 [00:33<00:11,  2.79it/s]Evaluating:  76%|███████▌  | 94/124 [00:34<00:10,  2.78it/s]Evaluating:  77%|███████▋  | 95/124 [00:34<00:10,  2.79it/s]Evaluating:  77%|███████▋  | 96/124 [00:34<00:10,  2.78it/s]Evaluating:  78%|███████▊  | 97/124 [00:35<00:09,  2.77it/s]Evaluating:  79%|███████▉  | 98/124 [00:35<00:09,  2.76it/s]Evaluating:  80%|███████▉  | 99/124 [00:35<00:09,  2.77it/s]Evaluating:  81%|████████  | 100/124 [00:36<00:08,  2.77it/s]Evaluating:  81%|████████▏ | 101/124 [00:36<00:08,  2.77it/s]Evaluating:  82%|████████▏ | 102/124 [00:36<00:07,  2.77it/s]Evaluating:  83%|████████▎ | 103/124 [00:37<00:07,  2.77it/s]Evaluating:  84%|████████▍ | 104/124 [00:37<00:07,  2.76it/s]Evaluating:  85%|████████▍ | 105/124 [00:38<00:06,  2.77it/s]Evaluating:  85%|████████▌ | 106/124 [00:38<00:06,  2.77it/s]Evaluating:  86%|████████▋ | 107/124 [00:38<00:06,  2.78it/s]Evaluating:  87%|████████▋ | 108/124 [00:39<00:05,  2.78it/s]Evaluating:  88%|████████▊ | 109/124 [00:39<00:05,  2.77it/s]Evaluating:  89%|████████▊ | 110/124 [00:39<00:05,  2.76it/s]Evaluating:  90%|████████▉ | 111/124 [00:40<00:04,  2.75it/s]Evaluating:  90%|█████████ | 112/124 [00:40<00:04,  2.77it/s]Evaluating:  91%|█████████ | 113/124 [00:40<00:03,  2.77it/s]Evaluating:  92%|█████████▏| 114/124 [00:41<00:03,  2.77it/s]Evaluating:  93%|█████████▎| 115/124 [00:41<00:03,  2.75it/s]Evaluating:  94%|█████████▎| 116/124 [00:41<00:02,  2.75it/s]Evaluating:  94%|█████████▍| 117/124 [00:42<00:02,  2.75it/s]Evaluating:  95%|█████████▌| 118/124 [00:42<00:02,  2.75it/s]Evaluating:  96%|█████████▌| 119/124 [00:43<00:01,  2.76it/s]Evaluating:  97%|█████████▋| 120/124 [00:43<00:01,  2.77it/s]Evaluating:  98%|█████████▊| 121/124 [00:43<00:01,  2.77it/s]Evaluating:  98%|█████████▊| 122/124 [00:44<00:00,  2.77it/s]Evaluating:  99%|█████████▉| 123/124 [00:44<00:00,  2.77it/s]Evaluating: 100%|██████████| 124/124 [00:44<00:00,  2.78it/s]
05/09/2022 22:51:40 - INFO - __main__ -     Evaluation done in total 44.590808 secs (0.045270 sec per example)
05/09/2022 22:51:43 - INFO - __main__ -   Results: {'exact': 54.180238870792614, 'f1': 71.31763969185191, 'total': 921, 'HasAns_exact': 54.180238870792614, 'HasAns_f1': 71.31763969185191, 'HasAns_total': 921, 'best_exact': 54.180238870792614, 'best_exact_thresh': 0.0, 'best_f1': 71.31763969185191, 'best_f1_thresh': 0.0}
  bn 
2022-05-09 22:51:46.507928: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0
05/09/2022 22:51:50 - WARNING - __main__ -   Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, 16-bits training: False
You are using a model of type xlm-roberta to instantiate a model of type xlm. This is not supported for all configurations of models and can yield errors.
Some weights of the model checkpoint at /cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//tydiqa/xlm-KG_LR8e-6_EPOCH2.0_maxlen384_batchsize4_gradacc4 were not used when initializing XLMRobertaModel: ['base_model.encoder.layer.22.intermediate.dense.weight', 'base_model.encoder.layer.0.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.1.attention.self.query.weight', 'base_model.encoder.layer.16.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.9.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.13.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.22.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.16.output.LayerNorm.weight', 'base_model.encoder.layer.4.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.4.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.22.output.LayerNorm.bias', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.17.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.19.attention.output.dense.bias', 'base_model.encoder.layer.0.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.2.attention.self.value.bias', 'base_model.encoder.layer.6.output.dense.bias', 'base_model.encoder.layer.3.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.8.attention.output.LayerNorm.bias', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.17.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.9.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.11.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.17.output.dense.bias', 'base_model.encoder.layer.17.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.8.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.11.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.23.attention.output.LayerNorm.bias', 'base_model.encoder.layer.19.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.11.attention.self.value.weight', 'base_model.encoder.layer.15.output.LayerNorm.bias', 'base_model.encoder.layer.18.attention.self.key.bias', 'base_model.encoder.layer.20.output.LayerNorm.weight', 'base_model.encoder.layer.21.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.9.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.6.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.22.intermediate.dense.bias', 'base_model.encoder.layer.23.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.21.attention.output.LayerNorm.weight', 'base_model.encoder.layer.23.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.1.output.LayerNorm.bias', 'base_model.encoder.layer.13.attention.output.dense.weight', 'base_model.encoder.layer.17.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.5.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.9.output.LayerNorm.weight', 'base_model.encoder.layer.14.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.13.intermediate.dense.weight', 'base_model.encoder.layer.10.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.4.attention.self.query.weight', 'base_model.encoder.layer.8.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.5.attention.self.query.weight', 'base_model.encoder.layer.19.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.13.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.8.attention.self.key.weight', 'base_model.encoder.layer.6.attention.self.query.weight', 'base_model.encoder.layer.8.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.9.output.dense.weight', 'base_model.encoder.layer.22.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.20.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.2.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.9.attention.self.query.weight', 'base_model.encoder.layer.9.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.0.output.LayerNorm.bias', 'base_model.encoder.layer.3.attention.self.value.weight', 'base_model.encoder.layer.10.intermediate.dense.bias', 'base_model.encoder.layer.0.attention.output.LayerNorm.weight', 'base_model.encoder.layer.16.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.20.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.13.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.22.output.dense.bias', 'base_model.encoder.layer.14.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.17.attention.output.LayerNorm.weight', 'base_model.encoder.layer.5.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.17.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.16.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.20.attention.self.key.weight', 'base_model.encoder.layer.12.attention.output.dense.weight', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.9.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.23.attention.self.query.bias', 'base_model.encoder.layer.18.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.13.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.14.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.22.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.16.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.6.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.21.output.LayerNorm.weight', 'base_model.encoder.layer.1.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.0.intermediate.dense.weight', 'base_model.encoder.layer.0.intermediate.dense.bias', 'base_model.encoder.layer.14.output.dense.bias', 'base_model.encoder.layer.15.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.11.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.6.output.LayerNorm.bias', 'base_model.encoder.layer.19.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.14.intermediate.dense.weight', 'base_model.encoder.layer.3.attention.output.LayerNorm.bias', 'base_model.encoder.layer.5.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.15.attention.output.dense.weight', 'base_model.encoder.layer.21.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.12.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.9.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.17.attention.self.value.bias', 'base_model.encoder.layer.21.output.LayerNorm.bias', 'base_model.encoder.layer.10.attention.output.dense.weight', 'base_model.encoder.layer.0.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.1.output.dense.weight', 'base_model.encoder.layer.11.intermediate.dense.weight', 'qa_outputs.weight', 'base_model.encoder.layer.2.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.23.attention.output.LayerNorm.weight', 'base_model.encoder.layer.3.attention.self.query.weight', 'base_model.encoder.layer.3.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.5.attention.self.key.weight', 'base_model.encoder.layer.15.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.6.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.4.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.9.attention.output.LayerNorm.bias', 'base_model.encoder.layer.8.attention.self.query.bias', 'base_model.encoder.layer.21.attention.output.dense.weight', 'base_model.encoder.layer.0.output.dense.weight', 'base_model.encoder.layer.21.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.22.attention.self.key.weight', 'base_model.encoder.layer.6.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.0.attention.output.dense.bias', 'base_model.encoder.layer.8.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.2.output.dense.weight', 'base_model.encoder.layer.2.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.5.attention.output.LayerNorm.weight', 'base_model.encoder.layer.12.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.6.attention.self.key.weight', 'base_model.encoder.layer.15.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.10.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.11.attention.output.LayerNorm.weight', 'base_model.encoder.layer.20.attention.self.key.bias', 'base_model.encoder.layer.1.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.5.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.12.attention.self.query.bias', 'base_model.encoder.layer.15.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.14.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.7.intermediate.dense.weight', 'base_model.encoder.layer.19.attention.self.query.bias', 'base_model.encoder.layer.7.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.8.output.LayerNorm.weight', 'base_model.encoder.layer.2.intermediate.dense.weight', 'base_model.encoder.layer.13.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.6.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.4.attention.output.dense.bias', 'base_model.encoder.layer.3.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.20.output.LayerNorm.bias', 'base_model.encoder.layer.15.attention.self.query.weight', 'base_model.encoder.layer.4.attention.self.query.bias', 'base_model.encoder.layer.7.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.20.attention.output.dense.weight', 'base_model.encoder.layer.18.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.13.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.21.attention.self.value.weight', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.23.attention.self.key.weight', 'base_model.encoder.layer.13.output.LayerNorm.weight', 'base_model.encoder.layer.17.attention.self.query.weight', 'base_model.encoder.layer.0.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.6.output.dense.weight', 'base_model.encoder.layer.1.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.16.intermediate.dense.weight', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.18.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.3.output.dense.bias', 'base_model.encoder.layer.16.attention.self.key.bias', 'base_model.encoder.layer.9.output.dense.bias', 'base_model.encoder.layer.15.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.17.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.17.attention.self.key.bias', 'base_model.encoder.layer.10.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.2.attention.self.value.weight', 'base_model.encoder.layer.2.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.6.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.22.attention.self.query.bias', 'base_model.encoder.layer.0.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.8.intermediate.dense.bias', 'base_model.encoder.layer.15.attention.output.dense.bias', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.10.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.9.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.15.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.3.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.16.output.dense.weight', 'base_model.encoder.layer.14.attention.output.LayerNorm.bias', 'base_model.encoder.layer.8.attention.output.dense.weight', 'base_model.encoder.layer.12.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.1.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.19.output.LayerNorm.weight', 'base_model.embeddings.position_embeddings.weight', 'base_model.encoder.layer.14.output.LayerNorm.bias', 'base_model.encoder.layer.21.attention.self.value.bias', 'base_model.encoder.layer.7.attention.output.LayerNorm.bias', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.10.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.16.attention.self.query.bias', 'base_model.encoder.layer.7.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.14.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.5.attention.output.dense.weight', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.7.attention.self.key.bias', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.7.attention.self.key.weight', 'base_model.encoder.layer.17.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.21.intermediate.dense.weight', 'base_model.encoder.layer.0.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.10.output.LayerNorm.bias', 'base_model.encoder.layer.2.attention.output.dense.bias', 'base_model.encoder.layer.21.attention.output.LayerNorm.bias', 'base_model.encoder.layer.12.attention.output.LayerNorm.weight', 'base_model.encoder.layer.21.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.11.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.14.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.22.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.20.attention.self.query.bias', 'base_model.encoder.layer.18.attention.output.dense.bias', 'base_model.encoder.layer.3.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.6.attention.self.value.bias', 'base_model.encoder.layer.5.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.0.attention.self.key.bias', 'base_model.encoder.layer.5.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.6.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.11.output.dense.weight', 'base_model.encoder.layer.22.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.19.attention.output.LayerNorm.bias', 'base_model.embeddings.LayerNorm.bias', 'base_model.encoder.layer.3.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.10.attention.output.LayerNorm.weight', 'base_model.encoder.layer.20.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.20.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.11.output.LayerNorm.bias', 'base_model.encoder.layer.3.attention.self.query.bias', 'base_model.encoder.layer.17.attention.output.LayerNorm.bias', 'base_model.encoder.layer.15.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.9.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.23.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.4.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.4.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.13.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.17.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.18.intermediate.dense.weight', 'base_model.encoder.layer.18.intermediate.dense.bias', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.0.attention.output.LayerNorm.bias', 'base_model.encoder.layer.4.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.4.attention.self.value.bias', 'base_model.encoder.layer.11.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.0.attention.self.key.weight', 'base_model.encoder.layer.20.output.dense.bias', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.3.output.LayerNorm.weight', 'base_model.encoder.layer.20.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.17.attention.self.value.weight', 'base_model.encoder.layer.12.output.LayerNorm.weight', 'base_model.encoder.layer.18.attention.self.key.weight', 'base_model.encoder.layer.3.attention.self.value.bias', 'base_model.encoder.layer.4.attention.self.key.bias', 'qa_outputs.bias', 'base_model.encoder.layer.23.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.17.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.7.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.21.attention.self.key.weight', 'base_model.encoder.layer.9.attention.output.dense.bias', 'base_model.encoder.layer.19.attention.self.value.bias', 'base_model.encoder.layer.3.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.4.attention.output.LayerNorm.bias', 'base_model.encoder.layer.5.output.adapters.ep.adapter_down.0.bias', 'base_model.pooler.dense.bias', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.8.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.12.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.15.attention.output.LayerNorm.bias', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.16.attention.output.LayerNorm.bias', 'base_model.encoder.layer.4.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.13.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.19.output.dense.weight', 'base_model.encoder.layer.4.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.1.attention.output.LayerNorm.bias', 'base_model.encoder.layer.13.attention.output.LayerNorm.weight', 'base_model.encoder.layer.6.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.8.attention.output.LayerNorm.weight', 'base_model.encoder.layer.13.output.dense.weight', 'base_model.encoder.layer.0.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.17.intermediate.dense.bias', 'base_model.encoder.layer.21.attention.output.dense.bias', 'base_model.encoder.layer.8.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.15.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.3.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.1.intermediate.dense.bias', 'base_model.encoder.layer.2.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.18.output.dense.bias', 'base_model.encoder.layer.20.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.16.output.LayerNorm.bias', 'base_model.encoder.layer.6.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.17.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.3.intermediate.dense.bias', 'base_model.encoder.layer.15.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.2.attention.self.key.bias', 'base_model.encoder.layer.17.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.18.attention.output.LayerNorm.bias', 'base_model.encoder.layer.19.attention.output.LayerNorm.weight', 'base_model.encoder.layer.21.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.12.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.11.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.20.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.20.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.12.output.dense.bias', 'base_model.encoder.layer.9.attention.output.dense.weight', 'base_model.encoder.layer.21.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.10.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.22.attention.output.dense.bias', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.22.attention.self.query.weight', 'base_model.encoder.layer.15.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.18.attention.self.value.bias', 'base_model.encoder.layer.11.attention.output.LayerNorm.bias', 'base_model.encoder.layer.18.output.LayerNorm.bias', 'base_model.encoder.layer.23.attention.output.dense.weight', 'base_model.encoder.layer.1.attention.output.dense.bias', 'base_model.encoder.layer.16.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.10.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.20.attention.output.LayerNorm.bias', 'base_model.encoder.layer.6.attention.self.query.bias', 'base_model.embeddings.word_embeddings.weight', 'base_model.encoder.layer.14.attention.output.dense.bias', 'base_model.encoder.layer.14.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.10.attention.output.dense.bias', 'base_model.encoder.layer.2.attention.output.LayerNorm.bias', 'base_model.encoder.layer.14.output.dense.weight', 'base_model.encoder.layer.21.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.8.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.19.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.6.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.14.attention.self.value.bias', 'base_model.encoder.layer.18.output.LayerNorm.weight', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.2.attention.self.key.weight', 'base_model.encoder.layer.11.output.dense.bias', 'base_model.encoder.layer.2.output.dense.bias', 'base_model.encoder.layer.8.output.dense.weight', 'base_model.encoder.layer.7.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.9.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.10.output.LayerNorm.weight', 'base_model.encoder.layer.19.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.8.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.21.attention.self.query.weight', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.2.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.13.output.LayerNorm.bias', 'base_model.encoder.layer.6.attention.self.value.weight', 'base_model.encoder.layer.2.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.5.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.2.intermediate.dense.bias', 'base_model.encoder.layer.14.attention.output.dense.weight', 'base_model.encoder.layer.2.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.0.attention.self.query.weight', 'base_model.encoder.layer.9.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.7.attention.output.dense.bias', 'base_model.encoder.layer.9.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.21.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.12.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.19.attention.self.value.weight', 'base_model.encoder.layer.21.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.19.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.12.attention.self.query.weight', 'base_model.encoder.layer.10.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.19.attention.self.key.weight', 'base_model.encoder.layer.1.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.5.output.LayerNorm.bias', 'base_model.encoder.layer.4.attention.self.value.weight', 'base_model.encoder.layer.7.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.15.output.dense.weight', 'base_model.encoder.layer.12.attention.self.key.bias', 'base_model.encoder.layer.15.attention.self.key.weight', 'base_model.encoder.layer.19.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.19.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.20.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.5.output.dense.bias', 'base_model.encoder.layer.7.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.23.attention.self.value.weight', 'base_model.encoder.layer.7.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.7.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.2.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.6.output.LayerNorm.weight', 'base_model.encoder.layer.13.attention.self.value.weight', 'base_model.encoder.layer.23.output.LayerNorm.bias', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.15.attention.self.key.bias', 'base_model.encoder.layer.0.output.LayerNorm.weight', 'base_model.encoder.layer.1.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.14.attention.self.value.weight', 'base_model.encoder.layer.1.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.4.output.dense.bias', 'base_model.encoder.layer.11.attention.self.key.weight', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.19.attention.self.key.bias', 'base_model.encoder.layer.1.attention.output.LayerNorm.weight', 'base_model.encoder.layer.13.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.10.output.dense.bias', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.4.intermediate.dense.bias', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.10.attention.self.value.weight', 'base_model.encoder.layer.5.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.11.attention.output.dense.bias', 'base_model.encoder.layer.0.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.16.intermediate.dense.bias', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.4.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.6.intermediate.dense.bias', 'base_model.encoder.layer.17.attention.self.key.weight', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.15.output.LayerNorm.weight', 'base_model.encoder.layer.14.output.LayerNorm.weight', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.9.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.11.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.5.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.17.attention.self.query.bias', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.21.attention.self.query.bias', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.2.output.adapters.es.adapter_up.weight', 'base_model.embeddings.token_type_embeddings.weight', 'base_model.encoder.layer.1.attention.self.value.bias', 'base_model.encoder.layer.6.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.22.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.9.attention.self.key.bias', 'base_model.encoder.layer.3.attention.output.dense.bias', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.1.attention.self.value.weight', 'base_model.encoder.layer.21.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.17.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.11.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.3.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.13.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.3.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.3.attention.output.dense.weight', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.22.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.1.attention.self.query.bias', 'base_model.encoder.layer.6.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.5.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.0.attention.output.dense.weight', 'base_model.encoder.layer.6.attention.self.key.bias', 'base_model.encoder.layer.2.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.13.attention.output.dense.bias', 'base_model.encoder.layer.17.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.18.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.2.output.LayerNorm.weight', 'base_model.encoder.layer.5.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.12.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.0.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.1.attention.output.dense.weight', 'base_model.encoder.layer.1.output.dense.bias', 'base_model.encoder.layer.7.intermediate.dense.bias', 'base_model.encoder.layer.2.attention.self.query.bias', 'base_model.encoder.layer.5.attention.self.value.bias', 'base_model.encoder.layer.14.attention.self.query.bias', 'base_model.encoder.layer.5.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.4.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.6.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.11.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.20.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.4.attention.self.key.weight', 'base_model.encoder.layer.4.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.16.output.dense.bias', 'base_model.encoder.layer.4.output.LayerNorm.bias', 'base_model.encoder.layer.1.attention.self.key.weight', 'base_model.encoder.layer.16.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.14.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.17.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.4.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.9.attention.self.query.bias', 'base_model.encoder.layer.12.output.LayerNorm.bias', 'base_model.encoder.layer.20.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.22.attention.self.value.bias', 'base_model.encoder.layer.10.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.23.intermediate.dense.weight', 'base_model.encoder.layer.4.attention.output.dense.weight', 'base_model.encoder.layer.7.attention.self.query.weight', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.19.attention.self.query.weight', 'base_model.encoder.layer.0.attention.self.value.weight', 'base_model.encoder.layer.18.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.6.intermediate.dense.weight', 'base_model.encoder.layer.23.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.18.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.15.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.8.output.dense.bias', 'base_model.encoder.layer.12.attention.self.value.weight', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.11.attention.self.query.bias', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.17.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.6.attention.output.dense.weight', 'base_model.encoder.layer.17.output.LayerNorm.bias', 'base_model.encoder.layer.7.output.LayerNorm.bias', 'base_model.encoder.layer.1.intermediate.dense.weight', 'base_model.encoder.layer.7.attention.self.value.bias', 'base_model.encoder.layer.0.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.8.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.19.intermediate.dense.bias', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.9.attention.self.value.weight', 'base_model.encoder.layer.9.attention.self.value.bias', 'base_model.encoder.layer.5.attention.self.value.weight', 'base_model.embeddings.position_ids', 'base_model.encoder.layer.21.intermediate.dense.bias', 'base_model.encoder.layer.8.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.0.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.1.output.LayerNorm.weight', 'base_model.encoder.layer.8.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.12.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.13.intermediate.dense.bias', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.16.attention.self.query.weight', 'base_model.encoder.layer.16.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.23.output.dense.bias', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.5.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.23.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.20.attention.self.query.weight', 'base_model.encoder.layer.16.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.12.attention.output.LayerNorm.bias', 'base_model.encoder.layer.13.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.14.attention.self.key.bias', 'base_model.encoder.layer.4.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.6.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.4.intermediate.dense.weight', 'base_model.encoder.layer.19.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.11.output.LayerNorm.weight', 'base_model.encoder.layer.9.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.16.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.3.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.5.output.LayerNorm.weight', 'base_model.encoder.layer.5.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.22.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.13.attention.self.value.bias', 'base_model.encoder.layer.4.output.dense.weight', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.18.output.dense.weight', 'base_model.encoder.layer.10.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.22.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.16.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.2.attention.output.dense.weight', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.23.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.3.output.dense.weight', 'base_model.encoder.layer.13.attention.self.key.bias', 'base_model.encoder.layer.8.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.10.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.16.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.20.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.23.attention.self.key.bias', 'base_model.encoder.layer.2.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.4.attention.output.LayerNorm.weight', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.21.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.18.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.19.intermediate.dense.weight', 'base_model.encoder.layer.22.output.dense.weight', 'base_model.encoder.layer.22.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.22.attention.output.dense.weight', 'base_model.encoder.layer.0.output.dense.bias', 'base_model.encoder.layer.9.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.18.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.23.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.14.attention.output.LayerNorm.weight', 'base_model.encoder.layer.0.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.8.attention.self.value.weight', 'base_model.encoder.layer.9.output.LayerNorm.bias', 'base_model.encoder.layer.8.attention.self.query.weight', 'base_model.encoder.layer.22.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.16.attention.self.value.bias', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.1.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.5.intermediate.dense.weight', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.11.intermediate.dense.bias', 'base_model.encoder.layer.9.attention.output.LayerNorm.weight', 'base_model.encoder.layer.23.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.7.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.23.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.20.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.18.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.23.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.7.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.14.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.15.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.6.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.15.attention.self.query.bias', 'base_model.encoder.layer.16.attention.self.value.weight', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.11.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.13.attention.self.query.bias', 'base_model.encoder.layer.16.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.16.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.10.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.7.output.LayerNorm.weight', 'base_model.encoder.layer.18.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.22.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.7.attention.self.query.bias', 'base_model.encoder.layer.4.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.5.attention.output.dense.bias', 'base_model.encoder.layer.12.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.14.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.11.attention.self.key.bias', 'base_model.encoder.layer.17.output.LayerNorm.weight', 'base_model.encoder.layer.19.output.LayerNorm.bias', 'base_model.encoder.layer.21.output.dense.weight', 'base_model.encoder.layer.2.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.21.output.dense.bias', 'base_model.encoder.layer.12.attention.self.key.weight', 'base_model.encoder.layer.0.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.9.intermediate.dense.bias', 'base_model.encoder.layer.19.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.7.attention.output.dense.weight', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.11.attention.output.dense.weight', 'base_model.encoder.layer.3.attention.self.key.bias', 'base_model.encoder.layer.3.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.4.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.3.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.18.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.0.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.14.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.10.attention.self.query.bias', 'base_model.encoder.layer.12.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.19.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.14.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.18.attention.self.value.weight', 'base_model.encoder.layer.10.attention.self.value.bias', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.20.attention.output.LayerNorm.weight', 'base_model.encoder.layer.6.attention.output.LayerNorm.weight', 'base_model.encoder.layer.14.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.18.attention.output.dense.weight', 'base_model.encoder.layer.19.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.1.attention.self.key.bias', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.19.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.8.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.2.output.LayerNorm.bias', 'base_model.encoder.layer.21.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.22.output.LayerNorm.weight', 'base_model.encoder.layer.8.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.18.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.21.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.11.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.19.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.20.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.5.output.dense.weight', 'base_model.encoder.layer.12.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.23.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.9.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.15.intermediate.dense.bias', 'base_model.encoder.layer.20.attention.self.value.bias', 'base_model.encoder.layer.1.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.12.attention.output.dense.bias', 'base_model.encoder.layer.23.attention.self.query.weight', 'base_model.encoder.layer.12.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.10.attention.self.key.weight', 'base_model.encoder.layer.8.attention.output.dense.bias', 'base_model.encoder.layer.13.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.18.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.20.output.dense.weight', 'base_model.encoder.layer.20.attention.self.value.weight', 'base_model.encoder.layer.15.intermediate.dense.weight', 'base_model.encoder.layer.23.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.9.attention.self.key.weight', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.7.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.10.intermediate.dense.weight', 'base_model.encoder.layer.16.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.22.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.19.attention.output.dense.weight', 'base_model.encoder.layer.21.attention.self.key.bias', 'base_model.encoder.layer.0.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.20.attention.output.dense.bias', 'base_model.encoder.layer.7.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.6.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.6.attention.output.dense.bias', 'base_model.encoder.layer.23.output.LayerNorm.weight', 'base_model.encoder.layer.17.attention.output.dense.weight', 'base_model.encoder.layer.22.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.18.attention.output.LayerNorm.weight', 'base_model.encoder.layer.16.attention.output.dense.bias', 'base_model.encoder.layer.15.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.8.intermediate.dense.weight', 'base_model.encoder.layer.1.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.1.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.12.attention.self.value.bias', 'base_model.encoder.layer.3.intermediate.dense.weight', 'base_model.encoder.layer.7.output.dense.weight', 'base_model.encoder.layer.13.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.16.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.16.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.20.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.8.output.LayerNorm.bias', 'base_model.encoder.layer.16.attention.output.dense.weight', 'base_model.encoder.layer.16.attention.output.LayerNorm.weight', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.5.attention.self.query.bias', 'base_model.encoder.layer.5.attention.output.LayerNorm.bias', 'base_model.encoder.layer.20.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.0.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.11.attention.self.value.bias', 'base_model.encoder.layer.19.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.1.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.3.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.17.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.19.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.18.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.17.attention.output.dense.bias', 'base_model.encoder.layer.10.attention.self.query.weight', 'base_model.encoder.layer.14.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.16.attention.self.key.weight', 'base_model.encoder.layer.5.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.10.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.12.intermediate.dense.bias', 'base_model.encoder.layer.18.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.10.output.dense.weight', 'base_model.encoder.layer.11.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.9.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.12.intermediate.dense.weight', 'base_model.encoder.layer.0.attention.self.query.bias', 'base_model.encoder.layer.12.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.13.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.18.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.7.attention.self.value.weight', 'base_model.encoder.layer.13.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.18.attention.self.query.weight', 'base_model.encoder.layer.4.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.13.attention.self.key.weight', 'base_model.encoder.layer.14.attention.self.query.weight', 'base_model.encoder.layer.1.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.11.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.22.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.7.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.22.attention.self.value.weight', 'base_model.encoder.layer.4.output.LayerNorm.weight', 'base_model.encoder.layer.20.intermediate.dense.weight', 'base_model.encoder.layer.10.attention.self.key.bias', 'base_model.encoder.layer.7.output.dense.bias', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.11.attention.self.query.weight', 'base_model.encoder.layer.0.attention.self.value.bias', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.13.output.dense.bias', 'base_model.encoder.layer.23.intermediate.dense.bias', 'base_model.pooler.dense.weight', 'base_model.encoder.layer.12.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.3.output.LayerNorm.bias', 'base_model.encoder.layer.12.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.23.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.14.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.14.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.17.output.dense.weight', 'base_model.encoder.layer.22.attention.output.LayerNorm.weight', 'base_model.encoder.layer.3.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.2.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.15.attention.self.value.weight', 'base_model.encoder.layer.8.attention.self.value.bias', 'base_model.encoder.layer.11.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.8.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.10.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.23.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.14.intermediate.dense.bias', 'base_model.encoder.layer.7.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.11.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.6.attention.output.LayerNorm.bias', 'base_model.encoder.layer.3.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.15.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.3.attention.output.LayerNorm.weight', 'base_model.encoder.layer.15.attention.self.value.bias', 'base_model.encoder.layer.13.attention.self.query.weight', 'base_model.encoder.layer.10.attention.output.LayerNorm.bias', 'base_model.encoder.layer.15.output.dense.bias', 'base_model.encoder.layer.15.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.12.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.15.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.22.attention.self.key.bias', 'base_model.embeddings.LayerNorm.weight', 'base_model.encoder.layer.23.attention.self.value.bias', 'base_model.encoder.layer.5.intermediate.dense.bias', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.22.attention.output.LayerNorm.bias', 'base_model.encoder.layer.10.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.21.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.20.intermediate.dense.bias', 'base_model.encoder.layer.19.output.dense.bias', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.17.intermediate.dense.weight', 'base_model.encoder.layer.21.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.18.attention.self.query.bias', 'base_model.encoder.layer.21.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.8.attention.self.key.bias', 'base_model.encoder.layer.23.attention.output.dense.bias', 'base_model.encoder.layer.1.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.8.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.7.attention.output.LayerNorm.weight', 'base_model.encoder.layer.11.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.5.attention.self.key.bias', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.10.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.23.output.dense.weight', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.23.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.7.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.13.attention.output.LayerNorm.bias', 'base_model.encoder.layer.14.attention.self.key.weight', 'base_model.encoder.layer.1.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.2.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.9.intermediate.dense.weight', 'base_model.encoder.layer.2.attention.self.query.weight', 'base_model.encoder.layer.2.attention.output.LayerNorm.weight', 'base_model.encoder.layer.2.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.12.output.dense.weight', 'base_model.encoder.layer.13.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.1.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.22.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.3.attention.self.key.weight', 'base_model.encoder.layer.15.attention.output.LayerNorm.weight']
- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of XLMRobertaModel were not initialized from the model checkpoint at /cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//tydiqa/xlm-KG_LR8e-6_EPOCH2.0_maxlen384_batchsize4_gradacc4 and are newly initialized: ['encoder.layer.14.attention.self.key.weight', 'encoder.layer.8.output.dense.weight', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.10.output.LayerNorm.weight', 'encoder.layer.6.attention.self.value.weight', 'encoder.layer.9.output.dense.weight', 'encoder.layer.3.attention.self.value.bias', 'encoder.layer.1.attention.self.value.weight', 'encoder.layer.7.output.LayerNorm.weight', 'encoder.layer.22.output.dense.bias', 'encoder.layer.13.intermediate.dense.weight', 'encoder.layer.20.attention.self.value.bias', 'encoder.layer.2.output.dense.weight', 'encoder.layer.8.output.LayerNorm.bias', 'encoder.layer.10.attention.self.key.weight', 'encoder.layer.2.attention.self.value.bias', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.19.output.LayerNorm.weight', 'encoder.layer.22.intermediate.dense.weight', 'encoder.layer.18.output.dense.weight', 'encoder.layer.1.attention.self.key.bias', 'encoder.layer.4.attention.output.dense.weight', 'encoder.layer.23.attention.output.dense.weight', 'encoder.layer.9.attention.self.value.weight', 'encoder.layer.17.output.dense.weight', 'encoder.layer.18.attention.self.key.bias', 'encoder.layer.12.attention.output.LayerNorm.weight', 'encoder.layer.20.attention.self.value.weight', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.17.output.dense.bias', 'encoder.layer.15.output.LayerNorm.weight', 'encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.21.output.LayerNorm.bias', 'encoder.layer.7.output.dense.weight', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.21.attention.self.key.weight', 'encoder.layer.15.output.dense.weight', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.11.attention.self.key.bias', 'encoder.layer.4.attention.self.query.weight', 'encoder.layer.21.output.dense.weight', 'encoder.layer.11.attention.self.query.bias', 'pooler.dense.weight', 'encoder.layer.11.attention.output.dense.weight', 'encoder.layer.12.intermediate.dense.weight', 'encoder.layer.16.intermediate.dense.weight', 'encoder.layer.13.attention.output.LayerNorm.weight', 'encoder.layer.15.attention.self.value.weight', 'encoder.layer.17.attention.self.value.bias', 'encoder.layer.6.attention.self.query.bias', 'encoder.layer.14.intermediate.dense.bias', 'encoder.layer.6.attention.self.key.bias', 'pooler.dense.bias', 'encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.layer.5.attention.output.dense.weight', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.11.attention.self.query.weight', 'encoder.layer.0.attention.output.dense.weight', 'encoder.layer.11.output.LayerNorm.bias', 'encoder.layer.10.attention.self.value.bias', 'encoder.layer.15.attention.self.query.bias', 'encoder.layer.0.attention.self.value.bias', 'encoder.layer.21.attention.self.value.bias', 'encoder.layer.8.attention.self.query.bias', 'encoder.layer.19.attention.self.key.weight', 'encoder.layer.9.attention.output.LayerNorm.bias', 'encoder.layer.13.output.dense.weight', 'encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.layer.0.attention.self.query.weight', 'embeddings.token_type_embeddings.weight', 'encoder.layer.12.attention.self.value.weight', 'encoder.layer.4.output.dense.bias', 'encoder.layer.10.output.dense.weight', 'encoder.layer.16.attention.output.dense.bias', 'encoder.layer.18.attention.self.value.weight', 'encoder.layer.17.attention.self.value.weight', 'encoder.layer.10.attention.self.key.bias', 'encoder.layer.20.attention.output.LayerNorm.weight', 'encoder.layer.19.attention.output.LayerNorm.bias', 'encoder.layer.7.attention.self.value.bias', 'encoder.layer.12.attention.self.query.bias', 'encoder.layer.8.output.dense.bias', 'encoder.layer.7.attention.self.query.bias', 'encoder.layer.20.output.LayerNorm.bias', 'encoder.layer.5.attention.self.query.bias', 'encoder.layer.19.attention.self.value.weight', 'encoder.layer.5.attention.self.query.weight', 'encoder.layer.20.attention.output.dense.bias', 'encoder.layer.11.output.dense.bias', 'encoder.layer.8.attention.self.key.bias', 'encoder.layer.10.attention.self.value.weight', 'encoder.layer.19.attention.output.LayerNorm.weight', 'encoder.layer.16.output.LayerNorm.weight', 'encoder.layer.23.output.LayerNorm.weight', 'encoder.layer.21.attention.output.dense.weight', 'encoder.layer.18.attention.output.dense.weight', 'encoder.layer.18.attention.self.value.bias', 'encoder.layer.16.attention.self.query.bias', 'encoder.layer.21.intermediate.dense.weight', 'encoder.layer.19.attention.self.query.bias', 'encoder.layer.2.attention.self.query.weight', 'encoder.layer.5.output.dense.weight', 'encoder.layer.10.attention.output.LayerNorm.bias', 'encoder.layer.21.attention.self.key.bias', 'encoder.layer.1.attention.self.key.weight', 'encoder.layer.7.attention.self.key.bias', 'encoder.layer.19.output.LayerNorm.bias', 'encoder.layer.9.attention.self.key.weight', 'encoder.layer.14.attention.self.key.bias', 'encoder.layer.13.attention.self.key.bias', 'encoder.layer.7.attention.output.dense.bias', 'encoder.layer.8.attention.self.value.bias', 'encoder.layer.20.attention.self.query.weight', 'encoder.layer.16.attention.self.value.bias', 'encoder.layer.22.attention.self.value.weight', 'encoder.layer.18.output.LayerNorm.weight', 'encoder.layer.12.output.dense.weight', 'encoder.layer.5.output.dense.bias', 'encoder.layer.3.attention.self.value.weight', 'encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.layer.0.attention.output.dense.bias', 'encoder.layer.3.output.dense.bias', 'encoder.layer.2.attention.self.query.bias', 'encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.layer.22.output.LayerNorm.weight', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.11.attention.self.value.bias', 'encoder.layer.2.attention.output.dense.bias', 'encoder.layer.21.attention.output.dense.bias', 'encoder.layer.23.attention.self.query.weight', 'encoder.layer.15.attention.self.key.bias', 'encoder.layer.14.attention.self.query.bias', 'encoder.layer.23.intermediate.dense.weight', 'encoder.layer.23.attention.output.LayerNorm.bias', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.8.output.LayerNorm.weight', 'encoder.layer.22.attention.self.key.weight', 'encoder.layer.3.attention.output.dense.weight', 'encoder.layer.6.attention.output.LayerNorm.bias', 'encoder.layer.12.attention.output.dense.weight', 'encoder.layer.16.attention.self.query.weight', 'encoder.layer.7.output.LayerNorm.bias', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.20.attention.self.key.bias', 'encoder.layer.22.attention.self.value.bias', 'encoder.layer.14.output.LayerNorm.weight', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.2.attention.output.LayerNorm.weight', 'encoder.layer.10.attention.output.dense.weight', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.21.attention.self.query.weight', 'encoder.layer.17.intermediate.dense.weight', 'encoder.layer.9.attention.self.value.bias', 'encoder.layer.5.attention.self.value.weight', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.14.attention.self.value.bias', 'encoder.layer.15.intermediate.dense.weight', 'encoder.layer.18.intermediate.dense.bias', 'encoder.layer.18.attention.output.dense.bias', 'encoder.layer.17.output.LayerNorm.weight', 'encoder.layer.14.attention.output.dense.weight', 'encoder.layer.12.attention.self.value.bias', 'encoder.layer.22.attention.output.LayerNorm.weight', 'encoder.layer.10.attention.self.query.weight', 'encoder.layer.23.attention.self.key.weight', 'encoder.layer.17.attention.output.LayerNorm.weight', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.21.output.dense.bias', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.23.attention.self.query.bias', 'encoder.layer.6.output.dense.bias', 'encoder.layer.19.intermediate.dense.bias', 'encoder.layer.14.attention.output.LayerNorm.weight', 'embeddings.LayerNorm.bias', 'encoder.layer.2.attention.output.dense.weight', 'encoder.layer.8.attention.output.dense.bias', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.23.attention.self.value.bias', 'encoder.layer.8.attention.self.key.weight', 'encoder.layer.17.intermediate.dense.bias', 'encoder.layer.16.attention.self.key.weight', 'encoder.layer.22.attention.output.dense.bias', 'encoder.layer.7.attention.output.LayerNorm.bias', 'encoder.layer.10.intermediate.dense.weight', 'encoder.layer.22.attention.self.query.weight', 'encoder.layer.7.output.dense.bias', 'encoder.layer.10.attention.output.dense.bias', 'encoder.layer.9.output.dense.bias', 'encoder.layer.20.output.dense.weight', 'encoder.layer.10.attention.output.LayerNorm.weight', 'encoder.layer.16.output.dense.weight', 'encoder.layer.5.output.LayerNorm.bias', 'encoder.layer.12.attention.output.dense.bias', 'encoder.layer.19.output.dense.weight', 'encoder.layer.10.attention.self.query.bias', 'encoder.layer.7.attention.self.key.weight', 'encoder.layer.15.attention.output.dense.bias', 'encoder.layer.17.attention.output.LayerNorm.bias', 'encoder.layer.13.attention.self.key.weight', 'encoder.layer.9.attention.output.dense.bias', 'embeddings.position_embeddings.weight', 'encoder.layer.1.attention.output.LayerNorm.weight', 'encoder.layer.20.attention.output.dense.weight', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.15.output.LayerNorm.bias', 'encoder.layer.15.attention.output.dense.weight', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.0.attention.output.LayerNorm.weight', 'encoder.layer.6.attention.self.query.weight', 'encoder.layer.13.attention.self.query.bias', 'encoder.layer.18.attention.self.query.weight', 'encoder.layer.23.attention.self.key.bias', 'encoder.layer.17.attention.self.key.bias', 'encoder.layer.6.attention.output.dense.bias', 'encoder.layer.14.attention.self.query.weight', 'encoder.layer.13.attention.self.value.weight', 'encoder.layer.7.intermediate.dense.bias', 'encoder.layer.1.attention.output.dense.weight', 'encoder.layer.18.output.dense.bias', 'encoder.layer.15.attention.self.key.weight', 'encoder.layer.17.attention.self.key.weight', 'encoder.layer.0.output.dense.weight', 'encoder.layer.12.output.LayerNorm.bias', 'encoder.layer.15.intermediate.dense.bias', 'encoder.layer.4.attention.output.LayerNorm.weight', 'encoder.layer.21.attention.output.LayerNorm.weight', 'encoder.layer.9.attention.output.dense.weight', 'encoder.layer.20.attention.output.LayerNorm.bias', 'encoder.layer.9.attention.self.key.bias', 'encoder.layer.8.attention.self.query.weight', 'encoder.layer.12.attention.self.key.weight', 'encoder.layer.13.attention.output.LayerNorm.bias', 'encoder.layer.1.output.dense.weight', 'encoder.layer.23.output.dense.weight', 'encoder.layer.13.output.dense.bias', 'encoder.layer.19.attention.self.value.bias', 'encoder.layer.16.output.dense.bias', 'encoder.layer.23.intermediate.dense.bias', 'encoder.layer.16.output.LayerNorm.bias', 'encoder.layer.21.attention.self.query.bias', 'encoder.layer.11.attention.self.value.weight', 'encoder.layer.14.attention.self.value.weight', 'encoder.layer.21.intermediate.dense.bias', 'encoder.layer.20.attention.self.query.bias', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.9.attention.self.query.bias', 'encoder.layer.6.attention.self.key.weight', 'encoder.layer.3.output.dense.weight', 'encoder.layer.16.attention.output.LayerNorm.weight', 'encoder.layer.1.attention.output.dense.bias', 'encoder.layer.10.output.dense.bias', 'encoder.layer.5.attention.output.dense.bias', 'encoder.layer.18.output.LayerNorm.bias', 'encoder.layer.19.intermediate.dense.weight', 'encoder.layer.1.output.dense.bias', 'encoder.layer.11.output.LayerNorm.weight', 'encoder.layer.4.attention.self.value.bias', 'encoder.layer.4.output.dense.weight', 'encoder.layer.18.attention.self.key.weight', 'encoder.layer.5.attention.self.value.bias', 'encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.layer.6.attention.self.value.bias', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.9.attention.self.query.weight', 'encoder.layer.3.attention.self.query.bias', 'encoder.layer.11.output.dense.weight', 'encoder.layer.23.output.LayerNorm.bias', 'encoder.layer.6.attention.output.LayerNorm.weight', 'encoder.layer.14.output.LayerNorm.bias', 'encoder.layer.23.attention.output.dense.bias', 'encoder.layer.17.attention.output.dense.bias', 'encoder.layer.17.attention.self.query.bias', 'encoder.layer.2.output.dense.bias', 'encoder.layer.13.attention.self.query.weight', 'encoder.layer.12.intermediate.dense.bias', 'encoder.layer.21.output.LayerNorm.weight', 'encoder.layer.1.attention.self.value.bias', 'encoder.layer.16.intermediate.dense.bias', 'embeddings.word_embeddings.weight', 'encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.layer.15.attention.output.LayerNorm.weight', 'encoder.layer.4.attention.self.key.weight', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.15.attention.output.LayerNorm.bias', 'encoder.layer.23.output.dense.bias', 'encoder.layer.20.intermediate.dense.bias', 'encoder.layer.4.attention.output.LayerNorm.bias', 'encoder.layer.4.attention.self.value.weight', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.18.attention.output.LayerNorm.weight', 'encoder.layer.2.attention.self.key.weight', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.0.attention.self.value.weight', 'encoder.layer.19.attention.output.dense.weight', 'embeddings.LayerNorm.weight', 'encoder.layer.22.intermediate.dense.bias', 'encoder.layer.17.output.LayerNorm.bias', 'encoder.layer.20.intermediate.dense.weight', 'encoder.layer.8.attention.output.LayerNorm.bias', 'encoder.layer.22.output.LayerNorm.bias', 'encoder.layer.14.attention.output.LayerNorm.bias', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.11.attention.self.key.weight', 'encoder.layer.14.attention.output.dense.bias', 'encoder.layer.19.attention.self.query.weight', 'encoder.layer.0.output.dense.bias', 'encoder.layer.21.attention.self.value.weight', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.7.attention.self.value.weight', 'encoder.layer.4.attention.self.query.bias', 'encoder.layer.18.intermediate.dense.weight', 'encoder.layer.0.attention.self.key.bias', 'encoder.layer.3.attention.self.key.weight', 'encoder.layer.22.attention.self.key.bias', 'encoder.layer.12.attention.self.query.weight', 'encoder.layer.5.attention.self.key.weight', 'encoder.layer.13.output.LayerNorm.bias', 'encoder.layer.13.attention.output.dense.weight', 'encoder.layer.10.output.LayerNorm.bias', 'encoder.layer.15.attention.self.query.weight', 'encoder.layer.12.attention.self.key.bias', 'encoder.layer.7.attention.self.query.weight', 'encoder.layer.12.output.LayerNorm.weight', 'encoder.layer.14.intermediate.dense.weight', 'encoder.layer.16.attention.output.dense.weight', 'encoder.layer.18.attention.output.LayerNorm.bias', 'encoder.layer.16.attention.self.key.bias', 'encoder.layer.13.intermediate.dense.bias', 'encoder.layer.1.attention.self.query.bias', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.3.attention.self.query.weight', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.18.attention.self.query.bias', 'encoder.layer.22.attention.self.query.bias', 'encoder.layer.11.attention.output.dense.bias', 'encoder.layer.3.attention.self.key.bias', 'encoder.layer.3.attention.output.dense.bias', 'encoder.layer.7.attention.output.dense.weight', 'encoder.layer.11.attention.output.LayerNorm.weight', 'encoder.layer.22.attention.output.LayerNorm.bias', 'encoder.layer.13.attention.output.dense.bias', 'encoder.layer.13.output.LayerNorm.weight', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.13.attention.self.value.bias', 'encoder.layer.4.attention.output.dense.bias', 'encoder.layer.5.attention.self.key.bias', 'encoder.layer.9.output.LayerNorm.bias', 'encoder.layer.22.attention.output.dense.weight', 'encoder.layer.23.attention.self.value.weight', 'encoder.layer.2.attention.self.value.weight', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.17.attention.self.query.weight', 'encoder.layer.12.attention.output.LayerNorm.bias', 'encoder.layer.2.attention.output.LayerNorm.bias', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.17.attention.output.dense.weight', 'encoder.layer.6.output.dense.weight', 'encoder.layer.9.attention.output.LayerNorm.weight', 'encoder.layer.8.attention.output.LayerNorm.weight', 'encoder.layer.21.attention.output.LayerNorm.bias', 'encoder.layer.19.attention.output.dense.bias', 'encoder.layer.20.output.dense.bias', 'encoder.layer.19.attention.self.key.bias', 'encoder.layer.9.output.LayerNorm.weight', 'encoder.layer.1.attention.self.query.weight', 'encoder.layer.19.output.dense.bias', 'encoder.layer.14.output.dense.weight', 'encoder.layer.20.output.LayerNorm.weight', 'encoder.layer.14.output.dense.bias', 'encoder.layer.8.attention.output.dense.weight', 'encoder.layer.0.attention.self.query.bias', 'encoder.layer.5.attention.output.LayerNorm.weight', 'encoder.layer.16.attention.output.LayerNorm.bias', 'encoder.layer.4.attention.self.key.bias', 'encoder.layer.20.attention.self.key.weight', 'encoder.layer.15.attention.self.value.bias', 'encoder.layer.12.output.dense.bias', 'encoder.layer.0.attention.self.key.weight', 'encoder.layer.2.attention.self.key.bias', 'encoder.layer.23.attention.output.LayerNorm.weight', 'encoder.layer.16.attention.self.value.weight', 'encoder.layer.8.attention.self.value.weight', 'encoder.layer.6.output.LayerNorm.bias', 'encoder.layer.22.output.dense.weight', 'encoder.layer.7.attention.output.LayerNorm.weight', 'encoder.layer.15.output.dense.bias', 'encoder.layer.6.attention.output.dense.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Overwriting existing adapter 'ep'.
Overwriting existing adapter 'tp'.
Overwriting existing adapter 'es'.
Overwriting existing adapter 'ts'.
Overwriting existing adapter fusion module 'ep,tp,es,ts'
05/09/2022 22:52:10 - INFO - __main__ -   lang2id = None
05/09/2022 22:52:13 - INFO - __main__ -   Training/evaluation parameters Namespace(adam_epsilon=1e-08, cache_dir='', config_name='', data_dir=None, device=device(type='cuda'), do_eval=True, do_lower_case=False, do_train=False, doc_stride=128, eval_all_checkpoints=False, eval_lang='bn', evaluate_during_training=False, fp16=False, fp16_opt_level='O1', gradient_accumulation_steps=1, learning_rate=5e-05, local_rank=-1, logging_steps=50, max_answer_length=30, max_grad_norm=1.0, max_query_length=64, max_seq_length=384, max_steps=-1, model_name='xlm-KG', model_name_or_path='/cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//tydiqa/xlm-KG_LR8e-6_EPOCH2.0_maxlen384_batchsize4_gradacc4', model_type='xlm', modelkg_dir='/cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/adapter/xlmr_adapter', n_best_size=20, n_gpu=1, no_cuda=False, null_score_diff_threshold=0.0, num_train_epochs=3.0, output_dir='/cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//tydiqa/xlm-KG_LR8e-6_EPOCH2.0_maxlen384_batchsize4_gradacc4/predictions/tydiqa/', overwrite_cache=False, overwrite_output_dir=False, per_gpu_eval_batch_size=8, per_gpu_train_batch_size=8, predict_file='/cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/download//tydiqa//tydiqa-goldp-v1.1-dev/tydiqa.goldp.bn.dev.json', save_steps=50, seed=42, server_ip='', server_port='', threads=1, tokenizer_name='', train_file=None, train_lang='en', verbose_logging=False, version_2_with_negative=False, warmup_steps=0, weight_decay=0.0)
05/09/2022 22:52:13 - INFO - __main__ -   Loading checkpoint /cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//tydiqa/xlm-KG_LR8e-6_EPOCH2.0_maxlen384_batchsize4_gradacc4 for evaluation
05/09/2022 22:52:13 - INFO - __main__ -   Evaluate the following checkpoints: ['/cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//tydiqa/xlm-KG_LR8e-6_EPOCH2.0_maxlen384_batchsize4_gradacc4']
Some weights of the model checkpoint at /cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//tydiqa/xlm-KG_LR8e-6_EPOCH2.0_maxlen384_batchsize4_gradacc4 were not used when initializing XLMRobertaModel: ['base_model.encoder.layer.22.intermediate.dense.weight', 'base_model.encoder.layer.0.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.1.attention.self.query.weight', 'base_model.encoder.layer.16.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.9.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.13.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.22.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.16.output.LayerNorm.weight', 'base_model.encoder.layer.4.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.4.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.22.output.LayerNorm.bias', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.17.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.19.attention.output.dense.bias', 'base_model.encoder.layer.0.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.2.attention.self.value.bias', 'base_model.encoder.layer.6.output.dense.bias', 'base_model.encoder.layer.3.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.8.attention.output.LayerNorm.bias', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.17.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.9.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.11.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.17.output.dense.bias', 'base_model.encoder.layer.17.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.8.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.11.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.23.attention.output.LayerNorm.bias', 'base_model.encoder.layer.19.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.11.attention.self.value.weight', 'base_model.encoder.layer.15.output.LayerNorm.bias', 'base_model.encoder.layer.18.attention.self.key.bias', 'base_model.encoder.layer.20.output.LayerNorm.weight', 'base_model.encoder.layer.21.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.9.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.6.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.22.intermediate.dense.bias', 'base_model.encoder.layer.23.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.21.attention.output.LayerNorm.weight', 'base_model.encoder.layer.23.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.1.output.LayerNorm.bias', 'base_model.encoder.layer.13.attention.output.dense.weight', 'base_model.encoder.layer.17.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.5.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.9.output.LayerNorm.weight', 'base_model.encoder.layer.14.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.13.intermediate.dense.weight', 'base_model.encoder.layer.10.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.4.attention.self.query.weight', 'base_model.encoder.layer.8.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.5.attention.self.query.weight', 'base_model.encoder.layer.19.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.13.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.8.attention.self.key.weight', 'base_model.encoder.layer.6.attention.self.query.weight', 'base_model.encoder.layer.8.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.9.output.dense.weight', 'base_model.encoder.layer.22.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.20.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.2.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.9.attention.self.query.weight', 'base_model.encoder.layer.9.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.0.output.LayerNorm.bias', 'base_model.encoder.layer.3.attention.self.value.weight', 'base_model.encoder.layer.10.intermediate.dense.bias', 'base_model.encoder.layer.0.attention.output.LayerNorm.weight', 'base_model.encoder.layer.16.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.20.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.13.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.22.output.dense.bias', 'base_model.encoder.layer.14.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.17.attention.output.LayerNorm.weight', 'base_model.encoder.layer.5.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.17.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.16.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.20.attention.self.key.weight', 'base_model.encoder.layer.12.attention.output.dense.weight', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.9.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.23.attention.self.query.bias', 'base_model.encoder.layer.18.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.13.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.14.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.22.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.16.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.6.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.21.output.LayerNorm.weight', 'base_model.encoder.layer.1.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.0.intermediate.dense.weight', 'base_model.encoder.layer.0.intermediate.dense.bias', 'base_model.encoder.layer.14.output.dense.bias', 'base_model.encoder.layer.15.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.11.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.6.output.LayerNorm.bias', 'base_model.encoder.layer.19.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.14.intermediate.dense.weight', 'base_model.encoder.layer.3.attention.output.LayerNorm.bias', 'base_model.encoder.layer.5.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.15.attention.output.dense.weight', 'base_model.encoder.layer.21.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.12.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.9.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.17.attention.self.value.bias', 'base_model.encoder.layer.21.output.LayerNorm.bias', 'base_model.encoder.layer.10.attention.output.dense.weight', 'base_model.encoder.layer.0.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.1.output.dense.weight', 'base_model.encoder.layer.11.intermediate.dense.weight', 'qa_outputs.weight', 'base_model.encoder.layer.2.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.23.attention.output.LayerNorm.weight', 'base_model.encoder.layer.3.attention.self.query.weight', 'base_model.encoder.layer.3.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.5.attention.self.key.weight', 'base_model.encoder.layer.15.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.6.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.4.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.9.attention.output.LayerNorm.bias', 'base_model.encoder.layer.8.attention.self.query.bias', 'base_model.encoder.layer.21.attention.output.dense.weight', 'base_model.encoder.layer.0.output.dense.weight', 'base_model.encoder.layer.21.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.22.attention.self.key.weight', 'base_model.encoder.layer.6.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.0.attention.output.dense.bias', 'base_model.encoder.layer.8.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.2.output.dense.weight', 'base_model.encoder.layer.2.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.5.attention.output.LayerNorm.weight', 'base_model.encoder.layer.12.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.6.attention.self.key.weight', 'base_model.encoder.layer.15.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.10.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.11.attention.output.LayerNorm.weight', 'base_model.encoder.layer.20.attention.self.key.bias', 'base_model.encoder.layer.1.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.5.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.12.attention.self.query.bias', 'base_model.encoder.layer.15.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.14.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.7.intermediate.dense.weight', 'base_model.encoder.layer.19.attention.self.query.bias', 'base_model.encoder.layer.7.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.8.output.LayerNorm.weight', 'base_model.encoder.layer.2.intermediate.dense.weight', 'base_model.encoder.layer.13.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.6.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.4.attention.output.dense.bias', 'base_model.encoder.layer.3.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.20.output.LayerNorm.bias', 'base_model.encoder.layer.15.attention.self.query.weight', 'base_model.encoder.layer.4.attention.self.query.bias', 'base_model.encoder.layer.7.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.20.attention.output.dense.weight', 'base_model.encoder.layer.18.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.13.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.21.attention.self.value.weight', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.23.attention.self.key.weight', 'base_model.encoder.layer.13.output.LayerNorm.weight', 'base_model.encoder.layer.17.attention.self.query.weight', 'base_model.encoder.layer.0.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.6.output.dense.weight', 'base_model.encoder.layer.1.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.16.intermediate.dense.weight', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.18.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.3.output.dense.bias', 'base_model.encoder.layer.16.attention.self.key.bias', 'base_model.encoder.layer.9.output.dense.bias', 'base_model.encoder.layer.15.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.17.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.17.attention.self.key.bias', 'base_model.encoder.layer.10.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.2.attention.self.value.weight', 'base_model.encoder.layer.2.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.6.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.22.attention.self.query.bias', 'base_model.encoder.layer.0.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.8.intermediate.dense.bias', 'base_model.encoder.layer.15.attention.output.dense.bias', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.10.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.9.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.15.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.3.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.16.output.dense.weight', 'base_model.encoder.layer.14.attention.output.LayerNorm.bias', 'base_model.encoder.layer.8.attention.output.dense.weight', 'base_model.encoder.layer.12.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.1.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.19.output.LayerNorm.weight', 'base_model.embeddings.position_embeddings.weight', 'base_model.encoder.layer.14.output.LayerNorm.bias', 'base_model.encoder.layer.21.attention.self.value.bias', 'base_model.encoder.layer.7.attention.output.LayerNorm.bias', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.10.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.16.attention.self.query.bias', 'base_model.encoder.layer.7.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.14.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.5.attention.output.dense.weight', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.7.attention.self.key.bias', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.7.attention.self.key.weight', 'base_model.encoder.layer.17.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.21.intermediate.dense.weight', 'base_model.encoder.layer.0.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.10.output.LayerNorm.bias', 'base_model.encoder.layer.2.attention.output.dense.bias', 'base_model.encoder.layer.21.attention.output.LayerNorm.bias', 'base_model.encoder.layer.12.attention.output.LayerNorm.weight', 'base_model.encoder.layer.21.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.11.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.14.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.22.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.20.attention.self.query.bias', 'base_model.encoder.layer.18.attention.output.dense.bias', 'base_model.encoder.layer.3.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.6.attention.self.value.bias', 'base_model.encoder.layer.5.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.0.attention.self.key.bias', 'base_model.encoder.layer.5.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.6.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.11.output.dense.weight', 'base_model.encoder.layer.22.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.19.attention.output.LayerNorm.bias', 'base_model.embeddings.LayerNorm.bias', 'base_model.encoder.layer.3.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.10.attention.output.LayerNorm.weight', 'base_model.encoder.layer.20.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.20.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.11.output.LayerNorm.bias', 'base_model.encoder.layer.3.attention.self.query.bias', 'base_model.encoder.layer.17.attention.output.LayerNorm.bias', 'base_model.encoder.layer.15.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.9.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.23.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.4.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.4.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.13.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.17.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.18.intermediate.dense.weight', 'base_model.encoder.layer.18.intermediate.dense.bias', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.0.attention.output.LayerNorm.bias', 'base_model.encoder.layer.4.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.4.attention.self.value.bias', 'base_model.encoder.layer.11.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.0.attention.self.key.weight', 'base_model.encoder.layer.20.output.dense.bias', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.3.output.LayerNorm.weight', 'base_model.encoder.layer.20.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.17.attention.self.value.weight', 'base_model.encoder.layer.12.output.LayerNorm.weight', 'base_model.encoder.layer.18.attention.self.key.weight', 'base_model.encoder.layer.3.attention.self.value.bias', 'base_model.encoder.layer.4.attention.self.key.bias', 'qa_outputs.bias', 'base_model.encoder.layer.23.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.17.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.7.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.21.attention.self.key.weight', 'base_model.encoder.layer.9.attention.output.dense.bias', 'base_model.encoder.layer.19.attention.self.value.bias', 'base_model.encoder.layer.3.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.4.attention.output.LayerNorm.bias', 'base_model.encoder.layer.5.output.adapters.ep.adapter_down.0.bias', 'base_model.pooler.dense.bias', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.8.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.12.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.15.attention.output.LayerNorm.bias', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.16.attention.output.LayerNorm.bias', 'base_model.encoder.layer.4.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.13.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.19.output.dense.weight', 'base_model.encoder.layer.4.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.1.attention.output.LayerNorm.bias', 'base_model.encoder.layer.13.attention.output.LayerNorm.weight', 'base_model.encoder.layer.6.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.8.attention.output.LayerNorm.weight', 'base_model.encoder.layer.13.output.dense.weight', 'base_model.encoder.layer.0.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.17.intermediate.dense.bias', 'base_model.encoder.layer.21.attention.output.dense.bias', 'base_model.encoder.layer.8.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.15.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.3.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.1.intermediate.dense.bias', 'base_model.encoder.layer.2.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.18.output.dense.bias', 'base_model.encoder.layer.20.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.16.output.LayerNorm.bias', 'base_model.encoder.layer.6.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.17.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.3.intermediate.dense.bias', 'base_model.encoder.layer.15.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.2.attention.self.key.bias', 'base_model.encoder.layer.17.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.18.attention.output.LayerNorm.bias', 'base_model.encoder.layer.19.attention.output.LayerNorm.weight', 'base_model.encoder.layer.21.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.12.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.11.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.20.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.20.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.12.output.dense.bias', 'base_model.encoder.layer.9.attention.output.dense.weight', 'base_model.encoder.layer.21.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.10.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.22.attention.output.dense.bias', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.22.attention.self.query.weight', 'base_model.encoder.layer.15.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.18.attention.self.value.bias', 'base_model.encoder.layer.11.attention.output.LayerNorm.bias', 'base_model.encoder.layer.18.output.LayerNorm.bias', 'base_model.encoder.layer.23.attention.output.dense.weight', 'base_model.encoder.layer.1.attention.output.dense.bias', 'base_model.encoder.layer.16.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.10.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.20.attention.output.LayerNorm.bias', 'base_model.encoder.layer.6.attention.self.query.bias', 'base_model.embeddings.word_embeddings.weight', 'base_model.encoder.layer.14.attention.output.dense.bias', 'base_model.encoder.layer.14.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.10.attention.output.dense.bias', 'base_model.encoder.layer.2.attention.output.LayerNorm.bias', 'base_model.encoder.layer.14.output.dense.weight', 'base_model.encoder.layer.21.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.8.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.19.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.6.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.14.attention.self.value.bias', 'base_model.encoder.layer.18.output.LayerNorm.weight', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.2.attention.self.key.weight', 'base_model.encoder.layer.11.output.dense.bias', 'base_model.encoder.layer.2.output.dense.bias', 'base_model.encoder.layer.8.output.dense.weight', 'base_model.encoder.layer.7.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.9.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.10.output.LayerNorm.weight', 'base_model.encoder.layer.19.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.8.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.21.attention.self.query.weight', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.2.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.13.output.LayerNorm.bias', 'base_model.encoder.layer.6.attention.self.value.weight', 'base_model.encoder.layer.2.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.5.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.2.intermediate.dense.bias', 'base_model.encoder.layer.14.attention.output.dense.weight', 'base_model.encoder.layer.2.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.0.attention.self.query.weight', 'base_model.encoder.layer.9.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.7.attention.output.dense.bias', 'base_model.encoder.layer.9.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.21.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.12.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.19.attention.self.value.weight', 'base_model.encoder.layer.21.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.19.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.12.attention.self.query.weight', 'base_model.encoder.layer.10.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.19.attention.self.key.weight', 'base_model.encoder.layer.1.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.5.output.LayerNorm.bias', 'base_model.encoder.layer.4.attention.self.value.weight', 'base_model.encoder.layer.7.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.15.output.dense.weight', 'base_model.encoder.layer.12.attention.self.key.bias', 'base_model.encoder.layer.15.attention.self.key.weight', 'base_model.encoder.layer.19.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.19.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.20.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.5.output.dense.bias', 'base_model.encoder.layer.7.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.23.attention.self.value.weight', 'base_model.encoder.layer.7.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.7.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.2.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.6.output.LayerNorm.weight', 'base_model.encoder.layer.13.attention.self.value.weight', 'base_model.encoder.layer.23.output.LayerNorm.bias', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.15.attention.self.key.bias', 'base_model.encoder.layer.0.output.LayerNorm.weight', 'base_model.encoder.layer.1.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.14.attention.self.value.weight', 'base_model.encoder.layer.1.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.4.output.dense.bias', 'base_model.encoder.layer.11.attention.self.key.weight', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.19.attention.self.key.bias', 'base_model.encoder.layer.1.attention.output.LayerNorm.weight', 'base_model.encoder.layer.13.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.10.output.dense.bias', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.4.intermediate.dense.bias', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.10.attention.self.value.weight', 'base_model.encoder.layer.5.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.11.attention.output.dense.bias', 'base_model.encoder.layer.0.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.16.intermediate.dense.bias', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.4.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.6.intermediate.dense.bias', 'base_model.encoder.layer.17.attention.self.key.weight', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.15.output.LayerNorm.weight', 'base_model.encoder.layer.14.output.LayerNorm.weight', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.9.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.11.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.5.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.17.attention.self.query.bias', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.21.attention.self.query.bias', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.2.output.adapters.es.adapter_up.weight', 'base_model.embeddings.token_type_embeddings.weight', 'base_model.encoder.layer.1.attention.self.value.bias', 'base_model.encoder.layer.6.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.22.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.9.attention.self.key.bias', 'base_model.encoder.layer.3.attention.output.dense.bias', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.1.attention.self.value.weight', 'base_model.encoder.layer.21.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.17.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.11.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.3.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.13.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.3.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.3.attention.output.dense.weight', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.22.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.1.attention.self.query.bias', 'base_model.encoder.layer.6.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.5.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.0.attention.output.dense.weight', 'base_model.encoder.layer.6.attention.self.key.bias', 'base_model.encoder.layer.2.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.13.attention.output.dense.bias', 'base_model.encoder.layer.17.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.18.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.2.output.LayerNorm.weight', 'base_model.encoder.layer.5.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.12.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.0.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.1.attention.output.dense.weight', 'base_model.encoder.layer.1.output.dense.bias', 'base_model.encoder.layer.7.intermediate.dense.bias', 'base_model.encoder.layer.2.attention.self.query.bias', 'base_model.encoder.layer.5.attention.self.value.bias', 'base_model.encoder.layer.14.attention.self.query.bias', 'base_model.encoder.layer.5.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.4.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.6.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.11.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.20.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.4.attention.self.key.weight', 'base_model.encoder.layer.4.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.16.output.dense.bias', 'base_model.encoder.layer.4.output.LayerNorm.bias', 'base_model.encoder.layer.1.attention.self.key.weight', 'base_model.encoder.layer.16.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.14.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.17.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.4.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.9.attention.self.query.bias', 'base_model.encoder.layer.12.output.LayerNorm.bias', 'base_model.encoder.layer.20.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.22.attention.self.value.bias', 'base_model.encoder.layer.10.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.23.intermediate.dense.weight', 'base_model.encoder.layer.4.attention.output.dense.weight', 'base_model.encoder.layer.7.attention.self.query.weight', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.19.attention.self.query.weight', 'base_model.encoder.layer.0.attention.self.value.weight', 'base_model.encoder.layer.18.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.6.intermediate.dense.weight', 'base_model.encoder.layer.23.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.18.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.15.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.8.output.dense.bias', 'base_model.encoder.layer.12.attention.self.value.weight', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.11.attention.self.query.bias', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.17.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.6.attention.output.dense.weight', 'base_model.encoder.layer.17.output.LayerNorm.bias', 'base_model.encoder.layer.7.output.LayerNorm.bias', 'base_model.encoder.layer.1.intermediate.dense.weight', 'base_model.encoder.layer.7.attention.self.value.bias', 'base_model.encoder.layer.0.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.8.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.19.intermediate.dense.bias', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.9.attention.self.value.weight', 'base_model.encoder.layer.9.attention.self.value.bias', 'base_model.encoder.layer.5.attention.self.value.weight', 'base_model.embeddings.position_ids', 'base_model.encoder.layer.21.intermediate.dense.bias', 'base_model.encoder.layer.8.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.0.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.1.output.LayerNorm.weight', 'base_model.encoder.layer.8.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.12.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.13.intermediate.dense.bias', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.16.attention.self.query.weight', 'base_model.encoder.layer.16.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.23.output.dense.bias', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.5.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.23.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.20.attention.self.query.weight', 'base_model.encoder.layer.16.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.12.attention.output.LayerNorm.bias', 'base_model.encoder.layer.13.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.14.attention.self.key.bias', 'base_model.encoder.layer.4.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.6.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.4.intermediate.dense.weight', 'base_model.encoder.layer.19.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.11.output.LayerNorm.weight', 'base_model.encoder.layer.9.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.16.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.3.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.5.output.LayerNorm.weight', 'base_model.encoder.layer.5.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.22.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.13.attention.self.value.bias', 'base_model.encoder.layer.4.output.dense.weight', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.18.output.dense.weight', 'base_model.encoder.layer.10.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.22.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.16.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.2.attention.output.dense.weight', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.23.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.3.output.dense.weight', 'base_model.encoder.layer.13.attention.self.key.bias', 'base_model.encoder.layer.8.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.10.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.16.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.20.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.23.attention.self.key.bias', 'base_model.encoder.layer.2.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.4.attention.output.LayerNorm.weight', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.21.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.18.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.19.intermediate.dense.weight', 'base_model.encoder.layer.22.output.dense.weight', 'base_model.encoder.layer.22.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.22.attention.output.dense.weight', 'base_model.encoder.layer.0.output.dense.bias', 'base_model.encoder.layer.9.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.18.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.23.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.14.attention.output.LayerNorm.weight', 'base_model.encoder.layer.0.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.8.attention.self.value.weight', 'base_model.encoder.layer.9.output.LayerNorm.bias', 'base_model.encoder.layer.8.attention.self.query.weight', 'base_model.encoder.layer.22.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.16.attention.self.value.bias', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.1.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.5.intermediate.dense.weight', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.11.intermediate.dense.bias', 'base_model.encoder.layer.9.attention.output.LayerNorm.weight', 'base_model.encoder.layer.23.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.7.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.23.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.20.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.18.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.23.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.7.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.14.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.15.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.6.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.15.attention.self.query.bias', 'base_model.encoder.layer.16.attention.self.value.weight', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.11.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.13.attention.self.query.bias', 'base_model.encoder.layer.16.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.16.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.10.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.7.output.LayerNorm.weight', 'base_model.encoder.layer.18.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.22.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.7.attention.self.query.bias', 'base_model.encoder.layer.4.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.5.attention.output.dense.bias', 'base_model.encoder.layer.12.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.14.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.11.attention.self.key.bias', 'base_model.encoder.layer.17.output.LayerNorm.weight', 'base_model.encoder.layer.19.output.LayerNorm.bias', 'base_model.encoder.layer.21.output.dense.weight', 'base_model.encoder.layer.2.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.21.output.dense.bias', 'base_model.encoder.layer.12.attention.self.key.weight', 'base_model.encoder.layer.0.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.9.intermediate.dense.bias', 'base_model.encoder.layer.19.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.7.attention.output.dense.weight', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.11.attention.output.dense.weight', 'base_model.encoder.layer.3.attention.self.key.bias', 'base_model.encoder.layer.3.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.4.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.3.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.18.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.0.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.14.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.10.attention.self.query.bias', 'base_model.encoder.layer.12.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.19.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.14.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.18.attention.self.value.weight', 'base_model.encoder.layer.10.attention.self.value.bias', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.20.attention.output.LayerNorm.weight', 'base_model.encoder.layer.6.attention.output.LayerNorm.weight', 'base_model.encoder.layer.14.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.18.attention.output.dense.weight', 'base_model.encoder.layer.19.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.1.attention.self.key.bias', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.19.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.8.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.2.output.LayerNorm.bias', 'base_model.encoder.layer.21.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.22.output.LayerNorm.weight', 'base_model.encoder.layer.8.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.18.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.21.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.11.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.19.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.20.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.5.output.dense.weight', 'base_model.encoder.layer.12.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.23.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.9.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.15.intermediate.dense.bias', 'base_model.encoder.layer.20.attention.self.value.bias', 'base_model.encoder.layer.1.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.12.attention.output.dense.bias', 'base_model.encoder.layer.23.attention.self.query.weight', 'base_model.encoder.layer.12.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.10.attention.self.key.weight', 'base_model.encoder.layer.8.attention.output.dense.bias', 'base_model.encoder.layer.13.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.18.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.20.output.dense.weight', 'base_model.encoder.layer.20.attention.self.value.weight', 'base_model.encoder.layer.15.intermediate.dense.weight', 'base_model.encoder.layer.23.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.9.attention.self.key.weight', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.7.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.10.intermediate.dense.weight', 'base_model.encoder.layer.16.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.22.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.19.attention.output.dense.weight', 'base_model.encoder.layer.21.attention.self.key.bias', 'base_model.encoder.layer.0.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.20.attention.output.dense.bias', 'base_model.encoder.layer.7.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.6.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.6.attention.output.dense.bias', 'base_model.encoder.layer.23.output.LayerNorm.weight', 'base_model.encoder.layer.17.attention.output.dense.weight', 'base_model.encoder.layer.22.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.18.attention.output.LayerNorm.weight', 'base_model.encoder.layer.16.attention.output.dense.bias', 'base_model.encoder.layer.15.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.8.intermediate.dense.weight', 'base_model.encoder.layer.1.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.1.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.12.attention.self.value.bias', 'base_model.encoder.layer.3.intermediate.dense.weight', 'base_model.encoder.layer.7.output.dense.weight', 'base_model.encoder.layer.13.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.16.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.16.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.20.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.8.output.LayerNorm.bias', 'base_model.encoder.layer.16.attention.output.dense.weight', 'base_model.encoder.layer.16.attention.output.LayerNorm.weight', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.5.attention.self.query.bias', 'base_model.encoder.layer.5.attention.output.LayerNorm.bias', 'base_model.encoder.layer.20.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.0.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.11.attention.self.value.bias', 'base_model.encoder.layer.19.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.1.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.3.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.17.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.19.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.18.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.17.attention.output.dense.bias', 'base_model.encoder.layer.10.attention.self.query.weight', 'base_model.encoder.layer.14.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.16.attention.self.key.weight', 'base_model.encoder.layer.5.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.10.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.12.intermediate.dense.bias', 'base_model.encoder.layer.18.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.10.output.dense.weight', 'base_model.encoder.layer.11.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.9.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.12.intermediate.dense.weight', 'base_model.encoder.layer.0.attention.self.query.bias', 'base_model.encoder.layer.12.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.13.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.18.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.7.attention.self.value.weight', 'base_model.encoder.layer.13.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.18.attention.self.query.weight', 'base_model.encoder.layer.4.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.13.attention.self.key.weight', 'base_model.encoder.layer.14.attention.self.query.weight', 'base_model.encoder.layer.1.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.11.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.22.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.7.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.22.attention.self.value.weight', 'base_model.encoder.layer.4.output.LayerNorm.weight', 'base_model.encoder.layer.20.intermediate.dense.weight', 'base_model.encoder.layer.10.attention.self.key.bias', 'base_model.encoder.layer.7.output.dense.bias', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.11.attention.self.query.weight', 'base_model.encoder.layer.0.attention.self.value.bias', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.13.output.dense.bias', 'base_model.encoder.layer.23.intermediate.dense.bias', 'base_model.pooler.dense.weight', 'base_model.encoder.layer.12.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.3.output.LayerNorm.bias', 'base_model.encoder.layer.12.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.23.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.14.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.14.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.17.output.dense.weight', 'base_model.encoder.layer.22.attention.output.LayerNorm.weight', 'base_model.encoder.layer.3.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.2.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.15.attention.self.value.weight', 'base_model.encoder.layer.8.attention.self.value.bias', 'base_model.encoder.layer.11.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.8.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.10.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.23.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.14.intermediate.dense.bias', 'base_model.encoder.layer.7.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.11.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.6.attention.output.LayerNorm.bias', 'base_model.encoder.layer.3.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.15.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.3.attention.output.LayerNorm.weight', 'base_model.encoder.layer.15.attention.self.value.bias', 'base_model.encoder.layer.13.attention.self.query.weight', 'base_model.encoder.layer.10.attention.output.LayerNorm.bias', 'base_model.encoder.layer.15.output.dense.bias', 'base_model.encoder.layer.15.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.12.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.15.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.22.attention.self.key.bias', 'base_model.embeddings.LayerNorm.weight', 'base_model.encoder.layer.23.attention.self.value.bias', 'base_model.encoder.layer.5.intermediate.dense.bias', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.22.attention.output.LayerNorm.bias', 'base_model.encoder.layer.10.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.21.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.20.intermediate.dense.bias', 'base_model.encoder.layer.19.output.dense.bias', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.17.intermediate.dense.weight', 'base_model.encoder.layer.21.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.18.attention.self.query.bias', 'base_model.encoder.layer.21.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.8.attention.self.key.bias', 'base_model.encoder.layer.23.attention.output.dense.bias', 'base_model.encoder.layer.1.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.8.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.7.attention.output.LayerNorm.weight', 'base_model.encoder.layer.11.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.5.attention.self.key.bias', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.10.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.23.output.dense.weight', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.23.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.7.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.13.attention.output.LayerNorm.bias', 'base_model.encoder.layer.14.attention.self.key.weight', 'base_model.encoder.layer.1.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.2.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.9.intermediate.dense.weight', 'base_model.encoder.layer.2.attention.self.query.weight', 'base_model.encoder.layer.2.attention.output.LayerNorm.weight', 'base_model.encoder.layer.2.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.12.output.dense.weight', 'base_model.encoder.layer.13.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.1.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.22.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.3.attention.self.key.weight', 'base_model.encoder.layer.15.attention.output.LayerNorm.weight']
- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of XLMRobertaModel were not initialized from the model checkpoint at /cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//tydiqa/xlm-KG_LR8e-6_EPOCH2.0_maxlen384_batchsize4_gradacc4 and are newly initialized: ['encoder.layer.14.attention.self.key.weight', 'encoder.layer.8.output.dense.weight', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.10.output.LayerNorm.weight', 'encoder.layer.6.attention.self.value.weight', 'encoder.layer.9.output.dense.weight', 'encoder.layer.3.attention.self.value.bias', 'encoder.layer.1.attention.self.value.weight', 'encoder.layer.7.output.LayerNorm.weight', 'encoder.layer.22.output.dense.bias', 'encoder.layer.13.intermediate.dense.weight', 'encoder.layer.20.attention.self.value.bias', 'encoder.layer.2.output.dense.weight', 'encoder.layer.8.output.LayerNorm.bias', 'encoder.layer.10.attention.self.key.weight', 'encoder.layer.2.attention.self.value.bias', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.19.output.LayerNorm.weight', 'encoder.layer.22.intermediate.dense.weight', 'encoder.layer.18.output.dense.weight', 'encoder.layer.1.attention.self.key.bias', 'encoder.layer.4.attention.output.dense.weight', 'encoder.layer.23.attention.output.dense.weight', 'encoder.layer.9.attention.self.value.weight', 'encoder.layer.17.output.dense.weight', 'encoder.layer.18.attention.self.key.bias', 'encoder.layer.12.attention.output.LayerNorm.weight', 'encoder.layer.20.attention.self.value.weight', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.17.output.dense.bias', 'encoder.layer.15.output.LayerNorm.weight', 'encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.21.output.LayerNorm.bias', 'encoder.layer.7.output.dense.weight', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.21.attention.self.key.weight', 'encoder.layer.15.output.dense.weight', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.11.attention.self.key.bias', 'encoder.layer.4.attention.self.query.weight', 'encoder.layer.21.output.dense.weight', 'encoder.layer.11.attention.self.query.bias', 'pooler.dense.weight', 'encoder.layer.11.attention.output.dense.weight', 'encoder.layer.12.intermediate.dense.weight', 'encoder.layer.16.intermediate.dense.weight', 'encoder.layer.13.attention.output.LayerNorm.weight', 'encoder.layer.15.attention.self.value.weight', 'encoder.layer.17.attention.self.value.bias', 'encoder.layer.6.attention.self.query.bias', 'encoder.layer.14.intermediate.dense.bias', 'encoder.layer.6.attention.self.key.bias', 'pooler.dense.bias', 'encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.layer.5.attention.output.dense.weight', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.11.attention.self.query.weight', 'encoder.layer.0.attention.output.dense.weight', 'encoder.layer.11.output.LayerNorm.bias', 'encoder.layer.10.attention.self.value.bias', 'encoder.layer.15.attention.self.query.bias', 'encoder.layer.0.attention.self.value.bias', 'encoder.layer.21.attention.self.value.bias', 'encoder.layer.8.attention.self.query.bias', 'encoder.layer.19.attention.self.key.weight', 'encoder.layer.9.attention.output.LayerNorm.bias', 'encoder.layer.13.output.dense.weight', 'encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.layer.0.attention.self.query.weight', 'embeddings.token_type_embeddings.weight', 'encoder.layer.12.attention.self.value.weight', 'encoder.layer.4.output.dense.bias', 'encoder.layer.10.output.dense.weight', 'encoder.layer.16.attention.output.dense.bias', 'encoder.layer.18.attention.self.value.weight', 'encoder.layer.17.attention.self.value.weight', 'encoder.layer.10.attention.self.key.bias', 'encoder.layer.20.attention.output.LayerNorm.weight', 'encoder.layer.19.attention.output.LayerNorm.bias', 'encoder.layer.7.attention.self.value.bias', 'encoder.layer.12.attention.self.query.bias', 'encoder.layer.8.output.dense.bias', 'encoder.layer.7.attention.self.query.bias', 'encoder.layer.20.output.LayerNorm.bias', 'encoder.layer.5.attention.self.query.bias', 'encoder.layer.19.attention.self.value.weight', 'encoder.layer.5.attention.self.query.weight', 'encoder.layer.20.attention.output.dense.bias', 'encoder.layer.11.output.dense.bias', 'encoder.layer.8.attention.self.key.bias', 'encoder.layer.10.attention.self.value.weight', 'encoder.layer.19.attention.output.LayerNorm.weight', 'encoder.layer.16.output.LayerNorm.weight', 'encoder.layer.23.output.LayerNorm.weight', 'encoder.layer.21.attention.output.dense.weight', 'encoder.layer.18.attention.output.dense.weight', 'encoder.layer.18.attention.self.value.bias', 'encoder.layer.16.attention.self.query.bias', 'encoder.layer.21.intermediate.dense.weight', 'encoder.layer.19.attention.self.query.bias', 'encoder.layer.2.attention.self.query.weight', 'encoder.layer.5.output.dense.weight', 'encoder.layer.10.attention.output.LayerNorm.bias', 'encoder.layer.21.attention.self.key.bias', 'encoder.layer.1.attention.self.key.weight', 'encoder.layer.7.attention.self.key.bias', 'encoder.layer.19.output.LayerNorm.bias', 'encoder.layer.9.attention.self.key.weight', 'encoder.layer.14.attention.self.key.bias', 'encoder.layer.13.attention.self.key.bias', 'encoder.layer.7.attention.output.dense.bias', 'encoder.layer.8.attention.self.value.bias', 'encoder.layer.20.attention.self.query.weight', 'encoder.layer.16.attention.self.value.bias', 'encoder.layer.22.attention.self.value.weight', 'encoder.layer.18.output.LayerNorm.weight', 'encoder.layer.12.output.dense.weight', 'encoder.layer.5.output.dense.bias', 'encoder.layer.3.attention.self.value.weight', 'encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.layer.0.attention.output.dense.bias', 'encoder.layer.3.output.dense.bias', 'encoder.layer.2.attention.self.query.bias', 'encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.layer.22.output.LayerNorm.weight', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.11.attention.self.value.bias', 'encoder.layer.2.attention.output.dense.bias', 'encoder.layer.21.attention.output.dense.bias', 'encoder.layer.23.attention.self.query.weight', 'encoder.layer.15.attention.self.key.bias', 'encoder.layer.14.attention.self.query.bias', 'encoder.layer.23.intermediate.dense.weight', 'encoder.layer.23.attention.output.LayerNorm.bias', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.8.output.LayerNorm.weight', 'encoder.layer.22.attention.self.key.weight', 'encoder.layer.3.attention.output.dense.weight', 'encoder.layer.6.attention.output.LayerNorm.bias', 'encoder.layer.12.attention.output.dense.weight', 'encoder.layer.16.attention.self.query.weight', 'encoder.layer.7.output.LayerNorm.bias', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.20.attention.self.key.bias', 'encoder.layer.22.attention.self.value.bias', 'encoder.layer.14.output.LayerNorm.weight', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.2.attention.output.LayerNorm.weight', 'encoder.layer.10.attention.output.dense.weight', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.21.attention.self.query.weight', 'encoder.layer.17.intermediate.dense.weight', 'encoder.layer.9.attention.self.value.bias', 'encoder.layer.5.attention.self.value.weight', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.14.attention.self.value.bias', 'encoder.layer.15.intermediate.dense.weight', 'encoder.layer.18.intermediate.dense.bias', 'encoder.layer.18.attention.output.dense.bias', 'encoder.layer.17.output.LayerNorm.weight', 'encoder.layer.14.attention.output.dense.weight', 'encoder.layer.12.attention.self.value.bias', 'encoder.layer.22.attention.output.LayerNorm.weight', 'encoder.layer.10.attention.self.query.weight', 'encoder.layer.23.attention.self.key.weight', 'encoder.layer.17.attention.output.LayerNorm.weight', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.21.output.dense.bias', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.23.attention.self.query.bias', 'encoder.layer.6.output.dense.bias', 'encoder.layer.19.intermediate.dense.bias', 'encoder.layer.14.attention.output.LayerNorm.weight', 'embeddings.LayerNorm.bias', 'encoder.layer.2.attention.output.dense.weight', 'encoder.layer.8.attention.output.dense.bias', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.23.attention.self.value.bias', 'encoder.layer.8.attention.self.key.weight', 'encoder.layer.17.intermediate.dense.bias', 'encoder.layer.16.attention.self.key.weight', 'encoder.layer.22.attention.output.dense.bias', 'encoder.layer.7.attention.output.LayerNorm.bias', 'encoder.layer.10.intermediate.dense.weight', 'encoder.layer.22.attention.self.query.weight', 'encoder.layer.7.output.dense.bias', 'encoder.layer.10.attention.output.dense.bias', 'encoder.layer.9.output.dense.bias', 'encoder.layer.20.output.dense.weight', 'encoder.layer.10.attention.output.LayerNorm.weight', 'encoder.layer.16.output.dense.weight', 'encoder.layer.5.output.LayerNorm.bias', 'encoder.layer.12.attention.output.dense.bias', 'encoder.layer.19.output.dense.weight', 'encoder.layer.10.attention.self.query.bias', 'encoder.layer.7.attention.self.key.weight', 'encoder.layer.15.attention.output.dense.bias', 'encoder.layer.17.attention.output.LayerNorm.bias', 'encoder.layer.13.attention.self.key.weight', 'encoder.layer.9.attention.output.dense.bias', 'embeddings.position_embeddings.weight', 'encoder.layer.1.attention.output.LayerNorm.weight', 'encoder.layer.20.attention.output.dense.weight', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.15.output.LayerNorm.bias', 'encoder.layer.15.attention.output.dense.weight', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.0.attention.output.LayerNorm.weight', 'encoder.layer.6.attention.self.query.weight', 'encoder.layer.13.attention.self.query.bias', 'encoder.layer.18.attention.self.query.weight', 'encoder.layer.23.attention.self.key.bias', 'encoder.layer.17.attention.self.key.bias', 'encoder.layer.6.attention.output.dense.bias', 'encoder.layer.14.attention.self.query.weight', 'encoder.layer.13.attention.self.value.weight', 'encoder.layer.7.intermediate.dense.bias', 'encoder.layer.1.attention.output.dense.weight', 'encoder.layer.18.output.dense.bias', 'encoder.layer.15.attention.self.key.weight', 'encoder.layer.17.attention.self.key.weight', 'encoder.layer.0.output.dense.weight', 'encoder.layer.12.output.LayerNorm.bias', 'encoder.layer.15.intermediate.dense.bias', 'encoder.layer.4.attention.output.LayerNorm.weight', 'encoder.layer.21.attention.output.LayerNorm.weight', 'encoder.layer.9.attention.output.dense.weight', 'encoder.layer.20.attention.output.LayerNorm.bias', 'encoder.layer.9.attention.self.key.bias', 'encoder.layer.8.attention.self.query.weight', 'encoder.layer.12.attention.self.key.weight', 'encoder.layer.13.attention.output.LayerNorm.bias', 'encoder.layer.1.output.dense.weight', 'encoder.layer.23.output.dense.weight', 'encoder.layer.13.output.dense.bias', 'encoder.layer.19.attention.self.value.bias', 'encoder.layer.16.output.dense.bias', 'encoder.layer.23.intermediate.dense.bias', 'encoder.layer.16.output.LayerNorm.bias', 'encoder.layer.21.attention.self.query.bias', 'encoder.layer.11.attention.self.value.weight', 'encoder.layer.14.attention.self.value.weight', 'encoder.layer.21.intermediate.dense.bias', 'encoder.layer.20.attention.self.query.bias', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.9.attention.self.query.bias', 'encoder.layer.6.attention.self.key.weight', 'encoder.layer.3.output.dense.weight', 'encoder.layer.16.attention.output.LayerNorm.weight', 'encoder.layer.1.attention.output.dense.bias', 'encoder.layer.10.output.dense.bias', 'encoder.layer.5.attention.output.dense.bias', 'encoder.layer.18.output.LayerNorm.bias', 'encoder.layer.19.intermediate.dense.weight', 'encoder.layer.1.output.dense.bias', 'encoder.layer.11.output.LayerNorm.weight', 'encoder.layer.4.attention.self.value.bias', 'encoder.layer.4.output.dense.weight', 'encoder.layer.18.attention.self.key.weight', 'encoder.layer.5.attention.self.value.bias', 'encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.layer.6.attention.self.value.bias', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.9.attention.self.query.weight', 'encoder.layer.3.attention.self.query.bias', 'encoder.layer.11.output.dense.weight', 'encoder.layer.23.output.LayerNorm.bias', 'encoder.layer.6.attention.output.LayerNorm.weight', 'encoder.layer.14.output.LayerNorm.bias', 'encoder.layer.23.attention.output.dense.bias', 'encoder.layer.17.attention.output.dense.bias', 'encoder.layer.17.attention.self.query.bias', 'encoder.layer.2.output.dense.bias', 'encoder.layer.13.attention.self.query.weight', 'encoder.layer.12.intermediate.dense.bias', 'encoder.layer.21.output.LayerNorm.weight', 'encoder.layer.1.attention.self.value.bias', 'encoder.layer.16.intermediate.dense.bias', 'embeddings.word_embeddings.weight', 'encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.layer.15.attention.output.LayerNorm.weight', 'encoder.layer.4.attention.self.key.weight', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.15.attention.output.LayerNorm.bias', 'encoder.layer.23.output.dense.bias', 'encoder.layer.20.intermediate.dense.bias', 'encoder.layer.4.attention.output.LayerNorm.bias', 'encoder.layer.4.attention.self.value.weight', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.18.attention.output.LayerNorm.weight', 'encoder.layer.2.attention.self.key.weight', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.0.attention.self.value.weight', 'encoder.layer.19.attention.output.dense.weight', 'embeddings.LayerNorm.weight', 'encoder.layer.22.intermediate.dense.bias', 'encoder.layer.17.output.LayerNorm.bias', 'encoder.layer.20.intermediate.dense.weight', 'encoder.layer.8.attention.output.LayerNorm.bias', 'encoder.layer.22.output.LayerNorm.bias', 'encoder.layer.14.attention.output.LayerNorm.bias', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.11.attention.self.key.weight', 'encoder.layer.14.attention.output.dense.bias', 'encoder.layer.19.attention.self.query.weight', 'encoder.layer.0.output.dense.bias', 'encoder.layer.21.attention.self.value.weight', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.7.attention.self.value.weight', 'encoder.layer.4.attention.self.query.bias', 'encoder.layer.18.intermediate.dense.weight', 'encoder.layer.0.attention.self.key.bias', 'encoder.layer.3.attention.self.key.weight', 'encoder.layer.22.attention.self.key.bias', 'encoder.layer.12.attention.self.query.weight', 'encoder.layer.5.attention.self.key.weight', 'encoder.layer.13.output.LayerNorm.bias', 'encoder.layer.13.attention.output.dense.weight', 'encoder.layer.10.output.LayerNorm.bias', 'encoder.layer.15.attention.self.query.weight', 'encoder.layer.12.attention.self.key.bias', 'encoder.layer.7.attention.self.query.weight', 'encoder.layer.12.output.LayerNorm.weight', 'encoder.layer.14.intermediate.dense.weight', 'encoder.layer.16.attention.output.dense.weight', 'encoder.layer.18.attention.output.LayerNorm.bias', 'encoder.layer.16.attention.self.key.bias', 'encoder.layer.13.intermediate.dense.bias', 'encoder.layer.1.attention.self.query.bias', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.3.attention.self.query.weight', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.18.attention.self.query.bias', 'encoder.layer.22.attention.self.query.bias', 'encoder.layer.11.attention.output.dense.bias', 'encoder.layer.3.attention.self.key.bias', 'encoder.layer.3.attention.output.dense.bias', 'encoder.layer.7.attention.output.dense.weight', 'encoder.layer.11.attention.output.LayerNorm.weight', 'encoder.layer.22.attention.output.LayerNorm.bias', 'encoder.layer.13.attention.output.dense.bias', 'encoder.layer.13.output.LayerNorm.weight', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.13.attention.self.value.bias', 'encoder.layer.4.attention.output.dense.bias', 'encoder.layer.5.attention.self.key.bias', 'encoder.layer.9.output.LayerNorm.bias', 'encoder.layer.22.attention.output.dense.weight', 'encoder.layer.23.attention.self.value.weight', 'encoder.layer.2.attention.self.value.weight', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.17.attention.self.query.weight', 'encoder.layer.12.attention.output.LayerNorm.bias', 'encoder.layer.2.attention.output.LayerNorm.bias', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.17.attention.output.dense.weight', 'encoder.layer.6.output.dense.weight', 'encoder.layer.9.attention.output.LayerNorm.weight', 'encoder.layer.8.attention.output.LayerNorm.weight', 'encoder.layer.21.attention.output.LayerNorm.bias', 'encoder.layer.19.attention.output.dense.bias', 'encoder.layer.20.output.dense.bias', 'encoder.layer.19.attention.self.key.bias', 'encoder.layer.9.output.LayerNorm.weight', 'encoder.layer.1.attention.self.query.weight', 'encoder.layer.19.output.dense.bias', 'encoder.layer.14.output.dense.weight', 'encoder.layer.20.output.LayerNorm.weight', 'encoder.layer.14.output.dense.bias', 'encoder.layer.8.attention.output.dense.weight', 'encoder.layer.0.attention.self.query.bias', 'encoder.layer.5.attention.output.LayerNorm.weight', 'encoder.layer.16.attention.output.LayerNorm.bias', 'encoder.layer.4.attention.self.key.bias', 'encoder.layer.20.attention.self.key.weight', 'encoder.layer.15.attention.self.value.bias', 'encoder.layer.12.output.dense.bias', 'encoder.layer.0.attention.self.key.weight', 'encoder.layer.2.attention.self.key.bias', 'encoder.layer.23.attention.output.LayerNorm.weight', 'encoder.layer.16.attention.self.value.weight', 'encoder.layer.8.attention.self.value.weight', 'encoder.layer.6.output.LayerNorm.bias', 'encoder.layer.22.output.dense.weight', 'encoder.layer.7.attention.output.LayerNorm.weight', 'encoder.layer.15.output.dense.bias', 'encoder.layer.6.attention.output.dense.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Overwriting existing adapter 'ep'.
Overwriting existing adapter 'tp'.
Overwriting existing adapter 'es'.
Overwriting existing adapter 'ts'.
Overwriting existing adapter fusion module 'ep,tp,es,ts'
05/09/2022 22:52:41 - INFO - __main__ -   Creating features from dataset file at .
/cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//tydiqa/xlm-KG_LR8e-6_EPOCH2.0_maxlen384_batchsize4_gradacc4
XLMConfig {
  "architectures": [
    "XLMRobertaForMaskedLM"
  ],
  "asm": false,
  "attention_dropout": 0.1,
  "attention_probs_dropout_prob": 0.1,
  "bos_index": 0,
  "bos_token_id": 0,
  "causal": false,
  "dropout": 0.1,
  "emb_dim": 1024,
  "embed_init_std": 0.02209708691207961,
  "end_n_top": 5,
  "eos_index": 1,
  "eos_token_id": 2,
  "gelu_activation": true,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "init_std": 0.02,
  "initializer_range": 0.02,
  "intermediate_size": 4096,
  "is_encoder": true,
  "lang_id": 0,
  "layer_norm_eps": 1e-05,
  "mask_index": 5,
  "mask_token_id": 0,
  "max_position_embeddings": 514,
  "model_type": "xlm",
  "n_heads": 16,
  "n_langs": 1,
  "n_layers": 24,
  "output_past": true,
  "pad_index": 2,
  "pad_token_id": 1,
  "sinusoidal_embeddings": false,
  "start_n_top": 5,
  "summary_activation": null,
  "summary_first_dropout": 0.1,
  "summary_proj_to_labels": true,
  "summary_type": "first",
  "summary_use_proj": true,
  "transformers_version": "4.17.0",
  "type_vocab_size": 1,
  "unk_index": 3,
  "use_lang_emb": false,
  "vocab_size": 250002
}

  0%|          | 0/113 [00:00<?, ?it/s]100%|██████████| 113/113 [00:00<00:00, 2590.66it/s]
convert squad examples to features:   0%|          | 0/113 [00:00<?, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.
convert squad examples to features:   1%|          | 1/113 [00:00<00:16,  6.81it/s]convert squad examples to features:  29%|██▉       | 33/113 [00:00<00:00, 126.37it/s]convert squad examples to features:  58%|█████▊    | 65/113 [00:00<00:00, 168.22it/s]convert squad examples to features: 100%|██████████| 113/113 [00:00<00:00, 213.82it/s]/cluster/project/sachan/yifan/softwares/anaconda/anaconda3/envs/xfactr/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2272: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

add example index and unique id:   0%|          | 0/113 [00:00<?, ?it/s]add example index and unique id: 100%|██████████| 113/113 [00:00<00:00, 420174.07it/s]
05/09/2022 22:52:42 - INFO - __main__ -   Saving features into cached file ./cached_tydiqa.goldp.bn.dev.json_xlm-KG_LR8e-6_EPOCH2.0_maxlen384_batchsize4_gradacc4_384_bn
05/09/2022 22:52:42 - INFO - __main__ -   ***** Running evaluation  *****
05/09/2022 22:52:42 - INFO - __main__ -     Num examples = 133
05/09/2022 22:52:42 - INFO - __main__ -     Batch size = 8
Evaluating:   0%|          | 0/17 [00:00<?, ?it/s]Evaluating:   6%|▌         | 1/17 [00:00<00:14,  1.10it/s]Evaluating:  12%|█▏        | 2/17 [00:01<00:08,  1.71it/s]Evaluating:  18%|█▊        | 3/17 [00:01<00:06,  2.08it/s]Evaluating:  24%|██▎       | 4/17 [00:01<00:05,  2.32it/s]Evaluating:  29%|██▉       | 5/17 [00:02<00:04,  2.47it/s]Evaluating:  35%|███▌      | 6/17 [00:02<00:04,  2.58it/s]Evaluating:  41%|████      | 7/17 [00:03<00:03,  2.64it/s]Evaluating:  47%|████▋     | 8/17 [00:03<00:03,  2.69it/s]Evaluating:  53%|█████▎    | 9/17 [00:03<00:02,  2.72it/s]Evaluating:  59%|█████▉    | 10/17 [00:04<00:02,  2.75it/s]Evaluating:  65%|██████▍   | 11/17 [00:04<00:02,  2.76it/s]Evaluating:  71%|███████   | 12/17 [00:04<00:01,  2.76it/s]Evaluating:  76%|███████▋  | 13/17 [00:05<00:01,  2.77it/s]Evaluating:  82%|████████▏ | 14/17 [00:05<00:01,  2.77it/s]Evaluating:  88%|████████▊ | 15/17 [00:05<00:00,  2.78it/s]Evaluating:  94%|█████████▍| 16/17 [00:06<00:00,  2.78it/s]Evaluating: 100%|██████████| 17/17 [00:06<00:00,  3.10it/s]Evaluating: 100%|██████████| 17/17 [00:06<00:00,  2.61it/s]
05/09/2022 22:52:49 - INFO - __main__ -     Evaluation done in total 6.512987 secs (0.048970 sec per example)
05/09/2022 22:52:49 - INFO - __main__ -   Results: {'exact': 65.48672566371681, 'f1': 79.15788734372805, 'total': 113, 'HasAns_exact': 65.48672566371681, 'HasAns_f1': 79.15788734372805, 'HasAns_total': 113, 'best_exact': 65.48672566371681, 'best_exact_thresh': 0.0, 'best_f1': 79.15788734372805, 'best_f1_thresh': 0.0}
  fi 
2022-05-09 22:52:52.894827: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0
05/09/2022 22:52:56 - WARNING - __main__ -   Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, 16-bits training: False
You are using a model of type xlm-roberta to instantiate a model of type xlm. This is not supported for all configurations of models and can yield errors.
Some weights of the model checkpoint at /cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//tydiqa/xlm-KG_LR8e-6_EPOCH2.0_maxlen384_batchsize4_gradacc4 were not used when initializing XLMRobertaModel: ['base_model.encoder.layer.1.intermediate.dense.bias', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.embeddings.token_type_embeddings.weight', 'base_model.encoder.layer.14.attention.output.dense.bias', 'base_model.encoder.layer.20.attention.output.LayerNorm.bias', 'base_model.encoder.layer.16.attention.self.value.bias', 'base_model.encoder.layer.18.attention.self.value.weight', 'base_model.encoder.layer.15.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.20.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.19.attention.self.query.bias', 'base_model.encoder.layer.6.attention.output.LayerNorm.weight', 'base_model.encoder.layer.22.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.18.output.LayerNorm.bias', 'base_model.encoder.layer.21.attention.output.dense.bias', 'base_model.encoder.layer.4.attention.self.query.weight', 'base_model.encoder.layer.17.attention.output.dense.bias', 'base_model.encoder.layer.0.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.5.output.dense.weight', 'base_model.encoder.layer.2.attention.output.LayerNorm.weight', 'base_model.encoder.layer.8.output.dense.bias', 'base_model.encoder.layer.14.attention.output.LayerNorm.bias', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.18.attention.self.key.weight', 'base_model.encoder.layer.21.attention.output.LayerNorm.bias', 'base_model.encoder.layer.6.attention.self.key.weight', 'base_model.encoder.layer.12.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.5.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.2.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.5.attention.self.query.weight', 'base_model.encoder.layer.14.output.LayerNorm.bias', 'base_model.encoder.layer.10.attention.output.dense.bias', 'base_model.encoder.layer.4.attention.self.value.bias', 'base_model.encoder.layer.2.attention.self.key.bias', 'base_model.encoder.layer.11.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.6.attention.self.query.weight', 'base_model.encoder.layer.15.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.17.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.16.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.19.output.dense.weight', 'base_model.encoder.layer.2.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.22.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.11.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.19.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.20.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.10.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.13.attention.self.key.weight', 'base_model.encoder.layer.9.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.8.output.dense.weight', 'base_model.encoder.layer.5.intermediate.dense.weight', 'base_model.encoder.layer.0.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.12.attention.self.value.weight', 'base_model.encoder.layer.5.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.7.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.1.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.21.attention.self.key.weight', 'base_model.encoder.layer.20.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.0.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.2.output.LayerNorm.bias', 'base_model.encoder.layer.22.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.12.attention.self.key.bias', 'base_model.encoder.layer.11.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.16.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.23.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.0.attention.output.LayerNorm.bias', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.7.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.20.attention.output.dense.weight', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.3.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.17.attention.self.key.weight', 'base_model.encoder.layer.7.output.dense.bias', 'base_model.encoder.layer.13.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.19.attention.self.value.bias', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.23.attention.output.LayerNorm.weight', 'base_model.encoder.layer.20.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.13.attention.self.value.weight', 'base_model.encoder.layer.15.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.1.attention.output.LayerNorm.weight', 'base_model.encoder.layer.6.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.17.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.1.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.9.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.15.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.11.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.17.intermediate.dense.weight', 'base_model.encoder.layer.22.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.3.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.0.attention.output.dense.bias', 'base_model.encoder.layer.10.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.11.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.14.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.6.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.20.attention.self.key.weight', 'base_model.encoder.layer.23.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.11.attention.output.dense.weight', 'base_model.encoder.layer.2.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.16.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.17.output.dense.weight', 'base_model.encoder.layer.5.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.11.output.LayerNorm.weight', 'base_model.encoder.layer.3.output.LayerNorm.weight', 'base_model.encoder.layer.1.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.14.intermediate.dense.weight', 'base_model.encoder.layer.4.attention.output.LayerNorm.bias', 'base_model.encoder.layer.22.attention.self.value.weight', 'base_model.encoder.layer.13.attention.self.value.bias', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.21.intermediate.dense.bias', 'base_model.encoder.layer.12.attention.self.value.bias', 'base_model.encoder.layer.19.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.5.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.1.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.3.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.6.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.14.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.15.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.16.output.LayerNorm.bias', 'base_model.encoder.layer.19.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.1.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.8.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.20.output.dense.weight', 'base_model.encoder.layer.12.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.9.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.12.attention.self.key.weight', 'base_model.encoder.layer.17.attention.self.key.bias', 'base_model.encoder.layer.20.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.18.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.8.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.9.attention.self.value.weight', 'base_model.encoder.layer.12.attention.self.query.bias', 'base_model.encoder.layer.13.attention.output.LayerNorm.bias', 'base_model.encoder.layer.22.intermediate.dense.bias', 'base_model.encoder.layer.12.intermediate.dense.weight', 'base_model.encoder.layer.19.intermediate.dense.weight', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.0.attention.self.query.bias', 'base_model.encoder.layer.10.attention.self.key.bias', 'base_model.encoder.layer.1.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.8.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.10.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.12.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.18.attention.self.query.bias', 'base_model.encoder.layer.10.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.22.output.LayerNorm.bias', 'base_model.encoder.layer.9.attention.self.query.bias', 'base_model.encoder.layer.21.attention.self.query.bias', 'base_model.encoder.layer.1.output.LayerNorm.bias', 'base_model.encoder.layer.4.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.14.attention.output.dense.weight', 'base_model.encoder.layer.13.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.11.intermediate.dense.weight', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.22.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.23.attention.self.query.bias', 'base_model.encoder.layer.11.output.dense.weight', 'base_model.encoder.layer.7.attention.self.query.bias', 'base_model.encoder.layer.18.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.7.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.8.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.7.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.19.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.21.attention.output.dense.weight', 'base_model.encoder.layer.20.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.16.attention.output.LayerNorm.bias', 'base_model.encoder.layer.21.output.adapters.ts.adapter_up.weight', 'qa_outputs.bias', 'base_model.encoder.layer.8.attention.self.query.weight', 'base_model.encoder.layer.5.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.10.attention.output.LayerNorm.bias', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.1.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.7.output.dense.weight', 'base_model.encoder.layer.9.output.LayerNorm.weight', 'base_model.encoder.layer.6.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.8.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.11.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.6.attention.output.dense.bias', 'base_model.encoder.layer.18.attention.output.LayerNorm.bias', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.9.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.21.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.6.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.21.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.13.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.21.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.17.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.13.output.dense.bias', 'base_model.encoder.layer.14.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.12.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.11.attention.self.value.weight', 'base_model.encoder.layer.15.intermediate.dense.weight', 'base_model.encoder.layer.7.attention.output.LayerNorm.bias', 'base_model.encoder.layer.18.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.7.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.3.attention.output.dense.bias', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.3.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.2.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.16.attention.self.key.weight', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.22.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.23.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.15.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.8.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.12.intermediate.dense.bias', 'base_model.encoder.layer.7.attention.output.dense.weight', 'base_model.encoder.layer.11.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.6.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.21.attention.self.key.bias', 'base_model.encoder.layer.1.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.8.attention.output.dense.bias', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.22.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.3.attention.self.query.weight', 'base_model.encoder.layer.15.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.5.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.6.intermediate.dense.bias', 'base_model.encoder.layer.8.attention.output.dense.weight', 'base_model.encoder.layer.16.output.LayerNorm.weight', 'base_model.encoder.layer.17.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.16.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.21.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.13.attention.self.query.bias', 'base_model.encoder.layer.7.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.0.output.dense.weight', 'base_model.encoder.layer.7.attention.self.value.bias', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.1.attention.self.query.bias', 'base_model.encoder.layer.2.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.14.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.2.attention.self.value.bias', 'base_model.encoder.layer.1.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.2.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.17.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.15.attention.output.LayerNorm.bias', 'base_model.encoder.layer.22.attention.output.dense.weight', 'base_model.encoder.layer.11.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.7.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.16.attention.self.key.bias', 'base_model.encoder.layer.20.intermediate.dense.bias', 'base_model.encoder.layer.9.output.dense.weight', 'base_model.embeddings.position_ids', 'base_model.encoder.layer.0.attention.self.key.bias', 'base_model.encoder.layer.0.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.11.output.dense.bias', 'base_model.encoder.layer.16.attention.self.query.weight', 'base_model.encoder.layer.3.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.15.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.1.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.10.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.20.attention.self.query.weight', 'base_model.encoder.layer.23.output.dense.weight', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.10.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.14.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.4.intermediate.dense.weight', 'base_model.encoder.layer.10.output.LayerNorm.weight', 'base_model.encoder.layer.6.attention.output.LayerNorm.bias', 'base_model.encoder.layer.1.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.20.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.22.attention.self.key.weight', 'base_model.encoder.layer.15.output.LayerNorm.weight', 'base_model.encoder.layer.9.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.15.output.dense.bias', 'base_model.encoder.layer.14.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.17.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.5.attention.self.key.weight', 'base_model.encoder.layer.8.attention.output.LayerNorm.weight', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.14.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.12.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.4.attention.output.LayerNorm.weight', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.3.output.dense.weight', 'base_model.encoder.layer.21.attention.output.LayerNorm.weight', 'base_model.encoder.layer.9.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.2.intermediate.dense.weight', 'base_model.encoder.layer.7.attention.self.value.weight', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.16.intermediate.dense.weight', 'base_model.encoder.layer.21.output.dense.weight', 'base_model.encoder.layer.5.attention.output.dense.bias', 'base_model.encoder.layer.13.intermediate.dense.bias', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.4.attention.self.value.weight', 'base_model.encoder.layer.23.attention.self.query.weight', 'base_model.encoder.layer.5.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.12.attention.output.dense.weight', 'base_model.encoder.layer.0.output.LayerNorm.bias', 'base_model.encoder.layer.3.intermediate.dense.weight', 'base_model.encoder.layer.9.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.19.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.8.intermediate.dense.weight', 'base_model.encoder.layer.2.attention.output.dense.bias', 'base_model.encoder.layer.6.attention.self.value.bias', 'base_model.encoder.layer.3.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.9.attention.self.key.weight', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.5.attention.output.LayerNorm.bias', 'base_model.encoder.layer.16.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.23.output.LayerNorm.bias', 'base_model.encoder.layer.9.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.14.attention.self.value.weight', 'base_model.encoder.layer.10.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.17.attention.output.dense.weight', 'base_model.encoder.layer.20.output.LayerNorm.bias', 'base_model.encoder.layer.5.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.4.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.6.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.14.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.22.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.14.output.LayerNorm.weight', 'base_model.encoder.layer.15.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.0.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.13.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.18.intermediate.dense.bias', 'base_model.encoder.layer.3.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.23.attention.self.key.weight', 'base_model.encoder.layer.17.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.11.attention.self.key.bias', 'base_model.encoder.layer.13.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.8.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.9.attention.self.key.bias', 'base_model.encoder.layer.1.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.4.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.20.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.12.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.0.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.14.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.5.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.19.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.15.attention.self.key.bias', 'base_model.encoder.layer.23.attention.self.value.bias', 'base_model.encoder.layer.7.attention.output.LayerNorm.weight', 'base_model.encoder.layer.22.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.1.attention.output.dense.weight', 'base_model.encoder.layer.16.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.18.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.13.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.11.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.2.attention.self.query.weight', 'base_model.encoder.layer.9.output.dense.bias', 'base_model.encoder.layer.13.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.9.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.20.intermediate.dense.weight', 'base_model.encoder.layer.23.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.0.output.dense.bias', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.4.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.22.output.dense.bias', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.17.output.dense.bias', 'qa_outputs.weight', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.14.intermediate.dense.bias', 'base_model.encoder.layer.1.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.15.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.23.output.LayerNorm.weight', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.0.intermediate.dense.weight', 'base_model.encoder.layer.13.output.LayerNorm.bias', 'base_model.encoder.layer.16.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.8.output.adapters.tp.adapter_up.weight', 'base_model.embeddings.LayerNorm.weight', 'base_model.encoder.layer.15.attention.self.value.weight', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.17.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.22.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.12.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.11.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.7.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.1.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.3.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.7.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.13.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.21.intermediate.dense.weight', 'base_model.encoder.layer.20.attention.self.value.bias', 'base_model.encoder.layer.2.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.11.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.12.attention.output.LayerNorm.bias', 'base_model.encoder.layer.22.attention.self.query.bias', 'base_model.encoder.layer.20.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.2.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.22.attention.self.query.weight', 'base_model.encoder.layer.2.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.8.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.9.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.4.output.dense.bias', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.23.attention.output.dense.weight', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.14.attention.self.value.bias', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.13.intermediate.dense.weight', 'base_model.encoder.layer.10.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.20.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.14.output.dense.weight', 'base_model.encoder.layer.21.attention.self.query.weight', 'base_model.encoder.layer.17.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.21.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.16.intermediate.dense.bias', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.8.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.1.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.13.attention.output.LayerNorm.weight', 'base_model.encoder.layer.14.attention.self.key.weight', 'base_model.encoder.layer.17.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.22.attention.output.dense.bias', 'base_model.encoder.layer.22.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.23.intermediate.dense.weight', 'base_model.encoder.layer.5.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.12.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.11.output.adapters.tp.adapter_up.weight', 'base_model.pooler.dense.bias', 'base_model.encoder.layer.7.intermediate.dense.weight', 'base_model.encoder.layer.2.attention.output.dense.weight', 'base_model.encoder.layer.5.attention.self.query.bias', 'base_model.encoder.layer.22.intermediate.dense.weight', 'base_model.encoder.layer.13.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.16.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.19.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.17.attention.self.query.weight', 'base_model.encoder.layer.1.output.LayerNorm.weight', 'base_model.encoder.layer.17.output.LayerNorm.bias', 'base_model.encoder.layer.22.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.3.attention.self.value.bias', 'base_model.encoder.layer.11.attention.output.dense.bias', 'base_model.encoder.layer.3.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.15.attention.output.LayerNorm.weight', 'base_model.encoder.layer.17.intermediate.dense.bias', 'base_model.encoder.layer.19.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.3.attention.output.dense.weight', 'base_model.encoder.layer.2.attention.self.query.bias', 'base_model.encoder.layer.2.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.6.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.18.output.LayerNorm.weight', 'base_model.encoder.layer.12.attention.output.dense.bias', 'base_model.encoder.layer.21.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.5.output.LayerNorm.bias', 'base_model.encoder.layer.10.intermediate.dense.bias', 'base_model.encoder.layer.11.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.3.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.12.attention.output.LayerNorm.weight', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.4.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.19.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.14.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.9.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.15.output.dense.weight', 'base_model.encoder.layer.6.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.18.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.23.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.20.attention.output.dense.bias', 'base_model.encoder.layer.3.output.dense.bias', 'base_model.encoder.layer.6.attention.self.query.bias', 'base_model.encoder.layer.12.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.8.intermediate.dense.bias', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.5.intermediate.dense.bias', 'base_model.encoder.layer.19.attention.self.query.weight', 'base_model.encoder.layer.18.output.dense.weight', 'base_model.encoder.layer.6.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.15.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.1.attention.self.key.bias', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.4.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.17.attention.self.query.bias', 'base_model.encoder.layer.9.attention.output.dense.weight', 'base_model.encoder.layer.4.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.16.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.0.attention.output.LayerNorm.weight', 'base_model.encoder.layer.0.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.0.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.6.intermediate.dense.weight', 'base_model.encoder.layer.0.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.7.output.LayerNorm.bias', 'base_model.encoder.layer.11.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.8.output.LayerNorm.weight', 'base_model.encoder.layer.13.output.dense.weight', 'base_model.encoder.layer.14.attention.output.LayerNorm.weight', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.4.attention.self.key.bias', 'base_model.encoder.layer.0.attention.self.value.weight', 'base_model.encoder.layer.10.output.dense.weight', 'base_model.encoder.layer.2.output.dense.bias', 'base_model.encoder.layer.22.output.LayerNorm.weight', 'base_model.encoder.layer.6.output.LayerNorm.weight', 'base_model.encoder.layer.9.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.19.attention.output.LayerNorm.weight', 'base_model.encoder.layer.9.intermediate.dense.weight', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.3.attention.self.key.bias', 'base_model.encoder.layer.11.attention.self.key.weight', 'base_model.encoder.layer.5.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.15.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.18.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.12.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.16.attention.self.value.weight', 'base_model.encoder.layer.18.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.1.output.dense.weight', 'base_model.encoder.layer.10.attention.self.key.weight', 'base_model.encoder.layer.3.attention.output.LayerNorm.weight', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.18.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.7.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.4.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.7.intermediate.dense.bias', 'base_model.encoder.layer.2.output.LayerNorm.weight', 'base_model.encoder.layer.20.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.10.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.11.intermediate.dense.bias', 'base_model.encoder.layer.6.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.3.attention.self.value.weight', 'base_model.encoder.layer.3.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.1.attention.output.LayerNorm.bias', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.9.attention.output.LayerNorm.weight', 'base_model.encoder.layer.22.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.21.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.19.attention.output.LayerNorm.bias', 'base_model.encoder.layer.7.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.23.output.dense.bias', 'base_model.encoder.layer.5.output.LayerNorm.weight', 'base_model.encoder.layer.4.attention.self.key.weight', 'base_model.encoder.layer.20.output.dense.bias', 'base_model.encoder.layer.21.output.LayerNorm.weight', 'base_model.encoder.layer.3.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.15.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.4.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.6.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.13.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.18.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.19.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.20.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.19.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.4.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.15.attention.output.dense.weight', 'base_model.encoder.layer.21.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.7.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.23.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.19.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.5.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.14.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.7.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.21.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.2.output.dense.weight', 'base_model.encoder.layer.6.attention.output.dense.weight', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.20.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.5.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.10.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.3.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.14.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.20.attention.output.LayerNorm.weight', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.13.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.15.attention.self.value.bias', 'base_model.encoder.layer.21.attention.self.value.weight', 'base_model.encoder.layer.8.output.LayerNorm.bias', 'base_model.encoder.layer.0.attention.self.value.bias', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.10.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.4.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.19.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.14.attention.self.key.bias', 'base_model.encoder.layer.6.attention.self.value.weight', 'base_model.encoder.layer.0.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.2.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.10.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.17.attention.self.value.bias', 'base_model.encoder.layer.17.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.22.output.dense.weight', 'base_model.encoder.layer.23.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.21.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.7.output.LayerNorm.weight', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.13.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.8.attention.self.value.bias', 'base_model.encoder.layer.18.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.13.attention.output.dense.bias', 'base_model.encoder.layer.11.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.20.output.adapters.es.adapter_up.bias', 'base_model.embeddings.LayerNorm.bias', 'base_model.encoder.layer.1.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.10.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.4.output.dense.weight', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.15.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.0.output.LayerNorm.weight', 'base_model.encoder.layer.4.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.11.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.6.attention.self.key.bias', 'base_model.encoder.layer.18.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.17.attention.output.LayerNorm.weight', 'base_model.encoder.layer.8.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.19.attention.self.value.weight', 'base_model.encoder.layer.2.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.18.attention.output.LayerNorm.weight', 'base_model.encoder.layer.7.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.14.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.22.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.6.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.12.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.12.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.5.attention.output.dense.weight', 'base_model.encoder.layer.3.intermediate.dense.bias', 'base_model.encoder.layer.18.attention.self.value.bias', 'base_model.encoder.layer.21.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.4.attention.output.dense.bias', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.0.attention.output.dense.weight', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.18.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.19.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.10.output.dense.bias', 'base_model.encoder.layer.22.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.0.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.11.attention.self.value.bias', 'base_model.encoder.layer.8.attention.self.query.bias', 'base_model.encoder.layer.23.attention.output.LayerNorm.bias', 'base_model.encoder.layer.9.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.19.output.dense.bias', 'base_model.encoder.layer.10.attention.self.value.bias', 'base_model.encoder.layer.10.attention.output.dense.weight', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.15.intermediate.dense.bias', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.6.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.16.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.10.attention.self.value.weight', 'base_model.encoder.layer.19.attention.self.key.weight', 'base_model.encoder.layer.9.output.LayerNorm.bias', 'base_model.encoder.layer.16.attention.output.dense.weight', 'base_model.encoder.layer.16.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.4.output.LayerNorm.bias', 'base_model.encoder.layer.1.attention.self.value.bias', 'base_model.encoder.layer.5.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.5.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.13.attention.self.query.weight', 'base_model.encoder.layer.5.attention.self.value.weight', 'base_model.encoder.layer.13.output.LayerNorm.weight', 'base_model.encoder.layer.5.attention.self.key.bias', 'base_model.encoder.layer.3.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.18.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.9.attention.output.dense.bias', 'base_model.encoder.layer.12.attention.self.query.weight', 'base_model.encoder.layer.19.attention.output.dense.bias', 'base_model.encoder.layer.14.attention.self.query.weight', 'base_model.encoder.layer.10.attention.self.query.weight', 'base_model.encoder.layer.15.attention.output.dense.bias', 'base_model.encoder.layer.2.intermediate.dense.bias', 'base_model.encoder.layer.7.attention.self.key.weight', 'base_model.encoder.layer.8.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.17.attention.self.value.weight', 'base_model.encoder.layer.0.intermediate.dense.bias', 'base_model.encoder.layer.7.attention.self.key.bias', 'base_model.encoder.layer.17.attention.output.LayerNorm.bias', 'base_model.encoder.layer.22.attention.output.LayerNorm.weight', 'base_model.encoder.layer.16.attention.output.LayerNorm.weight', 'base_model.pooler.dense.weight', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.17.output.LayerNorm.weight', 'base_model.encoder.layer.23.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.10.attention.self.query.bias', 'base_model.encoder.layer.2.attention.self.key.weight', 'base_model.encoder.layer.8.attention.self.key.weight', 'base_model.encoder.layer.4.intermediate.dense.bias', 'base_model.encoder.layer.2.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.16.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.23.intermediate.dense.bias', 'base_model.encoder.layer.10.output.LayerNorm.bias', 'base_model.encoder.layer.4.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.18.attention.self.query.weight', 'base_model.encoder.layer.16.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.9.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.16.output.dense.bias', 'base_model.encoder.layer.23.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.0.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.22.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.2.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.0.attention.self.key.weight', 'base_model.encoder.layer.0.attention.self.query.weight', 'base_model.encoder.layer.10.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.21.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.8.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.1.intermediate.dense.weight', 'base_model.encoder.layer.7.attention.self.query.weight', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.9.attention.self.query.weight', 'base_model.encoder.layer.6.output.dense.weight', 'base_model.encoder.layer.12.output.dense.weight', 'base_model.encoder.layer.18.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.13.attention.self.key.bias', 'base_model.encoder.layer.15.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.16.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.20.attention.self.query.bias', 'base_model.encoder.layer.5.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.10.attention.output.LayerNorm.weight', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.1.attention.self.query.weight', 'base_model.encoder.layer.1.attention.output.dense.bias', 'base_model.encoder.layer.17.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.9.attention.output.LayerNorm.bias', 'base_model.encoder.layer.12.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.6.output.LayerNorm.bias', 'base_model.encoder.layer.3.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.4.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.18.intermediate.dense.weight', 'base_model.encoder.layer.11.attention.output.LayerNorm.weight', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.16.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.3.attention.self.key.weight', 'base_model.encoder.layer.23.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.0.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.1.attention.self.key.weight', 'base_model.encoder.layer.3.output.LayerNorm.bias', 'base_model.encoder.layer.4.attention.self.query.bias', 'base_model.encoder.layer.22.attention.self.value.bias', 'base_model.encoder.layer.4.output.LayerNorm.weight', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.15.attention.self.query.weight', 'base_model.encoder.layer.17.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.10.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.21.output.dense.bias', 'base_model.encoder.layer.23.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.9.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.0.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.7.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.23.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.3.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.6.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.10.intermediate.dense.weight', 'base_model.encoder.layer.10.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.2.attention.output.LayerNorm.bias', 'base_model.encoder.layer.20.attention.self.key.bias', 'base_model.encoder.layer.19.output.LayerNorm.bias', 'base_model.encoder.layer.15.attention.self.query.bias', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.18.attention.self.key.bias', 'base_model.encoder.layer.17.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.18.output.dense.bias', 'base_model.encoder.layer.17.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.16.attention.output.dense.bias', 'base_model.encoder.layer.4.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.2.attention.self.value.weight', 'base_model.encoder.layer.7.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.19.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.21.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.0.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.14.attention.self.query.bias', 'base_model.encoder.layer.19.attention.self.key.bias', 'base_model.encoder.layer.8.attention.output.LayerNorm.bias', 'base_model.encoder.layer.14.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.18.attention.output.dense.weight', 'base_model.encoder.layer.12.output.LayerNorm.weight', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.2.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.3.attention.output.LayerNorm.bias', 'base_model.encoder.layer.20.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.9.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.21.attention.self.value.bias', 'base_model.encoder.layer.23.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.12.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.15.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.16.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.12.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.8.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.11.attention.self.query.weight', 'base_model.encoder.layer.23.attention.output.dense.bias', 'base_model.encoder.layer.15.attention.self.key.weight', 'base_model.encoder.layer.18.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.19.intermediate.dense.bias', 'base_model.encoder.layer.14.output.dense.bias', 'base_model.encoder.layer.13.attention.output.dense.weight', 'base_model.encoder.layer.9.attention.self.value.bias', 'base_model.encoder.layer.13.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.23.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.16.output.dense.weight', 'base_model.encoder.layer.8.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.9.intermediate.dense.bias', 'base_model.encoder.layer.12.output.LayerNorm.bias', 'base_model.encoder.layer.17.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.4.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.12.output.dense.bias', 'base_model.encoder.layer.12.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.11.attention.output.LayerNorm.bias', 'base_model.encoder.layer.6.output.dense.bias', 'base_model.encoder.layer.5.attention.output.LayerNorm.weight', 'base_model.encoder.layer.11.attention.self.query.bias', 'base_model.encoder.layer.14.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.5.output.dense.bias', 'base_model.encoder.layer.20.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.11.output.LayerNorm.bias', 'base_model.embeddings.word_embeddings.weight', 'base_model.encoder.layer.20.attention.self.value.weight', 'base_model.encoder.layer.0.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.19.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.1.output.dense.bias', 'base_model.encoder.layer.23.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.14.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.22.attention.self.key.bias', 'base_model.encoder.layer.19.attention.output.dense.weight', 'base_model.encoder.layer.4.attention.output.dense.weight', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.1.attention.self.value.weight', 'base_model.encoder.layer.13.output.adapters.ep.adapter_up.weight', 'base_model.embeddings.position_embeddings.weight', 'base_model.encoder.layer.18.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.21.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.13.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.23.attention.self.value.weight', 'base_model.encoder.layer.23.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.20.output.LayerNorm.weight', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.8.attention.self.value.weight', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.23.attention.self.key.bias', 'base_model.encoder.layer.7.attention.output.dense.bias', 'base_model.encoder.layer.5.attention.self.value.bias', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.22.attention.output.LayerNorm.bias', 'base_model.encoder.layer.21.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.2.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.13.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.18.attention.output.dense.bias', 'base_model.encoder.layer.15.output.LayerNorm.bias', 'base_model.encoder.layer.8.attention.self.key.bias', 'base_model.encoder.layer.8.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.19.output.LayerNorm.weight', 'base_model.encoder.layer.16.attention.self.query.bias', 'base_model.encoder.layer.3.attention.self.query.bias', 'base_model.encoder.layer.21.output.LayerNorm.bias', 'base_model.encoder.layer.6.output.adapters.tp.adapter_up.bias']
- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of XLMRobertaModel were not initialized from the model checkpoint at /cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//tydiqa/xlm-KG_LR8e-6_EPOCH2.0_maxlen384_batchsize4_gradacc4 and are newly initialized: ['encoder.layer.23.attention.self.query.bias', 'encoder.layer.23.intermediate.dense.bias', 'encoder.layer.5.attention.self.query.bias', 'encoder.layer.8.attention.output.LayerNorm.weight', 'encoder.layer.7.intermediate.dense.bias', 'encoder.layer.22.output.LayerNorm.bias', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.22.attention.self.value.weight', 'encoder.layer.2.attention.output.dense.bias', 'encoder.layer.3.attention.self.value.weight', 'encoder.layer.14.attention.output.LayerNorm.weight', 'encoder.layer.10.attention.output.dense.weight', 'encoder.layer.5.attention.output.LayerNorm.weight', 'encoder.layer.18.attention.output.dense.bias', 'encoder.layer.2.attention.output.LayerNorm.weight', 'encoder.layer.7.attention.self.key.weight', 'encoder.layer.23.attention.self.value.bias', 'encoder.layer.13.attention.self.value.bias', 'encoder.layer.21.intermediate.dense.bias', 'encoder.layer.23.output.LayerNorm.weight', 'encoder.layer.23.output.dense.weight', 'encoder.layer.0.attention.self.value.bias', 'encoder.layer.9.output.LayerNorm.bias', 'encoder.layer.18.attention.self.value.weight', 'encoder.layer.19.attention.self.value.weight', 'encoder.layer.19.attention.output.dense.weight', 'encoder.layer.7.attention.output.LayerNorm.weight', 'encoder.layer.23.intermediate.dense.weight', 'encoder.layer.1.attention.output.dense.bias', 'encoder.layer.4.attention.output.dense.weight', 'encoder.layer.20.attention.self.value.weight', 'encoder.layer.14.output.LayerNorm.weight', 'encoder.layer.17.attention.self.key.bias', 'embeddings.token_type_embeddings.weight', 'encoder.layer.3.attention.self.key.weight', 'encoder.layer.20.attention.output.LayerNorm.bias', 'encoder.layer.4.attention.self.key.weight', 'encoder.layer.20.attention.output.LayerNorm.weight', 'encoder.layer.14.attention.self.query.bias', 'encoder.layer.23.attention.output.LayerNorm.weight', 'encoder.layer.8.attention.self.key.weight', 'encoder.layer.6.attention.output.LayerNorm.weight', 'encoder.layer.14.attention.self.key.bias', 'encoder.layer.14.output.LayerNorm.bias', 'encoder.layer.7.attention.output.LayerNorm.bias', 'encoder.layer.14.attention.self.key.weight', 'encoder.layer.8.output.LayerNorm.weight', 'encoder.layer.17.intermediate.dense.weight', 'encoder.layer.16.attention.output.LayerNorm.weight', 'encoder.layer.18.output.dense.weight', 'embeddings.LayerNorm.weight', 'encoder.layer.15.attention.self.query.weight', 'encoder.layer.12.output.LayerNorm.bias', 'encoder.layer.21.attention.self.value.weight', 'encoder.layer.8.attention.self.value.bias', 'encoder.layer.8.attention.output.LayerNorm.bias', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.2.attention.output.dense.weight', 'encoder.layer.11.output.LayerNorm.weight', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.6.attention.output.dense.bias', 'encoder.layer.8.output.LayerNorm.bias', 'encoder.layer.9.attention.self.query.bias', 'encoder.layer.16.attention.self.value.bias', 'encoder.layer.18.attention.self.value.bias', 'encoder.layer.10.attention.output.LayerNorm.weight', 'encoder.layer.18.intermediate.dense.bias', 'encoder.layer.8.attention.self.value.weight', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.0.output.dense.weight', 'encoder.layer.9.output.dense.weight', 'encoder.layer.20.attention.self.key.bias', 'encoder.layer.17.attention.self.value.bias', 'encoder.layer.14.attention.output.dense.weight', 'encoder.layer.13.output.LayerNorm.weight', 'encoder.layer.1.attention.self.key.bias', 'encoder.layer.8.attention.self.key.bias', 'encoder.layer.6.attention.output.LayerNorm.bias', 'encoder.layer.19.attention.self.query.weight', 'encoder.layer.17.attention.self.value.weight', 'encoder.layer.2.attention.self.query.weight', 'encoder.layer.17.attention.self.query.bias', 'encoder.layer.3.attention.self.key.bias', 'encoder.layer.12.intermediate.dense.bias', 'encoder.layer.15.intermediate.dense.bias', 'encoder.layer.14.intermediate.dense.bias', 'encoder.layer.14.attention.self.value.bias', 'encoder.layer.2.attention.self.query.bias', 'encoder.layer.1.attention.self.query.weight', 'encoder.layer.4.output.dense.bias', 'encoder.layer.8.attention.self.query.weight', 'encoder.layer.15.attention.output.dense.weight', 'encoder.layer.13.attention.self.key.bias', 'encoder.layer.16.attention.self.key.bias', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.22.attention.output.dense.weight', 'encoder.layer.6.attention.self.value.weight', 'encoder.layer.21.attention.self.key.bias', 'encoder.layer.21.attention.output.LayerNorm.weight', 'encoder.layer.0.attention.self.key.weight', 'encoder.layer.22.attention.output.dense.bias', 'encoder.layer.3.output.dense.weight', 'encoder.layer.13.attention.self.query.weight', 'encoder.layer.17.attention.self.key.weight', 'encoder.layer.8.attention.output.dense.weight', 'encoder.layer.10.attention.output.dense.bias', 'encoder.layer.4.output.LayerNorm.weight', 'embeddings.position_embeddings.weight', 'encoder.layer.19.attention.self.key.bias', 'encoder.layer.13.attention.self.value.weight', 'encoder.layer.9.attention.output.LayerNorm.weight', 'encoder.layer.17.attention.output.LayerNorm.bias', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.10.attention.output.LayerNorm.bias', 'encoder.layer.14.attention.self.value.weight', 'encoder.layer.15.output.LayerNorm.weight', 'encoder.layer.18.output.LayerNorm.weight', 'encoder.layer.3.attention.output.dense.weight', 'encoder.layer.6.attention.self.key.weight', 'encoder.layer.6.attention.self.value.bias', 'encoder.layer.11.output.dense.weight', 'encoder.layer.17.attention.output.LayerNorm.weight', 'encoder.layer.4.attention.self.value.bias', 'encoder.layer.7.output.dense.weight', 'encoder.layer.2.attention.output.LayerNorm.bias', 'encoder.layer.0.attention.self.query.weight', 'encoder.layer.17.output.LayerNorm.bias', 'encoder.layer.10.attention.self.query.weight', 'encoder.layer.16.output.LayerNorm.weight', 'encoder.layer.5.attention.output.dense.weight', 'encoder.layer.18.attention.self.key.weight', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.17.attention.output.dense.bias', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.21.intermediate.dense.weight', 'encoder.layer.15.attention.output.LayerNorm.weight', 'encoder.layer.12.output.dense.bias', 'encoder.layer.13.attention.output.dense.bias', 'encoder.layer.11.attention.output.dense.bias', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.18.attention.output.LayerNorm.bias', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.15.output.LayerNorm.bias', 'encoder.layer.19.attention.self.query.bias', 'encoder.layer.22.output.LayerNorm.weight', 'encoder.layer.15.output.dense.bias', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.22.attention.self.value.bias', 'encoder.layer.1.output.dense.weight', 'encoder.layer.6.output.dense.weight', 'encoder.layer.11.output.LayerNorm.bias', 'encoder.layer.4.attention.self.value.weight', 'encoder.layer.12.attention.output.dense.bias', 'encoder.layer.8.attention.self.query.bias', 'encoder.layer.19.intermediate.dense.weight', 'encoder.layer.3.attention.self.query.weight', 'encoder.layer.15.attention.self.value.weight', 'encoder.layer.8.output.dense.bias', 'encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.layer.22.attention.self.key.bias', 'encoder.layer.17.output.LayerNorm.weight', 'encoder.layer.22.intermediate.dense.weight', 'encoder.layer.14.attention.self.query.weight', 'encoder.layer.9.output.dense.bias', 'encoder.layer.2.attention.self.value.bias', 'encoder.layer.20.attention.self.key.weight', 'encoder.layer.9.attention.output.dense.weight', 'encoder.layer.12.attention.self.key.weight', 'encoder.layer.13.attention.self.key.weight', 'encoder.layer.9.attention.self.query.weight', 'encoder.layer.5.output.dense.bias', 'encoder.layer.11.attention.self.key.weight', 'encoder.layer.4.attention.output.dense.bias', 'encoder.layer.7.attention.self.query.weight', 'encoder.layer.17.attention.output.dense.weight', 'encoder.layer.12.attention.self.query.bias', 'encoder.layer.12.attention.self.value.weight', 'encoder.layer.20.output.LayerNorm.weight', 'encoder.layer.7.attention.self.key.bias', 'encoder.layer.10.intermediate.dense.weight', 'encoder.layer.10.output.dense.bias', 'encoder.layer.13.intermediate.dense.bias', 'encoder.layer.18.intermediate.dense.weight', 'encoder.layer.14.output.dense.bias', 'encoder.layer.23.attention.output.LayerNorm.bias', 'encoder.layer.2.attention.self.key.weight', 'encoder.layer.20.attention.self.value.bias', 'encoder.layer.10.output.dense.weight', 'encoder.layer.18.attention.self.key.bias', 'encoder.layer.21.output.LayerNorm.bias', 'embeddings.word_embeddings.weight', 'pooler.dense.weight', 'encoder.layer.6.output.dense.bias', 'encoder.layer.9.attention.self.value.bias', 'encoder.layer.19.output.dense.weight', 'encoder.layer.16.intermediate.dense.weight', 'encoder.layer.12.output.LayerNorm.weight', 'encoder.layer.17.attention.self.query.weight', 'encoder.layer.2.attention.self.key.bias', 'encoder.layer.7.attention.output.dense.weight', 'encoder.layer.6.attention.self.query.weight', 'encoder.layer.13.attention.self.query.bias', 'encoder.layer.1.attention.output.dense.weight', 'encoder.layer.21.attention.self.key.weight', 'encoder.layer.6.attention.self.query.bias', 'encoder.layer.12.attention.self.query.weight', 'encoder.layer.21.output.LayerNorm.weight', 'encoder.layer.19.attention.self.value.bias', 'encoder.layer.15.attention.self.key.weight', 'encoder.layer.15.attention.output.dense.bias', 'encoder.layer.4.attention.output.LayerNorm.bias', 'encoder.layer.2.output.dense.weight', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.11.attention.self.value.weight', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.0.attention.output.dense.bias', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.5.output.LayerNorm.bias', 'encoder.layer.21.output.dense.weight', 'encoder.layer.15.output.dense.weight', 'encoder.layer.22.output.dense.weight', 'encoder.layer.6.attention.output.dense.weight', 'encoder.layer.7.output.dense.bias', 'encoder.layer.22.attention.self.key.weight', 'encoder.layer.23.attention.self.value.weight', 'encoder.layer.18.attention.self.query.bias', 'encoder.layer.5.attention.self.query.weight', 'encoder.layer.12.attention.self.value.bias', 'encoder.layer.23.attention.self.key.bias', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.layer.20.intermediate.dense.bias', 'encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.layer.22.attention.self.query.weight', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.0.attention.self.query.bias', 'encoder.layer.3.output.dense.bias', 'encoder.layer.12.attention.self.key.bias', 'encoder.layer.19.attention.output.dense.bias', 'encoder.layer.19.intermediate.dense.bias', 'encoder.layer.14.output.dense.weight', 'encoder.layer.19.output.dense.bias', 'encoder.layer.10.attention.self.query.bias', 'encoder.layer.17.intermediate.dense.bias', 'encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.layer.10.attention.self.key.weight', 'encoder.layer.14.attention.output.LayerNorm.bias', 'encoder.layer.13.attention.output.LayerNorm.weight', 'encoder.layer.16.output.LayerNorm.bias', 'encoder.layer.11.attention.self.key.bias', 'encoder.layer.1.attention.self.value.weight', 'encoder.layer.15.intermediate.dense.weight', 'encoder.layer.19.attention.output.LayerNorm.weight', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.5.attention.self.key.weight', 'encoder.layer.4.attention.self.query.weight', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.19.output.LayerNorm.weight', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.15.attention.self.query.bias', 'encoder.layer.16.attention.self.query.weight', 'encoder.layer.3.attention.self.query.bias', 'encoder.layer.10.output.LayerNorm.bias', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.18.attention.self.query.weight', 'encoder.layer.22.output.dense.bias', 'encoder.layer.4.attention.self.key.bias', 'encoder.layer.18.attention.output.LayerNorm.weight', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.16.attention.output.dense.bias', 'encoder.layer.4.attention.self.query.bias', 'encoder.layer.2.attention.self.value.weight', 'encoder.layer.5.attention.self.value.weight', 'encoder.layer.21.attention.self.query.bias', 'encoder.layer.3.attention.output.dense.bias', 'encoder.layer.7.attention.self.value.bias', 'encoder.layer.0.attention.output.LayerNorm.weight', 'encoder.layer.11.attention.self.query.weight', 'encoder.layer.1.output.dense.bias', 'encoder.layer.15.attention.self.value.bias', 'encoder.layer.21.output.dense.bias', 'encoder.layer.1.attention.self.key.weight', 'encoder.layer.23.attention.output.dense.weight', 'encoder.layer.12.attention.output.LayerNorm.bias', 'encoder.layer.16.output.dense.bias', 'encoder.layer.5.attention.output.dense.bias', 'encoder.layer.18.output.dense.bias', 'encoder.layer.4.attention.output.LayerNorm.weight', 'encoder.layer.3.attention.self.value.bias', 'encoder.layer.16.output.dense.weight', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.layer.22.intermediate.dense.bias', 'encoder.layer.10.attention.self.value.weight', 'encoder.layer.6.attention.self.key.bias', 'encoder.layer.16.intermediate.dense.bias', 'encoder.layer.22.attention.output.LayerNorm.bias', 'encoder.layer.10.attention.self.key.bias', 'encoder.layer.20.attention.self.query.weight', 'encoder.layer.14.intermediate.dense.weight', 'encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.layer.20.attention.self.query.bias', 'encoder.layer.11.attention.self.query.bias', 'encoder.layer.20.intermediate.dense.weight', 'encoder.layer.18.attention.output.dense.weight', 'encoder.layer.20.output.dense.bias', 'encoder.layer.23.attention.output.dense.bias', 'encoder.layer.20.output.dense.weight', 'encoder.layer.0.attention.self.value.weight', 'encoder.layer.22.attention.self.query.bias', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.22.attention.output.LayerNorm.weight', 'encoder.layer.9.attention.output.dense.bias', 'encoder.layer.15.attention.output.LayerNorm.bias', 'encoder.layer.5.attention.self.key.bias', 'encoder.layer.9.attention.output.LayerNorm.bias', 'encoder.layer.21.attention.self.query.weight', 'encoder.layer.1.attention.self.query.bias', 'encoder.layer.0.output.dense.bias', 'encoder.layer.21.attention.output.dense.bias', 'encoder.layer.2.output.dense.bias', 'encoder.layer.12.attention.output.dense.weight', 'encoder.layer.0.attention.self.key.bias', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.11.attention.self.value.bias', 'encoder.layer.12.output.dense.weight', 'encoder.layer.13.output.dense.bias', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.16.attention.output.dense.weight', 'encoder.layer.20.attention.output.dense.bias', 'encoder.layer.23.output.dense.bias', 'encoder.layer.10.attention.self.value.bias', 'encoder.layer.5.attention.self.value.bias', 'encoder.layer.1.attention.output.LayerNorm.weight', 'pooler.dense.bias', 'encoder.layer.14.attention.output.dense.bias', 'encoder.layer.5.intermediate.dense.bias', 'embeddings.LayerNorm.bias', 'encoder.layer.7.output.LayerNorm.bias', 'encoder.layer.15.attention.self.key.bias', 'encoder.layer.16.attention.self.key.weight', 'encoder.layer.19.attention.output.LayerNorm.bias', 'encoder.layer.13.attention.output.LayerNorm.bias', 'encoder.layer.11.output.dense.bias', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.12.attention.output.LayerNorm.weight', 'encoder.layer.19.attention.self.key.weight', 'encoder.layer.23.attention.self.query.weight', 'encoder.layer.17.output.dense.bias', 'encoder.layer.21.attention.output.LayerNorm.bias', 'encoder.layer.12.intermediate.dense.weight', 'encoder.layer.17.output.dense.weight', 'encoder.layer.9.output.LayerNorm.weight', 'encoder.layer.11.attention.output.LayerNorm.weight', 'encoder.layer.9.attention.self.value.weight', 'encoder.layer.13.intermediate.dense.weight', 'encoder.layer.18.output.LayerNorm.bias', 'encoder.layer.13.output.LayerNorm.bias', 'encoder.layer.20.attention.output.dense.weight', 'encoder.layer.20.output.LayerNorm.bias', 'encoder.layer.8.output.dense.weight', 'encoder.layer.7.attention.self.query.bias', 'encoder.layer.6.output.LayerNorm.bias', 'encoder.layer.16.attention.output.LayerNorm.bias', 'encoder.layer.23.output.LayerNorm.bias', 'encoder.layer.11.attention.output.dense.weight', 'encoder.layer.0.attention.output.dense.weight', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.16.attention.self.value.weight', 'encoder.layer.8.attention.output.dense.bias', 'encoder.layer.7.attention.output.dense.bias', 'encoder.layer.23.attention.self.key.weight', 'encoder.layer.13.attention.output.dense.weight', 'encoder.layer.4.output.dense.weight', 'encoder.layer.7.attention.self.value.weight', 'encoder.layer.21.attention.self.value.bias', 'encoder.layer.13.output.dense.weight', 'encoder.layer.10.output.LayerNorm.weight', 'encoder.layer.5.output.dense.weight', 'encoder.layer.9.attention.self.key.bias', 'encoder.layer.1.attention.self.value.bias', 'encoder.layer.16.attention.self.query.bias', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.9.attention.self.key.weight', 'encoder.layer.21.attention.output.dense.weight', 'encoder.layer.7.output.LayerNorm.weight', 'encoder.layer.19.output.LayerNorm.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Overwriting existing adapter 'ep'.
Overwriting existing adapter 'tp'.
Overwriting existing adapter 'es'.
Overwriting existing adapter 'ts'.
Overwriting existing adapter fusion module 'ep,tp,es,ts'
05/09/2022 22:53:18 - INFO - __main__ -   lang2id = None
05/09/2022 22:53:22 - INFO - __main__ -   Training/evaluation parameters Namespace(adam_epsilon=1e-08, cache_dir='', config_name='', data_dir=None, device=device(type='cuda'), do_eval=True, do_lower_case=False, do_train=False, doc_stride=128, eval_all_checkpoints=False, eval_lang='fi', evaluate_during_training=False, fp16=False, fp16_opt_level='O1', gradient_accumulation_steps=1, learning_rate=5e-05, local_rank=-1, logging_steps=50, max_answer_length=30, max_grad_norm=1.0, max_query_length=64, max_seq_length=384, max_steps=-1, model_name='xlm-KG', model_name_or_path='/cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//tydiqa/xlm-KG_LR8e-6_EPOCH2.0_maxlen384_batchsize4_gradacc4', model_type='xlm', modelkg_dir='/cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/adapter/xlmr_adapter', n_best_size=20, n_gpu=1, no_cuda=False, null_score_diff_threshold=0.0, num_train_epochs=3.0, output_dir='/cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//tydiqa/xlm-KG_LR8e-6_EPOCH2.0_maxlen384_batchsize4_gradacc4/predictions/tydiqa/', overwrite_cache=False, overwrite_output_dir=False, per_gpu_eval_batch_size=8, per_gpu_train_batch_size=8, predict_file='/cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/download//tydiqa//tydiqa-goldp-v1.1-dev/tydiqa.goldp.fi.dev.json', save_steps=50, seed=42, server_ip='', server_port='', threads=1, tokenizer_name='', train_file=None, train_lang='en', verbose_logging=False, version_2_with_negative=False, warmup_steps=0, weight_decay=0.0)
05/09/2022 22:53:22 - INFO - __main__ -   Loading checkpoint /cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//tydiqa/xlm-KG_LR8e-6_EPOCH2.0_maxlen384_batchsize4_gradacc4 for evaluation
05/09/2022 22:53:22 - INFO - __main__ -   Evaluate the following checkpoints: ['/cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//tydiqa/xlm-KG_LR8e-6_EPOCH2.0_maxlen384_batchsize4_gradacc4']
Some weights of the model checkpoint at /cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//tydiqa/xlm-KG_LR8e-6_EPOCH2.0_maxlen384_batchsize4_gradacc4 were not used when initializing XLMRobertaModel: ['base_model.encoder.layer.1.intermediate.dense.bias', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.embeddings.token_type_embeddings.weight', 'base_model.encoder.layer.14.attention.output.dense.bias', 'base_model.encoder.layer.20.attention.output.LayerNorm.bias', 'base_model.encoder.layer.16.attention.self.value.bias', 'base_model.encoder.layer.18.attention.self.value.weight', 'base_model.encoder.layer.15.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.20.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.19.attention.self.query.bias', 'base_model.encoder.layer.6.attention.output.LayerNorm.weight', 'base_model.encoder.layer.22.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.18.output.LayerNorm.bias', 'base_model.encoder.layer.21.attention.output.dense.bias', 'base_model.encoder.layer.4.attention.self.query.weight', 'base_model.encoder.layer.17.attention.output.dense.bias', 'base_model.encoder.layer.0.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.5.output.dense.weight', 'base_model.encoder.layer.2.attention.output.LayerNorm.weight', 'base_model.encoder.layer.8.output.dense.bias', 'base_model.encoder.layer.14.attention.output.LayerNorm.bias', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.18.attention.self.key.weight', 'base_model.encoder.layer.21.attention.output.LayerNorm.bias', 'base_model.encoder.layer.6.attention.self.key.weight', 'base_model.encoder.layer.12.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.5.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.2.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.5.attention.self.query.weight', 'base_model.encoder.layer.14.output.LayerNorm.bias', 'base_model.encoder.layer.10.attention.output.dense.bias', 'base_model.encoder.layer.4.attention.self.value.bias', 'base_model.encoder.layer.2.attention.self.key.bias', 'base_model.encoder.layer.11.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.6.attention.self.query.weight', 'base_model.encoder.layer.15.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.17.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.16.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.19.output.dense.weight', 'base_model.encoder.layer.2.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.22.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.11.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.19.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.20.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.10.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.13.attention.self.key.weight', 'base_model.encoder.layer.9.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.8.output.dense.weight', 'base_model.encoder.layer.5.intermediate.dense.weight', 'base_model.encoder.layer.0.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.12.attention.self.value.weight', 'base_model.encoder.layer.5.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.7.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.1.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.21.attention.self.key.weight', 'base_model.encoder.layer.20.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.0.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.2.output.LayerNorm.bias', 'base_model.encoder.layer.22.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.12.attention.self.key.bias', 'base_model.encoder.layer.11.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.16.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.23.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.0.attention.output.LayerNorm.bias', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.7.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.20.attention.output.dense.weight', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.3.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.17.attention.self.key.weight', 'base_model.encoder.layer.7.output.dense.bias', 'base_model.encoder.layer.13.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.19.attention.self.value.bias', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.23.attention.output.LayerNorm.weight', 'base_model.encoder.layer.20.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.13.attention.self.value.weight', 'base_model.encoder.layer.15.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.1.attention.output.LayerNorm.weight', 'base_model.encoder.layer.6.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.17.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.1.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.9.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.15.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.11.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.17.intermediate.dense.weight', 'base_model.encoder.layer.22.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.3.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.0.attention.output.dense.bias', 'base_model.encoder.layer.10.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.11.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.14.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.6.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.20.attention.self.key.weight', 'base_model.encoder.layer.23.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.11.attention.output.dense.weight', 'base_model.encoder.layer.2.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.16.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.17.output.dense.weight', 'base_model.encoder.layer.5.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.11.output.LayerNorm.weight', 'base_model.encoder.layer.3.output.LayerNorm.weight', 'base_model.encoder.layer.1.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.14.intermediate.dense.weight', 'base_model.encoder.layer.4.attention.output.LayerNorm.bias', 'base_model.encoder.layer.22.attention.self.value.weight', 'base_model.encoder.layer.13.attention.self.value.bias', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.21.intermediate.dense.bias', 'base_model.encoder.layer.12.attention.self.value.bias', 'base_model.encoder.layer.19.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.5.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.1.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.3.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.6.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.14.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.15.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.16.output.LayerNorm.bias', 'base_model.encoder.layer.19.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.1.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.8.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.20.output.dense.weight', 'base_model.encoder.layer.12.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.9.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.12.attention.self.key.weight', 'base_model.encoder.layer.17.attention.self.key.bias', 'base_model.encoder.layer.20.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.18.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.8.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.9.attention.self.value.weight', 'base_model.encoder.layer.12.attention.self.query.bias', 'base_model.encoder.layer.13.attention.output.LayerNorm.bias', 'base_model.encoder.layer.22.intermediate.dense.bias', 'base_model.encoder.layer.12.intermediate.dense.weight', 'base_model.encoder.layer.19.intermediate.dense.weight', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.0.attention.self.query.bias', 'base_model.encoder.layer.10.attention.self.key.bias', 'base_model.encoder.layer.1.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.8.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.10.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.12.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.18.attention.self.query.bias', 'base_model.encoder.layer.10.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.22.output.LayerNorm.bias', 'base_model.encoder.layer.9.attention.self.query.bias', 'base_model.encoder.layer.21.attention.self.query.bias', 'base_model.encoder.layer.1.output.LayerNorm.bias', 'base_model.encoder.layer.4.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.14.attention.output.dense.weight', 'base_model.encoder.layer.13.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.11.intermediate.dense.weight', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.22.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.23.attention.self.query.bias', 'base_model.encoder.layer.11.output.dense.weight', 'base_model.encoder.layer.7.attention.self.query.bias', 'base_model.encoder.layer.18.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.7.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.8.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.7.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.19.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.21.attention.output.dense.weight', 'base_model.encoder.layer.20.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.16.attention.output.LayerNorm.bias', 'base_model.encoder.layer.21.output.adapters.ts.adapter_up.weight', 'qa_outputs.bias', 'base_model.encoder.layer.8.attention.self.query.weight', 'base_model.encoder.layer.5.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.10.attention.output.LayerNorm.bias', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.1.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.7.output.dense.weight', 'base_model.encoder.layer.9.output.LayerNorm.weight', 'base_model.encoder.layer.6.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.8.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.11.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.6.attention.output.dense.bias', 'base_model.encoder.layer.18.attention.output.LayerNorm.bias', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.9.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.21.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.6.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.21.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.13.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.21.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.17.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.13.output.dense.bias', 'base_model.encoder.layer.14.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.12.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.11.attention.self.value.weight', 'base_model.encoder.layer.15.intermediate.dense.weight', 'base_model.encoder.layer.7.attention.output.LayerNorm.bias', 'base_model.encoder.layer.18.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.7.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.3.attention.output.dense.bias', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.3.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.2.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.16.attention.self.key.weight', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.22.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.23.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.15.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.8.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.12.intermediate.dense.bias', 'base_model.encoder.layer.7.attention.output.dense.weight', 'base_model.encoder.layer.11.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.6.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.21.attention.self.key.bias', 'base_model.encoder.layer.1.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.8.attention.output.dense.bias', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.22.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.3.attention.self.query.weight', 'base_model.encoder.layer.15.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.5.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.6.intermediate.dense.bias', 'base_model.encoder.layer.8.attention.output.dense.weight', 'base_model.encoder.layer.16.output.LayerNorm.weight', 'base_model.encoder.layer.17.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.16.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.21.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.13.attention.self.query.bias', 'base_model.encoder.layer.7.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.0.output.dense.weight', 'base_model.encoder.layer.7.attention.self.value.bias', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.1.attention.self.query.bias', 'base_model.encoder.layer.2.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.14.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.2.attention.self.value.bias', 'base_model.encoder.layer.1.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.2.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.17.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.15.attention.output.LayerNorm.bias', 'base_model.encoder.layer.22.attention.output.dense.weight', 'base_model.encoder.layer.11.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.7.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.16.attention.self.key.bias', 'base_model.encoder.layer.20.intermediate.dense.bias', 'base_model.encoder.layer.9.output.dense.weight', 'base_model.embeddings.position_ids', 'base_model.encoder.layer.0.attention.self.key.bias', 'base_model.encoder.layer.0.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.11.output.dense.bias', 'base_model.encoder.layer.16.attention.self.query.weight', 'base_model.encoder.layer.3.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.15.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.1.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.10.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.20.attention.self.query.weight', 'base_model.encoder.layer.23.output.dense.weight', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.10.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.14.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.4.intermediate.dense.weight', 'base_model.encoder.layer.10.output.LayerNorm.weight', 'base_model.encoder.layer.6.attention.output.LayerNorm.bias', 'base_model.encoder.layer.1.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.20.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.22.attention.self.key.weight', 'base_model.encoder.layer.15.output.LayerNorm.weight', 'base_model.encoder.layer.9.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.15.output.dense.bias', 'base_model.encoder.layer.14.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.17.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.5.attention.self.key.weight', 'base_model.encoder.layer.8.attention.output.LayerNorm.weight', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.14.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.12.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.4.attention.output.LayerNorm.weight', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.3.output.dense.weight', 'base_model.encoder.layer.21.attention.output.LayerNorm.weight', 'base_model.encoder.layer.9.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.2.intermediate.dense.weight', 'base_model.encoder.layer.7.attention.self.value.weight', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.16.intermediate.dense.weight', 'base_model.encoder.layer.21.output.dense.weight', 'base_model.encoder.layer.5.attention.output.dense.bias', 'base_model.encoder.layer.13.intermediate.dense.bias', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.4.attention.self.value.weight', 'base_model.encoder.layer.23.attention.self.query.weight', 'base_model.encoder.layer.5.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.12.attention.output.dense.weight', 'base_model.encoder.layer.0.output.LayerNorm.bias', 'base_model.encoder.layer.3.intermediate.dense.weight', 'base_model.encoder.layer.9.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.19.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.8.intermediate.dense.weight', 'base_model.encoder.layer.2.attention.output.dense.bias', 'base_model.encoder.layer.6.attention.self.value.bias', 'base_model.encoder.layer.3.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.9.attention.self.key.weight', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.5.attention.output.LayerNorm.bias', 'base_model.encoder.layer.16.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.23.output.LayerNorm.bias', 'base_model.encoder.layer.9.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.14.attention.self.value.weight', 'base_model.encoder.layer.10.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.17.attention.output.dense.weight', 'base_model.encoder.layer.20.output.LayerNorm.bias', 'base_model.encoder.layer.5.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.4.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.6.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.14.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.22.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.14.output.LayerNorm.weight', 'base_model.encoder.layer.15.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.0.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.13.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.18.intermediate.dense.bias', 'base_model.encoder.layer.3.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.23.attention.self.key.weight', 'base_model.encoder.layer.17.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.11.attention.self.key.bias', 'base_model.encoder.layer.13.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.8.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.9.attention.self.key.bias', 'base_model.encoder.layer.1.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.4.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.20.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.12.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.0.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.14.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.5.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.19.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.15.attention.self.key.bias', 'base_model.encoder.layer.23.attention.self.value.bias', 'base_model.encoder.layer.7.attention.output.LayerNorm.weight', 'base_model.encoder.layer.22.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.1.attention.output.dense.weight', 'base_model.encoder.layer.16.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.18.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.13.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.11.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.2.attention.self.query.weight', 'base_model.encoder.layer.9.output.dense.bias', 'base_model.encoder.layer.13.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.9.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.20.intermediate.dense.weight', 'base_model.encoder.layer.23.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.0.output.dense.bias', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.4.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.22.output.dense.bias', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.17.output.dense.bias', 'qa_outputs.weight', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.14.intermediate.dense.bias', 'base_model.encoder.layer.1.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.15.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.23.output.LayerNorm.weight', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.0.intermediate.dense.weight', 'base_model.encoder.layer.13.output.LayerNorm.bias', 'base_model.encoder.layer.16.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.8.output.adapters.tp.adapter_up.weight', 'base_model.embeddings.LayerNorm.weight', 'base_model.encoder.layer.15.attention.self.value.weight', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.17.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.22.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.12.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.11.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.7.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.1.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.3.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.7.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.13.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.21.intermediate.dense.weight', 'base_model.encoder.layer.20.attention.self.value.bias', 'base_model.encoder.layer.2.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.11.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.12.attention.output.LayerNorm.bias', 'base_model.encoder.layer.22.attention.self.query.bias', 'base_model.encoder.layer.20.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.2.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.22.attention.self.query.weight', 'base_model.encoder.layer.2.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.8.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.9.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.4.output.dense.bias', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.23.attention.output.dense.weight', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.14.attention.self.value.bias', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.13.intermediate.dense.weight', 'base_model.encoder.layer.10.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.20.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.14.output.dense.weight', 'base_model.encoder.layer.21.attention.self.query.weight', 'base_model.encoder.layer.17.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.21.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.16.intermediate.dense.bias', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.8.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.1.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.13.attention.output.LayerNorm.weight', 'base_model.encoder.layer.14.attention.self.key.weight', 'base_model.encoder.layer.17.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.22.attention.output.dense.bias', 'base_model.encoder.layer.22.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.23.intermediate.dense.weight', 'base_model.encoder.layer.5.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.12.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.11.output.adapters.tp.adapter_up.weight', 'base_model.pooler.dense.bias', 'base_model.encoder.layer.7.intermediate.dense.weight', 'base_model.encoder.layer.2.attention.output.dense.weight', 'base_model.encoder.layer.5.attention.self.query.bias', 'base_model.encoder.layer.22.intermediate.dense.weight', 'base_model.encoder.layer.13.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.16.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.19.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.17.attention.self.query.weight', 'base_model.encoder.layer.1.output.LayerNorm.weight', 'base_model.encoder.layer.17.output.LayerNorm.bias', 'base_model.encoder.layer.22.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.3.attention.self.value.bias', 'base_model.encoder.layer.11.attention.output.dense.bias', 'base_model.encoder.layer.3.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.15.attention.output.LayerNorm.weight', 'base_model.encoder.layer.17.intermediate.dense.bias', 'base_model.encoder.layer.19.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.3.attention.output.dense.weight', 'base_model.encoder.layer.2.attention.self.query.bias', 'base_model.encoder.layer.2.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.6.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.18.output.LayerNorm.weight', 'base_model.encoder.layer.12.attention.output.dense.bias', 'base_model.encoder.layer.21.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.5.output.LayerNorm.bias', 'base_model.encoder.layer.10.intermediate.dense.bias', 'base_model.encoder.layer.11.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.3.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.12.attention.output.LayerNorm.weight', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.4.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.19.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.14.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.9.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.15.output.dense.weight', 'base_model.encoder.layer.6.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.18.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.23.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.20.attention.output.dense.bias', 'base_model.encoder.layer.3.output.dense.bias', 'base_model.encoder.layer.6.attention.self.query.bias', 'base_model.encoder.layer.12.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.8.intermediate.dense.bias', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.5.intermediate.dense.bias', 'base_model.encoder.layer.19.attention.self.query.weight', 'base_model.encoder.layer.18.output.dense.weight', 'base_model.encoder.layer.6.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.15.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.1.attention.self.key.bias', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.4.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.17.attention.self.query.bias', 'base_model.encoder.layer.9.attention.output.dense.weight', 'base_model.encoder.layer.4.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.16.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.0.attention.output.LayerNorm.weight', 'base_model.encoder.layer.0.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.0.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.6.intermediate.dense.weight', 'base_model.encoder.layer.0.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.7.output.LayerNorm.bias', 'base_model.encoder.layer.11.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.8.output.LayerNorm.weight', 'base_model.encoder.layer.13.output.dense.weight', 'base_model.encoder.layer.14.attention.output.LayerNorm.weight', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.4.attention.self.key.bias', 'base_model.encoder.layer.0.attention.self.value.weight', 'base_model.encoder.layer.10.output.dense.weight', 'base_model.encoder.layer.2.output.dense.bias', 'base_model.encoder.layer.22.output.LayerNorm.weight', 'base_model.encoder.layer.6.output.LayerNorm.weight', 'base_model.encoder.layer.9.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.19.attention.output.LayerNorm.weight', 'base_model.encoder.layer.9.intermediate.dense.weight', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.3.attention.self.key.bias', 'base_model.encoder.layer.11.attention.self.key.weight', 'base_model.encoder.layer.5.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.15.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.18.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.12.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.16.attention.self.value.weight', 'base_model.encoder.layer.18.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.1.output.dense.weight', 'base_model.encoder.layer.10.attention.self.key.weight', 'base_model.encoder.layer.3.attention.output.LayerNorm.weight', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.18.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.7.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.4.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.7.intermediate.dense.bias', 'base_model.encoder.layer.2.output.LayerNorm.weight', 'base_model.encoder.layer.20.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.10.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.11.intermediate.dense.bias', 'base_model.encoder.layer.6.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.3.attention.self.value.weight', 'base_model.encoder.layer.3.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.1.attention.output.LayerNorm.bias', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.9.attention.output.LayerNorm.weight', 'base_model.encoder.layer.22.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.21.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.19.attention.output.LayerNorm.bias', 'base_model.encoder.layer.7.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.23.output.dense.bias', 'base_model.encoder.layer.5.output.LayerNorm.weight', 'base_model.encoder.layer.4.attention.self.key.weight', 'base_model.encoder.layer.20.output.dense.bias', 'base_model.encoder.layer.21.output.LayerNorm.weight', 'base_model.encoder.layer.3.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.15.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.4.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.6.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.13.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.18.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.19.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.20.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.19.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.4.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.15.attention.output.dense.weight', 'base_model.encoder.layer.21.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.7.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.23.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.19.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.5.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.14.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.7.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.21.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.2.output.dense.weight', 'base_model.encoder.layer.6.attention.output.dense.weight', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.20.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.5.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.10.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.3.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.14.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.20.attention.output.LayerNorm.weight', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.13.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.15.attention.self.value.bias', 'base_model.encoder.layer.21.attention.self.value.weight', 'base_model.encoder.layer.8.output.LayerNorm.bias', 'base_model.encoder.layer.0.attention.self.value.bias', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.10.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.4.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.19.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.14.attention.self.key.bias', 'base_model.encoder.layer.6.attention.self.value.weight', 'base_model.encoder.layer.0.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.2.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.10.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.17.attention.self.value.bias', 'base_model.encoder.layer.17.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.22.output.dense.weight', 'base_model.encoder.layer.23.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.21.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.7.output.LayerNorm.weight', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.13.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.8.attention.self.value.bias', 'base_model.encoder.layer.18.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.13.attention.output.dense.bias', 'base_model.encoder.layer.11.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.20.output.adapters.es.adapter_up.bias', 'base_model.embeddings.LayerNorm.bias', 'base_model.encoder.layer.1.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.10.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.4.output.dense.weight', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.15.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.0.output.LayerNorm.weight', 'base_model.encoder.layer.4.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.11.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.6.attention.self.key.bias', 'base_model.encoder.layer.18.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.17.attention.output.LayerNorm.weight', 'base_model.encoder.layer.8.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.19.attention.self.value.weight', 'base_model.encoder.layer.2.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.18.attention.output.LayerNorm.weight', 'base_model.encoder.layer.7.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.14.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.22.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.6.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.12.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.12.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.5.attention.output.dense.weight', 'base_model.encoder.layer.3.intermediate.dense.bias', 'base_model.encoder.layer.18.attention.self.value.bias', 'base_model.encoder.layer.21.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.4.attention.output.dense.bias', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.0.attention.output.dense.weight', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.18.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.19.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.10.output.dense.bias', 'base_model.encoder.layer.22.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.0.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.11.attention.self.value.bias', 'base_model.encoder.layer.8.attention.self.query.bias', 'base_model.encoder.layer.23.attention.output.LayerNorm.bias', 'base_model.encoder.layer.9.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.19.output.dense.bias', 'base_model.encoder.layer.10.attention.self.value.bias', 'base_model.encoder.layer.10.attention.output.dense.weight', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.15.intermediate.dense.bias', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.6.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.16.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.10.attention.self.value.weight', 'base_model.encoder.layer.19.attention.self.key.weight', 'base_model.encoder.layer.9.output.LayerNorm.bias', 'base_model.encoder.layer.16.attention.output.dense.weight', 'base_model.encoder.layer.16.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.4.output.LayerNorm.bias', 'base_model.encoder.layer.1.attention.self.value.bias', 'base_model.encoder.layer.5.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.5.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.13.attention.self.query.weight', 'base_model.encoder.layer.5.attention.self.value.weight', 'base_model.encoder.layer.13.output.LayerNorm.weight', 'base_model.encoder.layer.5.attention.self.key.bias', 'base_model.encoder.layer.3.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.18.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.9.attention.output.dense.bias', 'base_model.encoder.layer.12.attention.self.query.weight', 'base_model.encoder.layer.19.attention.output.dense.bias', 'base_model.encoder.layer.14.attention.self.query.weight', 'base_model.encoder.layer.10.attention.self.query.weight', 'base_model.encoder.layer.15.attention.output.dense.bias', 'base_model.encoder.layer.2.intermediate.dense.bias', 'base_model.encoder.layer.7.attention.self.key.weight', 'base_model.encoder.layer.8.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.17.attention.self.value.weight', 'base_model.encoder.layer.0.intermediate.dense.bias', 'base_model.encoder.layer.7.attention.self.key.bias', 'base_model.encoder.layer.17.attention.output.LayerNorm.bias', 'base_model.encoder.layer.22.attention.output.LayerNorm.weight', 'base_model.encoder.layer.16.attention.output.LayerNorm.weight', 'base_model.pooler.dense.weight', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.17.output.LayerNorm.weight', 'base_model.encoder.layer.23.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.10.attention.self.query.bias', 'base_model.encoder.layer.2.attention.self.key.weight', 'base_model.encoder.layer.8.attention.self.key.weight', 'base_model.encoder.layer.4.intermediate.dense.bias', 'base_model.encoder.layer.2.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.16.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.23.intermediate.dense.bias', 'base_model.encoder.layer.10.output.LayerNorm.bias', 'base_model.encoder.layer.4.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.18.attention.self.query.weight', 'base_model.encoder.layer.16.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.9.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.16.output.dense.bias', 'base_model.encoder.layer.23.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.0.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.22.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.2.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.0.attention.self.key.weight', 'base_model.encoder.layer.0.attention.self.query.weight', 'base_model.encoder.layer.10.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.21.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.8.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.1.intermediate.dense.weight', 'base_model.encoder.layer.7.attention.self.query.weight', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.9.attention.self.query.weight', 'base_model.encoder.layer.6.output.dense.weight', 'base_model.encoder.layer.12.output.dense.weight', 'base_model.encoder.layer.18.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.13.attention.self.key.bias', 'base_model.encoder.layer.15.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.16.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.20.attention.self.query.bias', 'base_model.encoder.layer.5.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.10.attention.output.LayerNorm.weight', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.1.attention.self.query.weight', 'base_model.encoder.layer.1.attention.output.dense.bias', 'base_model.encoder.layer.17.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.9.attention.output.LayerNorm.bias', 'base_model.encoder.layer.12.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.6.output.LayerNorm.bias', 'base_model.encoder.layer.3.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.4.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.18.intermediate.dense.weight', 'base_model.encoder.layer.11.attention.output.LayerNorm.weight', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.16.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.3.attention.self.key.weight', 'base_model.encoder.layer.23.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.0.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.1.attention.self.key.weight', 'base_model.encoder.layer.3.output.LayerNorm.bias', 'base_model.encoder.layer.4.attention.self.query.bias', 'base_model.encoder.layer.22.attention.self.value.bias', 'base_model.encoder.layer.4.output.LayerNorm.weight', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.15.attention.self.query.weight', 'base_model.encoder.layer.17.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.10.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.21.output.dense.bias', 'base_model.encoder.layer.23.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.9.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.0.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.7.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.23.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.3.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.6.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.10.intermediate.dense.weight', 'base_model.encoder.layer.10.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.2.attention.output.LayerNorm.bias', 'base_model.encoder.layer.20.attention.self.key.bias', 'base_model.encoder.layer.19.output.LayerNorm.bias', 'base_model.encoder.layer.15.attention.self.query.bias', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.18.attention.self.key.bias', 'base_model.encoder.layer.17.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.18.output.dense.bias', 'base_model.encoder.layer.17.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.16.attention.output.dense.bias', 'base_model.encoder.layer.4.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.2.attention.self.value.weight', 'base_model.encoder.layer.7.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.19.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.21.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.0.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.14.attention.self.query.bias', 'base_model.encoder.layer.19.attention.self.key.bias', 'base_model.encoder.layer.8.attention.output.LayerNorm.bias', 'base_model.encoder.layer.14.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.18.attention.output.dense.weight', 'base_model.encoder.layer.12.output.LayerNorm.weight', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.2.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.3.attention.output.LayerNorm.bias', 'base_model.encoder.layer.20.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.9.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.21.attention.self.value.bias', 'base_model.encoder.layer.23.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.12.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.15.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.16.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.12.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.8.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.11.attention.self.query.weight', 'base_model.encoder.layer.23.attention.output.dense.bias', 'base_model.encoder.layer.15.attention.self.key.weight', 'base_model.encoder.layer.18.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.19.intermediate.dense.bias', 'base_model.encoder.layer.14.output.dense.bias', 'base_model.encoder.layer.13.attention.output.dense.weight', 'base_model.encoder.layer.9.attention.self.value.bias', 'base_model.encoder.layer.13.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.23.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.16.output.dense.weight', 'base_model.encoder.layer.8.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.9.intermediate.dense.bias', 'base_model.encoder.layer.12.output.LayerNorm.bias', 'base_model.encoder.layer.17.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.4.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.12.output.dense.bias', 'base_model.encoder.layer.12.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.11.attention.output.LayerNorm.bias', 'base_model.encoder.layer.6.output.dense.bias', 'base_model.encoder.layer.5.attention.output.LayerNorm.weight', 'base_model.encoder.layer.11.attention.self.query.bias', 'base_model.encoder.layer.14.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.5.output.dense.bias', 'base_model.encoder.layer.20.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.11.output.LayerNorm.bias', 'base_model.embeddings.word_embeddings.weight', 'base_model.encoder.layer.20.attention.self.value.weight', 'base_model.encoder.layer.0.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.19.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.1.output.dense.bias', 'base_model.encoder.layer.23.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.14.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.22.attention.self.key.bias', 'base_model.encoder.layer.19.attention.output.dense.weight', 'base_model.encoder.layer.4.attention.output.dense.weight', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.1.attention.self.value.weight', 'base_model.encoder.layer.13.output.adapters.ep.adapter_up.weight', 'base_model.embeddings.position_embeddings.weight', 'base_model.encoder.layer.18.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.21.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.13.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.23.attention.self.value.weight', 'base_model.encoder.layer.23.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.20.output.LayerNorm.weight', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.8.attention.self.value.weight', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.23.attention.self.key.bias', 'base_model.encoder.layer.7.attention.output.dense.bias', 'base_model.encoder.layer.5.attention.self.value.bias', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.22.attention.output.LayerNorm.bias', 'base_model.encoder.layer.21.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.2.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.13.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.18.attention.output.dense.bias', 'base_model.encoder.layer.15.output.LayerNorm.bias', 'base_model.encoder.layer.8.attention.self.key.bias', 'base_model.encoder.layer.8.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.19.output.LayerNorm.weight', 'base_model.encoder.layer.16.attention.self.query.bias', 'base_model.encoder.layer.3.attention.self.query.bias', 'base_model.encoder.layer.21.output.LayerNorm.bias', 'base_model.encoder.layer.6.output.adapters.tp.adapter_up.bias']
- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of XLMRobertaModel were not initialized from the model checkpoint at /cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//tydiqa/xlm-KG_LR8e-6_EPOCH2.0_maxlen384_batchsize4_gradacc4 and are newly initialized: ['encoder.layer.23.attention.self.query.bias', 'encoder.layer.23.intermediate.dense.bias', 'encoder.layer.5.attention.self.query.bias', 'encoder.layer.8.attention.output.LayerNorm.weight', 'encoder.layer.7.intermediate.dense.bias', 'encoder.layer.22.output.LayerNorm.bias', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.22.attention.self.value.weight', 'encoder.layer.2.attention.output.dense.bias', 'encoder.layer.3.attention.self.value.weight', 'encoder.layer.14.attention.output.LayerNorm.weight', 'encoder.layer.10.attention.output.dense.weight', 'encoder.layer.5.attention.output.LayerNorm.weight', 'encoder.layer.18.attention.output.dense.bias', 'encoder.layer.2.attention.output.LayerNorm.weight', 'encoder.layer.7.attention.self.key.weight', 'encoder.layer.23.attention.self.value.bias', 'encoder.layer.13.attention.self.value.bias', 'encoder.layer.21.intermediate.dense.bias', 'encoder.layer.23.output.LayerNorm.weight', 'encoder.layer.23.output.dense.weight', 'encoder.layer.0.attention.self.value.bias', 'encoder.layer.9.output.LayerNorm.bias', 'encoder.layer.18.attention.self.value.weight', 'encoder.layer.19.attention.self.value.weight', 'encoder.layer.19.attention.output.dense.weight', 'encoder.layer.7.attention.output.LayerNorm.weight', 'encoder.layer.23.intermediate.dense.weight', 'encoder.layer.1.attention.output.dense.bias', 'encoder.layer.4.attention.output.dense.weight', 'encoder.layer.20.attention.self.value.weight', 'encoder.layer.14.output.LayerNorm.weight', 'encoder.layer.17.attention.self.key.bias', 'embeddings.token_type_embeddings.weight', 'encoder.layer.3.attention.self.key.weight', 'encoder.layer.20.attention.output.LayerNorm.bias', 'encoder.layer.4.attention.self.key.weight', 'encoder.layer.20.attention.output.LayerNorm.weight', 'encoder.layer.14.attention.self.query.bias', 'encoder.layer.23.attention.output.LayerNorm.weight', 'encoder.layer.8.attention.self.key.weight', 'encoder.layer.6.attention.output.LayerNorm.weight', 'encoder.layer.14.attention.self.key.bias', 'encoder.layer.14.output.LayerNorm.bias', 'encoder.layer.7.attention.output.LayerNorm.bias', 'encoder.layer.14.attention.self.key.weight', 'encoder.layer.8.output.LayerNorm.weight', 'encoder.layer.17.intermediate.dense.weight', 'encoder.layer.16.attention.output.LayerNorm.weight', 'encoder.layer.18.output.dense.weight', 'embeddings.LayerNorm.weight', 'encoder.layer.15.attention.self.query.weight', 'encoder.layer.12.output.LayerNorm.bias', 'encoder.layer.21.attention.self.value.weight', 'encoder.layer.8.attention.self.value.bias', 'encoder.layer.8.attention.output.LayerNorm.bias', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.2.attention.output.dense.weight', 'encoder.layer.11.output.LayerNorm.weight', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.6.attention.output.dense.bias', 'encoder.layer.8.output.LayerNorm.bias', 'encoder.layer.9.attention.self.query.bias', 'encoder.layer.16.attention.self.value.bias', 'encoder.layer.18.attention.self.value.bias', 'encoder.layer.10.attention.output.LayerNorm.weight', 'encoder.layer.18.intermediate.dense.bias', 'encoder.layer.8.attention.self.value.weight', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.0.output.dense.weight', 'encoder.layer.9.output.dense.weight', 'encoder.layer.20.attention.self.key.bias', 'encoder.layer.17.attention.self.value.bias', 'encoder.layer.14.attention.output.dense.weight', 'encoder.layer.13.output.LayerNorm.weight', 'encoder.layer.1.attention.self.key.bias', 'encoder.layer.8.attention.self.key.bias', 'encoder.layer.6.attention.output.LayerNorm.bias', 'encoder.layer.19.attention.self.query.weight', 'encoder.layer.17.attention.self.value.weight', 'encoder.layer.2.attention.self.query.weight', 'encoder.layer.17.attention.self.query.bias', 'encoder.layer.3.attention.self.key.bias', 'encoder.layer.12.intermediate.dense.bias', 'encoder.layer.15.intermediate.dense.bias', 'encoder.layer.14.intermediate.dense.bias', 'encoder.layer.14.attention.self.value.bias', 'encoder.layer.2.attention.self.query.bias', 'encoder.layer.1.attention.self.query.weight', 'encoder.layer.4.output.dense.bias', 'encoder.layer.8.attention.self.query.weight', 'encoder.layer.15.attention.output.dense.weight', 'encoder.layer.13.attention.self.key.bias', 'encoder.layer.16.attention.self.key.bias', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.22.attention.output.dense.weight', 'encoder.layer.6.attention.self.value.weight', 'encoder.layer.21.attention.self.key.bias', 'encoder.layer.21.attention.output.LayerNorm.weight', 'encoder.layer.0.attention.self.key.weight', 'encoder.layer.22.attention.output.dense.bias', 'encoder.layer.3.output.dense.weight', 'encoder.layer.13.attention.self.query.weight', 'encoder.layer.17.attention.self.key.weight', 'encoder.layer.8.attention.output.dense.weight', 'encoder.layer.10.attention.output.dense.bias', 'encoder.layer.4.output.LayerNorm.weight', 'embeddings.position_embeddings.weight', 'encoder.layer.19.attention.self.key.bias', 'encoder.layer.13.attention.self.value.weight', 'encoder.layer.9.attention.output.LayerNorm.weight', 'encoder.layer.17.attention.output.LayerNorm.bias', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.10.attention.output.LayerNorm.bias', 'encoder.layer.14.attention.self.value.weight', 'encoder.layer.15.output.LayerNorm.weight', 'encoder.layer.18.output.LayerNorm.weight', 'encoder.layer.3.attention.output.dense.weight', 'encoder.layer.6.attention.self.key.weight', 'encoder.layer.6.attention.self.value.bias', 'encoder.layer.11.output.dense.weight', 'encoder.layer.17.attention.output.LayerNorm.weight', 'encoder.layer.4.attention.self.value.bias', 'encoder.layer.7.output.dense.weight', 'encoder.layer.2.attention.output.LayerNorm.bias', 'encoder.layer.0.attention.self.query.weight', 'encoder.layer.17.output.LayerNorm.bias', 'encoder.layer.10.attention.self.query.weight', 'encoder.layer.16.output.LayerNorm.weight', 'encoder.layer.5.attention.output.dense.weight', 'encoder.layer.18.attention.self.key.weight', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.17.attention.output.dense.bias', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.21.intermediate.dense.weight', 'encoder.layer.15.attention.output.LayerNorm.weight', 'encoder.layer.12.output.dense.bias', 'encoder.layer.13.attention.output.dense.bias', 'encoder.layer.11.attention.output.dense.bias', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.18.attention.output.LayerNorm.bias', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.15.output.LayerNorm.bias', 'encoder.layer.19.attention.self.query.bias', 'encoder.layer.22.output.LayerNorm.weight', 'encoder.layer.15.output.dense.bias', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.22.attention.self.value.bias', 'encoder.layer.1.output.dense.weight', 'encoder.layer.6.output.dense.weight', 'encoder.layer.11.output.LayerNorm.bias', 'encoder.layer.4.attention.self.value.weight', 'encoder.layer.12.attention.output.dense.bias', 'encoder.layer.8.attention.self.query.bias', 'encoder.layer.19.intermediate.dense.weight', 'encoder.layer.3.attention.self.query.weight', 'encoder.layer.15.attention.self.value.weight', 'encoder.layer.8.output.dense.bias', 'encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.layer.22.attention.self.key.bias', 'encoder.layer.17.output.LayerNorm.weight', 'encoder.layer.22.intermediate.dense.weight', 'encoder.layer.14.attention.self.query.weight', 'encoder.layer.9.output.dense.bias', 'encoder.layer.2.attention.self.value.bias', 'encoder.layer.20.attention.self.key.weight', 'encoder.layer.9.attention.output.dense.weight', 'encoder.layer.12.attention.self.key.weight', 'encoder.layer.13.attention.self.key.weight', 'encoder.layer.9.attention.self.query.weight', 'encoder.layer.5.output.dense.bias', 'encoder.layer.11.attention.self.key.weight', 'encoder.layer.4.attention.output.dense.bias', 'encoder.layer.7.attention.self.query.weight', 'encoder.layer.17.attention.output.dense.weight', 'encoder.layer.12.attention.self.query.bias', 'encoder.layer.12.attention.self.value.weight', 'encoder.layer.20.output.LayerNorm.weight', 'encoder.layer.7.attention.self.key.bias', 'encoder.layer.10.intermediate.dense.weight', 'encoder.layer.10.output.dense.bias', 'encoder.layer.13.intermediate.dense.bias', 'encoder.layer.18.intermediate.dense.weight', 'encoder.layer.14.output.dense.bias', 'encoder.layer.23.attention.output.LayerNorm.bias', 'encoder.layer.2.attention.self.key.weight', 'encoder.layer.20.attention.self.value.bias', 'encoder.layer.10.output.dense.weight', 'encoder.layer.18.attention.self.key.bias', 'encoder.layer.21.output.LayerNorm.bias', 'embeddings.word_embeddings.weight', 'pooler.dense.weight', 'encoder.layer.6.output.dense.bias', 'encoder.layer.9.attention.self.value.bias', 'encoder.layer.19.output.dense.weight', 'encoder.layer.16.intermediate.dense.weight', 'encoder.layer.12.output.LayerNorm.weight', 'encoder.layer.17.attention.self.query.weight', 'encoder.layer.2.attention.self.key.bias', 'encoder.layer.7.attention.output.dense.weight', 'encoder.layer.6.attention.self.query.weight', 'encoder.layer.13.attention.self.query.bias', 'encoder.layer.1.attention.output.dense.weight', 'encoder.layer.21.attention.self.key.weight', 'encoder.layer.6.attention.self.query.bias', 'encoder.layer.12.attention.self.query.weight', 'encoder.layer.21.output.LayerNorm.weight', 'encoder.layer.19.attention.self.value.bias', 'encoder.layer.15.attention.self.key.weight', 'encoder.layer.15.attention.output.dense.bias', 'encoder.layer.4.attention.output.LayerNorm.bias', 'encoder.layer.2.output.dense.weight', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.11.attention.self.value.weight', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.0.attention.output.dense.bias', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.5.output.LayerNorm.bias', 'encoder.layer.21.output.dense.weight', 'encoder.layer.15.output.dense.weight', 'encoder.layer.22.output.dense.weight', 'encoder.layer.6.attention.output.dense.weight', 'encoder.layer.7.output.dense.bias', 'encoder.layer.22.attention.self.key.weight', 'encoder.layer.23.attention.self.value.weight', 'encoder.layer.18.attention.self.query.bias', 'encoder.layer.5.attention.self.query.weight', 'encoder.layer.12.attention.self.value.bias', 'encoder.layer.23.attention.self.key.bias', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.layer.20.intermediate.dense.bias', 'encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.layer.22.attention.self.query.weight', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.0.attention.self.query.bias', 'encoder.layer.3.output.dense.bias', 'encoder.layer.12.attention.self.key.bias', 'encoder.layer.19.attention.output.dense.bias', 'encoder.layer.19.intermediate.dense.bias', 'encoder.layer.14.output.dense.weight', 'encoder.layer.19.output.dense.bias', 'encoder.layer.10.attention.self.query.bias', 'encoder.layer.17.intermediate.dense.bias', 'encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.layer.10.attention.self.key.weight', 'encoder.layer.14.attention.output.LayerNorm.bias', 'encoder.layer.13.attention.output.LayerNorm.weight', 'encoder.layer.16.output.LayerNorm.bias', 'encoder.layer.11.attention.self.key.bias', 'encoder.layer.1.attention.self.value.weight', 'encoder.layer.15.intermediate.dense.weight', 'encoder.layer.19.attention.output.LayerNorm.weight', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.5.attention.self.key.weight', 'encoder.layer.4.attention.self.query.weight', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.19.output.LayerNorm.weight', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.15.attention.self.query.bias', 'encoder.layer.16.attention.self.query.weight', 'encoder.layer.3.attention.self.query.bias', 'encoder.layer.10.output.LayerNorm.bias', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.18.attention.self.query.weight', 'encoder.layer.22.output.dense.bias', 'encoder.layer.4.attention.self.key.bias', 'encoder.layer.18.attention.output.LayerNorm.weight', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.16.attention.output.dense.bias', 'encoder.layer.4.attention.self.query.bias', 'encoder.layer.2.attention.self.value.weight', 'encoder.layer.5.attention.self.value.weight', 'encoder.layer.21.attention.self.query.bias', 'encoder.layer.3.attention.output.dense.bias', 'encoder.layer.7.attention.self.value.bias', 'encoder.layer.0.attention.output.LayerNorm.weight', 'encoder.layer.11.attention.self.query.weight', 'encoder.layer.1.output.dense.bias', 'encoder.layer.15.attention.self.value.bias', 'encoder.layer.21.output.dense.bias', 'encoder.layer.1.attention.self.key.weight', 'encoder.layer.23.attention.output.dense.weight', 'encoder.layer.12.attention.output.LayerNorm.bias', 'encoder.layer.16.output.dense.bias', 'encoder.layer.5.attention.output.dense.bias', 'encoder.layer.18.output.dense.bias', 'encoder.layer.4.attention.output.LayerNorm.weight', 'encoder.layer.3.attention.self.value.bias', 'encoder.layer.16.output.dense.weight', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.layer.22.intermediate.dense.bias', 'encoder.layer.10.attention.self.value.weight', 'encoder.layer.6.attention.self.key.bias', 'encoder.layer.16.intermediate.dense.bias', 'encoder.layer.22.attention.output.LayerNorm.bias', 'encoder.layer.10.attention.self.key.bias', 'encoder.layer.20.attention.self.query.weight', 'encoder.layer.14.intermediate.dense.weight', 'encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.layer.20.attention.self.query.bias', 'encoder.layer.11.attention.self.query.bias', 'encoder.layer.20.intermediate.dense.weight', 'encoder.layer.18.attention.output.dense.weight', 'encoder.layer.20.output.dense.bias', 'encoder.layer.23.attention.output.dense.bias', 'encoder.layer.20.output.dense.weight', 'encoder.layer.0.attention.self.value.weight', 'encoder.layer.22.attention.self.query.bias', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.22.attention.output.LayerNorm.weight', 'encoder.layer.9.attention.output.dense.bias', 'encoder.layer.15.attention.output.LayerNorm.bias', 'encoder.layer.5.attention.self.key.bias', 'encoder.layer.9.attention.output.LayerNorm.bias', 'encoder.layer.21.attention.self.query.weight', 'encoder.layer.1.attention.self.query.bias', 'encoder.layer.0.output.dense.bias', 'encoder.layer.21.attention.output.dense.bias', 'encoder.layer.2.output.dense.bias', 'encoder.layer.12.attention.output.dense.weight', 'encoder.layer.0.attention.self.key.bias', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.11.attention.self.value.bias', 'encoder.layer.12.output.dense.weight', 'encoder.layer.13.output.dense.bias', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.16.attention.output.dense.weight', 'encoder.layer.20.attention.output.dense.bias', 'encoder.layer.23.output.dense.bias', 'encoder.layer.10.attention.self.value.bias', 'encoder.layer.5.attention.self.value.bias', 'encoder.layer.1.attention.output.LayerNorm.weight', 'pooler.dense.bias', 'encoder.layer.14.attention.output.dense.bias', 'encoder.layer.5.intermediate.dense.bias', 'embeddings.LayerNorm.bias', 'encoder.layer.7.output.LayerNorm.bias', 'encoder.layer.15.attention.self.key.bias', 'encoder.layer.16.attention.self.key.weight', 'encoder.layer.19.attention.output.LayerNorm.bias', 'encoder.layer.13.attention.output.LayerNorm.bias', 'encoder.layer.11.output.dense.bias', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.12.attention.output.LayerNorm.weight', 'encoder.layer.19.attention.self.key.weight', 'encoder.layer.23.attention.self.query.weight', 'encoder.layer.17.output.dense.bias', 'encoder.layer.21.attention.output.LayerNorm.bias', 'encoder.layer.12.intermediate.dense.weight', 'encoder.layer.17.output.dense.weight', 'encoder.layer.9.output.LayerNorm.weight', 'encoder.layer.11.attention.output.LayerNorm.weight', 'encoder.layer.9.attention.self.value.weight', 'encoder.layer.13.intermediate.dense.weight', 'encoder.layer.18.output.LayerNorm.bias', 'encoder.layer.13.output.LayerNorm.bias', 'encoder.layer.20.attention.output.dense.weight', 'encoder.layer.20.output.LayerNorm.bias', 'encoder.layer.8.output.dense.weight', 'encoder.layer.7.attention.self.query.bias', 'encoder.layer.6.output.LayerNorm.bias', 'encoder.layer.16.attention.output.LayerNorm.bias', 'encoder.layer.23.output.LayerNorm.bias', 'encoder.layer.11.attention.output.dense.weight', 'encoder.layer.0.attention.output.dense.weight', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.16.attention.self.value.weight', 'encoder.layer.8.attention.output.dense.bias', 'encoder.layer.7.attention.output.dense.bias', 'encoder.layer.23.attention.self.key.weight', 'encoder.layer.13.attention.output.dense.weight', 'encoder.layer.4.output.dense.weight', 'encoder.layer.7.attention.self.value.weight', 'encoder.layer.21.attention.self.value.bias', 'encoder.layer.13.output.dense.weight', 'encoder.layer.10.output.LayerNorm.weight', 'encoder.layer.5.output.dense.weight', 'encoder.layer.9.attention.self.key.bias', 'encoder.layer.1.attention.self.value.bias', 'encoder.layer.16.attention.self.query.bias', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.9.attention.self.key.weight', 'encoder.layer.21.attention.output.dense.weight', 'encoder.layer.7.output.LayerNorm.weight', 'encoder.layer.19.output.LayerNorm.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Overwriting existing adapter 'ep'.
Overwriting existing adapter 'tp'.
Overwriting existing adapter 'es'.
Overwriting existing adapter 'ts'.
Overwriting existing adapter fusion module 'ep,tp,es,ts'
05/09/2022 22:53:49 - INFO - __main__ -   Creating features from dataset file at .
/cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//tydiqa/xlm-KG_LR8e-6_EPOCH2.0_maxlen384_batchsize4_gradacc4
XLMConfig {
  "architectures": [
    "XLMRobertaForMaskedLM"
  ],
  "asm": false,
  "attention_dropout": 0.1,
  "attention_probs_dropout_prob": 0.1,
  "bos_index": 0,
  "bos_token_id": 0,
  "causal": false,
  "dropout": 0.1,
  "emb_dim": 1024,
  "embed_init_std": 0.02209708691207961,
  "end_n_top": 5,
  "eos_index": 1,
  "eos_token_id": 2,
  "gelu_activation": true,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "init_std": 0.02,
  "initializer_range": 0.02,
  "intermediate_size": 4096,
  "is_encoder": true,
  "lang_id": 0,
  "layer_norm_eps": 1e-05,
  "mask_index": 5,
  "mask_token_id": 0,
  "max_position_embeddings": 514,
  "model_type": "xlm",
  "n_heads": 16,
  "n_langs": 1,
  "n_layers": 24,
  "output_past": true,
  "pad_index": 2,
  "pad_token_id": 1,
  "sinusoidal_embeddings": false,
  "start_n_top": 5,
  "summary_activation": null,
  "summary_first_dropout": 0.1,
  "summary_proj_to_labels": true,
  "summary_type": "first",
  "summary_use_proj": true,
  "transformers_version": "4.17.0",
  "type_vocab_size": 1,
  "unk_index": 3,
  "use_lang_emb": false,
  "vocab_size": 250002
}

  0%|          | 0/782 [00:00<?, ?it/s] 52%|█████▏    | 405/782 [00:00<00:00, 4047.93it/s]100%|██████████| 782/782 [00:00<00:00, 4484.71it/s]
convert squad examples to features:   0%|          | 0/782 [00:00<?, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.
convert squad examples to features:   4%|▍         | 33/782 [00:00<00:04, 155.54it/s]convert squad examples to features:  12%|█▏        | 97/782 [00:00<00:02, 281.45it/s]convert squad examples to features:  21%|██        | 161/782 [00:00<00:02, 296.41it/s]convert squad examples to features:  29%|██▉       | 225/782 [00:00<00:01, 282.94it/s]convert squad examples to features:  33%|███▎      | 257/782 [00:00<00:02, 260.57it/s]convert squad examples to features:  41%|████      | 321/782 [00:01<00:01, 298.71it/s]convert squad examples to features:  45%|████▌     | 353/782 [00:01<00:01, 292.17it/s]convert squad examples to features:  49%|████▉     | 385/782 [00:01<00:01, 271.16it/s]convert squad examples to features:  57%|█████▋    | 449/782 [00:01<00:01, 282.29it/s]convert squad examples to features:  66%|██████▌   | 513/782 [00:01<00:00, 304.25it/s]convert squad examples to features:  74%|███████▍  | 577/782 [00:01<00:00, 326.25it/s]convert squad examples to features:  82%|████████▏ | 641/782 [00:02<00:00, 344.24it/s]convert squad examples to features:  90%|█████████ | 705/782 [00:02<00:00, 344.15it/s]convert squad examples to features:  95%|█████████▍| 740/782 [00:02<00:00, 340.50it/s]convert squad examples to features: 100%|██████████| 782/782 [00:02<00:00, 317.58it/s]/cluster/project/sachan/yifan/softwares/anaconda/anaconda3/envs/xfactr/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2272: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

add example index and unique id:   0%|          | 0/782 [00:00<?, ?it/s]add example index and unique id: 100%|██████████| 782/782 [00:00<00:00, 656120.37it/s]
05/09/2022 22:53:52 - INFO - __main__ -   Saving features into cached file ./cached_tydiqa.goldp.fi.dev.json_xlm-KG_LR8e-6_EPOCH2.0_maxlen384_batchsize4_gradacc4_384_fi
05/09/2022 22:53:52 - INFO - __main__ -   ***** Running evaluation  *****
05/09/2022 22:53:52 - INFO - __main__ -     Num examples = 811
05/09/2022 22:53:52 - INFO - __main__ -     Batch size = 8
Evaluating:   0%|          | 0/102 [00:00<?, ?it/s]Evaluating:   1%|          | 1/102 [00:00<01:24,  1.19it/s]Evaluating:   2%|▏         | 2/102 [00:01<00:55,  1.81it/s]Evaluating:   3%|▎         | 3/102 [00:01<00:45,  2.16it/s]Evaluating:   4%|▍         | 4/102 [00:01<00:41,  2.38it/s]Evaluating:   5%|▍         | 5/102 [00:02<00:38,  2.52it/s]Evaluating:   6%|▌         | 6/102 [00:02<00:36,  2.61it/s]Evaluating:   7%|▋         | 7/102 [00:02<00:35,  2.67it/s]Evaluating:   8%|▊         | 8/102 [00:03<00:34,  2.72it/s]Evaluating:   9%|▉         | 9/102 [00:03<00:33,  2.74it/s]Evaluating:  10%|▉         | 10/102 [00:04<00:33,  2.74it/s]Evaluating:  11%|█         | 11/102 [00:04<00:32,  2.76it/s]Evaluating:  12%|█▏        | 12/102 [00:04<00:32,  2.78it/s]Evaluating:  13%|█▎        | 13/102 [00:05<00:32,  2.77it/s]Evaluating:  14%|█▎        | 14/102 [00:05<00:31,  2.77it/s]Evaluating:  15%|█▍        | 15/102 [00:05<00:31,  2.77it/s]Evaluating:  16%|█▌        | 16/102 [00:06<00:31,  2.77it/s]Evaluating:  17%|█▋        | 17/102 [00:06<00:30,  2.77it/s]Evaluating:  18%|█▊        | 18/102 [00:06<00:30,  2.78it/s]Evaluating:  19%|█▊        | 19/102 [00:07<00:29,  2.79it/s]Evaluating:  20%|█▉        | 20/102 [00:07<00:29,  2.80it/s]Evaluating:  21%|██        | 21/102 [00:07<00:28,  2.81it/s]Evaluating:  22%|██▏       | 22/102 [00:08<00:28,  2.80it/s]Evaluating:  23%|██▎       | 23/102 [00:08<00:28,  2.80it/s]Evaluating:  24%|██▎       | 24/102 [00:09<00:27,  2.80it/s]Evaluating:  25%|██▍       | 25/102 [00:09<00:27,  2.80it/s]Evaluating:  25%|██▌       | 26/102 [00:09<00:27,  2.80it/s]Evaluating:  26%|██▋       | 27/102 [00:10<00:26,  2.80it/s]Evaluating:  27%|██▋       | 28/102 [00:10<00:26,  2.80it/s]Evaluating:  28%|██▊       | 29/102 [00:10<00:26,  2.80it/s]Evaluating:  29%|██▉       | 30/102 [00:11<00:25,  2.80it/s]Evaluating:  30%|███       | 31/102 [00:11<00:25,  2.79it/s]Evaluating:  31%|███▏      | 32/102 [00:11<00:25,  2.79it/s]Evaluating:  32%|███▏      | 33/102 [00:12<00:24,  2.79it/s]Evaluating:  33%|███▎      | 34/102 [00:12<00:24,  2.79it/s]Evaluating:  34%|███▍      | 35/102 [00:12<00:23,  2.79it/s]Evaluating:  35%|███▌      | 36/102 [00:13<00:23,  2.79it/s]Evaluating:  36%|███▋      | 37/102 [00:13<00:23,  2.78it/s]Evaluating:  37%|███▋      | 38/102 [00:14<00:22,  2.78it/s]Evaluating:  38%|███▊      | 39/102 [00:14<00:22,  2.79it/s]Evaluating:  39%|███▉      | 40/102 [00:14<00:22,  2.79it/s]Evaluating:  40%|████      | 41/102 [00:15<00:21,  2.79it/s]Evaluating:  41%|████      | 42/102 [00:15<00:21,  2.79it/s]Evaluating:  42%|████▏     | 43/102 [00:15<00:21,  2.79it/s]Evaluating:  43%|████▎     | 44/102 [00:16<00:20,  2.80it/s]Evaluating:  44%|████▍     | 45/102 [00:16<00:20,  2.78it/s]Evaluating:  45%|████▌     | 46/102 [00:16<00:20,  2.79it/s]Evaluating:  46%|████▌     | 47/102 [00:17<00:19,  2.79it/s]Evaluating:  47%|████▋     | 48/102 [00:17<00:19,  2.78it/s]Evaluating:  48%|████▊     | 49/102 [00:18<00:19,  2.77it/s]Evaluating:  49%|████▉     | 50/102 [00:18<00:18,  2.78it/s]Evaluating:  50%|█████     | 51/102 [00:18<00:18,  2.78it/s]Evaluating:  51%|█████     | 52/102 [00:19<00:17,  2.79it/s]Evaluating:  52%|█████▏    | 53/102 [00:19<00:17,  2.79it/s]Evaluating:  53%|█████▎    | 54/102 [00:19<00:17,  2.78it/s]Evaluating:  54%|█████▍    | 55/102 [00:20<00:16,  2.77it/s]Evaluating:  55%|█████▍    | 56/102 [00:20<00:16,  2.78it/s]Evaluating:  56%|█████▌    | 57/102 [00:20<00:16,  2.78it/s]Evaluating:  57%|█████▋    | 58/102 [00:21<00:15,  2.79it/s]Evaluating:  58%|█████▊    | 59/102 [00:21<00:15,  2.79it/s]Evaluating:  59%|█████▉    | 60/102 [00:21<00:15,  2.78it/s]Evaluating:  60%|█████▉    | 61/102 [00:22<00:14,  2.77it/s]Evaluating:  61%|██████    | 62/102 [00:22<00:14,  2.76it/s]Evaluating:  62%|██████▏   | 63/102 [00:23<00:14,  2.77it/s]Evaluating:  63%|██████▎   | 64/102 [00:23<00:13,  2.78it/s]Evaluating:  64%|██████▎   | 65/102 [00:23<00:13,  2.79it/s]Evaluating:  65%|██████▍   | 66/102 [00:24<00:12,  2.79it/s]Evaluating:  66%|██████▌   | 67/102 [00:24<00:12,  2.78it/s]Evaluating:  67%|██████▋   | 68/102 [00:24<00:12,  2.77it/s]Evaluating:  68%|██████▊   | 69/102 [00:25<00:11,  2.77it/s]Evaluating:  69%|██████▊   | 70/102 [00:25<00:11,  2.78it/s]Evaluating:  70%|██████▉   | 71/102 [00:25<00:11,  2.78it/s]Evaluating:  71%|███████   | 72/102 [00:26<00:10,  2.78it/s]Evaluating:  72%|███████▏  | 73/102 [00:26<00:10,  2.79it/s]Evaluating:  73%|███████▎  | 74/102 [00:27<00:10,  2.79it/s]Evaluating:  74%|███████▎  | 75/102 [00:27<00:09,  2.79it/s]Evaluating:  75%|███████▍  | 76/102 [00:27<00:09,  2.79it/s]Evaluating:  75%|███████▌  | 77/102 [00:28<00:08,  2.79it/s]Evaluating:  76%|███████▋  | 78/102 [00:28<00:08,  2.78it/s]Evaluating:  77%|███████▋  | 79/102 [00:28<00:08,  2.78it/s]Evaluating:  78%|███████▊  | 80/102 [00:29<00:07,  2.79it/s]Evaluating:  79%|███████▉  | 81/102 [00:29<00:07,  2.78it/s]Evaluating:  80%|████████  | 82/102 [00:29<00:07,  2.78it/s]Evaluating:  81%|████████▏ | 83/102 [00:30<00:06,  2.78it/s]Evaluating:  82%|████████▏ | 84/102 [00:30<00:06,  2.77it/s]Evaluating:  83%|████████▎ | 85/102 [00:30<00:06,  2.78it/s]Evaluating:  84%|████████▍ | 86/102 [00:31<00:05,  2.77it/s]Evaluating:  85%|████████▌ | 87/102 [00:31<00:05,  2.78it/s]Evaluating:  86%|████████▋ | 88/102 [00:32<00:05,  2.77it/s]Evaluating:  87%|████████▋ | 89/102 [00:32<00:04,  2.77it/s]Evaluating:  88%|████████▊ | 90/102 [00:32<00:04,  2.78it/s]Evaluating:  89%|████████▉ | 91/102 [00:33<00:03,  2.78it/s]Evaluating:  90%|█████████ | 92/102 [00:33<00:03,  2.78it/s]Evaluating:  91%|█████████ | 93/102 [00:33<00:03,  2.78it/s]Evaluating:  92%|█████████▏| 94/102 [00:34<00:02,  2.79it/s]Evaluating:  93%|█████████▎| 95/102 [00:34<00:02,  2.78it/s]Evaluating:  94%|█████████▍| 96/102 [00:34<00:02,  2.78it/s]Evaluating:  95%|█████████▌| 97/102 [00:35<00:01,  2.78it/s]Evaluating:  96%|█████████▌| 98/102 [00:35<00:01,  2.78it/s]Evaluating:  97%|█████████▋| 99/102 [00:36<00:01,  2.78it/s]Evaluating:  98%|█████████▊| 100/102 [00:36<00:00,  2.79it/s]Evaluating:  99%|█████████▉| 101/102 [00:36<00:00,  2.78it/s]Evaluating: 100%|██████████| 102/102 [00:36<00:00,  3.42it/s]Evaluating: 100%|██████████| 102/102 [00:36<00:00,  2.77it/s]
05/09/2022 22:54:29 - INFO - __main__ -     Evaluation done in total 36.861307 secs (0.045452 sec per example)
05/09/2022 22:54:32 - INFO - __main__ -   Results: {'exact': 62.40409207161125, 'f1': 76.46173104744543, 'total': 782, 'HasAns_exact': 62.40409207161125, 'HasAns_f1': 76.46173104744543, 'HasAns_total': 782, 'best_exact': 62.40409207161125, 'best_exact_thresh': 0.0, 'best_f1': 76.46173104744543, 'best_f1_thresh': 0.0}
  id 
2022-05-09 22:54:35.442736: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0
05/09/2022 22:54:38 - WARNING - __main__ -   Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, 16-bits training: False
You are using a model of type xlm-roberta to instantiate a model of type xlm. This is not supported for all configurations of models and can yield errors.
Some weights of the model checkpoint at /cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//tydiqa/xlm-KG_LR8e-6_EPOCH2.0_maxlen384_batchsize4_gradacc4 were not used when initializing XLMRobertaModel: ['base_model.encoder.layer.11.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.2.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.10.attention.self.key.bias', 'base_model.encoder.layer.12.attention.self.key.weight', 'base_model.encoder.layer.12.intermediate.dense.weight', 'base_model.encoder.layer.18.output.LayerNorm.bias', 'base_model.encoder.layer.4.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.5.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.17.attention.output.dense.bias', 'base_model.encoder.layer.16.attention.self.query.bias', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.2.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.22.output.dense.bias', 'base_model.encoder.layer.15.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.14.attention.output.dense.bias', 'base_model.encoder.layer.14.attention.output.LayerNorm.weight', 'base_model.encoder.layer.15.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.0.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.11.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.17.attention.output.LayerNorm.bias', 'base_model.encoder.layer.12.attention.output.LayerNorm.bias', 'base_model.encoder.layer.10.output.LayerNorm.bias', 'base_model.encoder.layer.16.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.7.attention.self.key.weight', 'base_model.encoder.layer.11.attention.self.value.bias', 'base_model.encoder.layer.5.intermediate.dense.weight', 'base_model.encoder.layer.3.attention.self.value.bias', 'base_model.encoder.layer.23.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.12.attention.output.dense.weight', 'base_model.encoder.layer.3.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.9.attention.self.value.weight', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.17.attention.self.value.weight', 'base_model.encoder.layer.10.attention.self.value.weight', 'base_model.encoder.layer.22.attention.self.value.bias', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.7.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.17.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.15.output.LayerNorm.bias', 'base_model.encoder.layer.13.output.LayerNorm.bias', 'base_model.encoder.layer.14.output.dense.weight', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.3.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.8.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.18.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.22.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.14.intermediate.dense.weight', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.1.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.21.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.11.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.6.attention.self.key.bias', 'base_model.encoder.layer.9.attention.output.dense.bias', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.4.attention.self.query.weight', 'base_model.encoder.layer.20.attention.self.value.weight', 'base_model.encoder.layer.9.output.LayerNorm.bias', 'base_model.encoder.layer.21.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.23.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.11.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.6.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.6.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.5.intermediate.dense.bias', 'base_model.encoder.layer.13.attention.output.LayerNorm.weight', 'base_model.encoder.layer.14.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.2.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.19.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.5.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.15.output.LayerNorm.weight', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.8.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.10.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.10.output.adapters.tp.adapter_down.0.weight', 'base_model.embeddings.LayerNorm.weight', 'base_model.encoder.layer.13.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.18.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.12.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.10.output.dense.bias', 'base_model.encoder.layer.21.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.2.output.dense.bias', 'base_model.encoder.layer.10.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.16.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.20.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.23.attention.self.key.weight', 'base_model.encoder.layer.16.attention.self.value.weight', 'base_model.encoder.layer.12.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.7.attention.self.query.bias', 'base_model.encoder.layer.2.output.LayerNorm.bias', 'base_model.encoder.layer.10.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.5.attention.output.LayerNorm.weight', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.21.attention.output.LayerNorm.weight', 'base_model.encoder.layer.19.attention.self.value.bias', 'base_model.encoder.layer.20.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.10.output.LayerNorm.weight', 'base_model.encoder.layer.20.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.12.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.5.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.18.output.dense.bias', 'base_model.encoder.layer.18.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.21.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.11.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.16.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.22.output.LayerNorm.weight', 'base_model.encoder.layer.0.attention.output.dense.weight', 'base_model.encoder.layer.23.intermediate.dense.weight', 'base_model.encoder.layer.5.output.dense.weight', 'base_model.encoder.layer.9.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.8.output.dense.bias', 'base_model.encoder.layer.17.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.23.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.22.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.19.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.7.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.21.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.21.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.4.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.5.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.3.output.LayerNorm.bias', 'base_model.encoder.layer.9.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.6.attention.self.value.bias', 'base_model.encoder.layer.23.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.3.attention.output.dense.weight', 'base_model.encoder.layer.3.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.3.attention.self.query.bias', 'base_model.encoder.layer.1.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.14.attention.output.dense.weight', 'base_model.encoder.layer.10.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.19.attention.output.LayerNorm.weight', 'base_model.encoder.layer.19.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.0.attention.self.key.weight', 'base_model.encoder.layer.16.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.4.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.0.attention.self.value.weight', 'base_model.encoder.layer.12.output.LayerNorm.bias', 'base_model.encoder.layer.12.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.20.output.dense.bias', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.19.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.2.attention.output.dense.bias', 'base_model.encoder.layer.4.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.16.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.2.attention.output.dense.weight', 'base_model.encoder.layer.19.attention.self.query.weight', 'base_model.encoder.layer.3.output.dense.weight', 'base_model.encoder.layer.17.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.4.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.20.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.2.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.3.output.LayerNorm.weight', 'base_model.encoder.layer.9.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.15.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.6.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.8.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.1.attention.output.LayerNorm.weight', 'base_model.encoder.layer.14.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.22.output.dense.weight', 'base_model.encoder.layer.7.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.16.attention.self.query.weight', 'base_model.encoder.layer.22.attention.self.query.weight', 'base_model.encoder.layer.8.intermediate.dense.bias', 'base_model.encoder.layer.4.attention.output.dense.weight', 'base_model.encoder.layer.4.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.4.output.LayerNorm.bias', 'base_model.encoder.layer.20.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.12.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.21.output.dense.bias', 'base_model.encoder.layer.2.attention.output.LayerNorm.weight', 'base_model.encoder.layer.1.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.11.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.19.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.20.attention.output.dense.weight', 'base_model.encoder.layer.22.attention.output.dense.weight', 'base_model.encoder.layer.20.attention.self.value.bias', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.4.attention.self.key.weight', 'base_model.encoder.layer.10.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.12.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.18.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.6.attention.self.query.bias', 'base_model.encoder.layer.0.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.7.attention.output.dense.bias', 'base_model.encoder.layer.4.attention.output.dense.bias', 'base_model.encoder.layer.1.output.dense.bias', 'base_model.encoder.layer.2.attention.self.key.bias', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.18.attention.self.key.weight', 'base_model.encoder.layer.23.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.20.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.23.output.dense.weight', 'base_model.encoder.layer.17.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.11.attention.self.key.bias', 'base_model.encoder.layer.13.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.17.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.22.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.16.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.6.attention.output.LayerNorm.weight', 'base_model.encoder.layer.4.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.20.attention.output.LayerNorm.weight', 'base_model.encoder.layer.10.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.22.intermediate.dense.bias', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.11.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.20.intermediate.dense.weight', 'base_model.encoder.layer.6.output.LayerNorm.weight', 'base_model.encoder.layer.21.output.LayerNorm.bias', 'base_model.encoder.layer.18.attention.self.value.bias', 'base_model.encoder.layer.8.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.13.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.15.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.16.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.9.output.LayerNorm.weight', 'base_model.encoder.layer.18.attention.self.key.bias', 'base_model.encoder.layer.3.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.4.intermediate.dense.weight', 'base_model.encoder.layer.17.intermediate.dense.bias', 'base_model.encoder.layer.10.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.9.intermediate.dense.weight', 'base_model.encoder.layer.19.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.8.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.17.output.LayerNorm.weight', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.7.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.17.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.4.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.13.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.14.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.8.output.LayerNorm.weight', 'base_model.encoder.layer.10.attention.self.value.bias', 'base_model.encoder.layer.6.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.11.attention.output.dense.weight', 'base_model.encoder.layer.17.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.16.output.dense.weight', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.16.output.LayerNorm.weight', 'base_model.encoder.layer.23.output.dense.bias', 'base_model.encoder.layer.8.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.8.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.8.attention.output.LayerNorm.bias', 'base_model.encoder.layer.5.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.19.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.18.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.2.attention.self.value.weight', 'base_model.encoder.layer.2.output.dense.weight', 'base_model.encoder.layer.6.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.3.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.20.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.2.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.23.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.14.attention.self.query.weight', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.22.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.17.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.5.attention.self.value.bias', 'base_model.encoder.layer.21.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.9.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.2.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.22.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.0.attention.output.dense.bias', 'base_model.encoder.layer.23.intermediate.dense.bias', 'base_model.encoder.layer.7.attention.self.key.bias', 'base_model.encoder.layer.4.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.12.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.14.attention.self.value.weight', 'base_model.encoder.layer.10.attention.output.LayerNorm.weight', 'base_model.encoder.layer.16.attention.output.LayerNorm.weight', 'base_model.encoder.layer.12.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.21.output.LayerNorm.weight', 'base_model.encoder.layer.16.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.15.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.2.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.13.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.11.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.19.attention.output.dense.bias', 'base_model.encoder.layer.8.attention.self.query.weight', 'base_model.encoder.layer.9.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.5.attention.output.LayerNorm.bias', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.13.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.16.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.2.attention.self.query.weight', 'base_model.encoder.layer.18.attention.output.dense.weight', 'base_model.encoder.layer.8.attention.output.LayerNorm.weight', 'base_model.encoder.layer.9.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.18.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.14.attention.output.LayerNorm.bias', 'base_model.encoder.layer.19.output.dense.weight', 'base_model.encoder.layer.11.attention.self.value.weight', 'base_model.encoder.layer.20.intermediate.dense.bias', 'base_model.encoder.layer.23.attention.self.value.weight', 'base_model.encoder.layer.17.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.3.attention.self.query.weight', 'base_model.encoder.layer.19.attention.self.query.bias', 'base_model.encoder.layer.19.output.LayerNorm.weight', 'base_model.encoder.layer.17.output.dense.bias', 'base_model.encoder.layer.11.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.10.intermediate.dense.weight', 'base_model.encoder.layer.18.intermediate.dense.weight', 'base_model.encoder.layer.21.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.14.attention.self.key.bias', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.19.output.dense.bias', 'base_model.encoder.layer.23.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.8.attention.output.dense.bias', 'base_model.encoder.layer.15.intermediate.dense.weight', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.0.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.19.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.20.attention.output.dense.bias', 'base_model.pooler.dense.bias', 'base_model.encoder.layer.19.attention.self.value.weight', 'base_model.encoder.layer.18.attention.self.query.weight', 'base_model.encoder.layer.14.attention.self.value.bias', 'base_model.encoder.layer.17.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.20.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.13.attention.self.query.weight', 'base_model.encoder.layer.0.attention.self.query.bias', 'base_model.encoder.layer.0.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.19.output.LayerNorm.bias', 'base_model.encoder.layer.20.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.21.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.7.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.9.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.7.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.23.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.10.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.6.attention.self.key.weight', 'base_model.encoder.layer.11.attention.output.LayerNorm.weight', 'base_model.encoder.layer.4.attention.self.value.weight', 'base_model.embeddings.LayerNorm.bias', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.1.attention.self.query.weight', 'base_model.encoder.layer.1.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.5.attention.self.value.weight', 'base_model.encoder.layer.19.intermediate.dense.bias', 'base_model.encoder.layer.15.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.13.attention.self.value.bias', 'base_model.encoder.layer.22.intermediate.dense.weight', 'base_model.encoder.layer.14.attention.self.key.weight', 'base_model.encoder.layer.22.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.1.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.23.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.5.attention.self.key.weight', 'base_model.encoder.layer.21.attention.self.key.bias', 'base_model.encoder.layer.18.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.19.attention.output.LayerNorm.bias', 'base_model.encoder.layer.7.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.18.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.17.attention.self.query.weight', 'base_model.encoder.layer.13.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.16.attention.output.LayerNorm.bias', 'base_model.encoder.layer.4.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.12.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.16.output.dense.bias', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.9.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.1.output.LayerNorm.bias', 'base_model.encoder.layer.0.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.9.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.12.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.1.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.5.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.13.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.19.attention.self.key.weight', 'base_model.encoder.layer.8.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.6.output.dense.weight', 'base_model.encoder.layer.1.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.5.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.13.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.11.attention.self.key.weight', 'base_model.encoder.layer.2.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.7.output.LayerNorm.weight', 'base_model.encoder.layer.5.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.13.output.dense.weight', 'base_model.encoder.layer.0.intermediate.dense.bias', 'base_model.encoder.layer.4.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.13.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.15.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.11.output.LayerNorm.weight', 'base_model.encoder.layer.6.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.6.attention.output.dense.bias', 'base_model.encoder.layer.2.output.LayerNorm.weight', 'base_model.encoder.layer.18.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.20.output.dense.weight', 'base_model.encoder.layer.20.attention.self.query.weight', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.20.attention.output.LayerNorm.bias', 'base_model.encoder.layer.22.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.9.output.dense.weight', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.22.attention.output.LayerNorm.bias', 'base_model.encoder.layer.15.attention.output.dense.bias', 'base_model.encoder.layer.0.attention.output.LayerNorm.weight', 'base_model.encoder.layer.6.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.10.attention.output.dense.bias', 'base_model.encoder.layer.15.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.13.attention.self.key.bias', 'base_model.encoder.layer.18.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.3.output.dense.bias', 'base_model.encoder.layer.10.attention.self.query.bias', 'base_model.encoder.layer.12.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.19.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.18.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.5.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.8.attention.self.query.bias', 'base_model.encoder.layer.5.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.8.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.18.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.17.attention.output.LayerNorm.weight', 'base_model.encoder.layer.19.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.20.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.2.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.15.intermediate.dense.bias', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.12.output.dense.bias', 'base_model.encoder.layer.10.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.1.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.14.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.4.attention.self.key.bias', 'base_model.encoder.layer.13.attention.output.dense.bias', 'base_model.encoder.layer.0.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.5.output.dense.bias', 'base_model.encoder.layer.22.attention.self.query.bias', 'base_model.encoder.layer.11.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.1.attention.output.LayerNorm.bias', 'base_model.encoder.layer.0.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.2.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.4.attention.output.LayerNorm.bias', 'base_model.encoder.layer.14.intermediate.dense.bias', 'base_model.encoder.layer.0.attention.output.LayerNorm.bias', 'base_model.encoder.layer.0.output.LayerNorm.weight', 'base_model.encoder.layer.18.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.18.attention.self.value.weight', 'base_model.encoder.layer.4.attention.self.query.bias', 'base_model.encoder.layer.9.intermediate.dense.bias', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.4.attention.self.value.bias', 'base_model.encoder.layer.8.attention.self.value.bias', 'base_model.encoder.layer.11.attention.self.query.weight', 'base_model.encoder.layer.6.intermediate.dense.weight', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.13.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.4.attention.output.LayerNorm.weight', 'base_model.encoder.layer.1.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.8.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.2.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.8.output.LayerNorm.bias', 'base_model.encoder.layer.9.attention.self.query.weight', 'base_model.encoder.layer.10.intermediate.dense.bias', 'base_model.encoder.layer.12.intermediate.dense.bias', 'base_model.encoder.layer.2.attention.self.value.bias', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.9.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.12.attention.self.key.bias', 'base_model.encoder.layer.23.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.12.attention.self.value.weight', 'base_model.encoder.layer.22.attention.self.key.bias', 'base_model.encoder.layer.10.attention.self.query.weight', 'base_model.encoder.layer.1.output.LayerNorm.weight', 'base_model.encoder.layer.9.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.16.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.6.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.17.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.17.attention.self.key.weight', 'base_model.encoder.layer.9.attention.self.key.bias', 'base_model.encoder.layer.11.output.dense.weight', 'base_model.encoder.layer.21.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.6.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.5.attention.output.dense.bias', 'base_model.encoder.layer.0.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.2.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.14.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.21.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.14.output.dense.bias', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.0.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.23.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.6.intermediate.dense.bias', 'base_model.encoder.layer.22.attention.output.dense.bias', 'base_model.encoder.layer.21.attention.self.value.weight', 'base_model.encoder.layer.22.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.1.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.15.attention.self.key.weight', 'base_model.encoder.layer.17.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.23.attention.self.key.bias', 'base_model.encoder.layer.3.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.16.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.5.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.12.attention.output.dense.bias', 'base_model.encoder.layer.15.attention.self.query.weight', 'base_model.encoder.layer.8.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.15.attention.self.query.bias', 'base_model.encoder.layer.5.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.18.intermediate.dense.bias', 'base_model.encoder.layer.20.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.22.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.23.output.LayerNorm.bias', 'base_model.encoder.layer.14.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.7.output.LayerNorm.bias', 'base_model.encoder.layer.12.output.LayerNorm.weight', 'base_model.encoder.layer.19.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.17.intermediate.dense.weight', 'base_model.encoder.layer.1.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.8.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.18.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.7.attention.self.value.weight', 'base_model.encoder.layer.7.intermediate.dense.weight', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.17.output.dense.weight', 'base_model.encoder.layer.21.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.1.attention.self.value.bias', 'base_model.encoder.layer.7.attention.output.dense.weight', 'base_model.encoder.layer.16.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.13.attention.self.value.weight', 'base_model.encoder.layer.22.attention.self.key.weight', 'base_model.encoder.layer.23.attention.output.LayerNorm.weight', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.1.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.15.attention.output.LayerNorm.bias', 'base_model.encoder.layer.8.attention.self.value.weight', 'base_model.encoder.layer.14.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.5.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.21.intermediate.dense.weight', 'base_model.encoder.layer.7.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.14.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.22.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.18.attention.output.LayerNorm.bias', 'base_model.encoder.layer.15.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.12.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.15.attention.self.value.weight', 'base_model.encoder.layer.7.attention.self.value.bias', 'base_model.encoder.layer.11.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.5.attention.output.dense.weight', 'base_model.encoder.layer.22.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.10.attention.output.dense.weight', 'base_model.encoder.layer.22.output.adapters.es.adapter_down.0.bias', 'base_model.embeddings.position_ids', 'base_model.encoder.layer.6.attention.output.LayerNorm.bias', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.15.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.0.attention.self.key.bias', 'base_model.encoder.layer.5.attention.self.key.bias', 'base_model.encoder.layer.13.output.dense.bias', 'base_model.encoder.layer.18.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.20.attention.self.key.weight', 'base_model.encoder.layer.5.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.14.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.14.output.LayerNorm.weight', 'base_model.encoder.layer.22.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.1.intermediate.dense.bias', 'base_model.encoder.layer.9.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.0.attention.self.value.bias', 'base_model.encoder.layer.7.attention.output.LayerNorm.bias', 'base_model.encoder.layer.10.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.14.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.18.output.LayerNorm.weight', 'base_model.encoder.layer.9.attention.output.LayerNorm.bias', 'base_model.encoder.layer.9.attention.self.query.bias', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.20.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.20.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.1.attention.self.value.weight', 'base_model.encoder.layer.11.output.dense.bias', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.11.output.LayerNorm.bias', 'base_model.encoder.layer.13.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.0.output.LayerNorm.bias', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.7.attention.output.LayerNorm.weight', 'base_model.encoder.layer.18.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.19.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.22.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'qa_outputs.bias', 'base_model.encoder.layer.11.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.9.attention.self.value.bias', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.1.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.6.output.LayerNorm.bias', 'base_model.encoder.layer.15.attention.output.dense.weight', 'base_model.encoder.layer.6.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.15.output.dense.weight', 'base_model.encoder.layer.18.attention.output.dense.bias', 'base_model.encoder.layer.23.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.1.output.dense.weight', 'base_model.embeddings.word_embeddings.weight', 'base_model.encoder.layer.20.output.LayerNorm.weight', 'base_model.encoder.layer.16.intermediate.dense.bias', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.16.output.LayerNorm.bias', 'base_model.encoder.layer.5.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.7.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.4.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.9.attention.output.dense.weight', 'base_model.encoder.layer.23.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.1.attention.self.key.weight', 'base_model.encoder.layer.7.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.10.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.8.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.21.attention.self.query.bias', 'base_model.encoder.layer.6.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.7.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.2.intermediate.dense.bias', 'base_model.encoder.layer.6.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.15.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.16.attention.output.dense.bias', 'base_model.encoder.layer.20.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.11.attention.self.query.bias', 'base_model.encoder.layer.12.attention.self.query.bias', 'base_model.encoder.layer.3.intermediate.dense.bias', 'base_model.encoder.layer.16.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.20.attention.self.key.bias', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.15.attention.output.LayerNorm.weight', 'base_model.encoder.layer.18.attention.output.LayerNorm.weight', 'base_model.encoder.layer.23.attention.output.LayerNorm.bias', 'base_model.encoder.layer.13.intermediate.dense.weight', 'base_model.encoder.layer.11.intermediate.dense.bias', 'base_model.encoder.layer.7.attention.self.query.weight', 'base_model.encoder.layer.15.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.14.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.13.intermediate.dense.bias', 'base_model.encoder.layer.21.attention.self.query.weight', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.15.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.12.output.dense.weight', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.17.output.LayerNorm.bias', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.12.attention.output.LayerNorm.weight', 'base_model.encoder.layer.4.output.dense.weight', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.13.attention.output.dense.weight', 'base_model.encoder.layer.11.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.3.attention.self.key.bias', 'base_model.encoder.layer.13.attention.self.query.bias', 'base_model.encoder.layer.5.output.LayerNorm.weight', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.13.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.7.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.12.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.6.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.21.intermediate.dense.bias', 'base_model.encoder.layer.17.attention.self.query.bias', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.3.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.11.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.7.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.6.output.dense.bias', 'base_model.encoder.layer.2.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.19.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.14.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.16.attention.output.dense.weight', 'base_model.encoder.layer.0.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.3.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.17.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.3.attention.output.LayerNorm.bias', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.6.attention.output.dense.weight', 'base_model.encoder.layer.8.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.19.intermediate.dense.weight', 'base_model.encoder.layer.17.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.21.attention.output.dense.weight', 'base_model.encoder.layer.6.attention.self.value.weight', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.10.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.6.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.6.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.15.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.2.attention.output.LayerNorm.bias', 'base_model.encoder.layer.21.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.22.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.23.attention.self.query.bias', 'base_model.encoder.layer.9.output.dense.bias', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.14.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.21.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.7.output.dense.weight', 'base_model.encoder.layer.0.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.19.attention.output.dense.weight', 'base_model.encoder.layer.9.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.5.attention.self.query.weight', 'base_model.encoder.layer.11.attention.output.LayerNorm.bias', 'base_model.encoder.layer.7.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.17.attention.self.value.bias', 'base_model.encoder.layer.11.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.17.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.22.output.LayerNorm.bias', 'base_model.encoder.layer.11.intermediate.dense.weight', 'base_model.encoder.layer.14.attention.self.query.bias', 'base_model.encoder.layer.1.attention.self.query.bias', 'base_model.encoder.layer.16.attention.self.key.weight', 'base_model.encoder.layer.3.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.4.output.dense.bias', 'base_model.encoder.layer.10.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.3.attention.output.dense.bias', 'base_model.encoder.layer.23.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.17.attention.self.key.bias', 'base_model.encoder.layer.12.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.15.output.dense.bias', 'base_model.encoder.layer.21.attention.output.LayerNorm.bias', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.23.attention.self.query.weight', 'base_model.encoder.layer.0.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.16.attention.self.key.bias', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.21.attention.self.value.bias', 'base_model.encoder.layer.3.attention.output.LayerNorm.weight', 'base_model.encoder.layer.16.intermediate.dense.weight', 'base_model.encoder.layer.7.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.13.attention.self.key.weight', 'base_model.encoder.layer.19.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.14.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.9.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.1.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.23.attention.self.value.bias', 'base_model.encoder.layer.2.intermediate.dense.weight', 'base_model.encoder.layer.19.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.23.attention.output.dense.bias', 'base_model.encoder.layer.4.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.7.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.2.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.0.output.dense.bias', 'base_model.encoder.layer.8.attention.output.dense.weight', 'base_model.encoder.layer.15.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.3.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.8.attention.self.key.bias', 'base_model.encoder.layer.14.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.6.attention.self.query.weight', 'base_model.encoder.layer.8.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.4.output.LayerNorm.weight', 'base_model.encoder.layer.9.attention.output.LayerNorm.weight', 'base_model.encoder.layer.18.output.dense.weight', 'base_model.embeddings.position_embeddings.weight', 'base_model.encoder.layer.13.output.LayerNorm.weight', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.8.attention.self.key.weight', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.7.intermediate.dense.bias', 'base_model.encoder.layer.4.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.15.attention.self.value.bias', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.21.attention.output.dense.bias', 'base_model.encoder.layer.4.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.4.intermediate.dense.bias', 'base_model.encoder.layer.20.output.LayerNorm.bias', 'base_model.encoder.layer.20.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.23.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.3.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.12.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.20.attention.self.query.bias', 'base_model.encoder.layer.2.attention.self.query.bias', 'base_model.embeddings.token_type_embeddings.weight', 'base_model.encoder.layer.3.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.8.intermediate.dense.weight', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.10.output.dense.weight', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.13.attention.output.LayerNorm.bias', 'base_model.encoder.layer.6.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.10.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.0.intermediate.dense.weight', 'base_model.encoder.layer.15.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.1.attention.self.key.bias', 'base_model.encoder.layer.3.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.0.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.3.attention.self.key.weight', 'base_model.encoder.layer.1.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.5.attention.self.query.bias', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.16.attention.self.value.bias', 'base_model.encoder.layer.19.attention.self.key.bias', 'base_model.encoder.layer.10.attention.self.key.weight', 'qa_outputs.weight', 'base_model.encoder.layer.20.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.9.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.0.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.18.attention.self.query.bias', 'base_model.encoder.layer.8.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.13.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.3.attention.self.value.weight', 'base_model.encoder.layer.21.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.23.output.LayerNorm.weight', 'base_model.encoder.layer.9.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.11.attention.output.dense.bias', 'base_model.encoder.layer.0.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.12.attention.self.query.weight', 'base_model.encoder.layer.1.attention.output.dense.bias', 'base_model.encoder.layer.13.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.19.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.23.attention.output.dense.weight', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.14.output.LayerNorm.bias', 'base_model.encoder.layer.12.output.adapters.ep.adapter_down.0.weight', 'base_model.pooler.dense.weight', 'base_model.encoder.layer.23.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.3.intermediate.dense.weight', 'base_model.encoder.layer.16.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.7.output.dense.bias', 'base_model.encoder.layer.22.attention.self.value.weight', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.21.output.dense.weight', 'base_model.encoder.layer.3.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.10.attention.output.LayerNorm.bias', 'base_model.encoder.layer.22.attention.output.LayerNorm.weight', 'base_model.encoder.layer.5.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.0.attention.self.query.weight', 'base_model.encoder.layer.3.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.1.attention.output.dense.weight', 'base_model.encoder.layer.0.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.10.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.3.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.14.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.1.intermediate.dense.weight', 'base_model.encoder.layer.9.attention.self.key.weight', 'base_model.encoder.layer.2.attention.self.key.weight', 'base_model.encoder.layer.11.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.16.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.22.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.13.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.2.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.17.attention.output.dense.weight', 'base_model.encoder.layer.0.output.dense.weight', 'base_model.encoder.layer.8.output.dense.weight', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.5.output.LayerNorm.bias', 'base_model.encoder.layer.12.attention.self.value.bias', 'base_model.encoder.layer.4.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.1.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.15.attention.self.key.bias', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.2.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.16.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.21.attention.self.key.weight', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.17.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.21.output.adapters.es.adapter_up.bias']
- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of XLMRobertaModel were not initialized from the model checkpoint at /cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//tydiqa/xlm-KG_LR8e-6_EPOCH2.0_maxlen384_batchsize4_gradacc4 and are newly initialized: ['encoder.layer.9.attention.output.dense.bias', 'encoder.layer.13.output.dense.bias', 'encoder.layer.10.output.LayerNorm.weight', 'encoder.layer.18.attention.self.key.bias', 'encoder.layer.16.intermediate.dense.bias', 'encoder.layer.2.attention.output.dense.weight', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.14.attention.self.key.bias', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.16.attention.self.query.bias', 'encoder.layer.17.output.dense.weight', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.16.attention.self.key.weight', 'encoder.layer.4.output.dense.bias', 'encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.10.attention.self.key.bias', 'encoder.layer.14.attention.self.query.bias', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.17.attention.output.LayerNorm.weight', 'encoder.layer.21.output.LayerNorm.bias', 'encoder.layer.17.output.dense.bias', 'encoder.layer.18.attention.output.dense.weight', 'encoder.layer.18.intermediate.dense.bias', 'encoder.layer.11.output.LayerNorm.bias', 'encoder.layer.22.output.LayerNorm.weight', 'encoder.layer.7.output.LayerNorm.bias', 'encoder.layer.3.attention.output.dense.weight', 'encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.layer.20.intermediate.dense.bias', 'encoder.layer.6.attention.output.dense.bias', 'encoder.layer.23.output.LayerNorm.bias', 'encoder.layer.14.attention.output.dense.weight', 'encoder.layer.17.attention.self.query.bias', 'encoder.layer.17.intermediate.dense.weight', 'encoder.layer.8.output.LayerNorm.bias', 'encoder.layer.7.attention.self.key.bias', 'encoder.layer.20.attention.output.LayerNorm.weight', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.6.attention.output.LayerNorm.weight', 'encoder.layer.4.attention.self.key.bias', 'encoder.layer.19.output.dense.weight', 'encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.12.attention.output.LayerNorm.bias', 'encoder.layer.19.attention.self.key.bias', 'encoder.layer.13.attention.self.query.weight', 'encoder.layer.20.attention.self.value.bias', 'encoder.layer.15.output.LayerNorm.weight', 'encoder.layer.14.attention.output.LayerNorm.weight', 'encoder.layer.17.attention.output.dense.weight', 'encoder.layer.3.attention.self.key.weight', 'encoder.layer.2.attention.output.LayerNorm.weight', 'encoder.layer.8.attention.output.LayerNorm.bias', 'encoder.layer.5.attention.output.dense.weight', 'encoder.layer.19.attention.output.LayerNorm.weight', 'encoder.layer.17.intermediate.dense.bias', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.11.attention.self.query.bias', 'encoder.layer.8.attention.self.query.bias', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.17.attention.self.key.bias', 'encoder.layer.7.attention.self.value.bias', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.4.attention.self.key.weight', 'encoder.layer.2.attention.self.value.weight', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.22.attention.self.key.bias', 'encoder.layer.18.attention.output.LayerNorm.bias', 'encoder.layer.4.attention.output.dense.weight', 'encoder.layer.13.output.LayerNorm.bias', 'encoder.layer.13.attention.self.value.bias', 'encoder.layer.22.attention.output.dense.weight', 'encoder.layer.15.attention.self.query.weight', 'encoder.layer.19.attention.self.key.weight', 'encoder.layer.14.output.dense.weight', 'encoder.layer.20.attention.self.query.weight', 'encoder.layer.21.output.dense.weight', 'encoder.layer.20.attention.output.LayerNorm.bias', 'encoder.layer.13.attention.output.dense.bias', 'encoder.layer.14.output.LayerNorm.weight', 'encoder.layer.11.attention.output.LayerNorm.weight', 'encoder.layer.12.attention.self.query.bias', 'encoder.layer.1.attention.self.value.weight', 'encoder.layer.23.output.LayerNorm.weight', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.20.attention.self.key.bias', 'encoder.layer.10.attention.self.query.weight', 'encoder.layer.9.attention.self.value.weight', 'encoder.layer.15.attention.output.LayerNorm.bias', 'encoder.layer.10.attention.self.value.weight', 'encoder.layer.15.output.dense.bias', 'encoder.layer.19.intermediate.dense.bias', 'encoder.layer.0.output.dense.weight', 'encoder.layer.17.output.LayerNorm.weight', 'encoder.layer.19.attention.output.dense.weight', 'encoder.layer.8.output.dense.weight', 'encoder.layer.2.output.dense.bias', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.10.attention.output.LayerNorm.bias', 'encoder.layer.19.attention.output.dense.bias', 'encoder.layer.12.output.dense.weight', 'encoder.layer.15.attention.output.dense.bias', 'encoder.layer.17.attention.self.value.weight', 'encoder.layer.17.attention.output.dense.bias', 'encoder.layer.0.attention.output.LayerNorm.bias', 'embeddings.LayerNorm.bias', 'encoder.layer.23.attention.self.value.weight', 'encoder.layer.19.attention.self.value.weight', 'encoder.layer.7.attention.self.query.weight', 'encoder.layer.7.attention.output.dense.weight', 'encoder.layer.9.output.LayerNorm.weight', 'encoder.layer.9.output.dense.bias', 'encoder.layer.5.attention.self.key.bias', 'encoder.layer.18.attention.output.dense.bias', 'encoder.layer.14.intermediate.dense.bias', 'encoder.layer.11.attention.output.dense.weight', 'encoder.layer.6.attention.self.key.bias', 'encoder.layer.7.output.LayerNorm.weight', 'encoder.layer.8.attention.self.value.bias', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.6.attention.output.dense.weight', 'encoder.layer.6.output.LayerNorm.bias', 'encoder.layer.23.attention.output.LayerNorm.bias', 'encoder.layer.11.attention.self.value.bias', 'encoder.layer.23.output.dense.bias', 'encoder.layer.16.output.dense.bias', 'encoder.layer.8.attention.output.dense.weight', 'encoder.layer.1.attention.output.dense.weight', 'encoder.layer.5.attention.output.LayerNorm.weight', 'encoder.layer.13.attention.self.value.weight', 'encoder.layer.20.attention.self.key.weight', 'encoder.layer.3.output.dense.weight', 'encoder.layer.4.attention.self.value.bias', 'embeddings.LayerNorm.weight', 'encoder.layer.1.attention.self.key.weight', 'encoder.layer.1.attention.self.key.bias', 'encoder.layer.18.output.dense.bias', 'encoder.layer.9.attention.self.key.weight', 'encoder.layer.11.attention.self.value.weight', 'encoder.layer.4.attention.self.query.bias', 'encoder.layer.20.attention.self.value.weight', 'encoder.layer.4.output.dense.weight', 'encoder.layer.12.output.dense.bias', 'pooler.dense.bias', 'encoder.layer.19.attention.self.query.weight', 'encoder.layer.17.attention.output.LayerNorm.bias', 'encoder.layer.21.attention.self.query.weight', 'encoder.layer.9.output.dense.weight', 'encoder.layer.22.output.LayerNorm.bias', 'encoder.layer.1.attention.self.query.weight', 'encoder.layer.19.output.LayerNorm.bias', 'encoder.layer.20.attention.output.dense.bias', 'encoder.layer.10.attention.self.key.weight', 'encoder.layer.16.attention.self.value.weight', 'encoder.layer.7.attention.self.value.weight', 'encoder.layer.12.intermediate.dense.weight', 'encoder.layer.3.attention.self.query.bias', 'encoder.layer.16.output.LayerNorm.bias', 'encoder.layer.15.attention.output.dense.weight', 'encoder.layer.4.attention.self.query.weight', 'encoder.layer.22.intermediate.dense.bias', 'encoder.layer.15.intermediate.dense.bias', 'encoder.layer.5.attention.self.query.bias', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.6.attention.self.value.weight', 'encoder.layer.19.attention.self.query.bias', 'encoder.layer.12.attention.self.value.weight', 'encoder.layer.21.output.dense.bias', 'encoder.layer.18.output.dense.weight', 'encoder.layer.2.output.dense.weight', 'encoder.layer.15.attention.self.value.weight', 'encoder.layer.0.attention.self.value.bias', 'encoder.layer.14.intermediate.dense.weight', 'encoder.layer.22.intermediate.dense.weight', 'encoder.layer.0.attention.self.key.weight', 'encoder.layer.0.attention.self.value.weight', 'encoder.layer.5.output.dense.bias', 'encoder.layer.16.output.LayerNorm.weight', 'encoder.layer.11.output.dense.bias', 'encoder.layer.1.output.dense.bias', 'encoder.layer.4.attention.output.LayerNorm.weight', 'encoder.layer.5.output.dense.weight', 'encoder.layer.14.attention.output.dense.bias', 'encoder.layer.20.output.LayerNorm.bias', 'encoder.layer.19.attention.self.value.bias', 'encoder.layer.2.attention.self.query.bias', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.4.attention.self.value.weight', 'encoder.layer.2.attention.self.query.weight', 'encoder.layer.0.attention.output.LayerNorm.weight', 'encoder.layer.3.attention.self.value.weight', 'encoder.layer.21.intermediate.dense.weight', 'encoder.layer.7.attention.output.LayerNorm.weight', 'encoder.layer.2.attention.output.LayerNorm.bias', 'encoder.layer.1.attention.self.value.bias', 'encoder.layer.1.attention.output.dense.bias', 'encoder.layer.11.attention.self.query.weight', 'encoder.layer.11.attention.self.key.weight', 'encoder.layer.7.output.dense.bias', 'encoder.layer.8.output.dense.bias', 'encoder.layer.23.attention.self.key.bias', 'encoder.layer.8.attention.self.key.weight', 'encoder.layer.12.attention.output.LayerNorm.weight', 'encoder.layer.7.intermediate.dense.bias', 'encoder.layer.13.attention.self.key.weight', 'encoder.layer.3.attention.self.key.bias', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.10.output.dense.bias', 'encoder.layer.16.output.dense.weight', 'encoder.layer.14.attention.self.value.weight', 'encoder.layer.3.output.dense.bias', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.5.attention.self.query.weight', 'encoder.layer.13.intermediate.dense.bias', 'encoder.layer.21.attention.self.value.bias', 'encoder.layer.22.attention.output.LayerNorm.bias', 'encoder.layer.20.intermediate.dense.weight', 'encoder.layer.12.output.LayerNorm.bias', 'encoder.layer.17.attention.self.key.weight', 'encoder.layer.16.attention.output.dense.bias', 'encoder.layer.10.output.LayerNorm.bias', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.3.attention.output.dense.bias', 'encoder.layer.14.output.LayerNorm.bias', 'encoder.layer.18.output.LayerNorm.weight', 'encoder.layer.15.attention.output.LayerNorm.weight', 'encoder.layer.22.attention.self.value.bias', 'encoder.layer.22.attention.output.dense.bias', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.18.output.LayerNorm.bias', 'encoder.layer.5.attention.self.value.weight', 'encoder.layer.18.attention.self.value.bias', 'encoder.layer.22.output.dense.weight', 'encoder.layer.6.attention.self.value.bias', 'encoder.layer.0.attention.output.dense.bias', 'encoder.layer.21.attention.output.dense.weight', 'encoder.layer.23.attention.self.query.bias', 'embeddings.position_embeddings.weight', 'encoder.layer.6.attention.self.key.weight', 'encoder.layer.14.attention.self.key.weight', 'encoder.layer.8.attention.self.query.weight', 'encoder.layer.23.attention.self.value.bias', 'encoder.layer.7.attention.output.dense.bias', 'encoder.layer.0.attention.self.query.weight', 'encoder.layer.0.attention.output.dense.weight', 'encoder.layer.10.attention.output.dense.weight', 'encoder.layer.6.output.dense.weight', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.11.output.LayerNorm.weight', 'encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.layer.14.attention.self.query.weight', 'encoder.layer.12.attention.self.query.weight', 'encoder.layer.14.output.dense.bias', 'encoder.layer.12.output.LayerNorm.weight', 'encoder.layer.21.attention.self.key.weight', 'encoder.layer.9.attention.self.query.weight', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.2.attention.self.key.weight', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.5.output.LayerNorm.bias', 'encoder.layer.16.intermediate.dense.weight', 'encoder.layer.22.attention.output.LayerNorm.weight', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.23.attention.output.dense.bias', 'encoder.layer.2.attention.output.dense.bias', 'encoder.layer.9.attention.output.LayerNorm.weight', 'encoder.layer.20.output.dense.bias', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.9.attention.self.key.bias', 'encoder.layer.9.attention.output.LayerNorm.bias', 'encoder.layer.13.output.dense.weight', 'encoder.layer.19.attention.output.LayerNorm.bias', 'encoder.layer.5.attention.self.value.bias', 'encoder.layer.6.attention.output.LayerNorm.bias', 'encoder.layer.11.output.dense.weight', 'encoder.layer.18.attention.self.key.weight', 'encoder.layer.21.intermediate.dense.bias', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.1.output.dense.weight', 'encoder.layer.15.attention.self.key.weight', 'encoder.layer.16.attention.self.key.bias', 'encoder.layer.3.attention.self.value.bias', 'embeddings.token_type_embeddings.weight', 'encoder.layer.6.attention.self.query.weight', 'encoder.layer.20.attention.output.dense.weight', 'encoder.layer.14.attention.self.value.bias', 'encoder.layer.13.attention.output.LayerNorm.weight', 'encoder.layer.15.output.dense.weight', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.22.attention.self.query.bias', 'embeddings.word_embeddings.weight', 'encoder.layer.18.intermediate.dense.weight', 'encoder.layer.9.attention.output.dense.weight', 'encoder.layer.16.attention.output.dense.weight', 'encoder.layer.12.attention.self.key.bias', 'encoder.layer.5.attention.output.dense.bias', 'encoder.layer.10.intermediate.dense.weight', 'encoder.layer.23.attention.self.key.weight', 'encoder.layer.21.attention.output.LayerNorm.weight', 'encoder.layer.10.attention.self.query.bias', 'encoder.layer.16.attention.output.LayerNorm.bias', 'encoder.layer.12.attention.output.dense.bias', 'encoder.layer.21.attention.self.query.bias', 'encoder.layer.0.attention.self.query.bias', 'encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.layer.17.output.LayerNorm.bias', 'encoder.layer.5.attention.self.key.weight', 'encoder.layer.20.output.dense.weight', 'encoder.layer.7.attention.self.key.weight', 'encoder.layer.22.attention.self.value.weight', 'encoder.layer.21.output.LayerNorm.weight', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.9.attention.self.query.bias', 'encoder.layer.19.output.LayerNorm.weight', 'encoder.layer.8.attention.self.key.bias', 'encoder.layer.14.attention.output.LayerNorm.bias', 'encoder.layer.8.attention.output.LayerNorm.weight', 'encoder.layer.15.attention.self.key.bias', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.11.attention.self.key.bias', 'encoder.layer.10.attention.output.LayerNorm.weight', 'encoder.layer.6.attention.self.query.bias', 'encoder.layer.22.attention.self.key.weight', 'encoder.layer.17.attention.self.query.weight', 'encoder.layer.23.attention.output.dense.weight', 'encoder.layer.13.attention.output.LayerNorm.bias', 'encoder.layer.16.attention.output.LayerNorm.weight', 'encoder.layer.7.attention.output.LayerNorm.bias', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.15.attention.self.value.bias', 'encoder.layer.16.attention.self.query.weight', 'encoder.layer.0.attention.self.key.bias', 'encoder.layer.7.attention.self.query.bias', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.23.attention.output.LayerNorm.weight', 'encoder.layer.18.attention.self.query.weight', 'encoder.layer.4.attention.output.dense.bias', 'encoder.layer.13.attention.output.dense.weight', 'encoder.layer.23.attention.self.query.weight', 'encoder.layer.21.attention.output.LayerNorm.bias', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.7.output.dense.weight', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.23.intermediate.dense.weight', 'encoder.layer.18.attention.self.value.weight', 'encoder.layer.12.attention.self.key.weight', 'encoder.layer.19.output.dense.bias', 'encoder.layer.1.attention.output.LayerNorm.weight', 'encoder.layer.2.attention.self.key.bias', 'encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.layer.13.attention.self.query.bias', 'encoder.layer.8.output.LayerNorm.weight', 'encoder.layer.10.attention.output.dense.bias', 'encoder.layer.10.output.dense.weight', 'encoder.layer.19.intermediate.dense.weight', 'encoder.layer.20.output.LayerNorm.weight', 'encoder.layer.6.output.dense.bias', 'encoder.layer.12.attention.self.value.bias', 'encoder.layer.1.attention.self.query.bias', 'encoder.layer.16.attention.self.value.bias', 'encoder.layer.9.attention.self.value.bias', 'encoder.layer.0.output.dense.bias', 'encoder.layer.8.attention.output.dense.bias', 'encoder.layer.21.attention.self.key.bias', 'encoder.layer.23.output.dense.weight', 'encoder.layer.8.attention.self.value.weight', 'encoder.layer.21.attention.output.dense.bias', 'encoder.layer.13.output.LayerNorm.weight', 'encoder.layer.18.attention.output.LayerNorm.weight', 'encoder.layer.10.attention.self.value.bias', 'encoder.layer.21.attention.self.value.weight', 'encoder.layer.2.attention.self.value.bias', 'encoder.layer.22.output.dense.bias', 'encoder.layer.13.attention.self.key.bias', 'encoder.layer.15.output.LayerNorm.bias', 'encoder.layer.20.attention.self.query.bias', 'encoder.layer.23.intermediate.dense.bias', 'encoder.layer.9.output.LayerNorm.bias', 'encoder.layer.13.intermediate.dense.weight', 'encoder.layer.15.attention.self.query.bias', 'pooler.dense.weight', 'encoder.layer.22.attention.self.query.weight', 'encoder.layer.4.attention.output.LayerNorm.bias', 'encoder.layer.11.attention.output.dense.bias', 'encoder.layer.12.attention.output.dense.weight', 'encoder.layer.3.attention.self.query.weight', 'encoder.layer.18.attention.self.query.bias', 'encoder.layer.17.attention.self.value.bias', 'encoder.layer.12.intermediate.dense.bias', 'encoder.layer.15.intermediate.dense.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Overwriting existing adapter 'ep'.
Overwriting existing adapter 'tp'.
Overwriting existing adapter 'es'.
Overwriting existing adapter 'ts'.
Overwriting existing adapter fusion module 'ep,tp,es,ts'
05/09/2022 22:55:02 - INFO - __main__ -   lang2id = None
05/09/2022 22:55:05 - INFO - __main__ -   Training/evaluation parameters Namespace(adam_epsilon=1e-08, cache_dir='', config_name='', data_dir=None, device=device(type='cuda'), do_eval=True, do_lower_case=False, do_train=False, doc_stride=128, eval_all_checkpoints=False, eval_lang='id', evaluate_during_training=False, fp16=False, fp16_opt_level='O1', gradient_accumulation_steps=1, learning_rate=5e-05, local_rank=-1, logging_steps=50, max_answer_length=30, max_grad_norm=1.0, max_query_length=64, max_seq_length=384, max_steps=-1, model_name='xlm-KG', model_name_or_path='/cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//tydiqa/xlm-KG_LR8e-6_EPOCH2.0_maxlen384_batchsize4_gradacc4', model_type='xlm', modelkg_dir='/cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/adapter/xlmr_adapter', n_best_size=20, n_gpu=1, no_cuda=False, null_score_diff_threshold=0.0, num_train_epochs=3.0, output_dir='/cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//tydiqa/xlm-KG_LR8e-6_EPOCH2.0_maxlen384_batchsize4_gradacc4/predictions/tydiqa/', overwrite_cache=False, overwrite_output_dir=False, per_gpu_eval_batch_size=8, per_gpu_train_batch_size=8, predict_file='/cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/download//tydiqa//tydiqa-goldp-v1.1-dev/tydiqa.goldp.id.dev.json', save_steps=50, seed=42, server_ip='', server_port='', threads=1, tokenizer_name='', train_file=None, train_lang='en', verbose_logging=False, version_2_with_negative=False, warmup_steps=0, weight_decay=0.0)
05/09/2022 22:55:05 - INFO - __main__ -   Loading checkpoint /cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//tydiqa/xlm-KG_LR8e-6_EPOCH2.0_maxlen384_batchsize4_gradacc4 for evaluation
05/09/2022 22:55:05 - INFO - __main__ -   Evaluate the following checkpoints: ['/cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//tydiqa/xlm-KG_LR8e-6_EPOCH2.0_maxlen384_batchsize4_gradacc4']
Some weights of the model checkpoint at /cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//tydiqa/xlm-KG_LR8e-6_EPOCH2.0_maxlen384_batchsize4_gradacc4 were not used when initializing XLMRobertaModel: ['base_model.encoder.layer.11.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.2.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.10.attention.self.key.bias', 'base_model.encoder.layer.12.attention.self.key.weight', 'base_model.encoder.layer.12.intermediate.dense.weight', 'base_model.encoder.layer.18.output.LayerNorm.bias', 'base_model.encoder.layer.4.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.5.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.17.attention.output.dense.bias', 'base_model.encoder.layer.16.attention.self.query.bias', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.2.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.22.output.dense.bias', 'base_model.encoder.layer.15.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.14.attention.output.dense.bias', 'base_model.encoder.layer.14.attention.output.LayerNorm.weight', 'base_model.encoder.layer.15.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.0.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.11.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.17.attention.output.LayerNorm.bias', 'base_model.encoder.layer.12.attention.output.LayerNorm.bias', 'base_model.encoder.layer.10.output.LayerNorm.bias', 'base_model.encoder.layer.16.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.7.attention.self.key.weight', 'base_model.encoder.layer.11.attention.self.value.bias', 'base_model.encoder.layer.5.intermediate.dense.weight', 'base_model.encoder.layer.3.attention.self.value.bias', 'base_model.encoder.layer.23.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.12.attention.output.dense.weight', 'base_model.encoder.layer.3.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.9.attention.self.value.weight', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.17.attention.self.value.weight', 'base_model.encoder.layer.10.attention.self.value.weight', 'base_model.encoder.layer.22.attention.self.value.bias', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.7.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.17.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.15.output.LayerNorm.bias', 'base_model.encoder.layer.13.output.LayerNorm.bias', 'base_model.encoder.layer.14.output.dense.weight', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.3.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.8.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.18.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.22.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.14.intermediate.dense.weight', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.1.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.21.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.11.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.6.attention.self.key.bias', 'base_model.encoder.layer.9.attention.output.dense.bias', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.4.attention.self.query.weight', 'base_model.encoder.layer.20.attention.self.value.weight', 'base_model.encoder.layer.9.output.LayerNorm.bias', 'base_model.encoder.layer.21.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.23.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.11.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.6.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.6.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.5.intermediate.dense.bias', 'base_model.encoder.layer.13.attention.output.LayerNorm.weight', 'base_model.encoder.layer.14.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.2.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.19.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.5.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.15.output.LayerNorm.weight', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.8.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.10.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.10.output.adapters.tp.adapter_down.0.weight', 'base_model.embeddings.LayerNorm.weight', 'base_model.encoder.layer.13.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.18.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.12.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.10.output.dense.bias', 'base_model.encoder.layer.21.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.2.output.dense.bias', 'base_model.encoder.layer.10.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.16.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.20.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.23.attention.self.key.weight', 'base_model.encoder.layer.16.attention.self.value.weight', 'base_model.encoder.layer.12.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.7.attention.self.query.bias', 'base_model.encoder.layer.2.output.LayerNorm.bias', 'base_model.encoder.layer.10.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.5.attention.output.LayerNorm.weight', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.21.attention.output.LayerNorm.weight', 'base_model.encoder.layer.19.attention.self.value.bias', 'base_model.encoder.layer.20.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.10.output.LayerNorm.weight', 'base_model.encoder.layer.20.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.12.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.5.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.18.output.dense.bias', 'base_model.encoder.layer.18.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.21.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.11.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.16.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.22.output.LayerNorm.weight', 'base_model.encoder.layer.0.attention.output.dense.weight', 'base_model.encoder.layer.23.intermediate.dense.weight', 'base_model.encoder.layer.5.output.dense.weight', 'base_model.encoder.layer.9.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.8.output.dense.bias', 'base_model.encoder.layer.17.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.23.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.22.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.19.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.7.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.21.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.21.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.4.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.5.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.3.output.LayerNorm.bias', 'base_model.encoder.layer.9.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.6.attention.self.value.bias', 'base_model.encoder.layer.23.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.3.attention.output.dense.weight', 'base_model.encoder.layer.3.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.3.attention.self.query.bias', 'base_model.encoder.layer.1.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.14.attention.output.dense.weight', 'base_model.encoder.layer.10.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.19.attention.output.LayerNorm.weight', 'base_model.encoder.layer.19.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.0.attention.self.key.weight', 'base_model.encoder.layer.16.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.4.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.0.attention.self.value.weight', 'base_model.encoder.layer.12.output.LayerNorm.bias', 'base_model.encoder.layer.12.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.20.output.dense.bias', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.19.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.2.attention.output.dense.bias', 'base_model.encoder.layer.4.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.16.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.2.attention.output.dense.weight', 'base_model.encoder.layer.19.attention.self.query.weight', 'base_model.encoder.layer.3.output.dense.weight', 'base_model.encoder.layer.17.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.4.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.20.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.2.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.3.output.LayerNorm.weight', 'base_model.encoder.layer.9.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.15.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.6.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.8.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.1.attention.output.LayerNorm.weight', 'base_model.encoder.layer.14.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.22.output.dense.weight', 'base_model.encoder.layer.7.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.16.attention.self.query.weight', 'base_model.encoder.layer.22.attention.self.query.weight', 'base_model.encoder.layer.8.intermediate.dense.bias', 'base_model.encoder.layer.4.attention.output.dense.weight', 'base_model.encoder.layer.4.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.4.output.LayerNorm.bias', 'base_model.encoder.layer.20.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.12.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.21.output.dense.bias', 'base_model.encoder.layer.2.attention.output.LayerNorm.weight', 'base_model.encoder.layer.1.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.11.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.19.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.20.attention.output.dense.weight', 'base_model.encoder.layer.22.attention.output.dense.weight', 'base_model.encoder.layer.20.attention.self.value.bias', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.4.attention.self.key.weight', 'base_model.encoder.layer.10.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.12.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.18.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.6.attention.self.query.bias', 'base_model.encoder.layer.0.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.7.attention.output.dense.bias', 'base_model.encoder.layer.4.attention.output.dense.bias', 'base_model.encoder.layer.1.output.dense.bias', 'base_model.encoder.layer.2.attention.self.key.bias', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.18.attention.self.key.weight', 'base_model.encoder.layer.23.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.20.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.23.output.dense.weight', 'base_model.encoder.layer.17.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.11.attention.self.key.bias', 'base_model.encoder.layer.13.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.17.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.22.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.16.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.6.attention.output.LayerNorm.weight', 'base_model.encoder.layer.4.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.20.attention.output.LayerNorm.weight', 'base_model.encoder.layer.10.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.22.intermediate.dense.bias', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.11.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.20.intermediate.dense.weight', 'base_model.encoder.layer.6.output.LayerNorm.weight', 'base_model.encoder.layer.21.output.LayerNorm.bias', 'base_model.encoder.layer.18.attention.self.value.bias', 'base_model.encoder.layer.8.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.13.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.15.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.16.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.9.output.LayerNorm.weight', 'base_model.encoder.layer.18.attention.self.key.bias', 'base_model.encoder.layer.3.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.4.intermediate.dense.weight', 'base_model.encoder.layer.17.intermediate.dense.bias', 'base_model.encoder.layer.10.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.9.intermediate.dense.weight', 'base_model.encoder.layer.19.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.8.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.17.output.LayerNorm.weight', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.7.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.17.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.4.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.13.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.14.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.8.output.LayerNorm.weight', 'base_model.encoder.layer.10.attention.self.value.bias', 'base_model.encoder.layer.6.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.11.attention.output.dense.weight', 'base_model.encoder.layer.17.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.16.output.dense.weight', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.16.output.LayerNorm.weight', 'base_model.encoder.layer.23.output.dense.bias', 'base_model.encoder.layer.8.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.8.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.8.attention.output.LayerNorm.bias', 'base_model.encoder.layer.5.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.19.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.18.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.2.attention.self.value.weight', 'base_model.encoder.layer.2.output.dense.weight', 'base_model.encoder.layer.6.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.3.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.20.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.2.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.23.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.14.attention.self.query.weight', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.22.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.17.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.5.attention.self.value.bias', 'base_model.encoder.layer.21.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.9.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.2.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.22.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.0.attention.output.dense.bias', 'base_model.encoder.layer.23.intermediate.dense.bias', 'base_model.encoder.layer.7.attention.self.key.bias', 'base_model.encoder.layer.4.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.12.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.14.attention.self.value.weight', 'base_model.encoder.layer.10.attention.output.LayerNorm.weight', 'base_model.encoder.layer.16.attention.output.LayerNorm.weight', 'base_model.encoder.layer.12.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.21.output.LayerNorm.weight', 'base_model.encoder.layer.16.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.15.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.2.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.13.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.11.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.19.attention.output.dense.bias', 'base_model.encoder.layer.8.attention.self.query.weight', 'base_model.encoder.layer.9.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.5.attention.output.LayerNorm.bias', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.13.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.16.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.2.attention.self.query.weight', 'base_model.encoder.layer.18.attention.output.dense.weight', 'base_model.encoder.layer.8.attention.output.LayerNorm.weight', 'base_model.encoder.layer.9.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.18.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.14.attention.output.LayerNorm.bias', 'base_model.encoder.layer.19.output.dense.weight', 'base_model.encoder.layer.11.attention.self.value.weight', 'base_model.encoder.layer.20.intermediate.dense.bias', 'base_model.encoder.layer.23.attention.self.value.weight', 'base_model.encoder.layer.17.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.3.attention.self.query.weight', 'base_model.encoder.layer.19.attention.self.query.bias', 'base_model.encoder.layer.19.output.LayerNorm.weight', 'base_model.encoder.layer.17.output.dense.bias', 'base_model.encoder.layer.11.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.10.intermediate.dense.weight', 'base_model.encoder.layer.18.intermediate.dense.weight', 'base_model.encoder.layer.21.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.14.attention.self.key.bias', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.19.output.dense.bias', 'base_model.encoder.layer.23.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.8.attention.output.dense.bias', 'base_model.encoder.layer.15.intermediate.dense.weight', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.0.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.19.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.20.attention.output.dense.bias', 'base_model.pooler.dense.bias', 'base_model.encoder.layer.19.attention.self.value.weight', 'base_model.encoder.layer.18.attention.self.query.weight', 'base_model.encoder.layer.14.attention.self.value.bias', 'base_model.encoder.layer.17.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.20.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.13.attention.self.query.weight', 'base_model.encoder.layer.0.attention.self.query.bias', 'base_model.encoder.layer.0.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.19.output.LayerNorm.bias', 'base_model.encoder.layer.20.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.21.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.7.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.9.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.7.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.23.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.10.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.6.attention.self.key.weight', 'base_model.encoder.layer.11.attention.output.LayerNorm.weight', 'base_model.encoder.layer.4.attention.self.value.weight', 'base_model.embeddings.LayerNorm.bias', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.1.attention.self.query.weight', 'base_model.encoder.layer.1.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.5.attention.self.value.weight', 'base_model.encoder.layer.19.intermediate.dense.bias', 'base_model.encoder.layer.15.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.13.attention.self.value.bias', 'base_model.encoder.layer.22.intermediate.dense.weight', 'base_model.encoder.layer.14.attention.self.key.weight', 'base_model.encoder.layer.22.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.1.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.23.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.5.attention.self.key.weight', 'base_model.encoder.layer.21.attention.self.key.bias', 'base_model.encoder.layer.18.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.19.attention.output.LayerNorm.bias', 'base_model.encoder.layer.7.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.18.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.17.attention.self.query.weight', 'base_model.encoder.layer.13.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.16.attention.output.LayerNorm.bias', 'base_model.encoder.layer.4.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.12.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.16.output.dense.bias', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.9.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.1.output.LayerNorm.bias', 'base_model.encoder.layer.0.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.9.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.12.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.1.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.5.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.13.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.19.attention.self.key.weight', 'base_model.encoder.layer.8.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.6.output.dense.weight', 'base_model.encoder.layer.1.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.5.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.13.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.11.attention.self.key.weight', 'base_model.encoder.layer.2.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.7.output.LayerNorm.weight', 'base_model.encoder.layer.5.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.13.output.dense.weight', 'base_model.encoder.layer.0.intermediate.dense.bias', 'base_model.encoder.layer.4.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.13.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.15.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.11.output.LayerNorm.weight', 'base_model.encoder.layer.6.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.6.attention.output.dense.bias', 'base_model.encoder.layer.2.output.LayerNorm.weight', 'base_model.encoder.layer.18.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.20.output.dense.weight', 'base_model.encoder.layer.20.attention.self.query.weight', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.20.attention.output.LayerNorm.bias', 'base_model.encoder.layer.22.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.9.output.dense.weight', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.22.attention.output.LayerNorm.bias', 'base_model.encoder.layer.15.attention.output.dense.bias', 'base_model.encoder.layer.0.attention.output.LayerNorm.weight', 'base_model.encoder.layer.6.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.10.attention.output.dense.bias', 'base_model.encoder.layer.15.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.13.attention.self.key.bias', 'base_model.encoder.layer.18.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.3.output.dense.bias', 'base_model.encoder.layer.10.attention.self.query.bias', 'base_model.encoder.layer.12.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.19.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.18.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.5.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.8.attention.self.query.bias', 'base_model.encoder.layer.5.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.8.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.18.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.17.attention.output.LayerNorm.weight', 'base_model.encoder.layer.19.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.20.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.2.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.15.intermediate.dense.bias', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.12.output.dense.bias', 'base_model.encoder.layer.10.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.1.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.14.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.4.attention.self.key.bias', 'base_model.encoder.layer.13.attention.output.dense.bias', 'base_model.encoder.layer.0.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.5.output.dense.bias', 'base_model.encoder.layer.22.attention.self.query.bias', 'base_model.encoder.layer.11.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.1.attention.output.LayerNorm.bias', 'base_model.encoder.layer.0.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.2.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.4.attention.output.LayerNorm.bias', 'base_model.encoder.layer.14.intermediate.dense.bias', 'base_model.encoder.layer.0.attention.output.LayerNorm.bias', 'base_model.encoder.layer.0.output.LayerNorm.weight', 'base_model.encoder.layer.18.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.18.attention.self.value.weight', 'base_model.encoder.layer.4.attention.self.query.bias', 'base_model.encoder.layer.9.intermediate.dense.bias', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.4.attention.self.value.bias', 'base_model.encoder.layer.8.attention.self.value.bias', 'base_model.encoder.layer.11.attention.self.query.weight', 'base_model.encoder.layer.6.intermediate.dense.weight', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.13.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.4.attention.output.LayerNorm.weight', 'base_model.encoder.layer.1.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.8.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.2.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.8.output.LayerNorm.bias', 'base_model.encoder.layer.9.attention.self.query.weight', 'base_model.encoder.layer.10.intermediate.dense.bias', 'base_model.encoder.layer.12.intermediate.dense.bias', 'base_model.encoder.layer.2.attention.self.value.bias', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.9.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.12.attention.self.key.bias', 'base_model.encoder.layer.23.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.12.attention.self.value.weight', 'base_model.encoder.layer.22.attention.self.key.bias', 'base_model.encoder.layer.10.attention.self.query.weight', 'base_model.encoder.layer.1.output.LayerNorm.weight', 'base_model.encoder.layer.9.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.16.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.6.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.17.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.17.attention.self.key.weight', 'base_model.encoder.layer.9.attention.self.key.bias', 'base_model.encoder.layer.11.output.dense.weight', 'base_model.encoder.layer.21.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.6.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.5.attention.output.dense.bias', 'base_model.encoder.layer.0.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.2.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.14.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.21.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.14.output.dense.bias', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.0.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.23.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.6.intermediate.dense.bias', 'base_model.encoder.layer.22.attention.output.dense.bias', 'base_model.encoder.layer.21.attention.self.value.weight', 'base_model.encoder.layer.22.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.1.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.15.attention.self.key.weight', 'base_model.encoder.layer.17.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.23.attention.self.key.bias', 'base_model.encoder.layer.3.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.16.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.5.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.12.attention.output.dense.bias', 'base_model.encoder.layer.15.attention.self.query.weight', 'base_model.encoder.layer.8.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.15.attention.self.query.bias', 'base_model.encoder.layer.5.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.18.intermediate.dense.bias', 'base_model.encoder.layer.20.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.22.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.23.output.LayerNorm.bias', 'base_model.encoder.layer.14.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.7.output.LayerNorm.bias', 'base_model.encoder.layer.12.output.LayerNorm.weight', 'base_model.encoder.layer.19.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.17.intermediate.dense.weight', 'base_model.encoder.layer.1.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.8.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.18.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.7.attention.self.value.weight', 'base_model.encoder.layer.7.intermediate.dense.weight', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.17.output.dense.weight', 'base_model.encoder.layer.21.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.1.attention.self.value.bias', 'base_model.encoder.layer.7.attention.output.dense.weight', 'base_model.encoder.layer.16.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.13.attention.self.value.weight', 'base_model.encoder.layer.22.attention.self.key.weight', 'base_model.encoder.layer.23.attention.output.LayerNorm.weight', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.1.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.15.attention.output.LayerNorm.bias', 'base_model.encoder.layer.8.attention.self.value.weight', 'base_model.encoder.layer.14.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.5.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.21.intermediate.dense.weight', 'base_model.encoder.layer.7.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.14.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.22.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.18.attention.output.LayerNorm.bias', 'base_model.encoder.layer.15.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.12.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.15.attention.self.value.weight', 'base_model.encoder.layer.7.attention.self.value.bias', 'base_model.encoder.layer.11.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.5.attention.output.dense.weight', 'base_model.encoder.layer.22.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.10.attention.output.dense.weight', 'base_model.encoder.layer.22.output.adapters.es.adapter_down.0.bias', 'base_model.embeddings.position_ids', 'base_model.encoder.layer.6.attention.output.LayerNorm.bias', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.15.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.0.attention.self.key.bias', 'base_model.encoder.layer.5.attention.self.key.bias', 'base_model.encoder.layer.13.output.dense.bias', 'base_model.encoder.layer.18.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.20.attention.self.key.weight', 'base_model.encoder.layer.5.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.14.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.14.output.LayerNorm.weight', 'base_model.encoder.layer.22.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.1.intermediate.dense.bias', 'base_model.encoder.layer.9.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.0.attention.self.value.bias', 'base_model.encoder.layer.7.attention.output.LayerNorm.bias', 'base_model.encoder.layer.10.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.14.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.18.output.LayerNorm.weight', 'base_model.encoder.layer.9.attention.output.LayerNorm.bias', 'base_model.encoder.layer.9.attention.self.query.bias', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.20.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.20.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.1.attention.self.value.weight', 'base_model.encoder.layer.11.output.dense.bias', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.11.output.LayerNorm.bias', 'base_model.encoder.layer.13.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.0.output.LayerNorm.bias', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.7.attention.output.LayerNorm.weight', 'base_model.encoder.layer.18.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.19.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.22.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'qa_outputs.bias', 'base_model.encoder.layer.11.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.9.attention.self.value.bias', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.1.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.6.output.LayerNorm.bias', 'base_model.encoder.layer.15.attention.output.dense.weight', 'base_model.encoder.layer.6.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.15.output.dense.weight', 'base_model.encoder.layer.18.attention.output.dense.bias', 'base_model.encoder.layer.23.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.1.output.dense.weight', 'base_model.embeddings.word_embeddings.weight', 'base_model.encoder.layer.20.output.LayerNorm.weight', 'base_model.encoder.layer.16.intermediate.dense.bias', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.16.output.LayerNorm.bias', 'base_model.encoder.layer.5.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.7.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.4.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.9.attention.output.dense.weight', 'base_model.encoder.layer.23.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.1.attention.self.key.weight', 'base_model.encoder.layer.7.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.10.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.8.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.21.attention.self.query.bias', 'base_model.encoder.layer.6.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.7.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.2.intermediate.dense.bias', 'base_model.encoder.layer.6.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.15.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.16.attention.output.dense.bias', 'base_model.encoder.layer.20.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.11.attention.self.query.bias', 'base_model.encoder.layer.12.attention.self.query.bias', 'base_model.encoder.layer.3.intermediate.dense.bias', 'base_model.encoder.layer.16.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.20.attention.self.key.bias', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.15.attention.output.LayerNorm.weight', 'base_model.encoder.layer.18.attention.output.LayerNorm.weight', 'base_model.encoder.layer.23.attention.output.LayerNorm.bias', 'base_model.encoder.layer.13.intermediate.dense.weight', 'base_model.encoder.layer.11.intermediate.dense.bias', 'base_model.encoder.layer.7.attention.self.query.weight', 'base_model.encoder.layer.15.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.14.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.13.intermediate.dense.bias', 'base_model.encoder.layer.21.attention.self.query.weight', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.15.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.12.output.dense.weight', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.17.output.LayerNorm.bias', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.12.attention.output.LayerNorm.weight', 'base_model.encoder.layer.4.output.dense.weight', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.13.attention.output.dense.weight', 'base_model.encoder.layer.11.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.3.attention.self.key.bias', 'base_model.encoder.layer.13.attention.self.query.bias', 'base_model.encoder.layer.5.output.LayerNorm.weight', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.13.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.7.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.12.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.6.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.21.intermediate.dense.bias', 'base_model.encoder.layer.17.attention.self.query.bias', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.3.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.11.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.7.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.6.output.dense.bias', 'base_model.encoder.layer.2.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.19.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.14.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.16.attention.output.dense.weight', 'base_model.encoder.layer.0.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.3.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.17.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.3.attention.output.LayerNorm.bias', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.6.attention.output.dense.weight', 'base_model.encoder.layer.8.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.19.intermediate.dense.weight', 'base_model.encoder.layer.17.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.21.attention.output.dense.weight', 'base_model.encoder.layer.6.attention.self.value.weight', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.10.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.6.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.6.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.15.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.2.attention.output.LayerNorm.bias', 'base_model.encoder.layer.21.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.22.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.23.attention.self.query.bias', 'base_model.encoder.layer.9.output.dense.bias', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.14.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.21.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.7.output.dense.weight', 'base_model.encoder.layer.0.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.19.attention.output.dense.weight', 'base_model.encoder.layer.9.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.5.attention.self.query.weight', 'base_model.encoder.layer.11.attention.output.LayerNorm.bias', 'base_model.encoder.layer.7.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.17.attention.self.value.bias', 'base_model.encoder.layer.11.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.17.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.22.output.LayerNorm.bias', 'base_model.encoder.layer.11.intermediate.dense.weight', 'base_model.encoder.layer.14.attention.self.query.bias', 'base_model.encoder.layer.1.attention.self.query.bias', 'base_model.encoder.layer.16.attention.self.key.weight', 'base_model.encoder.layer.3.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.4.output.dense.bias', 'base_model.encoder.layer.10.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.3.attention.output.dense.bias', 'base_model.encoder.layer.23.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.17.attention.self.key.bias', 'base_model.encoder.layer.12.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.15.output.dense.bias', 'base_model.encoder.layer.21.attention.output.LayerNorm.bias', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.23.attention.self.query.weight', 'base_model.encoder.layer.0.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.16.attention.self.key.bias', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.21.attention.self.value.bias', 'base_model.encoder.layer.3.attention.output.LayerNorm.weight', 'base_model.encoder.layer.16.intermediate.dense.weight', 'base_model.encoder.layer.7.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.13.attention.self.key.weight', 'base_model.encoder.layer.19.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.14.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.9.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.1.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.23.attention.self.value.bias', 'base_model.encoder.layer.2.intermediate.dense.weight', 'base_model.encoder.layer.19.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.23.attention.output.dense.bias', 'base_model.encoder.layer.4.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.7.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.2.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.0.output.dense.bias', 'base_model.encoder.layer.8.attention.output.dense.weight', 'base_model.encoder.layer.15.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.3.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.8.attention.self.key.bias', 'base_model.encoder.layer.14.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.6.attention.self.query.weight', 'base_model.encoder.layer.8.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.4.output.LayerNorm.weight', 'base_model.encoder.layer.9.attention.output.LayerNorm.weight', 'base_model.encoder.layer.18.output.dense.weight', 'base_model.embeddings.position_embeddings.weight', 'base_model.encoder.layer.13.output.LayerNorm.weight', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.8.attention.self.key.weight', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.7.intermediate.dense.bias', 'base_model.encoder.layer.4.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.15.attention.self.value.bias', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.21.attention.output.dense.bias', 'base_model.encoder.layer.4.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.4.intermediate.dense.bias', 'base_model.encoder.layer.20.output.LayerNorm.bias', 'base_model.encoder.layer.20.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.23.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.3.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.12.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.20.attention.self.query.bias', 'base_model.encoder.layer.2.attention.self.query.bias', 'base_model.embeddings.token_type_embeddings.weight', 'base_model.encoder.layer.3.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.8.intermediate.dense.weight', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.10.output.dense.weight', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.13.attention.output.LayerNorm.bias', 'base_model.encoder.layer.6.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.10.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.0.intermediate.dense.weight', 'base_model.encoder.layer.15.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.1.attention.self.key.bias', 'base_model.encoder.layer.3.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.0.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.3.attention.self.key.weight', 'base_model.encoder.layer.1.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.5.attention.self.query.bias', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.16.attention.self.value.bias', 'base_model.encoder.layer.19.attention.self.key.bias', 'base_model.encoder.layer.10.attention.self.key.weight', 'qa_outputs.weight', 'base_model.encoder.layer.20.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.9.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.0.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.18.attention.self.query.bias', 'base_model.encoder.layer.8.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.13.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.3.attention.self.value.weight', 'base_model.encoder.layer.21.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.23.output.LayerNorm.weight', 'base_model.encoder.layer.9.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.11.attention.output.dense.bias', 'base_model.encoder.layer.0.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.12.attention.self.query.weight', 'base_model.encoder.layer.1.attention.output.dense.bias', 'base_model.encoder.layer.13.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.19.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.23.attention.output.dense.weight', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.14.output.LayerNorm.bias', 'base_model.encoder.layer.12.output.adapters.ep.adapter_down.0.weight', 'base_model.pooler.dense.weight', 'base_model.encoder.layer.23.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.3.intermediate.dense.weight', 'base_model.encoder.layer.16.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.7.output.dense.bias', 'base_model.encoder.layer.22.attention.self.value.weight', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.21.output.dense.weight', 'base_model.encoder.layer.3.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.10.attention.output.LayerNorm.bias', 'base_model.encoder.layer.22.attention.output.LayerNorm.weight', 'base_model.encoder.layer.5.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.0.attention.self.query.weight', 'base_model.encoder.layer.3.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.1.attention.output.dense.weight', 'base_model.encoder.layer.0.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.10.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.3.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.14.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.1.intermediate.dense.weight', 'base_model.encoder.layer.9.attention.self.key.weight', 'base_model.encoder.layer.2.attention.self.key.weight', 'base_model.encoder.layer.11.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.16.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.22.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.13.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.2.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.17.attention.output.dense.weight', 'base_model.encoder.layer.0.output.dense.weight', 'base_model.encoder.layer.8.output.dense.weight', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.5.output.LayerNorm.bias', 'base_model.encoder.layer.12.attention.self.value.bias', 'base_model.encoder.layer.4.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.1.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.15.attention.self.key.bias', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.2.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.16.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.21.attention.self.key.weight', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.17.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.21.output.adapters.es.adapter_up.bias']
- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of XLMRobertaModel were not initialized from the model checkpoint at /cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//tydiqa/xlm-KG_LR8e-6_EPOCH2.0_maxlen384_batchsize4_gradacc4 and are newly initialized: ['encoder.layer.9.attention.output.dense.bias', 'encoder.layer.13.output.dense.bias', 'encoder.layer.10.output.LayerNorm.weight', 'encoder.layer.18.attention.self.key.bias', 'encoder.layer.16.intermediate.dense.bias', 'encoder.layer.2.attention.output.dense.weight', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.14.attention.self.key.bias', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.16.attention.self.query.bias', 'encoder.layer.17.output.dense.weight', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.16.attention.self.key.weight', 'encoder.layer.4.output.dense.bias', 'encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.10.attention.self.key.bias', 'encoder.layer.14.attention.self.query.bias', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.17.attention.output.LayerNorm.weight', 'encoder.layer.21.output.LayerNorm.bias', 'encoder.layer.17.output.dense.bias', 'encoder.layer.18.attention.output.dense.weight', 'encoder.layer.18.intermediate.dense.bias', 'encoder.layer.11.output.LayerNorm.bias', 'encoder.layer.22.output.LayerNorm.weight', 'encoder.layer.7.output.LayerNorm.bias', 'encoder.layer.3.attention.output.dense.weight', 'encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.layer.20.intermediate.dense.bias', 'encoder.layer.6.attention.output.dense.bias', 'encoder.layer.23.output.LayerNorm.bias', 'encoder.layer.14.attention.output.dense.weight', 'encoder.layer.17.attention.self.query.bias', 'encoder.layer.17.intermediate.dense.weight', 'encoder.layer.8.output.LayerNorm.bias', 'encoder.layer.7.attention.self.key.bias', 'encoder.layer.20.attention.output.LayerNorm.weight', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.6.attention.output.LayerNorm.weight', 'encoder.layer.4.attention.self.key.bias', 'encoder.layer.19.output.dense.weight', 'encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.12.attention.output.LayerNorm.bias', 'encoder.layer.19.attention.self.key.bias', 'encoder.layer.13.attention.self.query.weight', 'encoder.layer.20.attention.self.value.bias', 'encoder.layer.15.output.LayerNorm.weight', 'encoder.layer.14.attention.output.LayerNorm.weight', 'encoder.layer.17.attention.output.dense.weight', 'encoder.layer.3.attention.self.key.weight', 'encoder.layer.2.attention.output.LayerNorm.weight', 'encoder.layer.8.attention.output.LayerNorm.bias', 'encoder.layer.5.attention.output.dense.weight', 'encoder.layer.19.attention.output.LayerNorm.weight', 'encoder.layer.17.intermediate.dense.bias', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.11.attention.self.query.bias', 'encoder.layer.8.attention.self.query.bias', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.17.attention.self.key.bias', 'encoder.layer.7.attention.self.value.bias', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.4.attention.self.key.weight', 'encoder.layer.2.attention.self.value.weight', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.22.attention.self.key.bias', 'encoder.layer.18.attention.output.LayerNorm.bias', 'encoder.layer.4.attention.output.dense.weight', 'encoder.layer.13.output.LayerNorm.bias', 'encoder.layer.13.attention.self.value.bias', 'encoder.layer.22.attention.output.dense.weight', 'encoder.layer.15.attention.self.query.weight', 'encoder.layer.19.attention.self.key.weight', 'encoder.layer.14.output.dense.weight', 'encoder.layer.20.attention.self.query.weight', 'encoder.layer.21.output.dense.weight', 'encoder.layer.20.attention.output.LayerNorm.bias', 'encoder.layer.13.attention.output.dense.bias', 'encoder.layer.14.output.LayerNorm.weight', 'encoder.layer.11.attention.output.LayerNorm.weight', 'encoder.layer.12.attention.self.query.bias', 'encoder.layer.1.attention.self.value.weight', 'encoder.layer.23.output.LayerNorm.weight', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.20.attention.self.key.bias', 'encoder.layer.10.attention.self.query.weight', 'encoder.layer.9.attention.self.value.weight', 'encoder.layer.15.attention.output.LayerNorm.bias', 'encoder.layer.10.attention.self.value.weight', 'encoder.layer.15.output.dense.bias', 'encoder.layer.19.intermediate.dense.bias', 'encoder.layer.0.output.dense.weight', 'encoder.layer.17.output.LayerNorm.weight', 'encoder.layer.19.attention.output.dense.weight', 'encoder.layer.8.output.dense.weight', 'encoder.layer.2.output.dense.bias', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.10.attention.output.LayerNorm.bias', 'encoder.layer.19.attention.output.dense.bias', 'encoder.layer.12.output.dense.weight', 'encoder.layer.15.attention.output.dense.bias', 'encoder.layer.17.attention.self.value.weight', 'encoder.layer.17.attention.output.dense.bias', 'encoder.layer.0.attention.output.LayerNorm.bias', 'embeddings.LayerNorm.bias', 'encoder.layer.23.attention.self.value.weight', 'encoder.layer.19.attention.self.value.weight', 'encoder.layer.7.attention.self.query.weight', 'encoder.layer.7.attention.output.dense.weight', 'encoder.layer.9.output.LayerNorm.weight', 'encoder.layer.9.output.dense.bias', 'encoder.layer.5.attention.self.key.bias', 'encoder.layer.18.attention.output.dense.bias', 'encoder.layer.14.intermediate.dense.bias', 'encoder.layer.11.attention.output.dense.weight', 'encoder.layer.6.attention.self.key.bias', 'encoder.layer.7.output.LayerNorm.weight', 'encoder.layer.8.attention.self.value.bias', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.6.attention.output.dense.weight', 'encoder.layer.6.output.LayerNorm.bias', 'encoder.layer.23.attention.output.LayerNorm.bias', 'encoder.layer.11.attention.self.value.bias', 'encoder.layer.23.output.dense.bias', 'encoder.layer.16.output.dense.bias', 'encoder.layer.8.attention.output.dense.weight', 'encoder.layer.1.attention.output.dense.weight', 'encoder.layer.5.attention.output.LayerNorm.weight', 'encoder.layer.13.attention.self.value.weight', 'encoder.layer.20.attention.self.key.weight', 'encoder.layer.3.output.dense.weight', 'encoder.layer.4.attention.self.value.bias', 'embeddings.LayerNorm.weight', 'encoder.layer.1.attention.self.key.weight', 'encoder.layer.1.attention.self.key.bias', 'encoder.layer.18.output.dense.bias', 'encoder.layer.9.attention.self.key.weight', 'encoder.layer.11.attention.self.value.weight', 'encoder.layer.4.attention.self.query.bias', 'encoder.layer.20.attention.self.value.weight', 'encoder.layer.4.output.dense.weight', 'encoder.layer.12.output.dense.bias', 'pooler.dense.bias', 'encoder.layer.19.attention.self.query.weight', 'encoder.layer.17.attention.output.LayerNorm.bias', 'encoder.layer.21.attention.self.query.weight', 'encoder.layer.9.output.dense.weight', 'encoder.layer.22.output.LayerNorm.bias', 'encoder.layer.1.attention.self.query.weight', 'encoder.layer.19.output.LayerNorm.bias', 'encoder.layer.20.attention.output.dense.bias', 'encoder.layer.10.attention.self.key.weight', 'encoder.layer.16.attention.self.value.weight', 'encoder.layer.7.attention.self.value.weight', 'encoder.layer.12.intermediate.dense.weight', 'encoder.layer.3.attention.self.query.bias', 'encoder.layer.16.output.LayerNorm.bias', 'encoder.layer.15.attention.output.dense.weight', 'encoder.layer.4.attention.self.query.weight', 'encoder.layer.22.intermediate.dense.bias', 'encoder.layer.15.intermediate.dense.bias', 'encoder.layer.5.attention.self.query.bias', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.6.attention.self.value.weight', 'encoder.layer.19.attention.self.query.bias', 'encoder.layer.12.attention.self.value.weight', 'encoder.layer.21.output.dense.bias', 'encoder.layer.18.output.dense.weight', 'encoder.layer.2.output.dense.weight', 'encoder.layer.15.attention.self.value.weight', 'encoder.layer.0.attention.self.value.bias', 'encoder.layer.14.intermediate.dense.weight', 'encoder.layer.22.intermediate.dense.weight', 'encoder.layer.0.attention.self.key.weight', 'encoder.layer.0.attention.self.value.weight', 'encoder.layer.5.output.dense.bias', 'encoder.layer.16.output.LayerNorm.weight', 'encoder.layer.11.output.dense.bias', 'encoder.layer.1.output.dense.bias', 'encoder.layer.4.attention.output.LayerNorm.weight', 'encoder.layer.5.output.dense.weight', 'encoder.layer.14.attention.output.dense.bias', 'encoder.layer.20.output.LayerNorm.bias', 'encoder.layer.19.attention.self.value.bias', 'encoder.layer.2.attention.self.query.bias', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.4.attention.self.value.weight', 'encoder.layer.2.attention.self.query.weight', 'encoder.layer.0.attention.output.LayerNorm.weight', 'encoder.layer.3.attention.self.value.weight', 'encoder.layer.21.intermediate.dense.weight', 'encoder.layer.7.attention.output.LayerNorm.weight', 'encoder.layer.2.attention.output.LayerNorm.bias', 'encoder.layer.1.attention.self.value.bias', 'encoder.layer.1.attention.output.dense.bias', 'encoder.layer.11.attention.self.query.weight', 'encoder.layer.11.attention.self.key.weight', 'encoder.layer.7.output.dense.bias', 'encoder.layer.8.output.dense.bias', 'encoder.layer.23.attention.self.key.bias', 'encoder.layer.8.attention.self.key.weight', 'encoder.layer.12.attention.output.LayerNorm.weight', 'encoder.layer.7.intermediate.dense.bias', 'encoder.layer.13.attention.self.key.weight', 'encoder.layer.3.attention.self.key.bias', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.10.output.dense.bias', 'encoder.layer.16.output.dense.weight', 'encoder.layer.14.attention.self.value.weight', 'encoder.layer.3.output.dense.bias', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.5.attention.self.query.weight', 'encoder.layer.13.intermediate.dense.bias', 'encoder.layer.21.attention.self.value.bias', 'encoder.layer.22.attention.output.LayerNorm.bias', 'encoder.layer.20.intermediate.dense.weight', 'encoder.layer.12.output.LayerNorm.bias', 'encoder.layer.17.attention.self.key.weight', 'encoder.layer.16.attention.output.dense.bias', 'encoder.layer.10.output.LayerNorm.bias', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.3.attention.output.dense.bias', 'encoder.layer.14.output.LayerNorm.bias', 'encoder.layer.18.output.LayerNorm.weight', 'encoder.layer.15.attention.output.LayerNorm.weight', 'encoder.layer.22.attention.self.value.bias', 'encoder.layer.22.attention.output.dense.bias', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.18.output.LayerNorm.bias', 'encoder.layer.5.attention.self.value.weight', 'encoder.layer.18.attention.self.value.bias', 'encoder.layer.22.output.dense.weight', 'encoder.layer.6.attention.self.value.bias', 'encoder.layer.0.attention.output.dense.bias', 'encoder.layer.21.attention.output.dense.weight', 'encoder.layer.23.attention.self.query.bias', 'embeddings.position_embeddings.weight', 'encoder.layer.6.attention.self.key.weight', 'encoder.layer.14.attention.self.key.weight', 'encoder.layer.8.attention.self.query.weight', 'encoder.layer.23.attention.self.value.bias', 'encoder.layer.7.attention.output.dense.bias', 'encoder.layer.0.attention.self.query.weight', 'encoder.layer.0.attention.output.dense.weight', 'encoder.layer.10.attention.output.dense.weight', 'encoder.layer.6.output.dense.weight', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.11.output.LayerNorm.weight', 'encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.layer.14.attention.self.query.weight', 'encoder.layer.12.attention.self.query.weight', 'encoder.layer.14.output.dense.bias', 'encoder.layer.12.output.LayerNorm.weight', 'encoder.layer.21.attention.self.key.weight', 'encoder.layer.9.attention.self.query.weight', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.2.attention.self.key.weight', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.5.output.LayerNorm.bias', 'encoder.layer.16.intermediate.dense.weight', 'encoder.layer.22.attention.output.LayerNorm.weight', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.23.attention.output.dense.bias', 'encoder.layer.2.attention.output.dense.bias', 'encoder.layer.9.attention.output.LayerNorm.weight', 'encoder.layer.20.output.dense.bias', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.9.attention.self.key.bias', 'encoder.layer.9.attention.output.LayerNorm.bias', 'encoder.layer.13.output.dense.weight', 'encoder.layer.19.attention.output.LayerNorm.bias', 'encoder.layer.5.attention.self.value.bias', 'encoder.layer.6.attention.output.LayerNorm.bias', 'encoder.layer.11.output.dense.weight', 'encoder.layer.18.attention.self.key.weight', 'encoder.layer.21.intermediate.dense.bias', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.1.output.dense.weight', 'encoder.layer.15.attention.self.key.weight', 'encoder.layer.16.attention.self.key.bias', 'encoder.layer.3.attention.self.value.bias', 'embeddings.token_type_embeddings.weight', 'encoder.layer.6.attention.self.query.weight', 'encoder.layer.20.attention.output.dense.weight', 'encoder.layer.14.attention.self.value.bias', 'encoder.layer.13.attention.output.LayerNorm.weight', 'encoder.layer.15.output.dense.weight', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.22.attention.self.query.bias', 'embeddings.word_embeddings.weight', 'encoder.layer.18.intermediate.dense.weight', 'encoder.layer.9.attention.output.dense.weight', 'encoder.layer.16.attention.output.dense.weight', 'encoder.layer.12.attention.self.key.bias', 'encoder.layer.5.attention.output.dense.bias', 'encoder.layer.10.intermediate.dense.weight', 'encoder.layer.23.attention.self.key.weight', 'encoder.layer.21.attention.output.LayerNorm.weight', 'encoder.layer.10.attention.self.query.bias', 'encoder.layer.16.attention.output.LayerNorm.bias', 'encoder.layer.12.attention.output.dense.bias', 'encoder.layer.21.attention.self.query.bias', 'encoder.layer.0.attention.self.query.bias', 'encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.layer.17.output.LayerNorm.bias', 'encoder.layer.5.attention.self.key.weight', 'encoder.layer.20.output.dense.weight', 'encoder.layer.7.attention.self.key.weight', 'encoder.layer.22.attention.self.value.weight', 'encoder.layer.21.output.LayerNorm.weight', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.9.attention.self.query.bias', 'encoder.layer.19.output.LayerNorm.weight', 'encoder.layer.8.attention.self.key.bias', 'encoder.layer.14.attention.output.LayerNorm.bias', 'encoder.layer.8.attention.output.LayerNorm.weight', 'encoder.layer.15.attention.self.key.bias', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.11.attention.self.key.bias', 'encoder.layer.10.attention.output.LayerNorm.weight', 'encoder.layer.6.attention.self.query.bias', 'encoder.layer.22.attention.self.key.weight', 'encoder.layer.17.attention.self.query.weight', 'encoder.layer.23.attention.output.dense.weight', 'encoder.layer.13.attention.output.LayerNorm.bias', 'encoder.layer.16.attention.output.LayerNorm.weight', 'encoder.layer.7.attention.output.LayerNorm.bias', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.15.attention.self.value.bias', 'encoder.layer.16.attention.self.query.weight', 'encoder.layer.0.attention.self.key.bias', 'encoder.layer.7.attention.self.query.bias', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.23.attention.output.LayerNorm.weight', 'encoder.layer.18.attention.self.query.weight', 'encoder.layer.4.attention.output.dense.bias', 'encoder.layer.13.attention.output.dense.weight', 'encoder.layer.23.attention.self.query.weight', 'encoder.layer.21.attention.output.LayerNorm.bias', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.7.output.dense.weight', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.23.intermediate.dense.weight', 'encoder.layer.18.attention.self.value.weight', 'encoder.layer.12.attention.self.key.weight', 'encoder.layer.19.output.dense.bias', 'encoder.layer.1.attention.output.LayerNorm.weight', 'encoder.layer.2.attention.self.key.bias', 'encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.layer.13.attention.self.query.bias', 'encoder.layer.8.output.LayerNorm.weight', 'encoder.layer.10.attention.output.dense.bias', 'encoder.layer.10.output.dense.weight', 'encoder.layer.19.intermediate.dense.weight', 'encoder.layer.20.output.LayerNorm.weight', 'encoder.layer.6.output.dense.bias', 'encoder.layer.12.attention.self.value.bias', 'encoder.layer.1.attention.self.query.bias', 'encoder.layer.16.attention.self.value.bias', 'encoder.layer.9.attention.self.value.bias', 'encoder.layer.0.output.dense.bias', 'encoder.layer.8.attention.output.dense.bias', 'encoder.layer.21.attention.self.key.bias', 'encoder.layer.23.output.dense.weight', 'encoder.layer.8.attention.self.value.weight', 'encoder.layer.21.attention.output.dense.bias', 'encoder.layer.13.output.LayerNorm.weight', 'encoder.layer.18.attention.output.LayerNorm.weight', 'encoder.layer.10.attention.self.value.bias', 'encoder.layer.21.attention.self.value.weight', 'encoder.layer.2.attention.self.value.bias', 'encoder.layer.22.output.dense.bias', 'encoder.layer.13.attention.self.key.bias', 'encoder.layer.15.output.LayerNorm.bias', 'encoder.layer.20.attention.self.query.bias', 'encoder.layer.23.intermediate.dense.bias', 'encoder.layer.9.output.LayerNorm.bias', 'encoder.layer.13.intermediate.dense.weight', 'encoder.layer.15.attention.self.query.bias', 'pooler.dense.weight', 'encoder.layer.22.attention.self.query.weight', 'encoder.layer.4.attention.output.LayerNorm.bias', 'encoder.layer.11.attention.output.dense.bias', 'encoder.layer.12.attention.output.dense.weight', 'encoder.layer.3.attention.self.query.weight', 'encoder.layer.18.attention.self.query.bias', 'encoder.layer.17.attention.self.value.bias', 'encoder.layer.12.intermediate.dense.bias', 'encoder.layer.15.intermediate.dense.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Overwriting existing adapter 'ep'.
Overwriting existing adapter 'tp'.
Overwriting existing adapter 'es'.
Overwriting existing adapter 'ts'.
Overwriting existing adapter fusion module 'ep,tp,es,ts'
05/09/2022 22:55:37 - INFO - __main__ -   Creating features from dataset file at .
/cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//tydiqa/xlm-KG_LR8e-6_EPOCH2.0_maxlen384_batchsize4_gradacc4
XLMConfig {
  "architectures": [
    "XLMRobertaForMaskedLM"
  ],
  "asm": false,
  "attention_dropout": 0.1,
  "attention_probs_dropout_prob": 0.1,
  "bos_index": 0,
  "bos_token_id": 0,
  "causal": false,
  "dropout": 0.1,
  "emb_dim": 1024,
  "embed_init_std": 0.02209708691207961,
  "end_n_top": 5,
  "eos_index": 1,
  "eos_token_id": 2,
  "gelu_activation": true,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "init_std": 0.02,
  "initializer_range": 0.02,
  "intermediate_size": 4096,
  "is_encoder": true,
  "lang_id": 0,
  "layer_norm_eps": 1e-05,
  "mask_index": 5,
  "mask_token_id": 0,
  "max_position_embeddings": 514,
  "model_type": "xlm",
  "n_heads": 16,
  "n_langs": 1,
  "n_layers": 24,
  "output_past": true,
  "pad_index": 2,
  "pad_token_id": 1,
  "sinusoidal_embeddings": false,
  "start_n_top": 5,
  "summary_activation": null,
  "summary_first_dropout": 0.1,
  "summary_proj_to_labels": true,
  "summary_type": "first",
  "summary_use_proj": true,
  "transformers_version": "4.17.0",
  "type_vocab_size": 1,
  "unk_index": 3,
  "use_lang_emb": false,
  "vocab_size": 250002
}

  0%|          | 0/565 [00:00<?, ?it/s] 71%|███████▏  | 403/565 [00:00<00:00, 4027.53it/s]100%|██████████| 565/565 [00:00<00:00, 3431.24it/s]
convert squad examples to features:   0%|          | 0/565 [00:00<?, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.
convert squad examples to features:   0%|          | 1/565 [00:00<01:07,  8.42it/s]convert squad examples to features:  12%|█▏        | 65/565 [00:00<00:02, 243.81it/s]convert squad examples to features:  23%|██▎       | 129/565 [00:00<00:01, 327.07it/s]convert squad examples to features:  34%|███▍      | 193/565 [00:00<00:00, 381.89it/s]convert squad examples to features:  45%|████▌     | 257/565 [00:00<00:00, 369.84it/s]convert squad examples to features:  52%|█████▏    | 294/565 [00:00<00:00, 353.43it/s]convert squad examples to features:  58%|█████▊    | 329/565 [00:01<00:00, 322.06it/s]convert squad examples to features:  68%|██████▊   | 385/565 [00:01<00:00, 334.93it/s]convert squad examples to features:  79%|███████▉  | 449/565 [00:01<00:00, 334.77it/s]convert squad examples to features:  91%|█████████ | 513/565 [00:01<00:00, 317.63it/s]convert squad examples to features: 100%|██████████| 565/565 [00:01<00:00, 339.19it/s]/cluster/project/sachan/yifan/softwares/anaconda/anaconda3/envs/xfactr/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2272: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

add example index and unique id:   0%|          | 0/565 [00:00<?, ?it/s]add example index and unique id: 100%|██████████| 565/565 [00:00<00:00, 578984.06it/s]
05/09/2022 22:55:39 - INFO - __main__ -   Saving features into cached file ./cached_tydiqa.goldp.id.dev.json_xlm-KG_LR8e-6_EPOCH2.0_maxlen384_batchsize4_gradacc4_384_id
05/09/2022 22:55:39 - INFO - __main__ -   ***** Running evaluation  *****
05/09/2022 22:55:39 - INFO - __main__ -     Num examples = 581
05/09/2022 22:55:39 - INFO - __main__ -     Batch size = 8
Evaluating:   0%|          | 0/73 [00:00<?, ?it/s]Evaluating:   1%|▏         | 1/73 [00:00<01:01,  1.18it/s]Evaluating:   3%|▎         | 2/73 [00:01<00:39,  1.80it/s]Evaluating:   4%|▍         | 3/73 [00:01<00:32,  2.15it/s]Evaluating:   5%|▌         | 4/73 [00:01<00:29,  2.38it/s]Evaluating:   7%|▋         | 5/73 [00:02<00:26,  2.52it/s]Evaluating:   8%|▊         | 6/73 [00:02<00:25,  2.61it/s]Evaluating:  10%|▉         | 7/73 [00:02<00:24,  2.67it/s]Evaluating:  11%|█         | 8/73 [00:03<00:23,  2.72it/s]Evaluating:  12%|█▏        | 9/73 [00:03<00:23,  2.75it/s]Evaluating:  14%|█▎        | 10/73 [00:04<00:22,  2.77it/s]Evaluating:  15%|█▌        | 11/73 [00:04<00:22,  2.77it/s]Evaluating:  16%|█▋        | 12/73 [00:04<00:21,  2.78it/s]Evaluating:  18%|█▊        | 13/73 [00:05<00:21,  2.79it/s]Evaluating:  19%|█▉        | 14/73 [00:05<00:21,  2.80it/s]Evaluating:  21%|██        | 15/73 [00:05<00:20,  2.81it/s]Evaluating:  22%|██▏       | 16/73 [00:06<00:20,  2.82it/s]Evaluating:  23%|██▎       | 17/73 [00:06<00:19,  2.81it/s]Evaluating:  25%|██▍       | 18/73 [00:06<00:19,  2.82it/s]Evaluating:  26%|██▌       | 19/73 [00:07<00:19,  2.82it/s]Evaluating:  27%|██▋       | 20/73 [00:07<00:18,  2.82it/s]Evaluating:  29%|██▉       | 21/73 [00:07<00:18,  2.82it/s]Evaluating:  30%|███       | 22/73 [00:08<00:18,  2.82it/s]Evaluating:  32%|███▏      | 23/73 [00:08<00:17,  2.82it/s]Evaluating:  33%|███▎      | 24/73 [00:09<00:17,  2.81it/s]Evaluating:  34%|███▍      | 25/73 [00:09<00:17,  2.80it/s]Evaluating:  36%|███▌      | 26/73 [00:09<00:16,  2.81it/s]Evaluating:  37%|███▋      | 27/73 [00:10<00:16,  2.81it/s]Evaluating:  38%|███▊      | 28/73 [00:10<00:16,  2.80it/s]Evaluating:  40%|███▉      | 29/73 [00:10<00:15,  2.79it/s]Evaluating:  41%|████      | 30/73 [00:11<00:15,  2.80it/s]Evaluating:  42%|████▏     | 31/73 [00:11<00:14,  2.80it/s]Evaluating:  44%|████▍     | 32/73 [00:11<00:14,  2.81it/s]Evaluating:  45%|████▌     | 33/73 [00:12<00:14,  2.80it/s]Evaluating:  47%|████▋     | 34/73 [00:12<00:13,  2.79it/s]Evaluating:  48%|████▊     | 35/73 [00:12<00:13,  2.79it/s]Evaluating:  49%|████▉     | 36/73 [00:13<00:13,  2.79it/s]Evaluating:  51%|█████     | 37/73 [00:13<00:12,  2.80it/s]Evaluating:  52%|█████▏    | 38/73 [00:14<00:12,  2.79it/s]Evaluating:  53%|█████▎    | 39/73 [00:14<00:12,  2.80it/s]Evaluating:  55%|█████▍    | 40/73 [00:14<00:11,  2.80it/s]Evaluating:  56%|█████▌    | 41/73 [00:15<00:11,  2.78it/s]Evaluating:  58%|█████▊    | 42/73 [00:15<00:11,  2.77it/s]Evaluating:  59%|█████▉    | 43/73 [00:15<00:10,  2.77it/s]Evaluating:  60%|██████    | 44/73 [00:16<00:10,  2.77it/s]Evaluating:  62%|██████▏   | 45/73 [00:16<00:10,  2.77it/s]Evaluating:  63%|██████▎   | 46/73 [00:16<00:09,  2.77it/s]Evaluating:  64%|██████▍   | 47/73 [00:17<00:09,  2.79it/s]Evaluating:  66%|██████▌   | 48/73 [00:17<00:08,  2.79it/s]Evaluating:  67%|██████▋   | 49/73 [00:17<00:08,  2.79it/s]Evaluating:  68%|██████▊   | 50/73 [00:18<00:08,  2.79it/s]Evaluating:  70%|██████▉   | 51/73 [00:18<00:07,  2.77it/s]Evaluating:  71%|███████   | 52/73 [00:19<00:07,  2.79it/s]Evaluating:  73%|███████▎  | 53/73 [00:19<00:07,  2.78it/s]Evaluating:  74%|███████▍  | 54/73 [00:19<00:06,  2.77it/s]Evaluating:  75%|███████▌  | 55/73 [00:20<00:06,  2.71it/s]Evaluating:  77%|███████▋  | 56/73 [00:20<00:06,  2.74it/s]Evaluating:  78%|███████▊  | 57/73 [00:20<00:05,  2.75it/s]Evaluating:  79%|███████▉  | 58/73 [00:21<00:05,  2.76it/s]Evaluating:  81%|████████  | 59/73 [00:21<00:05,  2.77it/s]Evaluating:  82%|████████▏ | 60/73 [00:21<00:04,  2.77it/s]Evaluating:  84%|████████▎ | 61/73 [00:22<00:04,  2.78it/s]Evaluating:  85%|████████▍ | 62/73 [00:22<00:03,  2.79it/s]Evaluating:  86%|████████▋ | 63/73 [00:23<00:03,  2.78it/s]Evaluating:  88%|████████▊ | 64/73 [00:23<00:03,  2.79it/s]Evaluating:  89%|████████▉ | 65/73 [00:23<00:02,  2.79it/s]Evaluating:  90%|█████████ | 66/73 [00:24<00:02,  2.79it/s]Evaluating:  92%|█████████▏| 67/73 [00:24<00:02,  2.79it/s]Evaluating:  93%|█████████▎| 68/73 [00:24<00:01,  2.79it/s]Evaluating:  95%|█████████▍| 69/73 [00:25<00:01,  2.78it/s]Evaluating:  96%|█████████▌| 70/73 [00:25<00:01,  2.78it/s]Evaluating:  97%|█████████▋| 71/73 [00:25<00:00,  2.78it/s]Evaluating:  99%|█████████▊| 72/73 [00:26<00:00,  2.77it/s]Evaluating: 100%|██████████| 73/73 [00:26<00:00,  3.09it/s]Evaluating: 100%|██████████| 73/73 [00:26<00:00,  2.75it/s]
05/09/2022 22:56:06 - INFO - __main__ -     Evaluation done in total 26.508540 secs (0.045626 sec per example)
05/09/2022 22:56:08 - INFO - __main__ -   Results: {'exact': 66.01769911504425, 'f1': 80.87726014405605, 'total': 565, 'HasAns_exact': 66.01769911504425, 'HasAns_f1': 80.87726014405605, 'HasAns_total': 565, 'best_exact': 66.01769911504425, 'best_exact_thresh': 0.0, 'best_f1': 80.87726014405605, 'best_f1_thresh': 0.0}
  ko 
2022-05-09 22:56:11.243489: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0
05/09/2022 22:56:13 - WARNING - __main__ -   Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, 16-bits training: False
You are using a model of type xlm-roberta to instantiate a model of type xlm. This is not supported for all configurations of models and can yield errors.
Some weights of the model checkpoint at /cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//tydiqa/xlm-KG_LR8e-6_EPOCH2.0_maxlen384_batchsize4_gradacc4 were not used when initializing XLMRobertaModel: ['base_model.encoder.layer.0.attention.self.key.bias', 'base_model.encoder.layer.11.attention.output.LayerNorm.bias', 'base_model.encoder.layer.14.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.15.intermediate.dense.weight', 'base_model.embeddings.word_embeddings.weight', 'base_model.encoder.layer.1.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.6.output.dense.weight', 'base_model.encoder.layer.8.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.2.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.12.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.7.output.dense.weight', 'base_model.encoder.layer.9.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.13.attention.self.value.weight', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.18.intermediate.dense.bias', 'base_model.encoder.layer.18.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.1.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.1.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.1.attention.self.key.weight', 'base_model.encoder.layer.5.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.3.attention.output.LayerNorm.bias', 'base_model.encoder.layer.18.output.dense.bias', 'base_model.encoder.layer.23.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.2.attention.output.dense.weight', 'base_model.encoder.layer.4.attention.output.dense.weight', 'base_model.encoder.layer.4.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.10.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.16.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.5.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.0.output.LayerNorm.weight', 'base_model.encoder.layer.15.attention.self.key.bias', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.23.attention.output.dense.weight', 'base_model.encoder.layer.6.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.15.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.5.output.dense.weight', 'base_model.encoder.layer.23.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.5.intermediate.dense.weight', 'base_model.encoder.layer.21.attention.output.LayerNorm.bias', 'base_model.embeddings.LayerNorm.bias', 'base_model.encoder.layer.0.attention.output.dense.bias', 'base_model.encoder.layer.6.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.13.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.5.attention.output.dense.weight', 'base_model.encoder.layer.11.attention.output.dense.bias', 'base_model.encoder.layer.17.intermediate.dense.bias', 'base_model.encoder.layer.20.output.LayerNorm.weight', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.16.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.0.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.19.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.3.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.9.attention.output.dense.weight', 'base_model.encoder.layer.14.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.15.attention.self.value.bias', 'base_model.encoder.layer.5.attention.output.LayerNorm.weight', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.2.attention.self.key.bias', 'base_model.encoder.layer.14.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.8.attention.output.dense.weight', 'base_model.encoder.layer.8.attention.self.key.bias', 'base_model.encoder.layer.23.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.21.output.dense.bias', 'base_model.encoder.layer.23.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.22.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.15.attention.output.dense.bias', 'base_model.encoder.layer.7.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.11.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.21.intermediate.dense.weight', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.6.attention.self.query.weight', 'base_model.encoder.layer.6.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.19.attention.output.dense.bias', 'base_model.encoder.layer.10.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.7.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.10.intermediate.dense.bias', 'base_model.encoder.layer.6.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.15.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.9.attention.self.key.bias', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.19.attention.self.value.bias', 'base_model.encoder.layer.13.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.17.output.LayerNorm.bias', 'base_model.encoder.layer.4.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.13.attention.output.dense.bias', 'base_model.encoder.layer.19.output.dense.weight', 'base_model.encoder.layer.14.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.1.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.15.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.10.attention.self.query.weight', 'base_model.encoder.layer.6.output.LayerNorm.bias', 'base_model.encoder.layer.0.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.17.output.dense.bias', 'base_model.encoder.layer.3.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.15.attention.self.query.weight', 'base_model.encoder.layer.3.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.5.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.9.attention.output.dense.bias', 'base_model.encoder.layer.23.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.1.output.LayerNorm.bias', 'base_model.encoder.layer.5.output.dense.bias', 'base_model.encoder.layer.15.output.LayerNorm.bias', 'base_model.encoder.layer.0.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.23.output.LayerNorm.bias', 'base_model.encoder.layer.20.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.1.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.7.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.13.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.18.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.10.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.15.attention.self.key.weight', 'base_model.encoder.layer.10.output.LayerNorm.bias', 'base_model.encoder.layer.13.output.dense.weight', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.13.attention.output.dense.weight', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.2.attention.self.query.weight', 'base_model.encoder.layer.10.intermediate.dense.weight', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.1.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.6.attention.self.value.bias', 'base_model.encoder.layer.6.attention.output.LayerNorm.bias', 'base_model.encoder.layer.12.attention.output.dense.weight', 'base_model.encoder.layer.20.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.7.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.7.attention.output.dense.weight', 'base_model.encoder.layer.19.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.10.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.14.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.21.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.6.output.LayerNorm.weight', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.22.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.15.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.9.attention.self.value.bias', 'base_model.encoder.layer.16.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.1.output.dense.weight', 'base_model.encoder.layer.18.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.2.attention.self.query.bias', 'base_model.encoder.layer.11.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.17.attention.output.dense.bias', 'base_model.encoder.layer.4.attention.output.dense.bias', 'base_model.encoder.layer.11.attention.self.key.bias', 'base_model.encoder.layer.0.output.dense.bias', 'base_model.encoder.layer.12.output.dense.bias', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.12.intermediate.dense.bias', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.20.output.adapters.ep.adapter_up.weight', 'base_model.pooler.dense.weight', 'base_model.encoder.layer.15.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.2.attention.self.value.bias', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.0.attention.output.LayerNorm.bias', 'base_model.encoder.layer.15.intermediate.dense.bias', 'base_model.encoder.layer.4.attention.self.value.bias', 'base_model.encoder.layer.10.attention.output.LayerNorm.weight', 'base_model.encoder.layer.16.attention.output.dense.weight', 'base_model.encoder.layer.11.attention.self.query.weight', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.11.attention.output.LayerNorm.weight', 'base_model.encoder.layer.18.attention.self.query.weight', 'base_model.encoder.layer.20.attention.output.dense.weight', 'base_model.encoder.layer.18.attention.output.dense.bias', 'base_model.encoder.layer.21.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.7.intermediate.dense.bias', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.7.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.2.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.23.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.8.attention.output.dense.bias', 'base_model.encoder.layer.2.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.5.attention.output.dense.bias', 'base_model.encoder.layer.16.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.12.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.9.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.18.attention.self.key.weight', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.2.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.19.output.LayerNorm.bias', 'base_model.encoder.layer.12.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.3.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.0.attention.self.value.bias', 'base_model.encoder.layer.21.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.11.attention.output.dense.weight', 'qa_outputs.weight', 'base_model.encoder.layer.16.attention.self.query.bias', 'base_model.encoder.layer.11.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.23.output.LayerNorm.weight', 'base_model.encoder.layer.1.attention.self.value.weight', 'base_model.encoder.layer.7.attention.output.dense.bias', 'base_model.encoder.layer.15.attention.output.dense.weight', 'base_model.encoder.layer.17.intermediate.dense.weight', 'base_model.encoder.layer.8.attention.self.query.weight', 'base_model.encoder.layer.12.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.19.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.17.attention.self.value.bias', 'base_model.encoder.layer.3.intermediate.dense.weight', 'base_model.encoder.layer.23.attention.self.value.weight', 'base_model.encoder.layer.3.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.4.output.LayerNorm.bias', 'base_model.encoder.layer.10.attention.self.key.bias', 'base_model.encoder.layer.8.attention.output.LayerNorm.bias', 'base_model.encoder.layer.19.attention.self.query.weight', 'base_model.encoder.layer.19.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.10.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.20.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.5.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.14.attention.self.query.bias', 'base_model.encoder.layer.8.attention.output.LayerNorm.weight', 'base_model.encoder.layer.22.output.dense.bias', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.4.output.dense.bias', 'base_model.encoder.layer.1.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.1.output.adapters.ep.adapter_up.bias', 'base_model.embeddings.position_embeddings.weight', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.18.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.14.attention.output.LayerNorm.bias', 'base_model.encoder.layer.5.output.LayerNorm.bias', 'base_model.encoder.layer.19.attention.output.dense.weight', 'base_model.encoder.layer.21.attention.self.key.weight', 'base_model.encoder.layer.15.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.8.attention.self.key.weight', 'base_model.encoder.layer.10.attention.output.dense.weight', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.0.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.6.attention.output.LayerNorm.weight', 'base_model.encoder.layer.10.output.dense.weight', 'base_model.encoder.layer.6.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.12.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.19.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.22.attention.output.dense.bias', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.1.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.0.output.dense.weight', 'base_model.encoder.layer.7.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.5.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.15.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.16.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.5.intermediate.dense.bias', 'base_model.encoder.layer.21.output.LayerNorm.bias', 'base_model.encoder.layer.12.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.9.attention.output.LayerNorm.weight', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.5.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.18.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.12.attention.output.dense.bias', 'base_model.encoder.layer.12.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.17.output.dense.weight', 'base_model.encoder.layer.14.output.LayerNorm.bias', 'base_model.encoder.layer.17.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.19.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.20.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.13.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.15.attention.output.LayerNorm.bias', 'base_model.encoder.layer.2.output.LayerNorm.weight', 'base_model.encoder.layer.9.output.LayerNorm.weight', 'base_model.encoder.layer.19.attention.self.query.bias', 'base_model.encoder.layer.11.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.22.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.23.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.17.attention.self.key.weight', 'base_model.encoder.layer.7.intermediate.dense.weight', 'base_model.encoder.layer.13.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.5.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.22.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.22.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.11.intermediate.dense.bias', 'base_model.encoder.layer.9.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.13.attention.output.LayerNorm.weight', 'base_model.encoder.layer.10.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.13.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.6.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.14.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.1.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.7.attention.self.key.bias', 'base_model.encoder.layer.9.attention.self.query.weight', 'base_model.encoder.layer.21.attention.self.value.weight', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.2.attention.output.dense.bias', 'base_model.encoder.layer.8.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.13.attention.self.key.bias', 'base_model.encoder.layer.0.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.4.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.4.attention.output.LayerNorm.bias', 'base_model.encoder.layer.23.attention.output.LayerNorm.weight', 'base_model.encoder.layer.16.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.17.attention.output.LayerNorm.bias', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.19.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.16.attention.self.value.weight', 'base_model.encoder.layer.7.attention.self.value.bias', 'base_model.encoder.layer.21.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.15.attention.output.LayerNorm.weight', 'base_model.encoder.layer.11.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.0.intermediate.dense.weight', 'base_model.encoder.layer.5.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.4.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.16.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.11.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.4.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.3.attention.self.query.bias', 'base_model.encoder.layer.20.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.21.attention.self.key.bias', 'base_model.encoder.layer.7.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.9.intermediate.dense.bias', 'base_model.encoder.layer.3.intermediate.dense.bias', 'base_model.encoder.layer.11.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.22.attention.self.value.bias', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.4.output.LayerNorm.weight', 'base_model.encoder.layer.13.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.17.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.22.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.6.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.7.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.14.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.8.attention.self.value.weight', 'base_model.encoder.layer.2.output.dense.weight', 'base_model.encoder.layer.23.attention.self.value.bias', 'base_model.encoder.layer.12.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.17.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.1.attention.self.query.bias', 'base_model.encoder.layer.1.intermediate.dense.bias', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.2.attention.output.LayerNorm.bias', 'base_model.encoder.layer.12.attention.self.query.bias', 'base_model.encoder.layer.16.intermediate.dense.weight', 'base_model.encoder.layer.14.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.7.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.21.attention.output.dense.weight', 'base_model.encoder.layer.10.attention.self.value.bias', 'base_model.encoder.layer.12.attention.output.LayerNorm.weight', 'base_model.encoder.layer.8.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.16.output.LayerNorm.bias', 'base_model.encoder.layer.3.attention.self.query.weight', 'base_model.encoder.layer.19.intermediate.dense.weight', 'base_model.encoder.layer.18.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.21.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.12.output.LayerNorm.bias', 'base_model.encoder.layer.18.output.LayerNorm.weight', 'base_model.encoder.layer.5.attention.self.value.weight', 'base_model.encoder.layer.20.output.dense.weight', 'base_model.encoder.layer.20.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.9.output.LayerNorm.bias', 'base_model.encoder.layer.14.attention.output.dense.bias', 'base_model.encoder.layer.18.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.4.output.dense.weight', 'base_model.encoder.layer.5.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.20.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.16.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.1.attention.output.LayerNorm.weight', 'base_model.encoder.layer.3.output.LayerNorm.bias', 'base_model.encoder.layer.22.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.12.intermediate.dense.weight', 'base_model.encoder.layer.3.output.dense.bias', 'base_model.encoder.layer.10.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.18.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.12.attention.self.value.bias', 'base_model.encoder.layer.3.output.dense.weight', 'base_model.encoder.layer.1.attention.self.value.bias', 'base_model.encoder.layer.12.attention.self.query.weight', 'base_model.encoder.layer.1.attention.self.key.bias', 'base_model.encoder.layer.18.attention.self.value.bias', 'base_model.encoder.layer.17.attention.output.dense.weight', 'base_model.encoder.layer.23.output.dense.bias', 'base_model.encoder.layer.12.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.8.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.0.attention.output.dense.weight', 'base_model.encoder.layer.11.intermediate.dense.weight', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.4.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.7.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.7.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.14.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.3.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.15.output.dense.bias', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.21.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.20.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.13.attention.self.query.weight', 'base_model.encoder.layer.19.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.5.attention.self.value.bias', 'base_model.encoder.layer.21.output.LayerNorm.weight', 'base_model.encoder.layer.3.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.0.attention.self.query.weight', 'base_model.encoder.layer.7.output.dense.bias', 'base_model.encoder.layer.17.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.13.attention.self.value.bias', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.3.attention.output.dense.weight', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.17.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.9.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.19.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.10.output.dense.bias', 'base_model.encoder.layer.6.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.4.attention.self.key.bias', 'base_model.encoder.layer.19.output.dense.bias', 'base_model.encoder.layer.11.output.LayerNorm.weight', 'base_model.encoder.layer.18.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.22.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.2.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.13.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.0.attention.self.query.bias', 'base_model.encoder.layer.8.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.10.attention.self.value.weight', 'base_model.encoder.layer.11.attention.self.key.weight', 'base_model.encoder.layer.1.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.11.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.4.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.2.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.20.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.9.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.8.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.11.output.dense.weight', 'base_model.encoder.layer.14.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.9.attention.self.query.bias', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.17.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.17.attention.output.LayerNorm.weight', 'base_model.encoder.layer.23.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.13.intermediate.dense.bias', 'base_model.encoder.layer.2.attention.self.key.weight', 'base_model.encoder.layer.9.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.12.attention.self.key.weight', 'base_model.encoder.layer.13.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.10.attention.output.dense.bias', 'base_model.encoder.layer.14.attention.output.dense.weight', 'base_model.encoder.layer.16.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.16.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.20.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.9.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.18.attention.output.LayerNorm.bias', 'base_model.encoder.layer.5.output.LayerNorm.weight', 'base_model.encoder.layer.9.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.23.attention.self.key.bias', 'base_model.encoder.layer.17.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.6.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.1.attention.output.LayerNorm.bias', 'base_model.encoder.layer.16.attention.self.key.weight', 'base_model.encoder.layer.6.attention.self.value.weight', 'base_model.encoder.layer.8.output.LayerNorm.bias', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.12.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.4.attention.output.LayerNorm.weight', 'base_model.encoder.layer.11.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.17.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.6.attention.output.dense.weight', 'base_model.encoder.layer.15.output.LayerNorm.weight', 'base_model.encoder.layer.0.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.3.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.8.attention.self.query.bias', 'base_model.encoder.layer.15.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.15.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.19.attention.self.key.weight', 'base_model.encoder.layer.1.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.4.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.14.output.dense.bias', 'base_model.encoder.layer.3.output.LayerNorm.weight', 'base_model.encoder.layer.6.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.20.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.21.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.5.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.23.attention.output.LayerNorm.bias', 'base_model.encoder.layer.23.output.dense.weight', 'base_model.encoder.layer.23.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.17.attention.self.value.weight', 'base_model.encoder.layer.4.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.8.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.0.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.11.attention.self.value.bias', 'base_model.encoder.layer.17.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.17.attention.self.query.weight', 'base_model.encoder.layer.22.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.22.output.LayerNorm.bias', 'base_model.encoder.layer.0.attention.self.key.weight', 'base_model.encoder.layer.11.output.dense.bias', 'base_model.encoder.layer.17.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.20.attention.output.LayerNorm.weight', 'base_model.encoder.layer.5.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.18.attention.self.value.weight', 'base_model.encoder.layer.22.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.4.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.20.attention.self.value.weight', 'base_model.encoder.layer.20.intermediate.dense.bias', 'base_model.encoder.layer.0.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.9.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.22.attention.output.LayerNorm.bias', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.15.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.18.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.1.intermediate.dense.weight', 'base_model.encoder.layer.6.output.dense.bias', 'base_model.encoder.layer.14.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.20.attention.self.key.bias', 'base_model.encoder.layer.4.attention.self.query.weight', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.19.attention.output.LayerNorm.bias', 'base_model.encoder.layer.21.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.15.attention.self.query.bias', 'base_model.encoder.layer.0.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.22.output.LayerNorm.weight', 'base_model.encoder.layer.21.output.dense.weight', 'base_model.encoder.layer.6.intermediate.dense.weight', 'base_model.encoder.layer.22.attention.self.query.weight', 'base_model.encoder.layer.14.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.11.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.6.attention.self.key.bias', 'base_model.encoder.layer.16.output.dense.weight', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.10.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.19.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.5.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.1.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.18.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.16.attention.self.query.weight', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.21.intermediate.dense.bias', 'base_model.encoder.layer.19.intermediate.dense.bias', 'base_model.encoder.layer.3.attention.self.value.weight', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.23.intermediate.dense.bias', 'base_model.encoder.layer.21.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.18.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.2.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.9.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.21.attention.self.value.bias', 'base_model.encoder.layer.5.attention.self.key.weight', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.23.intermediate.dense.weight', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.8.intermediate.dense.weight', 'base_model.encoder.layer.18.output.dense.weight', 'base_model.encoder.layer.13.output.dense.bias', 'base_model.encoder.layer.1.attention.self.query.weight', 'base_model.encoder.layer.12.output.LayerNorm.weight', 'base_model.encoder.layer.19.output.LayerNorm.weight', 'base_model.embeddings.token_type_embeddings.weight', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.12.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.12.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.14.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.3.attention.self.key.weight', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.19.attention.self.key.bias', 'base_model.encoder.layer.2.output.dense.bias', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.2.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.6.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.0.intermediate.dense.bias', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.9.output.dense.weight', 'base_model.encoder.layer.17.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.15.attention.self.value.weight', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.2.intermediate.dense.bias', 'base_model.encoder.layer.5.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.8.output.dense.weight', 'base_model.encoder.layer.0.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.5.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.20.attention.output.LayerNorm.bias', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.7.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.13.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.15.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.16.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.21.attention.self.query.weight', 'base_model.encoder.layer.9.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.6.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.3.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.20.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.10.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.19.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.21.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.20.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.9.output.adapters.es.adapter_down.0.weight', 'base_model.pooler.dense.bias', 'base_model.encoder.layer.8.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.20.output.dense.bias', 'base_model.encoder.layer.1.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.7.attention.output.LayerNorm.weight', 'base_model.encoder.layer.16.attention.output.LayerNorm.bias', 'base_model.encoder.layer.17.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.2.output.LayerNorm.bias', 'base_model.encoder.layer.12.attention.self.value.weight', 'base_model.encoder.layer.14.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.18.attention.output.dense.weight', 'base_model.encoder.layer.22.attention.self.key.bias', 'base_model.encoder.layer.8.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.22.intermediate.dense.weight', 'base_model.encoder.layer.10.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.0.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.14.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.7.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.22.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.0.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.4.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.8.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.13.output.LayerNorm.bias', 'base_model.encoder.layer.20.attention.self.value.bias', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.3.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.21.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.9.attention.self.key.weight', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.20.attention.self.key.weight', 'base_model.encoder.layer.19.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.13.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.23.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.18.attention.self.query.bias', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.19.attention.self.value.weight', 'base_model.encoder.layer.11.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.23.attention.output.dense.bias', 'base_model.encoder.layer.0.output.LayerNorm.bias', 'base_model.encoder.layer.10.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.8.attention.self.value.bias', 'base_model.encoder.layer.14.attention.self.value.weight', 'base_model.encoder.layer.14.attention.self.value.bias', 'base_model.encoder.layer.18.attention.self.key.bias', 'base_model.encoder.layer.14.attention.self.query.weight', 'base_model.encoder.layer.2.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.11.attention.self.value.weight', 'base_model.encoder.layer.7.attention.self.query.weight', 'base_model.encoder.layer.1.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.0.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.12.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.16.intermediate.dense.bias', 'base_model.encoder.layer.14.intermediate.dense.weight', 'base_model.encoder.layer.19.attention.output.LayerNorm.weight', 'base_model.encoder.layer.23.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.17.attention.self.key.bias', 'base_model.encoder.layer.9.attention.self.value.weight', 'base_model.encoder.layer.21.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.8.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.4.intermediate.dense.bias', 'base_model.encoder.layer.9.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.13.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.16.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.20.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.8.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.21.attention.output.LayerNorm.weight', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.10.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.2.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.13.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.1.output.LayerNorm.weight', 'base_model.encoder.layer.20.attention.self.query.bias', 'base_model.encoder.layer.13.output.LayerNorm.weight', 'base_model.encoder.layer.10.attention.output.LayerNorm.bias', 'base_model.encoder.layer.2.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.15.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.3.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.6.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.14.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.10.output.LayerNorm.weight', 'base_model.encoder.layer.11.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.12.attention.output.LayerNorm.bias', 'base_model.encoder.layer.20.attention.output.dense.bias', 'base_model.encoder.layer.21.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.2.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.21.attention.self.query.bias', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.7.attention.output.LayerNorm.bias', 'base_model.encoder.layer.0.attention.self.value.weight', 'base_model.encoder.layer.5.attention.self.query.bias', 'base_model.encoder.layer.3.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.4.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.2.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.5.attention.self.key.bias', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.13.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.16.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.12.output.dense.weight', 'qa_outputs.bias', 'base_model.encoder.layer.1.output.dense.bias', 'base_model.encoder.layer.17.output.LayerNorm.weight', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.5.attention.self.query.weight', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.12.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.13.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.15.output.adapters.tp.adapter_down.0.bias', 'base_model.embeddings.position_ids', 'base_model.encoder.layer.18.attention.output.LayerNorm.weight', 'base_model.encoder.layer.6.intermediate.dense.bias', 'base_model.encoder.layer.10.attention.self.query.bias', 'base_model.encoder.layer.18.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.23.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.4.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.19.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.3.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.22.output.dense.weight', 'base_model.encoder.layer.13.intermediate.dense.weight', 'base_model.encoder.layer.13.attention.output.LayerNorm.bias', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.11.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.5.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.8.intermediate.dense.bias', 'base_model.encoder.layer.7.attention.self.query.bias', 'base_model.encoder.layer.8.output.dense.bias', 'base_model.encoder.layer.7.attention.self.key.weight', 'base_model.encoder.layer.16.attention.output.dense.bias', 'base_model.encoder.layer.8.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.22.attention.self.key.weight', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.22.attention.self.value.weight', 'base_model.encoder.layer.21.attention.output.dense.bias', 'base_model.encoder.layer.23.attention.self.key.weight', 'base_model.encoder.layer.4.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.11.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.6.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.2.attention.output.LayerNorm.weight', 'base_model.encoder.layer.18.intermediate.dense.weight', 'base_model.encoder.layer.0.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.19.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.3.attention.self.value.bias', 'base_model.encoder.layer.15.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.11.attention.self.query.bias', 'base_model.encoder.layer.14.attention.output.LayerNorm.weight', 'base_model.encoder.layer.16.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.3.attention.self.key.bias', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.7.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.14.output.LayerNorm.weight', 'base_model.encoder.layer.4.attention.self.value.weight', 'base_model.encoder.layer.12.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.16.attention.output.LayerNorm.weight', 'base_model.encoder.layer.14.attention.self.key.weight', 'base_model.encoder.layer.12.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.19.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.3.attention.output.dense.bias', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.23.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.8.output.LayerNorm.weight', 'base_model.encoder.layer.8.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.16.attention.self.key.bias', 'base_model.encoder.layer.6.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.9.output.dense.bias', 'base_model.encoder.layer.3.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.7.output.LayerNorm.bias', 'base_model.encoder.layer.8.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.17.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.15.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.22.attention.output.dense.weight', 'base_model.encoder.layer.10.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.4.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.9.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.22.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.3.attention.output.LayerNorm.weight', 'base_model.encoder.layer.11.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.7.output.LayerNorm.weight', 'base_model.encoder.layer.14.intermediate.dense.bias', 'base_model.encoder.layer.6.attention.self.key.weight', 'base_model.encoder.layer.15.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.1.attention.output.dense.bias', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.22.attention.self.query.bias', 'base_model.encoder.layer.2.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.18.output.LayerNorm.bias', 'base_model.encoder.layer.10.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.12.attention.self.key.bias', 'base_model.encoder.layer.6.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.22.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.13.attention.self.key.weight', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.embeddings.LayerNorm.weight', 'base_model.encoder.layer.4.intermediate.dense.weight', 'base_model.encoder.layer.7.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.18.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.22.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.1.attention.output.dense.weight', 'base_model.encoder.layer.18.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.5.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.16.output.LayerNorm.weight', 'base_model.encoder.layer.10.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.14.attention.self.key.bias', 'base_model.encoder.layer.9.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.22.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.10.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.2.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.21.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.23.attention.self.query.weight', 'base_model.encoder.layer.0.attention.output.LayerNorm.weight', 'base_model.encoder.layer.6.attention.output.dense.bias', 'base_model.encoder.layer.1.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.4.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.7.attention.self.value.weight', 'base_model.encoder.layer.17.attention.self.query.bias', 'base_model.encoder.layer.10.attention.self.key.weight', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.2.intermediate.dense.weight', 'base_model.encoder.layer.21.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.22.attention.output.LayerNorm.weight', 'base_model.encoder.layer.9.attention.output.LayerNorm.bias', 'base_model.encoder.layer.2.attention.self.value.weight', 'base_model.encoder.layer.16.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.23.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.17.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.23.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.3.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.13.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.14.output.dense.weight', 'base_model.encoder.layer.4.attention.self.query.bias', 'base_model.encoder.layer.19.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.20.output.LayerNorm.bias', 'base_model.encoder.layer.17.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.20.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.5.attention.output.LayerNorm.bias', 'base_model.encoder.layer.20.attention.self.query.weight', 'base_model.encoder.layer.20.intermediate.dense.weight', 'base_model.encoder.layer.17.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.4.attention.self.key.weight', 'base_model.encoder.layer.21.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.22.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.7.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.16.output.dense.bias', 'base_model.encoder.layer.3.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.6.attention.self.query.bias', 'base_model.encoder.layer.23.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.16.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.9.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.0.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.11.output.LayerNorm.bias', 'base_model.encoder.layer.13.attention.self.query.bias', 'base_model.encoder.layer.16.attention.self.value.bias', 'base_model.encoder.layer.8.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.9.intermediate.dense.weight', 'base_model.encoder.layer.22.intermediate.dense.bias', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.2.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.15.output.dense.weight', 'base_model.encoder.layer.18.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.11.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.0.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.23.attention.self.query.bias']
- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of XLMRobertaModel were not initialized from the model checkpoint at /cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//tydiqa/xlm-KG_LR8e-6_EPOCH2.0_maxlen384_batchsize4_gradacc4 and are newly initialized: ['encoder.layer.6.attention.output.LayerNorm.weight', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.2.attention.output.dense.bias', 'encoder.layer.8.attention.self.key.bias', 'encoder.layer.7.attention.self.key.weight', 'encoder.layer.21.output.LayerNorm.bias', 'encoder.layer.16.output.dense.weight', 'encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.layer.21.attention.self.query.weight', 'encoder.layer.12.attention.self.query.weight', 'encoder.layer.4.attention.self.key.weight', 'encoder.layer.18.output.dense.weight', 'encoder.layer.15.attention.output.LayerNorm.bias', 'encoder.layer.11.attention.self.value.weight', 'encoder.layer.13.attention.self.key.weight', 'encoder.layer.9.output.dense.weight', 'encoder.layer.1.attention.output.LayerNorm.weight', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.1.attention.self.key.weight', 'encoder.layer.7.attention.output.LayerNorm.bias', 'encoder.layer.12.output.dense.bias', 'encoder.layer.15.intermediate.dense.bias', 'encoder.layer.21.intermediate.dense.weight', 'encoder.layer.4.attention.self.value.weight', 'encoder.layer.19.output.LayerNorm.bias', 'encoder.layer.10.attention.output.dense.weight', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.18.attention.output.LayerNorm.weight', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.15.output.LayerNorm.weight', 'encoder.layer.21.intermediate.dense.bias', 'encoder.layer.6.output.dense.weight', 'encoder.layer.8.attention.output.dense.bias', 'encoder.layer.19.attention.self.key.weight', 'encoder.layer.14.attention.self.value.weight', 'encoder.layer.19.attention.self.key.bias', 'encoder.layer.5.attention.output.dense.weight', 'encoder.layer.1.attention.self.query.weight', 'encoder.layer.5.attention.output.LayerNorm.weight', 'encoder.layer.9.attention.self.key.weight', 'encoder.layer.4.attention.self.key.bias', 'encoder.layer.1.attention.self.value.weight', 'encoder.layer.17.attention.output.dense.weight', 'encoder.layer.8.attention.output.LayerNorm.weight', 'encoder.layer.20.output.dense.bias', 'encoder.layer.23.output.LayerNorm.weight', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.11.attention.output.dense.bias', 'encoder.layer.19.attention.output.LayerNorm.weight', 'encoder.layer.23.attention.output.LayerNorm.weight', 'encoder.layer.3.output.dense.weight', 'encoder.layer.8.attention.self.value.bias', 'encoder.layer.10.attention.self.value.weight', 'encoder.layer.17.output.dense.weight', 'encoder.layer.19.attention.self.query.weight', 'encoder.layer.7.output.LayerNorm.bias', 'encoder.layer.19.intermediate.dense.bias', 'encoder.layer.15.output.LayerNorm.bias', 'encoder.layer.5.attention.self.query.weight', 'encoder.layer.17.intermediate.dense.weight', 'encoder.layer.4.output.dense.weight', 'encoder.layer.18.attention.self.value.weight', 'encoder.layer.15.attention.self.key.bias', 'encoder.layer.18.attention.output.LayerNorm.bias', 'encoder.layer.8.output.dense.bias', 'encoder.layer.0.attention.self.value.weight', 'encoder.layer.1.attention.self.query.bias', 'encoder.layer.17.attention.self.value.bias', 'encoder.layer.6.attention.self.query.weight', 'encoder.layer.22.output.LayerNorm.weight', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.9.attention.output.LayerNorm.weight', 'encoder.layer.3.attention.self.query.bias', 'encoder.layer.23.intermediate.dense.bias', 'encoder.layer.15.intermediate.dense.weight', 'encoder.layer.22.attention.output.LayerNorm.weight', 'encoder.layer.9.attention.self.key.bias', 'encoder.layer.20.attention.self.query.bias', 'encoder.layer.13.output.LayerNorm.weight', 'encoder.layer.10.attention.output.LayerNorm.bias', 'encoder.layer.10.output.dense.bias', 'encoder.layer.7.attention.self.query.bias', 'encoder.layer.5.output.dense.bias', 'encoder.layer.5.output.dense.weight', 'encoder.layer.0.attention.self.query.bias', 'encoder.layer.6.output.LayerNorm.bias', 'encoder.layer.1.output.dense.weight', 'encoder.layer.3.attention.output.dense.bias', 'encoder.layer.11.attention.self.key.bias', 'encoder.layer.15.attention.self.value.weight', 'encoder.layer.0.attention.output.dense.weight', 'encoder.layer.17.attention.self.key.weight', 'encoder.layer.14.attention.output.dense.bias', 'encoder.layer.13.attention.self.value.bias', 'encoder.layer.17.attention.self.value.weight', 'encoder.layer.22.output.dense.weight', 'encoder.layer.21.output.dense.bias', 'encoder.layer.19.attention.self.query.bias', 'encoder.layer.20.output.LayerNorm.weight', 'encoder.layer.3.attention.self.query.weight', 'embeddings.word_embeddings.weight', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.22.attention.output.LayerNorm.bias', 'encoder.layer.3.attention.self.key.bias', 'encoder.layer.18.output.LayerNorm.bias', 'encoder.layer.13.intermediate.dense.weight', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.11.attention.output.dense.weight', 'encoder.layer.18.attention.self.key.bias', 'encoder.layer.0.attention.self.value.bias', 'encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.layer.4.attention.self.value.bias', 'encoder.layer.16.attention.self.value.weight', 'encoder.layer.7.intermediate.dense.bias', 'encoder.layer.16.attention.output.LayerNorm.bias', 'encoder.layer.9.attention.output.LayerNorm.bias', 'encoder.layer.2.attention.self.key.bias', 'encoder.layer.0.attention.output.dense.bias', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.7.output.dense.bias', 'encoder.layer.21.attention.self.value.weight', 'encoder.layer.10.attention.output.LayerNorm.weight', 'encoder.layer.3.attention.output.dense.weight', 'encoder.layer.17.output.LayerNorm.bias', 'encoder.layer.23.attention.self.query.bias', 'encoder.layer.20.output.dense.weight', 'encoder.layer.17.intermediate.dense.bias', 'encoder.layer.0.output.dense.bias', 'encoder.layer.11.output.LayerNorm.bias', 'encoder.layer.13.attention.output.dense.bias', 'encoder.layer.9.output.LayerNorm.bias', 'encoder.layer.10.attention.self.key.weight', 'encoder.layer.15.attention.self.query.bias', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.18.output.LayerNorm.weight', 'encoder.layer.5.attention.self.query.bias', 'encoder.layer.16.output.LayerNorm.bias', 'encoder.layer.6.attention.self.value.bias', 'encoder.layer.15.output.dense.bias', 'encoder.layer.7.output.LayerNorm.weight', 'encoder.layer.10.output.LayerNorm.weight', 'encoder.layer.11.attention.self.query.bias', 'encoder.layer.21.attention.self.key.bias', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.11.attention.self.key.weight', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.2.attention.self.key.weight', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.8.attention.self.query.bias', 'encoder.layer.8.attention.output.dense.weight', 'encoder.layer.13.output.dense.bias', 'encoder.layer.10.attention.self.key.bias', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.13.intermediate.dense.bias', 'encoder.layer.7.attention.output.dense.weight', 'encoder.layer.16.attention.output.dense.bias', 'encoder.layer.14.attention.output.dense.weight', 'encoder.layer.14.output.dense.weight', 'encoder.layer.14.attention.self.key.bias', 'encoder.layer.17.attention.output.LayerNorm.weight', 'encoder.layer.5.attention.self.value.weight', 'encoder.layer.17.attention.self.query.weight', 'encoder.layer.18.attention.self.query.bias', 'encoder.layer.9.output.LayerNorm.weight', 'encoder.layer.11.output.dense.bias', 'encoder.layer.17.attention.self.key.bias', 'encoder.layer.9.output.dense.bias', 'encoder.layer.14.attention.self.value.bias', 'encoder.layer.2.attention.output.dense.weight', 'encoder.layer.12.output.LayerNorm.bias', 'encoder.layer.22.output.dense.bias', 'encoder.layer.5.attention.self.key.bias', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.3.attention.self.value.weight', 'encoder.layer.13.attention.output.LayerNorm.bias', 'encoder.layer.16.intermediate.dense.weight', 'encoder.layer.8.output.LayerNorm.weight', 'encoder.layer.10.attention.self.query.bias', 'encoder.layer.12.intermediate.dense.bias', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.23.attention.output.dense.weight', 'encoder.layer.6.attention.self.key.bias', 'encoder.layer.18.attention.output.dense.bias', 'encoder.layer.13.attention.output.LayerNorm.weight', 'encoder.layer.3.attention.self.value.bias', 'encoder.layer.0.attention.self.key.weight', 'encoder.layer.12.attention.self.query.bias', 'encoder.layer.2.attention.self.query.bias', 'embeddings.position_embeddings.weight', 'encoder.layer.16.output.LayerNorm.weight', 'encoder.layer.4.attention.self.query.bias', 'encoder.layer.20.attention.output.LayerNorm.bias', 'encoder.layer.19.attention.self.value.weight', 'encoder.layer.14.attention.self.key.weight', 'encoder.layer.4.attention.output.LayerNorm.weight', 'encoder.layer.23.attention.self.key.weight', 'encoder.layer.9.attention.self.value.bias', 'encoder.layer.20.attention.output.dense.bias', 'encoder.layer.22.attention.output.dense.weight', 'encoder.layer.5.attention.output.dense.bias', 'encoder.layer.20.output.LayerNorm.bias', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.6.attention.self.query.bias', 'encoder.layer.23.attention.output.dense.bias', 'encoder.layer.21.output.dense.weight', 'embeddings.token_type_embeddings.weight', 'encoder.layer.8.attention.output.LayerNorm.bias', 'encoder.layer.10.intermediate.dense.weight', 'encoder.layer.18.attention.self.value.bias', 'encoder.layer.2.attention.self.value.bias', 'encoder.layer.2.attention.self.query.weight', 'encoder.layer.6.attention.self.value.weight', 'encoder.layer.20.attention.self.value.weight', 'encoder.layer.11.attention.self.value.bias', 'encoder.layer.21.output.LayerNorm.weight', 'encoder.layer.13.attention.self.query.bias', 'encoder.layer.22.attention.self.query.bias', 'encoder.layer.17.attention.output.dense.bias', 'encoder.layer.6.attention.output.dense.bias', 'encoder.layer.7.attention.output.dense.bias', 'encoder.layer.22.output.LayerNorm.bias', 'encoder.layer.16.attention.output.dense.weight', 'encoder.layer.19.output.LayerNorm.weight', 'encoder.layer.21.attention.output.LayerNorm.weight', 'encoder.layer.19.attention.output.LayerNorm.bias', 'encoder.layer.9.attention.self.value.weight', 'pooler.dense.weight', 'encoder.layer.16.output.dense.bias', 'embeddings.LayerNorm.weight', 'encoder.layer.7.attention.self.value.bias', 'pooler.dense.bias', 'encoder.layer.19.output.dense.bias', 'encoder.layer.9.attention.self.query.bias', 'encoder.layer.0.attention.self.key.bias', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.16.attention.self.query.bias', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.8.attention.self.value.weight', 'encoder.layer.4.attention.output.LayerNorm.bias', 'encoder.layer.1.attention.self.value.bias', 'encoder.layer.23.attention.self.value.bias', 'encoder.layer.5.attention.self.key.weight', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.12.output.LayerNorm.weight', 'encoder.layer.22.attention.self.value.bias', 'encoder.layer.22.attention.self.key.bias', 'encoder.layer.21.attention.output.dense.weight', 'encoder.layer.10.attention.self.query.weight', 'encoder.layer.2.output.dense.weight', 'encoder.layer.13.attention.self.query.weight', 'encoder.layer.21.attention.self.value.bias', 'encoder.layer.12.attention.self.value.bias', 'encoder.layer.6.attention.output.dense.weight', 'encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.layer.6.attention.self.key.weight', 'encoder.layer.23.output.dense.weight', 'encoder.layer.18.intermediate.dense.weight', 'encoder.layer.9.attention.output.dense.bias', 'encoder.layer.22.attention.self.key.weight', 'encoder.layer.23.intermediate.dense.weight', 'encoder.layer.5.attention.self.value.bias', 'encoder.layer.22.intermediate.dense.bias', 'encoder.layer.17.attention.self.query.bias', 'encoder.layer.0.attention.output.LayerNorm.weight', 'encoder.layer.13.output.dense.weight', 'encoder.layer.15.attention.output.LayerNorm.weight', 'encoder.layer.19.attention.self.value.bias', 'encoder.layer.10.attention.output.dense.bias', 'encoder.layer.23.output.dense.bias', 'encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.layer.13.attention.self.key.bias', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.12.attention.self.key.weight', 'encoder.layer.6.output.dense.bias', 'encoder.layer.1.attention.self.key.bias', 'encoder.layer.1.output.dense.bias', 'encoder.layer.20.attention.self.value.bias', 'encoder.layer.17.output.dense.bias', 'encoder.layer.4.attention.output.dense.weight', 'encoder.layer.2.attention.output.LayerNorm.bias', 'encoder.layer.7.attention.output.LayerNorm.weight', 'encoder.layer.7.attention.self.key.bias', 'encoder.layer.11.attention.self.query.weight', 'encoder.layer.20.attention.self.key.bias', 'encoder.layer.12.attention.self.key.bias', 'encoder.layer.18.intermediate.dense.bias', 'encoder.layer.3.output.dense.bias', 'encoder.layer.4.attention.self.query.weight', 'encoder.layer.12.attention.output.dense.weight', 'encoder.layer.1.attention.output.dense.bias', 'encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.layer.7.attention.self.query.weight', 'encoder.layer.21.attention.self.query.bias', 'encoder.layer.12.attention.output.dense.bias', 'encoder.layer.4.output.dense.bias', 'encoder.layer.2.attention.self.value.weight', 'encoder.layer.15.attention.output.dense.weight', 'encoder.layer.16.attention.self.key.weight', 'encoder.layer.23.attention.output.LayerNorm.bias', 'encoder.layer.19.output.dense.weight', 'encoder.layer.20.attention.self.key.weight', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.3.attention.self.key.weight', 'encoder.layer.15.attention.output.dense.bias', 'encoder.layer.14.intermediate.dense.weight', 'encoder.layer.12.output.dense.weight', 'encoder.layer.9.attention.self.query.weight', 'encoder.layer.6.attention.output.LayerNorm.bias', 'encoder.layer.12.intermediate.dense.weight', 'encoder.layer.12.attention.self.value.weight', 'encoder.layer.0.attention.self.query.weight', 'encoder.layer.11.output.dense.weight', 'encoder.layer.12.attention.output.LayerNorm.bias', 'encoder.layer.13.attention.output.dense.weight', 'encoder.layer.20.attention.self.query.weight', 'encoder.layer.23.attention.self.query.weight', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.22.attention.self.value.weight', 'encoder.layer.0.output.dense.weight', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.17.output.LayerNorm.weight', 'encoder.layer.20.attention.output.LayerNorm.weight', 'encoder.layer.4.attention.output.dense.bias', 'encoder.layer.8.output.dense.weight', 'embeddings.LayerNorm.bias', 'encoder.layer.7.attention.self.value.weight', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.22.attention.self.query.weight', 'encoder.layer.10.attention.self.value.bias', 'encoder.layer.14.attention.self.query.bias', 'encoder.layer.16.attention.self.key.bias', 'encoder.layer.14.output.dense.bias', 'encoder.layer.22.intermediate.dense.weight', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.7.output.dense.weight', 'encoder.layer.11.attention.output.LayerNorm.weight', 'encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.16.intermediate.dense.bias', 'encoder.layer.18.output.dense.bias', 'encoder.layer.12.attention.output.LayerNorm.weight', 'encoder.layer.8.attention.self.query.weight', 'encoder.layer.14.attention.self.query.weight', 'encoder.layer.2.output.dense.bias', 'encoder.layer.13.output.LayerNorm.bias', 'encoder.layer.18.attention.output.dense.weight', 'encoder.layer.23.attention.self.key.bias', 'encoder.layer.19.attention.output.dense.bias', 'encoder.layer.2.attention.output.LayerNorm.weight', 'encoder.layer.20.intermediate.dense.weight', 'encoder.layer.16.attention.self.value.bias', 'encoder.layer.19.attention.output.dense.weight', 'encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.layer.9.attention.output.dense.weight', 'encoder.layer.21.attention.self.key.weight', 'encoder.layer.23.attention.self.value.weight', 'encoder.layer.16.attention.output.LayerNorm.weight', 'encoder.layer.11.output.LayerNorm.weight', 'encoder.layer.14.intermediate.dense.bias', 'encoder.layer.15.attention.self.value.bias', 'encoder.layer.5.output.LayerNorm.bias', 'encoder.layer.18.attention.self.key.weight', 'encoder.layer.14.output.LayerNorm.bias', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.15.output.dense.weight', 'encoder.layer.10.output.LayerNorm.bias', 'encoder.layer.21.attention.output.LayerNorm.bias', 'encoder.layer.20.intermediate.dense.bias', 'encoder.layer.18.attention.self.query.weight', 'encoder.layer.8.attention.self.key.weight', 'encoder.layer.23.output.LayerNorm.bias', 'encoder.layer.19.intermediate.dense.weight', 'encoder.layer.1.attention.output.dense.weight', 'encoder.layer.13.attention.self.value.weight', 'encoder.layer.14.output.LayerNorm.weight', 'encoder.layer.20.attention.output.dense.weight', 'encoder.layer.10.output.dense.weight', 'encoder.layer.14.attention.output.LayerNorm.bias', 'encoder.layer.15.attention.self.key.weight', 'encoder.layer.21.attention.output.dense.bias', 'encoder.layer.15.attention.self.query.weight', 'encoder.layer.17.attention.output.LayerNorm.bias', 'encoder.layer.14.attention.output.LayerNorm.weight', 'encoder.layer.22.attention.output.dense.bias', 'encoder.layer.16.attention.self.query.weight', 'encoder.layer.8.output.LayerNorm.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Overwriting existing adapter 'ep'.
Overwriting existing adapter 'tp'.
Overwriting existing adapter 'es'.
Overwriting existing adapter 'ts'.
Overwriting existing adapter fusion module 'ep,tp,es,ts'
05/09/2022 22:56:35 - INFO - __main__ -   lang2id = None
05/09/2022 22:56:39 - INFO - __main__ -   Training/evaluation parameters Namespace(adam_epsilon=1e-08, cache_dir='', config_name='', data_dir=None, device=device(type='cuda'), do_eval=True, do_lower_case=False, do_train=False, doc_stride=128, eval_all_checkpoints=False, eval_lang='ko', evaluate_during_training=False, fp16=False, fp16_opt_level='O1', gradient_accumulation_steps=1, learning_rate=5e-05, local_rank=-1, logging_steps=50, max_answer_length=30, max_grad_norm=1.0, max_query_length=64, max_seq_length=384, max_steps=-1, model_name='xlm-KG', model_name_or_path='/cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//tydiqa/xlm-KG_LR8e-6_EPOCH2.0_maxlen384_batchsize4_gradacc4', model_type='xlm', modelkg_dir='/cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/adapter/xlmr_adapter', n_best_size=20, n_gpu=1, no_cuda=False, null_score_diff_threshold=0.0, num_train_epochs=3.0, output_dir='/cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//tydiqa/xlm-KG_LR8e-6_EPOCH2.0_maxlen384_batchsize4_gradacc4/predictions/tydiqa/', overwrite_cache=False, overwrite_output_dir=False, per_gpu_eval_batch_size=8, per_gpu_train_batch_size=8, predict_file='/cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/download//tydiqa//tydiqa-goldp-v1.1-dev/tydiqa.goldp.ko.dev.json', save_steps=50, seed=42, server_ip='', server_port='', threads=1, tokenizer_name='', train_file=None, train_lang='en', verbose_logging=False, version_2_with_negative=False, warmup_steps=0, weight_decay=0.0)
05/09/2022 22:56:39 - INFO - __main__ -   Loading checkpoint /cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//tydiqa/xlm-KG_LR8e-6_EPOCH2.0_maxlen384_batchsize4_gradacc4 for evaluation
05/09/2022 22:56:39 - INFO - __main__ -   Evaluate the following checkpoints: ['/cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//tydiqa/xlm-KG_LR8e-6_EPOCH2.0_maxlen384_batchsize4_gradacc4']
Some weights of the model checkpoint at /cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//tydiqa/xlm-KG_LR8e-6_EPOCH2.0_maxlen384_batchsize4_gradacc4 were not used when initializing XLMRobertaModel: ['base_model.encoder.layer.0.attention.self.key.bias', 'base_model.encoder.layer.11.attention.output.LayerNorm.bias', 'base_model.encoder.layer.14.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.15.intermediate.dense.weight', 'base_model.embeddings.word_embeddings.weight', 'base_model.encoder.layer.1.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.6.output.dense.weight', 'base_model.encoder.layer.8.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.2.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.12.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.7.output.dense.weight', 'base_model.encoder.layer.9.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.13.attention.self.value.weight', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.18.intermediate.dense.bias', 'base_model.encoder.layer.18.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.1.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.1.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.1.attention.self.key.weight', 'base_model.encoder.layer.5.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.3.attention.output.LayerNorm.bias', 'base_model.encoder.layer.18.output.dense.bias', 'base_model.encoder.layer.23.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.2.attention.output.dense.weight', 'base_model.encoder.layer.4.attention.output.dense.weight', 'base_model.encoder.layer.4.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.10.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.16.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.5.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.0.output.LayerNorm.weight', 'base_model.encoder.layer.15.attention.self.key.bias', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.23.attention.output.dense.weight', 'base_model.encoder.layer.6.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.15.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.5.output.dense.weight', 'base_model.encoder.layer.23.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.5.intermediate.dense.weight', 'base_model.encoder.layer.21.attention.output.LayerNorm.bias', 'base_model.embeddings.LayerNorm.bias', 'base_model.encoder.layer.0.attention.output.dense.bias', 'base_model.encoder.layer.6.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.13.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.5.attention.output.dense.weight', 'base_model.encoder.layer.11.attention.output.dense.bias', 'base_model.encoder.layer.17.intermediate.dense.bias', 'base_model.encoder.layer.20.output.LayerNorm.weight', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.16.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.0.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.19.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.3.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.9.attention.output.dense.weight', 'base_model.encoder.layer.14.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.15.attention.self.value.bias', 'base_model.encoder.layer.5.attention.output.LayerNorm.weight', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.2.attention.self.key.bias', 'base_model.encoder.layer.14.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.8.attention.output.dense.weight', 'base_model.encoder.layer.8.attention.self.key.bias', 'base_model.encoder.layer.23.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.21.output.dense.bias', 'base_model.encoder.layer.23.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.22.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.15.attention.output.dense.bias', 'base_model.encoder.layer.7.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.11.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.21.intermediate.dense.weight', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.6.attention.self.query.weight', 'base_model.encoder.layer.6.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.19.attention.output.dense.bias', 'base_model.encoder.layer.10.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.7.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.10.intermediate.dense.bias', 'base_model.encoder.layer.6.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.15.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.9.attention.self.key.bias', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.19.attention.self.value.bias', 'base_model.encoder.layer.13.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.17.output.LayerNorm.bias', 'base_model.encoder.layer.4.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.13.attention.output.dense.bias', 'base_model.encoder.layer.19.output.dense.weight', 'base_model.encoder.layer.14.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.1.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.15.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.10.attention.self.query.weight', 'base_model.encoder.layer.6.output.LayerNorm.bias', 'base_model.encoder.layer.0.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.17.output.dense.bias', 'base_model.encoder.layer.3.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.15.attention.self.query.weight', 'base_model.encoder.layer.3.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.5.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.9.attention.output.dense.bias', 'base_model.encoder.layer.23.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.1.output.LayerNorm.bias', 'base_model.encoder.layer.5.output.dense.bias', 'base_model.encoder.layer.15.output.LayerNorm.bias', 'base_model.encoder.layer.0.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.23.output.LayerNorm.bias', 'base_model.encoder.layer.20.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.1.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.7.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.13.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.18.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.10.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.15.attention.self.key.weight', 'base_model.encoder.layer.10.output.LayerNorm.bias', 'base_model.encoder.layer.13.output.dense.weight', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.13.attention.output.dense.weight', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.2.attention.self.query.weight', 'base_model.encoder.layer.10.intermediate.dense.weight', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.1.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.6.attention.self.value.bias', 'base_model.encoder.layer.6.attention.output.LayerNorm.bias', 'base_model.encoder.layer.12.attention.output.dense.weight', 'base_model.encoder.layer.20.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.7.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.7.attention.output.dense.weight', 'base_model.encoder.layer.19.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.10.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.14.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.21.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.6.output.LayerNorm.weight', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.22.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.15.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.9.attention.self.value.bias', 'base_model.encoder.layer.16.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.1.output.dense.weight', 'base_model.encoder.layer.18.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.2.attention.self.query.bias', 'base_model.encoder.layer.11.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.17.attention.output.dense.bias', 'base_model.encoder.layer.4.attention.output.dense.bias', 'base_model.encoder.layer.11.attention.self.key.bias', 'base_model.encoder.layer.0.output.dense.bias', 'base_model.encoder.layer.12.output.dense.bias', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.12.intermediate.dense.bias', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.20.output.adapters.ep.adapter_up.weight', 'base_model.pooler.dense.weight', 'base_model.encoder.layer.15.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.2.attention.self.value.bias', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.0.attention.output.LayerNorm.bias', 'base_model.encoder.layer.15.intermediate.dense.bias', 'base_model.encoder.layer.4.attention.self.value.bias', 'base_model.encoder.layer.10.attention.output.LayerNorm.weight', 'base_model.encoder.layer.16.attention.output.dense.weight', 'base_model.encoder.layer.11.attention.self.query.weight', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.11.attention.output.LayerNorm.weight', 'base_model.encoder.layer.18.attention.self.query.weight', 'base_model.encoder.layer.20.attention.output.dense.weight', 'base_model.encoder.layer.18.attention.output.dense.bias', 'base_model.encoder.layer.21.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.7.intermediate.dense.bias', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.7.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.2.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.23.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.8.attention.output.dense.bias', 'base_model.encoder.layer.2.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.5.attention.output.dense.bias', 'base_model.encoder.layer.16.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.12.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.9.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.18.attention.self.key.weight', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.2.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.19.output.LayerNorm.bias', 'base_model.encoder.layer.12.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.3.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.0.attention.self.value.bias', 'base_model.encoder.layer.21.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.11.attention.output.dense.weight', 'qa_outputs.weight', 'base_model.encoder.layer.16.attention.self.query.bias', 'base_model.encoder.layer.11.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.23.output.LayerNorm.weight', 'base_model.encoder.layer.1.attention.self.value.weight', 'base_model.encoder.layer.7.attention.output.dense.bias', 'base_model.encoder.layer.15.attention.output.dense.weight', 'base_model.encoder.layer.17.intermediate.dense.weight', 'base_model.encoder.layer.8.attention.self.query.weight', 'base_model.encoder.layer.12.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.19.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.17.attention.self.value.bias', 'base_model.encoder.layer.3.intermediate.dense.weight', 'base_model.encoder.layer.23.attention.self.value.weight', 'base_model.encoder.layer.3.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.4.output.LayerNorm.bias', 'base_model.encoder.layer.10.attention.self.key.bias', 'base_model.encoder.layer.8.attention.output.LayerNorm.bias', 'base_model.encoder.layer.19.attention.self.query.weight', 'base_model.encoder.layer.19.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.10.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.20.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.5.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.14.attention.self.query.bias', 'base_model.encoder.layer.8.attention.output.LayerNorm.weight', 'base_model.encoder.layer.22.output.dense.bias', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.4.output.dense.bias', 'base_model.encoder.layer.1.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.1.output.adapters.ep.adapter_up.bias', 'base_model.embeddings.position_embeddings.weight', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.18.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.14.attention.output.LayerNorm.bias', 'base_model.encoder.layer.5.output.LayerNorm.bias', 'base_model.encoder.layer.19.attention.output.dense.weight', 'base_model.encoder.layer.21.attention.self.key.weight', 'base_model.encoder.layer.15.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.8.attention.self.key.weight', 'base_model.encoder.layer.10.attention.output.dense.weight', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.0.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.6.attention.output.LayerNorm.weight', 'base_model.encoder.layer.10.output.dense.weight', 'base_model.encoder.layer.6.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.12.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.19.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.22.attention.output.dense.bias', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.1.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.0.output.dense.weight', 'base_model.encoder.layer.7.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.5.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.15.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.16.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.5.intermediate.dense.bias', 'base_model.encoder.layer.21.output.LayerNorm.bias', 'base_model.encoder.layer.12.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.9.attention.output.LayerNorm.weight', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.5.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.18.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.12.attention.output.dense.bias', 'base_model.encoder.layer.12.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.17.output.dense.weight', 'base_model.encoder.layer.14.output.LayerNorm.bias', 'base_model.encoder.layer.17.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.19.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.20.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.13.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.15.attention.output.LayerNorm.bias', 'base_model.encoder.layer.2.output.LayerNorm.weight', 'base_model.encoder.layer.9.output.LayerNorm.weight', 'base_model.encoder.layer.19.attention.self.query.bias', 'base_model.encoder.layer.11.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.22.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.23.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.17.attention.self.key.weight', 'base_model.encoder.layer.7.intermediate.dense.weight', 'base_model.encoder.layer.13.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.5.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.22.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.22.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.11.intermediate.dense.bias', 'base_model.encoder.layer.9.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.13.attention.output.LayerNorm.weight', 'base_model.encoder.layer.10.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.13.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.6.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.14.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.1.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.7.attention.self.key.bias', 'base_model.encoder.layer.9.attention.self.query.weight', 'base_model.encoder.layer.21.attention.self.value.weight', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.2.attention.output.dense.bias', 'base_model.encoder.layer.8.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.13.attention.self.key.bias', 'base_model.encoder.layer.0.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.4.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.4.attention.output.LayerNorm.bias', 'base_model.encoder.layer.23.attention.output.LayerNorm.weight', 'base_model.encoder.layer.16.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.17.attention.output.LayerNorm.bias', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.19.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.16.attention.self.value.weight', 'base_model.encoder.layer.7.attention.self.value.bias', 'base_model.encoder.layer.21.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.15.attention.output.LayerNorm.weight', 'base_model.encoder.layer.11.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.0.intermediate.dense.weight', 'base_model.encoder.layer.5.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.4.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.16.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.11.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.4.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.3.attention.self.query.bias', 'base_model.encoder.layer.20.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.21.attention.self.key.bias', 'base_model.encoder.layer.7.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.9.intermediate.dense.bias', 'base_model.encoder.layer.3.intermediate.dense.bias', 'base_model.encoder.layer.11.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.22.attention.self.value.bias', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.4.output.LayerNorm.weight', 'base_model.encoder.layer.13.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.17.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.22.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.6.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.7.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.14.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.8.attention.self.value.weight', 'base_model.encoder.layer.2.output.dense.weight', 'base_model.encoder.layer.23.attention.self.value.bias', 'base_model.encoder.layer.12.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.17.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.1.attention.self.query.bias', 'base_model.encoder.layer.1.intermediate.dense.bias', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.2.attention.output.LayerNorm.bias', 'base_model.encoder.layer.12.attention.self.query.bias', 'base_model.encoder.layer.16.intermediate.dense.weight', 'base_model.encoder.layer.14.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.7.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.21.attention.output.dense.weight', 'base_model.encoder.layer.10.attention.self.value.bias', 'base_model.encoder.layer.12.attention.output.LayerNorm.weight', 'base_model.encoder.layer.8.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.16.output.LayerNorm.bias', 'base_model.encoder.layer.3.attention.self.query.weight', 'base_model.encoder.layer.19.intermediate.dense.weight', 'base_model.encoder.layer.18.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.21.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.12.output.LayerNorm.bias', 'base_model.encoder.layer.18.output.LayerNorm.weight', 'base_model.encoder.layer.5.attention.self.value.weight', 'base_model.encoder.layer.20.output.dense.weight', 'base_model.encoder.layer.20.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.9.output.LayerNorm.bias', 'base_model.encoder.layer.14.attention.output.dense.bias', 'base_model.encoder.layer.18.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.4.output.dense.weight', 'base_model.encoder.layer.5.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.20.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.16.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.1.attention.output.LayerNorm.weight', 'base_model.encoder.layer.3.output.LayerNorm.bias', 'base_model.encoder.layer.22.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.12.intermediate.dense.weight', 'base_model.encoder.layer.3.output.dense.bias', 'base_model.encoder.layer.10.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.18.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.12.attention.self.value.bias', 'base_model.encoder.layer.3.output.dense.weight', 'base_model.encoder.layer.1.attention.self.value.bias', 'base_model.encoder.layer.12.attention.self.query.weight', 'base_model.encoder.layer.1.attention.self.key.bias', 'base_model.encoder.layer.18.attention.self.value.bias', 'base_model.encoder.layer.17.attention.output.dense.weight', 'base_model.encoder.layer.23.output.dense.bias', 'base_model.encoder.layer.12.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.8.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.0.attention.output.dense.weight', 'base_model.encoder.layer.11.intermediate.dense.weight', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.4.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.7.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.7.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.14.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.3.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.15.output.dense.bias', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.21.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.20.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.13.attention.self.query.weight', 'base_model.encoder.layer.19.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.5.attention.self.value.bias', 'base_model.encoder.layer.21.output.LayerNorm.weight', 'base_model.encoder.layer.3.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.0.attention.self.query.weight', 'base_model.encoder.layer.7.output.dense.bias', 'base_model.encoder.layer.17.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.13.attention.self.value.bias', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.3.attention.output.dense.weight', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.17.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.9.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.19.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.10.output.dense.bias', 'base_model.encoder.layer.6.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.4.attention.self.key.bias', 'base_model.encoder.layer.19.output.dense.bias', 'base_model.encoder.layer.11.output.LayerNorm.weight', 'base_model.encoder.layer.18.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.22.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.2.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.13.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.0.attention.self.query.bias', 'base_model.encoder.layer.8.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.10.attention.self.value.weight', 'base_model.encoder.layer.11.attention.self.key.weight', 'base_model.encoder.layer.1.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.11.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.4.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.2.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.20.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.9.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.8.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.11.output.dense.weight', 'base_model.encoder.layer.14.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.9.attention.self.query.bias', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.17.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.17.attention.output.LayerNorm.weight', 'base_model.encoder.layer.23.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.13.intermediate.dense.bias', 'base_model.encoder.layer.2.attention.self.key.weight', 'base_model.encoder.layer.9.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.12.attention.self.key.weight', 'base_model.encoder.layer.13.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.10.attention.output.dense.bias', 'base_model.encoder.layer.14.attention.output.dense.weight', 'base_model.encoder.layer.16.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.16.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.20.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.9.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.18.attention.output.LayerNorm.bias', 'base_model.encoder.layer.5.output.LayerNorm.weight', 'base_model.encoder.layer.9.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.23.attention.self.key.bias', 'base_model.encoder.layer.17.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.6.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.1.attention.output.LayerNorm.bias', 'base_model.encoder.layer.16.attention.self.key.weight', 'base_model.encoder.layer.6.attention.self.value.weight', 'base_model.encoder.layer.8.output.LayerNorm.bias', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.12.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.4.attention.output.LayerNorm.weight', 'base_model.encoder.layer.11.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.17.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.6.attention.output.dense.weight', 'base_model.encoder.layer.15.output.LayerNorm.weight', 'base_model.encoder.layer.0.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.3.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.8.attention.self.query.bias', 'base_model.encoder.layer.15.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.15.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.19.attention.self.key.weight', 'base_model.encoder.layer.1.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.4.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.14.output.dense.bias', 'base_model.encoder.layer.3.output.LayerNorm.weight', 'base_model.encoder.layer.6.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.20.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.21.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.5.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.23.attention.output.LayerNorm.bias', 'base_model.encoder.layer.23.output.dense.weight', 'base_model.encoder.layer.23.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.17.attention.self.value.weight', 'base_model.encoder.layer.4.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.8.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.0.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.11.attention.self.value.bias', 'base_model.encoder.layer.17.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.17.attention.self.query.weight', 'base_model.encoder.layer.22.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.22.output.LayerNorm.bias', 'base_model.encoder.layer.0.attention.self.key.weight', 'base_model.encoder.layer.11.output.dense.bias', 'base_model.encoder.layer.17.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.20.attention.output.LayerNorm.weight', 'base_model.encoder.layer.5.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.18.attention.self.value.weight', 'base_model.encoder.layer.22.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.4.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.20.attention.self.value.weight', 'base_model.encoder.layer.20.intermediate.dense.bias', 'base_model.encoder.layer.0.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.9.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.22.attention.output.LayerNorm.bias', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.15.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.18.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.1.intermediate.dense.weight', 'base_model.encoder.layer.6.output.dense.bias', 'base_model.encoder.layer.14.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.20.attention.self.key.bias', 'base_model.encoder.layer.4.attention.self.query.weight', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.19.attention.output.LayerNorm.bias', 'base_model.encoder.layer.21.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.15.attention.self.query.bias', 'base_model.encoder.layer.0.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.22.output.LayerNorm.weight', 'base_model.encoder.layer.21.output.dense.weight', 'base_model.encoder.layer.6.intermediate.dense.weight', 'base_model.encoder.layer.22.attention.self.query.weight', 'base_model.encoder.layer.14.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.11.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.6.attention.self.key.bias', 'base_model.encoder.layer.16.output.dense.weight', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.10.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.19.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.5.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.1.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.18.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.16.attention.self.query.weight', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.21.intermediate.dense.bias', 'base_model.encoder.layer.19.intermediate.dense.bias', 'base_model.encoder.layer.3.attention.self.value.weight', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.23.intermediate.dense.bias', 'base_model.encoder.layer.21.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.18.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.2.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.9.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.21.attention.self.value.bias', 'base_model.encoder.layer.5.attention.self.key.weight', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.23.intermediate.dense.weight', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.8.intermediate.dense.weight', 'base_model.encoder.layer.18.output.dense.weight', 'base_model.encoder.layer.13.output.dense.bias', 'base_model.encoder.layer.1.attention.self.query.weight', 'base_model.encoder.layer.12.output.LayerNorm.weight', 'base_model.encoder.layer.19.output.LayerNorm.weight', 'base_model.embeddings.token_type_embeddings.weight', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.12.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.12.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.14.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.3.attention.self.key.weight', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.19.attention.self.key.bias', 'base_model.encoder.layer.2.output.dense.bias', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.2.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.6.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.0.intermediate.dense.bias', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.9.output.dense.weight', 'base_model.encoder.layer.17.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.15.attention.self.value.weight', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.2.intermediate.dense.bias', 'base_model.encoder.layer.5.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.8.output.dense.weight', 'base_model.encoder.layer.0.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.5.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.20.attention.output.LayerNorm.bias', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.7.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.13.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.15.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.16.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.21.attention.self.query.weight', 'base_model.encoder.layer.9.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.6.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.3.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.20.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.10.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.19.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.21.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.20.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.9.output.adapters.es.adapter_down.0.weight', 'base_model.pooler.dense.bias', 'base_model.encoder.layer.8.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.20.output.dense.bias', 'base_model.encoder.layer.1.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.7.attention.output.LayerNorm.weight', 'base_model.encoder.layer.16.attention.output.LayerNorm.bias', 'base_model.encoder.layer.17.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.2.output.LayerNorm.bias', 'base_model.encoder.layer.12.attention.self.value.weight', 'base_model.encoder.layer.14.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.18.attention.output.dense.weight', 'base_model.encoder.layer.22.attention.self.key.bias', 'base_model.encoder.layer.8.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.22.intermediate.dense.weight', 'base_model.encoder.layer.10.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.0.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.14.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.7.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.22.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.0.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.4.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.8.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.13.output.LayerNorm.bias', 'base_model.encoder.layer.20.attention.self.value.bias', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.3.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.21.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.9.attention.self.key.weight', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.20.attention.self.key.weight', 'base_model.encoder.layer.19.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.13.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.23.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.18.attention.self.query.bias', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.19.attention.self.value.weight', 'base_model.encoder.layer.11.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.23.attention.output.dense.bias', 'base_model.encoder.layer.0.output.LayerNorm.bias', 'base_model.encoder.layer.10.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.8.attention.self.value.bias', 'base_model.encoder.layer.14.attention.self.value.weight', 'base_model.encoder.layer.14.attention.self.value.bias', 'base_model.encoder.layer.18.attention.self.key.bias', 'base_model.encoder.layer.14.attention.self.query.weight', 'base_model.encoder.layer.2.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.11.attention.self.value.weight', 'base_model.encoder.layer.7.attention.self.query.weight', 'base_model.encoder.layer.1.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.0.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.12.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.16.intermediate.dense.bias', 'base_model.encoder.layer.14.intermediate.dense.weight', 'base_model.encoder.layer.19.attention.output.LayerNorm.weight', 'base_model.encoder.layer.23.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.17.attention.self.key.bias', 'base_model.encoder.layer.9.attention.self.value.weight', 'base_model.encoder.layer.21.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.8.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.4.intermediate.dense.bias', 'base_model.encoder.layer.9.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.13.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.16.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.20.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.8.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.21.attention.output.LayerNorm.weight', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.10.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.2.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.13.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.1.output.LayerNorm.weight', 'base_model.encoder.layer.20.attention.self.query.bias', 'base_model.encoder.layer.13.output.LayerNorm.weight', 'base_model.encoder.layer.10.attention.output.LayerNorm.bias', 'base_model.encoder.layer.2.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.15.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.3.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.6.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.14.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.10.output.LayerNorm.weight', 'base_model.encoder.layer.11.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.12.attention.output.LayerNorm.bias', 'base_model.encoder.layer.20.attention.output.dense.bias', 'base_model.encoder.layer.21.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.2.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.21.attention.self.query.bias', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.7.attention.output.LayerNorm.bias', 'base_model.encoder.layer.0.attention.self.value.weight', 'base_model.encoder.layer.5.attention.self.query.bias', 'base_model.encoder.layer.3.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.4.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.2.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.5.attention.self.key.bias', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.13.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.16.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.12.output.dense.weight', 'qa_outputs.bias', 'base_model.encoder.layer.1.output.dense.bias', 'base_model.encoder.layer.17.output.LayerNorm.weight', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.5.attention.self.query.weight', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.12.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.13.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.15.output.adapters.tp.adapter_down.0.bias', 'base_model.embeddings.position_ids', 'base_model.encoder.layer.18.attention.output.LayerNorm.weight', 'base_model.encoder.layer.6.intermediate.dense.bias', 'base_model.encoder.layer.10.attention.self.query.bias', 'base_model.encoder.layer.18.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.23.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.4.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.19.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.3.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.22.output.dense.weight', 'base_model.encoder.layer.13.intermediate.dense.weight', 'base_model.encoder.layer.13.attention.output.LayerNorm.bias', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.11.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.5.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.8.intermediate.dense.bias', 'base_model.encoder.layer.7.attention.self.query.bias', 'base_model.encoder.layer.8.output.dense.bias', 'base_model.encoder.layer.7.attention.self.key.weight', 'base_model.encoder.layer.16.attention.output.dense.bias', 'base_model.encoder.layer.8.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.22.attention.self.key.weight', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.22.attention.self.value.weight', 'base_model.encoder.layer.21.attention.output.dense.bias', 'base_model.encoder.layer.23.attention.self.key.weight', 'base_model.encoder.layer.4.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.11.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.6.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.2.attention.output.LayerNorm.weight', 'base_model.encoder.layer.18.intermediate.dense.weight', 'base_model.encoder.layer.0.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.19.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.3.attention.self.value.bias', 'base_model.encoder.layer.15.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.11.attention.self.query.bias', 'base_model.encoder.layer.14.attention.output.LayerNorm.weight', 'base_model.encoder.layer.16.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.3.attention.self.key.bias', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.7.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.14.output.LayerNorm.weight', 'base_model.encoder.layer.4.attention.self.value.weight', 'base_model.encoder.layer.12.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.16.attention.output.LayerNorm.weight', 'base_model.encoder.layer.14.attention.self.key.weight', 'base_model.encoder.layer.12.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.19.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.3.attention.output.dense.bias', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.23.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.8.output.LayerNorm.weight', 'base_model.encoder.layer.8.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.16.attention.self.key.bias', 'base_model.encoder.layer.6.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.9.output.dense.bias', 'base_model.encoder.layer.3.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.7.output.LayerNorm.bias', 'base_model.encoder.layer.8.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.17.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.15.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.22.attention.output.dense.weight', 'base_model.encoder.layer.10.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.4.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.9.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.22.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.3.attention.output.LayerNorm.weight', 'base_model.encoder.layer.11.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.7.output.LayerNorm.weight', 'base_model.encoder.layer.14.intermediate.dense.bias', 'base_model.encoder.layer.6.attention.self.key.weight', 'base_model.encoder.layer.15.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.1.attention.output.dense.bias', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.22.attention.self.query.bias', 'base_model.encoder.layer.2.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.18.output.LayerNorm.bias', 'base_model.encoder.layer.10.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.12.attention.self.key.bias', 'base_model.encoder.layer.6.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.22.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.13.attention.self.key.weight', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.embeddings.LayerNorm.weight', 'base_model.encoder.layer.4.intermediate.dense.weight', 'base_model.encoder.layer.7.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.18.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.22.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.1.attention.output.dense.weight', 'base_model.encoder.layer.18.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.5.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.16.output.LayerNorm.weight', 'base_model.encoder.layer.10.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.14.attention.self.key.bias', 'base_model.encoder.layer.9.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.22.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.10.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.2.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.21.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.23.attention.self.query.weight', 'base_model.encoder.layer.0.attention.output.LayerNorm.weight', 'base_model.encoder.layer.6.attention.output.dense.bias', 'base_model.encoder.layer.1.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.4.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.7.attention.self.value.weight', 'base_model.encoder.layer.17.attention.self.query.bias', 'base_model.encoder.layer.10.attention.self.key.weight', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.2.intermediate.dense.weight', 'base_model.encoder.layer.21.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.22.attention.output.LayerNorm.weight', 'base_model.encoder.layer.9.attention.output.LayerNorm.bias', 'base_model.encoder.layer.2.attention.self.value.weight', 'base_model.encoder.layer.16.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.23.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.17.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.23.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.3.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.13.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.14.output.dense.weight', 'base_model.encoder.layer.4.attention.self.query.bias', 'base_model.encoder.layer.19.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.20.output.LayerNorm.bias', 'base_model.encoder.layer.17.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.20.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.5.attention.output.LayerNorm.bias', 'base_model.encoder.layer.20.attention.self.query.weight', 'base_model.encoder.layer.20.intermediate.dense.weight', 'base_model.encoder.layer.17.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.4.attention.self.key.weight', 'base_model.encoder.layer.21.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.22.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.7.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.16.output.dense.bias', 'base_model.encoder.layer.3.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.6.attention.self.query.bias', 'base_model.encoder.layer.23.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.16.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.9.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.0.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.11.output.LayerNorm.bias', 'base_model.encoder.layer.13.attention.self.query.bias', 'base_model.encoder.layer.16.attention.self.value.bias', 'base_model.encoder.layer.8.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.9.intermediate.dense.weight', 'base_model.encoder.layer.22.intermediate.dense.bias', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.2.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.15.output.dense.weight', 'base_model.encoder.layer.18.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.11.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.0.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.23.attention.self.query.bias']
- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of XLMRobertaModel were not initialized from the model checkpoint at /cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//tydiqa/xlm-KG_LR8e-6_EPOCH2.0_maxlen384_batchsize4_gradacc4 and are newly initialized: ['encoder.layer.6.attention.output.LayerNorm.weight', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.2.attention.output.dense.bias', 'encoder.layer.8.attention.self.key.bias', 'encoder.layer.7.attention.self.key.weight', 'encoder.layer.21.output.LayerNorm.bias', 'encoder.layer.16.output.dense.weight', 'encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.layer.21.attention.self.query.weight', 'encoder.layer.12.attention.self.query.weight', 'encoder.layer.4.attention.self.key.weight', 'encoder.layer.18.output.dense.weight', 'encoder.layer.15.attention.output.LayerNorm.bias', 'encoder.layer.11.attention.self.value.weight', 'encoder.layer.13.attention.self.key.weight', 'encoder.layer.9.output.dense.weight', 'encoder.layer.1.attention.output.LayerNorm.weight', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.1.attention.self.key.weight', 'encoder.layer.7.attention.output.LayerNorm.bias', 'encoder.layer.12.output.dense.bias', 'encoder.layer.15.intermediate.dense.bias', 'encoder.layer.21.intermediate.dense.weight', 'encoder.layer.4.attention.self.value.weight', 'encoder.layer.19.output.LayerNorm.bias', 'encoder.layer.10.attention.output.dense.weight', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.18.attention.output.LayerNorm.weight', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.15.output.LayerNorm.weight', 'encoder.layer.21.intermediate.dense.bias', 'encoder.layer.6.output.dense.weight', 'encoder.layer.8.attention.output.dense.bias', 'encoder.layer.19.attention.self.key.weight', 'encoder.layer.14.attention.self.value.weight', 'encoder.layer.19.attention.self.key.bias', 'encoder.layer.5.attention.output.dense.weight', 'encoder.layer.1.attention.self.query.weight', 'encoder.layer.5.attention.output.LayerNorm.weight', 'encoder.layer.9.attention.self.key.weight', 'encoder.layer.4.attention.self.key.bias', 'encoder.layer.1.attention.self.value.weight', 'encoder.layer.17.attention.output.dense.weight', 'encoder.layer.8.attention.output.LayerNorm.weight', 'encoder.layer.20.output.dense.bias', 'encoder.layer.23.output.LayerNorm.weight', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.11.attention.output.dense.bias', 'encoder.layer.19.attention.output.LayerNorm.weight', 'encoder.layer.23.attention.output.LayerNorm.weight', 'encoder.layer.3.output.dense.weight', 'encoder.layer.8.attention.self.value.bias', 'encoder.layer.10.attention.self.value.weight', 'encoder.layer.17.output.dense.weight', 'encoder.layer.19.attention.self.query.weight', 'encoder.layer.7.output.LayerNorm.bias', 'encoder.layer.19.intermediate.dense.bias', 'encoder.layer.15.output.LayerNorm.bias', 'encoder.layer.5.attention.self.query.weight', 'encoder.layer.17.intermediate.dense.weight', 'encoder.layer.4.output.dense.weight', 'encoder.layer.18.attention.self.value.weight', 'encoder.layer.15.attention.self.key.bias', 'encoder.layer.18.attention.output.LayerNorm.bias', 'encoder.layer.8.output.dense.bias', 'encoder.layer.0.attention.self.value.weight', 'encoder.layer.1.attention.self.query.bias', 'encoder.layer.17.attention.self.value.bias', 'encoder.layer.6.attention.self.query.weight', 'encoder.layer.22.output.LayerNorm.weight', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.9.attention.output.LayerNorm.weight', 'encoder.layer.3.attention.self.query.bias', 'encoder.layer.23.intermediate.dense.bias', 'encoder.layer.15.intermediate.dense.weight', 'encoder.layer.22.attention.output.LayerNorm.weight', 'encoder.layer.9.attention.self.key.bias', 'encoder.layer.20.attention.self.query.bias', 'encoder.layer.13.output.LayerNorm.weight', 'encoder.layer.10.attention.output.LayerNorm.bias', 'encoder.layer.10.output.dense.bias', 'encoder.layer.7.attention.self.query.bias', 'encoder.layer.5.output.dense.bias', 'encoder.layer.5.output.dense.weight', 'encoder.layer.0.attention.self.query.bias', 'encoder.layer.6.output.LayerNorm.bias', 'encoder.layer.1.output.dense.weight', 'encoder.layer.3.attention.output.dense.bias', 'encoder.layer.11.attention.self.key.bias', 'encoder.layer.15.attention.self.value.weight', 'encoder.layer.0.attention.output.dense.weight', 'encoder.layer.17.attention.self.key.weight', 'encoder.layer.14.attention.output.dense.bias', 'encoder.layer.13.attention.self.value.bias', 'encoder.layer.17.attention.self.value.weight', 'encoder.layer.22.output.dense.weight', 'encoder.layer.21.output.dense.bias', 'encoder.layer.19.attention.self.query.bias', 'encoder.layer.20.output.LayerNorm.weight', 'encoder.layer.3.attention.self.query.weight', 'embeddings.word_embeddings.weight', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.22.attention.output.LayerNorm.bias', 'encoder.layer.3.attention.self.key.bias', 'encoder.layer.18.output.LayerNorm.bias', 'encoder.layer.13.intermediate.dense.weight', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.11.attention.output.dense.weight', 'encoder.layer.18.attention.self.key.bias', 'encoder.layer.0.attention.self.value.bias', 'encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.layer.4.attention.self.value.bias', 'encoder.layer.16.attention.self.value.weight', 'encoder.layer.7.intermediate.dense.bias', 'encoder.layer.16.attention.output.LayerNorm.bias', 'encoder.layer.9.attention.output.LayerNorm.bias', 'encoder.layer.2.attention.self.key.bias', 'encoder.layer.0.attention.output.dense.bias', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.7.output.dense.bias', 'encoder.layer.21.attention.self.value.weight', 'encoder.layer.10.attention.output.LayerNorm.weight', 'encoder.layer.3.attention.output.dense.weight', 'encoder.layer.17.output.LayerNorm.bias', 'encoder.layer.23.attention.self.query.bias', 'encoder.layer.20.output.dense.weight', 'encoder.layer.17.intermediate.dense.bias', 'encoder.layer.0.output.dense.bias', 'encoder.layer.11.output.LayerNorm.bias', 'encoder.layer.13.attention.output.dense.bias', 'encoder.layer.9.output.LayerNorm.bias', 'encoder.layer.10.attention.self.key.weight', 'encoder.layer.15.attention.self.query.bias', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.18.output.LayerNorm.weight', 'encoder.layer.5.attention.self.query.bias', 'encoder.layer.16.output.LayerNorm.bias', 'encoder.layer.6.attention.self.value.bias', 'encoder.layer.15.output.dense.bias', 'encoder.layer.7.output.LayerNorm.weight', 'encoder.layer.10.output.LayerNorm.weight', 'encoder.layer.11.attention.self.query.bias', 'encoder.layer.21.attention.self.key.bias', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.11.attention.self.key.weight', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.2.attention.self.key.weight', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.8.attention.self.query.bias', 'encoder.layer.8.attention.output.dense.weight', 'encoder.layer.13.output.dense.bias', 'encoder.layer.10.attention.self.key.bias', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.13.intermediate.dense.bias', 'encoder.layer.7.attention.output.dense.weight', 'encoder.layer.16.attention.output.dense.bias', 'encoder.layer.14.attention.output.dense.weight', 'encoder.layer.14.output.dense.weight', 'encoder.layer.14.attention.self.key.bias', 'encoder.layer.17.attention.output.LayerNorm.weight', 'encoder.layer.5.attention.self.value.weight', 'encoder.layer.17.attention.self.query.weight', 'encoder.layer.18.attention.self.query.bias', 'encoder.layer.9.output.LayerNorm.weight', 'encoder.layer.11.output.dense.bias', 'encoder.layer.17.attention.self.key.bias', 'encoder.layer.9.output.dense.bias', 'encoder.layer.14.attention.self.value.bias', 'encoder.layer.2.attention.output.dense.weight', 'encoder.layer.12.output.LayerNorm.bias', 'encoder.layer.22.output.dense.bias', 'encoder.layer.5.attention.self.key.bias', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.3.attention.self.value.weight', 'encoder.layer.13.attention.output.LayerNorm.bias', 'encoder.layer.16.intermediate.dense.weight', 'encoder.layer.8.output.LayerNorm.weight', 'encoder.layer.10.attention.self.query.bias', 'encoder.layer.12.intermediate.dense.bias', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.23.attention.output.dense.weight', 'encoder.layer.6.attention.self.key.bias', 'encoder.layer.18.attention.output.dense.bias', 'encoder.layer.13.attention.output.LayerNorm.weight', 'encoder.layer.3.attention.self.value.bias', 'encoder.layer.0.attention.self.key.weight', 'encoder.layer.12.attention.self.query.bias', 'encoder.layer.2.attention.self.query.bias', 'embeddings.position_embeddings.weight', 'encoder.layer.16.output.LayerNorm.weight', 'encoder.layer.4.attention.self.query.bias', 'encoder.layer.20.attention.output.LayerNorm.bias', 'encoder.layer.19.attention.self.value.weight', 'encoder.layer.14.attention.self.key.weight', 'encoder.layer.4.attention.output.LayerNorm.weight', 'encoder.layer.23.attention.self.key.weight', 'encoder.layer.9.attention.self.value.bias', 'encoder.layer.20.attention.output.dense.bias', 'encoder.layer.22.attention.output.dense.weight', 'encoder.layer.5.attention.output.dense.bias', 'encoder.layer.20.output.LayerNorm.bias', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.6.attention.self.query.bias', 'encoder.layer.23.attention.output.dense.bias', 'encoder.layer.21.output.dense.weight', 'embeddings.token_type_embeddings.weight', 'encoder.layer.8.attention.output.LayerNorm.bias', 'encoder.layer.10.intermediate.dense.weight', 'encoder.layer.18.attention.self.value.bias', 'encoder.layer.2.attention.self.value.bias', 'encoder.layer.2.attention.self.query.weight', 'encoder.layer.6.attention.self.value.weight', 'encoder.layer.20.attention.self.value.weight', 'encoder.layer.11.attention.self.value.bias', 'encoder.layer.21.output.LayerNorm.weight', 'encoder.layer.13.attention.self.query.bias', 'encoder.layer.22.attention.self.query.bias', 'encoder.layer.17.attention.output.dense.bias', 'encoder.layer.6.attention.output.dense.bias', 'encoder.layer.7.attention.output.dense.bias', 'encoder.layer.22.output.LayerNorm.bias', 'encoder.layer.16.attention.output.dense.weight', 'encoder.layer.19.output.LayerNorm.weight', 'encoder.layer.21.attention.output.LayerNorm.weight', 'encoder.layer.19.attention.output.LayerNorm.bias', 'encoder.layer.9.attention.self.value.weight', 'pooler.dense.weight', 'encoder.layer.16.output.dense.bias', 'embeddings.LayerNorm.weight', 'encoder.layer.7.attention.self.value.bias', 'pooler.dense.bias', 'encoder.layer.19.output.dense.bias', 'encoder.layer.9.attention.self.query.bias', 'encoder.layer.0.attention.self.key.bias', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.16.attention.self.query.bias', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.8.attention.self.value.weight', 'encoder.layer.4.attention.output.LayerNorm.bias', 'encoder.layer.1.attention.self.value.bias', 'encoder.layer.23.attention.self.value.bias', 'encoder.layer.5.attention.self.key.weight', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.12.output.LayerNorm.weight', 'encoder.layer.22.attention.self.value.bias', 'encoder.layer.22.attention.self.key.bias', 'encoder.layer.21.attention.output.dense.weight', 'encoder.layer.10.attention.self.query.weight', 'encoder.layer.2.output.dense.weight', 'encoder.layer.13.attention.self.query.weight', 'encoder.layer.21.attention.self.value.bias', 'encoder.layer.12.attention.self.value.bias', 'encoder.layer.6.attention.output.dense.weight', 'encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.layer.6.attention.self.key.weight', 'encoder.layer.23.output.dense.weight', 'encoder.layer.18.intermediate.dense.weight', 'encoder.layer.9.attention.output.dense.bias', 'encoder.layer.22.attention.self.key.weight', 'encoder.layer.23.intermediate.dense.weight', 'encoder.layer.5.attention.self.value.bias', 'encoder.layer.22.intermediate.dense.bias', 'encoder.layer.17.attention.self.query.bias', 'encoder.layer.0.attention.output.LayerNorm.weight', 'encoder.layer.13.output.dense.weight', 'encoder.layer.15.attention.output.LayerNorm.weight', 'encoder.layer.19.attention.self.value.bias', 'encoder.layer.10.attention.output.dense.bias', 'encoder.layer.23.output.dense.bias', 'encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.layer.13.attention.self.key.bias', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.12.attention.self.key.weight', 'encoder.layer.6.output.dense.bias', 'encoder.layer.1.attention.self.key.bias', 'encoder.layer.1.output.dense.bias', 'encoder.layer.20.attention.self.value.bias', 'encoder.layer.17.output.dense.bias', 'encoder.layer.4.attention.output.dense.weight', 'encoder.layer.2.attention.output.LayerNorm.bias', 'encoder.layer.7.attention.output.LayerNorm.weight', 'encoder.layer.7.attention.self.key.bias', 'encoder.layer.11.attention.self.query.weight', 'encoder.layer.20.attention.self.key.bias', 'encoder.layer.12.attention.self.key.bias', 'encoder.layer.18.intermediate.dense.bias', 'encoder.layer.3.output.dense.bias', 'encoder.layer.4.attention.self.query.weight', 'encoder.layer.12.attention.output.dense.weight', 'encoder.layer.1.attention.output.dense.bias', 'encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.layer.7.attention.self.query.weight', 'encoder.layer.21.attention.self.query.bias', 'encoder.layer.12.attention.output.dense.bias', 'encoder.layer.4.output.dense.bias', 'encoder.layer.2.attention.self.value.weight', 'encoder.layer.15.attention.output.dense.weight', 'encoder.layer.16.attention.self.key.weight', 'encoder.layer.23.attention.output.LayerNorm.bias', 'encoder.layer.19.output.dense.weight', 'encoder.layer.20.attention.self.key.weight', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.3.attention.self.key.weight', 'encoder.layer.15.attention.output.dense.bias', 'encoder.layer.14.intermediate.dense.weight', 'encoder.layer.12.output.dense.weight', 'encoder.layer.9.attention.self.query.weight', 'encoder.layer.6.attention.output.LayerNorm.bias', 'encoder.layer.12.intermediate.dense.weight', 'encoder.layer.12.attention.self.value.weight', 'encoder.layer.0.attention.self.query.weight', 'encoder.layer.11.output.dense.weight', 'encoder.layer.12.attention.output.LayerNorm.bias', 'encoder.layer.13.attention.output.dense.weight', 'encoder.layer.20.attention.self.query.weight', 'encoder.layer.23.attention.self.query.weight', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.22.attention.self.value.weight', 'encoder.layer.0.output.dense.weight', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.17.output.LayerNorm.weight', 'encoder.layer.20.attention.output.LayerNorm.weight', 'encoder.layer.4.attention.output.dense.bias', 'encoder.layer.8.output.dense.weight', 'embeddings.LayerNorm.bias', 'encoder.layer.7.attention.self.value.weight', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.22.attention.self.query.weight', 'encoder.layer.10.attention.self.value.bias', 'encoder.layer.14.attention.self.query.bias', 'encoder.layer.16.attention.self.key.bias', 'encoder.layer.14.output.dense.bias', 'encoder.layer.22.intermediate.dense.weight', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.7.output.dense.weight', 'encoder.layer.11.attention.output.LayerNorm.weight', 'encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.16.intermediate.dense.bias', 'encoder.layer.18.output.dense.bias', 'encoder.layer.12.attention.output.LayerNorm.weight', 'encoder.layer.8.attention.self.query.weight', 'encoder.layer.14.attention.self.query.weight', 'encoder.layer.2.output.dense.bias', 'encoder.layer.13.output.LayerNorm.bias', 'encoder.layer.18.attention.output.dense.weight', 'encoder.layer.23.attention.self.key.bias', 'encoder.layer.19.attention.output.dense.bias', 'encoder.layer.2.attention.output.LayerNorm.weight', 'encoder.layer.20.intermediate.dense.weight', 'encoder.layer.16.attention.self.value.bias', 'encoder.layer.19.attention.output.dense.weight', 'encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.layer.9.attention.output.dense.weight', 'encoder.layer.21.attention.self.key.weight', 'encoder.layer.23.attention.self.value.weight', 'encoder.layer.16.attention.output.LayerNorm.weight', 'encoder.layer.11.output.LayerNorm.weight', 'encoder.layer.14.intermediate.dense.bias', 'encoder.layer.15.attention.self.value.bias', 'encoder.layer.5.output.LayerNorm.bias', 'encoder.layer.18.attention.self.key.weight', 'encoder.layer.14.output.LayerNorm.bias', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.15.output.dense.weight', 'encoder.layer.10.output.LayerNorm.bias', 'encoder.layer.21.attention.output.LayerNorm.bias', 'encoder.layer.20.intermediate.dense.bias', 'encoder.layer.18.attention.self.query.weight', 'encoder.layer.8.attention.self.key.weight', 'encoder.layer.23.output.LayerNorm.bias', 'encoder.layer.19.intermediate.dense.weight', 'encoder.layer.1.attention.output.dense.weight', 'encoder.layer.13.attention.self.value.weight', 'encoder.layer.14.output.LayerNorm.weight', 'encoder.layer.20.attention.output.dense.weight', 'encoder.layer.10.output.dense.weight', 'encoder.layer.14.attention.output.LayerNorm.bias', 'encoder.layer.15.attention.self.key.weight', 'encoder.layer.21.attention.output.dense.bias', 'encoder.layer.15.attention.self.query.weight', 'encoder.layer.17.attention.output.LayerNorm.bias', 'encoder.layer.14.attention.output.LayerNorm.weight', 'encoder.layer.22.attention.output.dense.bias', 'encoder.layer.16.attention.self.query.weight', 'encoder.layer.8.output.LayerNorm.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Overwriting existing adapter 'ep'.
Overwriting existing adapter 'tp'.
Overwriting existing adapter 'es'.
Overwriting existing adapter 'ts'.
Overwriting existing adapter fusion module 'ep,tp,es,ts'
05/09/2022 22:57:07 - INFO - __main__ -   Creating features from dataset file at .
/cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//tydiqa/xlm-KG_LR8e-6_EPOCH2.0_maxlen384_batchsize4_gradacc4
XLMConfig {
  "architectures": [
    "XLMRobertaForMaskedLM"
  ],
  "asm": false,
  "attention_dropout": 0.1,
  "attention_probs_dropout_prob": 0.1,
  "bos_index": 0,
  "bos_token_id": 0,
  "causal": false,
  "dropout": 0.1,
  "emb_dim": 1024,
  "embed_init_std": 0.02209708691207961,
  "end_n_top": 5,
  "eos_index": 1,
  "eos_token_id": 2,
  "gelu_activation": true,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "init_std": 0.02,
  "initializer_range": 0.02,
  "intermediate_size": 4096,
  "is_encoder": true,
  "lang_id": 0,
  "layer_norm_eps": 1e-05,
  "mask_index": 5,
  "mask_token_id": 0,
  "max_position_embeddings": 514,
  "model_type": "xlm",
  "n_heads": 16,
  "n_langs": 1,
  "n_layers": 24,
  "output_past": true,
  "pad_index": 2,
  "pad_token_id": 1,
  "sinusoidal_embeddings": false,
  "start_n_top": 5,
  "summary_activation": null,
  "summary_first_dropout": 0.1,
  "summary_proj_to_labels": true,
  "summary_type": "first",
  "summary_use_proj": true,
  "transformers_version": "4.17.0",
  "type_vocab_size": 1,
  "unk_index": 3,
  "use_lang_emb": false,
  "vocab_size": 250002
}

  0%|          | 0/276 [00:00<?, ?it/s]100%|██████████| 276/276 [00:00<00:00, 9180.60it/s]
convert squad examples to features:   0%|          | 0/276 [00:00<?, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.
convert squad examples to features:   0%|          | 1/276 [00:00<00:35,  7.70it/s]convert squad examples to features:  24%|██▎       | 65/276 [00:00<00:00, 297.52it/s]convert squad examples to features:  47%|████▋     | 129/276 [00:00<00:00, 291.43it/s]convert squad examples to features:  70%|██████▉   | 193/276 [00:00<00:00, 361.02it/s]convert squad examples to features:  84%|████████▎ | 231/276 [00:00<00:00, 359.44it/s]convert squad examples to features: 100%|██████████| 276/276 [00:00<00:00, 363.21it/s]/cluster/project/sachan/yifan/softwares/anaconda/anaconda3/envs/xfactr/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2272: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

add example index and unique id:   0%|          | 0/276 [00:00<?, ?it/s]add example index and unique id: 100%|██████████| 276/276 [00:00<00:00, 755138.88it/s]
05/09/2022 22:57:08 - INFO - __main__ -   Saving features into cached file ./cached_tydiqa.goldp.ko.dev.json_xlm-KG_LR8e-6_EPOCH2.0_maxlen384_batchsize4_gradacc4_384_ko
05/09/2022 22:57:08 - INFO - __main__ -   ***** Running evaluation  *****
05/09/2022 22:57:08 - INFO - __main__ -     Num examples = 300
05/09/2022 22:57:08 - INFO - __main__ -     Batch size = 8
Evaluating:   0%|          | 0/38 [00:00<?, ?it/s]Evaluating:   3%|▎         | 1/38 [00:00<00:31,  1.16it/s]Evaluating:   5%|▌         | 2/38 [00:01<00:20,  1.77it/s]Evaluating:   8%|▊         | 3/38 [00:01<00:16,  2.13it/s]Evaluating:  11%|█         | 4/38 [00:01<00:14,  2.35it/s]Evaluating:  13%|█▎        | 5/38 [00:02<00:13,  2.50it/s]Evaluating:  16%|█▌        | 6/38 [00:02<00:12,  2.59it/s]Evaluating:  18%|█▊        | 7/38 [00:03<00:11,  2.65it/s]Evaluating:  21%|██        | 8/38 [00:03<00:11,  2.70it/s]Evaluating:  24%|██▎       | 9/38 [00:03<00:10,  2.73it/s]Evaluating:  26%|██▋       | 10/38 [00:04<00:10,  2.75it/s]Evaluating:  29%|██▉       | 11/38 [00:04<00:09,  2.75it/s]Evaluating:  32%|███▏      | 12/38 [00:04<00:09,  2.77it/s]Evaluating:  34%|███▍      | 13/38 [00:05<00:08,  2.78it/s]Evaluating:  37%|███▋      | 14/38 [00:05<00:08,  2.79it/s]Evaluating:  39%|███▉      | 15/38 [00:05<00:08,  2.79it/s]Evaluating:  42%|████▏     | 16/38 [00:06<00:07,  2.79it/s]Evaluating:  45%|████▍     | 17/38 [00:06<00:07,  2.73it/s]Evaluating:  47%|████▋     | 18/38 [00:06<00:07,  2.74it/s]Evaluating:  50%|█████     | 19/38 [00:07<00:06,  2.74it/s]Evaluating:  53%|█████▎    | 20/38 [00:07<00:06,  2.75it/s]Evaluating:  55%|█████▌    | 21/38 [00:08<00:06,  2.76it/s]Evaluating:  58%|█████▊    | 22/38 [00:08<00:05,  2.76it/s]Evaluating:  61%|██████    | 23/38 [00:08<00:05,  2.77it/s]Evaluating:  63%|██████▎   | 24/38 [00:09<00:05,  2.77it/s]Evaluating:  66%|██████▌   | 25/38 [00:09<00:04,  2.79it/s]Evaluating:  68%|██████▊   | 26/38 [00:09<00:04,  2.77it/s]Evaluating:  71%|███████   | 27/38 [00:10<00:03,  2.78it/s]Evaluating:  74%|███████▎  | 28/38 [00:10<00:03,  2.79it/s]Evaluating:  76%|███████▋  | 29/38 [00:10<00:03,  2.78it/s]Evaluating:  79%|███████▉  | 30/38 [00:11<00:02,  2.78it/s]Evaluating:  82%|████████▏ | 31/38 [00:11<00:02,  2.77it/s]Evaluating:  84%|████████▍ | 32/38 [00:12<00:02,  2.77it/s]Evaluating:  87%|████████▋ | 33/38 [00:12<00:01,  2.78it/s]Evaluating:  89%|████████▉ | 34/38 [00:12<00:01,  2.78it/s]Evaluating:  92%|█████████▏| 35/38 [00:13<00:01,  2.75it/s]Evaluating:  95%|█████████▍| 36/38 [00:13<00:00,  2.76it/s]Evaluating:  97%|█████████▋| 37/38 [00:13<00:00,  2.76it/s]Evaluating: 100%|██████████| 38/38 [00:14<00:00,  3.21it/s]Evaluating: 100%|██████████| 38/38 [00:14<00:00,  2.71it/s]
05/09/2022 22:57:22 - INFO - __main__ -     Evaluation done in total 14.019193 secs (0.046731 sec per example)
05/09/2022 22:57:23 - INFO - __main__ -   Results: {'exact': 53.26086956521739, 'f1': 65.53720602744757, 'total': 276, 'HasAns_exact': 53.26086956521739, 'HasAns_f1': 65.53720602744757, 'HasAns_total': 276, 'best_exact': 53.26086956521739, 'best_exact_thresh': 0.0, 'best_f1': 65.53720602744757, 'best_f1_thresh': 0.0}
  ru 
2022-05-09 22:57:26.556232: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0
05/09/2022 22:57:30 - WARNING - __main__ -   Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, 16-bits training: False
You are using a model of type xlm-roberta to instantiate a model of type xlm. This is not supported for all configurations of models and can yield errors.
Some weights of the model checkpoint at /cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//tydiqa/xlm-KG_LR8e-6_EPOCH2.0_maxlen384_batchsize4_gradacc4 were not used when initializing XLMRobertaModel: ['base_model.encoder.layer.13.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.10.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.12.output.dense.weight', 'base_model.encoder.layer.16.output.dense.weight', 'base_model.encoder.layer.23.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.20.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.23.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.11.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.18.intermediate.dense.bias', 'base_model.encoder.layer.23.intermediate.dense.weight', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'qa_outputs.weight', 'base_model.encoder.layer.6.intermediate.dense.weight', 'base_model.encoder.layer.14.attention.self.key.weight', 'base_model.encoder.layer.0.output.LayerNorm.weight', 'base_model.encoder.layer.9.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.19.attention.self.key.weight', 'base_model.encoder.layer.3.attention.output.LayerNorm.bias', 'base_model.encoder.layer.12.attention.output.dense.weight', 'base_model.encoder.layer.16.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.10.output.dense.weight', 'base_model.encoder.layer.19.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.1.output.LayerNorm.bias', 'base_model.encoder.layer.5.output.dense.weight', 'base_model.encoder.layer.10.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.16.intermediate.dense.bias', 'base_model.encoder.layer.22.attention.output.LayerNorm.bias', 'base_model.encoder.layer.23.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.0.intermediate.dense.weight', 'base_model.encoder.layer.16.attention.self.value.weight', 'base_model.encoder.layer.10.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.0.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.14.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.23.attention.output.dense.bias', 'base_model.encoder.layer.23.intermediate.dense.bias', 'base_model.encoder.layer.2.intermediate.dense.bias', 'base_model.encoder.layer.15.output.LayerNorm.bias', 'base_model.encoder.layer.15.attention.output.dense.weight', 'base_model.encoder.layer.1.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.20.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.10.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.21.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.5.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.6.attention.self.key.bias', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.11.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.17.output.dense.bias', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.19.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.8.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.8.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.8.intermediate.dense.weight', 'base_model.encoder.layer.7.attention.output.dense.weight', 'base_model.encoder.layer.10.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.1.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.23.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.23.output.dense.weight', 'base_model.encoder.layer.20.attention.output.LayerNorm.bias', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.13.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.19.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.9.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.2.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.1.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.7.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.11.attention.self.key.bias', 'base_model.encoder.layer.15.output.dense.bias', 'base_model.encoder.layer.12.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.13.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.16.attention.output.dense.weight', 'base_model.encoder.layer.3.output.dense.bias', 'base_model.encoder.layer.18.attention.self.value.weight', 'base_model.encoder.layer.12.attention.self.query.bias', 'base_model.encoder.layer.19.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.19.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.18.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.4.attention.output.dense.weight', 'base_model.encoder.layer.9.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.9.attention.self.key.weight', 'base_model.encoder.layer.2.output.dense.weight', 'base_model.encoder.layer.7.attention.self.query.bias', 'base_model.encoder.layer.8.output.LayerNorm.weight', 'base_model.encoder.layer.8.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.12.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.20.output.LayerNorm.weight', 'base_model.encoder.layer.2.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.3.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.18.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.11.output.LayerNorm.weight', 'base_model.encoder.layer.6.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.6.attention.self.query.weight', 'base_model.encoder.layer.12.attention.self.value.weight', 'base_model.encoder.layer.19.attention.output.dense.weight', 'base_model.encoder.layer.0.attention.output.dense.weight', 'base_model.encoder.layer.0.output.LayerNorm.bias', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.18.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.6.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.0.attention.self.query.weight', 'base_model.encoder.layer.19.attention.self.query.weight', 'base_model.encoder.layer.9.attention.self.value.bias', 'base_model.encoder.layer.10.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.23.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.4.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.9.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.1.attention.output.dense.weight', 'base_model.encoder.layer.0.attention.output.LayerNorm.weight', 'base_model.encoder.layer.8.attention.output.dense.bias', 'base_model.encoder.layer.12.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.6.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.1.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.23.attention.self.key.bias', 'base_model.encoder.layer.10.attention.self.value.bias', 'base_model.encoder.layer.20.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.18.attention.output.dense.bias', 'base_model.encoder.layer.1.attention.output.LayerNorm.bias', 'base_model.encoder.layer.9.attention.output.dense.bias', 'base_model.encoder.layer.19.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.17.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.11.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.17.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.11.attention.self.key.weight', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.7.attention.output.LayerNorm.weight', 'base_model.encoder.layer.9.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.11.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.11.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.16.output.dense.bias', 'base_model.encoder.layer.18.output.dense.weight', 'base_model.encoder.layer.23.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.19.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.21.attention.self.value.weight', 'base_model.encoder.layer.12.intermediate.dense.bias', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.9.output.LayerNorm.weight', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.3.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.13.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.1.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.20.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.5.attention.self.key.bias', 'base_model.encoder.layer.4.attention.self.value.bias', 'base_model.encoder.layer.13.attention.self.value.weight', 'base_model.encoder.layer.15.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.22.intermediate.dense.weight', 'base_model.encoder.layer.2.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.1.attention.self.value.bias', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.8.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.6.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.7.attention.self.value.bias', 'base_model.encoder.layer.14.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.7.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.4.attention.output.dense.bias', 'base_model.encoder.layer.15.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.2.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.5.attention.self.query.weight', 'base_model.encoder.layer.10.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.19.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.14.attention.self.value.weight', 'base_model.encoder.layer.15.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.18.attention.output.LayerNorm.bias', 'base_model.encoder.layer.22.attention.output.LayerNorm.weight', 'base_model.encoder.layer.19.attention.output.dense.bias', 'base_model.encoder.layer.1.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.13.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.0.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.9.intermediate.dense.bias', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.18.attention.self.value.bias', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.6.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.16.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.12.attention.self.key.bias', 'base_model.encoder.layer.21.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.16.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.13.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.7.intermediate.dense.weight', 'base_model.encoder.layer.15.output.adapters.ts.adapter_up.bias', 'base_model.embeddings.word_embeddings.weight', 'base_model.encoder.layer.19.output.LayerNorm.bias', 'base_model.encoder.layer.2.attention.output.dense.bias', 'base_model.encoder.layer.1.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.11.attention.output.dense.weight', 'base_model.encoder.layer.4.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.14.attention.output.LayerNorm.bias', 'base_model.encoder.layer.2.attention.self.query.bias', 'base_model.encoder.layer.21.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.18.output.LayerNorm.weight', 'base_model.encoder.layer.16.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.21.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.18.output.LayerNorm.bias', 'base_model.encoder.layer.5.attention.output.LayerNorm.bias', 'base_model.encoder.layer.2.output.LayerNorm.bias', 'base_model.encoder.layer.5.output.LayerNorm.bias', 'base_model.encoder.layer.22.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.6.attention.output.LayerNorm.bias', 'base_model.encoder.layer.9.attention.self.query.bias', 'base_model.encoder.layer.4.attention.self.key.bias', 'base_model.encoder.layer.18.attention.self.query.weight', 'base_model.encoder.layer.15.attention.self.value.bias', 'base_model.encoder.layer.19.attention.output.LayerNorm.bias', 'base_model.encoder.layer.21.attention.self.query.bias', 'base_model.encoder.layer.15.intermediate.dense.weight', 'base_model.encoder.layer.22.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.10.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.4.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.20.attention.self.key.bias', 'base_model.encoder.layer.23.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.23.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.9.output.dense.weight', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.8.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.20.intermediate.dense.weight', 'base_model.encoder.layer.23.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.10.attention.output.LayerNorm.weight', 'base_model.encoder.layer.19.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.20.attention.self.query.bias', 'base_model.encoder.layer.19.output.dense.weight', 'base_model.encoder.layer.3.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.3.attention.self.key.bias', 'base_model.encoder.layer.14.output.dense.bias', 'base_model.encoder.layer.7.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.12.attention.output.dense.bias', 'base_model.encoder.layer.3.attention.output.LayerNorm.weight', 'base_model.encoder.layer.7.output.dense.weight', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.1.attention.self.key.weight', 'base_model.encoder.layer.13.attention.output.LayerNorm.bias', 'base_model.encoder.layer.22.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.23.attention.self.value.bias', 'base_model.encoder.layer.14.intermediate.dense.weight', 'base_model.encoder.layer.17.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.17.attention.self.query.bias', 'base_model.encoder.layer.13.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.10.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.0.attention.self.key.bias', 'base_model.encoder.layer.3.attention.self.query.weight', 'base_model.encoder.layer.6.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.6.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.12.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.21.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.13.attention.output.dense.weight', 'base_model.encoder.layer.22.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.20.output.dense.bias', 'base_model.encoder.layer.12.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.20.intermediate.dense.bias', 'base_model.encoder.layer.19.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.14.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.19.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.1.intermediate.dense.bias', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.6.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.10.output.dense.bias', 'base_model.encoder.layer.16.attention.self.query.bias', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.16.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.7.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.18.intermediate.dense.weight', 'base_model.encoder.layer.17.attention.self.key.weight', 'base_model.encoder.layer.12.output.dense.bias', 'base_model.encoder.layer.16.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.3.output.LayerNorm.weight', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.19.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.0.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.1.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.11.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.16.intermediate.dense.weight', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.8.attention.self.value.bias', 'base_model.encoder.layer.15.intermediate.dense.bias', 'base_model.encoder.layer.8.attention.output.LayerNorm.weight', 'base_model.encoder.layer.8.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.23.attention.self.query.bias', 'base_model.encoder.layer.20.attention.self.value.bias', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.18.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.3.output.dense.weight', 'base_model.encoder.layer.11.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.5.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.6.attention.self.value.bias', 'base_model.encoder.layer.18.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.1.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.6.attention.self.key.weight', 'base_model.encoder.layer.14.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.15.attention.self.query.weight', 'base_model.encoder.layer.1.output.LayerNorm.weight', 'base_model.encoder.layer.21.attention.self.key.weight', 'base_model.encoder.layer.12.intermediate.dense.weight', 'base_model.encoder.layer.0.output.dense.bias', 'base_model.encoder.layer.3.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.13.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.17.attention.output.LayerNorm.bias', 'base_model.encoder.layer.3.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.6.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.5.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.14.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.14.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.9.attention.output.LayerNorm.weight', 'base_model.encoder.layer.9.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.14.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.3.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.15.attention.output.LayerNorm.bias', 'base_model.encoder.layer.17.attention.self.key.bias', 'base_model.encoder.layer.16.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.7.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.7.attention.self.query.weight', 'base_model.encoder.layer.20.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.7.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.6.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.21.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.10.intermediate.dense.bias', 'base_model.encoder.layer.22.attention.self.key.bias', 'base_model.encoder.layer.20.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.2.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.13.intermediate.dense.weight', 'base_model.encoder.layer.18.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.18.attention.output.dense.weight', 'base_model.encoder.layer.21.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.17.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.23.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.12.attention.output.LayerNorm.bias', 'base_model.encoder.layer.22.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.19.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.17.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.17.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.12.attention.self.key.weight', 'base_model.encoder.layer.18.attention.self.query.bias', 'base_model.encoder.layer.8.attention.self.query.bias', 'base_model.encoder.layer.9.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.1.output.dense.bias', 'base_model.encoder.layer.23.output.LayerNorm.weight', 'base_model.encoder.layer.19.output.dense.bias', 'base_model.encoder.layer.2.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.17.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.21.output.dense.weight', 'base_model.encoder.layer.17.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.17.attention.output.dense.weight', 'base_model.encoder.layer.15.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.13.intermediate.dense.bias', 'base_model.encoder.layer.10.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.1.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.18.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.11.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.0.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.12.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.15.output.LayerNorm.weight', 'base_model.encoder.layer.6.attention.output.dense.weight', 'base_model.encoder.layer.13.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.14.attention.self.key.bias', 'base_model.encoder.layer.18.attention.self.key.bias', 'base_model.encoder.layer.1.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.embeddings.LayerNorm.bias', 'base_model.encoder.layer.2.intermediate.dense.weight', 'base_model.encoder.layer.4.output.dense.weight', 'base_model.encoder.layer.14.output.LayerNorm.weight', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.18.output.dense.bias', 'base_model.encoder.layer.12.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.22.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.17.output.LayerNorm.bias', 'base_model.encoder.layer.16.attention.output.LayerNorm.weight', 'base_model.encoder.layer.2.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.11.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.14.attention.output.LayerNorm.weight', 'base_model.encoder.layer.15.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.10.intermediate.dense.weight', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.0.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.18.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.14.attention.output.dense.bias', 'base_model.encoder.layer.21.attention.output.LayerNorm.weight', 'base_model.encoder.layer.15.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.1.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.0.attention.output.LayerNorm.bias', 'base_model.encoder.layer.7.attention.self.key.bias', 'base_model.encoder.layer.16.output.LayerNorm.weight', 'base_model.encoder.layer.2.attention.self.key.bias', 'base_model.encoder.layer.7.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.11.attention.self.query.bias', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.0.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.6.attention.output.dense.bias', 'base_model.encoder.layer.4.output.LayerNorm.bias', 'base_model.encoder.layer.5.attention.self.value.weight', 'base_model.encoder.layer.2.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.3.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.3.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.17.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.7.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.15.output.dense.weight', 'base_model.encoder.layer.15.attention.self.key.weight', 'base_model.encoder.layer.12.attention.self.value.bias', 'base_model.encoder.layer.8.output.dense.bias', 'base_model.embeddings.position_embeddings.weight', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.embeddings.token_type_embeddings.weight', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.14.attention.self.query.bias', 'base_model.encoder.layer.6.output.LayerNorm.bias', 'base_model.encoder.layer.21.output.adapters.tp.adapter_up.bias', 'base_model.pooler.dense.weight', 'base_model.encoder.layer.5.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.6.output.dense.bias', 'base_model.embeddings.position_ids', 'base_model.encoder.layer.11.attention.self.value.weight', 'base_model.encoder.layer.13.attention.self.key.weight', 'base_model.encoder.layer.14.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.7.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.8.attention.output.LayerNorm.bias', 'base_model.encoder.layer.7.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.20.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.11.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.17.intermediate.dense.weight', 'base_model.encoder.layer.13.output.dense.bias', 'base_model.encoder.layer.16.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.9.output.LayerNorm.bias', 'base_model.encoder.layer.9.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.10.attention.output.dense.weight', 'qa_outputs.bias', 'base_model.encoder.layer.0.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.4.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.7.attention.output.LayerNorm.bias', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.4.intermediate.dense.weight', 'base_model.embeddings.LayerNorm.weight', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.21.attention.self.value.bias', 'base_model.encoder.layer.7.output.LayerNorm.weight', 'base_model.encoder.layer.15.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.22.attention.self.value.weight', 'base_model.encoder.layer.21.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.4.output.dense.bias', 'base_model.encoder.layer.20.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.14.attention.self.query.weight', 'base_model.encoder.layer.22.intermediate.dense.bias', 'base_model.encoder.layer.9.output.dense.bias', 'base_model.encoder.layer.2.attention.self.value.weight', 'base_model.encoder.layer.2.output.dense.bias', 'base_model.encoder.layer.8.intermediate.dense.bias', 'base_model.encoder.layer.15.attention.self.query.bias', 'base_model.encoder.layer.15.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.22.output.LayerNorm.bias', 'base_model.encoder.layer.6.intermediate.dense.bias', 'base_model.encoder.layer.0.attention.self.query.bias', 'base_model.encoder.layer.1.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.2.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.23.output.LayerNorm.bias', 'base_model.encoder.layer.3.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.7.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.8.attention.self.query.weight', 'base_model.encoder.layer.7.intermediate.dense.bias', 'base_model.encoder.layer.5.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.9.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.13.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.20.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.14.attention.output.dense.weight', 'base_model.encoder.layer.9.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.8.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.2.attention.output.LayerNorm.weight', 'base_model.encoder.layer.11.attention.output.dense.bias', 'base_model.encoder.layer.17.attention.self.value.weight', 'base_model.pooler.dense.bias', 'base_model.encoder.layer.7.attention.self.value.weight', 'base_model.encoder.layer.21.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.14.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.17.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.3.intermediate.dense.weight', 'base_model.encoder.layer.7.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.9.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.2.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.5.attention.self.value.bias', 'base_model.encoder.layer.10.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.4.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.6.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.5.attention.self.query.bias', 'base_model.encoder.layer.3.attention.self.value.weight', 'base_model.encoder.layer.12.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.23.output.dense.bias', 'base_model.encoder.layer.1.attention.self.key.bias', 'base_model.encoder.layer.23.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.0.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.5.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.21.attention.output.dense.bias', 'base_model.encoder.layer.4.attention.self.value.weight', 'base_model.encoder.layer.4.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.21.attention.self.key.bias', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.8.attention.output.dense.weight', 'base_model.encoder.layer.1.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.22.attention.self.query.weight', 'base_model.encoder.layer.2.attention.self.value.bias', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.11.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.17.intermediate.dense.bias', 'base_model.encoder.layer.9.attention.output.LayerNorm.bias', 'base_model.encoder.layer.22.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.8.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.1.attention.self.query.weight', 'base_model.encoder.layer.14.output.dense.weight', 'base_model.encoder.layer.11.intermediate.dense.bias', 'base_model.encoder.layer.18.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.19.attention.self.value.weight', 'base_model.encoder.layer.4.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.8.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.12.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.5.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.18.attention.self.key.weight', 'base_model.encoder.layer.22.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.3.attention.output.dense.bias', 'base_model.encoder.layer.22.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.0.attention.self.key.weight', 'base_model.encoder.layer.0.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.9.intermediate.dense.weight', 'base_model.encoder.layer.21.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.9.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.15.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.16.attention.self.key.weight', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.4.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.5.attention.self.key.weight', 'base_model.encoder.layer.10.attention.output.dense.bias', 'base_model.encoder.layer.20.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.11.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.0.output.dense.weight', 'base_model.encoder.layer.21.intermediate.dense.bias', 'base_model.encoder.layer.19.output.LayerNorm.weight', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.6.output.LayerNorm.weight', 'base_model.encoder.layer.23.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.16.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.12.attention.self.query.weight', 'base_model.encoder.layer.11.intermediate.dense.weight', 'base_model.encoder.layer.18.attention.output.LayerNorm.weight', 'base_model.encoder.layer.7.output.dense.bias', 'base_model.encoder.layer.23.attention.output.LayerNorm.bias', 'base_model.encoder.layer.0.intermediate.dense.bias', 'base_model.encoder.layer.13.attention.self.key.bias', 'base_model.encoder.layer.20.attention.output.dense.weight', 'base_model.encoder.layer.4.output.LayerNorm.weight', 'base_model.encoder.layer.5.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.23.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.5.attention.output.dense.bias', 'base_model.encoder.layer.3.attention.self.query.bias', 'base_model.encoder.layer.4.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.12.output.LayerNorm.bias', 'base_model.encoder.layer.16.attention.self.key.bias', 'base_model.encoder.layer.3.attention.output.dense.weight', 'base_model.encoder.layer.0.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.8.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.13.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.8.output.dense.weight', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.14.intermediate.dense.bias', 'base_model.encoder.layer.10.output.LayerNorm.weight', 'base_model.encoder.layer.23.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.13.attention.self.query.bias', 'base_model.encoder.layer.1.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.9.attention.self.query.weight', 'base_model.encoder.layer.10.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.21.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.17.output.dense.weight', 'base_model.encoder.layer.6.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.15.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.3.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.8.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.13.attention.output.dense.bias', 'base_model.encoder.layer.5.output.LayerNorm.weight', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.13.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.6.attention.self.value.weight', 'base_model.encoder.layer.4.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.17.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.2.output.LayerNorm.weight', 'base_model.encoder.layer.19.attention.self.key.bias', 'base_model.encoder.layer.9.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.10.output.LayerNorm.bias', 'base_model.encoder.layer.13.attention.self.value.bias', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.10.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.23.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.3.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.3.intermediate.dense.bias', 'base_model.encoder.layer.19.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.15.attention.output.LayerNorm.weight', 'base_model.encoder.layer.4.attention.output.LayerNorm.bias', 'base_model.encoder.layer.8.attention.self.key.bias', 'base_model.encoder.layer.16.output.LayerNorm.bias', 'base_model.encoder.layer.5.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.2.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.8.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.3.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.15.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.13.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.12.attention.output.LayerNorm.weight', 'base_model.encoder.layer.7.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.19.attention.self.value.bias', 'base_model.encoder.layer.4.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.1.attention.output.LayerNorm.weight', 'base_model.encoder.layer.15.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.20.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.5.output.dense.bias', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.9.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.10.attention.self.query.bias', 'base_model.encoder.layer.12.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.13.output.dense.weight', 'base_model.encoder.layer.2.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.15.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.22.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.22.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.17.attention.self.value.bias', 'base_model.encoder.layer.2.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.2.attention.self.query.weight', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.2.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.3.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.23.attention.self.value.weight', 'base_model.encoder.layer.1.intermediate.dense.weight', 'base_model.encoder.layer.16.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.7.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.14.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.18.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.21.attention.output.dense.weight', 'base_model.encoder.layer.1.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.7.attention.output.dense.bias', 'base_model.encoder.layer.8.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.12.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.5.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.2.attention.output.LayerNorm.bias', 'base_model.encoder.layer.13.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.0.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.8.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.3.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.6.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.21.output.LayerNorm.weight', 'base_model.encoder.layer.15.attention.self.value.weight', 'base_model.encoder.layer.0.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.0.attention.output.dense.bias', 'base_model.encoder.layer.20.attention.output.LayerNorm.weight', 'base_model.encoder.layer.2.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.20.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.21.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.17.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.10.attention.output.LayerNorm.bias', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.19.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.9.attention.output.dense.weight', 'base_model.encoder.layer.20.output.dense.weight', 'base_model.encoder.layer.5.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.16.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.10.attention.self.key.bias', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.10.attention.self.value.weight', 'base_model.encoder.layer.11.output.LayerNorm.bias', 'base_model.encoder.layer.23.attention.self.key.weight', 'base_model.encoder.layer.20.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.7.attention.self.key.weight', 'base_model.encoder.layer.1.attention.self.query.bias', 'base_model.encoder.layer.16.attention.output.dense.bias', 'base_model.encoder.layer.1.output.dense.weight', 'base_model.encoder.layer.22.output.dense.weight', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.3.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.17.output.LayerNorm.weight', 'base_model.encoder.layer.20.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.13.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.2.attention.output.dense.weight', 'base_model.encoder.layer.21.output.LayerNorm.bias', 'base_model.encoder.layer.14.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.23.attention.self.query.weight', 'base_model.encoder.layer.22.attention.output.dense.weight', 'base_model.encoder.layer.21.intermediate.dense.weight', 'base_model.encoder.layer.2.attention.self.key.weight', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.16.attention.self.query.weight', 'base_model.encoder.layer.20.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.1.attention.self.value.weight', 'base_model.encoder.layer.21.attention.self.query.weight', 'base_model.encoder.layer.17.attention.self.query.weight', 'base_model.encoder.layer.17.attention.output.LayerNorm.weight', 'base_model.encoder.layer.19.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.9.attention.self.value.weight', 'base_model.encoder.layer.4.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.18.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.2.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.4.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.6.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.5.intermediate.dense.bias', 'base_model.encoder.layer.15.attention.output.dense.bias', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.7.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.20.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.23.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.5.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.17.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.19.intermediate.dense.weight', 'base_model.encoder.layer.21.output.dense.bias', 'base_model.encoder.layer.1.attention.output.dense.bias', 'base_model.encoder.layer.0.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.11.attention.self.query.weight', 'base_model.encoder.layer.12.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.4.attention.self.query.weight', 'base_model.encoder.layer.3.output.LayerNorm.bias', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.11.attention.output.LayerNorm.weight', 'base_model.encoder.layer.4.attention.output.LayerNorm.weight', 'base_model.encoder.layer.13.output.LayerNorm.weight', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.15.attention.self.key.bias', 'base_model.encoder.layer.10.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.0.attention.self.value.weight', 'base_model.encoder.layer.4.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.16.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.21.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.22.output.LayerNorm.weight', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.10.attention.self.key.weight', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.18.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.17.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.22.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.8.attention.self.value.weight', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.8.attention.self.key.weight', 'base_model.encoder.layer.18.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.4.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.5.attention.output.LayerNorm.weight', 'base_model.encoder.layer.14.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.20.output.LayerNorm.bias', 'base_model.encoder.layer.11.attention.self.value.bias', 'base_model.encoder.layer.14.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.20.attention.self.key.weight', 'base_model.encoder.layer.3.attention.self.key.weight', 'base_model.encoder.layer.23.attention.output.dense.weight', 'base_model.encoder.layer.7.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.8.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.12.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.14.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.9.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.16.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.11.attention.output.LayerNorm.bias', 'base_model.encoder.layer.20.attention.output.dense.bias', 'base_model.encoder.layer.3.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.9.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.22.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.16.attention.output.LayerNorm.bias', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.22.attention.self.value.bias', 'base_model.encoder.layer.20.attention.self.value.weight', 'base_model.encoder.layer.4.intermediate.dense.bias', 'base_model.encoder.layer.11.output.dense.bias', 'base_model.encoder.layer.17.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.18.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.11.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.19.attention.self.query.bias', 'base_model.encoder.layer.22.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.0.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.4.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.0.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.9.attention.self.key.bias', 'base_model.encoder.layer.4.attention.self.query.bias', 'base_model.encoder.layer.16.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.22.attention.self.query.bias', 'base_model.encoder.layer.12.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.20.attention.self.query.weight', 'base_model.encoder.layer.6.attention.self.query.bias', 'base_model.encoder.layer.5.attention.output.dense.weight', 'base_model.encoder.layer.8.output.LayerNorm.bias', 'base_model.encoder.layer.11.output.dense.weight', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.17.attention.output.dense.bias', 'base_model.encoder.layer.5.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.13.attention.self.query.weight', 'base_model.encoder.layer.0.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.14.output.LayerNorm.bias', 'base_model.encoder.layer.16.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.21.attention.output.LayerNorm.bias', 'base_model.encoder.layer.18.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.6.attention.output.LayerNorm.weight', 'base_model.encoder.layer.6.output.dense.weight', 'base_model.encoder.layer.22.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.7.output.LayerNorm.bias', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.17.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.22.attention.self.key.weight', 'base_model.encoder.layer.12.output.LayerNorm.weight', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.13.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.14.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.12.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.10.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.22.output.dense.bias', 'base_model.encoder.layer.23.attention.output.LayerNorm.weight', 'base_model.encoder.layer.14.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.22.attention.output.dense.bias', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.0.attention.self.value.bias', 'base_model.encoder.layer.14.attention.self.value.bias', 'base_model.encoder.layer.13.output.LayerNorm.bias', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.11.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.15.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.16.attention.self.value.bias', 'base_model.encoder.layer.15.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.19.attention.output.LayerNorm.weight', 'base_model.encoder.layer.5.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.6.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.10.attention.self.query.weight', 'base_model.encoder.layer.18.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.21.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.22.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.11.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.10.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.8.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.19.intermediate.dense.bias', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.5.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.11.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.5.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.5.intermediate.dense.weight', 'base_model.encoder.layer.3.attention.self.value.bias', 'base_model.encoder.layer.12.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.21.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.4.attention.self.key.weight', 'base_model.encoder.layer.16.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.6.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.13.attention.output.LayerNorm.weight']
- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of XLMRobertaModel were not initialized from the model checkpoint at /cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//tydiqa/xlm-KG_LR8e-6_EPOCH2.0_maxlen384_batchsize4_gradacc4 and are newly initialized: ['encoder.layer.18.output.dense.weight', 'encoder.layer.7.attention.self.value.bias', 'encoder.layer.2.attention.self.query.bias', 'encoder.layer.18.attention.self.value.bias', 'encoder.layer.8.attention.output.LayerNorm.bias', 'encoder.layer.20.intermediate.dense.weight', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.11.attention.self.key.weight', 'encoder.layer.18.output.LayerNorm.weight', 'encoder.layer.7.attention.self.query.bias', 'encoder.layer.9.attention.self.key.weight', 'encoder.layer.10.attention.self.value.weight', 'encoder.layer.1.attention.self.value.bias', 'encoder.layer.14.attention.output.LayerNorm.bias', 'encoder.layer.19.intermediate.dense.bias', 'encoder.layer.14.output.LayerNorm.weight', 'encoder.layer.15.output.LayerNorm.bias', 'encoder.layer.16.output.LayerNorm.bias', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.4.attention.self.query.bias', 'pooler.dense.weight', 'encoder.layer.13.attention.output.LayerNorm.weight', 'encoder.layer.1.attention.self.key.bias', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.8.attention.output.LayerNorm.weight', 'encoder.layer.23.attention.output.LayerNorm.bias', 'embeddings.token_type_embeddings.weight', 'encoder.layer.21.attention.output.LayerNorm.bias', 'encoder.layer.17.attention.output.dense.weight', 'encoder.layer.11.attention.self.query.bias', 'encoder.layer.11.output.LayerNorm.weight', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.3.attention.self.query.bias', 'encoder.layer.0.attention.self.value.weight', 'encoder.layer.22.attention.output.LayerNorm.weight', 'encoder.layer.0.attention.output.dense.weight', 'encoder.layer.18.output.LayerNorm.bias', 'encoder.layer.13.attention.self.query.weight', 'encoder.layer.10.attention.output.dense.bias', 'encoder.layer.3.attention.self.key.bias', 'encoder.layer.9.attention.self.value.weight', 'encoder.layer.7.output.LayerNorm.bias', 'encoder.layer.19.attention.self.key.bias', 'encoder.layer.1.attention.output.LayerNorm.weight', 'embeddings.LayerNorm.weight', 'encoder.layer.3.output.dense.weight', 'encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.layer.14.attention.self.value.weight', 'encoder.layer.19.attention.self.value.bias', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.1.attention.self.key.weight', 'encoder.layer.9.attention.output.dense.bias', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.22.attention.self.value.bias', 'encoder.layer.12.attention.self.key.weight', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.layer.21.output.LayerNorm.weight', 'encoder.layer.6.attention.output.LayerNorm.bias', 'encoder.layer.23.output.dense.bias', 'encoder.layer.1.output.dense.weight', 'encoder.layer.15.attention.self.key.bias', 'encoder.layer.20.attention.self.query.bias', 'encoder.layer.6.output.dense.bias', 'encoder.layer.10.attention.self.key.weight', 'encoder.layer.20.attention.self.value.bias', 'encoder.layer.20.output.LayerNorm.weight', 'encoder.layer.12.output.LayerNorm.bias', 'encoder.layer.4.attention.self.value.weight', 'encoder.layer.22.attention.self.key.weight', 'encoder.layer.14.output.dense.bias', 'encoder.layer.3.attention.output.dense.bias', 'encoder.layer.17.output.dense.bias', 'encoder.layer.23.output.LayerNorm.weight', 'encoder.layer.5.attention.self.query.bias', 'encoder.layer.20.attention.self.key.bias', 'encoder.layer.7.attention.self.key.weight', 'encoder.layer.4.attention.output.dense.weight', 'encoder.layer.7.attention.self.value.weight', 'encoder.layer.16.attention.output.dense.bias', 'encoder.layer.22.attention.self.key.bias', 'encoder.layer.2.attention.output.dense.bias', 'encoder.layer.5.attention.self.value.bias', 'encoder.layer.16.attention.self.key.bias', 'encoder.layer.12.attention.output.dense.weight', 'encoder.layer.1.attention.self.query.bias', 'encoder.layer.16.output.dense.weight', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.9.output.dense.bias', 'encoder.layer.3.attention.self.key.weight', 'encoder.layer.19.attention.self.value.weight', 'encoder.layer.12.attention.output.dense.bias', 'encoder.layer.13.intermediate.dense.weight', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.14.intermediate.dense.weight', 'encoder.layer.20.attention.self.key.weight', 'encoder.layer.15.attention.self.query.bias', 'encoder.layer.0.attention.output.dense.bias', 'encoder.layer.21.output.dense.weight', 'encoder.layer.8.attention.self.key.weight', 'encoder.layer.19.attention.output.dense.weight', 'encoder.layer.18.attention.output.LayerNorm.bias', 'encoder.layer.10.attention.self.query.bias', 'pooler.dense.bias', 'encoder.layer.23.attention.output.dense.bias', 'encoder.layer.18.attention.self.query.weight', 'encoder.layer.0.attention.self.query.bias', 'encoder.layer.12.attention.output.LayerNorm.weight', 'encoder.layer.17.intermediate.dense.bias', 'encoder.layer.0.attention.self.value.bias', 'encoder.layer.15.output.dense.weight', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.10.attention.self.value.bias', 'encoder.layer.18.intermediate.dense.bias', 'encoder.layer.15.attention.self.value.bias', 'encoder.layer.16.attention.output.dense.weight', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.19.attention.output.LayerNorm.bias', 'encoder.layer.16.intermediate.dense.bias', 'encoder.layer.18.attention.output.dense.bias', 'encoder.layer.15.attention.output.dense.weight', 'encoder.layer.4.attention.self.value.bias', 'encoder.layer.12.attention.self.query.weight', 'encoder.layer.19.attention.output.LayerNorm.weight', 'encoder.layer.0.output.dense.bias', 'encoder.layer.15.intermediate.dense.weight', 'encoder.layer.6.attention.self.key.weight', 'encoder.layer.11.attention.output.dense.bias', 'encoder.layer.10.attention.output.LayerNorm.weight', 'encoder.layer.13.output.LayerNorm.weight', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.20.intermediate.dense.bias', 'encoder.layer.21.output.dense.bias', 'encoder.layer.7.attention.output.dense.bias', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.16.attention.output.LayerNorm.bias', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.19.output.dense.bias', 'embeddings.word_embeddings.weight', 'encoder.layer.18.output.dense.bias', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.17.attention.self.query.weight', 'encoder.layer.23.intermediate.dense.bias', 'encoder.layer.10.output.dense.bias', 'encoder.layer.13.attention.output.dense.weight', 'encoder.layer.22.output.LayerNorm.weight', 'encoder.layer.17.attention.output.LayerNorm.weight', 'encoder.layer.15.attention.output.dense.bias', 'encoder.layer.4.attention.self.key.weight', 'encoder.layer.22.attention.self.query.bias', 'encoder.layer.16.attention.output.LayerNorm.weight', 'encoder.layer.9.output.dense.weight', 'encoder.layer.8.attention.output.dense.bias', 'encoder.layer.1.attention.self.query.weight', 'encoder.layer.6.attention.self.key.bias', 'encoder.layer.5.attention.self.key.bias', 'encoder.layer.16.intermediate.dense.weight', 'encoder.layer.11.output.dense.bias', 'encoder.layer.1.output.dense.bias', 'encoder.layer.17.attention.output.LayerNorm.bias', 'encoder.layer.4.attention.self.key.bias', 'encoder.layer.14.attention.self.query.bias', 'encoder.layer.16.attention.self.key.weight', 'encoder.layer.7.output.dense.bias', 'encoder.layer.7.attention.output.dense.weight', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.15.attention.self.query.weight', 'encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.layer.3.attention.self.value.weight', 'encoder.layer.13.output.dense.weight', 'encoder.layer.22.intermediate.dense.weight', 'encoder.layer.5.attention.output.dense.weight', 'encoder.layer.17.attention.self.query.bias', 'encoder.layer.19.attention.self.key.weight', 'encoder.layer.0.attention.self.query.weight', 'encoder.layer.6.attention.output.LayerNorm.weight', 'encoder.layer.5.attention.output.LayerNorm.weight', 'encoder.layer.16.output.LayerNorm.weight', 'encoder.layer.9.attention.output.dense.weight', 'encoder.layer.5.attention.output.dense.bias', 'encoder.layer.0.output.dense.weight', 'encoder.layer.6.attention.self.value.weight', 'encoder.layer.2.attention.self.value.bias', 'encoder.layer.5.attention.self.key.weight', 'encoder.layer.1.attention.output.dense.weight', 'encoder.layer.13.attention.self.key.weight', 'encoder.layer.21.attention.output.LayerNorm.weight', 'encoder.layer.17.attention.self.key.bias', 'encoder.layer.19.output.LayerNorm.weight', 'encoder.layer.20.attention.self.query.weight', 'encoder.layer.15.attention.self.value.weight', 'encoder.layer.17.output.LayerNorm.weight', 'encoder.layer.19.output.LayerNorm.bias', 'encoder.layer.21.intermediate.dense.weight', 'encoder.layer.8.attention.self.key.bias', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.23.output.dense.weight', 'encoder.layer.4.output.dense.weight', 'encoder.layer.17.output.dense.weight', 'encoder.layer.22.attention.output.dense.weight', 'encoder.layer.10.attention.self.key.bias', 'encoder.layer.11.output.LayerNorm.bias', 'encoder.layer.22.intermediate.dense.bias', 'encoder.layer.13.attention.self.value.bias', 'encoder.layer.17.intermediate.dense.weight', 'encoder.layer.11.attention.output.LayerNorm.weight', 'encoder.layer.12.attention.self.key.bias', 'encoder.layer.4.output.dense.bias', 'encoder.layer.11.attention.output.dense.weight', 'encoder.layer.1.attention.output.dense.bias', 'encoder.layer.13.attention.output.LayerNorm.bias', 'encoder.layer.14.attention.output.dense.bias', 'encoder.layer.23.attention.self.key.bias', 'encoder.layer.2.output.dense.weight', 'encoder.layer.14.attention.self.key.bias', 'encoder.layer.19.attention.self.query.bias', 'encoder.layer.12.output.dense.bias', 'encoder.layer.2.output.dense.bias', 'encoder.layer.10.output.dense.weight', 'encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.layer.8.output.LayerNorm.bias', 'encoder.layer.4.attention.output.dense.bias', 'encoder.layer.23.attention.self.key.weight', 'encoder.layer.2.attention.output.LayerNorm.bias', 'encoder.layer.13.output.dense.bias', 'encoder.layer.20.output.dense.bias', 'encoder.layer.21.output.LayerNorm.bias', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.7.attention.self.key.bias', 'encoder.layer.1.attention.self.value.weight', 'encoder.layer.14.attention.output.dense.weight', 'encoder.layer.18.attention.self.key.weight', 'encoder.layer.8.output.dense.bias', 'encoder.layer.10.attention.output.LayerNorm.bias', 'encoder.layer.8.attention.output.dense.weight', 'encoder.layer.8.output.LayerNorm.weight', 'encoder.layer.13.intermediate.dense.bias', 'encoder.layer.2.attention.self.key.weight', 'encoder.layer.7.attention.self.query.weight', 'encoder.layer.15.output.dense.bias', 'encoder.layer.7.output.LayerNorm.weight', 'encoder.layer.3.output.dense.bias', 'encoder.layer.17.output.LayerNorm.bias', 'encoder.layer.12.attention.output.LayerNorm.bias', 'encoder.layer.11.attention.self.value.weight', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.12.attention.self.value.weight', 'encoder.layer.16.output.dense.bias', 'encoder.layer.22.attention.output.dense.bias', 'encoder.layer.17.attention.self.value.bias', 'encoder.layer.20.output.LayerNorm.bias', 'encoder.layer.23.attention.self.query.bias', 'encoder.layer.6.output.dense.weight', 'encoder.layer.23.attention.output.LayerNorm.weight', 'encoder.layer.6.output.LayerNorm.bias', 'encoder.layer.10.output.LayerNorm.bias', 'encoder.layer.15.attention.self.key.weight', 'encoder.layer.17.attention.self.value.weight', 'encoder.layer.12.output.dense.weight', 'encoder.layer.12.intermediate.dense.bias', 'encoder.layer.18.attention.output.dense.weight', 'encoder.layer.11.attention.self.key.bias', 'encoder.layer.7.attention.output.LayerNorm.bias', 'encoder.layer.4.attention.self.query.weight', 'embeddings.LayerNorm.bias', 'encoder.layer.9.attention.self.value.bias', 'encoder.layer.18.attention.self.value.weight', 'encoder.layer.14.attention.self.query.weight', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.4.attention.output.LayerNorm.weight', 'encoder.layer.19.attention.self.query.weight', 'encoder.layer.6.attention.self.value.bias', 'encoder.layer.8.attention.self.value.bias', 'encoder.layer.15.output.LayerNorm.weight', 'encoder.layer.23.attention.self.query.weight', 'encoder.layer.8.attention.self.value.weight', 'encoder.layer.14.attention.output.LayerNorm.weight', 'encoder.layer.23.intermediate.dense.weight', 'encoder.layer.10.attention.self.query.weight', 'encoder.layer.15.intermediate.dense.bias', 'encoder.layer.5.output.LayerNorm.bias', 'encoder.layer.13.attention.self.key.bias', 'encoder.layer.14.attention.self.key.weight', 'encoder.layer.6.attention.output.dense.bias', 'encoder.layer.7.intermediate.dense.bias', 'encoder.layer.23.output.LayerNorm.bias', 'encoder.layer.2.attention.self.key.bias', 'encoder.layer.20.attention.output.dense.bias', 'encoder.layer.21.intermediate.dense.bias', 'encoder.layer.6.attention.self.query.weight', 'encoder.layer.19.attention.output.dense.bias', 'encoder.layer.9.attention.self.query.weight', 'encoder.layer.21.attention.self.query.weight', 'encoder.layer.0.attention.self.key.bias', 'encoder.layer.18.attention.self.key.bias', 'encoder.layer.13.output.LayerNorm.bias', 'encoder.layer.14.intermediate.dense.bias', 'encoder.layer.12.attention.self.value.bias', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.8.attention.self.query.bias', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.20.attention.output.LayerNorm.weight', 'encoder.layer.10.output.LayerNorm.weight', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.22.attention.self.value.weight', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.3.attention.self.value.bias', 'encoder.layer.18.intermediate.dense.weight', 'encoder.layer.9.attention.self.query.bias', 'encoder.layer.6.attention.self.query.bias', 'encoder.layer.9.attention.output.LayerNorm.bias', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.18.attention.self.query.bias', 'encoder.layer.14.output.LayerNorm.bias', 'encoder.layer.2.attention.output.LayerNorm.weight', 'encoder.layer.13.attention.self.query.bias', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.9.output.LayerNorm.bias', 'encoder.layer.14.output.dense.weight', 'encoder.layer.13.attention.self.value.weight', 'encoder.layer.12.intermediate.dense.weight', 'encoder.layer.21.attention.output.dense.bias', 'encoder.layer.21.attention.self.key.weight', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.9.intermediate.dense.weight', 'embeddings.position_embeddings.weight', 'encoder.layer.7.output.dense.weight', 'encoder.layer.22.output.LayerNorm.bias', 'encoder.layer.5.attention.self.value.weight', 'encoder.layer.6.attention.output.dense.weight', 'encoder.layer.2.attention.self.value.weight', 'encoder.layer.21.attention.self.key.bias', 'encoder.layer.8.output.dense.weight', 'encoder.layer.20.attention.output.dense.weight', 'encoder.layer.21.attention.self.value.weight', 'encoder.layer.8.attention.self.query.weight', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.23.attention.self.value.bias', 'encoder.layer.4.attention.output.LayerNorm.bias', 'encoder.layer.20.attention.self.value.weight', 'encoder.layer.23.attention.self.value.weight', 'encoder.layer.9.attention.self.key.bias', 'encoder.layer.2.attention.self.query.weight', 'encoder.layer.10.intermediate.dense.weight', 'encoder.layer.5.output.dense.bias', 'encoder.layer.19.output.dense.weight', 'encoder.layer.10.attention.output.dense.weight', 'encoder.layer.3.attention.output.dense.weight', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.22.attention.output.LayerNorm.bias', 'encoder.layer.20.output.dense.weight', 'encoder.layer.5.output.dense.weight', 'encoder.layer.13.attention.output.dense.bias', 'encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.layer.0.attention.self.key.weight', 'encoder.layer.22.output.dense.weight', 'encoder.layer.21.attention.output.dense.weight', 'encoder.layer.2.attention.output.dense.weight', 'encoder.layer.9.output.LayerNorm.weight', 'encoder.layer.3.attention.self.query.weight', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.12.attention.self.query.bias', 'encoder.layer.9.attention.output.LayerNorm.weight', 'encoder.layer.16.attention.self.value.bias', 'encoder.layer.12.output.LayerNorm.weight', 'encoder.layer.5.attention.self.query.weight', 'encoder.layer.11.attention.self.query.weight', 'encoder.layer.16.attention.self.query.weight', 'encoder.layer.16.attention.self.value.weight', 'encoder.layer.15.attention.output.LayerNorm.bias', 'encoder.layer.19.intermediate.dense.weight', 'encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.layer.16.attention.self.query.bias', 'encoder.layer.23.attention.output.dense.weight', 'encoder.layer.20.attention.output.LayerNorm.bias', 'encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.17.attention.output.dense.bias', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.17.attention.self.key.weight', 'encoder.layer.22.output.dense.bias', 'encoder.layer.14.attention.self.value.bias', 'encoder.layer.18.attention.output.LayerNorm.weight', 'encoder.layer.7.attention.output.LayerNorm.weight', 'encoder.layer.11.attention.self.value.bias', 'encoder.layer.11.output.dense.weight', 'encoder.layer.21.attention.self.value.bias', 'encoder.layer.22.attention.self.query.weight', 'encoder.layer.15.attention.output.LayerNorm.weight', 'encoder.layer.0.attention.output.LayerNorm.weight', 'encoder.layer.21.attention.self.query.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Overwriting existing adapter 'ep'.
Overwriting existing adapter 'tp'.
Overwriting existing adapter 'es'.
Overwriting existing adapter 'ts'.
Overwriting existing adapter fusion module 'ep,tp,es,ts'
05/09/2022 22:57:50 - INFO - __main__ -   lang2id = None
05/09/2022 22:57:53 - INFO - __main__ -   Training/evaluation parameters Namespace(adam_epsilon=1e-08, cache_dir='', config_name='', data_dir=None, device=device(type='cuda'), do_eval=True, do_lower_case=False, do_train=False, doc_stride=128, eval_all_checkpoints=False, eval_lang='ru', evaluate_during_training=False, fp16=False, fp16_opt_level='O1', gradient_accumulation_steps=1, learning_rate=5e-05, local_rank=-1, logging_steps=50, max_answer_length=30, max_grad_norm=1.0, max_query_length=64, max_seq_length=384, max_steps=-1, model_name='xlm-KG', model_name_or_path='/cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//tydiqa/xlm-KG_LR8e-6_EPOCH2.0_maxlen384_batchsize4_gradacc4', model_type='xlm', modelkg_dir='/cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/adapter/xlmr_adapter', n_best_size=20, n_gpu=1, no_cuda=False, null_score_diff_threshold=0.0, num_train_epochs=3.0, output_dir='/cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//tydiqa/xlm-KG_LR8e-6_EPOCH2.0_maxlen384_batchsize4_gradacc4/predictions/tydiqa/', overwrite_cache=False, overwrite_output_dir=False, per_gpu_eval_batch_size=8, per_gpu_train_batch_size=8, predict_file='/cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/download//tydiqa//tydiqa-goldp-v1.1-dev/tydiqa.goldp.ru.dev.json', save_steps=50, seed=42, server_ip='', server_port='', threads=1, tokenizer_name='', train_file=None, train_lang='en', verbose_logging=False, version_2_with_negative=False, warmup_steps=0, weight_decay=0.0)
05/09/2022 22:57:53 - INFO - __main__ -   Loading checkpoint /cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//tydiqa/xlm-KG_LR8e-6_EPOCH2.0_maxlen384_batchsize4_gradacc4 for evaluation
05/09/2022 22:57:53 - INFO - __main__ -   Evaluate the following checkpoints: ['/cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//tydiqa/xlm-KG_LR8e-6_EPOCH2.0_maxlen384_batchsize4_gradacc4']
Some weights of the model checkpoint at /cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//tydiqa/xlm-KG_LR8e-6_EPOCH2.0_maxlen384_batchsize4_gradacc4 were not used when initializing XLMRobertaModel: ['base_model.encoder.layer.13.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.10.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.12.output.dense.weight', 'base_model.encoder.layer.16.output.dense.weight', 'base_model.encoder.layer.23.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.20.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.23.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.11.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.18.intermediate.dense.bias', 'base_model.encoder.layer.23.intermediate.dense.weight', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'qa_outputs.weight', 'base_model.encoder.layer.6.intermediate.dense.weight', 'base_model.encoder.layer.14.attention.self.key.weight', 'base_model.encoder.layer.0.output.LayerNorm.weight', 'base_model.encoder.layer.9.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.19.attention.self.key.weight', 'base_model.encoder.layer.3.attention.output.LayerNorm.bias', 'base_model.encoder.layer.12.attention.output.dense.weight', 'base_model.encoder.layer.16.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.10.output.dense.weight', 'base_model.encoder.layer.19.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.1.output.LayerNorm.bias', 'base_model.encoder.layer.5.output.dense.weight', 'base_model.encoder.layer.10.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.16.intermediate.dense.bias', 'base_model.encoder.layer.22.attention.output.LayerNorm.bias', 'base_model.encoder.layer.23.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.0.intermediate.dense.weight', 'base_model.encoder.layer.16.attention.self.value.weight', 'base_model.encoder.layer.10.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.0.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.14.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.23.attention.output.dense.bias', 'base_model.encoder.layer.23.intermediate.dense.bias', 'base_model.encoder.layer.2.intermediate.dense.bias', 'base_model.encoder.layer.15.output.LayerNorm.bias', 'base_model.encoder.layer.15.attention.output.dense.weight', 'base_model.encoder.layer.1.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.20.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.10.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.21.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.5.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.6.attention.self.key.bias', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.11.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.17.output.dense.bias', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.19.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.8.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.8.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.8.intermediate.dense.weight', 'base_model.encoder.layer.7.attention.output.dense.weight', 'base_model.encoder.layer.10.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.1.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.23.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.23.output.dense.weight', 'base_model.encoder.layer.20.attention.output.LayerNorm.bias', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.13.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.19.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.9.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.2.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.1.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.7.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.11.attention.self.key.bias', 'base_model.encoder.layer.15.output.dense.bias', 'base_model.encoder.layer.12.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.13.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.16.attention.output.dense.weight', 'base_model.encoder.layer.3.output.dense.bias', 'base_model.encoder.layer.18.attention.self.value.weight', 'base_model.encoder.layer.12.attention.self.query.bias', 'base_model.encoder.layer.19.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.19.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.18.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.4.attention.output.dense.weight', 'base_model.encoder.layer.9.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.9.attention.self.key.weight', 'base_model.encoder.layer.2.output.dense.weight', 'base_model.encoder.layer.7.attention.self.query.bias', 'base_model.encoder.layer.8.output.LayerNorm.weight', 'base_model.encoder.layer.8.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.12.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.20.output.LayerNorm.weight', 'base_model.encoder.layer.2.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.3.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.18.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.11.output.LayerNorm.weight', 'base_model.encoder.layer.6.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.6.attention.self.query.weight', 'base_model.encoder.layer.12.attention.self.value.weight', 'base_model.encoder.layer.19.attention.output.dense.weight', 'base_model.encoder.layer.0.attention.output.dense.weight', 'base_model.encoder.layer.0.output.LayerNorm.bias', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.18.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.6.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.0.attention.self.query.weight', 'base_model.encoder.layer.19.attention.self.query.weight', 'base_model.encoder.layer.9.attention.self.value.bias', 'base_model.encoder.layer.10.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.23.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.4.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.9.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.1.attention.output.dense.weight', 'base_model.encoder.layer.0.attention.output.LayerNorm.weight', 'base_model.encoder.layer.8.attention.output.dense.bias', 'base_model.encoder.layer.12.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.6.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.1.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.23.attention.self.key.bias', 'base_model.encoder.layer.10.attention.self.value.bias', 'base_model.encoder.layer.20.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.18.attention.output.dense.bias', 'base_model.encoder.layer.1.attention.output.LayerNorm.bias', 'base_model.encoder.layer.9.attention.output.dense.bias', 'base_model.encoder.layer.19.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.17.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.11.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.17.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.11.attention.self.key.weight', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.7.attention.output.LayerNorm.weight', 'base_model.encoder.layer.9.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.11.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.11.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.16.output.dense.bias', 'base_model.encoder.layer.18.output.dense.weight', 'base_model.encoder.layer.23.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.19.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.21.attention.self.value.weight', 'base_model.encoder.layer.12.intermediate.dense.bias', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.9.output.LayerNorm.weight', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.3.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.13.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.1.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.20.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.5.attention.self.key.bias', 'base_model.encoder.layer.4.attention.self.value.bias', 'base_model.encoder.layer.13.attention.self.value.weight', 'base_model.encoder.layer.15.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.22.intermediate.dense.weight', 'base_model.encoder.layer.2.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.1.attention.self.value.bias', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.8.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.6.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.7.attention.self.value.bias', 'base_model.encoder.layer.14.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.7.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.4.attention.output.dense.bias', 'base_model.encoder.layer.15.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.2.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.5.attention.self.query.weight', 'base_model.encoder.layer.10.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.19.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.14.attention.self.value.weight', 'base_model.encoder.layer.15.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.18.attention.output.LayerNorm.bias', 'base_model.encoder.layer.22.attention.output.LayerNorm.weight', 'base_model.encoder.layer.19.attention.output.dense.bias', 'base_model.encoder.layer.1.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.13.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.0.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.9.intermediate.dense.bias', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.18.attention.self.value.bias', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.6.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.16.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.12.attention.self.key.bias', 'base_model.encoder.layer.21.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.16.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.13.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.7.intermediate.dense.weight', 'base_model.encoder.layer.15.output.adapters.ts.adapter_up.bias', 'base_model.embeddings.word_embeddings.weight', 'base_model.encoder.layer.19.output.LayerNorm.bias', 'base_model.encoder.layer.2.attention.output.dense.bias', 'base_model.encoder.layer.1.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.11.attention.output.dense.weight', 'base_model.encoder.layer.4.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.14.attention.output.LayerNorm.bias', 'base_model.encoder.layer.2.attention.self.query.bias', 'base_model.encoder.layer.21.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.18.output.LayerNorm.weight', 'base_model.encoder.layer.16.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.21.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.18.output.LayerNorm.bias', 'base_model.encoder.layer.5.attention.output.LayerNorm.bias', 'base_model.encoder.layer.2.output.LayerNorm.bias', 'base_model.encoder.layer.5.output.LayerNorm.bias', 'base_model.encoder.layer.22.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.6.attention.output.LayerNorm.bias', 'base_model.encoder.layer.9.attention.self.query.bias', 'base_model.encoder.layer.4.attention.self.key.bias', 'base_model.encoder.layer.18.attention.self.query.weight', 'base_model.encoder.layer.15.attention.self.value.bias', 'base_model.encoder.layer.19.attention.output.LayerNorm.bias', 'base_model.encoder.layer.21.attention.self.query.bias', 'base_model.encoder.layer.15.intermediate.dense.weight', 'base_model.encoder.layer.22.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.10.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.4.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.20.attention.self.key.bias', 'base_model.encoder.layer.23.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.23.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.9.output.dense.weight', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.8.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.20.intermediate.dense.weight', 'base_model.encoder.layer.23.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.10.attention.output.LayerNorm.weight', 'base_model.encoder.layer.19.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.20.attention.self.query.bias', 'base_model.encoder.layer.19.output.dense.weight', 'base_model.encoder.layer.3.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.3.attention.self.key.bias', 'base_model.encoder.layer.14.output.dense.bias', 'base_model.encoder.layer.7.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.12.attention.output.dense.bias', 'base_model.encoder.layer.3.attention.output.LayerNorm.weight', 'base_model.encoder.layer.7.output.dense.weight', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.1.attention.self.key.weight', 'base_model.encoder.layer.13.attention.output.LayerNorm.bias', 'base_model.encoder.layer.22.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.23.attention.self.value.bias', 'base_model.encoder.layer.14.intermediate.dense.weight', 'base_model.encoder.layer.17.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.17.attention.self.query.bias', 'base_model.encoder.layer.13.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.10.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.0.attention.self.key.bias', 'base_model.encoder.layer.3.attention.self.query.weight', 'base_model.encoder.layer.6.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.6.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.12.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.21.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.13.attention.output.dense.weight', 'base_model.encoder.layer.22.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.20.output.dense.bias', 'base_model.encoder.layer.12.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.20.intermediate.dense.bias', 'base_model.encoder.layer.19.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.14.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.19.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.1.intermediate.dense.bias', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.6.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.10.output.dense.bias', 'base_model.encoder.layer.16.attention.self.query.bias', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.16.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.7.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.18.intermediate.dense.weight', 'base_model.encoder.layer.17.attention.self.key.weight', 'base_model.encoder.layer.12.output.dense.bias', 'base_model.encoder.layer.16.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.3.output.LayerNorm.weight', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.19.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.0.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.1.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.11.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.16.intermediate.dense.weight', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.8.attention.self.value.bias', 'base_model.encoder.layer.15.intermediate.dense.bias', 'base_model.encoder.layer.8.attention.output.LayerNorm.weight', 'base_model.encoder.layer.8.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.23.attention.self.query.bias', 'base_model.encoder.layer.20.attention.self.value.bias', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.18.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.3.output.dense.weight', 'base_model.encoder.layer.11.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.5.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.6.attention.self.value.bias', 'base_model.encoder.layer.18.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.1.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.6.attention.self.key.weight', 'base_model.encoder.layer.14.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.15.attention.self.query.weight', 'base_model.encoder.layer.1.output.LayerNorm.weight', 'base_model.encoder.layer.21.attention.self.key.weight', 'base_model.encoder.layer.12.intermediate.dense.weight', 'base_model.encoder.layer.0.output.dense.bias', 'base_model.encoder.layer.3.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.13.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.17.attention.output.LayerNorm.bias', 'base_model.encoder.layer.3.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.6.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.5.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.14.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.14.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.9.attention.output.LayerNorm.weight', 'base_model.encoder.layer.9.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.14.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.3.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.15.attention.output.LayerNorm.bias', 'base_model.encoder.layer.17.attention.self.key.bias', 'base_model.encoder.layer.16.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.7.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.7.attention.self.query.weight', 'base_model.encoder.layer.20.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.7.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.6.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.21.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.10.intermediate.dense.bias', 'base_model.encoder.layer.22.attention.self.key.bias', 'base_model.encoder.layer.20.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.2.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.13.intermediate.dense.weight', 'base_model.encoder.layer.18.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.18.attention.output.dense.weight', 'base_model.encoder.layer.21.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.17.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.23.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.12.attention.output.LayerNorm.bias', 'base_model.encoder.layer.22.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.19.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.17.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.17.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.12.attention.self.key.weight', 'base_model.encoder.layer.18.attention.self.query.bias', 'base_model.encoder.layer.8.attention.self.query.bias', 'base_model.encoder.layer.9.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.1.output.dense.bias', 'base_model.encoder.layer.23.output.LayerNorm.weight', 'base_model.encoder.layer.19.output.dense.bias', 'base_model.encoder.layer.2.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.17.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.21.output.dense.weight', 'base_model.encoder.layer.17.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.17.attention.output.dense.weight', 'base_model.encoder.layer.15.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.13.intermediate.dense.bias', 'base_model.encoder.layer.10.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.1.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.18.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.11.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.0.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.12.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.15.output.LayerNorm.weight', 'base_model.encoder.layer.6.attention.output.dense.weight', 'base_model.encoder.layer.13.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.14.attention.self.key.bias', 'base_model.encoder.layer.18.attention.self.key.bias', 'base_model.encoder.layer.1.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.embeddings.LayerNorm.bias', 'base_model.encoder.layer.2.intermediate.dense.weight', 'base_model.encoder.layer.4.output.dense.weight', 'base_model.encoder.layer.14.output.LayerNorm.weight', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.18.output.dense.bias', 'base_model.encoder.layer.12.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.22.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.17.output.LayerNorm.bias', 'base_model.encoder.layer.16.attention.output.LayerNorm.weight', 'base_model.encoder.layer.2.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.11.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.14.attention.output.LayerNorm.weight', 'base_model.encoder.layer.15.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.10.intermediate.dense.weight', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.0.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.18.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.14.attention.output.dense.bias', 'base_model.encoder.layer.21.attention.output.LayerNorm.weight', 'base_model.encoder.layer.15.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.1.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.0.attention.output.LayerNorm.bias', 'base_model.encoder.layer.7.attention.self.key.bias', 'base_model.encoder.layer.16.output.LayerNorm.weight', 'base_model.encoder.layer.2.attention.self.key.bias', 'base_model.encoder.layer.7.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.11.attention.self.query.bias', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.0.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.6.attention.output.dense.bias', 'base_model.encoder.layer.4.output.LayerNorm.bias', 'base_model.encoder.layer.5.attention.self.value.weight', 'base_model.encoder.layer.2.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.3.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.3.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.17.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.7.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.15.output.dense.weight', 'base_model.encoder.layer.15.attention.self.key.weight', 'base_model.encoder.layer.12.attention.self.value.bias', 'base_model.encoder.layer.8.output.dense.bias', 'base_model.embeddings.position_embeddings.weight', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.embeddings.token_type_embeddings.weight', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.14.attention.self.query.bias', 'base_model.encoder.layer.6.output.LayerNorm.bias', 'base_model.encoder.layer.21.output.adapters.tp.adapter_up.bias', 'base_model.pooler.dense.weight', 'base_model.encoder.layer.5.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.6.output.dense.bias', 'base_model.embeddings.position_ids', 'base_model.encoder.layer.11.attention.self.value.weight', 'base_model.encoder.layer.13.attention.self.key.weight', 'base_model.encoder.layer.14.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.7.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.8.attention.output.LayerNorm.bias', 'base_model.encoder.layer.7.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.20.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.11.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.17.intermediate.dense.weight', 'base_model.encoder.layer.13.output.dense.bias', 'base_model.encoder.layer.16.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.9.output.LayerNorm.bias', 'base_model.encoder.layer.9.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.10.attention.output.dense.weight', 'qa_outputs.bias', 'base_model.encoder.layer.0.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.4.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.7.attention.output.LayerNorm.bias', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.4.intermediate.dense.weight', 'base_model.embeddings.LayerNorm.weight', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.21.attention.self.value.bias', 'base_model.encoder.layer.7.output.LayerNorm.weight', 'base_model.encoder.layer.15.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.22.attention.self.value.weight', 'base_model.encoder.layer.21.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.4.output.dense.bias', 'base_model.encoder.layer.20.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.14.attention.self.query.weight', 'base_model.encoder.layer.22.intermediate.dense.bias', 'base_model.encoder.layer.9.output.dense.bias', 'base_model.encoder.layer.2.attention.self.value.weight', 'base_model.encoder.layer.2.output.dense.bias', 'base_model.encoder.layer.8.intermediate.dense.bias', 'base_model.encoder.layer.15.attention.self.query.bias', 'base_model.encoder.layer.15.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.22.output.LayerNorm.bias', 'base_model.encoder.layer.6.intermediate.dense.bias', 'base_model.encoder.layer.0.attention.self.query.bias', 'base_model.encoder.layer.1.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.2.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.23.output.LayerNorm.bias', 'base_model.encoder.layer.3.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.7.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.8.attention.self.query.weight', 'base_model.encoder.layer.7.intermediate.dense.bias', 'base_model.encoder.layer.5.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.9.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.13.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.20.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.14.attention.output.dense.weight', 'base_model.encoder.layer.9.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.8.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.2.attention.output.LayerNorm.weight', 'base_model.encoder.layer.11.attention.output.dense.bias', 'base_model.encoder.layer.17.attention.self.value.weight', 'base_model.pooler.dense.bias', 'base_model.encoder.layer.7.attention.self.value.weight', 'base_model.encoder.layer.21.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.14.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.17.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.3.intermediate.dense.weight', 'base_model.encoder.layer.7.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.9.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.2.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.5.attention.self.value.bias', 'base_model.encoder.layer.10.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.4.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.6.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.5.attention.self.query.bias', 'base_model.encoder.layer.3.attention.self.value.weight', 'base_model.encoder.layer.12.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.23.output.dense.bias', 'base_model.encoder.layer.1.attention.self.key.bias', 'base_model.encoder.layer.23.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.0.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.5.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.21.attention.output.dense.bias', 'base_model.encoder.layer.4.attention.self.value.weight', 'base_model.encoder.layer.4.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.21.attention.self.key.bias', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.8.attention.output.dense.weight', 'base_model.encoder.layer.1.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.22.attention.self.query.weight', 'base_model.encoder.layer.2.attention.self.value.bias', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.11.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.17.intermediate.dense.bias', 'base_model.encoder.layer.9.attention.output.LayerNorm.bias', 'base_model.encoder.layer.22.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.8.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.1.attention.self.query.weight', 'base_model.encoder.layer.14.output.dense.weight', 'base_model.encoder.layer.11.intermediate.dense.bias', 'base_model.encoder.layer.18.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.19.attention.self.value.weight', 'base_model.encoder.layer.4.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.8.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.12.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.5.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.18.attention.self.key.weight', 'base_model.encoder.layer.22.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.3.attention.output.dense.bias', 'base_model.encoder.layer.22.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.0.attention.self.key.weight', 'base_model.encoder.layer.0.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.9.intermediate.dense.weight', 'base_model.encoder.layer.21.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.9.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.15.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.16.attention.self.key.weight', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.4.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.5.attention.self.key.weight', 'base_model.encoder.layer.10.attention.output.dense.bias', 'base_model.encoder.layer.20.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.11.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.0.output.dense.weight', 'base_model.encoder.layer.21.intermediate.dense.bias', 'base_model.encoder.layer.19.output.LayerNorm.weight', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.6.output.LayerNorm.weight', 'base_model.encoder.layer.23.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.16.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.12.attention.self.query.weight', 'base_model.encoder.layer.11.intermediate.dense.weight', 'base_model.encoder.layer.18.attention.output.LayerNorm.weight', 'base_model.encoder.layer.7.output.dense.bias', 'base_model.encoder.layer.23.attention.output.LayerNorm.bias', 'base_model.encoder.layer.0.intermediate.dense.bias', 'base_model.encoder.layer.13.attention.self.key.bias', 'base_model.encoder.layer.20.attention.output.dense.weight', 'base_model.encoder.layer.4.output.LayerNorm.weight', 'base_model.encoder.layer.5.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.23.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.5.attention.output.dense.bias', 'base_model.encoder.layer.3.attention.self.query.bias', 'base_model.encoder.layer.4.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.12.output.LayerNorm.bias', 'base_model.encoder.layer.16.attention.self.key.bias', 'base_model.encoder.layer.3.attention.output.dense.weight', 'base_model.encoder.layer.0.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.8.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.13.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.8.output.dense.weight', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.14.intermediate.dense.bias', 'base_model.encoder.layer.10.output.LayerNorm.weight', 'base_model.encoder.layer.23.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.13.attention.self.query.bias', 'base_model.encoder.layer.1.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.9.attention.self.query.weight', 'base_model.encoder.layer.10.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.21.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.17.output.dense.weight', 'base_model.encoder.layer.6.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.15.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.3.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.8.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.13.attention.output.dense.bias', 'base_model.encoder.layer.5.output.LayerNorm.weight', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.13.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.6.attention.self.value.weight', 'base_model.encoder.layer.4.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.17.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.2.output.LayerNorm.weight', 'base_model.encoder.layer.19.attention.self.key.bias', 'base_model.encoder.layer.9.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.10.output.LayerNorm.bias', 'base_model.encoder.layer.13.attention.self.value.bias', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.10.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.23.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.3.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.3.intermediate.dense.bias', 'base_model.encoder.layer.19.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.15.attention.output.LayerNorm.weight', 'base_model.encoder.layer.4.attention.output.LayerNorm.bias', 'base_model.encoder.layer.8.attention.self.key.bias', 'base_model.encoder.layer.16.output.LayerNorm.bias', 'base_model.encoder.layer.5.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.2.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.8.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.3.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.15.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.13.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.12.attention.output.LayerNorm.weight', 'base_model.encoder.layer.7.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.19.attention.self.value.bias', 'base_model.encoder.layer.4.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.1.attention.output.LayerNorm.weight', 'base_model.encoder.layer.15.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.20.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.5.output.dense.bias', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.9.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.10.attention.self.query.bias', 'base_model.encoder.layer.12.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.13.output.dense.weight', 'base_model.encoder.layer.2.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.15.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.22.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.22.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.17.attention.self.value.bias', 'base_model.encoder.layer.2.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.2.attention.self.query.weight', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.2.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.3.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.23.attention.self.value.weight', 'base_model.encoder.layer.1.intermediate.dense.weight', 'base_model.encoder.layer.16.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.7.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.14.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.18.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.21.attention.output.dense.weight', 'base_model.encoder.layer.1.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.7.attention.output.dense.bias', 'base_model.encoder.layer.8.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.12.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.5.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.2.attention.output.LayerNorm.bias', 'base_model.encoder.layer.13.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.0.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.8.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.3.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.6.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.21.output.LayerNorm.weight', 'base_model.encoder.layer.15.attention.self.value.weight', 'base_model.encoder.layer.0.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.0.attention.output.dense.bias', 'base_model.encoder.layer.20.attention.output.LayerNorm.weight', 'base_model.encoder.layer.2.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.20.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.21.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.17.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.10.attention.output.LayerNorm.bias', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.19.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.9.attention.output.dense.weight', 'base_model.encoder.layer.20.output.dense.weight', 'base_model.encoder.layer.5.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.16.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.10.attention.self.key.bias', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.10.attention.self.value.weight', 'base_model.encoder.layer.11.output.LayerNorm.bias', 'base_model.encoder.layer.23.attention.self.key.weight', 'base_model.encoder.layer.20.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.7.attention.self.key.weight', 'base_model.encoder.layer.1.attention.self.query.bias', 'base_model.encoder.layer.16.attention.output.dense.bias', 'base_model.encoder.layer.1.output.dense.weight', 'base_model.encoder.layer.22.output.dense.weight', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.3.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.17.output.LayerNorm.weight', 'base_model.encoder.layer.20.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.13.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.2.attention.output.dense.weight', 'base_model.encoder.layer.21.output.LayerNorm.bias', 'base_model.encoder.layer.14.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.23.attention.self.query.weight', 'base_model.encoder.layer.22.attention.output.dense.weight', 'base_model.encoder.layer.21.intermediate.dense.weight', 'base_model.encoder.layer.2.attention.self.key.weight', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.16.attention.self.query.weight', 'base_model.encoder.layer.20.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.1.attention.self.value.weight', 'base_model.encoder.layer.21.attention.self.query.weight', 'base_model.encoder.layer.17.attention.self.query.weight', 'base_model.encoder.layer.17.attention.output.LayerNorm.weight', 'base_model.encoder.layer.19.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.9.attention.self.value.weight', 'base_model.encoder.layer.4.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.18.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.2.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.4.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.6.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.5.intermediate.dense.bias', 'base_model.encoder.layer.15.attention.output.dense.bias', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.7.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.20.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.23.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.5.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.17.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.19.intermediate.dense.weight', 'base_model.encoder.layer.21.output.dense.bias', 'base_model.encoder.layer.1.attention.output.dense.bias', 'base_model.encoder.layer.0.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.11.attention.self.query.weight', 'base_model.encoder.layer.12.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.4.attention.self.query.weight', 'base_model.encoder.layer.3.output.LayerNorm.bias', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.11.attention.output.LayerNorm.weight', 'base_model.encoder.layer.4.attention.output.LayerNorm.weight', 'base_model.encoder.layer.13.output.LayerNorm.weight', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.15.attention.self.key.bias', 'base_model.encoder.layer.10.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.0.attention.self.value.weight', 'base_model.encoder.layer.4.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.16.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.21.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.22.output.LayerNorm.weight', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.10.attention.self.key.weight', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.18.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.17.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.22.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.8.attention.self.value.weight', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.8.attention.self.key.weight', 'base_model.encoder.layer.18.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.4.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.5.attention.output.LayerNorm.weight', 'base_model.encoder.layer.14.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.20.output.LayerNorm.bias', 'base_model.encoder.layer.11.attention.self.value.bias', 'base_model.encoder.layer.14.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.20.attention.self.key.weight', 'base_model.encoder.layer.3.attention.self.key.weight', 'base_model.encoder.layer.23.attention.output.dense.weight', 'base_model.encoder.layer.7.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.8.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.12.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.14.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.9.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.16.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.11.attention.output.LayerNorm.bias', 'base_model.encoder.layer.20.attention.output.dense.bias', 'base_model.encoder.layer.3.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.9.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.22.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.16.attention.output.LayerNorm.bias', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.22.attention.self.value.bias', 'base_model.encoder.layer.20.attention.self.value.weight', 'base_model.encoder.layer.4.intermediate.dense.bias', 'base_model.encoder.layer.11.output.dense.bias', 'base_model.encoder.layer.17.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.18.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.11.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.19.attention.self.query.bias', 'base_model.encoder.layer.22.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.0.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.4.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.0.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.9.attention.self.key.bias', 'base_model.encoder.layer.4.attention.self.query.bias', 'base_model.encoder.layer.16.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.22.attention.self.query.bias', 'base_model.encoder.layer.12.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.20.attention.self.query.weight', 'base_model.encoder.layer.6.attention.self.query.bias', 'base_model.encoder.layer.5.attention.output.dense.weight', 'base_model.encoder.layer.8.output.LayerNorm.bias', 'base_model.encoder.layer.11.output.dense.weight', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.17.attention.output.dense.bias', 'base_model.encoder.layer.5.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.13.attention.self.query.weight', 'base_model.encoder.layer.0.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.14.output.LayerNorm.bias', 'base_model.encoder.layer.16.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.21.attention.output.LayerNorm.bias', 'base_model.encoder.layer.18.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.6.attention.output.LayerNorm.weight', 'base_model.encoder.layer.6.output.dense.weight', 'base_model.encoder.layer.22.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.7.output.LayerNorm.bias', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.17.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.22.attention.self.key.weight', 'base_model.encoder.layer.12.output.LayerNorm.weight', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.13.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.14.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.12.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.10.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.22.output.dense.bias', 'base_model.encoder.layer.23.attention.output.LayerNorm.weight', 'base_model.encoder.layer.14.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.22.attention.output.dense.bias', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.0.attention.self.value.bias', 'base_model.encoder.layer.14.attention.self.value.bias', 'base_model.encoder.layer.13.output.LayerNorm.bias', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.11.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.15.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.16.attention.self.value.bias', 'base_model.encoder.layer.15.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.19.attention.output.LayerNorm.weight', 'base_model.encoder.layer.5.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.6.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.10.attention.self.query.weight', 'base_model.encoder.layer.18.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.21.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.22.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.11.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.10.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.8.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.19.intermediate.dense.bias', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.5.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.11.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.5.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.5.intermediate.dense.weight', 'base_model.encoder.layer.3.attention.self.value.bias', 'base_model.encoder.layer.12.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.21.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.4.attention.self.key.weight', 'base_model.encoder.layer.16.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.6.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.13.attention.output.LayerNorm.weight']
- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of XLMRobertaModel were not initialized from the model checkpoint at /cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//tydiqa/xlm-KG_LR8e-6_EPOCH2.0_maxlen384_batchsize4_gradacc4 and are newly initialized: ['encoder.layer.18.output.dense.weight', 'encoder.layer.7.attention.self.value.bias', 'encoder.layer.2.attention.self.query.bias', 'encoder.layer.18.attention.self.value.bias', 'encoder.layer.8.attention.output.LayerNorm.bias', 'encoder.layer.20.intermediate.dense.weight', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.11.attention.self.key.weight', 'encoder.layer.18.output.LayerNorm.weight', 'encoder.layer.7.attention.self.query.bias', 'encoder.layer.9.attention.self.key.weight', 'encoder.layer.10.attention.self.value.weight', 'encoder.layer.1.attention.self.value.bias', 'encoder.layer.14.attention.output.LayerNorm.bias', 'encoder.layer.19.intermediate.dense.bias', 'encoder.layer.14.output.LayerNorm.weight', 'encoder.layer.15.output.LayerNorm.bias', 'encoder.layer.16.output.LayerNorm.bias', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.4.attention.self.query.bias', 'pooler.dense.weight', 'encoder.layer.13.attention.output.LayerNorm.weight', 'encoder.layer.1.attention.self.key.bias', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.8.attention.output.LayerNorm.weight', 'encoder.layer.23.attention.output.LayerNorm.bias', 'embeddings.token_type_embeddings.weight', 'encoder.layer.21.attention.output.LayerNorm.bias', 'encoder.layer.17.attention.output.dense.weight', 'encoder.layer.11.attention.self.query.bias', 'encoder.layer.11.output.LayerNorm.weight', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.3.attention.self.query.bias', 'encoder.layer.0.attention.self.value.weight', 'encoder.layer.22.attention.output.LayerNorm.weight', 'encoder.layer.0.attention.output.dense.weight', 'encoder.layer.18.output.LayerNorm.bias', 'encoder.layer.13.attention.self.query.weight', 'encoder.layer.10.attention.output.dense.bias', 'encoder.layer.3.attention.self.key.bias', 'encoder.layer.9.attention.self.value.weight', 'encoder.layer.7.output.LayerNorm.bias', 'encoder.layer.19.attention.self.key.bias', 'encoder.layer.1.attention.output.LayerNorm.weight', 'embeddings.LayerNorm.weight', 'encoder.layer.3.output.dense.weight', 'encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.layer.14.attention.self.value.weight', 'encoder.layer.19.attention.self.value.bias', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.1.attention.self.key.weight', 'encoder.layer.9.attention.output.dense.bias', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.22.attention.self.value.bias', 'encoder.layer.12.attention.self.key.weight', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.layer.21.output.LayerNorm.weight', 'encoder.layer.6.attention.output.LayerNorm.bias', 'encoder.layer.23.output.dense.bias', 'encoder.layer.1.output.dense.weight', 'encoder.layer.15.attention.self.key.bias', 'encoder.layer.20.attention.self.query.bias', 'encoder.layer.6.output.dense.bias', 'encoder.layer.10.attention.self.key.weight', 'encoder.layer.20.attention.self.value.bias', 'encoder.layer.20.output.LayerNorm.weight', 'encoder.layer.12.output.LayerNorm.bias', 'encoder.layer.4.attention.self.value.weight', 'encoder.layer.22.attention.self.key.weight', 'encoder.layer.14.output.dense.bias', 'encoder.layer.3.attention.output.dense.bias', 'encoder.layer.17.output.dense.bias', 'encoder.layer.23.output.LayerNorm.weight', 'encoder.layer.5.attention.self.query.bias', 'encoder.layer.20.attention.self.key.bias', 'encoder.layer.7.attention.self.key.weight', 'encoder.layer.4.attention.output.dense.weight', 'encoder.layer.7.attention.self.value.weight', 'encoder.layer.16.attention.output.dense.bias', 'encoder.layer.22.attention.self.key.bias', 'encoder.layer.2.attention.output.dense.bias', 'encoder.layer.5.attention.self.value.bias', 'encoder.layer.16.attention.self.key.bias', 'encoder.layer.12.attention.output.dense.weight', 'encoder.layer.1.attention.self.query.bias', 'encoder.layer.16.output.dense.weight', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.9.output.dense.bias', 'encoder.layer.3.attention.self.key.weight', 'encoder.layer.19.attention.self.value.weight', 'encoder.layer.12.attention.output.dense.bias', 'encoder.layer.13.intermediate.dense.weight', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.14.intermediate.dense.weight', 'encoder.layer.20.attention.self.key.weight', 'encoder.layer.15.attention.self.query.bias', 'encoder.layer.0.attention.output.dense.bias', 'encoder.layer.21.output.dense.weight', 'encoder.layer.8.attention.self.key.weight', 'encoder.layer.19.attention.output.dense.weight', 'encoder.layer.18.attention.output.LayerNorm.bias', 'encoder.layer.10.attention.self.query.bias', 'pooler.dense.bias', 'encoder.layer.23.attention.output.dense.bias', 'encoder.layer.18.attention.self.query.weight', 'encoder.layer.0.attention.self.query.bias', 'encoder.layer.12.attention.output.LayerNorm.weight', 'encoder.layer.17.intermediate.dense.bias', 'encoder.layer.0.attention.self.value.bias', 'encoder.layer.15.output.dense.weight', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.10.attention.self.value.bias', 'encoder.layer.18.intermediate.dense.bias', 'encoder.layer.15.attention.self.value.bias', 'encoder.layer.16.attention.output.dense.weight', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.19.attention.output.LayerNorm.bias', 'encoder.layer.16.intermediate.dense.bias', 'encoder.layer.18.attention.output.dense.bias', 'encoder.layer.15.attention.output.dense.weight', 'encoder.layer.4.attention.self.value.bias', 'encoder.layer.12.attention.self.query.weight', 'encoder.layer.19.attention.output.LayerNorm.weight', 'encoder.layer.0.output.dense.bias', 'encoder.layer.15.intermediate.dense.weight', 'encoder.layer.6.attention.self.key.weight', 'encoder.layer.11.attention.output.dense.bias', 'encoder.layer.10.attention.output.LayerNorm.weight', 'encoder.layer.13.output.LayerNorm.weight', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.20.intermediate.dense.bias', 'encoder.layer.21.output.dense.bias', 'encoder.layer.7.attention.output.dense.bias', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.16.attention.output.LayerNorm.bias', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.19.output.dense.bias', 'embeddings.word_embeddings.weight', 'encoder.layer.18.output.dense.bias', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.17.attention.self.query.weight', 'encoder.layer.23.intermediate.dense.bias', 'encoder.layer.10.output.dense.bias', 'encoder.layer.13.attention.output.dense.weight', 'encoder.layer.22.output.LayerNorm.weight', 'encoder.layer.17.attention.output.LayerNorm.weight', 'encoder.layer.15.attention.output.dense.bias', 'encoder.layer.4.attention.self.key.weight', 'encoder.layer.22.attention.self.query.bias', 'encoder.layer.16.attention.output.LayerNorm.weight', 'encoder.layer.9.output.dense.weight', 'encoder.layer.8.attention.output.dense.bias', 'encoder.layer.1.attention.self.query.weight', 'encoder.layer.6.attention.self.key.bias', 'encoder.layer.5.attention.self.key.bias', 'encoder.layer.16.intermediate.dense.weight', 'encoder.layer.11.output.dense.bias', 'encoder.layer.1.output.dense.bias', 'encoder.layer.17.attention.output.LayerNorm.bias', 'encoder.layer.4.attention.self.key.bias', 'encoder.layer.14.attention.self.query.bias', 'encoder.layer.16.attention.self.key.weight', 'encoder.layer.7.output.dense.bias', 'encoder.layer.7.attention.output.dense.weight', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.15.attention.self.query.weight', 'encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.layer.3.attention.self.value.weight', 'encoder.layer.13.output.dense.weight', 'encoder.layer.22.intermediate.dense.weight', 'encoder.layer.5.attention.output.dense.weight', 'encoder.layer.17.attention.self.query.bias', 'encoder.layer.19.attention.self.key.weight', 'encoder.layer.0.attention.self.query.weight', 'encoder.layer.6.attention.output.LayerNorm.weight', 'encoder.layer.5.attention.output.LayerNorm.weight', 'encoder.layer.16.output.LayerNorm.weight', 'encoder.layer.9.attention.output.dense.weight', 'encoder.layer.5.attention.output.dense.bias', 'encoder.layer.0.output.dense.weight', 'encoder.layer.6.attention.self.value.weight', 'encoder.layer.2.attention.self.value.bias', 'encoder.layer.5.attention.self.key.weight', 'encoder.layer.1.attention.output.dense.weight', 'encoder.layer.13.attention.self.key.weight', 'encoder.layer.21.attention.output.LayerNorm.weight', 'encoder.layer.17.attention.self.key.bias', 'encoder.layer.19.output.LayerNorm.weight', 'encoder.layer.20.attention.self.query.weight', 'encoder.layer.15.attention.self.value.weight', 'encoder.layer.17.output.LayerNorm.weight', 'encoder.layer.19.output.LayerNorm.bias', 'encoder.layer.21.intermediate.dense.weight', 'encoder.layer.8.attention.self.key.bias', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.23.output.dense.weight', 'encoder.layer.4.output.dense.weight', 'encoder.layer.17.output.dense.weight', 'encoder.layer.22.attention.output.dense.weight', 'encoder.layer.10.attention.self.key.bias', 'encoder.layer.11.output.LayerNorm.bias', 'encoder.layer.22.intermediate.dense.bias', 'encoder.layer.13.attention.self.value.bias', 'encoder.layer.17.intermediate.dense.weight', 'encoder.layer.11.attention.output.LayerNorm.weight', 'encoder.layer.12.attention.self.key.bias', 'encoder.layer.4.output.dense.bias', 'encoder.layer.11.attention.output.dense.weight', 'encoder.layer.1.attention.output.dense.bias', 'encoder.layer.13.attention.output.LayerNorm.bias', 'encoder.layer.14.attention.output.dense.bias', 'encoder.layer.23.attention.self.key.bias', 'encoder.layer.2.output.dense.weight', 'encoder.layer.14.attention.self.key.bias', 'encoder.layer.19.attention.self.query.bias', 'encoder.layer.12.output.dense.bias', 'encoder.layer.2.output.dense.bias', 'encoder.layer.10.output.dense.weight', 'encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.layer.8.output.LayerNorm.bias', 'encoder.layer.4.attention.output.dense.bias', 'encoder.layer.23.attention.self.key.weight', 'encoder.layer.2.attention.output.LayerNorm.bias', 'encoder.layer.13.output.dense.bias', 'encoder.layer.20.output.dense.bias', 'encoder.layer.21.output.LayerNorm.bias', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.7.attention.self.key.bias', 'encoder.layer.1.attention.self.value.weight', 'encoder.layer.14.attention.output.dense.weight', 'encoder.layer.18.attention.self.key.weight', 'encoder.layer.8.output.dense.bias', 'encoder.layer.10.attention.output.LayerNorm.bias', 'encoder.layer.8.attention.output.dense.weight', 'encoder.layer.8.output.LayerNorm.weight', 'encoder.layer.13.intermediate.dense.bias', 'encoder.layer.2.attention.self.key.weight', 'encoder.layer.7.attention.self.query.weight', 'encoder.layer.15.output.dense.bias', 'encoder.layer.7.output.LayerNorm.weight', 'encoder.layer.3.output.dense.bias', 'encoder.layer.17.output.LayerNorm.bias', 'encoder.layer.12.attention.output.LayerNorm.bias', 'encoder.layer.11.attention.self.value.weight', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.12.attention.self.value.weight', 'encoder.layer.16.output.dense.bias', 'encoder.layer.22.attention.output.dense.bias', 'encoder.layer.17.attention.self.value.bias', 'encoder.layer.20.output.LayerNorm.bias', 'encoder.layer.23.attention.self.query.bias', 'encoder.layer.6.output.dense.weight', 'encoder.layer.23.attention.output.LayerNorm.weight', 'encoder.layer.6.output.LayerNorm.bias', 'encoder.layer.10.output.LayerNorm.bias', 'encoder.layer.15.attention.self.key.weight', 'encoder.layer.17.attention.self.value.weight', 'encoder.layer.12.output.dense.weight', 'encoder.layer.12.intermediate.dense.bias', 'encoder.layer.18.attention.output.dense.weight', 'encoder.layer.11.attention.self.key.bias', 'encoder.layer.7.attention.output.LayerNorm.bias', 'encoder.layer.4.attention.self.query.weight', 'embeddings.LayerNorm.bias', 'encoder.layer.9.attention.self.value.bias', 'encoder.layer.18.attention.self.value.weight', 'encoder.layer.14.attention.self.query.weight', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.4.attention.output.LayerNorm.weight', 'encoder.layer.19.attention.self.query.weight', 'encoder.layer.6.attention.self.value.bias', 'encoder.layer.8.attention.self.value.bias', 'encoder.layer.15.output.LayerNorm.weight', 'encoder.layer.23.attention.self.query.weight', 'encoder.layer.8.attention.self.value.weight', 'encoder.layer.14.attention.output.LayerNorm.weight', 'encoder.layer.23.intermediate.dense.weight', 'encoder.layer.10.attention.self.query.weight', 'encoder.layer.15.intermediate.dense.bias', 'encoder.layer.5.output.LayerNorm.bias', 'encoder.layer.13.attention.self.key.bias', 'encoder.layer.14.attention.self.key.weight', 'encoder.layer.6.attention.output.dense.bias', 'encoder.layer.7.intermediate.dense.bias', 'encoder.layer.23.output.LayerNorm.bias', 'encoder.layer.2.attention.self.key.bias', 'encoder.layer.20.attention.output.dense.bias', 'encoder.layer.21.intermediate.dense.bias', 'encoder.layer.6.attention.self.query.weight', 'encoder.layer.19.attention.output.dense.bias', 'encoder.layer.9.attention.self.query.weight', 'encoder.layer.21.attention.self.query.weight', 'encoder.layer.0.attention.self.key.bias', 'encoder.layer.18.attention.self.key.bias', 'encoder.layer.13.output.LayerNorm.bias', 'encoder.layer.14.intermediate.dense.bias', 'encoder.layer.12.attention.self.value.bias', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.8.attention.self.query.bias', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.20.attention.output.LayerNorm.weight', 'encoder.layer.10.output.LayerNorm.weight', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.22.attention.self.value.weight', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.3.attention.self.value.bias', 'encoder.layer.18.intermediate.dense.weight', 'encoder.layer.9.attention.self.query.bias', 'encoder.layer.6.attention.self.query.bias', 'encoder.layer.9.attention.output.LayerNorm.bias', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.18.attention.self.query.bias', 'encoder.layer.14.output.LayerNorm.bias', 'encoder.layer.2.attention.output.LayerNorm.weight', 'encoder.layer.13.attention.self.query.bias', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.9.output.LayerNorm.bias', 'encoder.layer.14.output.dense.weight', 'encoder.layer.13.attention.self.value.weight', 'encoder.layer.12.intermediate.dense.weight', 'encoder.layer.21.attention.output.dense.bias', 'encoder.layer.21.attention.self.key.weight', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.9.intermediate.dense.weight', 'embeddings.position_embeddings.weight', 'encoder.layer.7.output.dense.weight', 'encoder.layer.22.output.LayerNorm.bias', 'encoder.layer.5.attention.self.value.weight', 'encoder.layer.6.attention.output.dense.weight', 'encoder.layer.2.attention.self.value.weight', 'encoder.layer.21.attention.self.key.bias', 'encoder.layer.8.output.dense.weight', 'encoder.layer.20.attention.output.dense.weight', 'encoder.layer.21.attention.self.value.weight', 'encoder.layer.8.attention.self.query.weight', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.23.attention.self.value.bias', 'encoder.layer.4.attention.output.LayerNorm.bias', 'encoder.layer.20.attention.self.value.weight', 'encoder.layer.23.attention.self.value.weight', 'encoder.layer.9.attention.self.key.bias', 'encoder.layer.2.attention.self.query.weight', 'encoder.layer.10.intermediate.dense.weight', 'encoder.layer.5.output.dense.bias', 'encoder.layer.19.output.dense.weight', 'encoder.layer.10.attention.output.dense.weight', 'encoder.layer.3.attention.output.dense.weight', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.22.attention.output.LayerNorm.bias', 'encoder.layer.20.output.dense.weight', 'encoder.layer.5.output.dense.weight', 'encoder.layer.13.attention.output.dense.bias', 'encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.layer.0.attention.self.key.weight', 'encoder.layer.22.output.dense.weight', 'encoder.layer.21.attention.output.dense.weight', 'encoder.layer.2.attention.output.dense.weight', 'encoder.layer.9.output.LayerNorm.weight', 'encoder.layer.3.attention.self.query.weight', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.12.attention.self.query.bias', 'encoder.layer.9.attention.output.LayerNorm.weight', 'encoder.layer.16.attention.self.value.bias', 'encoder.layer.12.output.LayerNorm.weight', 'encoder.layer.5.attention.self.query.weight', 'encoder.layer.11.attention.self.query.weight', 'encoder.layer.16.attention.self.query.weight', 'encoder.layer.16.attention.self.value.weight', 'encoder.layer.15.attention.output.LayerNorm.bias', 'encoder.layer.19.intermediate.dense.weight', 'encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.layer.16.attention.self.query.bias', 'encoder.layer.23.attention.output.dense.weight', 'encoder.layer.20.attention.output.LayerNorm.bias', 'encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.17.attention.output.dense.bias', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.17.attention.self.key.weight', 'encoder.layer.22.output.dense.bias', 'encoder.layer.14.attention.self.value.bias', 'encoder.layer.18.attention.output.LayerNorm.weight', 'encoder.layer.7.attention.output.LayerNorm.weight', 'encoder.layer.11.attention.self.value.bias', 'encoder.layer.11.output.dense.weight', 'encoder.layer.21.attention.self.value.bias', 'encoder.layer.22.attention.self.query.weight', 'encoder.layer.15.attention.output.LayerNorm.weight', 'encoder.layer.0.attention.output.LayerNorm.weight', 'encoder.layer.21.attention.self.query.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Overwriting existing adapter 'ep'.
Overwriting existing adapter 'tp'.
Overwriting existing adapter 'es'.
Overwriting existing adapter 'ts'.
Overwriting existing adapter fusion module 'ep,tp,es,ts'
05/09/2022 22:58:21 - INFO - __main__ -   Creating features from dataset file at .
/cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//tydiqa/xlm-KG_LR8e-6_EPOCH2.0_maxlen384_batchsize4_gradacc4
XLMConfig {
  "architectures": [
    "XLMRobertaForMaskedLM"
  ],
  "asm": false,
  "attention_dropout": 0.1,
  "attention_probs_dropout_prob": 0.1,
  "bos_index": 0,
  "bos_token_id": 0,
  "causal": false,
  "dropout": 0.1,
  "emb_dim": 1024,
  "embed_init_std": 0.02209708691207961,
  "end_n_top": 5,
  "eos_index": 1,
  "eos_token_id": 2,
  "gelu_activation": true,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "init_std": 0.02,
  "initializer_range": 0.02,
  "intermediate_size": 4096,
  "is_encoder": true,
  "lang_id": 0,
  "layer_norm_eps": 1e-05,
  "mask_index": 5,
  "mask_token_id": 0,
  "max_position_embeddings": 514,
  "model_type": "xlm",
  "n_heads": 16,
  "n_langs": 1,
  "n_layers": 24,
  "output_past": true,
  "pad_index": 2,
  "pad_token_id": 1,
  "sinusoidal_embeddings": false,
  "start_n_top": 5,
  "summary_activation": null,
  "summary_first_dropout": 0.1,
  "summary_proj_to_labels": true,
  "summary_type": "first",
  "summary_use_proj": true,
  "transformers_version": "4.17.0",
  "type_vocab_size": 1,
  "unk_index": 3,
  "use_lang_emb": false,
  "vocab_size": 250002
}

  0%|          | 0/812 [00:00<?, ?it/s] 49%|████▊     | 395/812 [00:00<00:00, 3939.87it/s]100%|██████████| 812/812 [00:00<00:00, 4277.16it/s]
convert squad examples to features:   0%|          | 0/812 [00:00<?, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.
convert squad examples to features:   0%|          | 1/812 [00:00<02:01,  6.68it/s]convert squad examples to features:   8%|▊         | 65/812 [00:00<00:03, 248.40it/s]convert squad examples to features:  16%|█▌        | 129/812 [00:00<00:02, 274.43it/s]convert squad examples to features:  20%|█▉        | 161/812 [00:00<00:02, 266.42it/s]convert squad examples to features:  24%|██▍       | 193/812 [00:00<00:02, 227.20it/s]convert squad examples to features:  28%|██▊       | 225/812 [00:00<00:02, 232.04it/s]convert squad examples to features:  36%|███▌      | 289/812 [00:01<00:01, 280.73it/s]convert squad examples to features:  40%|███▉      | 321/812 [00:01<00:01, 281.09it/s]convert squad examples to features:  43%|████▎     | 353/812 [00:01<00:01, 255.91it/s]convert squad examples to features:  51%|█████▏    | 417/812 [00:01<00:01, 282.06it/s]convert squad examples to features:  55%|█████▌    | 449/812 [00:01<00:01, 288.75it/s]convert squad examples to features:  59%|█████▉    | 481/812 [00:01<00:01, 284.23it/s]convert squad examples to features:  63%|██████▎   | 513/812 [00:01<00:01, 260.63it/s]convert squad examples to features:  67%|██████▋   | 545/812 [00:02<00:00, 270.33it/s]convert squad examples to features:  71%|███████   | 577/812 [00:02<00:00, 280.06it/s]convert squad examples to features:  75%|███████▌  | 609/812 [00:02<00:00, 287.83it/s]convert squad examples to features:  83%|████████▎ | 673/812 [00:02<00:00, 310.79it/s]convert squad examples to features:  87%|████████▋ | 705/812 [00:02<00:00, 312.96it/s]convert squad examples to features:  95%|█████████▍| 769/812 [00:02<00:00, 342.62it/s]convert squad examples to features: 100%|██████████| 812/812 [00:02<00:00, 290.62it/s]/cluster/project/sachan/yifan/softwares/anaconda/anaconda3/envs/xfactr/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2272: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

add example index and unique id:   0%|          | 0/812 [00:00<?, ?it/s]add example index and unique id: 100%|██████████| 812/812 [00:00<00:00, 494378.70it/s]
05/09/2022 22:58:25 - INFO - __main__ -   Saving features into cached file ./cached_tydiqa.goldp.ru.dev.json_xlm-KG_LR8e-6_EPOCH2.0_maxlen384_batchsize4_gradacc4_384_ru
05/09/2022 22:58:25 - INFO - __main__ -   ***** Running evaluation  *****
05/09/2022 22:58:25 - INFO - __main__ -     Num examples = 885
05/09/2022 22:58:25 - INFO - __main__ -     Batch size = 8
Evaluating:   0%|          | 0/111 [00:00<?, ?it/s]Evaluating:   1%|          | 1/111 [00:00<01:26,  1.28it/s]Evaluating:   2%|▏         | 2/111 [00:01<00:57,  1.89it/s]Evaluating:   3%|▎         | 3/111 [00:01<00:48,  2.22it/s]Evaluating:   4%|▎         | 4/111 [00:01<00:44,  2.42it/s]Evaluating:   5%|▍         | 5/111 [00:02<00:41,  2.54it/s]Evaluating:   5%|▌         | 6/111 [00:02<00:39,  2.63it/s]Evaluating:   6%|▋         | 7/111 [00:02<00:38,  2.68it/s]Evaluating:   7%|▋         | 8/111 [00:03<00:37,  2.72it/s]Evaluating:   8%|▊         | 9/111 [00:03<00:37,  2.74it/s]Evaluating:   9%|▉         | 10/111 [00:03<00:36,  2.75it/s]Evaluating:  10%|▉         | 11/111 [00:04<00:36,  2.76it/s]Evaluating:  11%|█         | 12/111 [00:04<00:36,  2.74it/s]Evaluating:  12%|█▏        | 13/111 [00:05<00:35,  2.76it/s]Evaluating:  13%|█▎        | 14/111 [00:05<00:35,  2.77it/s]Evaluating:  14%|█▎        | 15/111 [00:05<00:34,  2.77it/s]Evaluating:  14%|█▍        | 16/111 [00:06<00:34,  2.78it/s]Evaluating:  15%|█▌        | 17/111 [00:06<00:33,  2.79it/s]Evaluating:  16%|█▌        | 18/111 [00:06<00:33,  2.78it/s]Evaluating:  17%|█▋        | 19/111 [00:07<00:33,  2.79it/s]Evaluating:  18%|█▊        | 20/111 [00:07<00:32,  2.79it/s]Evaluating:  19%|█▉        | 21/111 [00:07<00:32,  2.79it/s]Evaluating:  20%|█▉        | 22/111 [00:08<00:32,  2.76it/s]Evaluating:  21%|██        | 23/111 [00:08<00:31,  2.77it/s]Evaluating:  22%|██▏       | 24/111 [00:09<00:31,  2.77it/s]Evaluating:  23%|██▎       | 25/111 [00:09<00:31,  2.77it/s]Evaluating:  23%|██▎       | 26/111 [00:09<00:30,  2.77it/s]Evaluating:  24%|██▍       | 27/111 [00:10<00:30,  2.78it/s]Evaluating:  25%|██▌       | 28/111 [00:10<00:29,  2.79it/s]Evaluating:  26%|██▌       | 29/111 [00:10<00:29,  2.78it/s]Evaluating:  27%|██▋       | 30/111 [00:11<00:29,  2.78it/s]Evaluating:  28%|██▊       | 31/111 [00:11<00:28,  2.78it/s]Evaluating:  29%|██▉       | 32/111 [00:11<00:28,  2.75it/s]Evaluating:  30%|██▉       | 33/111 [00:12<00:28,  2.77it/s]Evaluating:  31%|███       | 34/111 [00:12<00:27,  2.77it/s]Evaluating:  32%|███▏      | 35/111 [00:13<00:27,  2.77it/s]Evaluating:  32%|███▏      | 36/111 [00:13<00:27,  2.78it/s]Evaluating:  33%|███▎      | 37/111 [00:13<00:26,  2.78it/s]Evaluating:  34%|███▍      | 38/111 [00:14<00:26,  2.79it/s]Evaluating:  35%|███▌      | 39/111 [00:14<00:25,  2.79it/s]Evaluating:  36%|███▌      | 40/111 [00:14<00:25,  2.79it/s]Evaluating:  37%|███▋      | 41/111 [00:15<00:25,  2.79it/s]Evaluating:  38%|███▊      | 42/111 [00:15<00:24,  2.77it/s]Evaluating:  39%|███▊      | 43/111 [00:15<00:24,  2.78it/s]Evaluating:  40%|███▉      | 44/111 [00:16<00:24,  2.78it/s]Evaluating:  41%|████      | 45/111 [00:16<00:23,  2.79it/s]Evaluating:  41%|████▏     | 46/111 [00:16<00:23,  2.78it/s]Evaluating:  42%|████▏     | 47/111 [00:17<00:23,  2.78it/s]Evaluating:  43%|████▎     | 48/111 [00:17<00:22,  2.78it/s]Evaluating:  44%|████▍     | 49/111 [00:18<00:22,  2.77it/s]Evaluating:  45%|████▌     | 50/111 [00:18<00:22,  2.76it/s]Evaluating:  46%|████▌     | 51/111 [00:18<00:21,  2.77it/s]Evaluating:  47%|████▋     | 52/111 [00:19<00:21,  2.78it/s]Evaluating:  48%|████▊     | 53/111 [00:19<00:21,  2.74it/s]Evaluating:  49%|████▊     | 54/111 [00:19<00:20,  2.75it/s]Evaluating:  50%|████▉     | 55/111 [00:20<00:20,  2.77it/s]Evaluating:  50%|█████     | 56/111 [00:20<00:19,  2.77it/s]Evaluating:  51%|█████▏    | 57/111 [00:20<00:19,  2.77it/s]Evaluating:  52%|█████▏    | 58/111 [00:21<00:19,  2.77it/s]Evaluating:  53%|█████▎    | 59/111 [00:21<00:18,  2.77it/s]Evaluating:  54%|█████▍    | 60/111 [00:22<00:18,  2.77it/s]Evaluating:  55%|█████▍    | 61/111 [00:22<00:18,  2.77it/s]Evaluating:  56%|█████▌    | 62/111 [00:22<00:17,  2.77it/s]Evaluating:  57%|█████▋    | 63/111 [00:23<00:17,  2.74it/s]Evaluating:  58%|█████▊    | 64/111 [00:23<00:17,  2.75it/s]Evaluating:  59%|█████▊    | 65/111 [00:23<00:16,  2.76it/s]Evaluating:  59%|█████▉    | 66/111 [00:24<00:16,  2.76it/s]Evaluating:  60%|██████    | 67/111 [00:24<00:15,  2.75it/s]Evaluating:  61%|██████▏   | 68/111 [00:24<00:15,  2.76it/s]Evaluating:  62%|██████▏   | 69/111 [00:25<00:15,  2.75it/s]Evaluating:  63%|██████▎   | 70/111 [00:25<00:14,  2.76it/s]Evaluating:  64%|██████▍   | 71/111 [00:26<00:14,  2.76it/s]Evaluating:  65%|██████▍   | 72/111 [00:26<00:14,  2.76it/s]Evaluating:  66%|██████▌   | 73/111 [00:26<00:13,  2.73it/s]Evaluating:  67%|██████▋   | 74/111 [00:27<00:13,  2.73it/s]Evaluating:  68%|██████▊   | 75/111 [00:27<00:13,  2.75it/s]Evaluating:  68%|██████▊   | 76/111 [00:27<00:12,  2.75it/s]Evaluating:  69%|██████▉   | 77/111 [00:28<00:12,  2.76it/s]Evaluating:  70%|███████   | 78/111 [00:28<00:11,  2.76it/s]Evaluating:  71%|███████   | 79/111 [00:28<00:11,  2.77it/s]Evaluating:  72%|███████▏  | 80/111 [00:29<00:11,  2.76it/s]Evaluating:  73%|███████▎  | 81/111 [00:29<00:10,  2.76it/s]Evaluating:  74%|███████▍  | 82/111 [00:30<00:10,  2.77it/s]Evaluating:  75%|███████▍  | 83/111 [00:30<00:10,  2.75it/s]Evaluating:  76%|███████▌  | 84/111 [00:30<00:09,  2.76it/s]Evaluating:  77%|███████▋  | 85/111 [00:31<00:09,  2.77it/s]Evaluating:  77%|███████▋  | 86/111 [00:31<00:09,  2.76it/s]Evaluating:  78%|███████▊  | 87/111 [00:31<00:08,  2.76it/s]Evaluating:  79%|███████▉  | 88/111 [00:32<00:08,  2.76it/s]Evaluating:  80%|████████  | 89/111 [00:32<00:07,  2.77it/s]Evaluating:  81%|████████  | 90/111 [00:32<00:07,  2.77it/s]Evaluating:  82%|████████▏ | 91/111 [00:33<00:07,  2.77it/s]Evaluating:  83%|████████▎ | 92/111 [00:33<00:06,  2.77it/s]Evaluating:  84%|████████▍ | 93/111 [00:33<00:06,  2.73it/s]Evaluating:  85%|████████▍ | 94/111 [00:34<00:06,  2.74it/s]Evaluating:  86%|████████▌ | 95/111 [00:34<00:05,  2.74it/s]Evaluating:  86%|████████▋ | 96/111 [00:35<00:05,  2.75it/s]Evaluating:  87%|████████▋ | 97/111 [00:35<00:05,  2.75it/s]Evaluating:  88%|████████▊ | 98/111 [00:35<00:04,  2.76it/s]Evaluating:  89%|████████▉ | 99/111 [00:36<00:04,  2.70it/s]Evaluating:  90%|█████████ | 100/111 [00:36<00:04,  2.73it/s]Evaluating:  91%|█████████ | 101/111 [00:36<00:03,  2.74it/s]Evaluating:  92%|█████████▏| 102/111 [00:37<00:03,  2.73it/s]Evaluating:  93%|█████████▎| 103/111 [00:37<00:02,  2.75it/s]Evaluating:  94%|█████████▎| 104/111 [00:37<00:02,  2.77it/s]Evaluating:  95%|█████████▍| 105/111 [00:38<00:02,  2.77it/s]Evaluating:  95%|█████████▌| 106/111 [00:38<00:01,  2.78it/s]Evaluating:  96%|█████████▋| 107/111 [00:39<00:01,  2.79it/s]Evaluating:  97%|█████████▋| 108/111 [00:39<00:01,  2.78it/s]Evaluating:  98%|█████████▊| 109/111 [00:39<00:00,  2.77it/s]Evaluating:  99%|█████████▉| 110/111 [00:40<00:00,  2.77it/s]Evaluating: 100%|██████████| 111/111 [00:40<00:00,  3.09it/s]Evaluating: 100%|██████████| 111/111 [00:40<00:00,  2.75it/s]
05/09/2022 22:59:06 - INFO - __main__ -     Evaluation done in total 40.393415 secs (0.045642 sec per example)
05/09/2022 22:59:09 - INFO - __main__ -   Results: {'exact': 44.33497536945813, 'f1': 71.08334827238045, 'total': 812, 'HasAns_exact': 44.33497536945813, 'HasAns_f1': 71.08334827238045, 'HasAns_total': 812, 'best_exact': 44.33497536945813, 'best_exact_thresh': 0.0, 'best_f1': 71.08334827238045, 'best_f1_thresh': 0.0}
  sw 
2022-05-09 22:59:12.494128: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0
05/09/2022 22:59:16 - WARNING - __main__ -   Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, 16-bits training: False
You are using a model of type xlm-roberta to instantiate a model of type xlm. This is not supported for all configurations of models and can yield errors.
Some weights of the model checkpoint at /cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//tydiqa/xlm-KG_LR8e-6_EPOCH2.0_maxlen384_batchsize4_gradacc4 were not used when initializing XLMRobertaModel: ['base_model.encoder.layer.7.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.3.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.15.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.6.attention.self.value.bias', 'base_model.encoder.layer.7.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.9.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.13.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.16.intermediate.dense.weight', 'base_model.pooler.dense.weight', 'base_model.encoder.layer.10.attention.output.LayerNorm.weight', 'base_model.encoder.layer.4.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.10.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.11.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.17.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.5.attention.output.LayerNorm.bias', 'base_model.encoder.layer.8.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.7.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.17.intermediate.dense.bias', 'base_model.encoder.layer.4.attention.self.query.bias', 'base_model.encoder.layer.23.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.5.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.11.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.4.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.4.output.LayerNorm.weight', 'base_model.encoder.layer.9.attention.self.key.bias', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.21.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.21.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.14.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.9.intermediate.dense.bias', 'base_model.encoder.layer.18.attention.self.key.weight', 'base_model.encoder.layer.5.attention.output.LayerNorm.weight', 'base_model.encoder.layer.5.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.16.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.7.attention.self.value.weight', 'base_model.encoder.layer.15.output.dense.bias', 'base_model.encoder.layer.11.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.16.output.LayerNorm.weight', 'base_model.encoder.layer.12.output.LayerNorm.weight', 'base_model.encoder.layer.0.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.7.attention.self.key.bias', 'base_model.encoder.layer.18.output.LayerNorm.bias', 'base_model.encoder.layer.14.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.5.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.4.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.0.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.1.attention.self.key.weight', 'base_model.encoder.layer.13.attention.output.dense.weight', 'base_model.encoder.layer.22.output.dense.weight', 'base_model.encoder.layer.18.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.0.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.13.attention.output.dense.bias', 'base_model.encoder.layer.14.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.16.attention.self.value.weight', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.5.intermediate.dense.weight', 'base_model.encoder.layer.22.attention.output.LayerNorm.weight', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.3.attention.self.value.bias', 'base_model.encoder.layer.17.attention.output.dense.weight', 'base_model.encoder.layer.15.output.LayerNorm.weight', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.18.attention.output.LayerNorm.bias', 'base_model.encoder.layer.4.output.dense.weight', 'base_model.encoder.layer.8.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.21.output.LayerNorm.weight', 'base_model.encoder.layer.2.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.21.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.13.attention.self.value.weight', 'base_model.encoder.layer.20.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.10.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.12.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.5.intermediate.dense.bias', 'base_model.encoder.layer.15.attention.output.LayerNorm.weight', 'base_model.encoder.layer.12.attention.self.value.bias', 'base_model.encoder.layer.4.output.LayerNorm.bias', 'base_model.encoder.layer.1.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.12.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.13.attention.output.LayerNorm.weight', 'base_model.encoder.layer.22.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.2.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.8.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.17.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.7.output.LayerNorm.bias', 'base_model.encoder.layer.12.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.18.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.22.output.LayerNorm.bias', 'base_model.encoder.layer.0.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.20.output.LayerNorm.weight', 'base_model.encoder.layer.0.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.21.attention.self.query.weight', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.1.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.embeddings.LayerNorm.bias', 'base_model.encoder.layer.2.attention.self.value.bias', 'base_model.encoder.layer.4.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.0.attention.self.query.weight', 'base_model.encoder.layer.1.intermediate.dense.bias', 'base_model.encoder.layer.11.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.16.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.2.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.18.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.12.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.4.output.dense.bias', 'base_model.encoder.layer.8.output.dense.bias', 'base_model.encoder.layer.19.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.7.attention.output.dense.weight', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.1.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.19.attention.self.key.bias', 'base_model.encoder.layer.10.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.22.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.8.attention.self.key.weight', 'base_model.encoder.layer.16.output.adapters.es.adapter_down.0.weight', 'base_model.pooler.dense.bias', 'base_model.encoder.layer.14.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.14.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.11.output.LayerNorm.weight', 'base_model.encoder.layer.5.attention.self.value.weight', 'base_model.encoder.layer.18.attention.output.dense.weight', 'base_model.encoder.layer.2.output.dense.weight', 'base_model.encoder.layer.2.output.LayerNorm.bias', 'base_model.encoder.layer.6.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.10.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.18.attention.output.LayerNorm.weight', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.5.attention.self.key.weight', 'base_model.encoder.layer.8.attention.output.LayerNorm.bias', 'base_model.encoder.layer.22.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.23.output.dense.bias', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.16.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.1.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.2.output.adapters.ep.adapter_down.0.bias', 'qa_outputs.weight', 'base_model.encoder.layer.1.output.dense.weight', 'base_model.encoder.layer.20.attention.self.query.weight', 'base_model.encoder.layer.5.output.LayerNorm.weight', 'base_model.encoder.layer.11.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.18.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.1.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.14.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.10.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.8.attention.output.dense.weight', 'base_model.encoder.layer.6.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.21.output.dense.bias', 'base_model.encoder.layer.21.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.13.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.14.attention.self.key.weight', 'base_model.encoder.layer.15.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.16.intermediate.dense.bias', 'base_model.encoder.layer.20.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.18.attention.self.value.bias', 'base_model.encoder.layer.21.attention.output.LayerNorm.bias', 'base_model.encoder.layer.22.output.dense.bias', 'base_model.encoder.layer.21.attention.self.query.bias', 'base_model.encoder.layer.8.intermediate.dense.bias', 'base_model.encoder.layer.16.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.12.attention.self.value.weight', 'base_model.encoder.layer.20.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.15.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.18.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.8.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.0.attention.output.dense.bias', 'base_model.encoder.layer.0.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.6.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.9.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.23.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.2.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.16.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.10.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.11.intermediate.dense.bias', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.17.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.3.intermediate.dense.bias', 'base_model.encoder.layer.15.attention.self.key.bias', 'base_model.encoder.layer.2.output.dense.bias', 'base_model.encoder.layer.10.attention.output.dense.bias', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.9.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.10.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.4.attention.output.dense.bias', 'base_model.encoder.layer.8.output.LayerNorm.weight', 'base_model.encoder.layer.16.output.LayerNorm.bias', 'base_model.encoder.layer.20.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.20.attention.output.dense.bias', 'base_model.encoder.layer.20.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.17.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.19.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.23.attention.self.value.bias', 'base_model.encoder.layer.11.attention.self.key.weight', 'base_model.encoder.layer.3.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.2.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.12.attention.output.LayerNorm.weight', 'base_model.encoder.layer.10.attention.output.dense.weight', 'base_model.encoder.layer.4.attention.output.dense.weight', 'base_model.encoder.layer.8.attention.output.dense.bias', 'base_model.encoder.layer.1.attention.self.query.weight', 'base_model.encoder.layer.13.attention.self.value.bias', 'base_model.encoder.layer.5.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.15.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.13.attention.output.LayerNorm.bias', 'base_model.encoder.layer.21.attention.self.key.bias', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.17.output.LayerNorm.weight', 'base_model.encoder.layer.1.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.17.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.13.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.20.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.19.attention.self.query.bias', 'base_model.encoder.layer.1.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.3.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.17.attention.output.LayerNorm.weight', 'base_model.encoder.layer.2.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.21.output.dense.weight', 'base_model.encoder.layer.3.attention.output.LayerNorm.weight', 'base_model.encoder.layer.23.output.LayerNorm.weight', 'base_model.encoder.layer.19.output.dense.bias', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.16.attention.self.query.weight', 'base_model.encoder.layer.7.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.19.attention.self.value.weight', 'base_model.encoder.layer.11.output.dense.bias', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.23.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.7.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.19.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.20.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.6.attention.output.LayerNorm.weight', 'base_model.encoder.layer.3.attention.self.query.bias', 'base_model.encoder.layer.18.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.7.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.0.attention.output.LayerNorm.weight', 'base_model.encoder.layer.3.output.dense.weight', 'base_model.encoder.layer.1.output.LayerNorm.weight', 'base_model.encoder.layer.10.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.5.output.dense.weight', 'base_model.encoder.layer.5.attention.self.query.bias', 'base_model.encoder.layer.2.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.8.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.7.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.14.attention.self.query.bias', 'base_model.encoder.layer.6.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.10.attention.output.LayerNorm.bias', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.9.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.1.attention.self.key.bias', 'base_model.encoder.layer.15.attention.self.value.weight', 'base_model.encoder.layer.23.attention.self.query.weight', 'base_model.encoder.layer.3.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.6.attention.self.query.weight', 'base_model.encoder.layer.23.attention.self.key.bias', 'base_model.encoder.layer.3.intermediate.dense.weight', 'base_model.encoder.layer.17.output.LayerNorm.bias', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.18.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.0.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.18.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.6.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.20.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.8.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.10.attention.self.query.bias', 'base_model.encoder.layer.12.attention.self.key.bias', 'base_model.encoder.layer.13.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.19.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.22.attention.self.value.bias', 'base_model.encoder.layer.2.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.7.intermediate.dense.weight', 'base_model.encoder.layer.6.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.12.intermediate.dense.bias', 'base_model.encoder.layer.20.attention.self.value.bias', 'base_model.encoder.layer.0.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.20.attention.self.key.weight', 'base_model.encoder.layer.19.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.10.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.16.attention.output.dense.weight', 'base_model.encoder.layer.2.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.22.attention.self.key.weight', 'base_model.encoder.layer.13.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.22.attention.output.dense.bias', 'base_model.encoder.layer.17.output.dense.weight', 'base_model.encoder.layer.22.output.LayerNorm.weight', 'base_model.encoder.layer.6.attention.self.key.weight', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.19.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.12.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.7.attention.self.query.bias', 'base_model.encoder.layer.2.intermediate.dense.weight', 'base_model.encoder.layer.20.attention.output.LayerNorm.bias', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.11.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.9.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.6.attention.output.dense.bias', 'base_model.encoder.layer.0.output.LayerNorm.bias', 'base_model.encoder.layer.0.attention.self.key.bias', 'base_model.encoder.layer.5.attention.self.key.bias', 'base_model.encoder.layer.15.intermediate.dense.weight', 'base_model.encoder.layer.23.intermediate.dense.weight', 'base_model.encoder.layer.12.output.LayerNorm.bias', 'base_model.encoder.layer.3.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.7.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.0.output.LayerNorm.weight', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.20.attention.self.query.bias', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.18.output.LayerNorm.weight', 'base_model.encoder.layer.11.attention.self.key.bias', 'base_model.encoder.layer.2.attention.output.dense.weight', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.19.output.LayerNorm.bias', 'base_model.encoder.layer.6.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.17.attention.self.query.weight', 'base_model.encoder.layer.1.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.1.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.6.output.dense.weight', 'base_model.encoder.layer.14.attention.self.value.bias', 'base_model.encoder.layer.4.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.3.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.4.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.6.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.21.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.11.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.23.attention.output.LayerNorm.weight', 'base_model.encoder.layer.9.output.dense.bias', 'base_model.encoder.layer.0.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.13.output.LayerNorm.bias', 'base_model.encoder.layer.13.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.0.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.1.attention.self.value.bias', 'base_model.encoder.layer.16.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.10.attention.self.query.weight', 'base_model.encoder.layer.4.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.3.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.4.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.10.output.LayerNorm.weight', 'base_model.encoder.layer.21.output.LayerNorm.bias', 'base_model.encoder.layer.3.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.14.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.15.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.12.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.3.attention.output.dense.bias', 'base_model.encoder.layer.0.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.12.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.23.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.12.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.23.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.6.attention.self.value.weight', 'base_model.encoder.layer.18.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.13.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.7.attention.self.value.bias', 'base_model.encoder.layer.1.attention.output.LayerNorm.bias', 'base_model.encoder.layer.15.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.21.attention.output.dense.weight', 'base_model.encoder.layer.2.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.22.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.9.attention.self.key.weight', 'base_model.encoder.layer.11.attention.output.dense.weight', 'base_model.encoder.layer.12.attention.output.dense.weight', 'base_model.encoder.layer.15.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.8.intermediate.dense.weight', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.10.attention.self.value.bias', 'base_model.encoder.layer.10.output.dense.bias', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.7.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.13.output.dense.weight', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.6.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.22.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.20.attention.output.dense.weight', 'base_model.encoder.layer.18.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.14.attention.self.value.weight', 'base_model.encoder.layer.5.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.2.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.8.attention.self.key.bias', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.11.intermediate.dense.weight', 'base_model.encoder.layer.10.intermediate.dense.bias', 'base_model.encoder.layer.9.attention.output.dense.weight', 'base_model.encoder.layer.3.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.6.attention.self.key.bias', 'base_model.encoder.layer.8.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.16.attention.self.key.weight', 'base_model.encoder.layer.19.intermediate.dense.weight', 'base_model.encoder.layer.22.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.1.attention.output.dense.weight', 'base_model.encoder.layer.18.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.5.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.1.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.16.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.17.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.20.intermediate.dense.bias', 'base_model.encoder.layer.9.intermediate.dense.weight', 'base_model.encoder.layer.22.attention.output.dense.weight', 'base_model.encoder.layer.1.output.dense.bias', 'base_model.encoder.layer.16.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.12.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.1.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.10.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.21.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.22.intermediate.dense.weight', 'base_model.encoder.layer.9.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.19.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.9.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.11.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.1.intermediate.dense.weight', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.13.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.16.output.dense.weight', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.2.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.23.attention.self.key.weight', 'base_model.encoder.layer.7.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.12.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.15.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.16.attention.self.key.bias', 'base_model.encoder.layer.19.output.LayerNorm.weight', 'base_model.encoder.layer.9.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.13.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.22.attention.self.query.bias', 'base_model.encoder.layer.22.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.11.attention.self.query.bias', 'base_model.encoder.layer.23.attention.output.dense.bias', 'base_model.encoder.layer.5.output.LayerNorm.bias', 'base_model.encoder.layer.21.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.1.attention.self.value.weight', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.1.attention.output.LayerNorm.weight', 'base_model.encoder.layer.7.output.LayerNorm.weight', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.15.attention.output.LayerNorm.bias', 'base_model.encoder.layer.23.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.10.attention.self.key.bias', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.5.attention.output.dense.weight', 'base_model.encoder.layer.10.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.12.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.7.attention.output.LayerNorm.bias', 'base_model.encoder.layer.19.output.dense.weight', 'base_model.encoder.layer.5.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.4.attention.self.value.weight', 'base_model.encoder.layer.10.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.13.output.LayerNorm.weight', 'base_model.encoder.layer.6.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.18.intermediate.dense.bias', 'base_model.encoder.layer.21.intermediate.dense.bias', 'base_model.encoder.layer.0.intermediate.dense.weight', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.21.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.14.attention.output.LayerNorm.bias', 'base_model.encoder.layer.0.attention.output.LayerNorm.bias', 'base_model.encoder.layer.2.output.LayerNorm.weight', 'base_model.encoder.layer.15.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.9.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.19.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.13.output.dense.bias', 'base_model.encoder.layer.22.intermediate.dense.bias', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.15.attention.self.query.weight', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.8.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.7.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.6.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.5.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.15.attention.output.dense.weight', 'base_model.encoder.layer.11.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.14.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.3.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.6.attention.self.query.bias', 'base_model.encoder.layer.0.attention.self.key.weight', 'base_model.embeddings.token_type_embeddings.weight', 'base_model.encoder.layer.1.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.3.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.1.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.7.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.16.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.4.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.2.attention.output.dense.bias', 'base_model.encoder.layer.3.attention.output.dense.weight', 'base_model.encoder.layer.18.attention.output.dense.bias', 'base_model.encoder.layer.9.attention.output.dense.bias', 'base_model.encoder.layer.21.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.1.attention.self.query.bias', 'base_model.encoder.layer.3.attention.self.key.bias', 'base_model.encoder.layer.19.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.18.output.dense.weight', 'base_model.encoder.layer.3.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.13.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.20.attention.self.value.weight', 'base_model.encoder.layer.3.output.dense.bias', 'base_model.encoder.layer.9.attention.output.LayerNorm.weight', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.2.attention.output.LayerNorm.bias', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.4.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.14.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.10.attention.self.value.weight', 'base_model.encoder.layer.20.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.23.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.16.attention.self.query.bias', 'base_model.encoder.layer.14.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.20.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.4.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.23.attention.output.dense.weight', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.9.attention.self.value.bias', 'base_model.encoder.layer.12.output.dense.weight', 'base_model.encoder.layer.6.intermediate.dense.weight', 'base_model.encoder.layer.22.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.11.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.10.output.dense.weight', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.18.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.4.attention.self.key.weight', 'base_model.encoder.layer.14.output.LayerNorm.bias', 'base_model.encoder.layer.12.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.22.attention.output.LayerNorm.bias', 'base_model.encoder.layer.23.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.16.output.dense.bias', 'base_model.encoder.layer.3.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.4.attention.output.LayerNorm.weight', 'base_model.encoder.layer.13.attention.self.key.weight', 'base_model.encoder.layer.20.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.19.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.16.attention.output.dense.bias', 'base_model.encoder.layer.0.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.12.attention.self.query.bias', 'base_model.encoder.layer.0.output.dense.bias', 'base_model.encoder.layer.5.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.0.output.dense.weight', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.23.output.dense.weight', 'base_model.encoder.layer.6.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.17.intermediate.dense.weight', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.5.output.dense.bias', 'base_model.encoder.layer.8.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.23.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.18.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.11.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.5.attention.output.dense.bias', 'base_model.encoder.layer.14.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.6.attention.output.dense.weight', 'base_model.encoder.layer.22.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.4.attention.self.key.bias', 'base_model.encoder.layer.4.intermediate.dense.weight', 'base_model.encoder.layer.9.attention.self.query.bias', 'base_model.encoder.layer.8.attention.self.value.bias', 'base_model.encoder.layer.14.output.dense.weight', 'base_model.encoder.layer.11.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.1.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.9.output.LayerNorm.weight', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.16.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.16.attention.output.LayerNorm.weight', 'base_model.encoder.layer.9.attention.self.value.weight', 'base_model.encoder.layer.16.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.20.intermediate.dense.weight', 'base_model.encoder.layer.6.attention.output.LayerNorm.bias', 'base_model.encoder.layer.7.attention.self.key.weight', 'base_model.encoder.layer.5.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.14.attention.self.key.bias', 'base_model.encoder.layer.0.attention.self.value.bias', 'base_model.encoder.layer.3.attention.output.LayerNorm.bias', 'base_model.encoder.layer.0.attention.self.query.bias', 'base_model.encoder.layer.5.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.6.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.16.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.17.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.23.attention.self.query.bias', 'base_model.encoder.layer.14.intermediate.dense.weight', 'base_model.encoder.layer.5.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.13.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.10.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.15.attention.self.query.bias', 'base_model.encoder.layer.5.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.3.output.LayerNorm.weight', 'base_model.encoder.layer.12.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.4.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.9.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.0.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.15.attention.self.key.weight', 'base_model.encoder.layer.17.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.17.attention.output.LayerNorm.bias', 'base_model.encoder.layer.20.attention.output.LayerNorm.weight', 'base_model.encoder.layer.21.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.22.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.22.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.13.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.20.output.dense.bias', 'base_model.encoder.layer.7.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.17.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.8.attention.self.query.weight', 'base_model.encoder.layer.8.attention.self.query.bias', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.11.attention.self.value.weight', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.18.attention.self.value.weight', 'base_model.encoder.layer.23.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.16.attention.self.value.bias', 'base_model.encoder.layer.23.attention.self.value.weight', 'base_model.encoder.layer.7.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.17.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.22.attention.self.key.bias', 'base_model.encoder.layer.19.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.1.attention.output.dense.bias', 'base_model.encoder.layer.7.attention.self.query.weight', 'base_model.encoder.layer.5.attention.self.value.bias', 'base_model.encoder.layer.20.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.2.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.0.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.4.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.21.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.17.attention.self.value.bias', 'base_model.encoder.layer.21.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.21.attention.self.key.weight', 'base_model.encoder.layer.20.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.15.attention.self.value.bias', 'base_model.encoder.layer.22.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.0.attention.output.dense.weight', 'base_model.encoder.layer.11.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.14.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.16.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.7.attention.output.LayerNorm.weight', 'base_model.encoder.layer.9.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.12.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.9.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.16.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.17.attention.self.query.bias', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.18.attention.self.query.bias', 'base_model.encoder.layer.8.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.19.attention.output.dense.weight', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.18.attention.self.query.weight', 'base_model.encoder.layer.15.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.23.output.LayerNorm.bias', 'base_model.encoder.layer.4.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.18.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.13.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.11.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.20.output.LayerNorm.bias', 'base_model.encoder.layer.19.intermediate.dense.bias', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.2.attention.self.query.bias', 'base_model.encoder.layer.11.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.5.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.19.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.8.attention.self.value.weight', 'base_model.encoder.layer.17.attention.self.key.weight', 'base_model.encoder.layer.22.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.23.attention.output.LayerNorm.bias', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.13.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.23.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.2.attention.self.query.weight', 'base_model.embeddings.position_ids', 'base_model.encoder.layer.10.intermediate.dense.weight', 'base_model.encoder.layer.23.intermediate.dense.bias', 'base_model.encoder.layer.14.intermediate.dense.bias', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.20.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.17.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.21.attention.self.value.bias', 'base_model.encoder.layer.12.attention.output.dense.bias', 'base_model.encoder.layer.4.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.6.intermediate.dense.bias', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.17.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.15.output.dense.weight', 'base_model.encoder.layer.12.attention.self.key.weight', 'base_model.encoder.layer.9.attention.self.query.weight', 'base_model.encoder.layer.0.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.16.attention.output.LayerNorm.bias', 'base_model.encoder.layer.19.attention.self.query.weight', 'base_model.encoder.layer.22.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.6.output.dense.bias', 'base_model.encoder.layer.13.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.19.attention.self.key.weight', 'base_model.encoder.layer.8.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.11.attention.output.LayerNorm.bias', 'base_model.encoder.layer.9.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.2.intermediate.dense.bias', 'base_model.encoder.layer.13.attention.self.query.weight', 'base_model.encoder.layer.4.attention.output.LayerNorm.bias', 'base_model.encoder.layer.20.attention.self.key.bias', 'base_model.encoder.layer.17.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.15.attention.output.dense.bias', 'base_model.encoder.layer.2.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.3.attention.self.key.weight', 'base_model.encoder.layer.3.attention.self.query.weight', 'base_model.encoder.layer.8.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.11.output.dense.weight', 'base_model.encoder.layer.12.attention.self.query.weight', 'base_model.encoder.layer.7.intermediate.dense.bias', 'base_model.encoder.layer.23.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.21.attention.output.LayerNorm.weight', 'base_model.encoder.layer.14.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.21.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.6.output.LayerNorm.weight', 'base_model.encoder.layer.6.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.1.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.18.attention.self.key.bias', 'base_model.encoder.layer.23.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.9.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.19.attention.output.dense.bias', 'base_model.encoder.layer.9.attention.output.LayerNorm.bias', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.14.output.dense.bias', 'base_model.encoder.layer.18.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.3.output.LayerNorm.bias', 'base_model.encoder.layer.11.attention.output.dense.bias', 'base_model.encoder.layer.2.attention.self.key.weight', 'base_model.encoder.layer.4.attention.self.query.weight', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.23.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.23.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.1.output.LayerNorm.bias', 'base_model.encoder.layer.14.output.LayerNorm.weight', 'base_model.encoder.layer.8.output.dense.weight', 'base_model.encoder.layer.10.output.LayerNorm.bias', 'base_model.encoder.layer.10.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.1.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.19.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.22.attention.self.query.weight', 'base_model.encoder.layer.19.output.adapters.es.adapter_down.0.bias', 'base_model.embeddings.LayerNorm.weight', 'base_model.encoder.layer.7.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.4.attention.self.value.bias', 'base_model.encoder.layer.15.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.8.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.23.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.11.attention.output.LayerNorm.weight', 'base_model.encoder.layer.18.output.dense.bias', 'base_model.encoder.layer.18.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.5.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.12.output.dense.bias', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.20.output.dense.weight', 'base_model.encoder.layer.21.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.15.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.13.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.13.attention.self.query.bias', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.19.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.22.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.17.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.4.intermediate.dense.bias', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.12.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.17.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.19.attention.output.LayerNorm.weight', 'base_model.encoder.layer.10.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.10.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.5.attention.self.query.weight', 'base_model.encoder.layer.8.attention.output.LayerNorm.weight', 'base_model.encoder.layer.14.attention.output.LayerNorm.weight', 'base_model.encoder.layer.6.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.21.intermediate.dense.weight', 'base_model.encoder.layer.8.output.LayerNorm.bias', 'base_model.encoder.layer.14.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.7.attention.output.dense.bias', 'base_model.encoder.layer.9.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.20.output.adapters.tp.adapter_up.bias', 'base_model.embeddings.word_embeddings.weight', 'base_model.encoder.layer.6.output.LayerNorm.bias', 'base_model.encoder.layer.13.intermediate.dense.weight', 'base_model.encoder.layer.17.attention.self.value.weight', 'base_model.encoder.layer.3.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.9.output.dense.weight', 'base_model.encoder.layer.11.attention.self.query.weight', 'base_model.encoder.layer.14.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.embeddings.position_embeddings.weight', 'base_model.encoder.layer.2.attention.output.LayerNorm.weight', 'base_model.encoder.layer.3.attention.self.value.weight', 'base_model.encoder.layer.0.attention.self.value.weight', 'base_model.encoder.layer.2.attention.self.key.bias', 'base_model.encoder.layer.17.output.dense.bias', 'base_model.encoder.layer.19.attention.output.LayerNorm.bias', 'base_model.encoder.layer.21.attention.self.value.weight', 'base_model.encoder.layer.7.output.dense.bias', 'base_model.encoder.layer.10.attention.self.key.weight', 'qa_outputs.bias', 'base_model.encoder.layer.16.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.17.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.0.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.14.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.15.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.20.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.14.attention.output.dense.weight', 'base_model.encoder.layer.22.attention.self.value.weight', 'base_model.encoder.layer.0.intermediate.dense.bias', 'base_model.encoder.layer.11.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.2.attention.self.value.weight', 'base_model.encoder.layer.6.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.13.intermediate.dense.bias', 'base_model.encoder.layer.18.intermediate.dense.weight', 'base_model.encoder.layer.21.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.12.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.15.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.19.attention.self.value.bias', 'base_model.encoder.layer.8.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.14.attention.self.query.weight', 'base_model.encoder.layer.3.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.4.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.9.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.15.intermediate.dense.bias', 'base_model.encoder.layer.15.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.7.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.11.attention.self.value.bias', 'base_model.encoder.layer.15.output.LayerNorm.bias', 'base_model.encoder.layer.17.attention.self.key.bias', 'base_model.encoder.layer.7.output.dense.weight', 'base_model.encoder.layer.8.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.22.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.8.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.14.attention.output.dense.bias', 'base_model.encoder.layer.2.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.3.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.15.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.12.intermediate.dense.weight', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.5.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.12.attention.output.LayerNorm.bias', 'base_model.encoder.layer.21.attention.output.dense.bias', 'base_model.encoder.layer.11.output.LayerNorm.bias', 'base_model.encoder.layer.13.attention.self.key.bias', 'base_model.encoder.layer.19.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.21.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.9.output.LayerNorm.bias', 'base_model.encoder.layer.17.attention.output.dense.bias']
- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of XLMRobertaModel were not initialized from the model checkpoint at /cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//tydiqa/xlm-KG_LR8e-6_EPOCH2.0_maxlen384_batchsize4_gradacc4 and are newly initialized: ['encoder.layer.8.output.dense.bias', 'encoder.layer.13.attention.output.dense.bias', 'encoder.layer.22.attention.self.query.bias', 'encoder.layer.7.attention.self.value.bias', 'encoder.layer.23.output.LayerNorm.weight', 'encoder.layer.18.intermediate.dense.bias', 'encoder.layer.10.attention.self.value.weight', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.5.output.dense.weight', 'encoder.layer.12.output.LayerNorm.weight', 'encoder.layer.18.attention.output.dense.weight', 'encoder.layer.6.output.dense.bias', 'encoder.layer.18.output.LayerNorm.weight', 'encoder.layer.22.output.LayerNorm.bias', 'encoder.layer.20.attention.output.dense.weight', 'encoder.layer.13.attention.self.query.weight', 'encoder.layer.14.output.dense.bias', 'encoder.layer.10.attention.output.dense.bias', 'encoder.layer.23.attention.output.LayerNorm.bias', 'encoder.layer.16.attention.output.LayerNorm.weight', 'encoder.layer.11.attention.self.key.bias', 'encoder.layer.8.attention.self.key.weight', 'encoder.layer.14.intermediate.dense.weight', 'encoder.layer.19.intermediate.dense.weight', 'encoder.layer.7.attention.output.dense.weight', 'encoder.layer.0.attention.output.dense.weight', 'embeddings.LayerNorm.weight', 'encoder.layer.16.intermediate.dense.bias', 'encoder.layer.23.attention.self.value.weight', 'encoder.layer.18.attention.self.value.weight', 'encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.layer.2.attention.self.value.weight', 'encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.layer.9.attention.output.dense.bias', 'encoder.layer.15.attention.self.query.weight', 'encoder.layer.6.attention.output.LayerNorm.bias', 'encoder.layer.21.intermediate.dense.weight', 'encoder.layer.1.attention.self.value.bias', 'encoder.layer.1.attention.self.query.weight', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.9.attention.output.LayerNorm.bias', 'encoder.layer.14.attention.self.key.weight', 'encoder.layer.6.attention.self.query.weight', 'encoder.layer.18.attention.output.dense.bias', 'encoder.layer.7.output.LayerNorm.bias', 'encoder.layer.0.attention.output.dense.bias', 'encoder.layer.7.attention.self.key.bias', 'encoder.layer.22.output.LayerNorm.weight', 'encoder.layer.7.attention.self.query.bias', 'encoder.layer.6.attention.self.query.bias', 'encoder.layer.8.attention.output.LayerNorm.bias', 'encoder.layer.16.attention.self.value.weight', 'encoder.layer.4.attention.self.query.bias', 'encoder.layer.21.attention.output.LayerNorm.weight', 'encoder.layer.10.attention.self.query.weight', 'encoder.layer.0.attention.self.value.bias', 'encoder.layer.16.attention.self.key.bias', 'encoder.layer.5.output.dense.bias', 'encoder.layer.12.attention.output.dense.bias', 'encoder.layer.15.output.dense.bias', 'encoder.layer.21.attention.self.query.weight', 'encoder.layer.16.output.dense.weight', 'encoder.layer.2.attention.self.key.weight', 'encoder.layer.7.attention.output.dense.bias', 'encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.8.output.dense.weight', 'encoder.layer.14.output.LayerNorm.weight', 'encoder.layer.21.intermediate.dense.bias', 'encoder.layer.16.intermediate.dense.weight', 'encoder.layer.20.attention.self.value.bias', 'encoder.layer.7.attention.self.query.weight', 'encoder.layer.11.attention.self.value.weight', 'encoder.layer.5.attention.self.key.bias', 'encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.layer.2.attention.self.key.bias', 'encoder.layer.4.attention.self.key.bias', 'encoder.layer.11.attention.self.key.weight', 'encoder.layer.6.attention.self.key.bias', 'encoder.layer.21.output.dense.bias', 'encoder.layer.23.output.dense.weight', 'encoder.layer.17.attention.output.dense.weight', 'encoder.layer.8.attention.self.query.bias', 'encoder.layer.9.output.LayerNorm.bias', 'encoder.layer.21.output.LayerNorm.weight', 'encoder.layer.11.attention.self.query.weight', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.13.intermediate.dense.weight', 'encoder.layer.8.output.LayerNorm.bias', 'encoder.layer.15.intermediate.dense.weight', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.12.attention.output.dense.weight', 'encoder.layer.14.attention.self.query.weight', 'encoder.layer.8.attention.output.LayerNorm.weight', 'embeddings.word_embeddings.weight', 'encoder.layer.2.attention.self.query.bias', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.8.attention.self.value.weight', 'encoder.layer.5.attention.output.dense.bias', 'encoder.layer.16.attention.output.dense.weight', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.22.attention.self.value.weight', 'encoder.layer.10.intermediate.dense.weight', 'encoder.layer.15.attention.output.dense.weight', 'encoder.layer.13.output.LayerNorm.weight', 'encoder.layer.1.attention.self.key.bias', 'encoder.layer.9.output.LayerNorm.weight', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.16.attention.self.query.bias', 'encoder.layer.14.attention.output.dense.bias', 'encoder.layer.17.output.dense.weight', 'encoder.layer.19.attention.output.dense.weight', 'encoder.layer.12.attention.self.query.bias', 'encoder.layer.17.attention.self.key.weight', 'encoder.layer.15.attention.self.key.bias', 'encoder.layer.1.attention.self.key.weight', 'encoder.layer.20.attention.self.value.weight', 'encoder.layer.15.attention.self.query.bias', 'encoder.layer.19.attention.self.value.bias', 'encoder.layer.17.attention.output.LayerNorm.weight', 'encoder.layer.17.attention.self.value.weight', 'encoder.layer.8.attention.output.dense.bias', 'encoder.layer.18.output.LayerNorm.bias', 'encoder.layer.13.attention.self.key.bias', 'encoder.layer.12.attention.output.LayerNorm.bias', 'encoder.layer.20.intermediate.dense.weight', 'encoder.layer.8.output.LayerNorm.weight', 'encoder.layer.10.attention.self.key.bias', 'encoder.layer.17.intermediate.dense.bias', 'encoder.layer.17.output.LayerNorm.weight', 'encoder.layer.15.output.LayerNorm.bias', 'encoder.layer.19.output.dense.weight', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.4.attention.self.value.bias', 'encoder.layer.12.attention.self.key.weight', 'encoder.layer.10.attention.self.query.bias', 'encoder.layer.8.attention.output.dense.weight', 'encoder.layer.15.attention.output.LayerNorm.bias', 'encoder.layer.17.attention.output.dense.bias', 'encoder.layer.12.output.dense.weight', 'encoder.layer.3.output.dense.bias', 'encoder.layer.13.output.dense.bias', 'encoder.layer.13.attention.self.key.weight', 'encoder.layer.16.output.LayerNorm.bias', 'encoder.layer.10.output.dense.bias', 'encoder.layer.23.intermediate.dense.weight', 'encoder.layer.5.attention.self.value.weight', 'encoder.layer.6.attention.self.value.bias', 'encoder.layer.7.attention.output.LayerNorm.weight', 'encoder.layer.10.attention.output.LayerNorm.bias', 'encoder.layer.13.attention.output.LayerNorm.weight', 'encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.9.attention.self.key.bias', 'encoder.layer.16.attention.output.LayerNorm.bias', 'encoder.layer.23.attention.self.key.weight', 'encoder.layer.14.output.dense.weight', 'encoder.layer.5.attention.self.key.weight', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.6.attention.self.value.weight', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.6.attention.output.dense.bias', 'encoder.layer.10.output.LayerNorm.weight', 'encoder.layer.12.attention.self.key.bias', 'encoder.layer.2.attention.output.LayerNorm.weight', 'encoder.layer.11.output.LayerNorm.bias', 'encoder.layer.11.attention.output.LayerNorm.weight', 'encoder.layer.23.attention.self.value.bias', 'encoder.layer.4.attention.output.LayerNorm.bias', 'encoder.layer.11.output.LayerNorm.weight', 'encoder.layer.21.attention.output.dense.bias', 'encoder.layer.18.output.dense.weight', 'encoder.layer.21.attention.output.dense.weight', 'encoder.layer.20.attention.self.key.bias', 'encoder.layer.17.output.dense.bias', 'encoder.layer.18.attention.output.LayerNorm.weight', 'encoder.layer.23.intermediate.dense.bias', 'encoder.layer.11.attention.self.query.bias', 'encoder.layer.9.attention.output.LayerNorm.weight', 'encoder.layer.4.attention.self.value.weight', 'encoder.layer.14.attention.output.dense.weight', 'encoder.layer.14.attention.self.query.bias', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.1.attention.output.dense.weight', 'encoder.layer.9.attention.self.query.weight', 'encoder.layer.22.attention.self.query.weight', 'encoder.layer.22.attention.output.LayerNorm.bias', 'encoder.layer.7.intermediate.dense.bias', 'encoder.layer.16.attention.self.query.weight', 'encoder.layer.19.attention.self.key.bias', 'encoder.layer.15.output.LayerNorm.weight', 'encoder.layer.7.attention.self.key.weight', 'encoder.layer.13.attention.self.value.bias', 'encoder.layer.2.attention.output.dense.bias', 'encoder.layer.3.attention.self.key.bias', 'encoder.layer.9.attention.self.value.bias', 'encoder.layer.11.attention.self.value.bias', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.18.intermediate.dense.weight', 'encoder.layer.5.attention.output.LayerNorm.weight', 'encoder.layer.15.attention.self.key.weight', 'encoder.layer.13.attention.self.value.weight', 'encoder.layer.13.attention.output.LayerNorm.bias', 'encoder.layer.18.attention.self.key.weight', 'encoder.layer.19.attention.output.dense.bias', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.23.attention.output.LayerNorm.weight', 'encoder.layer.21.attention.self.key.weight', 'encoder.layer.22.attention.self.key.weight', 'encoder.layer.23.attention.self.query.bias', 'encoder.layer.13.output.dense.weight', 'encoder.layer.14.intermediate.dense.bias', 'encoder.layer.20.output.LayerNorm.weight', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.2.attention.output.LayerNorm.bias', 'encoder.layer.4.output.dense.bias', 'encoder.layer.18.attention.self.query.bias', 'encoder.layer.4.attention.self.query.weight', 'encoder.layer.5.attention.self.value.bias', 'encoder.layer.4.output.dense.weight', 'encoder.layer.10.output.LayerNorm.bias', 'encoder.layer.11.output.dense.bias', 'encoder.layer.3.attention.self.value.weight', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.5.attention.self.query.bias', 'encoder.layer.10.output.dense.weight', 'encoder.layer.14.attention.output.LayerNorm.weight', 'encoder.layer.3.attention.output.dense.bias', 'encoder.layer.6.output.dense.weight', 'encoder.layer.16.attention.self.value.bias', 'encoder.layer.0.attention.self.key.weight', 'encoder.layer.22.intermediate.dense.bias', 'encoder.layer.22.attention.output.dense.bias', 'encoder.layer.10.attention.self.value.bias', 'encoder.layer.21.attention.self.query.bias', 'encoder.layer.15.attention.output.dense.bias', 'encoder.layer.4.attention.self.key.weight', 'encoder.layer.8.attention.self.query.weight', 'encoder.layer.9.attention.self.key.weight', 'encoder.layer.12.attention.self.value.weight', 'encoder.layer.22.attention.output.LayerNorm.weight', 'embeddings.LayerNorm.bias', 'encoder.layer.19.attention.output.LayerNorm.weight', 'encoder.layer.16.attention.output.dense.bias', 'encoder.layer.13.intermediate.dense.bias', 'encoder.layer.4.attention.output.dense.bias', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.0.attention.output.LayerNorm.weight', 'encoder.layer.0.output.dense.weight', 'encoder.layer.1.attention.output.LayerNorm.weight', 'encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.layer.7.attention.self.value.weight', 'encoder.layer.7.output.dense.bias', 'encoder.layer.1.output.dense.weight', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.8.attention.self.key.bias', 'encoder.layer.9.attention.output.dense.weight', 'encoder.layer.20.output.dense.bias', 'encoder.layer.22.attention.self.key.bias', 'encoder.layer.9.output.dense.weight', 'encoder.layer.18.attention.self.query.weight', 'encoder.layer.23.attention.self.key.bias', 'encoder.layer.5.output.LayerNorm.bias', 'encoder.layer.18.attention.output.LayerNorm.bias', 'encoder.layer.20.intermediate.dense.bias', 'encoder.layer.7.output.dense.weight', 'encoder.layer.2.attention.self.query.weight', 'encoder.layer.2.output.dense.bias', 'encoder.layer.12.attention.self.value.bias', 'encoder.layer.15.intermediate.dense.bias', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.3.attention.output.dense.weight', 'encoder.layer.21.attention.self.value.bias', 'embeddings.token_type_embeddings.weight', 'encoder.layer.21.attention.self.value.weight', 'encoder.layer.11.attention.output.dense.weight', 'encoder.layer.19.output.dense.bias', 'encoder.layer.20.attention.output.dense.bias', 'encoder.layer.14.attention.self.key.bias', 'encoder.layer.6.attention.output.LayerNorm.weight', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.layer.20.output.dense.weight', 'encoder.layer.0.attention.self.query.weight', 'encoder.layer.12.output.LayerNorm.bias', 'encoder.layer.9.attention.self.value.weight', 'encoder.layer.5.attention.output.dense.weight', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.3.output.dense.weight', 'encoder.layer.0.attention.self.key.bias', 'encoder.layer.3.attention.self.query.weight', 'encoder.layer.7.attention.output.LayerNorm.bias', 'encoder.layer.17.output.LayerNorm.bias', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.6.attention.self.key.weight', 'encoder.layer.16.output.dense.bias', 'encoder.layer.10.attention.output.LayerNorm.weight', 'encoder.layer.2.attention.output.dense.weight', 'encoder.layer.13.output.LayerNorm.bias', 'encoder.layer.2.output.dense.weight', 'encoder.layer.19.output.LayerNorm.bias', 'encoder.layer.19.intermediate.dense.bias', 'encoder.layer.20.output.LayerNorm.bias', 'encoder.layer.14.attention.output.LayerNorm.bias', 'encoder.layer.19.attention.output.LayerNorm.bias', 'encoder.layer.16.output.LayerNorm.weight', 'encoder.layer.23.output.dense.bias', 'encoder.layer.11.attention.output.dense.bias', 'encoder.layer.17.attention.output.LayerNorm.bias', 'encoder.layer.18.attention.self.key.bias', 'encoder.layer.15.attention.self.value.bias', 'encoder.layer.0.attention.self.query.bias', 'encoder.layer.6.output.LayerNorm.bias', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.21.output.dense.weight', 'encoder.layer.10.attention.output.dense.weight', 'encoder.layer.14.attention.self.value.weight', 'encoder.layer.14.attention.self.value.bias', 'encoder.layer.9.output.dense.bias', 'encoder.layer.15.attention.self.value.weight', 'encoder.layer.2.attention.self.value.bias', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.17.attention.self.value.bias', 'encoder.layer.19.attention.self.query.weight', 'encoder.layer.3.attention.self.value.bias', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.21.attention.output.LayerNorm.bias', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.23.output.LayerNorm.bias', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.0.output.dense.bias', 'encoder.layer.12.output.dense.bias', 'encoder.layer.18.output.dense.bias', 'encoder.layer.21.output.LayerNorm.bias', 'encoder.layer.12.attention.self.query.weight', 'encoder.layer.23.attention.output.dense.weight', 'encoder.layer.13.attention.self.query.bias', 'encoder.layer.16.attention.self.key.weight', 'encoder.layer.11.output.dense.weight', 'encoder.layer.12.intermediate.dense.bias', 'encoder.layer.1.attention.self.value.weight', 'encoder.layer.9.attention.self.query.bias', 'encoder.layer.3.attention.self.key.weight', 'encoder.layer.18.attention.self.value.bias', 'encoder.layer.17.attention.self.query.weight', 'encoder.layer.19.attention.self.key.weight', 'encoder.layer.15.attention.output.LayerNorm.weight', 'encoder.layer.19.attention.self.value.weight', 'encoder.layer.12.intermediate.dense.weight', 'encoder.layer.6.attention.output.dense.weight', 'encoder.layer.17.attention.self.key.bias', 'encoder.layer.1.attention.self.query.bias', 'encoder.layer.19.output.LayerNorm.weight', 'encoder.layer.13.attention.output.dense.weight', 'pooler.dense.bias', 'encoder.layer.0.attention.self.value.weight', 'encoder.layer.22.attention.output.dense.weight', 'encoder.layer.12.attention.output.LayerNorm.weight', 'embeddings.position_embeddings.weight', 'encoder.layer.20.attention.output.LayerNorm.weight', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.19.attention.self.query.bias', 'encoder.layer.3.attention.self.query.bias', 'pooler.dense.weight', 'encoder.layer.22.output.dense.weight', 'encoder.layer.17.attention.self.query.bias', 'encoder.layer.17.intermediate.dense.weight', 'encoder.layer.22.attention.self.value.bias', 'encoder.layer.14.output.LayerNorm.bias', 'encoder.layer.22.output.dense.bias', 'encoder.layer.20.attention.self.query.weight', 'encoder.layer.1.output.dense.bias', 'encoder.layer.8.attention.self.value.bias', 'encoder.layer.23.attention.output.dense.bias', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.1.attention.output.dense.bias', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.20.attention.self.key.weight', 'encoder.layer.22.intermediate.dense.weight', 'encoder.layer.4.attention.output.LayerNorm.weight', 'encoder.layer.4.attention.output.dense.weight', 'encoder.layer.15.output.dense.weight', 'encoder.layer.10.attention.self.key.weight', 'encoder.layer.21.attention.self.key.bias', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.7.output.LayerNorm.weight', 'encoder.layer.20.attention.self.query.bias', 'encoder.layer.23.attention.self.query.weight', 'encoder.layer.20.attention.output.LayerNorm.bias', 'encoder.layer.5.attention.self.query.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Overwriting existing adapter 'ep'.
Overwriting existing adapter 'tp'.
Overwriting existing adapter 'es'.
Overwriting existing adapter 'ts'.
Overwriting existing adapter fusion module 'ep,tp,es,ts'
05/09/2022 22:59:37 - INFO - __main__ -   lang2id = None
05/09/2022 22:59:41 - INFO - __main__ -   Training/evaluation parameters Namespace(adam_epsilon=1e-08, cache_dir='', config_name='', data_dir=None, device=device(type='cuda'), do_eval=True, do_lower_case=False, do_train=False, doc_stride=128, eval_all_checkpoints=False, eval_lang='sw', evaluate_during_training=False, fp16=False, fp16_opt_level='O1', gradient_accumulation_steps=1, learning_rate=5e-05, local_rank=-1, logging_steps=50, max_answer_length=30, max_grad_norm=1.0, max_query_length=64, max_seq_length=384, max_steps=-1, model_name='xlm-KG', model_name_or_path='/cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//tydiqa/xlm-KG_LR8e-6_EPOCH2.0_maxlen384_batchsize4_gradacc4', model_type='xlm', modelkg_dir='/cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/adapter/xlmr_adapter', n_best_size=20, n_gpu=1, no_cuda=False, null_score_diff_threshold=0.0, num_train_epochs=3.0, output_dir='/cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//tydiqa/xlm-KG_LR8e-6_EPOCH2.0_maxlen384_batchsize4_gradacc4/predictions/tydiqa/', overwrite_cache=False, overwrite_output_dir=False, per_gpu_eval_batch_size=8, per_gpu_train_batch_size=8, predict_file='/cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/download//tydiqa//tydiqa-goldp-v1.1-dev/tydiqa.goldp.sw.dev.json', save_steps=50, seed=42, server_ip='', server_port='', threads=1, tokenizer_name='', train_file=None, train_lang='en', verbose_logging=False, version_2_with_negative=False, warmup_steps=0, weight_decay=0.0)
05/09/2022 22:59:41 - INFO - __main__ -   Loading checkpoint /cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//tydiqa/xlm-KG_LR8e-6_EPOCH2.0_maxlen384_batchsize4_gradacc4 for evaluation
05/09/2022 22:59:41 - INFO - __main__ -   Evaluate the following checkpoints: ['/cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//tydiqa/xlm-KG_LR8e-6_EPOCH2.0_maxlen384_batchsize4_gradacc4']
Some weights of the model checkpoint at /cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//tydiqa/xlm-KG_LR8e-6_EPOCH2.0_maxlen384_batchsize4_gradacc4 were not used when initializing XLMRobertaModel: ['base_model.encoder.layer.7.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.3.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.15.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.6.attention.self.value.bias', 'base_model.encoder.layer.7.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.9.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.13.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.16.intermediate.dense.weight', 'base_model.pooler.dense.weight', 'base_model.encoder.layer.10.attention.output.LayerNorm.weight', 'base_model.encoder.layer.4.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.10.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.11.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.17.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.5.attention.output.LayerNorm.bias', 'base_model.encoder.layer.8.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.7.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.17.intermediate.dense.bias', 'base_model.encoder.layer.4.attention.self.query.bias', 'base_model.encoder.layer.23.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.5.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.11.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.4.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.4.output.LayerNorm.weight', 'base_model.encoder.layer.9.attention.self.key.bias', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.21.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.21.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.14.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.9.intermediate.dense.bias', 'base_model.encoder.layer.18.attention.self.key.weight', 'base_model.encoder.layer.5.attention.output.LayerNorm.weight', 'base_model.encoder.layer.5.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.16.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.7.attention.self.value.weight', 'base_model.encoder.layer.15.output.dense.bias', 'base_model.encoder.layer.11.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.16.output.LayerNorm.weight', 'base_model.encoder.layer.12.output.LayerNorm.weight', 'base_model.encoder.layer.0.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.7.attention.self.key.bias', 'base_model.encoder.layer.18.output.LayerNorm.bias', 'base_model.encoder.layer.14.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.5.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.4.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.0.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.1.attention.self.key.weight', 'base_model.encoder.layer.13.attention.output.dense.weight', 'base_model.encoder.layer.22.output.dense.weight', 'base_model.encoder.layer.18.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.0.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.13.attention.output.dense.bias', 'base_model.encoder.layer.14.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.16.attention.self.value.weight', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.5.intermediate.dense.weight', 'base_model.encoder.layer.22.attention.output.LayerNorm.weight', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.3.attention.self.value.bias', 'base_model.encoder.layer.17.attention.output.dense.weight', 'base_model.encoder.layer.15.output.LayerNorm.weight', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.18.attention.output.LayerNorm.bias', 'base_model.encoder.layer.4.output.dense.weight', 'base_model.encoder.layer.8.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.21.output.LayerNorm.weight', 'base_model.encoder.layer.2.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.21.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.13.attention.self.value.weight', 'base_model.encoder.layer.20.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.10.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.12.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.5.intermediate.dense.bias', 'base_model.encoder.layer.15.attention.output.LayerNorm.weight', 'base_model.encoder.layer.12.attention.self.value.bias', 'base_model.encoder.layer.4.output.LayerNorm.bias', 'base_model.encoder.layer.1.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.12.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.13.attention.output.LayerNorm.weight', 'base_model.encoder.layer.22.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.2.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.8.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.17.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.7.output.LayerNorm.bias', 'base_model.encoder.layer.12.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.18.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.22.output.LayerNorm.bias', 'base_model.encoder.layer.0.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.20.output.LayerNorm.weight', 'base_model.encoder.layer.0.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.21.attention.self.query.weight', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.1.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.embeddings.LayerNorm.bias', 'base_model.encoder.layer.2.attention.self.value.bias', 'base_model.encoder.layer.4.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.0.attention.self.query.weight', 'base_model.encoder.layer.1.intermediate.dense.bias', 'base_model.encoder.layer.11.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.16.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.2.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.18.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.12.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.4.output.dense.bias', 'base_model.encoder.layer.8.output.dense.bias', 'base_model.encoder.layer.19.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.7.attention.output.dense.weight', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.1.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.19.attention.self.key.bias', 'base_model.encoder.layer.10.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.22.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.8.attention.self.key.weight', 'base_model.encoder.layer.16.output.adapters.es.adapter_down.0.weight', 'base_model.pooler.dense.bias', 'base_model.encoder.layer.14.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.14.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.11.output.LayerNorm.weight', 'base_model.encoder.layer.5.attention.self.value.weight', 'base_model.encoder.layer.18.attention.output.dense.weight', 'base_model.encoder.layer.2.output.dense.weight', 'base_model.encoder.layer.2.output.LayerNorm.bias', 'base_model.encoder.layer.6.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.10.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.18.attention.output.LayerNorm.weight', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.5.attention.self.key.weight', 'base_model.encoder.layer.8.attention.output.LayerNorm.bias', 'base_model.encoder.layer.22.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.23.output.dense.bias', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.16.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.1.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.2.output.adapters.ep.adapter_down.0.bias', 'qa_outputs.weight', 'base_model.encoder.layer.1.output.dense.weight', 'base_model.encoder.layer.20.attention.self.query.weight', 'base_model.encoder.layer.5.output.LayerNorm.weight', 'base_model.encoder.layer.11.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.18.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.1.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.14.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.10.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.8.attention.output.dense.weight', 'base_model.encoder.layer.6.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.21.output.dense.bias', 'base_model.encoder.layer.21.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.13.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.14.attention.self.key.weight', 'base_model.encoder.layer.15.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.16.intermediate.dense.bias', 'base_model.encoder.layer.20.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.18.attention.self.value.bias', 'base_model.encoder.layer.21.attention.output.LayerNorm.bias', 'base_model.encoder.layer.22.output.dense.bias', 'base_model.encoder.layer.21.attention.self.query.bias', 'base_model.encoder.layer.8.intermediate.dense.bias', 'base_model.encoder.layer.16.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.12.attention.self.value.weight', 'base_model.encoder.layer.20.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.15.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.18.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.8.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.0.attention.output.dense.bias', 'base_model.encoder.layer.0.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.6.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.9.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.23.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.2.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.16.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.10.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.11.intermediate.dense.bias', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.17.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.3.intermediate.dense.bias', 'base_model.encoder.layer.15.attention.self.key.bias', 'base_model.encoder.layer.2.output.dense.bias', 'base_model.encoder.layer.10.attention.output.dense.bias', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.9.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.10.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.4.attention.output.dense.bias', 'base_model.encoder.layer.8.output.LayerNorm.weight', 'base_model.encoder.layer.16.output.LayerNorm.bias', 'base_model.encoder.layer.20.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.20.attention.output.dense.bias', 'base_model.encoder.layer.20.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.17.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.19.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.23.attention.self.value.bias', 'base_model.encoder.layer.11.attention.self.key.weight', 'base_model.encoder.layer.3.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.2.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.12.attention.output.LayerNorm.weight', 'base_model.encoder.layer.10.attention.output.dense.weight', 'base_model.encoder.layer.4.attention.output.dense.weight', 'base_model.encoder.layer.8.attention.output.dense.bias', 'base_model.encoder.layer.1.attention.self.query.weight', 'base_model.encoder.layer.13.attention.self.value.bias', 'base_model.encoder.layer.5.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.15.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.13.attention.output.LayerNorm.bias', 'base_model.encoder.layer.21.attention.self.key.bias', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.17.output.LayerNorm.weight', 'base_model.encoder.layer.1.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.17.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.13.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.20.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.19.attention.self.query.bias', 'base_model.encoder.layer.1.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.3.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.17.attention.output.LayerNorm.weight', 'base_model.encoder.layer.2.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.21.output.dense.weight', 'base_model.encoder.layer.3.attention.output.LayerNorm.weight', 'base_model.encoder.layer.23.output.LayerNorm.weight', 'base_model.encoder.layer.19.output.dense.bias', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.16.attention.self.query.weight', 'base_model.encoder.layer.7.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.19.attention.self.value.weight', 'base_model.encoder.layer.11.output.dense.bias', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.23.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.7.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.19.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.20.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.6.attention.output.LayerNorm.weight', 'base_model.encoder.layer.3.attention.self.query.bias', 'base_model.encoder.layer.18.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.7.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.0.attention.output.LayerNorm.weight', 'base_model.encoder.layer.3.output.dense.weight', 'base_model.encoder.layer.1.output.LayerNorm.weight', 'base_model.encoder.layer.10.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.5.output.dense.weight', 'base_model.encoder.layer.5.attention.self.query.bias', 'base_model.encoder.layer.2.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.8.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.7.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.14.attention.self.query.bias', 'base_model.encoder.layer.6.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.10.attention.output.LayerNorm.bias', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.9.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.1.attention.self.key.bias', 'base_model.encoder.layer.15.attention.self.value.weight', 'base_model.encoder.layer.23.attention.self.query.weight', 'base_model.encoder.layer.3.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.6.attention.self.query.weight', 'base_model.encoder.layer.23.attention.self.key.bias', 'base_model.encoder.layer.3.intermediate.dense.weight', 'base_model.encoder.layer.17.output.LayerNorm.bias', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.18.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.0.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.18.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.6.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.20.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.8.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.10.attention.self.query.bias', 'base_model.encoder.layer.12.attention.self.key.bias', 'base_model.encoder.layer.13.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.19.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.22.attention.self.value.bias', 'base_model.encoder.layer.2.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.7.intermediate.dense.weight', 'base_model.encoder.layer.6.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.12.intermediate.dense.bias', 'base_model.encoder.layer.20.attention.self.value.bias', 'base_model.encoder.layer.0.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.20.attention.self.key.weight', 'base_model.encoder.layer.19.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.10.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.16.attention.output.dense.weight', 'base_model.encoder.layer.2.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.22.attention.self.key.weight', 'base_model.encoder.layer.13.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.22.attention.output.dense.bias', 'base_model.encoder.layer.17.output.dense.weight', 'base_model.encoder.layer.22.output.LayerNorm.weight', 'base_model.encoder.layer.6.attention.self.key.weight', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.19.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.12.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.7.attention.self.query.bias', 'base_model.encoder.layer.2.intermediate.dense.weight', 'base_model.encoder.layer.20.attention.output.LayerNorm.bias', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.11.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.9.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.6.attention.output.dense.bias', 'base_model.encoder.layer.0.output.LayerNorm.bias', 'base_model.encoder.layer.0.attention.self.key.bias', 'base_model.encoder.layer.5.attention.self.key.bias', 'base_model.encoder.layer.15.intermediate.dense.weight', 'base_model.encoder.layer.23.intermediate.dense.weight', 'base_model.encoder.layer.12.output.LayerNorm.bias', 'base_model.encoder.layer.3.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.7.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.0.output.LayerNorm.weight', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.20.attention.self.query.bias', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.18.output.LayerNorm.weight', 'base_model.encoder.layer.11.attention.self.key.bias', 'base_model.encoder.layer.2.attention.output.dense.weight', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.19.output.LayerNorm.bias', 'base_model.encoder.layer.6.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.17.attention.self.query.weight', 'base_model.encoder.layer.1.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.1.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.6.output.dense.weight', 'base_model.encoder.layer.14.attention.self.value.bias', 'base_model.encoder.layer.4.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.3.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.4.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.6.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.21.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.11.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.23.attention.output.LayerNorm.weight', 'base_model.encoder.layer.9.output.dense.bias', 'base_model.encoder.layer.0.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.13.output.LayerNorm.bias', 'base_model.encoder.layer.13.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.0.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.1.attention.self.value.bias', 'base_model.encoder.layer.16.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.10.attention.self.query.weight', 'base_model.encoder.layer.4.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.3.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.4.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.10.output.LayerNorm.weight', 'base_model.encoder.layer.21.output.LayerNorm.bias', 'base_model.encoder.layer.3.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.14.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.15.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.12.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.3.attention.output.dense.bias', 'base_model.encoder.layer.0.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.12.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.23.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.12.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.23.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.6.attention.self.value.weight', 'base_model.encoder.layer.18.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.13.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.7.attention.self.value.bias', 'base_model.encoder.layer.1.attention.output.LayerNorm.bias', 'base_model.encoder.layer.15.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.21.attention.output.dense.weight', 'base_model.encoder.layer.2.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.22.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.9.attention.self.key.weight', 'base_model.encoder.layer.11.attention.output.dense.weight', 'base_model.encoder.layer.12.attention.output.dense.weight', 'base_model.encoder.layer.15.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.8.intermediate.dense.weight', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.10.attention.self.value.bias', 'base_model.encoder.layer.10.output.dense.bias', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.7.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.13.output.dense.weight', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.6.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.22.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.20.attention.output.dense.weight', 'base_model.encoder.layer.18.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.14.attention.self.value.weight', 'base_model.encoder.layer.5.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.2.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.8.attention.self.key.bias', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.11.intermediate.dense.weight', 'base_model.encoder.layer.10.intermediate.dense.bias', 'base_model.encoder.layer.9.attention.output.dense.weight', 'base_model.encoder.layer.3.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.6.attention.self.key.bias', 'base_model.encoder.layer.8.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.16.attention.self.key.weight', 'base_model.encoder.layer.19.intermediate.dense.weight', 'base_model.encoder.layer.22.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.1.attention.output.dense.weight', 'base_model.encoder.layer.18.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.5.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.1.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.16.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.17.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.20.intermediate.dense.bias', 'base_model.encoder.layer.9.intermediate.dense.weight', 'base_model.encoder.layer.22.attention.output.dense.weight', 'base_model.encoder.layer.1.output.dense.bias', 'base_model.encoder.layer.16.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.12.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.1.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.10.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.21.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.22.intermediate.dense.weight', 'base_model.encoder.layer.9.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.19.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.9.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.11.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.1.intermediate.dense.weight', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.13.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.16.output.dense.weight', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.2.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.23.attention.self.key.weight', 'base_model.encoder.layer.7.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.12.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.15.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.16.attention.self.key.bias', 'base_model.encoder.layer.19.output.LayerNorm.weight', 'base_model.encoder.layer.9.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.13.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.22.attention.self.query.bias', 'base_model.encoder.layer.22.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.11.attention.self.query.bias', 'base_model.encoder.layer.23.attention.output.dense.bias', 'base_model.encoder.layer.5.output.LayerNorm.bias', 'base_model.encoder.layer.21.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.1.attention.self.value.weight', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.1.attention.output.LayerNorm.weight', 'base_model.encoder.layer.7.output.LayerNorm.weight', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.15.attention.output.LayerNorm.bias', 'base_model.encoder.layer.23.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.10.attention.self.key.bias', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.5.attention.output.dense.weight', 'base_model.encoder.layer.10.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.12.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.7.attention.output.LayerNorm.bias', 'base_model.encoder.layer.19.output.dense.weight', 'base_model.encoder.layer.5.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.4.attention.self.value.weight', 'base_model.encoder.layer.10.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.13.output.LayerNorm.weight', 'base_model.encoder.layer.6.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.18.intermediate.dense.bias', 'base_model.encoder.layer.21.intermediate.dense.bias', 'base_model.encoder.layer.0.intermediate.dense.weight', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.21.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.14.attention.output.LayerNorm.bias', 'base_model.encoder.layer.0.attention.output.LayerNorm.bias', 'base_model.encoder.layer.2.output.LayerNorm.weight', 'base_model.encoder.layer.15.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.9.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.19.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.13.output.dense.bias', 'base_model.encoder.layer.22.intermediate.dense.bias', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.15.attention.self.query.weight', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.8.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.7.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.6.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.5.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.15.attention.output.dense.weight', 'base_model.encoder.layer.11.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.14.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.3.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.6.attention.self.query.bias', 'base_model.encoder.layer.0.attention.self.key.weight', 'base_model.embeddings.token_type_embeddings.weight', 'base_model.encoder.layer.1.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.3.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.1.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.7.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.16.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.4.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.2.attention.output.dense.bias', 'base_model.encoder.layer.3.attention.output.dense.weight', 'base_model.encoder.layer.18.attention.output.dense.bias', 'base_model.encoder.layer.9.attention.output.dense.bias', 'base_model.encoder.layer.21.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.1.attention.self.query.bias', 'base_model.encoder.layer.3.attention.self.key.bias', 'base_model.encoder.layer.19.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.18.output.dense.weight', 'base_model.encoder.layer.3.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.13.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.20.attention.self.value.weight', 'base_model.encoder.layer.3.output.dense.bias', 'base_model.encoder.layer.9.attention.output.LayerNorm.weight', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.2.attention.output.LayerNorm.bias', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.4.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.14.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.10.attention.self.value.weight', 'base_model.encoder.layer.20.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.23.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.16.attention.self.query.bias', 'base_model.encoder.layer.14.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.20.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.4.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.23.attention.output.dense.weight', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.9.attention.self.value.bias', 'base_model.encoder.layer.12.output.dense.weight', 'base_model.encoder.layer.6.intermediate.dense.weight', 'base_model.encoder.layer.22.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.11.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.10.output.dense.weight', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.18.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.4.attention.self.key.weight', 'base_model.encoder.layer.14.output.LayerNorm.bias', 'base_model.encoder.layer.12.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.22.attention.output.LayerNorm.bias', 'base_model.encoder.layer.23.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.16.output.dense.bias', 'base_model.encoder.layer.3.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.4.attention.output.LayerNorm.weight', 'base_model.encoder.layer.13.attention.self.key.weight', 'base_model.encoder.layer.20.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.19.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.16.attention.output.dense.bias', 'base_model.encoder.layer.0.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.12.attention.self.query.bias', 'base_model.encoder.layer.0.output.dense.bias', 'base_model.encoder.layer.5.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.0.output.dense.weight', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.23.output.dense.weight', 'base_model.encoder.layer.6.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.17.intermediate.dense.weight', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.5.output.dense.bias', 'base_model.encoder.layer.8.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.23.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.18.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.11.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.5.attention.output.dense.bias', 'base_model.encoder.layer.14.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.6.attention.output.dense.weight', 'base_model.encoder.layer.22.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.4.attention.self.key.bias', 'base_model.encoder.layer.4.intermediate.dense.weight', 'base_model.encoder.layer.9.attention.self.query.bias', 'base_model.encoder.layer.8.attention.self.value.bias', 'base_model.encoder.layer.14.output.dense.weight', 'base_model.encoder.layer.11.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.1.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.9.output.LayerNorm.weight', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.16.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.16.attention.output.LayerNorm.weight', 'base_model.encoder.layer.9.attention.self.value.weight', 'base_model.encoder.layer.16.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.20.intermediate.dense.weight', 'base_model.encoder.layer.6.attention.output.LayerNorm.bias', 'base_model.encoder.layer.7.attention.self.key.weight', 'base_model.encoder.layer.5.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.14.attention.self.key.bias', 'base_model.encoder.layer.0.attention.self.value.bias', 'base_model.encoder.layer.3.attention.output.LayerNorm.bias', 'base_model.encoder.layer.0.attention.self.query.bias', 'base_model.encoder.layer.5.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.6.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.16.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.17.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.23.attention.self.query.bias', 'base_model.encoder.layer.14.intermediate.dense.weight', 'base_model.encoder.layer.5.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.13.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.10.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.15.attention.self.query.bias', 'base_model.encoder.layer.5.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.3.output.LayerNorm.weight', 'base_model.encoder.layer.12.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.4.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.9.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.0.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.15.attention.self.key.weight', 'base_model.encoder.layer.17.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.17.attention.output.LayerNorm.bias', 'base_model.encoder.layer.20.attention.output.LayerNorm.weight', 'base_model.encoder.layer.21.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.22.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.22.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.13.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.20.output.dense.bias', 'base_model.encoder.layer.7.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.17.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.8.attention.self.query.weight', 'base_model.encoder.layer.8.attention.self.query.bias', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.11.attention.self.value.weight', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.18.attention.self.value.weight', 'base_model.encoder.layer.23.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.16.attention.self.value.bias', 'base_model.encoder.layer.23.attention.self.value.weight', 'base_model.encoder.layer.7.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.17.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.22.attention.self.key.bias', 'base_model.encoder.layer.19.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.1.attention.output.dense.bias', 'base_model.encoder.layer.7.attention.self.query.weight', 'base_model.encoder.layer.5.attention.self.value.bias', 'base_model.encoder.layer.20.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.2.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.0.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.4.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.21.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.17.attention.self.value.bias', 'base_model.encoder.layer.21.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.21.attention.self.key.weight', 'base_model.encoder.layer.20.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.15.attention.self.value.bias', 'base_model.encoder.layer.22.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.0.attention.output.dense.weight', 'base_model.encoder.layer.11.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.14.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.16.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.7.attention.output.LayerNorm.weight', 'base_model.encoder.layer.9.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.12.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.9.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.16.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.17.attention.self.query.bias', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.18.attention.self.query.bias', 'base_model.encoder.layer.8.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.19.attention.output.dense.weight', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.18.attention.self.query.weight', 'base_model.encoder.layer.15.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.23.output.LayerNorm.bias', 'base_model.encoder.layer.4.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.18.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.13.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.11.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.20.output.LayerNorm.bias', 'base_model.encoder.layer.19.intermediate.dense.bias', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.2.attention.self.query.bias', 'base_model.encoder.layer.11.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.5.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.19.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.8.attention.self.value.weight', 'base_model.encoder.layer.17.attention.self.key.weight', 'base_model.encoder.layer.22.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.23.attention.output.LayerNorm.bias', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.13.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.23.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.2.attention.self.query.weight', 'base_model.embeddings.position_ids', 'base_model.encoder.layer.10.intermediate.dense.weight', 'base_model.encoder.layer.23.intermediate.dense.bias', 'base_model.encoder.layer.14.intermediate.dense.bias', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.20.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.17.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.21.attention.self.value.bias', 'base_model.encoder.layer.12.attention.output.dense.bias', 'base_model.encoder.layer.4.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.6.intermediate.dense.bias', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.17.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.15.output.dense.weight', 'base_model.encoder.layer.12.attention.self.key.weight', 'base_model.encoder.layer.9.attention.self.query.weight', 'base_model.encoder.layer.0.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.16.attention.output.LayerNorm.bias', 'base_model.encoder.layer.19.attention.self.query.weight', 'base_model.encoder.layer.22.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.6.output.dense.bias', 'base_model.encoder.layer.13.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.19.attention.self.key.weight', 'base_model.encoder.layer.8.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.11.attention.output.LayerNorm.bias', 'base_model.encoder.layer.9.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.2.intermediate.dense.bias', 'base_model.encoder.layer.13.attention.self.query.weight', 'base_model.encoder.layer.4.attention.output.LayerNorm.bias', 'base_model.encoder.layer.20.attention.self.key.bias', 'base_model.encoder.layer.17.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.15.attention.output.dense.bias', 'base_model.encoder.layer.2.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.3.attention.self.key.weight', 'base_model.encoder.layer.3.attention.self.query.weight', 'base_model.encoder.layer.8.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.11.output.dense.weight', 'base_model.encoder.layer.12.attention.self.query.weight', 'base_model.encoder.layer.7.intermediate.dense.bias', 'base_model.encoder.layer.23.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.21.attention.output.LayerNorm.weight', 'base_model.encoder.layer.14.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.21.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.6.output.LayerNorm.weight', 'base_model.encoder.layer.6.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.1.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.18.attention.self.key.bias', 'base_model.encoder.layer.23.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.9.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.19.attention.output.dense.bias', 'base_model.encoder.layer.9.attention.output.LayerNorm.bias', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.14.output.dense.bias', 'base_model.encoder.layer.18.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.3.output.LayerNorm.bias', 'base_model.encoder.layer.11.attention.output.dense.bias', 'base_model.encoder.layer.2.attention.self.key.weight', 'base_model.encoder.layer.4.attention.self.query.weight', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.23.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.23.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.1.output.LayerNorm.bias', 'base_model.encoder.layer.14.output.LayerNorm.weight', 'base_model.encoder.layer.8.output.dense.weight', 'base_model.encoder.layer.10.output.LayerNorm.bias', 'base_model.encoder.layer.10.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.1.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.19.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.22.attention.self.query.weight', 'base_model.encoder.layer.19.output.adapters.es.adapter_down.0.bias', 'base_model.embeddings.LayerNorm.weight', 'base_model.encoder.layer.7.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.4.attention.self.value.bias', 'base_model.encoder.layer.15.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.8.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.23.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.11.attention.output.LayerNorm.weight', 'base_model.encoder.layer.18.output.dense.bias', 'base_model.encoder.layer.18.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.5.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.12.output.dense.bias', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.20.output.dense.weight', 'base_model.encoder.layer.21.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.15.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.13.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.13.attention.self.query.bias', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.19.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.22.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.17.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.4.intermediate.dense.bias', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.12.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.17.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.19.attention.output.LayerNorm.weight', 'base_model.encoder.layer.10.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.10.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.5.attention.self.query.weight', 'base_model.encoder.layer.8.attention.output.LayerNorm.weight', 'base_model.encoder.layer.14.attention.output.LayerNorm.weight', 'base_model.encoder.layer.6.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.21.intermediate.dense.weight', 'base_model.encoder.layer.8.output.LayerNorm.bias', 'base_model.encoder.layer.14.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.7.attention.output.dense.bias', 'base_model.encoder.layer.9.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.20.output.adapters.tp.adapter_up.bias', 'base_model.embeddings.word_embeddings.weight', 'base_model.encoder.layer.6.output.LayerNorm.bias', 'base_model.encoder.layer.13.intermediate.dense.weight', 'base_model.encoder.layer.17.attention.self.value.weight', 'base_model.encoder.layer.3.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.9.output.dense.weight', 'base_model.encoder.layer.11.attention.self.query.weight', 'base_model.encoder.layer.14.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.embeddings.position_embeddings.weight', 'base_model.encoder.layer.2.attention.output.LayerNorm.weight', 'base_model.encoder.layer.3.attention.self.value.weight', 'base_model.encoder.layer.0.attention.self.value.weight', 'base_model.encoder.layer.2.attention.self.key.bias', 'base_model.encoder.layer.17.output.dense.bias', 'base_model.encoder.layer.19.attention.output.LayerNorm.bias', 'base_model.encoder.layer.21.attention.self.value.weight', 'base_model.encoder.layer.7.output.dense.bias', 'base_model.encoder.layer.10.attention.self.key.weight', 'qa_outputs.bias', 'base_model.encoder.layer.16.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.17.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.0.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.14.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.15.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.20.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.14.attention.output.dense.weight', 'base_model.encoder.layer.22.attention.self.value.weight', 'base_model.encoder.layer.0.intermediate.dense.bias', 'base_model.encoder.layer.11.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.2.attention.self.value.weight', 'base_model.encoder.layer.6.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.13.intermediate.dense.bias', 'base_model.encoder.layer.18.intermediate.dense.weight', 'base_model.encoder.layer.21.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.12.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.15.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.19.attention.self.value.bias', 'base_model.encoder.layer.8.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.14.attention.self.query.weight', 'base_model.encoder.layer.3.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.4.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.9.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.15.intermediate.dense.bias', 'base_model.encoder.layer.15.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.7.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.11.attention.self.value.bias', 'base_model.encoder.layer.15.output.LayerNorm.bias', 'base_model.encoder.layer.17.attention.self.key.bias', 'base_model.encoder.layer.7.output.dense.weight', 'base_model.encoder.layer.8.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.22.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.8.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.14.attention.output.dense.bias', 'base_model.encoder.layer.2.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.3.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.15.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.12.intermediate.dense.weight', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.5.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.12.attention.output.LayerNorm.bias', 'base_model.encoder.layer.21.attention.output.dense.bias', 'base_model.encoder.layer.11.output.LayerNorm.bias', 'base_model.encoder.layer.13.attention.self.key.bias', 'base_model.encoder.layer.19.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.21.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.9.output.LayerNorm.bias', 'base_model.encoder.layer.17.attention.output.dense.bias']
- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of XLMRobertaModel were not initialized from the model checkpoint at /cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//tydiqa/xlm-KG_LR8e-6_EPOCH2.0_maxlen384_batchsize4_gradacc4 and are newly initialized: ['encoder.layer.8.output.dense.bias', 'encoder.layer.13.attention.output.dense.bias', 'encoder.layer.22.attention.self.query.bias', 'encoder.layer.7.attention.self.value.bias', 'encoder.layer.23.output.LayerNorm.weight', 'encoder.layer.18.intermediate.dense.bias', 'encoder.layer.10.attention.self.value.weight', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.5.output.dense.weight', 'encoder.layer.12.output.LayerNorm.weight', 'encoder.layer.18.attention.output.dense.weight', 'encoder.layer.6.output.dense.bias', 'encoder.layer.18.output.LayerNorm.weight', 'encoder.layer.22.output.LayerNorm.bias', 'encoder.layer.20.attention.output.dense.weight', 'encoder.layer.13.attention.self.query.weight', 'encoder.layer.14.output.dense.bias', 'encoder.layer.10.attention.output.dense.bias', 'encoder.layer.23.attention.output.LayerNorm.bias', 'encoder.layer.16.attention.output.LayerNorm.weight', 'encoder.layer.11.attention.self.key.bias', 'encoder.layer.8.attention.self.key.weight', 'encoder.layer.14.intermediate.dense.weight', 'encoder.layer.19.intermediate.dense.weight', 'encoder.layer.7.attention.output.dense.weight', 'encoder.layer.0.attention.output.dense.weight', 'embeddings.LayerNorm.weight', 'encoder.layer.16.intermediate.dense.bias', 'encoder.layer.23.attention.self.value.weight', 'encoder.layer.18.attention.self.value.weight', 'encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.layer.2.attention.self.value.weight', 'encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.layer.9.attention.output.dense.bias', 'encoder.layer.15.attention.self.query.weight', 'encoder.layer.6.attention.output.LayerNorm.bias', 'encoder.layer.21.intermediate.dense.weight', 'encoder.layer.1.attention.self.value.bias', 'encoder.layer.1.attention.self.query.weight', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.9.attention.output.LayerNorm.bias', 'encoder.layer.14.attention.self.key.weight', 'encoder.layer.6.attention.self.query.weight', 'encoder.layer.18.attention.output.dense.bias', 'encoder.layer.7.output.LayerNorm.bias', 'encoder.layer.0.attention.output.dense.bias', 'encoder.layer.7.attention.self.key.bias', 'encoder.layer.22.output.LayerNorm.weight', 'encoder.layer.7.attention.self.query.bias', 'encoder.layer.6.attention.self.query.bias', 'encoder.layer.8.attention.output.LayerNorm.bias', 'encoder.layer.16.attention.self.value.weight', 'encoder.layer.4.attention.self.query.bias', 'encoder.layer.21.attention.output.LayerNorm.weight', 'encoder.layer.10.attention.self.query.weight', 'encoder.layer.0.attention.self.value.bias', 'encoder.layer.16.attention.self.key.bias', 'encoder.layer.5.output.dense.bias', 'encoder.layer.12.attention.output.dense.bias', 'encoder.layer.15.output.dense.bias', 'encoder.layer.21.attention.self.query.weight', 'encoder.layer.16.output.dense.weight', 'encoder.layer.2.attention.self.key.weight', 'encoder.layer.7.attention.output.dense.bias', 'encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.8.output.dense.weight', 'encoder.layer.14.output.LayerNorm.weight', 'encoder.layer.21.intermediate.dense.bias', 'encoder.layer.16.intermediate.dense.weight', 'encoder.layer.20.attention.self.value.bias', 'encoder.layer.7.attention.self.query.weight', 'encoder.layer.11.attention.self.value.weight', 'encoder.layer.5.attention.self.key.bias', 'encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.layer.2.attention.self.key.bias', 'encoder.layer.4.attention.self.key.bias', 'encoder.layer.11.attention.self.key.weight', 'encoder.layer.6.attention.self.key.bias', 'encoder.layer.21.output.dense.bias', 'encoder.layer.23.output.dense.weight', 'encoder.layer.17.attention.output.dense.weight', 'encoder.layer.8.attention.self.query.bias', 'encoder.layer.9.output.LayerNorm.bias', 'encoder.layer.21.output.LayerNorm.weight', 'encoder.layer.11.attention.self.query.weight', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.13.intermediate.dense.weight', 'encoder.layer.8.output.LayerNorm.bias', 'encoder.layer.15.intermediate.dense.weight', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.12.attention.output.dense.weight', 'encoder.layer.14.attention.self.query.weight', 'encoder.layer.8.attention.output.LayerNorm.weight', 'embeddings.word_embeddings.weight', 'encoder.layer.2.attention.self.query.bias', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.8.attention.self.value.weight', 'encoder.layer.5.attention.output.dense.bias', 'encoder.layer.16.attention.output.dense.weight', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.22.attention.self.value.weight', 'encoder.layer.10.intermediate.dense.weight', 'encoder.layer.15.attention.output.dense.weight', 'encoder.layer.13.output.LayerNorm.weight', 'encoder.layer.1.attention.self.key.bias', 'encoder.layer.9.output.LayerNorm.weight', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.16.attention.self.query.bias', 'encoder.layer.14.attention.output.dense.bias', 'encoder.layer.17.output.dense.weight', 'encoder.layer.19.attention.output.dense.weight', 'encoder.layer.12.attention.self.query.bias', 'encoder.layer.17.attention.self.key.weight', 'encoder.layer.15.attention.self.key.bias', 'encoder.layer.1.attention.self.key.weight', 'encoder.layer.20.attention.self.value.weight', 'encoder.layer.15.attention.self.query.bias', 'encoder.layer.19.attention.self.value.bias', 'encoder.layer.17.attention.output.LayerNorm.weight', 'encoder.layer.17.attention.self.value.weight', 'encoder.layer.8.attention.output.dense.bias', 'encoder.layer.18.output.LayerNorm.bias', 'encoder.layer.13.attention.self.key.bias', 'encoder.layer.12.attention.output.LayerNorm.bias', 'encoder.layer.20.intermediate.dense.weight', 'encoder.layer.8.output.LayerNorm.weight', 'encoder.layer.10.attention.self.key.bias', 'encoder.layer.17.intermediate.dense.bias', 'encoder.layer.17.output.LayerNorm.weight', 'encoder.layer.15.output.LayerNorm.bias', 'encoder.layer.19.output.dense.weight', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.4.attention.self.value.bias', 'encoder.layer.12.attention.self.key.weight', 'encoder.layer.10.attention.self.query.bias', 'encoder.layer.8.attention.output.dense.weight', 'encoder.layer.15.attention.output.LayerNorm.bias', 'encoder.layer.17.attention.output.dense.bias', 'encoder.layer.12.output.dense.weight', 'encoder.layer.3.output.dense.bias', 'encoder.layer.13.output.dense.bias', 'encoder.layer.13.attention.self.key.weight', 'encoder.layer.16.output.LayerNorm.bias', 'encoder.layer.10.output.dense.bias', 'encoder.layer.23.intermediate.dense.weight', 'encoder.layer.5.attention.self.value.weight', 'encoder.layer.6.attention.self.value.bias', 'encoder.layer.7.attention.output.LayerNorm.weight', 'encoder.layer.10.attention.output.LayerNorm.bias', 'encoder.layer.13.attention.output.LayerNorm.weight', 'encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.9.attention.self.key.bias', 'encoder.layer.16.attention.output.LayerNorm.bias', 'encoder.layer.23.attention.self.key.weight', 'encoder.layer.14.output.dense.weight', 'encoder.layer.5.attention.self.key.weight', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.6.attention.self.value.weight', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.6.attention.output.dense.bias', 'encoder.layer.10.output.LayerNorm.weight', 'encoder.layer.12.attention.self.key.bias', 'encoder.layer.2.attention.output.LayerNorm.weight', 'encoder.layer.11.output.LayerNorm.bias', 'encoder.layer.11.attention.output.LayerNorm.weight', 'encoder.layer.23.attention.self.value.bias', 'encoder.layer.4.attention.output.LayerNorm.bias', 'encoder.layer.11.output.LayerNorm.weight', 'encoder.layer.21.attention.output.dense.bias', 'encoder.layer.18.output.dense.weight', 'encoder.layer.21.attention.output.dense.weight', 'encoder.layer.20.attention.self.key.bias', 'encoder.layer.17.output.dense.bias', 'encoder.layer.18.attention.output.LayerNorm.weight', 'encoder.layer.23.intermediate.dense.bias', 'encoder.layer.11.attention.self.query.bias', 'encoder.layer.9.attention.output.LayerNorm.weight', 'encoder.layer.4.attention.self.value.weight', 'encoder.layer.14.attention.output.dense.weight', 'encoder.layer.14.attention.self.query.bias', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.1.attention.output.dense.weight', 'encoder.layer.9.attention.self.query.weight', 'encoder.layer.22.attention.self.query.weight', 'encoder.layer.22.attention.output.LayerNorm.bias', 'encoder.layer.7.intermediate.dense.bias', 'encoder.layer.16.attention.self.query.weight', 'encoder.layer.19.attention.self.key.bias', 'encoder.layer.15.output.LayerNorm.weight', 'encoder.layer.7.attention.self.key.weight', 'encoder.layer.13.attention.self.value.bias', 'encoder.layer.2.attention.output.dense.bias', 'encoder.layer.3.attention.self.key.bias', 'encoder.layer.9.attention.self.value.bias', 'encoder.layer.11.attention.self.value.bias', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.18.intermediate.dense.weight', 'encoder.layer.5.attention.output.LayerNorm.weight', 'encoder.layer.15.attention.self.key.weight', 'encoder.layer.13.attention.self.value.weight', 'encoder.layer.13.attention.output.LayerNorm.bias', 'encoder.layer.18.attention.self.key.weight', 'encoder.layer.19.attention.output.dense.bias', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.23.attention.output.LayerNorm.weight', 'encoder.layer.21.attention.self.key.weight', 'encoder.layer.22.attention.self.key.weight', 'encoder.layer.23.attention.self.query.bias', 'encoder.layer.13.output.dense.weight', 'encoder.layer.14.intermediate.dense.bias', 'encoder.layer.20.output.LayerNorm.weight', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.2.attention.output.LayerNorm.bias', 'encoder.layer.4.output.dense.bias', 'encoder.layer.18.attention.self.query.bias', 'encoder.layer.4.attention.self.query.weight', 'encoder.layer.5.attention.self.value.bias', 'encoder.layer.4.output.dense.weight', 'encoder.layer.10.output.LayerNorm.bias', 'encoder.layer.11.output.dense.bias', 'encoder.layer.3.attention.self.value.weight', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.5.attention.self.query.bias', 'encoder.layer.10.output.dense.weight', 'encoder.layer.14.attention.output.LayerNorm.weight', 'encoder.layer.3.attention.output.dense.bias', 'encoder.layer.6.output.dense.weight', 'encoder.layer.16.attention.self.value.bias', 'encoder.layer.0.attention.self.key.weight', 'encoder.layer.22.intermediate.dense.bias', 'encoder.layer.22.attention.output.dense.bias', 'encoder.layer.10.attention.self.value.bias', 'encoder.layer.21.attention.self.query.bias', 'encoder.layer.15.attention.output.dense.bias', 'encoder.layer.4.attention.self.key.weight', 'encoder.layer.8.attention.self.query.weight', 'encoder.layer.9.attention.self.key.weight', 'encoder.layer.12.attention.self.value.weight', 'encoder.layer.22.attention.output.LayerNorm.weight', 'embeddings.LayerNorm.bias', 'encoder.layer.19.attention.output.LayerNorm.weight', 'encoder.layer.16.attention.output.dense.bias', 'encoder.layer.13.intermediate.dense.bias', 'encoder.layer.4.attention.output.dense.bias', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.0.attention.output.LayerNorm.weight', 'encoder.layer.0.output.dense.weight', 'encoder.layer.1.attention.output.LayerNorm.weight', 'encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.layer.7.attention.self.value.weight', 'encoder.layer.7.output.dense.bias', 'encoder.layer.1.output.dense.weight', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.8.attention.self.key.bias', 'encoder.layer.9.attention.output.dense.weight', 'encoder.layer.20.output.dense.bias', 'encoder.layer.22.attention.self.key.bias', 'encoder.layer.9.output.dense.weight', 'encoder.layer.18.attention.self.query.weight', 'encoder.layer.23.attention.self.key.bias', 'encoder.layer.5.output.LayerNorm.bias', 'encoder.layer.18.attention.output.LayerNorm.bias', 'encoder.layer.20.intermediate.dense.bias', 'encoder.layer.7.output.dense.weight', 'encoder.layer.2.attention.self.query.weight', 'encoder.layer.2.output.dense.bias', 'encoder.layer.12.attention.self.value.bias', 'encoder.layer.15.intermediate.dense.bias', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.3.attention.output.dense.weight', 'encoder.layer.21.attention.self.value.bias', 'embeddings.token_type_embeddings.weight', 'encoder.layer.21.attention.self.value.weight', 'encoder.layer.11.attention.output.dense.weight', 'encoder.layer.19.output.dense.bias', 'encoder.layer.20.attention.output.dense.bias', 'encoder.layer.14.attention.self.key.bias', 'encoder.layer.6.attention.output.LayerNorm.weight', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.layer.20.output.dense.weight', 'encoder.layer.0.attention.self.query.weight', 'encoder.layer.12.output.LayerNorm.bias', 'encoder.layer.9.attention.self.value.weight', 'encoder.layer.5.attention.output.dense.weight', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.3.output.dense.weight', 'encoder.layer.0.attention.self.key.bias', 'encoder.layer.3.attention.self.query.weight', 'encoder.layer.7.attention.output.LayerNorm.bias', 'encoder.layer.17.output.LayerNorm.bias', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.6.attention.self.key.weight', 'encoder.layer.16.output.dense.bias', 'encoder.layer.10.attention.output.LayerNorm.weight', 'encoder.layer.2.attention.output.dense.weight', 'encoder.layer.13.output.LayerNorm.bias', 'encoder.layer.2.output.dense.weight', 'encoder.layer.19.output.LayerNorm.bias', 'encoder.layer.19.intermediate.dense.bias', 'encoder.layer.20.output.LayerNorm.bias', 'encoder.layer.14.attention.output.LayerNorm.bias', 'encoder.layer.19.attention.output.LayerNorm.bias', 'encoder.layer.16.output.LayerNorm.weight', 'encoder.layer.23.output.dense.bias', 'encoder.layer.11.attention.output.dense.bias', 'encoder.layer.17.attention.output.LayerNorm.bias', 'encoder.layer.18.attention.self.key.bias', 'encoder.layer.15.attention.self.value.bias', 'encoder.layer.0.attention.self.query.bias', 'encoder.layer.6.output.LayerNorm.bias', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.21.output.dense.weight', 'encoder.layer.10.attention.output.dense.weight', 'encoder.layer.14.attention.self.value.weight', 'encoder.layer.14.attention.self.value.bias', 'encoder.layer.9.output.dense.bias', 'encoder.layer.15.attention.self.value.weight', 'encoder.layer.2.attention.self.value.bias', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.17.attention.self.value.bias', 'encoder.layer.19.attention.self.query.weight', 'encoder.layer.3.attention.self.value.bias', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.21.attention.output.LayerNorm.bias', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.23.output.LayerNorm.bias', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.0.output.dense.bias', 'encoder.layer.12.output.dense.bias', 'encoder.layer.18.output.dense.bias', 'encoder.layer.21.output.LayerNorm.bias', 'encoder.layer.12.attention.self.query.weight', 'encoder.layer.23.attention.output.dense.weight', 'encoder.layer.13.attention.self.query.bias', 'encoder.layer.16.attention.self.key.weight', 'encoder.layer.11.output.dense.weight', 'encoder.layer.12.intermediate.dense.bias', 'encoder.layer.1.attention.self.value.weight', 'encoder.layer.9.attention.self.query.bias', 'encoder.layer.3.attention.self.key.weight', 'encoder.layer.18.attention.self.value.bias', 'encoder.layer.17.attention.self.query.weight', 'encoder.layer.19.attention.self.key.weight', 'encoder.layer.15.attention.output.LayerNorm.weight', 'encoder.layer.19.attention.self.value.weight', 'encoder.layer.12.intermediate.dense.weight', 'encoder.layer.6.attention.output.dense.weight', 'encoder.layer.17.attention.self.key.bias', 'encoder.layer.1.attention.self.query.bias', 'encoder.layer.19.output.LayerNorm.weight', 'encoder.layer.13.attention.output.dense.weight', 'pooler.dense.bias', 'encoder.layer.0.attention.self.value.weight', 'encoder.layer.22.attention.output.dense.weight', 'encoder.layer.12.attention.output.LayerNorm.weight', 'embeddings.position_embeddings.weight', 'encoder.layer.20.attention.output.LayerNorm.weight', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.19.attention.self.query.bias', 'encoder.layer.3.attention.self.query.bias', 'pooler.dense.weight', 'encoder.layer.22.output.dense.weight', 'encoder.layer.17.attention.self.query.bias', 'encoder.layer.17.intermediate.dense.weight', 'encoder.layer.22.attention.self.value.bias', 'encoder.layer.14.output.LayerNorm.bias', 'encoder.layer.22.output.dense.bias', 'encoder.layer.20.attention.self.query.weight', 'encoder.layer.1.output.dense.bias', 'encoder.layer.8.attention.self.value.bias', 'encoder.layer.23.attention.output.dense.bias', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.1.attention.output.dense.bias', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.20.attention.self.key.weight', 'encoder.layer.22.intermediate.dense.weight', 'encoder.layer.4.attention.output.LayerNorm.weight', 'encoder.layer.4.attention.output.dense.weight', 'encoder.layer.15.output.dense.weight', 'encoder.layer.10.attention.self.key.weight', 'encoder.layer.21.attention.self.key.bias', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.7.output.LayerNorm.weight', 'encoder.layer.20.attention.self.query.bias', 'encoder.layer.23.attention.self.query.weight', 'encoder.layer.20.attention.output.LayerNorm.bias', 'encoder.layer.5.attention.self.query.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Overwriting existing adapter 'ep'.
Overwriting existing adapter 'tp'.
Overwriting existing adapter 'es'.
Overwriting existing adapter 'ts'.
Overwriting existing adapter fusion module 'ep,tp,es,ts'
05/09/2022 23:00:08 - INFO - __main__ -   Creating features from dataset file at .
/cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//tydiqa/xlm-KG_LR8e-6_EPOCH2.0_maxlen384_batchsize4_gradacc4
XLMConfig {
  "architectures": [
    "XLMRobertaForMaskedLM"
  ],
  "asm": false,
  "attention_dropout": 0.1,
  "attention_probs_dropout_prob": 0.1,
  "bos_index": 0,
  "bos_token_id": 0,
  "causal": false,
  "dropout": 0.1,
  "emb_dim": 1024,
  "embed_init_std": 0.02209708691207961,
  "end_n_top": 5,
  "eos_index": 1,
  "eos_token_id": 2,
  "gelu_activation": true,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "init_std": 0.02,
  "initializer_range": 0.02,
  "intermediate_size": 4096,
  "is_encoder": true,
  "lang_id": 0,
  "layer_norm_eps": 1e-05,
  "mask_index": 5,
  "mask_token_id": 0,
  "max_position_embeddings": 514,
  "model_type": "xlm",
  "n_heads": 16,
  "n_langs": 1,
  "n_layers": 24,
  "output_past": true,
  "pad_index": 2,
  "pad_token_id": 1,
  "sinusoidal_embeddings": false,
  "start_n_top": 5,
  "summary_activation": null,
  "summary_first_dropout": 0.1,
  "summary_proj_to_labels": true,
  "summary_type": "first",
  "summary_use_proj": true,
  "transformers_version": "4.17.0",
  "type_vocab_size": 1,
  "unk_index": 3,
  "use_lang_emb": false,
  "vocab_size": 250002
}

  0%|          | 0/499 [00:00<?, ?it/s]100%|██████████| 499/499 [00:00<00:00, 7877.98it/s]
convert squad examples to features:   0%|          | 0/499 [00:00<?, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.
convert squad examples to features:   7%|▋         | 33/499 [00:00<00:02, 223.28it/s]convert squad examples to features:  19%|█▉        | 97/499 [00:00<00:01, 358.40it/s]convert squad examples to features:  32%|███▏      | 161/499 [00:00<00:00, 444.22it/s]convert squad examples to features:  45%|████▌     | 225/499 [00:00<00:00, 429.07it/s]convert squad examples to features:  54%|█████▍    | 269/499 [00:00<00:00, 423.43it/s]convert squad examples to features:  64%|██████▍   | 321/499 [00:00<00:00, 417.59it/s]convert squad examples to features:  77%|███████▋  | 385/499 [00:00<00:00, 453.20it/s]convert squad examples to features:  90%|████████▉ | 449/499 [00:01<00:00, 474.71it/s]convert squad examples to features: 100%|██████████| 499/499 [00:01<00:00, 467.63it/s]/cluster/project/sachan/yifan/softwares/anaconda/anaconda3/envs/xfactr/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2272: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

add example index and unique id:   0%|          | 0/499 [00:00<?, ?it/s]add example index and unique id: 100%|██████████| 499/499 [00:00<00:00, 513231.41it/s]
05/09/2022 23:00:09 - INFO - __main__ -   Saving features into cached file ./cached_tydiqa.goldp.sw.dev.json_xlm-KG_LR8e-6_EPOCH2.0_maxlen384_batchsize4_gradacc4_384_sw
05/09/2022 23:00:10 - INFO - __main__ -   ***** Running evaluation  *****
05/09/2022 23:00:10 - INFO - __main__ -     Num examples = 501
05/09/2022 23:00:10 - INFO - __main__ -     Batch size = 8
Evaluating:   0%|          | 0/63 [00:00<?, ?it/s]Evaluating:   2%|▏         | 1/63 [00:00<00:50,  1.23it/s]Evaluating:   3%|▎         | 2/63 [00:01<00:33,  1.84it/s]Evaluating:   5%|▍         | 3/63 [00:01<00:27,  2.19it/s]Evaluating:   6%|▋         | 4/63 [00:01<00:24,  2.40it/s]Evaluating:   8%|▊         | 5/63 [00:02<00:22,  2.53it/s]Evaluating:  10%|▉         | 6/63 [00:02<00:21,  2.62it/s]Evaluating:  11%|█         | 7/63 [00:02<00:20,  2.68it/s]Evaluating:  13%|█▎        | 8/63 [00:03<00:20,  2.71it/s]Evaluating:  14%|█▍        | 9/63 [00:03<00:19,  2.73it/s]Evaluating:  16%|█▌        | 10/63 [00:04<00:19,  2.75it/s]Evaluating:  17%|█▋        | 11/63 [00:04<00:18,  2.76it/s]Evaluating:  19%|█▉        | 12/63 [00:04<00:18,  2.78it/s]Evaluating:  21%|██        | 13/63 [00:05<00:17,  2.78it/s]Evaluating:  22%|██▏       | 14/63 [00:05<00:17,  2.79it/s]Evaluating:  24%|██▍       | 15/63 [00:05<00:17,  2.80it/s]Evaluating:  25%|██▌       | 16/63 [00:06<00:16,  2.78it/s]Evaluating:  27%|██▋       | 17/63 [00:06<00:16,  2.79it/s]Evaluating:  29%|██▊       | 18/63 [00:06<00:16,  2.78it/s]Evaluating:  30%|███       | 19/63 [00:07<00:15,  2.79it/s]Evaluating:  32%|███▏      | 20/63 [00:07<00:15,  2.79it/s]Evaluating:  33%|███▎      | 21/63 [00:07<00:15,  2.80it/s]Evaluating:  35%|███▍      | 22/63 [00:08<00:14,  2.80it/s]Evaluating:  37%|███▋      | 23/63 [00:08<00:14,  2.79it/s]Evaluating:  38%|███▊      | 24/63 [00:09<00:13,  2.79it/s]Evaluating:  40%|███▉      | 25/63 [00:09<00:13,  2.80it/s]Evaluating:  41%|████▏     | 26/63 [00:09<00:13,  2.81it/s]Evaluating:  43%|████▎     | 27/63 [00:10<00:12,  2.79it/s]Evaluating:  44%|████▍     | 28/63 [00:10<00:12,  2.80it/s]Evaluating:  46%|████▌     | 29/63 [00:10<00:12,  2.80it/s]Evaluating:  48%|████▊     | 30/63 [00:11<00:11,  2.80it/s]Evaluating:  49%|████▉     | 31/63 [00:11<00:11,  2.79it/s]Evaluating:  51%|█████     | 32/63 [00:11<00:11,  2.78it/s]Evaluating:  52%|█████▏    | 33/63 [00:12<00:10,  2.79it/s]Evaluating:  54%|█████▍    | 34/63 [00:12<00:10,  2.80it/s]Evaluating:  56%|█████▌    | 35/63 [00:12<00:09,  2.80it/s]Evaluating:  57%|█████▋    | 36/63 [00:13<00:09,  2.80it/s]Evaluating:  59%|█████▊    | 37/63 [00:13<00:09,  2.79it/s]Evaluating:  60%|██████    | 38/63 [00:14<00:09,  2.77it/s]Evaluating:  62%|██████▏   | 39/63 [00:14<00:08,  2.78it/s]Evaluating:  63%|██████▎   | 40/63 [00:14<00:08,  2.79it/s]Evaluating:  65%|██████▌   | 41/63 [00:15<00:07,  2.80it/s]Evaluating:  67%|██████▋   | 42/63 [00:15<00:07,  2.80it/s]Evaluating:  68%|██████▊   | 43/63 [00:15<00:07,  2.80it/s]Evaluating:  70%|██████▉   | 44/63 [00:16<00:06,  2.80it/s]Evaluating:  71%|███████▏  | 45/63 [00:16<00:06,  2.81it/s]Evaluating:  73%|███████▎  | 46/63 [00:16<00:06,  2.81it/s]Evaluating:  75%|███████▍  | 47/63 [00:17<00:05,  2.81it/s]Evaluating:  76%|███████▌  | 48/63 [00:17<00:05,  2.80it/s]Evaluating:  78%|███████▊  | 49/63 [00:17<00:05,  2.79it/s]Evaluating:  79%|███████▉  | 50/63 [00:18<00:04,  2.76it/s]Evaluating:  81%|████████  | 51/63 [00:18<00:04,  2.78it/s]Evaluating:  83%|████████▎ | 52/63 [00:19<00:03,  2.78it/s]Evaluating:  84%|████████▍ | 53/63 [00:19<00:03,  2.79it/s]Evaluating:  86%|████████▌ | 54/63 [00:19<00:03,  2.78it/s]Evaluating:  87%|████████▋ | 55/63 [00:20<00:02,  2.79it/s]Evaluating:  89%|████████▉ | 56/63 [00:20<00:02,  2.79it/s]Evaluating:  90%|█████████ | 57/63 [00:20<00:02,  2.80it/s]Evaluating:  92%|█████████▏| 58/63 [00:21<00:01,  2.79it/s]Evaluating:  94%|█████████▎| 59/63 [00:21<00:01,  2.79it/s]Evaluating:  95%|█████████▌| 60/63 [00:21<00:01,  2.80it/s]Evaluating:  97%|█████████▋| 61/63 [00:22<00:00,  2.77it/s]Evaluating:  98%|█████████▊| 62/63 [00:22<00:00,  2.78it/s]Evaluating: 100%|██████████| 63/63 [00:22<00:00,  3.11it/s]Evaluating: 100%|██████████| 63/63 [00:22<00:00,  2.75it/s]
05/09/2022 23:00:33 - INFO - __main__ -     Evaluation done in total 22.884839 secs (0.045678 sec per example)
05/09/2022 23:00:34 - INFO - __main__ -   Results: {'exact': 63.12625250501002, 'f1': 74.34777608307306, 'total': 499, 'HasAns_exact': 63.12625250501002, 'HasAns_f1': 74.34777608307306, 'HasAns_total': 499, 'best_exact': 63.12625250501002, 'best_exact_thresh': 0.0, 'best_f1': 74.34777608307306, 'best_f1_thresh': 0.0}
  te 
2022-05-09 23:00:37.711265: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0
05/09/2022 23:00:41 - WARNING - __main__ -   Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, 16-bits training: False
You are using a model of type xlm-roberta to instantiate a model of type xlm. This is not supported for all configurations of models and can yield errors.
Some weights of the model checkpoint at /cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//tydiqa/xlm-KG_LR8e-6_EPOCH2.0_maxlen384_batchsize4_gradacc4 were not used when initializing XLMRobertaModel: ['base_model.encoder.layer.10.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.17.attention.self.key.weight', 'base_model.encoder.layer.4.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.1.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.5.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.1.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.5.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.8.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.6.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.23.intermediate.dense.weight', 'base_model.encoder.layer.4.attention.self.value.bias', 'base_model.encoder.layer.23.output.dense.bias', 'base_model.encoder.layer.5.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.8.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.16.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.23.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.15.intermediate.dense.weight', 'base_model.encoder.layer.14.output.dense.weight', 'base_model.encoder.layer.3.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.17.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.10.attention.output.LayerNorm.bias', 'base_model.encoder.layer.13.intermediate.dense.weight', 'base_model.encoder.layer.6.attention.output.LayerNorm.weight', 'base_model.encoder.layer.7.attention.self.value.weight', 'base_model.encoder.layer.10.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.17.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.18.attention.output.dense.bias', 'base_model.encoder.layer.20.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.10.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.7.attention.self.value.bias', 'base_model.embeddings.LayerNorm.bias', 'base_model.encoder.layer.0.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.13.attention.self.query.weight', 'base_model.encoder.layer.16.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.22.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.20.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.21.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.11.output.LayerNorm.bias', 'base_model.encoder.layer.7.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.22.output.dense.weight', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.19.attention.output.dense.bias', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.22.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.11.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.9.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.3.output.LayerNorm.bias', 'base_model.encoder.layer.7.attention.output.LayerNorm.weight', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.19.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.2.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.23.attention.self.query.weight', 'base_model.encoder.layer.18.output.dense.weight', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.22.attention.self.key.weight', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.13.attention.self.key.weight', 'base_model.encoder.layer.4.attention.self.key.bias', 'base_model.encoder.layer.13.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.12.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.3.attention.output.LayerNorm.weight', 'base_model.encoder.layer.22.attention.self.value.weight', 'base_model.encoder.layer.12.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.20.output.LayerNorm.weight', 'base_model.encoder.layer.4.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.22.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.20.intermediate.dense.weight', 'base_model.encoder.layer.20.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.23.attention.output.dense.weight', 'base_model.encoder.layer.12.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.6.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.4.attention.self.value.weight', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.11.attention.output.LayerNorm.weight', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.16.attention.self.key.weight', 'base_model.encoder.layer.20.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.17.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.16.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.2.intermediate.dense.weight', 'base_model.encoder.layer.18.attention.self.key.bias', 'base_model.encoder.layer.14.intermediate.dense.weight', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.4.output.dense.bias', 'base_model.encoder.layer.21.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.9.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.16.attention.output.LayerNorm.bias', 'base_model.embeddings.word_embeddings.weight', 'base_model.encoder.layer.0.attention.self.query.weight', 'base_model.encoder.layer.0.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.1.intermediate.dense.weight', 'base_model.encoder.layer.9.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.4.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.0.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.23.attention.output.LayerNorm.weight', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.19.output.LayerNorm.weight', 'base_model.encoder.layer.12.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.7.output.dense.weight', 'base_model.encoder.layer.22.output.dense.bias', 'base_model.encoder.layer.18.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.13.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.9.attention.self.value.weight', 'base_model.encoder.layer.21.attention.self.key.bias', 'base_model.encoder.layer.22.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.0.attention.output.LayerNorm.bias', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.3.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.8.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.8.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.7.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.23.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.14.attention.self.key.bias', 'base_model.encoder.layer.5.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.23.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.21.output.LayerNorm.bias', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.0.output.LayerNorm.weight', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.2.attention.self.key.weight', 'base_model.encoder.layer.11.output.dense.bias', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.11.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.14.attention.self.key.weight', 'base_model.encoder.layer.20.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.17.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.7.attention.self.key.bias', 'base_model.encoder.layer.14.attention.output.dense.bias', 'base_model.encoder.layer.1.attention.output.LayerNorm.bias', 'base_model.encoder.layer.2.intermediate.dense.bias', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.10.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.20.attention.output.dense.weight', 'base_model.encoder.layer.8.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.14.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.3.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.2.output.dense.bias', 'base_model.encoder.layer.19.attention.self.key.weight', 'base_model.encoder.layer.18.attention.self.value.bias', 'base_model.encoder.layer.20.attention.self.key.weight', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.15.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.17.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.15.attention.self.value.weight', 'base_model.encoder.layer.20.attention.output.LayerNorm.weight', 'base_model.encoder.layer.20.output.dense.weight', 'base_model.encoder.layer.0.intermediate.dense.weight', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.19.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.20.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.0.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.13.output.LayerNorm.weight', 'base_model.encoder.layer.17.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.4.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.10.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.23.attention.self.query.bias', 'base_model.encoder.layer.10.output.dense.bias', 'base_model.encoder.layer.8.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.14.attention.self.query.weight', 'base_model.encoder.layer.5.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.18.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.3.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.14.output.LayerNorm.weight', 'base_model.encoder.layer.17.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.2.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.19.intermediate.dense.weight', 'base_model.encoder.layer.23.attention.self.key.bias', 'base_model.encoder.layer.3.attention.output.dense.bias', 'base_model.encoder.layer.3.output.dense.bias', 'base_model.encoder.layer.12.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.11.attention.output.LayerNorm.bias', 'base_model.encoder.layer.8.attention.self.value.weight', 'base_model.encoder.layer.2.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.14.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.22.attention.self.value.bias', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.10.output.LayerNorm.bias', 'base_model.encoder.layer.12.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.6.intermediate.dense.bias', 'base_model.encoder.layer.17.attention.self.value.weight', 'base_model.encoder.layer.14.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.23.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.20.attention.self.key.bias', 'base_model.encoder.layer.18.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.13.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.0.attention.output.dense.bias', 'base_model.encoder.layer.9.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.2.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.19.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.6.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.0.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.10.attention.self.query.weight', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.9.attention.output.dense.weight', 'base_model.pooler.dense.weight', 'base_model.encoder.layer.18.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.20.attention.output.LayerNorm.bias', 'base_model.encoder.layer.20.attention.self.value.weight', 'qa_outputs.weight', 'base_model.encoder.layer.1.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.11.attention.output.dense.weight', 'base_model.encoder.layer.13.output.dense.weight', 'base_model.encoder.layer.4.output.dense.weight', 'base_model.encoder.layer.15.attention.self.key.bias', 'base_model.encoder.layer.20.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.4.attention.output.LayerNorm.bias', 'base_model.encoder.layer.0.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.16.output.dense.weight', 'base_model.encoder.layer.19.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.16.attention.self.value.bias', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.22.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.6.output.LayerNorm.weight', 'base_model.encoder.layer.3.attention.self.value.weight', 'base_model.encoder.layer.18.attention.self.query.bias', 'base_model.encoder.layer.18.attention.output.LayerNorm.weight', 'base_model.encoder.layer.7.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.1.attention.self.value.weight', 'base_model.encoder.layer.20.attention.self.query.bias', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.11.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.15.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.10.attention.self.query.bias', 'base_model.encoder.layer.3.output.dense.weight', 'base_model.encoder.layer.10.intermediate.dense.bias', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.5.output.dense.bias', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.2.attention.output.LayerNorm.weight', 'base_model.encoder.layer.4.attention.output.dense.weight', 'base_model.encoder.layer.6.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.6.output.dense.bias', 'base_model.encoder.layer.16.attention.output.dense.weight', 'base_model.encoder.layer.6.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.23.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.6.attention.output.dense.bias', 'base_model.encoder.layer.0.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.13.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.13.attention.self.value.bias', 'base_model.encoder.layer.1.output.dense.bias', 'base_model.encoder.layer.2.attention.self.value.weight', 'base_model.encoder.layer.11.attention.self.value.bias', 'base_model.encoder.layer.1.output.LayerNorm.weight', 'base_model.encoder.layer.12.attention.self.value.weight', 'base_model.encoder.layer.9.attention.output.LayerNorm.weight', 'base_model.encoder.layer.11.intermediate.dense.weight', 'base_model.encoder.layer.15.attention.self.key.weight', 'base_model.encoder.layer.17.attention.self.query.weight', 'base_model.encoder.layer.13.intermediate.dense.bias', 'base_model.encoder.layer.12.output.LayerNorm.weight', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.0.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.3.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.14.intermediate.dense.bias', 'base_model.encoder.layer.18.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.2.attention.output.dense.bias', 'base_model.encoder.layer.8.attention.output.dense.bias', 'base_model.encoder.layer.12.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.8.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.3.intermediate.dense.weight', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.15.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.23.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.1.attention.self.key.weight', 'base_model.encoder.layer.6.attention.self.key.weight', 'base_model.encoder.layer.22.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.18.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.13.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.0.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.13.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.12.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.2.output.LayerNorm.weight', 'base_model.encoder.layer.22.attention.output.dense.bias', 'base_model.encoder.layer.13.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.8.attention.self.query.weight', 'base_model.encoder.layer.16.intermediate.dense.weight', 'base_model.encoder.layer.16.attention.output.LayerNorm.weight', 'base_model.encoder.layer.15.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.22.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.18.attention.self.query.weight', 'base_model.encoder.layer.21.attention.output.dense.bias', 'base_model.encoder.layer.9.output.dense.bias', 'base_model.encoder.layer.17.attention.output.LayerNorm.weight', 'base_model.encoder.layer.10.attention.self.value.weight', 'base_model.encoder.layer.15.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.15.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.3.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.22.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.4.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.10.attention.output.LayerNorm.weight', 'base_model.encoder.layer.8.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.14.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.1.attention.output.LayerNorm.weight', 'base_model.encoder.layer.10.attention.self.key.weight', 'base_model.encoder.layer.1.attention.self.key.bias', 'base_model.encoder.layer.7.intermediate.dense.weight', 'base_model.encoder.layer.12.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.12.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.19.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.12.intermediate.dense.bias', 'base_model.encoder.layer.17.attention.output.dense.weight', 'base_model.encoder.layer.12.attention.output.dense.weight', 'base_model.encoder.layer.20.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.2.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.11.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.18.attention.output.LayerNorm.bias', 'base_model.encoder.layer.19.attention.output.dense.weight', 'base_model.encoder.layer.22.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.9.attention.output.dense.bias', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.15.output.dense.weight', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.14.attention.output.LayerNorm.bias', 'base_model.encoder.layer.13.attention.output.dense.bias', 'base_model.encoder.layer.21.output.dense.bias', 'base_model.encoder.layer.19.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.0.output.LayerNorm.bias', 'base_model.encoder.layer.7.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.18.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.7.output.LayerNorm.weight', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.13.attention.output.LayerNorm.weight', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.3.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.3.attention.self.value.bias', 'base_model.encoder.layer.17.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.2.attention.output.LayerNorm.bias', 'base_model.encoder.layer.8.attention.self.key.weight', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.15.attention.self.value.bias', 'base_model.encoder.layer.16.output.dense.bias', 'base_model.encoder.layer.15.output.dense.bias', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.8.attention.output.LayerNorm.bias', 'base_model.encoder.layer.4.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.2.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.22.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.22.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.10.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.10.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.16.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.3.attention.self.key.bias', 'base_model.encoder.layer.7.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.10.attention.output.dense.weight', 'base_model.encoder.layer.9.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.12.attention.output.dense.bias', 'base_model.encoder.layer.4.intermediate.dense.weight', 'base_model.encoder.layer.0.attention.self.query.bias', 'base_model.encoder.layer.20.output.dense.bias', 'base_model.encoder.layer.2.output.adapters.ep.adapter_up.bias', 'base_model.embeddings.LayerNorm.weight', 'base_model.encoder.layer.16.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.1.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.22.intermediate.dense.bias', 'base_model.encoder.layer.13.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.3.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.21.intermediate.dense.bias', 'base_model.encoder.layer.15.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.21.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.15.attention.output.dense.bias', 'base_model.encoder.layer.7.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.20.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.23.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.5.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.20.output.LayerNorm.bias', 'base_model.encoder.layer.6.intermediate.dense.weight', 'base_model.encoder.layer.9.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.14.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.4.attention.self.key.weight', 'base_model.encoder.layer.11.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.8.attention.output.LayerNorm.weight', 'base_model.encoder.layer.2.attention.self.value.bias', 'base_model.encoder.layer.23.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.21.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.14.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.21.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.17.output.dense.weight', 'base_model.encoder.layer.23.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.23.intermediate.dense.bias', 'base_model.encoder.layer.20.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.15.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.20.attention.self.value.bias', 'base_model.encoder.layer.4.attention.self.query.bias', 'base_model.encoder.layer.16.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.22.attention.output.dense.weight', 'base_model.encoder.layer.4.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.11.intermediate.dense.bias', 'base_model.encoder.layer.8.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.17.attention.self.value.bias', 'base_model.encoder.layer.7.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.16.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.18.output.dense.bias', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.2.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.3.output.LayerNorm.weight', 'base_model.encoder.layer.9.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.5.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.5.attention.self.query.bias', 'base_model.encoder.layer.4.attention.output.dense.bias', 'base_model.encoder.layer.4.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.16.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.14.output.LayerNorm.bias', 'base_model.encoder.layer.13.attention.self.query.bias', 'base_model.encoder.layer.6.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.13.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.9.intermediate.dense.bias', 'base_model.encoder.layer.3.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.9.attention.output.LayerNorm.bias', 'base_model.encoder.layer.11.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.21.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.9.attention.self.query.bias', 'base_model.encoder.layer.6.attention.self.value.weight', 'base_model.encoder.layer.14.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.18.intermediate.dense.weight', 'base_model.encoder.layer.8.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.8.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.16.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.17.output.LayerNorm.bias', 'base_model.encoder.layer.19.output.LayerNorm.bias', 'base_model.encoder.layer.0.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.3.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.5.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.10.attention.self.value.bias', 'base_model.encoder.layer.18.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.23.attention.self.key.weight', 'base_model.encoder.layer.23.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.8.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.3.attention.self.key.weight', 'base_model.encoder.layer.4.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.1.output.LayerNorm.bias', 'base_model.encoder.layer.8.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.19.attention.output.LayerNorm.bias', 'base_model.encoder.layer.5.attention.output.LayerNorm.weight', 'base_model.encoder.layer.18.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.15.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.0.attention.self.value.weight', 'base_model.encoder.layer.10.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.2.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.6.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.22.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.9.output.LayerNorm.bias', 'base_model.encoder.layer.11.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.3.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.1.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.4.attention.output.LayerNorm.weight', 'base_model.encoder.layer.19.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.16.attention.self.value.weight', 'base_model.encoder.layer.1.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.23.output.dense.weight', 'base_model.encoder.layer.18.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.1.attention.self.value.bias', 'base_model.encoder.layer.5.intermediate.dense.weight', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.11.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.21.attention.output.dense.weight', 'base_model.encoder.layer.19.attention.self.value.weight', 'base_model.encoder.layer.5.attention.self.value.bias', 'base_model.encoder.layer.6.attention.self.query.weight', 'base_model.encoder.layer.6.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.13.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.0.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.18.attention.self.value.weight', 'base_model.encoder.layer.16.attention.self.query.bias', 'base_model.encoder.layer.8.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.7.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.9.output.dense.weight', 'base_model.encoder.layer.2.attention.output.dense.weight', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.11.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.13.attention.self.value.weight', 'base_model.encoder.layer.16.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.7.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.16.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.18.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.7.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.4.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.6.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.2.attention.self.key.bias', 'base_model.encoder.layer.4.output.LayerNorm.bias', 'base_model.encoder.layer.8.intermediate.dense.weight', 'base_model.encoder.layer.14.attention.output.LayerNorm.weight', 'base_model.encoder.layer.18.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.21.output.dense.weight', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.1.attention.self.query.weight', 'base_model.encoder.layer.3.intermediate.dense.bias', 'base_model.encoder.layer.4.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.16.attention.self.query.weight', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.15.attention.output.dense.weight', 'base_model.encoder.layer.18.attention.self.key.weight', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.23.output.LayerNorm.weight', 'base_model.encoder.layer.15.attention.self.query.weight', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.13.attention.self.key.bias', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.14.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.6.attention.output.dense.weight', 'base_model.encoder.layer.12.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.10.attention.self.key.bias', 'base_model.encoder.layer.9.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.0.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.16.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.11.attention.self.key.bias', 'base_model.encoder.layer.10.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.13.output.dense.bias', 'base_model.encoder.layer.19.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.5.attention.self.query.weight', 'base_model.encoder.layer.15.attention.output.LayerNorm.weight', 'base_model.encoder.layer.7.intermediate.dense.bias', 'base_model.encoder.layer.11.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.19.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.9.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.12.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.0.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.21.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.22.attention.output.LayerNorm.weight', 'base_model.encoder.layer.9.attention.self.key.bias', 'base_model.encoder.layer.11.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.9.attention.self.query.weight', 'base_model.encoder.layer.7.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.0.output.dense.bias', 'base_model.encoder.layer.10.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.2.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.11.attention.self.key.weight', 'base_model.encoder.layer.9.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.17.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.5.attention.output.LayerNorm.bias', 'base_model.encoder.layer.4.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.3.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.16.attention.output.dense.bias', 'base_model.encoder.layer.15.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.3.attention.output.LayerNorm.bias', 'base_model.encoder.layer.9.intermediate.dense.weight', 'base_model.encoder.layer.18.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.20.attention.self.query.weight', 'base_model.encoder.layer.6.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.14.attention.self.value.weight', 'base_model.encoder.layer.11.attention.self.query.weight', 'base_model.encoder.layer.1.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.12.attention.self.key.weight', 'base_model.encoder.layer.5.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.16.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.23.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.0.attention.output.dense.weight', 'base_model.encoder.layer.7.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.12.attention.output.LayerNorm.weight', 'base_model.encoder.layer.3.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.12.attention.self.value.bias', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.18.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.17.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.21.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.10.attention.output.dense.bias', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.14.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.2.attention.self.query.weight', 'base_model.embeddings.position_embeddings.weight', 'base_model.encoder.layer.7.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.1.intermediate.dense.bias', 'base_model.encoder.layer.8.attention.self.key.bias', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.7.attention.output.LayerNorm.bias', 'base_model.encoder.layer.5.output.LayerNorm.bias', 'base_model.encoder.layer.11.attention.output.dense.bias', 'base_model.encoder.layer.17.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.21.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.21.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.14.attention.output.dense.weight', 'base_model.encoder.layer.16.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.21.intermediate.dense.weight', 'base_model.encoder.layer.10.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.1.output.dense.weight', 'base_model.encoder.layer.6.output.LayerNorm.bias', 'base_model.encoder.layer.9.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.10.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.10.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.21.attention.output.LayerNorm.weight', 'base_model.encoder.layer.23.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.13.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.17.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.21.attention.self.value.weight', 'base_model.encoder.layer.14.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.4.intermediate.dense.bias', 'base_model.encoder.layer.12.output.dense.weight', 'base_model.encoder.layer.21.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.22.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.7.output.dense.bias', 'base_model.encoder.layer.13.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.7.output.LayerNorm.bias', 'base_model.encoder.layer.17.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.21.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.1.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.6.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.14.output.dense.bias', 'base_model.encoder.layer.17.attention.self.key.bias', 'base_model.encoder.layer.18.output.LayerNorm.weight', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.7.attention.self.key.weight', 'base_model.encoder.layer.22.output.LayerNorm.bias', 'base_model.encoder.layer.6.attention.output.LayerNorm.bias', 'base_model.encoder.layer.5.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.22.attention.output.LayerNorm.bias', 'base_model.encoder.layer.4.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.19.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.13.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.5.attention.output.dense.bias', 'base_model.encoder.layer.6.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.19.output.dense.bias', 'base_model.encoder.layer.4.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.5.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.23.attention.output.dense.bias', 'base_model.encoder.layer.4.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.20.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.1.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.22.output.adapters.ts.adapter_up.bias', 'base_model.embeddings.position_ids', 'base_model.encoder.layer.5.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.14.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.5.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.11.output.LayerNorm.weight', 'base_model.encoder.layer.19.output.dense.weight', 'base_model.encoder.layer.21.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.11.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.18.output.LayerNorm.bias', 'base_model.encoder.layer.2.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.19.attention.self.query.bias', 'base_model.encoder.layer.22.output.LayerNorm.weight', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.21.attention.self.value.bias', 'base_model.encoder.layer.19.attention.self.value.bias', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.20.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.8.attention.self.value.bias', 'base_model.encoder.layer.22.intermediate.dense.weight', 'base_model.encoder.layer.0.intermediate.dense.bias', 'base_model.encoder.layer.12.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.9.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.7.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.8.output.LayerNorm.bias', 'base_model.encoder.layer.9.attention.self.value.bias', 'base_model.encoder.layer.9.output.LayerNorm.weight', 'base_model.encoder.layer.16.attention.self.key.bias', 'base_model.encoder.layer.0.attention.output.LayerNorm.weight', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.12.attention.self.query.weight', 'base_model.encoder.layer.19.intermediate.dense.bias', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.17.output.LayerNorm.weight', 'base_model.encoder.layer.10.intermediate.dense.weight', 'base_model.encoder.layer.15.output.LayerNorm.weight', 'base_model.encoder.layer.14.attention.self.query.bias', 'base_model.encoder.layer.23.attention.self.value.bias', 'base_model.encoder.layer.21.attention.self.key.weight', 'base_model.encoder.layer.23.output.LayerNorm.bias', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.17.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.1.attention.output.dense.bias', 'base_model.encoder.layer.22.attention.self.query.weight', 'base_model.encoder.layer.15.attention.self.query.bias', 'base_model.encoder.layer.3.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.6.output.dense.weight', 'base_model.encoder.layer.6.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.15.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.0.attention.self.key.bias', 'base_model.encoder.layer.0.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.13.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.12.attention.output.LayerNorm.bias', 'base_model.encoder.layer.0.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.13.attention.output.dense.weight', 'base_model.encoder.layer.12.attention.self.query.bias', 'base_model.encoder.layer.5.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.12.output.dense.bias', 'base_model.encoder.layer.18.intermediate.dense.bias', 'base_model.encoder.layer.18.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.8.output.dense.weight', 'base_model.encoder.layer.21.attention.self.query.bias', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.6.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.1.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.14.attention.self.value.bias', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.4.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.21.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.15.output.LayerNorm.bias', 'base_model.pooler.dense.bias', 'base_model.encoder.layer.23.attention.self.value.weight', 'base_model.encoder.layer.23.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.22.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.11.attention.self.query.bias', 'base_model.encoder.layer.15.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.3.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.10.output.dense.weight', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.8.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.0.attention.self.value.bias', 'base_model.encoder.layer.1.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.9.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.6.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.18.attention.output.dense.weight', 'base_model.encoder.layer.1.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.9.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.17.attention.output.dense.bias', 'base_model.encoder.layer.21.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.6.attention.self.query.bias', 'base_model.encoder.layer.2.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.10.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.20.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.8.attention.self.query.bias', 'base_model.encoder.layer.19.attention.output.LayerNorm.weight', 'base_model.encoder.layer.11.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.13.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.10.output.LayerNorm.weight', 'base_model.encoder.layer.22.attention.self.key.bias', 'base_model.encoder.layer.8.intermediate.dense.bias', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.11.attention.self.value.weight', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.8.output.LayerNorm.weight', 'base_model.encoder.layer.1.attention.output.dense.weight', 'base_model.encoder.layer.15.attention.output.LayerNorm.bias', 'base_model.encoder.layer.20.attention.output.dense.bias', 'base_model.encoder.layer.3.attention.self.query.bias', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.8.attention.output.dense.weight', 'base_model.encoder.layer.16.output.LayerNorm.bias', 'base_model.encoder.layer.23.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.2.attention.self.query.bias', 'base_model.encoder.layer.5.attention.self.key.bias', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.21.attention.output.LayerNorm.bias', 'base_model.encoder.layer.19.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.17.intermediate.dense.bias', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.23.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.14.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.19.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.12.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.14.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.1.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.19.attention.self.query.weight', 'base_model.encoder.layer.19.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.18.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.21.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.6.attention.self.value.bias', 'base_model.encoder.layer.4.output.LayerNorm.weight', 'base_model.encoder.layer.5.attention.self.value.weight', 'base_model.encoder.layer.19.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.7.attention.output.dense.weight', 'base_model.encoder.layer.5.output.dense.weight', 'base_model.encoder.layer.17.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.12.intermediate.dense.weight', 'base_model.encoder.layer.2.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.2.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.12.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.16.intermediate.dense.bias', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.21.output.LayerNorm.weight', 'base_model.encoder.layer.17.attention.output.LayerNorm.bias', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.5.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.16.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.13.attention.output.LayerNorm.bias', 'base_model.encoder.layer.11.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.14.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.20.intermediate.dense.bias', 'base_model.encoder.layer.15.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.17.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.20.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.2.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.12.output.LayerNorm.bias', 'base_model.encoder.layer.19.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.8.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.6.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.13.output.LayerNorm.bias', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.14.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.17.intermediate.dense.weight', 'base_model.encoder.layer.0.attention.self.key.weight', 'base_model.encoder.layer.7.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.12.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.5.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.11.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.15.intermediate.dense.bias', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.2.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.5.attention.self.key.weight', 'base_model.encoder.layer.23.attention.output.LayerNorm.bias', 'base_model.encoder.layer.2.output.LayerNorm.bias', 'base_model.encoder.layer.1.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.7.attention.output.dense.bias', 'base_model.encoder.layer.7.attention.self.query.bias', 'base_model.encoder.layer.0.output.dense.weight', 'base_model.encoder.layer.14.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.5.attention.output.dense.weight', 'base_model.encoder.layer.1.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.17.output.dense.bias', 'base_model.encoder.layer.8.output.dense.bias', 'base_model.encoder.layer.4.attention.self.query.weight', 'base_model.encoder.layer.22.attention.self.query.bias', 'base_model.embeddings.token_type_embeddings.weight', 'base_model.encoder.layer.3.attention.self.query.weight', 'base_model.encoder.layer.11.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.15.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.3.attention.output.dense.weight', 'base_model.encoder.layer.0.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.23.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.9.attention.self.key.weight', 'base_model.encoder.layer.16.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.21.attention.self.query.weight', 'base_model.encoder.layer.6.attention.self.key.bias', 'qa_outputs.bias', 'base_model.encoder.layer.20.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.13.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.9.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.20.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.5.output.LayerNorm.weight', 'base_model.encoder.layer.7.attention.self.query.weight', 'base_model.encoder.layer.10.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.15.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.17.attention.self.query.bias', 'base_model.encoder.layer.19.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.1.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.9.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.3.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.19.attention.self.key.bias', 'base_model.encoder.layer.10.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.12.attention.self.key.bias', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.16.output.LayerNorm.weight', 'base_model.encoder.layer.15.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.2.output.dense.weight', 'base_model.encoder.layer.7.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.11.output.dense.weight', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.22.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.1.attention.self.query.bias', 'base_model.encoder.layer.5.intermediate.dense.bias']
- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of XLMRobertaModel were not initialized from the model checkpoint at /cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//tydiqa/xlm-KG_LR8e-6_EPOCH2.0_maxlen384_batchsize4_gradacc4 and are newly initialized: ['encoder.layer.10.attention.output.dense.bias', 'encoder.layer.23.output.dense.bias', 'encoder.layer.10.attention.self.value.bias', 'embeddings.position_embeddings.weight', 'encoder.layer.7.output.LayerNorm.bias', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.23.output.dense.weight', 'encoder.layer.5.attention.self.value.weight', 'encoder.layer.3.attention.self.value.bias', 'encoder.layer.15.attention.output.dense.weight', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.5.attention.self.query.weight', 'encoder.layer.7.attention.self.key.weight', 'encoder.layer.2.output.dense.bias', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.5.attention.self.key.bias', 'encoder.layer.6.attention.output.LayerNorm.bias', 'encoder.layer.15.intermediate.dense.weight', 'encoder.layer.8.output.LayerNorm.weight', 'encoder.layer.13.attention.self.key.weight', 'encoder.layer.16.attention.self.key.bias', 'encoder.layer.18.attention.self.value.weight', 'encoder.layer.13.attention.output.LayerNorm.weight', 'encoder.layer.19.attention.output.dense.weight', 'encoder.layer.2.attention.self.value.bias', 'encoder.layer.19.attention.output.LayerNorm.bias', 'encoder.layer.21.attention.self.query.bias', 'encoder.layer.10.attention.self.value.weight', 'encoder.layer.11.attention.output.dense.weight', 'encoder.layer.4.attention.self.key.weight', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.3.attention.self.key.weight', 'encoder.layer.0.attention.self.query.weight', 'encoder.layer.23.attention.self.value.bias', 'encoder.layer.12.intermediate.dense.bias', 'encoder.layer.0.attention.self.value.weight', 'encoder.layer.4.attention.self.query.bias', 'encoder.layer.9.attention.self.query.bias', 'encoder.layer.15.attention.self.value.weight', 'encoder.layer.9.output.dense.bias', 'encoder.layer.9.attention.output.dense.weight', 'encoder.layer.11.attention.self.key.weight', 'encoder.layer.16.attention.self.key.weight', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.18.attention.self.query.weight', 'encoder.layer.20.attention.output.LayerNorm.bias', 'encoder.layer.23.attention.self.key.bias', 'encoder.layer.12.output.dense.bias', 'encoder.layer.23.output.LayerNorm.bias', 'encoder.layer.22.output.LayerNorm.bias', 'encoder.layer.18.attention.self.query.bias', 'encoder.layer.5.attention.self.value.bias', 'encoder.layer.2.attention.output.dense.bias', 'encoder.layer.16.intermediate.dense.bias', 'encoder.layer.6.attention.output.dense.weight', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.18.attention.output.dense.bias', 'encoder.layer.10.attention.output.LayerNorm.bias', 'encoder.layer.5.output.LayerNorm.bias', 'encoder.layer.21.attention.self.key.weight', 'encoder.layer.21.attention.self.query.weight', 'encoder.layer.15.intermediate.dense.bias', 'encoder.layer.10.intermediate.dense.weight', 'encoder.layer.9.attention.self.value.bias', 'encoder.layer.15.attention.self.query.weight', 'encoder.layer.0.attention.self.key.weight', 'encoder.layer.19.attention.self.value.bias', 'encoder.layer.19.output.LayerNorm.weight', 'encoder.layer.20.output.dense.bias', 'encoder.layer.4.attention.output.dense.weight', 'encoder.layer.17.output.dense.bias', 'encoder.layer.17.output.dense.weight', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.19.attention.self.query.weight', 'encoder.layer.15.attention.self.key.bias', 'encoder.layer.20.attention.self.query.weight', 'encoder.layer.16.attention.output.dense.weight', 'encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.layer.7.attention.output.dense.weight', 'encoder.layer.18.attention.output.LayerNorm.weight', 'encoder.layer.20.output.dense.weight', 'encoder.layer.4.output.dense.bias', 'encoder.layer.20.attention.self.query.bias', 'encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.layer.21.attention.output.LayerNorm.weight', 'encoder.layer.20.output.LayerNorm.weight', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.14.attention.self.value.weight', 'encoder.layer.12.output.dense.weight', 'encoder.layer.2.output.dense.weight', 'encoder.layer.18.intermediate.dense.bias', 'encoder.layer.10.output.LayerNorm.bias', 'encoder.layer.14.output.LayerNorm.bias', 'encoder.layer.5.intermediate.dense.bias', 'pooler.dense.bias', 'encoder.layer.18.attention.output.dense.weight', 'encoder.layer.19.output.dense.bias', 'encoder.layer.23.attention.self.query.weight', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.4.attention.output.dense.bias', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.3.attention.self.query.bias', 'encoder.layer.21.attention.self.key.bias', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.11.attention.self.value.weight', 'encoder.layer.13.output.dense.weight', 'encoder.layer.15.output.LayerNorm.bias', 'encoder.layer.20.attention.output.dense.bias', 'encoder.layer.17.attention.self.query.bias', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.8.attention.self.query.weight', 'encoder.layer.15.output.LayerNorm.weight', 'encoder.layer.9.attention.output.dense.bias', 'encoder.layer.1.attention.output.dense.bias', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.layer.4.attention.self.value.weight', 'encoder.layer.9.attention.self.key.weight', 'encoder.layer.10.attention.output.dense.weight', 'encoder.layer.4.attention.self.key.bias', 'encoder.layer.9.attention.output.LayerNorm.weight', 'encoder.layer.6.attention.self.value.weight', 'encoder.layer.16.attention.self.value.bias', 'encoder.layer.19.attention.output.LayerNorm.weight', 'encoder.layer.9.attention.self.key.bias', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.16.attention.output.LayerNorm.bias', 'encoder.layer.15.output.dense.bias', 'encoder.layer.13.intermediate.dense.bias', 'encoder.layer.5.attention.output.dense.bias', 'encoder.layer.22.attention.self.value.bias', 'encoder.layer.16.intermediate.dense.weight', 'encoder.layer.22.attention.output.LayerNorm.bias', 'encoder.layer.6.output.LayerNorm.bias', 'encoder.layer.6.attention.output.LayerNorm.weight', 'encoder.layer.8.attention.output.dense.weight', 'encoder.layer.17.output.LayerNorm.weight', 'encoder.layer.20.attention.output.LayerNorm.weight', 'encoder.layer.12.intermediate.dense.weight', 'encoder.layer.17.attention.self.query.weight', 'encoder.layer.15.output.dense.weight', 'encoder.layer.6.output.dense.bias', 'encoder.layer.18.output.dense.bias', 'encoder.layer.21.attention.output.LayerNorm.bias', 'encoder.layer.4.output.dense.weight', 'encoder.layer.13.attention.output.LayerNorm.bias', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.21.intermediate.dense.bias', 'encoder.layer.18.intermediate.dense.weight', 'encoder.layer.12.attention.self.query.bias', 'encoder.layer.21.attention.output.dense.weight', 'encoder.layer.16.attention.output.dense.bias', 'encoder.layer.14.attention.self.value.bias', 'encoder.layer.16.attention.self.value.weight', 'encoder.layer.16.attention.self.query.bias', 'encoder.layer.4.attention.output.LayerNorm.bias', 'encoder.layer.17.attention.output.dense.bias', 'encoder.layer.1.attention.self.key.bias', 'encoder.layer.22.output.dense.weight', 'encoder.layer.1.attention.self.key.weight', 'encoder.layer.20.attention.self.value.weight', 'encoder.layer.1.attention.self.value.weight', 'encoder.layer.3.output.dense.weight', 'encoder.layer.21.attention.self.value.bias', 'encoder.layer.23.attention.output.LayerNorm.weight', 'encoder.layer.14.output.LayerNorm.weight', 'encoder.layer.23.attention.self.value.weight', 'encoder.layer.11.attention.self.value.bias', 'encoder.layer.18.output.LayerNorm.weight', 'encoder.layer.8.output.dense.weight', 'encoder.layer.13.attention.self.query.bias', 'encoder.layer.20.attention.self.key.weight', 'encoder.layer.10.attention.self.key.bias', 'encoder.layer.7.attention.output.LayerNorm.weight', 'encoder.layer.18.attention.self.key.bias', 'encoder.layer.23.attention.self.key.weight', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.1.attention.self.query.bias', 'encoder.layer.12.attention.output.dense.bias', 'encoder.layer.11.attention.self.query.weight', 'encoder.layer.4.intermediate.dense.weight', 'pooler.dense.weight', 'encoder.layer.22.attention.output.LayerNorm.weight', 'encoder.layer.2.attention.output.LayerNorm.weight', 'encoder.layer.6.attention.self.query.bias', 'encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.18.attention.self.key.weight', 'encoder.layer.16.output.LayerNorm.bias', 'encoder.layer.21.intermediate.dense.weight', 'encoder.layer.0.attention.output.LayerNorm.weight', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.11.output.dense.weight', 'encoder.layer.20.attention.self.value.bias', 'encoder.layer.7.output.dense.weight', 'encoder.layer.3.attention.output.dense.weight', 'encoder.layer.13.attention.output.dense.bias', 'encoder.layer.8.output.dense.bias', 'encoder.layer.8.attention.self.query.bias', 'encoder.layer.4.attention.output.LayerNorm.weight', 'encoder.layer.18.output.LayerNorm.bias', 'encoder.layer.23.intermediate.dense.bias', 'encoder.layer.23.attention.output.LayerNorm.bias', 'encoder.layer.0.attention.output.dense.weight', 'encoder.layer.7.attention.self.value.bias', 'encoder.layer.14.output.dense.bias', 'encoder.layer.6.attention.self.value.bias', 'encoder.layer.6.attention.output.dense.bias', 'encoder.layer.21.output.dense.weight', 'encoder.layer.1.attention.output.dense.weight', 'encoder.layer.13.attention.output.dense.weight', 'encoder.layer.4.attention.self.query.weight', 'encoder.layer.12.output.LayerNorm.bias', 'encoder.layer.17.attention.self.value.weight', 'encoder.layer.22.attention.self.query.bias', 'encoder.layer.9.attention.self.value.weight', 'encoder.layer.17.attention.output.LayerNorm.bias', 'encoder.layer.7.intermediate.dense.bias', 'encoder.layer.8.output.LayerNorm.bias', 'encoder.layer.17.attention.output.dense.weight', 'encoder.layer.13.attention.self.query.weight', 'encoder.layer.10.attention.self.query.weight', 'encoder.layer.3.attention.self.value.weight', 'encoder.layer.13.attention.self.value.weight', 'encoder.layer.18.attention.output.LayerNorm.bias', 'encoder.layer.22.attention.self.key.bias', 'encoder.layer.20.output.LayerNorm.bias', 'encoder.layer.17.output.LayerNorm.bias', 'encoder.layer.2.attention.output.dense.weight', 'encoder.layer.3.attention.self.key.bias', 'encoder.layer.7.attention.output.LayerNorm.bias', 'encoder.layer.11.attention.self.key.bias', 'encoder.layer.19.attention.self.key.bias', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.10.attention.output.LayerNorm.weight', 'encoder.layer.11.attention.output.LayerNorm.weight', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.22.intermediate.dense.bias', 'encoder.layer.12.attention.output.dense.weight', 'encoder.layer.13.attention.self.value.bias', 'encoder.layer.12.attention.self.value.weight', 'encoder.layer.7.attention.self.key.bias', 'encoder.layer.16.output.dense.weight', 'encoder.layer.8.attention.self.value.bias', 'encoder.layer.17.attention.self.value.bias', 'embeddings.token_type_embeddings.weight', 'encoder.layer.9.output.LayerNorm.weight', 'encoder.layer.14.intermediate.dense.weight', 'encoder.layer.22.attention.self.key.weight', 'encoder.layer.22.attention.output.dense.bias', 'encoder.layer.14.attention.self.query.weight', 'encoder.layer.10.output.dense.bias', 'encoder.layer.23.attention.output.dense.weight', 'encoder.layer.8.attention.self.key.bias', 'encoder.layer.0.attention.self.value.bias', 'encoder.layer.14.attention.self.key.bias', 'encoder.layer.10.attention.self.key.weight', 'encoder.layer.2.attention.self.value.weight', 'encoder.layer.14.attention.output.dense.weight', 'encoder.layer.15.attention.output.LayerNorm.weight', 'encoder.layer.18.attention.self.value.bias', 'encoder.layer.19.intermediate.dense.bias', 'encoder.layer.12.attention.self.value.bias', 'encoder.layer.19.attention.self.query.bias', 'encoder.layer.2.attention.self.query.weight', 'encoder.layer.13.attention.self.key.bias', 'encoder.layer.11.attention.output.dense.bias', 'encoder.layer.20.attention.output.dense.weight', 'encoder.layer.14.attention.output.dense.bias', 'encoder.layer.5.output.dense.weight', 'encoder.layer.19.intermediate.dense.weight', 'encoder.layer.20.intermediate.dense.weight', 'encoder.layer.22.output.LayerNorm.weight', 'encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.layer.4.attention.self.value.bias', 'encoder.layer.8.attention.self.key.weight', 'encoder.layer.22.attention.output.dense.weight', 'encoder.layer.15.attention.output.LayerNorm.bias', 'encoder.layer.1.attention.self.query.weight', 'encoder.layer.9.attention.output.LayerNorm.bias', 'encoder.layer.1.output.dense.weight', 'encoder.layer.21.output.LayerNorm.bias', 'encoder.layer.0.attention.self.key.bias', 'encoder.layer.8.attention.output.LayerNorm.bias', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.15.attention.output.dense.bias', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.6.attention.self.key.bias', 'encoder.layer.20.attention.self.key.bias', 'encoder.layer.18.output.dense.weight', 'encoder.layer.17.intermediate.dense.bias', 'encoder.layer.14.output.dense.weight', 'encoder.layer.0.output.dense.bias', 'encoder.layer.7.attention.self.query.bias', 'encoder.layer.16.output.LayerNorm.weight', 'encoder.layer.17.attention.output.LayerNorm.weight', 'encoder.layer.14.attention.self.key.weight', 'encoder.layer.7.attention.output.dense.bias', 'encoder.layer.11.output.LayerNorm.bias', 'encoder.layer.23.intermediate.dense.weight', 'encoder.layer.9.output.LayerNorm.bias', 'encoder.layer.22.attention.self.value.weight', 'encoder.layer.5.attention.output.dense.weight', 'encoder.layer.1.output.dense.bias', 'encoder.layer.10.output.LayerNorm.weight', 'encoder.layer.0.output.dense.weight', 'encoder.layer.6.attention.self.query.weight', 'encoder.layer.11.attention.self.query.bias', 'encoder.layer.15.attention.self.query.bias', 'embeddings.word_embeddings.weight', 'encoder.layer.22.attention.self.query.weight', 'encoder.layer.13.intermediate.dense.weight', 'encoder.layer.2.attention.output.LayerNorm.bias', 'encoder.layer.2.attention.self.query.bias', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.13.output.LayerNorm.weight', 'encoder.layer.0.attention.self.query.bias', 'encoder.layer.19.attention.self.value.weight', 'encoder.layer.3.output.dense.bias', 'embeddings.LayerNorm.bias', 'encoder.layer.10.attention.self.query.bias', 'encoder.layer.17.attention.self.key.weight', 'embeddings.LayerNorm.weight', 'encoder.layer.14.attention.output.LayerNorm.weight', 'encoder.layer.13.output.dense.bias', 'encoder.layer.1.attention.self.value.bias', 'encoder.layer.7.attention.self.query.weight', 'encoder.layer.14.intermediate.dense.bias', 'encoder.layer.8.attention.output.LayerNorm.weight', 'encoder.layer.6.output.dense.weight', 'encoder.layer.7.output.LayerNorm.weight', 'encoder.layer.21.output.LayerNorm.weight', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.20.intermediate.dense.bias', 'encoder.layer.21.attention.output.dense.bias', 'encoder.layer.3.attention.output.dense.bias', 'encoder.layer.5.attention.self.query.bias', 'encoder.layer.22.output.dense.bias', 'encoder.layer.17.attention.self.key.bias', 'encoder.layer.5.attention.self.key.weight', 'encoder.layer.12.attention.output.LayerNorm.weight', 'encoder.layer.21.attention.self.value.weight', 'encoder.layer.9.output.dense.weight', 'encoder.layer.19.attention.self.key.weight', 'encoder.layer.12.attention.self.key.bias', 'encoder.layer.2.attention.self.key.weight', 'encoder.layer.12.output.LayerNorm.weight', 'encoder.layer.17.intermediate.dense.weight', 'encoder.layer.6.attention.self.key.weight', 'encoder.layer.14.attention.output.LayerNorm.bias', 'encoder.layer.15.attention.self.value.bias', 'encoder.layer.8.attention.output.dense.bias', 'encoder.layer.11.output.dense.bias', 'encoder.layer.14.attention.self.query.bias', 'encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.layer.22.intermediate.dense.weight', 'encoder.layer.21.output.dense.bias', 'encoder.layer.2.attention.self.key.bias', 'encoder.layer.12.attention.self.key.weight', 'encoder.layer.13.output.LayerNorm.bias', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.12.attention.self.query.weight', 'encoder.layer.23.attention.self.query.bias', 'encoder.layer.16.attention.self.query.weight', 'encoder.layer.3.attention.self.query.weight', 'encoder.layer.7.attention.self.value.weight', 'encoder.layer.19.output.LayerNorm.bias', 'encoder.layer.15.attention.self.key.weight', 'encoder.layer.19.output.dense.weight', 'encoder.layer.8.attention.self.value.weight', 'encoder.layer.11.output.LayerNorm.weight', 'encoder.layer.7.output.dense.bias', 'encoder.layer.10.output.dense.weight', 'encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.layer.16.attention.output.LayerNorm.weight', 'encoder.layer.16.output.dense.bias', 'encoder.layer.19.attention.output.dense.bias', 'encoder.layer.1.attention.output.LayerNorm.weight', 'encoder.layer.23.attention.output.dense.bias', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.5.output.dense.bias', 'encoder.layer.9.attention.self.query.weight', 'encoder.layer.0.attention.output.dense.bias', 'encoder.layer.12.attention.output.LayerNorm.bias', 'encoder.layer.5.attention.output.LayerNorm.weight', 'encoder.layer.23.output.LayerNorm.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Overwriting existing adapter 'ep'.
Overwriting existing adapter 'tp'.
Overwriting existing adapter 'es'.
Overwriting existing adapter 'ts'.
Overwriting existing adapter fusion module 'ep,tp,es,ts'
05/09/2022 23:01:02 - INFO - __main__ -   lang2id = None
05/09/2022 23:01:05 - INFO - __main__ -   Training/evaluation parameters Namespace(adam_epsilon=1e-08, cache_dir='', config_name='', data_dir=None, device=device(type='cuda'), do_eval=True, do_lower_case=False, do_train=False, doc_stride=128, eval_all_checkpoints=False, eval_lang='te', evaluate_during_training=False, fp16=False, fp16_opt_level='O1', gradient_accumulation_steps=1, learning_rate=5e-05, local_rank=-1, logging_steps=50, max_answer_length=30, max_grad_norm=1.0, max_query_length=64, max_seq_length=384, max_steps=-1, model_name='xlm-KG', model_name_or_path='/cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//tydiqa/xlm-KG_LR8e-6_EPOCH2.0_maxlen384_batchsize4_gradacc4', model_type='xlm', modelkg_dir='/cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/adapter/xlmr_adapter', n_best_size=20, n_gpu=1, no_cuda=False, null_score_diff_threshold=0.0, num_train_epochs=3.0, output_dir='/cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//tydiqa/xlm-KG_LR8e-6_EPOCH2.0_maxlen384_batchsize4_gradacc4/predictions/tydiqa/', overwrite_cache=False, overwrite_output_dir=False, per_gpu_eval_batch_size=8, per_gpu_train_batch_size=8, predict_file='/cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/download//tydiqa//tydiqa-goldp-v1.1-dev/tydiqa.goldp.te.dev.json', save_steps=50, seed=42, server_ip='', server_port='', threads=1, tokenizer_name='', train_file=None, train_lang='en', verbose_logging=False, version_2_with_negative=False, warmup_steps=0, weight_decay=0.0)
05/09/2022 23:01:05 - INFO - __main__ -   Loading checkpoint /cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//tydiqa/xlm-KG_LR8e-6_EPOCH2.0_maxlen384_batchsize4_gradacc4 for evaluation
05/09/2022 23:01:05 - INFO - __main__ -   Evaluate the following checkpoints: ['/cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//tydiqa/xlm-KG_LR8e-6_EPOCH2.0_maxlen384_batchsize4_gradacc4']
Some weights of the model checkpoint at /cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//tydiqa/xlm-KG_LR8e-6_EPOCH2.0_maxlen384_batchsize4_gradacc4 were not used when initializing XLMRobertaModel: ['base_model.encoder.layer.10.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.17.attention.self.key.weight', 'base_model.encoder.layer.4.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.1.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.5.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.1.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.5.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.8.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.6.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.23.intermediate.dense.weight', 'base_model.encoder.layer.4.attention.self.value.bias', 'base_model.encoder.layer.23.output.dense.bias', 'base_model.encoder.layer.5.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.8.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.16.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.23.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.15.intermediate.dense.weight', 'base_model.encoder.layer.14.output.dense.weight', 'base_model.encoder.layer.3.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.17.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.10.attention.output.LayerNorm.bias', 'base_model.encoder.layer.13.intermediate.dense.weight', 'base_model.encoder.layer.6.attention.output.LayerNorm.weight', 'base_model.encoder.layer.7.attention.self.value.weight', 'base_model.encoder.layer.10.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.17.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.18.attention.output.dense.bias', 'base_model.encoder.layer.20.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.10.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.7.attention.self.value.bias', 'base_model.embeddings.LayerNorm.bias', 'base_model.encoder.layer.0.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.13.attention.self.query.weight', 'base_model.encoder.layer.16.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.22.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.20.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.21.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.11.output.LayerNorm.bias', 'base_model.encoder.layer.7.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.22.output.dense.weight', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.19.attention.output.dense.bias', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.22.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.11.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.9.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.3.output.LayerNorm.bias', 'base_model.encoder.layer.7.attention.output.LayerNorm.weight', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.19.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.2.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.23.attention.self.query.weight', 'base_model.encoder.layer.18.output.dense.weight', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.22.attention.self.key.weight', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.13.attention.self.key.weight', 'base_model.encoder.layer.4.attention.self.key.bias', 'base_model.encoder.layer.13.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.12.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.3.attention.output.LayerNorm.weight', 'base_model.encoder.layer.22.attention.self.value.weight', 'base_model.encoder.layer.12.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.20.output.LayerNorm.weight', 'base_model.encoder.layer.4.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.22.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.20.intermediate.dense.weight', 'base_model.encoder.layer.20.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.23.attention.output.dense.weight', 'base_model.encoder.layer.12.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.6.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.4.attention.self.value.weight', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.11.attention.output.LayerNorm.weight', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.16.attention.self.key.weight', 'base_model.encoder.layer.20.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.17.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.16.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.2.intermediate.dense.weight', 'base_model.encoder.layer.18.attention.self.key.bias', 'base_model.encoder.layer.14.intermediate.dense.weight', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.4.output.dense.bias', 'base_model.encoder.layer.21.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.9.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.16.attention.output.LayerNorm.bias', 'base_model.embeddings.word_embeddings.weight', 'base_model.encoder.layer.0.attention.self.query.weight', 'base_model.encoder.layer.0.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.1.intermediate.dense.weight', 'base_model.encoder.layer.9.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.4.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.0.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.23.attention.output.LayerNorm.weight', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.19.output.LayerNorm.weight', 'base_model.encoder.layer.12.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.7.output.dense.weight', 'base_model.encoder.layer.22.output.dense.bias', 'base_model.encoder.layer.18.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.13.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.9.attention.self.value.weight', 'base_model.encoder.layer.21.attention.self.key.bias', 'base_model.encoder.layer.22.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.0.attention.output.LayerNorm.bias', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.3.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.8.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.8.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.7.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.23.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.14.attention.self.key.bias', 'base_model.encoder.layer.5.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.23.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.21.output.LayerNorm.bias', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.0.output.LayerNorm.weight', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.2.attention.self.key.weight', 'base_model.encoder.layer.11.output.dense.bias', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.11.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.14.attention.self.key.weight', 'base_model.encoder.layer.20.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.17.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.7.attention.self.key.bias', 'base_model.encoder.layer.14.attention.output.dense.bias', 'base_model.encoder.layer.1.attention.output.LayerNorm.bias', 'base_model.encoder.layer.2.intermediate.dense.bias', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.10.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.20.attention.output.dense.weight', 'base_model.encoder.layer.8.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.14.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.3.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.2.output.dense.bias', 'base_model.encoder.layer.19.attention.self.key.weight', 'base_model.encoder.layer.18.attention.self.value.bias', 'base_model.encoder.layer.20.attention.self.key.weight', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.15.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.17.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.15.attention.self.value.weight', 'base_model.encoder.layer.20.attention.output.LayerNorm.weight', 'base_model.encoder.layer.20.output.dense.weight', 'base_model.encoder.layer.0.intermediate.dense.weight', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.19.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.20.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.0.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.13.output.LayerNorm.weight', 'base_model.encoder.layer.17.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.4.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.10.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.23.attention.self.query.bias', 'base_model.encoder.layer.10.output.dense.bias', 'base_model.encoder.layer.8.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.14.attention.self.query.weight', 'base_model.encoder.layer.5.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.18.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.3.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.14.output.LayerNorm.weight', 'base_model.encoder.layer.17.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.2.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.19.intermediate.dense.weight', 'base_model.encoder.layer.23.attention.self.key.bias', 'base_model.encoder.layer.3.attention.output.dense.bias', 'base_model.encoder.layer.3.output.dense.bias', 'base_model.encoder.layer.12.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.11.attention.output.LayerNorm.bias', 'base_model.encoder.layer.8.attention.self.value.weight', 'base_model.encoder.layer.2.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.14.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.22.attention.self.value.bias', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.10.output.LayerNorm.bias', 'base_model.encoder.layer.12.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.6.intermediate.dense.bias', 'base_model.encoder.layer.17.attention.self.value.weight', 'base_model.encoder.layer.14.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.23.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.20.attention.self.key.bias', 'base_model.encoder.layer.18.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.13.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.0.attention.output.dense.bias', 'base_model.encoder.layer.9.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.2.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.19.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.6.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.0.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.10.attention.self.query.weight', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.9.attention.output.dense.weight', 'base_model.pooler.dense.weight', 'base_model.encoder.layer.18.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.20.attention.output.LayerNorm.bias', 'base_model.encoder.layer.20.attention.self.value.weight', 'qa_outputs.weight', 'base_model.encoder.layer.1.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.11.attention.output.dense.weight', 'base_model.encoder.layer.13.output.dense.weight', 'base_model.encoder.layer.4.output.dense.weight', 'base_model.encoder.layer.15.attention.self.key.bias', 'base_model.encoder.layer.20.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.4.attention.output.LayerNorm.bias', 'base_model.encoder.layer.0.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.16.output.dense.weight', 'base_model.encoder.layer.19.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.16.attention.self.value.bias', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.22.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.6.output.LayerNorm.weight', 'base_model.encoder.layer.3.attention.self.value.weight', 'base_model.encoder.layer.18.attention.self.query.bias', 'base_model.encoder.layer.18.attention.output.LayerNorm.weight', 'base_model.encoder.layer.7.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.1.attention.self.value.weight', 'base_model.encoder.layer.20.attention.self.query.bias', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.11.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.15.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.10.attention.self.query.bias', 'base_model.encoder.layer.3.output.dense.weight', 'base_model.encoder.layer.10.intermediate.dense.bias', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.5.output.dense.bias', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.2.attention.output.LayerNorm.weight', 'base_model.encoder.layer.4.attention.output.dense.weight', 'base_model.encoder.layer.6.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.6.output.dense.bias', 'base_model.encoder.layer.16.attention.output.dense.weight', 'base_model.encoder.layer.6.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.23.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.6.attention.output.dense.bias', 'base_model.encoder.layer.0.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.13.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.13.attention.self.value.bias', 'base_model.encoder.layer.1.output.dense.bias', 'base_model.encoder.layer.2.attention.self.value.weight', 'base_model.encoder.layer.11.attention.self.value.bias', 'base_model.encoder.layer.1.output.LayerNorm.weight', 'base_model.encoder.layer.12.attention.self.value.weight', 'base_model.encoder.layer.9.attention.output.LayerNorm.weight', 'base_model.encoder.layer.11.intermediate.dense.weight', 'base_model.encoder.layer.15.attention.self.key.weight', 'base_model.encoder.layer.17.attention.self.query.weight', 'base_model.encoder.layer.13.intermediate.dense.bias', 'base_model.encoder.layer.12.output.LayerNorm.weight', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.0.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.3.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.14.intermediate.dense.bias', 'base_model.encoder.layer.18.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.2.attention.output.dense.bias', 'base_model.encoder.layer.8.attention.output.dense.bias', 'base_model.encoder.layer.12.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.8.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.3.intermediate.dense.weight', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.15.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.23.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.1.attention.self.key.weight', 'base_model.encoder.layer.6.attention.self.key.weight', 'base_model.encoder.layer.22.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.18.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.13.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.0.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.13.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.12.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.2.output.LayerNorm.weight', 'base_model.encoder.layer.22.attention.output.dense.bias', 'base_model.encoder.layer.13.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.8.attention.self.query.weight', 'base_model.encoder.layer.16.intermediate.dense.weight', 'base_model.encoder.layer.16.attention.output.LayerNorm.weight', 'base_model.encoder.layer.15.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.22.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.18.attention.self.query.weight', 'base_model.encoder.layer.21.attention.output.dense.bias', 'base_model.encoder.layer.9.output.dense.bias', 'base_model.encoder.layer.17.attention.output.LayerNorm.weight', 'base_model.encoder.layer.10.attention.self.value.weight', 'base_model.encoder.layer.15.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.15.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.3.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.22.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.4.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.10.attention.output.LayerNorm.weight', 'base_model.encoder.layer.8.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.14.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.1.attention.output.LayerNorm.weight', 'base_model.encoder.layer.10.attention.self.key.weight', 'base_model.encoder.layer.1.attention.self.key.bias', 'base_model.encoder.layer.7.intermediate.dense.weight', 'base_model.encoder.layer.12.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.12.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.19.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.12.intermediate.dense.bias', 'base_model.encoder.layer.17.attention.output.dense.weight', 'base_model.encoder.layer.12.attention.output.dense.weight', 'base_model.encoder.layer.20.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.2.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.11.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.18.attention.output.LayerNorm.bias', 'base_model.encoder.layer.19.attention.output.dense.weight', 'base_model.encoder.layer.22.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.9.attention.output.dense.bias', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.15.output.dense.weight', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.14.attention.output.LayerNorm.bias', 'base_model.encoder.layer.13.attention.output.dense.bias', 'base_model.encoder.layer.21.output.dense.bias', 'base_model.encoder.layer.19.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.0.output.LayerNorm.bias', 'base_model.encoder.layer.7.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.18.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.7.output.LayerNorm.weight', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.13.attention.output.LayerNorm.weight', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.3.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.3.attention.self.value.bias', 'base_model.encoder.layer.17.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.2.attention.output.LayerNorm.bias', 'base_model.encoder.layer.8.attention.self.key.weight', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.15.attention.self.value.bias', 'base_model.encoder.layer.16.output.dense.bias', 'base_model.encoder.layer.15.output.dense.bias', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.8.attention.output.LayerNorm.bias', 'base_model.encoder.layer.4.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.2.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.22.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.22.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.10.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.10.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.16.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.3.attention.self.key.bias', 'base_model.encoder.layer.7.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.10.attention.output.dense.weight', 'base_model.encoder.layer.9.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.12.attention.output.dense.bias', 'base_model.encoder.layer.4.intermediate.dense.weight', 'base_model.encoder.layer.0.attention.self.query.bias', 'base_model.encoder.layer.20.output.dense.bias', 'base_model.encoder.layer.2.output.adapters.ep.adapter_up.bias', 'base_model.embeddings.LayerNorm.weight', 'base_model.encoder.layer.16.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.1.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.22.intermediate.dense.bias', 'base_model.encoder.layer.13.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.3.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.21.intermediate.dense.bias', 'base_model.encoder.layer.15.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.21.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.15.attention.output.dense.bias', 'base_model.encoder.layer.7.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.20.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.23.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.5.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.20.output.LayerNorm.bias', 'base_model.encoder.layer.6.intermediate.dense.weight', 'base_model.encoder.layer.9.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.14.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.4.attention.self.key.weight', 'base_model.encoder.layer.11.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.8.attention.output.LayerNorm.weight', 'base_model.encoder.layer.2.attention.self.value.bias', 'base_model.encoder.layer.23.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.21.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.14.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.21.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.17.output.dense.weight', 'base_model.encoder.layer.23.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.23.intermediate.dense.bias', 'base_model.encoder.layer.20.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.15.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.20.attention.self.value.bias', 'base_model.encoder.layer.4.attention.self.query.bias', 'base_model.encoder.layer.16.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.22.attention.output.dense.weight', 'base_model.encoder.layer.4.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.11.intermediate.dense.bias', 'base_model.encoder.layer.8.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.17.attention.self.value.bias', 'base_model.encoder.layer.7.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.16.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.18.output.dense.bias', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.2.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.3.output.LayerNorm.weight', 'base_model.encoder.layer.9.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.5.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.5.attention.self.query.bias', 'base_model.encoder.layer.4.attention.output.dense.bias', 'base_model.encoder.layer.4.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.16.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.14.output.LayerNorm.bias', 'base_model.encoder.layer.13.attention.self.query.bias', 'base_model.encoder.layer.6.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.13.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.9.intermediate.dense.bias', 'base_model.encoder.layer.3.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.9.attention.output.LayerNorm.bias', 'base_model.encoder.layer.11.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.21.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.9.attention.self.query.bias', 'base_model.encoder.layer.6.attention.self.value.weight', 'base_model.encoder.layer.14.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.18.intermediate.dense.weight', 'base_model.encoder.layer.8.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.8.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.16.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.17.output.LayerNorm.bias', 'base_model.encoder.layer.19.output.LayerNorm.bias', 'base_model.encoder.layer.0.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.3.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.5.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.10.attention.self.value.bias', 'base_model.encoder.layer.18.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.23.attention.self.key.weight', 'base_model.encoder.layer.23.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.8.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.3.attention.self.key.weight', 'base_model.encoder.layer.4.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.1.output.LayerNorm.bias', 'base_model.encoder.layer.8.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.19.attention.output.LayerNorm.bias', 'base_model.encoder.layer.5.attention.output.LayerNorm.weight', 'base_model.encoder.layer.18.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.15.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.0.attention.self.value.weight', 'base_model.encoder.layer.10.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.2.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.6.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.22.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.9.output.LayerNorm.bias', 'base_model.encoder.layer.11.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.3.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.1.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.4.attention.output.LayerNorm.weight', 'base_model.encoder.layer.19.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.16.attention.self.value.weight', 'base_model.encoder.layer.1.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.23.output.dense.weight', 'base_model.encoder.layer.18.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.1.attention.self.value.bias', 'base_model.encoder.layer.5.intermediate.dense.weight', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.11.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.21.attention.output.dense.weight', 'base_model.encoder.layer.19.attention.self.value.weight', 'base_model.encoder.layer.5.attention.self.value.bias', 'base_model.encoder.layer.6.attention.self.query.weight', 'base_model.encoder.layer.6.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.13.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.0.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.18.attention.self.value.weight', 'base_model.encoder.layer.16.attention.self.query.bias', 'base_model.encoder.layer.8.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.7.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.9.output.dense.weight', 'base_model.encoder.layer.2.attention.output.dense.weight', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.11.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.13.attention.self.value.weight', 'base_model.encoder.layer.16.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.7.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.16.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.18.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.7.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.4.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.6.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.2.attention.self.key.bias', 'base_model.encoder.layer.4.output.LayerNorm.bias', 'base_model.encoder.layer.8.intermediate.dense.weight', 'base_model.encoder.layer.14.attention.output.LayerNorm.weight', 'base_model.encoder.layer.18.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.21.output.dense.weight', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.1.attention.self.query.weight', 'base_model.encoder.layer.3.intermediate.dense.bias', 'base_model.encoder.layer.4.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.16.attention.self.query.weight', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.15.attention.output.dense.weight', 'base_model.encoder.layer.18.attention.self.key.weight', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.23.output.LayerNorm.weight', 'base_model.encoder.layer.15.attention.self.query.weight', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.13.attention.self.key.bias', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.14.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.6.attention.output.dense.weight', 'base_model.encoder.layer.12.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.10.attention.self.key.bias', 'base_model.encoder.layer.9.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.0.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.16.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.11.attention.self.key.bias', 'base_model.encoder.layer.10.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.13.output.dense.bias', 'base_model.encoder.layer.19.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.5.attention.self.query.weight', 'base_model.encoder.layer.15.attention.output.LayerNorm.weight', 'base_model.encoder.layer.7.intermediate.dense.bias', 'base_model.encoder.layer.11.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.19.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.9.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.12.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.0.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.21.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.22.attention.output.LayerNorm.weight', 'base_model.encoder.layer.9.attention.self.key.bias', 'base_model.encoder.layer.11.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.9.attention.self.query.weight', 'base_model.encoder.layer.7.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.0.output.dense.bias', 'base_model.encoder.layer.10.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.2.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.11.attention.self.key.weight', 'base_model.encoder.layer.9.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.17.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.5.attention.output.LayerNorm.bias', 'base_model.encoder.layer.4.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.3.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.16.attention.output.dense.bias', 'base_model.encoder.layer.15.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.3.attention.output.LayerNorm.bias', 'base_model.encoder.layer.9.intermediate.dense.weight', 'base_model.encoder.layer.18.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.20.attention.self.query.weight', 'base_model.encoder.layer.6.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.14.attention.self.value.weight', 'base_model.encoder.layer.11.attention.self.query.weight', 'base_model.encoder.layer.1.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.12.attention.self.key.weight', 'base_model.encoder.layer.5.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.16.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.23.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.0.attention.output.dense.weight', 'base_model.encoder.layer.7.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.12.attention.output.LayerNorm.weight', 'base_model.encoder.layer.3.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.12.attention.self.value.bias', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.18.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.17.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.21.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.10.attention.output.dense.bias', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.14.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.2.attention.self.query.weight', 'base_model.embeddings.position_embeddings.weight', 'base_model.encoder.layer.7.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.1.intermediate.dense.bias', 'base_model.encoder.layer.8.attention.self.key.bias', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.7.attention.output.LayerNorm.bias', 'base_model.encoder.layer.5.output.LayerNorm.bias', 'base_model.encoder.layer.11.attention.output.dense.bias', 'base_model.encoder.layer.17.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.21.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.21.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.14.attention.output.dense.weight', 'base_model.encoder.layer.16.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.21.intermediate.dense.weight', 'base_model.encoder.layer.10.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.1.output.dense.weight', 'base_model.encoder.layer.6.output.LayerNorm.bias', 'base_model.encoder.layer.9.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.10.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.10.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.21.attention.output.LayerNorm.weight', 'base_model.encoder.layer.23.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.13.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.17.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.21.attention.self.value.weight', 'base_model.encoder.layer.14.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.4.intermediate.dense.bias', 'base_model.encoder.layer.12.output.dense.weight', 'base_model.encoder.layer.21.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.22.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.7.output.dense.bias', 'base_model.encoder.layer.13.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.7.output.LayerNorm.bias', 'base_model.encoder.layer.17.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.21.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.1.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.6.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.14.output.dense.bias', 'base_model.encoder.layer.17.attention.self.key.bias', 'base_model.encoder.layer.18.output.LayerNorm.weight', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.7.attention.self.key.weight', 'base_model.encoder.layer.22.output.LayerNorm.bias', 'base_model.encoder.layer.6.attention.output.LayerNorm.bias', 'base_model.encoder.layer.5.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.22.attention.output.LayerNorm.bias', 'base_model.encoder.layer.4.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.19.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.13.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.5.attention.output.dense.bias', 'base_model.encoder.layer.6.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.19.output.dense.bias', 'base_model.encoder.layer.4.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.5.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.23.attention.output.dense.bias', 'base_model.encoder.layer.4.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.20.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.1.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.22.output.adapters.ts.adapter_up.bias', 'base_model.embeddings.position_ids', 'base_model.encoder.layer.5.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.14.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.5.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.11.output.LayerNorm.weight', 'base_model.encoder.layer.19.output.dense.weight', 'base_model.encoder.layer.21.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.11.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.18.output.LayerNorm.bias', 'base_model.encoder.layer.2.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.19.attention.self.query.bias', 'base_model.encoder.layer.22.output.LayerNorm.weight', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.21.attention.self.value.bias', 'base_model.encoder.layer.19.attention.self.value.bias', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.20.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.8.attention.self.value.bias', 'base_model.encoder.layer.22.intermediate.dense.weight', 'base_model.encoder.layer.0.intermediate.dense.bias', 'base_model.encoder.layer.12.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.9.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.7.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.8.output.LayerNorm.bias', 'base_model.encoder.layer.9.attention.self.value.bias', 'base_model.encoder.layer.9.output.LayerNorm.weight', 'base_model.encoder.layer.16.attention.self.key.bias', 'base_model.encoder.layer.0.attention.output.LayerNorm.weight', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.12.attention.self.query.weight', 'base_model.encoder.layer.19.intermediate.dense.bias', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.17.output.LayerNorm.weight', 'base_model.encoder.layer.10.intermediate.dense.weight', 'base_model.encoder.layer.15.output.LayerNorm.weight', 'base_model.encoder.layer.14.attention.self.query.bias', 'base_model.encoder.layer.23.attention.self.value.bias', 'base_model.encoder.layer.21.attention.self.key.weight', 'base_model.encoder.layer.23.output.LayerNorm.bias', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.17.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.1.attention.output.dense.bias', 'base_model.encoder.layer.22.attention.self.query.weight', 'base_model.encoder.layer.15.attention.self.query.bias', 'base_model.encoder.layer.3.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.6.output.dense.weight', 'base_model.encoder.layer.6.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.15.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.0.attention.self.key.bias', 'base_model.encoder.layer.0.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.13.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.12.attention.output.LayerNorm.bias', 'base_model.encoder.layer.0.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.13.attention.output.dense.weight', 'base_model.encoder.layer.12.attention.self.query.bias', 'base_model.encoder.layer.5.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.12.output.dense.bias', 'base_model.encoder.layer.18.intermediate.dense.bias', 'base_model.encoder.layer.18.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.8.output.dense.weight', 'base_model.encoder.layer.21.attention.self.query.bias', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.6.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.1.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.14.attention.self.value.bias', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.4.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.21.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.15.output.LayerNorm.bias', 'base_model.pooler.dense.bias', 'base_model.encoder.layer.23.attention.self.value.weight', 'base_model.encoder.layer.23.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.22.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.11.attention.self.query.bias', 'base_model.encoder.layer.15.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.3.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.10.output.dense.weight', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.8.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.0.attention.self.value.bias', 'base_model.encoder.layer.1.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.9.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.6.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.18.attention.output.dense.weight', 'base_model.encoder.layer.1.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.9.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.17.attention.output.dense.bias', 'base_model.encoder.layer.21.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.6.attention.self.query.bias', 'base_model.encoder.layer.2.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.10.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.20.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.8.attention.self.query.bias', 'base_model.encoder.layer.19.attention.output.LayerNorm.weight', 'base_model.encoder.layer.11.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.13.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.10.output.LayerNorm.weight', 'base_model.encoder.layer.22.attention.self.key.bias', 'base_model.encoder.layer.8.intermediate.dense.bias', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.11.attention.self.value.weight', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.8.output.LayerNorm.weight', 'base_model.encoder.layer.1.attention.output.dense.weight', 'base_model.encoder.layer.15.attention.output.LayerNorm.bias', 'base_model.encoder.layer.20.attention.output.dense.bias', 'base_model.encoder.layer.3.attention.self.query.bias', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.8.attention.output.dense.weight', 'base_model.encoder.layer.16.output.LayerNorm.bias', 'base_model.encoder.layer.23.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.2.attention.self.query.bias', 'base_model.encoder.layer.5.attention.self.key.bias', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.21.attention.output.LayerNorm.bias', 'base_model.encoder.layer.19.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.17.intermediate.dense.bias', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.23.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.14.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.19.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.12.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.14.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.1.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.19.attention.self.query.weight', 'base_model.encoder.layer.19.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.18.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.21.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.6.attention.self.value.bias', 'base_model.encoder.layer.4.output.LayerNorm.weight', 'base_model.encoder.layer.5.attention.self.value.weight', 'base_model.encoder.layer.19.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.7.attention.output.dense.weight', 'base_model.encoder.layer.5.output.dense.weight', 'base_model.encoder.layer.17.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.12.intermediate.dense.weight', 'base_model.encoder.layer.2.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.2.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.12.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.16.intermediate.dense.bias', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.21.output.LayerNorm.weight', 'base_model.encoder.layer.17.attention.output.LayerNorm.bias', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.5.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.16.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.13.attention.output.LayerNorm.bias', 'base_model.encoder.layer.11.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.14.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.20.intermediate.dense.bias', 'base_model.encoder.layer.15.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.17.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.20.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.2.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.12.output.LayerNorm.bias', 'base_model.encoder.layer.19.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.8.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.6.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.13.output.LayerNorm.bias', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.14.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.17.intermediate.dense.weight', 'base_model.encoder.layer.0.attention.self.key.weight', 'base_model.encoder.layer.7.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.12.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.5.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.11.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.15.intermediate.dense.bias', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.2.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.5.attention.self.key.weight', 'base_model.encoder.layer.23.attention.output.LayerNorm.bias', 'base_model.encoder.layer.2.output.LayerNorm.bias', 'base_model.encoder.layer.1.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.7.attention.output.dense.bias', 'base_model.encoder.layer.7.attention.self.query.bias', 'base_model.encoder.layer.0.output.dense.weight', 'base_model.encoder.layer.14.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.5.attention.output.dense.weight', 'base_model.encoder.layer.1.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.17.output.dense.bias', 'base_model.encoder.layer.8.output.dense.bias', 'base_model.encoder.layer.4.attention.self.query.weight', 'base_model.encoder.layer.22.attention.self.query.bias', 'base_model.embeddings.token_type_embeddings.weight', 'base_model.encoder.layer.3.attention.self.query.weight', 'base_model.encoder.layer.11.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.15.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.3.attention.output.dense.weight', 'base_model.encoder.layer.0.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.23.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.9.attention.self.key.weight', 'base_model.encoder.layer.16.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.21.attention.self.query.weight', 'base_model.encoder.layer.6.attention.self.key.bias', 'qa_outputs.bias', 'base_model.encoder.layer.20.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.13.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.9.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.20.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.5.output.LayerNorm.weight', 'base_model.encoder.layer.7.attention.self.query.weight', 'base_model.encoder.layer.10.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.15.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.17.attention.self.query.bias', 'base_model.encoder.layer.19.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.1.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.9.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.3.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.19.attention.self.key.bias', 'base_model.encoder.layer.10.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.12.attention.self.key.bias', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.16.output.LayerNorm.weight', 'base_model.encoder.layer.15.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.2.output.dense.weight', 'base_model.encoder.layer.7.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.11.output.dense.weight', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.22.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.1.attention.self.query.bias', 'base_model.encoder.layer.5.intermediate.dense.bias']
- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of XLMRobertaModel were not initialized from the model checkpoint at /cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//tydiqa/xlm-KG_LR8e-6_EPOCH2.0_maxlen384_batchsize4_gradacc4 and are newly initialized: ['encoder.layer.10.attention.output.dense.bias', 'encoder.layer.23.output.dense.bias', 'encoder.layer.10.attention.self.value.bias', 'embeddings.position_embeddings.weight', 'encoder.layer.7.output.LayerNorm.bias', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.23.output.dense.weight', 'encoder.layer.5.attention.self.value.weight', 'encoder.layer.3.attention.self.value.bias', 'encoder.layer.15.attention.output.dense.weight', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.5.attention.self.query.weight', 'encoder.layer.7.attention.self.key.weight', 'encoder.layer.2.output.dense.bias', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.5.attention.self.key.bias', 'encoder.layer.6.attention.output.LayerNorm.bias', 'encoder.layer.15.intermediate.dense.weight', 'encoder.layer.8.output.LayerNorm.weight', 'encoder.layer.13.attention.self.key.weight', 'encoder.layer.16.attention.self.key.bias', 'encoder.layer.18.attention.self.value.weight', 'encoder.layer.13.attention.output.LayerNorm.weight', 'encoder.layer.19.attention.output.dense.weight', 'encoder.layer.2.attention.self.value.bias', 'encoder.layer.19.attention.output.LayerNorm.bias', 'encoder.layer.21.attention.self.query.bias', 'encoder.layer.10.attention.self.value.weight', 'encoder.layer.11.attention.output.dense.weight', 'encoder.layer.4.attention.self.key.weight', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.3.attention.self.key.weight', 'encoder.layer.0.attention.self.query.weight', 'encoder.layer.23.attention.self.value.bias', 'encoder.layer.12.intermediate.dense.bias', 'encoder.layer.0.attention.self.value.weight', 'encoder.layer.4.attention.self.query.bias', 'encoder.layer.9.attention.self.query.bias', 'encoder.layer.15.attention.self.value.weight', 'encoder.layer.9.output.dense.bias', 'encoder.layer.9.attention.output.dense.weight', 'encoder.layer.11.attention.self.key.weight', 'encoder.layer.16.attention.self.key.weight', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.18.attention.self.query.weight', 'encoder.layer.20.attention.output.LayerNorm.bias', 'encoder.layer.23.attention.self.key.bias', 'encoder.layer.12.output.dense.bias', 'encoder.layer.23.output.LayerNorm.bias', 'encoder.layer.22.output.LayerNorm.bias', 'encoder.layer.18.attention.self.query.bias', 'encoder.layer.5.attention.self.value.bias', 'encoder.layer.2.attention.output.dense.bias', 'encoder.layer.16.intermediate.dense.bias', 'encoder.layer.6.attention.output.dense.weight', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.18.attention.output.dense.bias', 'encoder.layer.10.attention.output.LayerNorm.bias', 'encoder.layer.5.output.LayerNorm.bias', 'encoder.layer.21.attention.self.key.weight', 'encoder.layer.21.attention.self.query.weight', 'encoder.layer.15.intermediate.dense.bias', 'encoder.layer.10.intermediate.dense.weight', 'encoder.layer.9.attention.self.value.bias', 'encoder.layer.15.attention.self.query.weight', 'encoder.layer.0.attention.self.key.weight', 'encoder.layer.19.attention.self.value.bias', 'encoder.layer.19.output.LayerNorm.weight', 'encoder.layer.20.output.dense.bias', 'encoder.layer.4.attention.output.dense.weight', 'encoder.layer.17.output.dense.bias', 'encoder.layer.17.output.dense.weight', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.19.attention.self.query.weight', 'encoder.layer.15.attention.self.key.bias', 'encoder.layer.20.attention.self.query.weight', 'encoder.layer.16.attention.output.dense.weight', 'encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.layer.7.attention.output.dense.weight', 'encoder.layer.18.attention.output.LayerNorm.weight', 'encoder.layer.20.output.dense.weight', 'encoder.layer.4.output.dense.bias', 'encoder.layer.20.attention.self.query.bias', 'encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.layer.21.attention.output.LayerNorm.weight', 'encoder.layer.20.output.LayerNorm.weight', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.14.attention.self.value.weight', 'encoder.layer.12.output.dense.weight', 'encoder.layer.2.output.dense.weight', 'encoder.layer.18.intermediate.dense.bias', 'encoder.layer.10.output.LayerNorm.bias', 'encoder.layer.14.output.LayerNorm.bias', 'encoder.layer.5.intermediate.dense.bias', 'pooler.dense.bias', 'encoder.layer.18.attention.output.dense.weight', 'encoder.layer.19.output.dense.bias', 'encoder.layer.23.attention.self.query.weight', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.4.attention.output.dense.bias', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.3.attention.self.query.bias', 'encoder.layer.21.attention.self.key.bias', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.11.attention.self.value.weight', 'encoder.layer.13.output.dense.weight', 'encoder.layer.15.output.LayerNorm.bias', 'encoder.layer.20.attention.output.dense.bias', 'encoder.layer.17.attention.self.query.bias', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.8.attention.self.query.weight', 'encoder.layer.15.output.LayerNorm.weight', 'encoder.layer.9.attention.output.dense.bias', 'encoder.layer.1.attention.output.dense.bias', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.layer.4.attention.self.value.weight', 'encoder.layer.9.attention.self.key.weight', 'encoder.layer.10.attention.output.dense.weight', 'encoder.layer.4.attention.self.key.bias', 'encoder.layer.9.attention.output.LayerNorm.weight', 'encoder.layer.6.attention.self.value.weight', 'encoder.layer.16.attention.self.value.bias', 'encoder.layer.19.attention.output.LayerNorm.weight', 'encoder.layer.9.attention.self.key.bias', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.16.attention.output.LayerNorm.bias', 'encoder.layer.15.output.dense.bias', 'encoder.layer.13.intermediate.dense.bias', 'encoder.layer.5.attention.output.dense.bias', 'encoder.layer.22.attention.self.value.bias', 'encoder.layer.16.intermediate.dense.weight', 'encoder.layer.22.attention.output.LayerNorm.bias', 'encoder.layer.6.output.LayerNorm.bias', 'encoder.layer.6.attention.output.LayerNorm.weight', 'encoder.layer.8.attention.output.dense.weight', 'encoder.layer.17.output.LayerNorm.weight', 'encoder.layer.20.attention.output.LayerNorm.weight', 'encoder.layer.12.intermediate.dense.weight', 'encoder.layer.17.attention.self.query.weight', 'encoder.layer.15.output.dense.weight', 'encoder.layer.6.output.dense.bias', 'encoder.layer.18.output.dense.bias', 'encoder.layer.21.attention.output.LayerNorm.bias', 'encoder.layer.4.output.dense.weight', 'encoder.layer.13.attention.output.LayerNorm.bias', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.21.intermediate.dense.bias', 'encoder.layer.18.intermediate.dense.weight', 'encoder.layer.12.attention.self.query.bias', 'encoder.layer.21.attention.output.dense.weight', 'encoder.layer.16.attention.output.dense.bias', 'encoder.layer.14.attention.self.value.bias', 'encoder.layer.16.attention.self.value.weight', 'encoder.layer.16.attention.self.query.bias', 'encoder.layer.4.attention.output.LayerNorm.bias', 'encoder.layer.17.attention.output.dense.bias', 'encoder.layer.1.attention.self.key.bias', 'encoder.layer.22.output.dense.weight', 'encoder.layer.1.attention.self.key.weight', 'encoder.layer.20.attention.self.value.weight', 'encoder.layer.1.attention.self.value.weight', 'encoder.layer.3.output.dense.weight', 'encoder.layer.21.attention.self.value.bias', 'encoder.layer.23.attention.output.LayerNorm.weight', 'encoder.layer.14.output.LayerNorm.weight', 'encoder.layer.23.attention.self.value.weight', 'encoder.layer.11.attention.self.value.bias', 'encoder.layer.18.output.LayerNorm.weight', 'encoder.layer.8.output.dense.weight', 'encoder.layer.13.attention.self.query.bias', 'encoder.layer.20.attention.self.key.weight', 'encoder.layer.10.attention.self.key.bias', 'encoder.layer.7.attention.output.LayerNorm.weight', 'encoder.layer.18.attention.self.key.bias', 'encoder.layer.23.attention.self.key.weight', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.1.attention.self.query.bias', 'encoder.layer.12.attention.output.dense.bias', 'encoder.layer.11.attention.self.query.weight', 'encoder.layer.4.intermediate.dense.weight', 'pooler.dense.weight', 'encoder.layer.22.attention.output.LayerNorm.weight', 'encoder.layer.2.attention.output.LayerNorm.weight', 'encoder.layer.6.attention.self.query.bias', 'encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.18.attention.self.key.weight', 'encoder.layer.16.output.LayerNorm.bias', 'encoder.layer.21.intermediate.dense.weight', 'encoder.layer.0.attention.output.LayerNorm.weight', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.11.output.dense.weight', 'encoder.layer.20.attention.self.value.bias', 'encoder.layer.7.output.dense.weight', 'encoder.layer.3.attention.output.dense.weight', 'encoder.layer.13.attention.output.dense.bias', 'encoder.layer.8.output.dense.bias', 'encoder.layer.8.attention.self.query.bias', 'encoder.layer.4.attention.output.LayerNorm.weight', 'encoder.layer.18.output.LayerNorm.bias', 'encoder.layer.23.intermediate.dense.bias', 'encoder.layer.23.attention.output.LayerNorm.bias', 'encoder.layer.0.attention.output.dense.weight', 'encoder.layer.7.attention.self.value.bias', 'encoder.layer.14.output.dense.bias', 'encoder.layer.6.attention.self.value.bias', 'encoder.layer.6.attention.output.dense.bias', 'encoder.layer.21.output.dense.weight', 'encoder.layer.1.attention.output.dense.weight', 'encoder.layer.13.attention.output.dense.weight', 'encoder.layer.4.attention.self.query.weight', 'encoder.layer.12.output.LayerNorm.bias', 'encoder.layer.17.attention.self.value.weight', 'encoder.layer.22.attention.self.query.bias', 'encoder.layer.9.attention.self.value.weight', 'encoder.layer.17.attention.output.LayerNorm.bias', 'encoder.layer.7.intermediate.dense.bias', 'encoder.layer.8.output.LayerNorm.bias', 'encoder.layer.17.attention.output.dense.weight', 'encoder.layer.13.attention.self.query.weight', 'encoder.layer.10.attention.self.query.weight', 'encoder.layer.3.attention.self.value.weight', 'encoder.layer.13.attention.self.value.weight', 'encoder.layer.18.attention.output.LayerNorm.bias', 'encoder.layer.22.attention.self.key.bias', 'encoder.layer.20.output.LayerNorm.bias', 'encoder.layer.17.output.LayerNorm.bias', 'encoder.layer.2.attention.output.dense.weight', 'encoder.layer.3.attention.self.key.bias', 'encoder.layer.7.attention.output.LayerNorm.bias', 'encoder.layer.11.attention.self.key.bias', 'encoder.layer.19.attention.self.key.bias', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.10.attention.output.LayerNorm.weight', 'encoder.layer.11.attention.output.LayerNorm.weight', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.22.intermediate.dense.bias', 'encoder.layer.12.attention.output.dense.weight', 'encoder.layer.13.attention.self.value.bias', 'encoder.layer.12.attention.self.value.weight', 'encoder.layer.7.attention.self.key.bias', 'encoder.layer.16.output.dense.weight', 'encoder.layer.8.attention.self.value.bias', 'encoder.layer.17.attention.self.value.bias', 'embeddings.token_type_embeddings.weight', 'encoder.layer.9.output.LayerNorm.weight', 'encoder.layer.14.intermediate.dense.weight', 'encoder.layer.22.attention.self.key.weight', 'encoder.layer.22.attention.output.dense.bias', 'encoder.layer.14.attention.self.query.weight', 'encoder.layer.10.output.dense.bias', 'encoder.layer.23.attention.output.dense.weight', 'encoder.layer.8.attention.self.key.bias', 'encoder.layer.0.attention.self.value.bias', 'encoder.layer.14.attention.self.key.bias', 'encoder.layer.10.attention.self.key.weight', 'encoder.layer.2.attention.self.value.weight', 'encoder.layer.14.attention.output.dense.weight', 'encoder.layer.15.attention.output.LayerNorm.weight', 'encoder.layer.18.attention.self.value.bias', 'encoder.layer.19.intermediate.dense.bias', 'encoder.layer.12.attention.self.value.bias', 'encoder.layer.19.attention.self.query.bias', 'encoder.layer.2.attention.self.query.weight', 'encoder.layer.13.attention.self.key.bias', 'encoder.layer.11.attention.output.dense.bias', 'encoder.layer.20.attention.output.dense.weight', 'encoder.layer.14.attention.output.dense.bias', 'encoder.layer.5.output.dense.weight', 'encoder.layer.19.intermediate.dense.weight', 'encoder.layer.20.intermediate.dense.weight', 'encoder.layer.22.output.LayerNorm.weight', 'encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.layer.4.attention.self.value.bias', 'encoder.layer.8.attention.self.key.weight', 'encoder.layer.22.attention.output.dense.weight', 'encoder.layer.15.attention.output.LayerNorm.bias', 'encoder.layer.1.attention.self.query.weight', 'encoder.layer.9.attention.output.LayerNorm.bias', 'encoder.layer.1.output.dense.weight', 'encoder.layer.21.output.LayerNorm.bias', 'encoder.layer.0.attention.self.key.bias', 'encoder.layer.8.attention.output.LayerNorm.bias', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.15.attention.output.dense.bias', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.6.attention.self.key.bias', 'encoder.layer.20.attention.self.key.bias', 'encoder.layer.18.output.dense.weight', 'encoder.layer.17.intermediate.dense.bias', 'encoder.layer.14.output.dense.weight', 'encoder.layer.0.output.dense.bias', 'encoder.layer.7.attention.self.query.bias', 'encoder.layer.16.output.LayerNorm.weight', 'encoder.layer.17.attention.output.LayerNorm.weight', 'encoder.layer.14.attention.self.key.weight', 'encoder.layer.7.attention.output.dense.bias', 'encoder.layer.11.output.LayerNorm.bias', 'encoder.layer.23.intermediate.dense.weight', 'encoder.layer.9.output.LayerNorm.bias', 'encoder.layer.22.attention.self.value.weight', 'encoder.layer.5.attention.output.dense.weight', 'encoder.layer.1.output.dense.bias', 'encoder.layer.10.output.LayerNorm.weight', 'encoder.layer.0.output.dense.weight', 'encoder.layer.6.attention.self.query.weight', 'encoder.layer.11.attention.self.query.bias', 'encoder.layer.15.attention.self.query.bias', 'embeddings.word_embeddings.weight', 'encoder.layer.22.attention.self.query.weight', 'encoder.layer.13.intermediate.dense.weight', 'encoder.layer.2.attention.output.LayerNorm.bias', 'encoder.layer.2.attention.self.query.bias', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.13.output.LayerNorm.weight', 'encoder.layer.0.attention.self.query.bias', 'encoder.layer.19.attention.self.value.weight', 'encoder.layer.3.output.dense.bias', 'embeddings.LayerNorm.bias', 'encoder.layer.10.attention.self.query.bias', 'encoder.layer.17.attention.self.key.weight', 'embeddings.LayerNorm.weight', 'encoder.layer.14.attention.output.LayerNorm.weight', 'encoder.layer.13.output.dense.bias', 'encoder.layer.1.attention.self.value.bias', 'encoder.layer.7.attention.self.query.weight', 'encoder.layer.14.intermediate.dense.bias', 'encoder.layer.8.attention.output.LayerNorm.weight', 'encoder.layer.6.output.dense.weight', 'encoder.layer.7.output.LayerNorm.weight', 'encoder.layer.21.output.LayerNorm.weight', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.20.intermediate.dense.bias', 'encoder.layer.21.attention.output.dense.bias', 'encoder.layer.3.attention.output.dense.bias', 'encoder.layer.5.attention.self.query.bias', 'encoder.layer.22.output.dense.bias', 'encoder.layer.17.attention.self.key.bias', 'encoder.layer.5.attention.self.key.weight', 'encoder.layer.12.attention.output.LayerNorm.weight', 'encoder.layer.21.attention.self.value.weight', 'encoder.layer.9.output.dense.weight', 'encoder.layer.19.attention.self.key.weight', 'encoder.layer.12.attention.self.key.bias', 'encoder.layer.2.attention.self.key.weight', 'encoder.layer.12.output.LayerNorm.weight', 'encoder.layer.17.intermediate.dense.weight', 'encoder.layer.6.attention.self.key.weight', 'encoder.layer.14.attention.output.LayerNorm.bias', 'encoder.layer.15.attention.self.value.bias', 'encoder.layer.8.attention.output.dense.bias', 'encoder.layer.11.output.dense.bias', 'encoder.layer.14.attention.self.query.bias', 'encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.layer.22.intermediate.dense.weight', 'encoder.layer.21.output.dense.bias', 'encoder.layer.2.attention.self.key.bias', 'encoder.layer.12.attention.self.key.weight', 'encoder.layer.13.output.LayerNorm.bias', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.12.attention.self.query.weight', 'encoder.layer.23.attention.self.query.bias', 'encoder.layer.16.attention.self.query.weight', 'encoder.layer.3.attention.self.query.weight', 'encoder.layer.7.attention.self.value.weight', 'encoder.layer.19.output.LayerNorm.bias', 'encoder.layer.15.attention.self.key.weight', 'encoder.layer.19.output.dense.weight', 'encoder.layer.8.attention.self.value.weight', 'encoder.layer.11.output.LayerNorm.weight', 'encoder.layer.7.output.dense.bias', 'encoder.layer.10.output.dense.weight', 'encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.layer.16.attention.output.LayerNorm.weight', 'encoder.layer.16.output.dense.bias', 'encoder.layer.19.attention.output.dense.bias', 'encoder.layer.1.attention.output.LayerNorm.weight', 'encoder.layer.23.attention.output.dense.bias', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.5.output.dense.bias', 'encoder.layer.9.attention.self.query.weight', 'encoder.layer.0.attention.output.dense.bias', 'encoder.layer.12.attention.output.LayerNorm.bias', 'encoder.layer.5.attention.output.LayerNorm.weight', 'encoder.layer.23.output.LayerNorm.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Overwriting existing adapter 'ep'.
Overwriting existing adapter 'tp'.
Overwriting existing adapter 'es'.
Overwriting existing adapter 'ts'.
Overwriting existing adapter fusion module 'ep,tp,es,ts'
05/09/2022 23:01:36 - INFO - __main__ -   Creating features from dataset file at .
/cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//tydiqa/xlm-KG_LR8e-6_EPOCH2.0_maxlen384_batchsize4_gradacc4
XLMConfig {
  "architectures": [
    "XLMRobertaForMaskedLM"
  ],
  "asm": false,
  "attention_dropout": 0.1,
  "attention_probs_dropout_prob": 0.1,
  "bos_index": 0,
  "bos_token_id": 0,
  "causal": false,
  "dropout": 0.1,
  "emb_dim": 1024,
  "embed_init_std": 0.02209708691207961,
  "end_n_top": 5,
  "eos_index": 1,
  "eos_token_id": 2,
  "gelu_activation": true,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "init_std": 0.02,
  "initializer_range": 0.02,
  "intermediate_size": 4096,
  "is_encoder": true,
  "lang_id": 0,
  "layer_norm_eps": 1e-05,
  "mask_index": 5,
  "mask_token_id": 0,
  "max_position_embeddings": 514,
  "model_type": "xlm",
  "n_heads": 16,
  "n_langs": 1,
  "n_layers": 24,
  "output_past": true,
  "pad_index": 2,
  "pad_token_id": 1,
  "sinusoidal_embeddings": false,
  "start_n_top": 5,
  "summary_activation": null,
  "summary_first_dropout": 0.1,
  "summary_proj_to_labels": true,
  "summary_type": "first",
  "summary_use_proj": true,
  "transformers_version": "4.17.0",
  "type_vocab_size": 1,
  "unk_index": 3,
  "use_lang_emb": false,
  "vocab_size": 250002
}

  0%|          | 0/669 [00:00<?, ?it/s] 69%|██████▉   | 464/669 [00:00<00:00, 4423.58it/s]100%|██████████| 669/669 [00:00<00:00, 4510.74it/s]
convert squad examples to features:   0%|          | 0/669 [00:00<?, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.
convert squad examples to features:   0%|          | 1/669 [00:00<01:43,  6.44it/s]convert squad examples to features:  10%|▉         | 65/669 [00:00<00:02, 218.38it/s]convert squad examples to features:  14%|█▍        | 97/669 [00:00<00:03, 160.39it/s]convert squad examples to features:  24%|██▍       | 161/669 [00:00<00:02, 226.57it/s]convert squad examples to features:  29%|██▉       | 193/669 [00:00<00:02, 228.75it/s]convert squad examples to features:  38%|███▊      | 257/669 [00:01<00:01, 254.04it/s]convert squad examples to features:  43%|████▎     | 289/669 [00:01<00:01, 260.27it/s]convert squad examples to features:  53%|█████▎    | 353/669 [00:01<00:01, 297.55it/s]convert squad examples to features:  58%|█████▊    | 385/669 [00:01<00:00, 296.08it/s]convert squad examples to features:  62%|██████▏   | 417/669 [00:01<00:00, 272.99it/s]convert squad examples to features:  72%|███████▏  | 481/669 [00:01<00:00, 293.13it/s]convert squad examples to features:  77%|███████▋  | 513/669 [00:01<00:00, 295.30it/s]convert squad examples to features:  86%|████████▌ | 577/669 [00:02<00:00, 288.14it/s]convert squad examples to features:  91%|█████████ | 609/669 [00:02<00:00, 290.03it/s]convert squad examples to features: 100%|██████████| 669/669 [00:02<00:00, 277.80it/s]
add example index and unique id:   0%|          | 0/669 [00:00<?, ?it/s]add example index and unique id: 100%|██████████| 669/669 [00:00<00:00, 676794.35it/s]
05/09/2022 23:01:39 - INFO - __main__ -   Saving features into cached file ./cached_tydiqa.goldp.te.dev.json_xlm-KG_LR8e-6_EPOCH2.0_maxlen384_batchsize4_gradacc4_384_te
05/09/2022 23:01:40 - INFO - __main__ -   ***** Running evaluation  *****
05/09/2022 23:01:40 - INFO - __main__ -     Num examples = 735
05/09/2022 23:01:40 - INFO - __main__ -     Batch size = 8
Evaluating:   0%|          | 0/92 [00:00<?, ?it/s]Evaluating:   1%|          | 1/92 [00:00<01:23,  1.08it/s]Evaluating:   2%|▏         | 2/92 [00:01<00:53,  1.70it/s]Evaluating:   3%|▎         | 3/92 [00:01<00:43,  2.07it/s]Evaluating:   4%|▍         | 4/92 [00:01<00:38,  2.30it/s]Evaluating:   5%|▌         | 5/92 [00:02<00:35,  2.42it/s]Evaluating:   7%|▋         | 6/92 [00:02<00:33,  2.53it/s]Evaluating:   8%|▊         | 7/92 [00:03<00:32,  2.61it/s]Evaluating:   9%|▊         | 8/92 [00:03<00:31,  2.67it/s]Evaluating:  10%|▉         | 9/92 [00:03<00:30,  2.71it/s]Evaluating:  11%|█         | 10/92 [00:04<00:30,  2.73it/s]Evaluating:  12%|█▏        | 11/92 [00:04<00:29,  2.74it/s]Evaluating:  13%|█▎        | 12/92 [00:04<00:28,  2.76it/s]Evaluating:  14%|█▍        | 13/92 [00:05<00:28,  2.78it/s]Evaluating:  15%|█▌        | 14/92 [00:05<00:28,  2.77it/s]Evaluating:  16%|█▋        | 15/92 [00:05<00:27,  2.78it/s]Evaluating:  17%|█▋        | 16/92 [00:06<00:27,  2.75it/s]Evaluating:  18%|█▊        | 17/92 [00:06<00:27,  2.75it/s]Evaluating:  20%|█▉        | 18/92 [00:07<00:26,  2.75it/s]Evaluating:  21%|██        | 19/92 [00:07<00:26,  2.75it/s]Evaluating:  22%|██▏       | 20/92 [00:07<00:26,  2.76it/s]Evaluating:  23%|██▎       | 21/92 [00:08<00:25,  2.78it/s]Evaluating:  24%|██▍       | 22/92 [00:08<00:25,  2.79it/s]Evaluating:  25%|██▌       | 23/92 [00:08<00:24,  2.79it/s]Evaluating:  26%|██▌       | 24/92 [00:09<00:24,  2.79it/s]Evaluating:  27%|██▋       | 25/92 [00:09<00:24,  2.77it/s]Evaluating:  28%|██▊       | 26/92 [00:09<00:23,  2.78it/s]Evaluating:  29%|██▉       | 27/92 [00:10<00:23,  2.78it/s]Evaluating:  30%|███       | 28/92 [00:10<00:22,  2.78it/s]Evaluating:  32%|███▏      | 29/92 [00:11<00:22,  2.78it/s]Evaluating:  33%|███▎      | 30/92 [00:11<00:22,  2.79it/s]Evaluating:  34%|███▎      | 31/92 [00:11<00:21,  2.79it/s]Evaluating:  35%|███▍      | 32/92 [00:12<00:21,  2.79it/s]Evaluating:  36%|███▌      | 33/92 [00:12<00:21,  2.79it/s]Evaluating:  37%|███▋      | 34/92 [00:12<00:20,  2.79it/s]Evaluating:  38%|███▊      | 35/92 [00:13<00:20,  2.79it/s]Evaluating:  39%|███▉      | 36/92 [00:13<00:20,  2.79it/s]Evaluating:  40%|████      | 37/92 [00:13<00:19,  2.80it/s]Evaluating:  41%|████▏     | 38/92 [00:14<00:19,  2.80it/s]Evaluating:  42%|████▏     | 39/92 [00:14<00:18,  2.80it/s]Evaluating:  43%|████▎     | 40/92 [00:14<00:18,  2.80it/s]Evaluating:  45%|████▍     | 41/92 [00:15<00:18,  2.81it/s]Evaluating:  46%|████▌     | 42/92 [00:15<00:17,  2.80it/s]Evaluating:  47%|████▋     | 43/92 [00:16<00:17,  2.81it/s]Evaluating:  48%|████▊     | 44/92 [00:16<00:17,  2.81it/s]Evaluating:  49%|████▉     | 45/92 [00:16<00:16,  2.80it/s]Evaluating:  50%|█████     | 46/92 [00:17<00:16,  2.80it/s]Evaluating:  51%|█████     | 47/92 [00:17<00:16,  2.80it/s]Evaluating:  52%|█████▏    | 48/92 [00:17<00:15,  2.80it/s]Evaluating:  53%|█████▎    | 49/92 [00:18<00:15,  2.80it/s]Evaluating:  54%|█████▍    | 50/92 [00:18<00:14,  2.80it/s]Evaluating:  55%|█████▌    | 51/92 [00:18<00:14,  2.80it/s]Evaluating:  57%|█████▋    | 52/92 [00:19<00:14,  2.80it/s]Evaluating:  58%|█████▊    | 53/92 [00:19<00:13,  2.80it/s]Evaluating:  59%|█████▊    | 54/92 [00:19<00:13,  2.80it/s]Evaluating:  60%|█████▉    | 55/92 [00:20<00:13,  2.79it/s]Evaluating:  61%|██████    | 56/92 [00:20<00:12,  2.79it/s]Evaluating:  62%|██████▏   | 57/92 [00:21<00:12,  2.80it/s]Evaluating:  63%|██████▎   | 58/92 [00:21<00:12,  2.80it/s]Evaluating:  64%|██████▍   | 59/92 [00:21<00:11,  2.79it/s]Evaluating:  65%|██████▌   | 60/92 [00:22<00:11,  2.79it/s]Evaluating:  66%|██████▋   | 61/92 [00:22<00:11,  2.79it/s]Evaluating:  67%|██████▋   | 62/92 [00:22<00:10,  2.79it/s]Evaluating:  68%|██████▊   | 63/92 [00:23<00:10,  2.79it/s]Evaluating:  70%|██████▉   | 64/92 [00:23<00:10,  2.79it/s]Evaluating:  71%|███████   | 65/92 [00:23<00:09,  2.79it/s]Evaluating:  72%|███████▏  | 66/92 [00:24<00:09,  2.78it/s]Evaluating:  73%|███████▎  | 67/92 [00:24<00:08,  2.78it/s]Evaluating:  74%|███████▍  | 68/92 [00:24<00:08,  2.77it/s]Evaluating:  75%|███████▌  | 69/92 [00:25<00:08,  2.77it/s]Evaluating:  76%|███████▌  | 70/92 [00:25<00:07,  2.77it/s]Evaluating:  77%|███████▋  | 71/92 [00:26<00:07,  2.77it/s]Evaluating:  78%|███████▊  | 72/92 [00:26<00:07,  2.73it/s]Evaluating:  79%|███████▉  | 73/92 [00:26<00:06,  2.75it/s]Evaluating:  80%|████████  | 74/92 [00:27<00:06,  2.76it/s]Evaluating:  82%|████████▏ | 75/92 [00:27<00:06,  2.77it/s]Evaluating:  83%|████████▎ | 76/92 [00:27<00:05,  2.77it/s]Evaluating:  84%|████████▎ | 77/92 [00:28<00:05,  2.78it/s]Evaluating:  85%|████████▍ | 78/92 [00:28<00:05,  2.76it/s]Evaluating:  86%|████████▌ | 79/92 [00:28<00:04,  2.77it/s]Evaluating:  87%|████████▋ | 80/92 [00:29<00:04,  2.77it/s]Evaluating:  88%|████████▊ | 81/92 [00:29<00:03,  2.77it/s]Evaluating:  89%|████████▉ | 82/92 [00:30<00:03,  2.76it/s]Evaluating:  90%|█████████ | 83/92 [00:30<00:03,  2.77it/s]Evaluating:  91%|█████████▏| 84/92 [00:30<00:02,  2.77it/s]Evaluating:  92%|█████████▏| 85/92 [00:31<00:02,  2.76it/s]Evaluating:  93%|█████████▎| 86/92 [00:31<00:02,  2.76it/s]Evaluating:  95%|█████████▍| 87/92 [00:31<00:01,  2.76it/s]Evaluating:  96%|█████████▌| 88/92 [00:32<00:01,  2.78it/s]Evaluating:  97%|█████████▋| 89/92 [00:32<00:01,  2.78it/s]Evaluating:  98%|█████████▊| 90/92 [00:32<00:00,  2.78it/s]Evaluating:  99%|█████████▉| 91/92 [00:33<00:00,  2.78it/s]Evaluating: 100%|██████████| 92/92 [00:33<00:00,  2.83it/s]Evaluating: 100%|██████████| 92/92 [00:33<00:00,  2.74it/s]
05/09/2022 23:02:13 - INFO - __main__ -     Evaluation done in total 33.609890 secs (0.045728 sec per example)
05/09/2022 23:02:16 - INFO - __main__ -   Results: {'exact': 61.88340807174888, 'f1': 77.73458189377476, 'total': 669, 'HasAns_exact': 61.88340807174888, 'HasAns_f1': 77.73458189377476, 'HasAns_total': 669, 'best_exact': 61.88340807174888, 'best_exact_thresh': 0.0, 'best_f1': 77.73458189377476, 'best_f1_thresh': 0.0}
mv: cannot stat ‘/cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//tydiqa/xlm-KG_LR8e-6_EPOCH2.0_maxlen384_batchsize4_gradacc4/predictions/tydiqa//predictions_en_.json’: No such file or directory
mv: cannot stat ‘/cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//tydiqa/xlm-KG_LR8e-6_EPOCH2.0_maxlen384_batchsize4_gradacc4/predictions/tydiqa//predictions_ar_.json’: No such file or directory
