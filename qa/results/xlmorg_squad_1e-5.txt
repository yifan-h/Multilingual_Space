Fine-tuning /cluster/home/yifhou/scratch_yifan/qa/xtreme_xlm/xlm-roberta-base on xquad using GPU 4
Load data from /cluster/home/yifhou/scratch_yifan/qa/xtreme_xlm/download/, and save models to /cluster/home/yifhou/scratch_yifan/qa/xtreme_xlm/outputs-adapter/
************************
/cluster/home/yifhou/scratch_yifan/qa/xtreme_xlm/xlm-roberta-base
************************

Predictions on xquad
  en 
2022-05-09 18:33:08.405018: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0
05/09/2022 18:33:10 - WARNING - __main__ -   Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, 16-bits training: False
You are using a model of type xlm-roberta to instantiate a model of type xlm. This is not supported for all configurations of models and can yield errors.
Some weights of the model checkpoint at /cluster/home/yifhou/scratch_yifan/qa/xtreme_xlm/outputs-adapter//squad/xlm_LR1e-5_EPOCH2.0_maxlen384_batchsize8_gradacc2 were not used when initializing XLMRobertaModel: ['base_model.encoder.layer.4.attention.self.query.weight', 'base_model.encoder.layer.6.output.LayerNorm.weight', 'base_model.encoder.layer.0.attention.self.query.weight', 'base_model.encoder.layer.6.output.dense.bias', 'base_model.encoder.layer.5.attention.output.dense.bias', 'base_model.encoder.layer.11.attention.self.query.bias', 'base_model.encoder.layer.4.output.LayerNorm.bias', 'base_model.encoder.layer.10.intermediate.dense.weight', 'base_model.encoder.layer.9.output.LayerNorm.bias', 'base_model.encoder.layer.10.attention.output.LayerNorm.bias', 'base_model.encoder.layer.11.output.LayerNorm.weight', 'base_model.encoder.layer.11.attention.output.LayerNorm.weight', 'base_model.encoder.layer.10.intermediate.dense.bias', 'base_model.encoder.layer.7.attention.self.key.bias', 'base_model.encoder.layer.2.intermediate.dense.weight', 'base_model.encoder.layer.6.attention.self.key.bias', 'base_model.encoder.layer.8.attention.output.dense.weight', 'base_model.encoder.layer.6.attention.self.query.weight', 'base_model.encoder.layer.7.intermediate.dense.weight', 'base_model.encoder.layer.2.attention.output.LayerNorm.weight', 'base_model.encoder.layer.4.output.LayerNorm.weight', 'base_model.encoder.layer.4.output.dense.weight', 'base_model.encoder.layer.4.intermediate.dense.weight', 'base_model.encoder.layer.10.attention.self.query.weight', 'qa_outputs.bias', 'base_model.encoder.layer.4.intermediate.dense.bias', 'base_model.encoder.layer.5.intermediate.dense.weight', 'base_model.encoder.layer.1.output.dense.bias', 'base_model.encoder.layer.1.output.LayerNorm.weight', 'base_model.encoder.layer.9.output.dense.weight', 'base_model.encoder.layer.7.output.LayerNorm.bias', 'base_model.embeddings.LayerNorm.bias', 'base_model.encoder.layer.0.intermediate.dense.weight', 'base_model.encoder.layer.8.output.dense.weight', 'base_model.encoder.layer.10.attention.self.key.bias', 'base_model.encoder.layer.2.output.dense.weight', 'base_model.encoder.layer.0.attention.self.value.bias', 'base_model.encoder.layer.1.attention.output.dense.weight', 'base_model.encoder.layer.2.attention.output.dense.weight', 'base_model.encoder.layer.3.attention.self.value.bias', 'base_model.encoder.layer.4.attention.output.dense.weight', 'base_model.encoder.layer.9.attention.self.key.weight', 'base_model.encoder.layer.10.output.LayerNorm.weight', 'base_model.encoder.layer.11.intermediate.dense.weight', 'base_model.encoder.layer.8.intermediate.dense.bias', 'base_model.encoder.layer.3.attention.self.query.weight', 'base_model.encoder.layer.8.output.LayerNorm.weight', 'base_model.encoder.layer.1.attention.self.key.bias', 'base_model.encoder.layer.11.attention.self.value.bias', 'base_model.encoder.layer.8.attention.self.query.bias', 'base_model.encoder.layer.3.attention.self.query.bias', 'base_model.encoder.layer.9.output.LayerNorm.weight', 'base_model.encoder.layer.9.attention.output.dense.weight', 'base_model.encoder.layer.0.attention.self.key.weight', 'base_model.encoder.layer.0.output.LayerNorm.bias', 'base_model.encoder.layer.6.attention.output.LayerNorm.weight', 'base_model.encoder.layer.2.attention.self.key.weight', 'base_model.encoder.layer.4.attention.self.value.bias', 'base_model.encoder.layer.4.attention.output.LayerNorm.weight', 'base_model.encoder.layer.7.attention.output.LayerNorm.bias', 'base_model.encoder.layer.8.attention.self.value.weight', 'base_model.encoder.layer.1.attention.self.query.weight', 'base_model.encoder.layer.5.output.LayerNorm.bias', 'base_model.encoder.layer.5.attention.output.LayerNorm.weight', 'base_model.encoder.layer.7.output.dense.weight', 'base_model.encoder.layer.3.attention.self.key.bias', 'base_model.encoder.layer.5.attention.self.value.bias', 'base_model.encoder.layer.11.attention.self.value.weight', 'base_model.encoder.layer.11.attention.self.key.weight', 'base_model.encoder.layer.2.attention.self.query.bias', 'base_model.encoder.layer.5.attention.self.key.weight', 'base_model.encoder.layer.3.attention.output.LayerNorm.weight', 'base_model.encoder.layer.7.attention.self.query.bias', 'base_model.encoder.layer.5.output.LayerNorm.weight', 'base_model.encoder.layer.10.attention.output.dense.bias', 'base_model.encoder.layer.10.attention.output.dense.weight', 'base_model.encoder.layer.3.attention.output.LayerNorm.bias', 'base_model.encoder.layer.2.output.LayerNorm.bias', 'base_model.encoder.layer.6.attention.self.key.weight', 'base_model.encoder.layer.0.attention.output.dense.bias', 'base_model.encoder.layer.6.output.dense.weight', 'base_model.encoder.layer.11.attention.output.dense.bias', 'base_model.encoder.layer.2.attention.self.value.weight', 'base_model.encoder.layer.7.attention.self.value.bias', 'base_model.encoder.layer.4.attention.self.value.weight', 'base_model.encoder.layer.6.intermediate.dense.bias', 'base_model.pooler.dense.weight', 'base_model.encoder.layer.0.attention.output.LayerNorm.weight', 'base_model.encoder.layer.1.attention.self.value.bias', 'base_model.encoder.layer.9.attention.self.query.bias', 'base_model.encoder.layer.5.attention.self.value.weight', 'base_model.encoder.layer.0.intermediate.dense.bias', 'base_model.encoder.layer.3.output.dense.weight', 'base_model.encoder.layer.1.output.dense.weight', 'base_model.encoder.layer.9.intermediate.dense.weight', 'base_model.encoder.layer.6.output.LayerNorm.bias', 'base_model.encoder.layer.9.attention.output.dense.bias', 'base_model.encoder.layer.5.attention.self.query.weight', 'base_model.encoder.layer.5.intermediate.dense.bias', 'base_model.encoder.layer.2.output.dense.bias', 'base_model.encoder.layer.4.output.dense.bias', 'base_model.encoder.layer.1.attention.self.query.bias', 'base_model.encoder.layer.1.attention.output.dense.bias', 'base_model.encoder.layer.7.output.LayerNorm.weight', 'base_model.encoder.layer.3.attention.output.dense.bias', 'base_model.encoder.layer.3.output.dense.bias', 'base_model.encoder.layer.2.output.LayerNorm.weight', 'base_model.encoder.layer.11.output.dense.weight', 'base_model.encoder.layer.10.attention.self.value.weight', 'base_model.encoder.layer.3.attention.self.key.weight', 'base_model.encoder.layer.1.attention.output.LayerNorm.bias', 'base_model.encoder.layer.8.output.LayerNorm.bias', 'base_model.encoder.layer.1.attention.self.value.weight', 'base_model.encoder.layer.9.output.dense.bias', 'base_model.encoder.layer.11.intermediate.dense.bias', 'base_model.encoder.layer.7.attention.output.dense.bias', 'base_model.encoder.layer.1.output.LayerNorm.bias', 'base_model.encoder.layer.10.attention.self.value.bias', 'base_model.encoder.layer.3.intermediate.dense.bias', 'base_model.encoder.layer.4.attention.self.key.weight', 'base_model.encoder.layer.9.attention.self.key.bias', 'base_model.encoder.layer.4.attention.self.query.bias', 'base_model.encoder.layer.9.attention.output.LayerNorm.weight', 'base_model.pooler.dense.bias', 'base_model.encoder.layer.8.attention.output.LayerNorm.bias', 'base_model.encoder.layer.8.intermediate.dense.weight', 'base_model.encoder.layer.2.attention.self.key.bias', 'base_model.encoder.layer.7.attention.output.LayerNorm.weight', 'base_model.encoder.layer.5.attention.output.dense.weight', 'base_model.embeddings.word_embeddings.weight', 'base_model.encoder.layer.7.output.dense.bias', 'base_model.encoder.layer.9.intermediate.dense.bias', 'base_model.encoder.layer.2.attention.self.query.weight', 'base_model.encoder.layer.11.attention.self.key.bias', 'qa_outputs.weight', 'base_model.encoder.layer.8.attention.output.LayerNorm.weight', 'base_model.encoder.layer.0.attention.self.value.weight', 'base_model.encoder.layer.7.attention.self.key.weight', 'base_model.encoder.layer.0.output.dense.weight', 'base_model.encoder.layer.5.attention.self.key.bias', 'base_model.encoder.layer.6.attention.self.value.weight', 'base_model.encoder.layer.8.attention.self.value.bias', 'base_model.encoder.layer.7.intermediate.dense.bias', 'base_model.encoder.layer.5.attention.output.LayerNorm.bias', 'base_model.encoder.layer.1.attention.output.LayerNorm.weight', 'base_model.encoder.layer.11.attention.output.LayerNorm.bias', 'base_model.embeddings.token_type_embeddings.weight', 'base_model.encoder.layer.2.attention.output.dense.bias', 'base_model.encoder.layer.6.intermediate.dense.weight', 'base_model.encoder.layer.3.output.LayerNorm.bias', 'base_model.encoder.layer.0.attention.self.query.bias', 'base_model.encoder.layer.7.attention.self.value.weight', 'base_model.encoder.layer.10.attention.self.query.bias', 'base_model.embeddings.LayerNorm.weight', 'base_model.encoder.layer.0.attention.self.key.bias', 'base_model.encoder.layer.8.output.dense.bias', 'base_model.encoder.layer.6.attention.output.dense.weight', 'base_model.encoder.layer.3.attention.self.value.weight', 'base_model.encoder.layer.1.attention.self.key.weight', 'base_model.encoder.layer.10.attention.self.key.weight', 'base_model.encoder.layer.0.attention.output.dense.weight', 'base_model.encoder.layer.8.attention.self.query.weight', 'base_model.encoder.layer.9.attention.self.value.weight', 'base_model.encoder.layer.10.output.LayerNorm.bias', 'base_model.encoder.layer.4.attention.output.dense.bias', 'base_model.encoder.layer.10.output.dense.weight', 'base_model.encoder.layer.5.attention.self.query.bias', 'base_model.encoder.layer.6.attention.self.query.bias', 'base_model.encoder.layer.6.attention.output.dense.bias', 'base_model.encoder.layer.4.attention.self.key.bias', 'base_model.encoder.layer.2.attention.output.LayerNorm.bias', 'base_model.encoder.layer.3.output.LayerNorm.weight', 'base_model.encoder.layer.11.output.LayerNorm.bias', 'base_model.encoder.layer.3.intermediate.dense.weight', 'base_model.encoder.layer.0.output.dense.bias', 'base_model.encoder.layer.10.attention.output.LayerNorm.weight', 'base_model.encoder.layer.2.attention.self.value.bias', 'base_model.encoder.layer.5.output.dense.bias', 'base_model.encoder.layer.8.attention.self.key.bias', 'base_model.encoder.layer.10.output.dense.bias', 'base_model.encoder.layer.11.attention.output.dense.weight', 'base_model.embeddings.position_embeddings.weight', 'base_model.encoder.layer.1.intermediate.dense.bias', 'base_model.encoder.layer.1.intermediate.dense.weight', 'base_model.encoder.layer.5.output.dense.weight', 'base_model.encoder.layer.7.attention.self.query.weight', 'base_model.encoder.layer.7.attention.output.dense.weight', 'base_model.encoder.layer.0.output.LayerNorm.weight', 'base_model.encoder.layer.8.attention.self.key.weight', 'base_model.encoder.layer.8.attention.output.dense.bias', 'base_model.encoder.layer.9.attention.self.value.bias', 'base_model.encoder.layer.3.attention.output.dense.weight', 'base_model.encoder.layer.11.attention.self.query.weight', 'base_model.encoder.layer.4.attention.output.LayerNorm.bias', 'base_model.encoder.layer.9.attention.self.query.weight', 'base_model.encoder.layer.6.attention.self.value.bias', 'base_model.encoder.layer.11.output.dense.bias', 'base_model.embeddings.position_ids', 'base_model.encoder.layer.2.intermediate.dense.bias', 'base_model.encoder.layer.0.attention.output.LayerNorm.bias', 'base_model.encoder.layer.6.attention.output.LayerNorm.bias', 'base_model.encoder.layer.9.attention.output.LayerNorm.bias']
- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of XLMRobertaModel were not initialized from the model checkpoint at /cluster/home/yifhou/scratch_yifan/qa/xtreme_xlm/outputs-adapter//squad/xlm_LR1e-5_EPOCH2.0_maxlen384_batchsize8_gradacc2 and are newly initialized: ['encoder.layer.1.attention.self.query.weight', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.8.attention.self.key.weight', 'encoder.layer.0.attention.self.key.weight', 'encoder.layer.9.attention.output.LayerNorm.bias', 'encoder.layer.8.attention.self.value.weight', 'embeddings.position_embeddings.weight', 'encoder.layer.7.attention.self.key.weight', 'encoder.layer.7.output.dense.weight', 'encoder.layer.3.attention.self.value.weight', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.2.output.dense.weight', 'encoder.layer.1.output.dense.bias', 'encoder.layer.4.attention.output.LayerNorm.weight', 'embeddings.token_type_embeddings.weight', 'encoder.layer.10.attention.self.query.bias', 'encoder.layer.5.attention.output.dense.weight', 'pooler.dense.bias', 'encoder.layer.1.attention.self.key.bias', 'encoder.layer.5.output.dense.bias', 'encoder.layer.9.attention.self.key.bias', 'encoder.layer.3.attention.output.dense.weight', 'encoder.layer.0.attention.output.dense.weight', 'encoder.layer.11.attention.self.key.weight', 'encoder.layer.1.output.dense.weight', 'encoder.layer.1.attention.output.dense.weight', 'encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.layer.8.attention.output.LayerNorm.bias', 'encoder.layer.9.attention.output.LayerNorm.weight', 'encoder.layer.11.attention.self.value.bias', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.2.attention.self.query.weight', 'encoder.layer.0.attention.output.dense.bias', 'encoder.layer.2.attention.self.value.weight', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.7.attention.self.query.weight', 'encoder.layer.8.attention.self.key.bias', 'encoder.layer.8.attention.output.dense.bias', 'encoder.layer.8.output.dense.weight', 'encoder.layer.9.output.LayerNorm.weight', 'embeddings.LayerNorm.weight', 'encoder.layer.2.attention.self.query.bias', 'encoder.layer.9.attention.self.value.weight', 'encoder.layer.9.attention.self.value.bias', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.4.attention.self.value.weight', 'encoder.layer.11.attention.output.dense.bias', 'encoder.layer.1.attention.self.key.weight', 'encoder.layer.3.output.dense.bias', 'encoder.layer.3.attention.self.key.weight', 'encoder.layer.10.attention.self.key.bias', 'encoder.layer.6.attention.output.LayerNorm.bias', 'encoder.layer.7.attention.self.key.bias', 'encoder.layer.7.attention.self.value.weight', 'encoder.layer.9.attention.output.dense.bias', 'encoder.layer.0.output.dense.bias', 'encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.9.output.LayerNorm.bias', 'encoder.layer.5.attention.output.LayerNorm.weight', 'encoder.layer.6.attention.output.LayerNorm.weight', 'encoder.layer.2.attention.output.LayerNorm.weight', 'encoder.layer.7.attention.output.LayerNorm.bias', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.6.attention.self.key.bias', 'encoder.layer.11.attention.self.query.weight', 'encoder.layer.10.output.LayerNorm.weight', 'encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.layer.9.attention.self.query.bias', 'encoder.layer.6.attention.output.dense.bias', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.7.attention.self.query.bias', 'encoder.layer.5.attention.self.query.bias', 'encoder.layer.8.attention.self.query.weight', 'encoder.layer.7.output.LayerNorm.bias', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.6.attention.self.query.bias', 'encoder.layer.3.output.dense.weight', 'encoder.layer.4.attention.output.LayerNorm.bias', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.8.attention.self.value.bias', 'encoder.layer.0.output.dense.weight', 'encoder.layer.9.attention.output.dense.weight', 'encoder.layer.11.attention.self.key.bias', 'encoder.layer.1.attention.self.value.weight', 'encoder.layer.3.attention.self.value.bias', 'encoder.layer.6.attention.self.query.weight', 'encoder.layer.6.attention.self.value.bias', 'encoder.layer.7.attention.output.dense.weight', 'encoder.layer.5.attention.self.query.weight', 'encoder.layer.10.attention.output.LayerNorm.bias', 'encoder.layer.10.attention.output.dense.weight', 'encoder.layer.6.attention.self.key.weight', 'encoder.layer.11.attention.self.query.bias', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.2.attention.output.dense.weight', 'encoder.layer.6.output.dense.weight', 'encoder.layer.10.attention.self.value.weight', 'encoder.layer.10.output.dense.weight', 'encoder.layer.8.output.LayerNorm.weight', 'encoder.layer.5.output.dense.weight', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.11.output.dense.weight', 'encoder.layer.5.attention.self.key.weight', 'encoder.layer.4.attention.self.value.bias', 'encoder.layer.10.output.LayerNorm.bias', 'encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.layer.4.attention.self.query.bias', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.5.output.LayerNorm.bias', 'encoder.layer.1.attention.output.dense.bias', 'encoder.layer.0.attention.self.value.weight', 'encoder.layer.7.attention.output.LayerNorm.weight', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.7.attention.self.value.bias', 'encoder.layer.11.output.dense.bias', 'encoder.layer.11.output.LayerNorm.weight', 'encoder.layer.5.output.LayerNorm.weight', 'embeddings.LayerNorm.bias', 'encoder.layer.1.attention.output.LayerNorm.weight', 'encoder.layer.4.output.dense.weight', 'encoder.layer.7.attention.output.dense.bias', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.5.attention.self.value.bias', 'encoder.layer.3.attention.self.query.bias', 'encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.layer.0.attention.output.LayerNorm.weight', 'encoder.layer.1.output.LayerNorm.bias', 'pooler.dense.weight', 'encoder.layer.6.attention.self.value.weight', 'encoder.layer.4.attention.self.key.weight', 'encoder.layer.5.attention.self.value.weight', 'encoder.layer.9.output.dense.bias', 'encoder.layer.9.output.dense.weight', 'encoder.layer.2.attention.self.key.bias', 'encoder.layer.4.attention.self.key.bias', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.10.intermediate.dense.weight', 'encoder.layer.8.attention.self.query.bias', 'encoder.layer.0.attention.self.value.bias', 'encoder.layer.10.attention.output.dense.bias', 'encoder.layer.1.attention.self.value.bias', 'encoder.layer.9.attention.self.query.weight', 'encoder.layer.4.output.dense.bias', 'encoder.layer.8.output.LayerNorm.bias', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.10.attention.self.query.weight', 'encoder.layer.10.attention.self.key.weight', 'encoder.layer.2.output.dense.bias', 'encoder.layer.4.attention.output.dense.bias', 'encoder.layer.0.attention.self.key.bias', 'encoder.layer.3.attention.self.key.bias', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.5.attention.self.key.bias', 'encoder.layer.10.attention.self.value.bias', 'encoder.layer.4.attention.self.query.weight', 'encoder.layer.6.attention.output.dense.weight', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.8.output.dense.bias', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.3.attention.self.query.weight', 'encoder.layer.10.attention.output.LayerNorm.weight', 'encoder.layer.11.attention.output.dense.weight', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.4.attention.output.dense.weight', 'encoder.layer.5.attention.output.dense.bias', 'encoder.layer.6.output.dense.bias', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.11.attention.output.LayerNorm.weight', 'encoder.layer.2.attention.output.LayerNorm.bias', 'encoder.layer.0.attention.self.query.weight', 'encoder.layer.2.attention.self.value.bias', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.7.output.LayerNorm.weight', 'encoder.layer.7.intermediate.dense.bias', 'embeddings.word_embeddings.weight', 'encoder.layer.2.attention.self.key.weight', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.9.attention.self.key.weight', 'encoder.layer.2.attention.output.dense.bias', 'encoder.layer.11.output.LayerNorm.bias', 'encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.1.attention.self.query.bias', 'encoder.layer.0.attention.self.query.bias', 'encoder.layer.8.attention.output.dense.weight', 'encoder.layer.6.output.LayerNorm.bias', 'encoder.layer.7.output.dense.bias', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.layer.10.output.dense.bias', 'encoder.layer.8.attention.output.LayerNorm.weight', 'encoder.layer.11.attention.self.value.weight', 'encoder.layer.3.attention.output.dense.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
05/09/2022 18:33:16 - INFO - __main__ -   lang2id = None
05/09/2022 18:33:19 - INFO - __main__ -   Training/evaluation parameters Namespace(adam_epsilon=1e-08, cache_dir='', config_name='', data_dir=None, device=device(type='cuda'), do_eval=True, do_lower_case=False, do_train=False, doc_stride=128, eval_all_checkpoints=False, eval_lang='en', evaluate_during_training=False, fp16=False, fp16_opt_level='O1', gradient_accumulation_steps=1, learning_rate=5e-05, local_rank=-1, logging_steps=50, max_answer_length=30, max_grad_norm=1.0, max_query_length=64, max_seq_length=384, max_steps=-1, model_name='xlm-KG', model_name_or_path='/cluster/home/yifhou/scratch_yifan/qa/xtreme_xlm/outputs-adapter//squad/xlm_LR1e-5_EPOCH2.0_maxlen384_batchsize8_gradacc2', model_type='xlm', modelkg_dir='/cluster/home/yifhou/scratch_yifan/qa/xtreme_xlm/adapter/xlm_adapter', n_best_size=20, n_gpu=1, no_cuda=False, null_score_diff_threshold=0.0, num_train_epochs=3.0, output_dir='/cluster/home/yifhou/scratch_yifan/qa/xtreme_xlm/outputs-adapter//squad/xlm_LR1e-5_EPOCH2.0_maxlen384_batchsize8_gradacc2/predictions/xquad/', overwrite_cache=False, overwrite_output_dir=False, per_gpu_eval_batch_size=8, per_gpu_train_batch_size=8, predict_file='/cluster/home/yifhou/scratch_yifan/qa/xtreme_xlm/download//xquad//xquad.en.json', save_steps=50, seed=42, server_ip='', server_port='', threads=1, tokenizer_name='', train_file=None, train_lang='en', verbose_logging=False, version_2_with_negative=False, warmup_steps=0, weight_decay=0.0)
05/09/2022 18:33:19 - INFO - __main__ -   Loading checkpoint /cluster/home/yifhou/scratch_yifan/qa/xtreme_xlm/outputs-adapter//squad/xlm_LR1e-5_EPOCH2.0_maxlen384_batchsize8_gradacc2 for evaluation
05/09/2022 18:33:19 - INFO - __main__ -   Evaluate the following checkpoints: ['/cluster/home/yifhou/scratch_yifan/qa/xtreme_xlm/outputs-adapter//squad/xlm_LR1e-5_EPOCH2.0_maxlen384_batchsize8_gradacc2']
Some weights of the model checkpoint at /cluster/home/yifhou/scratch_yifan/qa/xtreme_xlm/outputs-adapter//squad/xlm_LR1e-5_EPOCH2.0_maxlen384_batchsize8_gradacc2 were not used when initializing XLMRobertaModel: ['base_model.encoder.layer.4.attention.self.query.weight', 'base_model.encoder.layer.6.output.LayerNorm.weight', 'base_model.encoder.layer.0.attention.self.query.weight', 'base_model.encoder.layer.6.output.dense.bias', 'base_model.encoder.layer.5.attention.output.dense.bias', 'base_model.encoder.layer.11.attention.self.query.bias', 'base_model.encoder.layer.4.output.LayerNorm.bias', 'base_model.encoder.layer.10.intermediate.dense.weight', 'base_model.encoder.layer.9.output.LayerNorm.bias', 'base_model.encoder.layer.10.attention.output.LayerNorm.bias', 'base_model.encoder.layer.11.output.LayerNorm.weight', 'base_model.encoder.layer.11.attention.output.LayerNorm.weight', 'base_model.encoder.layer.10.intermediate.dense.bias', 'base_model.encoder.layer.7.attention.self.key.bias', 'base_model.encoder.layer.2.intermediate.dense.weight', 'base_model.encoder.layer.6.attention.self.key.bias', 'base_model.encoder.layer.8.attention.output.dense.weight', 'base_model.encoder.layer.6.attention.self.query.weight', 'base_model.encoder.layer.7.intermediate.dense.weight', 'base_model.encoder.layer.2.attention.output.LayerNorm.weight', 'base_model.encoder.layer.4.output.LayerNorm.weight', 'base_model.encoder.layer.4.output.dense.weight', 'base_model.encoder.layer.4.intermediate.dense.weight', 'base_model.encoder.layer.10.attention.self.query.weight', 'qa_outputs.bias', 'base_model.encoder.layer.4.intermediate.dense.bias', 'base_model.encoder.layer.5.intermediate.dense.weight', 'base_model.encoder.layer.1.output.dense.bias', 'base_model.encoder.layer.1.output.LayerNorm.weight', 'base_model.encoder.layer.9.output.dense.weight', 'base_model.encoder.layer.7.output.LayerNorm.bias', 'base_model.embeddings.LayerNorm.bias', 'base_model.encoder.layer.0.intermediate.dense.weight', 'base_model.encoder.layer.8.output.dense.weight', 'base_model.encoder.layer.10.attention.self.key.bias', 'base_model.encoder.layer.2.output.dense.weight', 'base_model.encoder.layer.0.attention.self.value.bias', 'base_model.encoder.layer.1.attention.output.dense.weight', 'base_model.encoder.layer.2.attention.output.dense.weight', 'base_model.encoder.layer.3.attention.self.value.bias', 'base_model.encoder.layer.4.attention.output.dense.weight', 'base_model.encoder.layer.9.attention.self.key.weight', 'base_model.encoder.layer.10.output.LayerNorm.weight', 'base_model.encoder.layer.11.intermediate.dense.weight', 'base_model.encoder.layer.8.intermediate.dense.bias', 'base_model.encoder.layer.3.attention.self.query.weight', 'base_model.encoder.layer.8.output.LayerNorm.weight', 'base_model.encoder.layer.1.attention.self.key.bias', 'base_model.encoder.layer.11.attention.self.value.bias', 'base_model.encoder.layer.8.attention.self.query.bias', 'base_model.encoder.layer.3.attention.self.query.bias', 'base_model.encoder.layer.9.output.LayerNorm.weight', 'base_model.encoder.layer.9.attention.output.dense.weight', 'base_model.encoder.layer.0.attention.self.key.weight', 'base_model.encoder.layer.0.output.LayerNorm.bias', 'base_model.encoder.layer.6.attention.output.LayerNorm.weight', 'base_model.encoder.layer.2.attention.self.key.weight', 'base_model.encoder.layer.4.attention.self.value.bias', 'base_model.encoder.layer.4.attention.output.LayerNorm.weight', 'base_model.encoder.layer.7.attention.output.LayerNorm.bias', 'base_model.encoder.layer.8.attention.self.value.weight', 'base_model.encoder.layer.1.attention.self.query.weight', 'base_model.encoder.layer.5.output.LayerNorm.bias', 'base_model.encoder.layer.5.attention.output.LayerNorm.weight', 'base_model.encoder.layer.7.output.dense.weight', 'base_model.encoder.layer.3.attention.self.key.bias', 'base_model.encoder.layer.5.attention.self.value.bias', 'base_model.encoder.layer.11.attention.self.value.weight', 'base_model.encoder.layer.11.attention.self.key.weight', 'base_model.encoder.layer.2.attention.self.query.bias', 'base_model.encoder.layer.5.attention.self.key.weight', 'base_model.encoder.layer.3.attention.output.LayerNorm.weight', 'base_model.encoder.layer.7.attention.self.query.bias', 'base_model.encoder.layer.5.output.LayerNorm.weight', 'base_model.encoder.layer.10.attention.output.dense.bias', 'base_model.encoder.layer.10.attention.output.dense.weight', 'base_model.encoder.layer.3.attention.output.LayerNorm.bias', 'base_model.encoder.layer.2.output.LayerNorm.bias', 'base_model.encoder.layer.6.attention.self.key.weight', 'base_model.encoder.layer.0.attention.output.dense.bias', 'base_model.encoder.layer.6.output.dense.weight', 'base_model.encoder.layer.11.attention.output.dense.bias', 'base_model.encoder.layer.2.attention.self.value.weight', 'base_model.encoder.layer.7.attention.self.value.bias', 'base_model.encoder.layer.4.attention.self.value.weight', 'base_model.encoder.layer.6.intermediate.dense.bias', 'base_model.pooler.dense.weight', 'base_model.encoder.layer.0.attention.output.LayerNorm.weight', 'base_model.encoder.layer.1.attention.self.value.bias', 'base_model.encoder.layer.9.attention.self.query.bias', 'base_model.encoder.layer.5.attention.self.value.weight', 'base_model.encoder.layer.0.intermediate.dense.bias', 'base_model.encoder.layer.3.output.dense.weight', 'base_model.encoder.layer.1.output.dense.weight', 'base_model.encoder.layer.9.intermediate.dense.weight', 'base_model.encoder.layer.6.output.LayerNorm.bias', 'base_model.encoder.layer.9.attention.output.dense.bias', 'base_model.encoder.layer.5.attention.self.query.weight', 'base_model.encoder.layer.5.intermediate.dense.bias', 'base_model.encoder.layer.2.output.dense.bias', 'base_model.encoder.layer.4.output.dense.bias', 'base_model.encoder.layer.1.attention.self.query.bias', 'base_model.encoder.layer.1.attention.output.dense.bias', 'base_model.encoder.layer.7.output.LayerNorm.weight', 'base_model.encoder.layer.3.attention.output.dense.bias', 'base_model.encoder.layer.3.output.dense.bias', 'base_model.encoder.layer.2.output.LayerNorm.weight', 'base_model.encoder.layer.11.output.dense.weight', 'base_model.encoder.layer.10.attention.self.value.weight', 'base_model.encoder.layer.3.attention.self.key.weight', 'base_model.encoder.layer.1.attention.output.LayerNorm.bias', 'base_model.encoder.layer.8.output.LayerNorm.bias', 'base_model.encoder.layer.1.attention.self.value.weight', 'base_model.encoder.layer.9.output.dense.bias', 'base_model.encoder.layer.11.intermediate.dense.bias', 'base_model.encoder.layer.7.attention.output.dense.bias', 'base_model.encoder.layer.1.output.LayerNorm.bias', 'base_model.encoder.layer.10.attention.self.value.bias', 'base_model.encoder.layer.3.intermediate.dense.bias', 'base_model.encoder.layer.4.attention.self.key.weight', 'base_model.encoder.layer.9.attention.self.key.bias', 'base_model.encoder.layer.4.attention.self.query.bias', 'base_model.encoder.layer.9.attention.output.LayerNorm.weight', 'base_model.pooler.dense.bias', 'base_model.encoder.layer.8.attention.output.LayerNorm.bias', 'base_model.encoder.layer.8.intermediate.dense.weight', 'base_model.encoder.layer.2.attention.self.key.bias', 'base_model.encoder.layer.7.attention.output.LayerNorm.weight', 'base_model.encoder.layer.5.attention.output.dense.weight', 'base_model.embeddings.word_embeddings.weight', 'base_model.encoder.layer.7.output.dense.bias', 'base_model.encoder.layer.9.intermediate.dense.bias', 'base_model.encoder.layer.2.attention.self.query.weight', 'base_model.encoder.layer.11.attention.self.key.bias', 'qa_outputs.weight', 'base_model.encoder.layer.8.attention.output.LayerNorm.weight', 'base_model.encoder.layer.0.attention.self.value.weight', 'base_model.encoder.layer.7.attention.self.key.weight', 'base_model.encoder.layer.0.output.dense.weight', 'base_model.encoder.layer.5.attention.self.key.bias', 'base_model.encoder.layer.6.attention.self.value.weight', 'base_model.encoder.layer.8.attention.self.value.bias', 'base_model.encoder.layer.7.intermediate.dense.bias', 'base_model.encoder.layer.5.attention.output.LayerNorm.bias', 'base_model.encoder.layer.1.attention.output.LayerNorm.weight', 'base_model.encoder.layer.11.attention.output.LayerNorm.bias', 'base_model.embeddings.token_type_embeddings.weight', 'base_model.encoder.layer.2.attention.output.dense.bias', 'base_model.encoder.layer.6.intermediate.dense.weight', 'base_model.encoder.layer.3.output.LayerNorm.bias', 'base_model.encoder.layer.0.attention.self.query.bias', 'base_model.encoder.layer.7.attention.self.value.weight', 'base_model.encoder.layer.10.attention.self.query.bias', 'base_model.embeddings.LayerNorm.weight', 'base_model.encoder.layer.0.attention.self.key.bias', 'base_model.encoder.layer.8.output.dense.bias', 'base_model.encoder.layer.6.attention.output.dense.weight', 'base_model.encoder.layer.3.attention.self.value.weight', 'base_model.encoder.layer.1.attention.self.key.weight', 'base_model.encoder.layer.10.attention.self.key.weight', 'base_model.encoder.layer.0.attention.output.dense.weight', 'base_model.encoder.layer.8.attention.self.query.weight', 'base_model.encoder.layer.9.attention.self.value.weight', 'base_model.encoder.layer.10.output.LayerNorm.bias', 'base_model.encoder.layer.4.attention.output.dense.bias', 'base_model.encoder.layer.10.output.dense.weight', 'base_model.encoder.layer.5.attention.self.query.bias', 'base_model.encoder.layer.6.attention.self.query.bias', 'base_model.encoder.layer.6.attention.output.dense.bias', 'base_model.encoder.layer.4.attention.self.key.bias', 'base_model.encoder.layer.2.attention.output.LayerNorm.bias', 'base_model.encoder.layer.3.output.LayerNorm.weight', 'base_model.encoder.layer.11.output.LayerNorm.bias', 'base_model.encoder.layer.3.intermediate.dense.weight', 'base_model.encoder.layer.0.output.dense.bias', 'base_model.encoder.layer.10.attention.output.LayerNorm.weight', 'base_model.encoder.layer.2.attention.self.value.bias', 'base_model.encoder.layer.5.output.dense.bias', 'base_model.encoder.layer.8.attention.self.key.bias', 'base_model.encoder.layer.10.output.dense.bias', 'base_model.encoder.layer.11.attention.output.dense.weight', 'base_model.embeddings.position_embeddings.weight', 'base_model.encoder.layer.1.intermediate.dense.bias', 'base_model.encoder.layer.1.intermediate.dense.weight', 'base_model.encoder.layer.5.output.dense.weight', 'base_model.encoder.layer.7.attention.self.query.weight', 'base_model.encoder.layer.7.attention.output.dense.weight', 'base_model.encoder.layer.0.output.LayerNorm.weight', 'base_model.encoder.layer.8.attention.self.key.weight', 'base_model.encoder.layer.8.attention.output.dense.bias', 'base_model.encoder.layer.9.attention.self.value.bias', 'base_model.encoder.layer.3.attention.output.dense.weight', 'base_model.encoder.layer.11.attention.self.query.weight', 'base_model.encoder.layer.4.attention.output.LayerNorm.bias', 'base_model.encoder.layer.9.attention.self.query.weight', 'base_model.encoder.layer.6.attention.self.value.bias', 'base_model.encoder.layer.11.output.dense.bias', 'base_model.embeddings.position_ids', 'base_model.encoder.layer.2.intermediate.dense.bias', 'base_model.encoder.layer.0.attention.output.LayerNorm.bias', 'base_model.encoder.layer.6.attention.output.LayerNorm.bias', 'base_model.encoder.layer.9.attention.output.LayerNorm.bias']
- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of XLMRobertaModel were not initialized from the model checkpoint at /cluster/home/yifhou/scratch_yifan/qa/xtreme_xlm/outputs-adapter//squad/xlm_LR1e-5_EPOCH2.0_maxlen384_batchsize8_gradacc2 and are newly initialized: ['encoder.layer.1.attention.self.query.weight', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.8.attention.self.key.weight', 'encoder.layer.0.attention.self.key.weight', 'encoder.layer.9.attention.output.LayerNorm.bias', 'encoder.layer.8.attention.self.value.weight', 'embeddings.position_embeddings.weight', 'encoder.layer.7.attention.self.key.weight', 'encoder.layer.7.output.dense.weight', 'encoder.layer.3.attention.self.value.weight', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.2.output.dense.weight', 'encoder.layer.1.output.dense.bias', 'encoder.layer.4.attention.output.LayerNorm.weight', 'embeddings.token_type_embeddings.weight', 'encoder.layer.10.attention.self.query.bias', 'encoder.layer.5.attention.output.dense.weight', 'pooler.dense.bias', 'encoder.layer.1.attention.self.key.bias', 'encoder.layer.5.output.dense.bias', 'encoder.layer.9.attention.self.key.bias', 'encoder.layer.3.attention.output.dense.weight', 'encoder.layer.0.attention.output.dense.weight', 'encoder.layer.11.attention.self.key.weight', 'encoder.layer.1.output.dense.weight', 'encoder.layer.1.attention.output.dense.weight', 'encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.layer.8.attention.output.LayerNorm.bias', 'encoder.layer.9.attention.output.LayerNorm.weight', 'encoder.layer.11.attention.self.value.bias', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.2.attention.self.query.weight', 'encoder.layer.0.attention.output.dense.bias', 'encoder.layer.2.attention.self.value.weight', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.7.attention.self.query.weight', 'encoder.layer.8.attention.self.key.bias', 'encoder.layer.8.attention.output.dense.bias', 'encoder.layer.8.output.dense.weight', 'encoder.layer.9.output.LayerNorm.weight', 'embeddings.LayerNorm.weight', 'encoder.layer.2.attention.self.query.bias', 'encoder.layer.9.attention.self.value.weight', 'encoder.layer.9.attention.self.value.bias', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.4.attention.self.value.weight', 'encoder.layer.11.attention.output.dense.bias', 'encoder.layer.1.attention.self.key.weight', 'encoder.layer.3.output.dense.bias', 'encoder.layer.3.attention.self.key.weight', 'encoder.layer.10.attention.self.key.bias', 'encoder.layer.6.attention.output.LayerNorm.bias', 'encoder.layer.7.attention.self.key.bias', 'encoder.layer.7.attention.self.value.weight', 'encoder.layer.9.attention.output.dense.bias', 'encoder.layer.0.output.dense.bias', 'encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.9.output.LayerNorm.bias', 'encoder.layer.5.attention.output.LayerNorm.weight', 'encoder.layer.6.attention.output.LayerNorm.weight', 'encoder.layer.2.attention.output.LayerNorm.weight', 'encoder.layer.7.attention.output.LayerNorm.bias', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.6.attention.self.key.bias', 'encoder.layer.11.attention.self.query.weight', 'encoder.layer.10.output.LayerNorm.weight', 'encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.layer.9.attention.self.query.bias', 'encoder.layer.6.attention.output.dense.bias', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.7.attention.self.query.bias', 'encoder.layer.5.attention.self.query.bias', 'encoder.layer.8.attention.self.query.weight', 'encoder.layer.7.output.LayerNorm.bias', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.6.attention.self.query.bias', 'encoder.layer.3.output.dense.weight', 'encoder.layer.4.attention.output.LayerNorm.bias', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.8.attention.self.value.bias', 'encoder.layer.0.output.dense.weight', 'encoder.layer.9.attention.output.dense.weight', 'encoder.layer.11.attention.self.key.bias', 'encoder.layer.1.attention.self.value.weight', 'encoder.layer.3.attention.self.value.bias', 'encoder.layer.6.attention.self.query.weight', 'encoder.layer.6.attention.self.value.bias', 'encoder.layer.7.attention.output.dense.weight', 'encoder.layer.5.attention.self.query.weight', 'encoder.layer.10.attention.output.LayerNorm.bias', 'encoder.layer.10.attention.output.dense.weight', 'encoder.layer.6.attention.self.key.weight', 'encoder.layer.11.attention.self.query.bias', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.2.attention.output.dense.weight', 'encoder.layer.6.output.dense.weight', 'encoder.layer.10.attention.self.value.weight', 'encoder.layer.10.output.dense.weight', 'encoder.layer.8.output.LayerNorm.weight', 'encoder.layer.5.output.dense.weight', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.11.output.dense.weight', 'encoder.layer.5.attention.self.key.weight', 'encoder.layer.4.attention.self.value.bias', 'encoder.layer.10.output.LayerNorm.bias', 'encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.layer.4.attention.self.query.bias', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.5.output.LayerNorm.bias', 'encoder.layer.1.attention.output.dense.bias', 'encoder.layer.0.attention.self.value.weight', 'encoder.layer.7.attention.output.LayerNorm.weight', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.7.attention.self.value.bias', 'encoder.layer.11.output.dense.bias', 'encoder.layer.11.output.LayerNorm.weight', 'encoder.layer.5.output.LayerNorm.weight', 'embeddings.LayerNorm.bias', 'encoder.layer.1.attention.output.LayerNorm.weight', 'encoder.layer.4.output.dense.weight', 'encoder.layer.7.attention.output.dense.bias', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.5.attention.self.value.bias', 'encoder.layer.3.attention.self.query.bias', 'encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.layer.0.attention.output.LayerNorm.weight', 'encoder.layer.1.output.LayerNorm.bias', 'pooler.dense.weight', 'encoder.layer.6.attention.self.value.weight', 'encoder.layer.4.attention.self.key.weight', 'encoder.layer.5.attention.self.value.weight', 'encoder.layer.9.output.dense.bias', 'encoder.layer.9.output.dense.weight', 'encoder.layer.2.attention.self.key.bias', 'encoder.layer.4.attention.self.key.bias', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.10.intermediate.dense.weight', 'encoder.layer.8.attention.self.query.bias', 'encoder.layer.0.attention.self.value.bias', 'encoder.layer.10.attention.output.dense.bias', 'encoder.layer.1.attention.self.value.bias', 'encoder.layer.9.attention.self.query.weight', 'encoder.layer.4.output.dense.bias', 'encoder.layer.8.output.LayerNorm.bias', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.10.attention.self.query.weight', 'encoder.layer.10.attention.self.key.weight', 'encoder.layer.2.output.dense.bias', 'encoder.layer.4.attention.output.dense.bias', 'encoder.layer.0.attention.self.key.bias', 'encoder.layer.3.attention.self.key.bias', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.5.attention.self.key.bias', 'encoder.layer.10.attention.self.value.bias', 'encoder.layer.4.attention.self.query.weight', 'encoder.layer.6.attention.output.dense.weight', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.8.output.dense.bias', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.3.attention.self.query.weight', 'encoder.layer.10.attention.output.LayerNorm.weight', 'encoder.layer.11.attention.output.dense.weight', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.4.attention.output.dense.weight', 'encoder.layer.5.attention.output.dense.bias', 'encoder.layer.6.output.dense.bias', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.11.attention.output.LayerNorm.weight', 'encoder.layer.2.attention.output.LayerNorm.bias', 'encoder.layer.0.attention.self.query.weight', 'encoder.layer.2.attention.self.value.bias', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.7.output.LayerNorm.weight', 'encoder.layer.7.intermediate.dense.bias', 'embeddings.word_embeddings.weight', 'encoder.layer.2.attention.self.key.weight', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.9.attention.self.key.weight', 'encoder.layer.2.attention.output.dense.bias', 'encoder.layer.11.output.LayerNorm.bias', 'encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.1.attention.self.query.bias', 'encoder.layer.0.attention.self.query.bias', 'encoder.layer.8.attention.output.dense.weight', 'encoder.layer.6.output.LayerNorm.bias', 'encoder.layer.7.output.dense.bias', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.layer.10.output.dense.bias', 'encoder.layer.8.attention.output.LayerNorm.weight', 'encoder.layer.11.attention.self.value.weight', 'encoder.layer.3.attention.output.dense.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
05/09/2022 18:33:27 - INFO - __main__ -   Creating features from dataset file at .
/cluster/home/yifhou/scratch_yifan/qa/xtreme_xlm/outputs-adapter//squad/xlm_LR1e-5_EPOCH2.0_maxlen384_batchsize8_gradacc2
XLMConfig {
  "architectures": [
    "XLMRobertaForMaskedLM"
  ],
  "asm": false,
  "attention_dropout": 0.1,
  "attention_probs_dropout_prob": 0.1,
  "bos_index": 0,
  "bos_token_id": 0,
  "causal": false,
  "dropout": 0.1,
  "emb_dim": 768,
  "embed_init_std": 0.02209708691207961,
  "end_n_top": 5,
  "eos_index": 1,
  "eos_token_id": 2,
  "gelu_activation": true,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "init_std": 0.02,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "is_encoder": true,
  "lang_id": 0,
  "layer_norm_eps": 1e-05,
  "mask_index": 5,
  "mask_token_id": 0,
  "max_position_embeddings": 514,
  "model_type": "xlm",
  "n_heads": 12,
  "n_langs": 1,
  "n_layers": 12,
  "output_past": true,
  "pad_index": 2,
  "pad_token_id": 1,
  "sinusoidal_embeddings": false,
  "start_n_top": 5,
  "summary_activation": null,
  "summary_first_dropout": 0.1,
  "summary_proj_to_labels": true,
  "summary_type": "first",
  "summary_use_proj": true,
  "transformers_version": "4.17.0",
  "type_vocab_size": 1,
  "unk_index": 3,
  "use_lang_emb": false,
  "vocab_size": 250002
}

  0%|          | 0/48 [00:00<?, ?it/s] 31%|███▏      | 15/48 [00:00<00:00, 145.47it/s] 62%|██████▎   | 30/48 [00:00<00:00, 114.99it/s] 96%|█████████▌| 46/48 [00:00<00:00, 131.86it/s]100%|██████████| 48/48 [00:00<00:00, 131.16it/s]
convert squad examples to features:   0%|          | 0/1190 [00:00<?, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.
convert squad examples to features:   0%|          | 1/1190 [00:00<02:57,  6.70it/s]convert squad examples to features:   5%|▌         | 65/1190 [00:00<00:04, 232.65it/s]convert squad examples to features:   8%|▊         | 97/1190 [00:00<00:04, 252.82it/s]convert squad examples to features:  14%|█▎        | 161/1190 [00:00<00:03, 320.98it/s]convert squad examples to features:  16%|█▌        | 193/1190 [00:00<00:03, 304.69it/s]convert squad examples to features:  19%|█▉        | 225/1190 [00:00<00:03, 299.71it/s]convert squad examples to features:  24%|██▍       | 289/1190 [00:01<00:03, 287.56it/s]convert squad examples to features:  27%|██▋       | 321/1190 [00:01<00:03, 277.07it/s]convert squad examples to features:  30%|██▉       | 353/1190 [00:01<00:03, 278.05it/s]convert squad examples to features:  32%|███▏      | 385/1190 [00:01<00:04, 164.93it/s]convert squad examples to features:  35%|███▌      | 417/1190 [00:01<00:04, 175.80it/s]convert squad examples to features:  38%|███▊      | 449/1190 [00:01<00:03, 191.18it/s]convert squad examples to features:  40%|████      | 481/1190 [00:02<00:03, 192.97it/s]convert squad examples to features:  43%|████▎     | 513/1190 [00:02<00:03, 215.26it/s]convert squad examples to features:  46%|████▌     | 545/1190 [00:02<00:03, 207.69it/s]convert squad examples to features:  48%|████▊     | 577/1190 [00:02<00:02, 222.66it/s]convert squad examples to features:  51%|█████     | 609/1190 [00:02<00:02, 218.30it/s]convert squad examples to features:  54%|█████▍    | 641/1190 [00:02<00:02, 222.74it/s]convert squad examples to features:  57%|█████▋    | 673/1190 [00:03<00:02, 203.71it/s]convert squad examples to features:  59%|█████▉    | 705/1190 [00:03<00:02, 224.35it/s]convert squad examples to features:  62%|██████▏   | 737/1190 [00:03<00:02, 219.03it/s]convert squad examples to features:  67%|██████▋   | 801/1190 [00:03<00:01, 260.27it/s]convert squad examples to features:  70%|███████   | 833/1190 [00:03<00:01, 237.80it/s]convert squad examples to features:  73%|███████▎  | 865/1190 [00:03<00:01, 232.38it/s]convert squad examples to features:  75%|███████▌  | 897/1190 [00:03<00:01, 219.86it/s]convert squad examples to features:  78%|███████▊  | 929/1190 [00:04<00:01, 204.77it/s]convert squad examples to features:  83%|████████▎ | 993/1190 [00:04<00:00, 249.48it/s]convert squad examples to features:  89%|████████▉ | 1057/1190 [00:04<00:00, 280.96it/s]convert squad examples to features:  94%|█████████▍| 1121/1190 [00:04<00:00, 280.64it/s]convert squad examples to features:  97%|█████████▋| 1153/1190 [00:04<00:00, 272.88it/s]convert squad examples to features: 100%|██████████| 1190/1190 [00:04<00:00, 244.13it/s]
add example index and unique id:   0%|          | 0/1190 [00:00<?, ?it/s]add example index and unique id: 100%|██████████| 1190/1190 [00:00<00:00, 498275.11it/s]
05/09/2022 18:33:33 - INFO - __main__ -   Saving features into cached file ./cached_xquad.en.json_xlm_LR1e-5_EPOCH2.0_maxlen384_batchsize8_gradacc2_384_en
05/09/2022 18:33:34 - INFO - __main__ -   ***** Running evaluation  *****
05/09/2022 18:33:34 - INFO - __main__ -     Num examples = 1270
05/09/2022 18:33:34 - INFO - __main__ -     Batch size = 8
Evaluating:   0%|          | 0/159 [00:00<?, ?it/s]Evaluating:   1%|          | 1/159 [00:00<01:20,  1.96it/s]Evaluating:   2%|▏         | 3/159 [00:00<00:28,  5.39it/s]Evaluating:   3%|▎         | 5/159 [00:00<00:19,  7.89it/s]Evaluating:   4%|▍         | 7/159 [00:00<00:15,  9.99it/s]Evaluating:   6%|▌         | 9/159 [00:01<00:13, 11.50it/s]Evaluating:   7%|▋         | 11/159 [00:01<00:11, 12.59it/s]Evaluating:   8%|▊         | 13/159 [00:01<00:10, 13.45it/s]Evaluating:   9%|▉         | 15/159 [00:01<00:10, 14.10it/s]Evaluating:  11%|█         | 17/159 [00:01<00:09, 14.58it/s]Evaluating:  12%|█▏        | 19/159 [00:01<00:09, 14.89it/s]Evaluating:  13%|█▎        | 21/159 [00:01<00:09, 14.94it/s]Evaluating:  14%|█▍        | 23/159 [00:01<00:09, 15.01it/s]Evaluating:  16%|█▌        | 25/159 [00:02<00:08, 15.09it/s]Evaluating:  17%|█▋        | 27/159 [00:02<00:08, 15.18it/s]Evaluating:  18%|█▊        | 29/159 [00:02<00:08, 15.26it/s]Evaluating:  19%|█▉        | 31/159 [00:02<00:08, 15.36it/s]Evaluating:  21%|██        | 33/159 [00:02<00:08, 15.47it/s]Evaluating:  22%|██▏       | 35/159 [00:02<00:08, 15.50it/s]Evaluating:  23%|██▎       | 37/159 [00:02<00:07, 15.49it/s]Evaluating:  25%|██▍       | 39/159 [00:02<00:07, 15.35it/s]Evaluating:  26%|██▌       | 41/159 [00:03<00:07, 15.33it/s]Evaluating:  27%|██▋       | 43/159 [00:03<00:07, 15.39it/s]Evaluating:  28%|██▊       | 45/159 [00:03<00:07, 15.33it/s]Evaluating:  30%|██▉       | 47/159 [00:03<00:07, 15.25it/s]Evaluating:  31%|███       | 49/159 [00:03<00:07, 15.25it/s]Evaluating:  32%|███▏      | 51/159 [00:03<00:07, 15.24it/s]Evaluating:  33%|███▎      | 53/159 [00:03<00:07, 15.13it/s]Evaluating:  35%|███▍      | 55/159 [00:04<00:06, 15.20it/s]Evaluating:  36%|███▌      | 57/159 [00:04<00:06, 15.25it/s]Evaluating:  37%|███▋      | 59/159 [00:04<00:06, 15.27it/s]Evaluating:  38%|███▊      | 61/159 [00:04<00:06, 15.33it/s]Evaluating:  40%|███▉      | 63/159 [00:04<00:06, 15.38it/s]Evaluating:  41%|████      | 65/159 [00:04<00:06, 15.40it/s]Evaluating:  42%|████▏     | 67/159 [00:04<00:05, 15.38it/s]Evaluating:  43%|████▎     | 69/159 [00:04<00:05, 15.25it/s]Evaluating:  45%|████▍     | 71/159 [00:05<00:05, 15.20it/s]Evaluating:  46%|████▌     | 73/159 [00:05<00:05, 15.29it/s]Evaluating:  47%|████▋     | 75/159 [00:05<00:05, 15.37it/s]Evaluating:  48%|████▊     | 77/159 [00:05<00:05, 15.38it/s]Evaluating:  50%|████▉     | 79/159 [00:05<00:05, 15.33it/s]Evaluating:  51%|█████     | 81/159 [00:05<00:05, 15.34it/s]Evaluating:  52%|█████▏    | 83/159 [00:05<00:04, 15.34it/s]Evaluating:  53%|█████▎    | 85/159 [00:06<00:04, 15.40it/s]Evaluating:  55%|█████▍    | 87/159 [00:06<00:04, 15.39it/s]Evaluating:  56%|█████▌    | 89/159 [00:06<00:04, 15.40it/s]Evaluating:  57%|█████▋    | 91/159 [00:06<00:04, 15.39it/s]Evaluating:  58%|█████▊    | 93/159 [00:06<00:04, 15.36it/s]Evaluating:  60%|█████▉    | 95/159 [00:06<00:04, 15.38it/s]Evaluating:  61%|██████    | 97/159 [00:06<00:04, 15.40it/s]Evaluating:  62%|██████▏   | 99/159 [00:06<00:03, 15.25it/s]Evaluating:  64%|██████▎   | 101/159 [00:07<00:03, 15.15it/s]Evaluating:  65%|██████▍   | 103/159 [00:07<00:03, 15.13it/s]Evaluating:  66%|██████▌   | 105/159 [00:07<00:03, 15.21it/s]Evaluating:  67%|██████▋   | 107/159 [00:07<00:03, 15.34it/s]Evaluating:  69%|██████▊   | 109/159 [00:07<00:03, 15.42it/s]Evaluating:  70%|██████▉   | 111/159 [00:07<00:03, 15.47it/s]Evaluating:  71%|███████   | 113/159 [00:07<00:03, 14.46it/s]Evaluating:  72%|███████▏  | 115/159 [00:07<00:02, 14.76it/s]Evaluating:  74%|███████▎  | 117/159 [00:08<00:02, 14.90it/s]Evaluating:  75%|███████▍  | 119/159 [00:08<00:02, 15.05it/s]Evaluating:  76%|███████▌  | 121/159 [00:08<00:02, 15.10it/s]Evaluating:  77%|███████▋  | 123/159 [00:08<00:02, 15.15it/s]Evaluating:  79%|███████▊  | 125/159 [00:08<00:02, 15.22it/s]Evaluating:  80%|███████▉  | 127/159 [00:08<00:02, 15.20it/s]Evaluating:  81%|████████  | 129/159 [00:09<00:03,  8.08it/s]Evaluating:  82%|████████▏ | 131/159 [00:09<00:02,  9.43it/s]Evaluating:  84%|████████▎ | 133/159 [00:09<00:02, 10.68it/s]Evaluating:  85%|████████▍ | 135/159 [00:09<00:02, 11.75it/s]Evaluating:  86%|████████▌ | 137/159 [00:09<00:01, 12.64it/s]Evaluating:  87%|████████▋ | 139/159 [00:09<00:01, 13.31it/s]Evaluating:  89%|████████▊ | 141/159 [00:10<00:01, 13.88it/s]Evaluating:  90%|████████▉ | 143/159 [00:10<00:01, 14.24it/s]Evaluating:  91%|█████████ | 145/159 [00:10<00:00, 14.56it/s]Evaluating:  92%|█████████▏| 147/159 [00:10<00:00, 14.85it/s]Evaluating:  94%|█████████▎| 149/159 [00:10<00:00, 14.92it/s]Evaluating:  95%|█████████▍| 151/159 [00:10<00:00, 14.97it/s]Evaluating:  96%|█████████▌| 153/159 [00:10<00:00, 15.13it/s]Evaluating:  97%|█████████▋| 155/159 [00:10<00:00, 15.26it/s]Evaluating:  99%|█████████▊| 157/159 [00:11<00:00, 15.30it/s]Evaluating: 100%|██████████| 159/159 [00:11<00:00, 15.93it/s]Evaluating: 100%|██████████| 159/159 [00:11<00:00, 14.16it/s]
05/09/2022 18:33:45 - INFO - __main__ -     Evaluation done in total 11.226342 secs (0.008840 sec per example)
05/09/2022 18:33:49 - INFO - __main__ -   Results: {'exact': 70.84033613445378, 'f1': 82.46264260239408, 'total': 1190, 'HasAns_exact': 70.84033613445378, 'HasAns_f1': 82.46264260239408, 'HasAns_total': 1190, 'best_exact': 70.84033613445378, 'best_exact_thresh': 0.0, 'best_f1': 82.46264260239408, 'best_f1_thresh': 0.0}
  es 
2022-05-09 18:33:52.077100: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0
05/09/2022 18:33:55 - WARNING - __main__ -   Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, 16-bits training: False
You are using a model of type xlm-roberta to instantiate a model of type xlm. This is not supported for all configurations of models and can yield errors.
Some weights of the model checkpoint at /cluster/home/yifhou/scratch_yifan/qa/xtreme_xlm/outputs-adapter//squad/xlm_LR1e-5_EPOCH2.0_maxlen384_batchsize8_gradacc2 were not used when initializing XLMRobertaModel: ['base_model.encoder.layer.10.output.LayerNorm.weight', 'base_model.encoder.layer.5.intermediate.dense.weight', 'base_model.encoder.layer.4.output.LayerNorm.weight', 'base_model.encoder.layer.5.attention.output.dense.bias', 'base_model.encoder.layer.9.attention.self.query.weight', 'base_model.encoder.layer.6.attention.self.key.weight', 'base_model.encoder.layer.3.attention.self.query.bias', 'base_model.encoder.layer.9.attention.self.value.weight', 'base_model.encoder.layer.1.output.dense.weight', 'base_model.encoder.layer.8.attention.output.dense.weight', 'base_model.encoder.layer.7.attention.self.query.weight', 'base_model.embeddings.token_type_embeddings.weight', 'qa_outputs.weight', 'base_model.encoder.layer.11.output.dense.bias', 'base_model.encoder.layer.1.attention.self.value.bias', 'base_model.encoder.layer.1.attention.output.dense.weight', 'base_model.encoder.layer.2.attention.output.dense.bias', 'base_model.encoder.layer.7.attention.self.key.weight', 'base_model.encoder.layer.7.intermediate.dense.bias', 'base_model.embeddings.LayerNorm.bias', 'base_model.encoder.layer.4.attention.self.query.bias', 'base_model.encoder.layer.1.attention.self.query.weight', 'base_model.encoder.layer.11.attention.self.query.bias', 'base_model.encoder.layer.4.output.LayerNorm.bias', 'base_model.encoder.layer.6.output.LayerNorm.weight', 'base_model.encoder.layer.3.output.dense.bias', 'base_model.encoder.layer.10.attention.self.key.bias', 'base_model.encoder.layer.10.attention.output.LayerNorm.bias', 'base_model.encoder.layer.4.output.dense.weight', 'base_model.encoder.layer.6.intermediate.dense.bias', 'base_model.encoder.layer.4.attention.self.query.weight', 'base_model.encoder.layer.8.attention.self.key.weight', 'base_model.encoder.layer.0.attention.self.value.bias', 'base_model.encoder.layer.11.attention.output.LayerNorm.weight', 'base_model.encoder.layer.6.output.LayerNorm.bias', 'base_model.encoder.layer.1.output.dense.bias', 'base_model.encoder.layer.7.output.LayerNorm.bias', 'base_model.encoder.layer.1.attention.output.dense.bias', 'base_model.encoder.layer.8.attention.output.dense.bias', 'base_model.encoder.layer.11.attention.self.query.weight', 'base_model.encoder.layer.0.intermediate.dense.weight', 'base_model.encoder.layer.0.output.LayerNorm.bias', 'base_model.encoder.layer.1.attention.self.key.bias', 'base_model.encoder.layer.4.intermediate.dense.weight', 'base_model.encoder.layer.7.output.LayerNorm.weight', 'base_model.encoder.layer.0.attention.output.LayerNorm.weight', 'base_model.encoder.layer.10.output.dense.bias', 'base_model.encoder.layer.8.output.LayerNorm.bias', 'base_model.encoder.layer.4.intermediate.dense.bias', 'base_model.encoder.layer.9.intermediate.dense.bias', 'base_model.encoder.layer.0.output.dense.weight', 'base_model.encoder.layer.5.attention.output.dense.weight', 'base_model.pooler.dense.weight', 'base_model.encoder.layer.10.attention.self.query.weight', 'base_model.encoder.layer.1.output.LayerNorm.weight', 'base_model.encoder.layer.10.output.LayerNorm.bias', 'base_model.encoder.layer.7.attention.self.key.bias', 'base_model.encoder.layer.2.output.LayerNorm.weight', 'base_model.encoder.layer.4.attention.output.dense.weight', 'base_model.encoder.layer.6.attention.output.LayerNorm.weight', 'base_model.encoder.layer.5.attention.self.key.weight', 'base_model.encoder.layer.5.output.dense.weight', 'base_model.encoder.layer.0.output.dense.bias', 'base_model.encoder.layer.6.output.dense.bias', 'base_model.encoder.layer.8.output.LayerNorm.weight', 'base_model.encoder.layer.1.output.LayerNorm.bias', 'base_model.embeddings.word_embeddings.weight', 'base_model.encoder.layer.8.intermediate.dense.bias', 'base_model.encoder.layer.4.attention.output.LayerNorm.bias', 'base_model.encoder.layer.5.attention.output.LayerNorm.weight', 'base_model.encoder.layer.0.attention.self.key.weight', 'base_model.encoder.layer.0.intermediate.dense.bias', 'base_model.encoder.layer.6.attention.output.dense.bias', 'base_model.encoder.layer.0.attention.output.dense.weight', 'base_model.encoder.layer.3.attention.output.LayerNorm.weight', 'base_model.encoder.layer.8.attention.self.value.bias', 'base_model.encoder.layer.0.attention.self.value.weight', 'base_model.encoder.layer.1.intermediate.dense.bias', 'base_model.encoder.layer.7.attention.output.LayerNorm.weight', 'base_model.encoder.layer.8.attention.self.query.weight', 'base_model.encoder.layer.2.attention.output.LayerNorm.weight', 'base_model.encoder.layer.8.attention.self.query.bias', 'base_model.encoder.layer.11.output.LayerNorm.weight', 'base_model.encoder.layer.5.attention.output.LayerNorm.bias', 'base_model.encoder.layer.0.attention.output.dense.bias', 'base_model.encoder.layer.2.attention.self.query.bias', 'base_model.encoder.layer.7.attention.output.LayerNorm.bias', 'base_model.encoder.layer.3.attention.output.dense.weight', 'base_model.encoder.layer.11.attention.self.key.bias', 'base_model.encoder.layer.9.intermediate.dense.weight', 'base_model.encoder.layer.7.intermediate.dense.weight', 'base_model.encoder.layer.3.intermediate.dense.bias', 'base_model.encoder.layer.1.attention.self.value.weight', 'base_model.encoder.layer.8.attention.self.value.weight', 'base_model.encoder.layer.5.intermediate.dense.bias', 'base_model.encoder.layer.11.intermediate.dense.weight', 'base_model.encoder.layer.5.attention.self.query.weight', 'base_model.encoder.layer.8.attention.output.LayerNorm.weight', 'base_model.encoder.layer.3.output.LayerNorm.weight', 'base_model.encoder.layer.3.attention.self.query.weight', 'base_model.encoder.layer.6.attention.output.LayerNorm.bias', 'base_model.encoder.layer.6.output.dense.weight', 'base_model.encoder.layer.9.output.LayerNorm.weight', 'base_model.encoder.layer.0.attention.output.LayerNorm.bias', 'base_model.encoder.layer.4.output.dense.bias', 'base_model.encoder.layer.9.attention.output.LayerNorm.bias', 'base_model.encoder.layer.2.attention.self.value.bias', 'base_model.encoder.layer.10.attention.self.key.weight', 'base_model.encoder.layer.3.attention.self.key.bias', 'qa_outputs.bias', 'base_model.encoder.layer.3.attention.output.dense.bias', 'base_model.encoder.layer.2.intermediate.dense.weight', 'base_model.encoder.layer.4.attention.self.value.bias', 'base_model.encoder.layer.11.output.LayerNorm.bias', 'base_model.encoder.layer.1.attention.output.LayerNorm.bias', 'base_model.encoder.layer.11.attention.self.key.weight', 'base_model.encoder.layer.11.output.dense.weight', 'base_model.encoder.layer.4.attention.self.value.weight', 'base_model.pooler.dense.bias', 'base_model.encoder.layer.6.attention.self.query.weight', 'base_model.encoder.layer.10.intermediate.dense.weight', 'base_model.embeddings.position_embeddings.weight', 'base_model.encoder.layer.1.attention.self.key.weight', 'base_model.encoder.layer.2.intermediate.dense.bias', 'base_model.encoder.layer.2.output.LayerNorm.bias', 'base_model.encoder.layer.3.intermediate.dense.weight', 'base_model.encoder.layer.2.output.dense.weight', 'base_model.encoder.layer.5.attention.self.query.bias', 'base_model.encoder.layer.10.attention.self.query.bias', 'base_model.encoder.layer.3.attention.output.LayerNorm.bias', 'base_model.encoder.layer.3.attention.self.value.weight', 'base_model.encoder.layer.2.attention.self.query.weight', 'base_model.encoder.layer.8.intermediate.dense.weight', 'base_model.encoder.layer.9.attention.self.query.bias', 'base_model.encoder.layer.9.attention.output.LayerNorm.weight', 'base_model.encoder.layer.2.output.dense.bias', 'base_model.encoder.layer.6.attention.self.query.bias', 'base_model.encoder.layer.2.attention.self.key.bias', 'base_model.encoder.layer.7.attention.self.query.bias', 'base_model.encoder.layer.10.attention.output.dense.weight', 'base_model.encoder.layer.9.attention.self.key.bias', 'base_model.encoder.layer.10.attention.output.LayerNorm.weight', 'base_model.encoder.layer.1.attention.self.query.bias', 'base_model.encoder.layer.9.output.dense.weight', 'base_model.encoder.layer.5.attention.self.key.bias', 'base_model.encoder.layer.5.output.LayerNorm.weight', 'base_model.embeddings.LayerNorm.weight', 'base_model.encoder.layer.3.attention.self.key.weight', 'base_model.encoder.layer.9.attention.self.key.weight', 'base_model.encoder.layer.5.output.LayerNorm.bias', 'base_model.encoder.layer.7.output.dense.bias', 'base_model.encoder.layer.0.attention.self.query.bias', 'base_model.encoder.layer.7.output.dense.weight', 'base_model.encoder.layer.2.attention.self.key.weight', 'base_model.encoder.layer.1.attention.output.LayerNorm.weight', 'base_model.encoder.layer.5.attention.self.value.weight', 'base_model.encoder.layer.11.attention.self.value.weight', 'base_model.encoder.layer.6.attention.self.value.bias', 'base_model.encoder.layer.0.output.LayerNorm.weight', 'base_model.encoder.layer.3.output.LayerNorm.bias', 'base_model.encoder.layer.2.attention.output.dense.weight', 'base_model.encoder.layer.6.attention.output.dense.weight', 'base_model.encoder.layer.11.attention.output.dense.bias', 'base_model.encoder.layer.4.attention.output.dense.bias', 'base_model.encoder.layer.6.attention.self.value.weight', 'base_model.encoder.layer.7.attention.self.value.bias', 'base_model.encoder.layer.10.intermediate.dense.bias', 'base_model.encoder.layer.5.attention.self.value.bias', 'base_model.encoder.layer.3.attention.self.value.bias', 'base_model.encoder.layer.0.attention.self.key.bias', 'base_model.encoder.layer.8.attention.self.key.bias', 'base_model.encoder.layer.7.attention.output.dense.weight', 'base_model.encoder.layer.8.output.dense.weight', 'base_model.encoder.layer.11.intermediate.dense.bias', 'base_model.encoder.layer.7.attention.output.dense.bias', 'base_model.encoder.layer.1.intermediate.dense.weight', 'base_model.encoder.layer.9.output.dense.bias', 'base_model.encoder.layer.10.attention.output.dense.bias', 'base_model.encoder.layer.4.attention.self.key.weight', 'base_model.encoder.layer.7.attention.self.value.weight', 'base_model.encoder.layer.3.output.dense.weight', 'base_model.encoder.layer.9.attention.output.dense.bias', 'base_model.encoder.layer.4.attention.self.key.bias', 'base_model.encoder.layer.0.attention.self.query.weight', 'base_model.encoder.layer.8.attention.output.LayerNorm.bias', 'base_model.encoder.layer.11.attention.self.value.bias', 'base_model.encoder.layer.9.attention.self.value.bias', 'base_model.encoder.layer.11.attention.output.LayerNorm.bias', 'base_model.embeddings.position_ids', 'base_model.encoder.layer.8.output.dense.bias', 'base_model.encoder.layer.2.attention.self.value.weight', 'base_model.encoder.layer.2.attention.output.LayerNorm.bias', 'base_model.encoder.layer.9.output.LayerNorm.bias', 'base_model.encoder.layer.10.output.dense.weight', 'base_model.encoder.layer.4.attention.output.LayerNorm.weight', 'base_model.encoder.layer.6.intermediate.dense.weight', 'base_model.encoder.layer.6.attention.self.key.bias', 'base_model.encoder.layer.5.output.dense.bias', 'base_model.encoder.layer.9.attention.output.dense.weight', 'base_model.encoder.layer.10.attention.self.value.bias', 'base_model.encoder.layer.10.attention.self.value.weight', 'base_model.encoder.layer.11.attention.output.dense.weight']
- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of XLMRobertaModel were not initialized from the model checkpoint at /cluster/home/yifhou/scratch_yifan/qa/xtreme_xlm/outputs-adapter//squad/xlm_LR1e-5_EPOCH2.0_maxlen384_batchsize8_gradacc2 and are newly initialized: ['encoder.layer.1.attention.self.value.bias', 'encoder.layer.3.attention.output.dense.bias', 'encoder.layer.7.attention.output.LayerNorm.weight', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.11.attention.self.value.bias', 'encoder.layer.7.output.LayerNorm.weight', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.7.output.dense.weight', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.2.attention.self.query.weight', 'encoder.layer.3.attention.self.key.weight', 'encoder.layer.11.attention.self.key.bias', 'encoder.layer.8.attention.self.key.bias', 'encoder.layer.11.output.dense.bias', 'encoder.layer.3.output.dense.weight', 'encoder.layer.3.output.dense.bias', 'encoder.layer.6.attention.self.query.weight', 'encoder.layer.7.intermediate.dense.bias', 'encoder.layer.11.output.dense.weight', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.9.attention.self.value.weight', 'encoder.layer.6.attention.self.value.weight', 'encoder.layer.7.attention.output.LayerNorm.bias', 'encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.3.attention.self.value.bias', 'encoder.layer.8.attention.self.query.weight', 'encoder.layer.0.output.dense.bias', 'encoder.layer.4.attention.output.LayerNorm.weight', 'encoder.layer.4.output.dense.weight', 'encoder.layer.4.output.dense.bias', 'encoder.layer.9.output.dense.bias', 'encoder.layer.11.attention.output.LayerNorm.weight', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.11.output.LayerNorm.weight', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.0.output.dense.weight', 'encoder.layer.4.attention.output.LayerNorm.bias', 'encoder.layer.1.attention.output.dense.bias', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.5.attention.self.value.bias', 'encoder.layer.8.attention.output.dense.bias', 'encoder.layer.3.intermediate.dense.bias', 'embeddings.word_embeddings.weight', 'encoder.layer.10.attention.self.value.bias', 'encoder.layer.4.attention.self.key.bias', 'encoder.layer.6.attention.output.dense.weight', 'encoder.layer.7.attention.output.dense.weight', 'encoder.layer.8.output.dense.weight', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.layer.7.attention.self.query.weight', 'encoder.layer.9.attention.self.value.bias', 'encoder.layer.10.attention.self.query.weight', 'encoder.layer.2.attention.self.key.weight', 'encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.layer.5.attention.self.query.bias', 'encoder.layer.4.attention.output.dense.weight', 'encoder.layer.6.attention.output.LayerNorm.bias', 'encoder.layer.3.attention.self.key.bias', 'encoder.layer.4.attention.output.dense.bias', 'encoder.layer.2.output.dense.bias', 'encoder.layer.6.attention.output.dense.bias', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.6.output.LayerNorm.bias', 'encoder.layer.10.attention.self.key.weight', 'encoder.layer.10.attention.output.LayerNorm.bias', 'pooler.dense.bias', 'encoder.layer.7.attention.self.key.weight', 'encoder.layer.9.attention.self.query.bias', 'encoder.layer.8.output.dense.bias', 'encoder.layer.9.attention.self.key.bias', 'encoder.layer.2.attention.output.LayerNorm.weight', 'encoder.layer.0.attention.self.value.bias', 'encoder.layer.7.attention.self.value.bias', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.1.attention.output.LayerNorm.weight', 'encoder.layer.0.attention.self.value.weight', 'encoder.layer.8.output.LayerNorm.bias', 'encoder.layer.9.attention.output.LayerNorm.bias', 'encoder.layer.11.attention.self.query.bias', 'encoder.layer.5.attention.output.dense.bias', 'encoder.layer.1.output.dense.bias', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.5.output.dense.bias', 'encoder.layer.8.attention.self.key.weight', 'encoder.layer.10.output.dense.bias', 'encoder.layer.2.attention.self.value.bias', 'encoder.layer.0.attention.output.dense.weight', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.8.attention.output.dense.weight', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.3.attention.self.query.weight', 'encoder.layer.8.output.LayerNorm.weight', 'encoder.layer.6.attention.output.LayerNorm.weight', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.4.attention.self.query.bias', 'encoder.layer.4.attention.self.key.weight', 'encoder.layer.4.attention.self.query.weight', 'encoder.layer.11.attention.output.dense.bias', 'encoder.layer.11.output.LayerNorm.bias', 'encoder.layer.3.attention.output.dense.weight', 'encoder.layer.6.attention.self.key.weight', 'encoder.layer.8.attention.output.LayerNorm.weight', 'embeddings.position_embeddings.weight', 'encoder.layer.2.attention.output.dense.weight', 'encoder.layer.7.output.dense.bias', 'encoder.layer.11.attention.self.query.weight', 'encoder.layer.1.attention.self.query.bias', 'encoder.layer.5.output.dense.weight', 'encoder.layer.9.output.LayerNorm.weight', 'encoder.layer.8.attention.self.value.bias', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.9.attention.output.LayerNorm.weight', 'encoder.layer.0.attention.output.LayerNorm.weight', 'encoder.layer.5.attention.output.LayerNorm.weight', 'embeddings.token_type_embeddings.weight', 'encoder.layer.7.attention.self.key.bias', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.1.attention.self.query.weight', 'encoder.layer.7.attention.self.value.weight', 'encoder.layer.0.attention.self.key.bias', 'encoder.layer.7.attention.output.dense.bias', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.10.attention.self.query.bias', 'encoder.layer.9.attention.output.dense.weight', 'embeddings.LayerNorm.bias', 'encoder.layer.0.attention.self.query.bias', 'encoder.layer.10.output.LayerNorm.weight', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.6.output.dense.weight', 'encoder.layer.8.attention.self.value.weight', 'encoder.layer.9.attention.self.key.weight', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.3.attention.self.query.bias', 'encoder.layer.6.output.dense.bias', 'encoder.layer.2.attention.output.LayerNorm.bias', 'encoder.layer.7.output.LayerNorm.bias', 'encoder.layer.1.attention.self.value.weight', 'encoder.layer.1.attention.output.dense.weight', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.9.attention.self.query.weight', 'encoder.layer.4.attention.self.value.bias', 'encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.layer.5.attention.self.key.weight', 'encoder.layer.2.attention.self.key.bias', 'encoder.layer.9.output.LayerNorm.bias', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.5.attention.self.key.bias', 'encoder.layer.2.attention.self.value.weight', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.0.attention.output.dense.bias', 'encoder.layer.5.attention.output.dense.weight', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.6.attention.self.value.bias', 'encoder.layer.5.output.LayerNorm.bias', 'encoder.layer.5.attention.self.query.weight', 'encoder.layer.8.attention.self.query.bias', 'encoder.layer.10.attention.self.value.weight', 'encoder.layer.10.attention.output.dense.bias', 'encoder.layer.9.attention.output.dense.bias', 'encoder.layer.4.attention.self.value.weight', 'encoder.layer.2.output.dense.weight', 'encoder.layer.11.attention.self.key.weight', 'encoder.layer.11.attention.self.value.weight', 'encoder.layer.11.attention.output.dense.weight', 'encoder.layer.10.output.dense.weight', 'pooler.dense.weight', 'encoder.layer.10.intermediate.dense.weight', 'encoder.layer.3.attention.self.value.weight', 'embeddings.LayerNorm.weight', 'encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.layer.0.attention.self.query.weight', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.2.attention.output.dense.bias', 'encoder.layer.10.attention.self.key.bias', 'encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.layer.1.attention.self.key.bias', 'encoder.layer.5.attention.self.value.weight', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.0.attention.self.key.weight', 'encoder.layer.9.output.dense.weight', 'encoder.layer.2.attention.self.query.bias', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.10.attention.output.LayerNorm.weight', 'encoder.layer.7.attention.self.query.bias', 'encoder.layer.8.attention.output.LayerNorm.bias', 'encoder.layer.1.attention.self.key.weight', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.6.attention.self.query.bias', 'encoder.layer.10.output.LayerNorm.bias', 'encoder.layer.1.output.dense.weight', 'encoder.layer.10.attention.output.dense.weight', 'encoder.layer.6.attention.self.key.bias', 'encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.layer.3.output.LayerNorm.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
05/09/2022 18:34:01 - INFO - __main__ -   lang2id = None
05/09/2022 18:34:04 - INFO - __main__ -   Training/evaluation parameters Namespace(adam_epsilon=1e-08, cache_dir='', config_name='', data_dir=None, device=device(type='cuda'), do_eval=True, do_lower_case=False, do_train=False, doc_stride=128, eval_all_checkpoints=False, eval_lang='es', evaluate_during_training=False, fp16=False, fp16_opt_level='O1', gradient_accumulation_steps=1, learning_rate=5e-05, local_rank=-1, logging_steps=50, max_answer_length=30, max_grad_norm=1.0, max_query_length=64, max_seq_length=384, max_steps=-1, model_name='xlm-KG', model_name_or_path='/cluster/home/yifhou/scratch_yifan/qa/xtreme_xlm/outputs-adapter//squad/xlm_LR1e-5_EPOCH2.0_maxlen384_batchsize8_gradacc2', model_type='xlm', modelkg_dir='/cluster/home/yifhou/scratch_yifan/qa/xtreme_xlm/adapter/xlm_adapter', n_best_size=20, n_gpu=1, no_cuda=False, null_score_diff_threshold=0.0, num_train_epochs=3.0, output_dir='/cluster/home/yifhou/scratch_yifan/qa/xtreme_xlm/outputs-adapter//squad/xlm_LR1e-5_EPOCH2.0_maxlen384_batchsize8_gradacc2/predictions/xquad/', overwrite_cache=False, overwrite_output_dir=False, per_gpu_eval_batch_size=8, per_gpu_train_batch_size=8, predict_file='/cluster/home/yifhou/scratch_yifan/qa/xtreme_xlm/download//xquad//xquad.es.json', save_steps=50, seed=42, server_ip='', server_port='', threads=1, tokenizer_name='', train_file=None, train_lang='en', verbose_logging=False, version_2_with_negative=False, warmup_steps=0, weight_decay=0.0)
05/09/2022 18:34:04 - INFO - __main__ -   Loading checkpoint /cluster/home/yifhou/scratch_yifan/qa/xtreme_xlm/outputs-adapter//squad/xlm_LR1e-5_EPOCH2.0_maxlen384_batchsize8_gradacc2 for evaluation
05/09/2022 18:34:04 - INFO - __main__ -   Evaluate the following checkpoints: ['/cluster/home/yifhou/scratch_yifan/qa/xtreme_xlm/outputs-adapter//squad/xlm_LR1e-5_EPOCH2.0_maxlen384_batchsize8_gradacc2']
Some weights of the model checkpoint at /cluster/home/yifhou/scratch_yifan/qa/xtreme_xlm/outputs-adapter//squad/xlm_LR1e-5_EPOCH2.0_maxlen384_batchsize8_gradacc2 were not used when initializing XLMRobertaModel: ['base_model.encoder.layer.10.output.LayerNorm.weight', 'base_model.encoder.layer.5.intermediate.dense.weight', 'base_model.encoder.layer.4.output.LayerNorm.weight', 'base_model.encoder.layer.5.attention.output.dense.bias', 'base_model.encoder.layer.9.attention.self.query.weight', 'base_model.encoder.layer.6.attention.self.key.weight', 'base_model.encoder.layer.3.attention.self.query.bias', 'base_model.encoder.layer.9.attention.self.value.weight', 'base_model.encoder.layer.1.output.dense.weight', 'base_model.encoder.layer.8.attention.output.dense.weight', 'base_model.encoder.layer.7.attention.self.query.weight', 'base_model.embeddings.token_type_embeddings.weight', 'qa_outputs.weight', 'base_model.encoder.layer.11.output.dense.bias', 'base_model.encoder.layer.1.attention.self.value.bias', 'base_model.encoder.layer.1.attention.output.dense.weight', 'base_model.encoder.layer.2.attention.output.dense.bias', 'base_model.encoder.layer.7.attention.self.key.weight', 'base_model.encoder.layer.7.intermediate.dense.bias', 'base_model.embeddings.LayerNorm.bias', 'base_model.encoder.layer.4.attention.self.query.bias', 'base_model.encoder.layer.1.attention.self.query.weight', 'base_model.encoder.layer.11.attention.self.query.bias', 'base_model.encoder.layer.4.output.LayerNorm.bias', 'base_model.encoder.layer.6.output.LayerNorm.weight', 'base_model.encoder.layer.3.output.dense.bias', 'base_model.encoder.layer.10.attention.self.key.bias', 'base_model.encoder.layer.10.attention.output.LayerNorm.bias', 'base_model.encoder.layer.4.output.dense.weight', 'base_model.encoder.layer.6.intermediate.dense.bias', 'base_model.encoder.layer.4.attention.self.query.weight', 'base_model.encoder.layer.8.attention.self.key.weight', 'base_model.encoder.layer.0.attention.self.value.bias', 'base_model.encoder.layer.11.attention.output.LayerNorm.weight', 'base_model.encoder.layer.6.output.LayerNorm.bias', 'base_model.encoder.layer.1.output.dense.bias', 'base_model.encoder.layer.7.output.LayerNorm.bias', 'base_model.encoder.layer.1.attention.output.dense.bias', 'base_model.encoder.layer.8.attention.output.dense.bias', 'base_model.encoder.layer.11.attention.self.query.weight', 'base_model.encoder.layer.0.intermediate.dense.weight', 'base_model.encoder.layer.0.output.LayerNorm.bias', 'base_model.encoder.layer.1.attention.self.key.bias', 'base_model.encoder.layer.4.intermediate.dense.weight', 'base_model.encoder.layer.7.output.LayerNorm.weight', 'base_model.encoder.layer.0.attention.output.LayerNorm.weight', 'base_model.encoder.layer.10.output.dense.bias', 'base_model.encoder.layer.8.output.LayerNorm.bias', 'base_model.encoder.layer.4.intermediate.dense.bias', 'base_model.encoder.layer.9.intermediate.dense.bias', 'base_model.encoder.layer.0.output.dense.weight', 'base_model.encoder.layer.5.attention.output.dense.weight', 'base_model.pooler.dense.weight', 'base_model.encoder.layer.10.attention.self.query.weight', 'base_model.encoder.layer.1.output.LayerNorm.weight', 'base_model.encoder.layer.10.output.LayerNorm.bias', 'base_model.encoder.layer.7.attention.self.key.bias', 'base_model.encoder.layer.2.output.LayerNorm.weight', 'base_model.encoder.layer.4.attention.output.dense.weight', 'base_model.encoder.layer.6.attention.output.LayerNorm.weight', 'base_model.encoder.layer.5.attention.self.key.weight', 'base_model.encoder.layer.5.output.dense.weight', 'base_model.encoder.layer.0.output.dense.bias', 'base_model.encoder.layer.6.output.dense.bias', 'base_model.encoder.layer.8.output.LayerNorm.weight', 'base_model.encoder.layer.1.output.LayerNorm.bias', 'base_model.embeddings.word_embeddings.weight', 'base_model.encoder.layer.8.intermediate.dense.bias', 'base_model.encoder.layer.4.attention.output.LayerNorm.bias', 'base_model.encoder.layer.5.attention.output.LayerNorm.weight', 'base_model.encoder.layer.0.attention.self.key.weight', 'base_model.encoder.layer.0.intermediate.dense.bias', 'base_model.encoder.layer.6.attention.output.dense.bias', 'base_model.encoder.layer.0.attention.output.dense.weight', 'base_model.encoder.layer.3.attention.output.LayerNorm.weight', 'base_model.encoder.layer.8.attention.self.value.bias', 'base_model.encoder.layer.0.attention.self.value.weight', 'base_model.encoder.layer.1.intermediate.dense.bias', 'base_model.encoder.layer.7.attention.output.LayerNorm.weight', 'base_model.encoder.layer.8.attention.self.query.weight', 'base_model.encoder.layer.2.attention.output.LayerNorm.weight', 'base_model.encoder.layer.8.attention.self.query.bias', 'base_model.encoder.layer.11.output.LayerNorm.weight', 'base_model.encoder.layer.5.attention.output.LayerNorm.bias', 'base_model.encoder.layer.0.attention.output.dense.bias', 'base_model.encoder.layer.2.attention.self.query.bias', 'base_model.encoder.layer.7.attention.output.LayerNorm.bias', 'base_model.encoder.layer.3.attention.output.dense.weight', 'base_model.encoder.layer.11.attention.self.key.bias', 'base_model.encoder.layer.9.intermediate.dense.weight', 'base_model.encoder.layer.7.intermediate.dense.weight', 'base_model.encoder.layer.3.intermediate.dense.bias', 'base_model.encoder.layer.1.attention.self.value.weight', 'base_model.encoder.layer.8.attention.self.value.weight', 'base_model.encoder.layer.5.intermediate.dense.bias', 'base_model.encoder.layer.11.intermediate.dense.weight', 'base_model.encoder.layer.5.attention.self.query.weight', 'base_model.encoder.layer.8.attention.output.LayerNorm.weight', 'base_model.encoder.layer.3.output.LayerNorm.weight', 'base_model.encoder.layer.3.attention.self.query.weight', 'base_model.encoder.layer.6.attention.output.LayerNorm.bias', 'base_model.encoder.layer.6.output.dense.weight', 'base_model.encoder.layer.9.output.LayerNorm.weight', 'base_model.encoder.layer.0.attention.output.LayerNorm.bias', 'base_model.encoder.layer.4.output.dense.bias', 'base_model.encoder.layer.9.attention.output.LayerNorm.bias', 'base_model.encoder.layer.2.attention.self.value.bias', 'base_model.encoder.layer.10.attention.self.key.weight', 'base_model.encoder.layer.3.attention.self.key.bias', 'qa_outputs.bias', 'base_model.encoder.layer.3.attention.output.dense.bias', 'base_model.encoder.layer.2.intermediate.dense.weight', 'base_model.encoder.layer.4.attention.self.value.bias', 'base_model.encoder.layer.11.output.LayerNorm.bias', 'base_model.encoder.layer.1.attention.output.LayerNorm.bias', 'base_model.encoder.layer.11.attention.self.key.weight', 'base_model.encoder.layer.11.output.dense.weight', 'base_model.encoder.layer.4.attention.self.value.weight', 'base_model.pooler.dense.bias', 'base_model.encoder.layer.6.attention.self.query.weight', 'base_model.encoder.layer.10.intermediate.dense.weight', 'base_model.embeddings.position_embeddings.weight', 'base_model.encoder.layer.1.attention.self.key.weight', 'base_model.encoder.layer.2.intermediate.dense.bias', 'base_model.encoder.layer.2.output.LayerNorm.bias', 'base_model.encoder.layer.3.intermediate.dense.weight', 'base_model.encoder.layer.2.output.dense.weight', 'base_model.encoder.layer.5.attention.self.query.bias', 'base_model.encoder.layer.10.attention.self.query.bias', 'base_model.encoder.layer.3.attention.output.LayerNorm.bias', 'base_model.encoder.layer.3.attention.self.value.weight', 'base_model.encoder.layer.2.attention.self.query.weight', 'base_model.encoder.layer.8.intermediate.dense.weight', 'base_model.encoder.layer.9.attention.self.query.bias', 'base_model.encoder.layer.9.attention.output.LayerNorm.weight', 'base_model.encoder.layer.2.output.dense.bias', 'base_model.encoder.layer.6.attention.self.query.bias', 'base_model.encoder.layer.2.attention.self.key.bias', 'base_model.encoder.layer.7.attention.self.query.bias', 'base_model.encoder.layer.10.attention.output.dense.weight', 'base_model.encoder.layer.9.attention.self.key.bias', 'base_model.encoder.layer.10.attention.output.LayerNorm.weight', 'base_model.encoder.layer.1.attention.self.query.bias', 'base_model.encoder.layer.9.output.dense.weight', 'base_model.encoder.layer.5.attention.self.key.bias', 'base_model.encoder.layer.5.output.LayerNorm.weight', 'base_model.embeddings.LayerNorm.weight', 'base_model.encoder.layer.3.attention.self.key.weight', 'base_model.encoder.layer.9.attention.self.key.weight', 'base_model.encoder.layer.5.output.LayerNorm.bias', 'base_model.encoder.layer.7.output.dense.bias', 'base_model.encoder.layer.0.attention.self.query.bias', 'base_model.encoder.layer.7.output.dense.weight', 'base_model.encoder.layer.2.attention.self.key.weight', 'base_model.encoder.layer.1.attention.output.LayerNorm.weight', 'base_model.encoder.layer.5.attention.self.value.weight', 'base_model.encoder.layer.11.attention.self.value.weight', 'base_model.encoder.layer.6.attention.self.value.bias', 'base_model.encoder.layer.0.output.LayerNorm.weight', 'base_model.encoder.layer.3.output.LayerNorm.bias', 'base_model.encoder.layer.2.attention.output.dense.weight', 'base_model.encoder.layer.6.attention.output.dense.weight', 'base_model.encoder.layer.11.attention.output.dense.bias', 'base_model.encoder.layer.4.attention.output.dense.bias', 'base_model.encoder.layer.6.attention.self.value.weight', 'base_model.encoder.layer.7.attention.self.value.bias', 'base_model.encoder.layer.10.intermediate.dense.bias', 'base_model.encoder.layer.5.attention.self.value.bias', 'base_model.encoder.layer.3.attention.self.value.bias', 'base_model.encoder.layer.0.attention.self.key.bias', 'base_model.encoder.layer.8.attention.self.key.bias', 'base_model.encoder.layer.7.attention.output.dense.weight', 'base_model.encoder.layer.8.output.dense.weight', 'base_model.encoder.layer.11.intermediate.dense.bias', 'base_model.encoder.layer.7.attention.output.dense.bias', 'base_model.encoder.layer.1.intermediate.dense.weight', 'base_model.encoder.layer.9.output.dense.bias', 'base_model.encoder.layer.10.attention.output.dense.bias', 'base_model.encoder.layer.4.attention.self.key.weight', 'base_model.encoder.layer.7.attention.self.value.weight', 'base_model.encoder.layer.3.output.dense.weight', 'base_model.encoder.layer.9.attention.output.dense.bias', 'base_model.encoder.layer.4.attention.self.key.bias', 'base_model.encoder.layer.0.attention.self.query.weight', 'base_model.encoder.layer.8.attention.output.LayerNorm.bias', 'base_model.encoder.layer.11.attention.self.value.bias', 'base_model.encoder.layer.9.attention.self.value.bias', 'base_model.encoder.layer.11.attention.output.LayerNorm.bias', 'base_model.embeddings.position_ids', 'base_model.encoder.layer.8.output.dense.bias', 'base_model.encoder.layer.2.attention.self.value.weight', 'base_model.encoder.layer.2.attention.output.LayerNorm.bias', 'base_model.encoder.layer.9.output.LayerNorm.bias', 'base_model.encoder.layer.10.output.dense.weight', 'base_model.encoder.layer.4.attention.output.LayerNorm.weight', 'base_model.encoder.layer.6.intermediate.dense.weight', 'base_model.encoder.layer.6.attention.self.key.bias', 'base_model.encoder.layer.5.output.dense.bias', 'base_model.encoder.layer.9.attention.output.dense.weight', 'base_model.encoder.layer.10.attention.self.value.bias', 'base_model.encoder.layer.10.attention.self.value.weight', 'base_model.encoder.layer.11.attention.output.dense.weight']
- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of XLMRobertaModel were not initialized from the model checkpoint at /cluster/home/yifhou/scratch_yifan/qa/xtreme_xlm/outputs-adapter//squad/xlm_LR1e-5_EPOCH2.0_maxlen384_batchsize8_gradacc2 and are newly initialized: ['encoder.layer.1.attention.self.value.bias', 'encoder.layer.3.attention.output.dense.bias', 'encoder.layer.7.attention.output.LayerNorm.weight', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.11.attention.self.value.bias', 'encoder.layer.7.output.LayerNorm.weight', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.7.output.dense.weight', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.2.attention.self.query.weight', 'encoder.layer.3.attention.self.key.weight', 'encoder.layer.11.attention.self.key.bias', 'encoder.layer.8.attention.self.key.bias', 'encoder.layer.11.output.dense.bias', 'encoder.layer.3.output.dense.weight', 'encoder.layer.3.output.dense.bias', 'encoder.layer.6.attention.self.query.weight', 'encoder.layer.7.intermediate.dense.bias', 'encoder.layer.11.output.dense.weight', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.9.attention.self.value.weight', 'encoder.layer.6.attention.self.value.weight', 'encoder.layer.7.attention.output.LayerNorm.bias', 'encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.3.attention.self.value.bias', 'encoder.layer.8.attention.self.query.weight', 'encoder.layer.0.output.dense.bias', 'encoder.layer.4.attention.output.LayerNorm.weight', 'encoder.layer.4.output.dense.weight', 'encoder.layer.4.output.dense.bias', 'encoder.layer.9.output.dense.bias', 'encoder.layer.11.attention.output.LayerNorm.weight', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.11.output.LayerNorm.weight', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.0.output.dense.weight', 'encoder.layer.4.attention.output.LayerNorm.bias', 'encoder.layer.1.attention.output.dense.bias', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.5.attention.self.value.bias', 'encoder.layer.8.attention.output.dense.bias', 'encoder.layer.3.intermediate.dense.bias', 'embeddings.word_embeddings.weight', 'encoder.layer.10.attention.self.value.bias', 'encoder.layer.4.attention.self.key.bias', 'encoder.layer.6.attention.output.dense.weight', 'encoder.layer.7.attention.output.dense.weight', 'encoder.layer.8.output.dense.weight', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.layer.7.attention.self.query.weight', 'encoder.layer.9.attention.self.value.bias', 'encoder.layer.10.attention.self.query.weight', 'encoder.layer.2.attention.self.key.weight', 'encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.layer.5.attention.self.query.bias', 'encoder.layer.4.attention.output.dense.weight', 'encoder.layer.6.attention.output.LayerNorm.bias', 'encoder.layer.3.attention.self.key.bias', 'encoder.layer.4.attention.output.dense.bias', 'encoder.layer.2.output.dense.bias', 'encoder.layer.6.attention.output.dense.bias', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.6.output.LayerNorm.bias', 'encoder.layer.10.attention.self.key.weight', 'encoder.layer.10.attention.output.LayerNorm.bias', 'pooler.dense.bias', 'encoder.layer.7.attention.self.key.weight', 'encoder.layer.9.attention.self.query.bias', 'encoder.layer.8.output.dense.bias', 'encoder.layer.9.attention.self.key.bias', 'encoder.layer.2.attention.output.LayerNorm.weight', 'encoder.layer.0.attention.self.value.bias', 'encoder.layer.7.attention.self.value.bias', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.1.attention.output.LayerNorm.weight', 'encoder.layer.0.attention.self.value.weight', 'encoder.layer.8.output.LayerNorm.bias', 'encoder.layer.9.attention.output.LayerNorm.bias', 'encoder.layer.11.attention.self.query.bias', 'encoder.layer.5.attention.output.dense.bias', 'encoder.layer.1.output.dense.bias', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.5.output.dense.bias', 'encoder.layer.8.attention.self.key.weight', 'encoder.layer.10.output.dense.bias', 'encoder.layer.2.attention.self.value.bias', 'encoder.layer.0.attention.output.dense.weight', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.8.attention.output.dense.weight', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.3.attention.self.query.weight', 'encoder.layer.8.output.LayerNorm.weight', 'encoder.layer.6.attention.output.LayerNorm.weight', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.4.attention.self.query.bias', 'encoder.layer.4.attention.self.key.weight', 'encoder.layer.4.attention.self.query.weight', 'encoder.layer.11.attention.output.dense.bias', 'encoder.layer.11.output.LayerNorm.bias', 'encoder.layer.3.attention.output.dense.weight', 'encoder.layer.6.attention.self.key.weight', 'encoder.layer.8.attention.output.LayerNorm.weight', 'embeddings.position_embeddings.weight', 'encoder.layer.2.attention.output.dense.weight', 'encoder.layer.7.output.dense.bias', 'encoder.layer.11.attention.self.query.weight', 'encoder.layer.1.attention.self.query.bias', 'encoder.layer.5.output.dense.weight', 'encoder.layer.9.output.LayerNorm.weight', 'encoder.layer.8.attention.self.value.bias', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.9.attention.output.LayerNorm.weight', 'encoder.layer.0.attention.output.LayerNorm.weight', 'encoder.layer.5.attention.output.LayerNorm.weight', 'embeddings.token_type_embeddings.weight', 'encoder.layer.7.attention.self.key.bias', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.1.attention.self.query.weight', 'encoder.layer.7.attention.self.value.weight', 'encoder.layer.0.attention.self.key.bias', 'encoder.layer.7.attention.output.dense.bias', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.10.attention.self.query.bias', 'encoder.layer.9.attention.output.dense.weight', 'embeddings.LayerNorm.bias', 'encoder.layer.0.attention.self.query.bias', 'encoder.layer.10.output.LayerNorm.weight', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.6.output.dense.weight', 'encoder.layer.8.attention.self.value.weight', 'encoder.layer.9.attention.self.key.weight', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.3.attention.self.query.bias', 'encoder.layer.6.output.dense.bias', 'encoder.layer.2.attention.output.LayerNorm.bias', 'encoder.layer.7.output.LayerNorm.bias', 'encoder.layer.1.attention.self.value.weight', 'encoder.layer.1.attention.output.dense.weight', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.9.attention.self.query.weight', 'encoder.layer.4.attention.self.value.bias', 'encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.layer.5.attention.self.key.weight', 'encoder.layer.2.attention.self.key.bias', 'encoder.layer.9.output.LayerNorm.bias', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.5.attention.self.key.bias', 'encoder.layer.2.attention.self.value.weight', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.0.attention.output.dense.bias', 'encoder.layer.5.attention.output.dense.weight', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.6.attention.self.value.bias', 'encoder.layer.5.output.LayerNorm.bias', 'encoder.layer.5.attention.self.query.weight', 'encoder.layer.8.attention.self.query.bias', 'encoder.layer.10.attention.self.value.weight', 'encoder.layer.10.attention.output.dense.bias', 'encoder.layer.9.attention.output.dense.bias', 'encoder.layer.4.attention.self.value.weight', 'encoder.layer.2.output.dense.weight', 'encoder.layer.11.attention.self.key.weight', 'encoder.layer.11.attention.self.value.weight', 'encoder.layer.11.attention.output.dense.weight', 'encoder.layer.10.output.dense.weight', 'pooler.dense.weight', 'encoder.layer.10.intermediate.dense.weight', 'encoder.layer.3.attention.self.value.weight', 'embeddings.LayerNorm.weight', 'encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.layer.0.attention.self.query.weight', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.2.attention.output.dense.bias', 'encoder.layer.10.attention.self.key.bias', 'encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.layer.1.attention.self.key.bias', 'encoder.layer.5.attention.self.value.weight', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.0.attention.self.key.weight', 'encoder.layer.9.output.dense.weight', 'encoder.layer.2.attention.self.query.bias', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.10.attention.output.LayerNorm.weight', 'encoder.layer.7.attention.self.query.bias', 'encoder.layer.8.attention.output.LayerNorm.bias', 'encoder.layer.1.attention.self.key.weight', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.6.attention.self.query.bias', 'encoder.layer.10.output.LayerNorm.bias', 'encoder.layer.1.output.dense.weight', 'encoder.layer.10.attention.output.dense.weight', 'encoder.layer.6.attention.self.key.bias', 'encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.layer.3.output.LayerNorm.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
05/09/2022 18:34:12 - INFO - __main__ -   Creating features from dataset file at .
/cluster/home/yifhou/scratch_yifan/qa/xtreme_xlm/outputs-adapter//squad/xlm_LR1e-5_EPOCH2.0_maxlen384_batchsize8_gradacc2
XLMConfig {
  "architectures": [
    "XLMRobertaForMaskedLM"
  ],
  "asm": false,
  "attention_dropout": 0.1,
  "attention_probs_dropout_prob": 0.1,
  "bos_index": 0,
  "bos_token_id": 0,
  "causal": false,
  "dropout": 0.1,
  "emb_dim": 768,
  "embed_init_std": 0.02209708691207961,
  "end_n_top": 5,
  "eos_index": 1,
  "eos_token_id": 2,
  "gelu_activation": true,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "init_std": 0.02,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "is_encoder": true,
  "lang_id": 0,
  "layer_norm_eps": 1e-05,
  "mask_index": 5,
  "mask_token_id": 0,
  "max_position_embeddings": 514,
  "model_type": "xlm",
  "n_heads": 12,
  "n_langs": 1,
  "n_layers": 12,
  "output_past": true,
  "pad_index": 2,
  "pad_token_id": 1,
  "sinusoidal_embeddings": false,
  "start_n_top": 5,
  "summary_activation": null,
  "summary_first_dropout": 0.1,
  "summary_proj_to_labels": true,
  "summary_type": "first",
  "summary_use_proj": true,
  "transformers_version": "4.17.0",
  "type_vocab_size": 1,
  "unk_index": 3,
  "use_lang_emb": false,
  "vocab_size": 250002
}

  0%|          | 0/48 [00:00<?, ?it/s] 23%|██▎       | 11/48 [00:00<00:00, 101.37it/s] 46%|████▌     | 22/48 [00:00<00:00, 88.73it/s]  65%|██████▍   | 31/48 [00:00<00:00, 86.28it/s] 92%|█████████▏| 44/48 [00:00<00:00, 99.89it/s]100%|██████████| 48/48 [00:00<00:00, 96.51it/s]
convert squad examples to features:   0%|          | 0/1190 [00:00<?, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.
convert squad examples to features:   0%|          | 1/1190 [00:00<04:48,  4.12it/s]convert squad examples to features:   5%|▌         | 65/1190 [00:00<00:06, 168.16it/s]convert squad examples to features:   8%|▊         | 97/1190 [00:00<00:05, 186.40it/s]convert squad examples to features:  14%|█▎        | 161/1190 [00:00<00:04, 240.43it/s]convert squad examples to features:  16%|█▌        | 193/1190 [00:00<00:04, 242.98it/s]convert squad examples to features:  19%|█▉        | 225/1190 [00:01<00:03, 249.88it/s]convert squad examples to features:  22%|██▏       | 257/1190 [00:01<00:03, 247.74it/s]convert squad examples to features:  24%|██▍       | 289/1190 [00:01<00:03, 247.00it/s]convert squad examples to features:  27%|██▋       | 321/1190 [00:01<00:03, 234.68it/s]convert squad examples to features:  30%|██▉       | 353/1190 [00:01<00:03, 248.87it/s]convert squad examples to features:  32%|███▏      | 385/1190 [00:02<00:06, 130.24it/s]convert squad examples to features:  35%|███▌      | 417/1190 [00:02<00:05, 141.54it/s]convert squad examples to features:  38%|███▊      | 449/1190 [00:02<00:04, 150.52it/s]convert squad examples to features:  40%|████      | 481/1190 [00:02<00:04, 161.91it/s]convert squad examples to features:  43%|████▎     | 513/1190 [00:02<00:04, 168.58it/s]convert squad examples to features:  46%|████▌     | 545/1190 [00:02<00:03, 170.11it/s]convert squad examples to features:  48%|████▊     | 577/1190 [00:03<00:03, 178.62it/s]convert squad examples to features:  51%|█████     | 609/1190 [00:03<00:03, 180.66it/s]convert squad examples to features:  54%|█████▍    | 641/1190 [00:03<00:03, 179.12it/s]convert squad examples to features:  57%|█████▋    | 673/1190 [00:03<00:02, 182.15it/s]convert squad examples to features:  59%|█████▉    | 705/1190 [00:03<00:02, 191.92it/s]convert squad examples to features:  62%|██████▏   | 737/1190 [00:03<00:02, 208.57it/s]convert squad examples to features:  65%|██████▍   | 769/1190 [00:04<00:01, 231.43it/s]convert squad examples to features:  67%|██████▋   | 801/1190 [00:04<00:01, 243.27it/s]convert squad examples to features:  70%|███████   | 833/1190 [00:04<00:01, 225.90it/s]convert squad examples to features:  73%|███████▎  | 865/1190 [00:04<00:01, 233.75it/s]convert squad examples to features:  75%|███████▌  | 897/1190 [00:04<00:01, 207.47it/s]convert squad examples to features:  78%|███████▊  | 929/1190 [00:04<00:01, 221.48it/s]convert squad examples to features:  81%|████████  | 961/1190 [00:04<00:01, 223.10it/s]convert squad examples to features:  83%|████████▎ | 993/1190 [00:05<00:00, 238.30it/s]convert squad examples to features:  86%|████████▌ | 1025/1190 [00:05<00:00, 242.56it/s]convert squad examples to features:  89%|████████▉ | 1057/1190 [00:05<00:00, 242.99it/s]convert squad examples to features:  92%|█████████▏| 1089/1190 [00:05<00:00, 246.45it/s]convert squad examples to features:  94%|█████████▍| 1121/1190 [00:05<00:00, 228.03it/s]convert squad examples to features:  97%|█████████▋| 1153/1190 [00:05<00:00, 194.69it/s]convert squad examples to features: 100%|██████████| 1190/1190 [00:05<00:00, 205.22it/s]/cluster/project/sachan/yifan/softwares/anaconda/anaconda3/envs/xfactr/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2272: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

add example index and unique id:   0%|          | 0/1190 [00:00<?, ?it/s]add example index and unique id: 100%|██████████| 1190/1190 [00:00<00:00, 474540.95it/s]
05/09/2022 18:34:18 - INFO - __main__ -   Saving features into cached file ./cached_xquad.es.json_xlm_LR1e-5_EPOCH2.0_maxlen384_batchsize8_gradacc2_384_es
05/09/2022 18:34:20 - INFO - __main__ -   ***** Running evaluation  *****
05/09/2022 18:34:20 - INFO - __main__ -     Num examples = 1304
05/09/2022 18:34:20 - INFO - __main__ -     Batch size = 8
Evaluating:   0%|          | 0/163 [00:00<?, ?it/s]Evaluating:   1%|          | 1/163 [00:00<01:20,  2.01it/s]Evaluating:   2%|▏         | 3/163 [00:00<00:29,  5.51it/s]Evaluating:   3%|▎         | 5/163 [00:00<00:19,  8.19it/s]Evaluating:   4%|▍         | 7/163 [00:00<00:15, 10.26it/s]Evaluating:   6%|▌         | 9/163 [00:01<00:13, 11.77it/s]Evaluating:   7%|▋         | 11/163 [00:01<00:11, 12.87it/s]Evaluating:   8%|▊         | 13/163 [00:01<00:11, 13.59it/s]Evaluating:   9%|▉         | 15/163 [00:01<00:10, 14.17it/s]Evaluating:  10%|█         | 17/163 [00:01<00:10, 14.55it/s]Evaluating:  12%|█▏        | 19/163 [00:01<00:09, 14.75it/s]Evaluating:  13%|█▎        | 21/163 [00:01<00:09, 14.95it/s]Evaluating:  14%|█▍        | 23/163 [00:01<00:09, 15.18it/s]Evaluating:  15%|█▌        | 25/163 [00:02<00:09, 15.28it/s]Evaluating:  17%|█▋        | 27/163 [00:02<00:08, 15.34it/s]Evaluating:  18%|█▊        | 29/163 [00:02<00:08, 15.32it/s]Evaluating:  19%|█▉        | 31/163 [00:02<00:08, 15.40it/s]Evaluating:  20%|██        | 33/163 [00:02<00:08, 15.41it/s]Evaluating:  21%|██▏       | 35/163 [00:02<00:08, 15.51it/s]Evaluating:  23%|██▎       | 37/163 [00:02<00:08, 15.41it/s]Evaluating:  24%|██▍       | 39/163 [00:02<00:08, 15.40it/s]Evaluating:  25%|██▌       | 41/163 [00:03<00:07, 15.37it/s]Evaluating:  26%|██▋       | 43/163 [00:03<00:07, 15.40it/s]Evaluating:  28%|██▊       | 45/163 [00:03<00:07, 15.43it/s]Evaluating:  29%|██▉       | 47/163 [00:03<00:07, 15.44it/s]Evaluating:  30%|███       | 49/163 [00:03<00:07, 15.40it/s]Evaluating:  31%|███▏      | 51/163 [00:03<00:07, 15.39it/s]Evaluating:  33%|███▎      | 53/163 [00:03<00:07, 15.38it/s]Evaluating:  34%|███▎      | 55/163 [00:04<00:07, 15.38it/s]Evaluating:  35%|███▍      | 57/163 [00:04<00:06, 15.39it/s]Evaluating:  36%|███▌      | 59/163 [00:04<00:06, 15.33it/s]Evaluating:  37%|███▋      | 61/163 [00:04<00:06, 15.27it/s]Evaluating:  39%|███▊      | 63/163 [00:04<00:06, 15.26it/s]Evaluating:  40%|███▉      | 65/163 [00:04<00:06, 15.24it/s]Evaluating:  41%|████      | 67/163 [00:04<00:06, 15.27it/s]Evaluating:  42%|████▏     | 69/163 [00:04<00:06, 15.20it/s]Evaluating:  44%|████▎     | 71/163 [00:05<00:06, 15.24it/s]Evaluating:  45%|████▍     | 73/163 [00:05<00:05, 15.33it/s]Evaluating:  46%|████▌     | 75/163 [00:05<00:05, 15.33it/s]Evaluating:  47%|████▋     | 77/163 [00:05<00:05, 15.39it/s]Evaluating:  48%|████▊     | 79/163 [00:05<00:05, 15.39it/s]Evaluating:  50%|████▉     | 81/163 [00:05<00:05, 15.37it/s]Evaluating:  51%|█████     | 83/163 [00:05<00:05, 15.33it/s]Evaluating:  52%|█████▏    | 85/163 [00:05<00:05, 15.38it/s]Evaluating:  53%|█████▎    | 87/163 [00:06<00:04, 15.40it/s]Evaluating:  55%|█████▍    | 89/163 [00:06<00:04, 15.34it/s]Evaluating:  56%|█████▌    | 91/163 [00:06<00:04, 15.28it/s]Evaluating:  57%|█████▋    | 93/163 [00:06<00:04, 15.32it/s]Evaluating:  58%|█████▊    | 95/163 [00:06<00:04, 15.38it/s]Evaluating:  60%|█████▉    | 97/163 [00:06<00:04, 15.39it/s]Evaluating:  61%|██████    | 99/163 [00:06<00:04, 15.30it/s]Evaluating:  62%|██████▏   | 101/163 [00:07<00:04, 15.31it/s]Evaluating:  63%|██████▎   | 103/163 [00:07<00:03, 15.37it/s]Evaluating:  64%|██████▍   | 105/163 [00:07<00:03, 15.26it/s]Evaluating:  66%|██████▌   | 107/163 [00:07<00:03, 15.27it/s]Evaluating:  67%|██████▋   | 109/163 [00:07<00:03, 15.34it/s]Evaluating:  68%|██████▊   | 111/163 [00:07<00:03, 15.41it/s]Evaluating:  69%|██████▉   | 113/163 [00:07<00:03, 14.89it/s]Evaluating:  71%|███████   | 115/163 [00:07<00:03, 15.08it/s]Evaluating:  72%|███████▏  | 117/163 [00:08<00:03, 15.20it/s]Evaluating:  73%|███████▎  | 119/163 [00:08<00:02, 15.24it/s]Evaluating:  74%|███████▍  | 121/163 [00:08<00:02, 15.32it/s]Evaluating:  75%|███████▌  | 123/163 [00:08<00:02, 15.36it/s]Evaluating:  77%|███████▋  | 125/163 [00:08<00:02, 15.32it/s]Evaluating:  78%|███████▊  | 127/163 [00:08<00:02, 15.22it/s]Evaluating:  79%|███████▉  | 129/163 [00:09<00:03,  9.29it/s]Evaluating:  80%|████████  | 131/163 [00:09<00:03, 10.51it/s]Evaluating:  82%|████████▏ | 133/163 [00:09<00:02, 11.59it/s]Evaluating:  83%|████████▎ | 135/163 [00:09<00:02, 12.54it/s]Evaluating:  84%|████████▍ | 137/163 [00:09<00:01, 13.33it/s]Evaluating:  85%|████████▌ | 139/163 [00:09<00:01, 13.91it/s]Evaluating:  87%|████████▋ | 141/163 [00:09<00:01, 14.31it/s]Evaluating:  88%|████████▊ | 143/163 [00:10<00:01, 14.65it/s]Evaluating:  89%|████████▉ | 145/163 [00:10<00:01, 14.91it/s]Evaluating:  90%|█████████ | 147/163 [00:10<00:01, 15.05it/s]Evaluating:  91%|█████████▏| 149/163 [00:10<00:00, 15.13it/s]Evaluating:  93%|█████████▎| 151/163 [00:10<00:00, 15.22it/s]Evaluating:  94%|█████████▍| 153/163 [00:10<00:00, 15.28it/s]Evaluating:  95%|█████████▌| 155/163 [00:10<00:00, 15.24it/s]Evaluating:  96%|█████████▋| 157/163 [00:10<00:00, 15.21it/s]Evaluating:  98%|█████████▊| 159/163 [00:11<00:00, 15.29it/s]Evaluating:  99%|█████████▉| 161/163 [00:11<00:00, 15.33it/s]Evaluating: 100%|██████████| 163/163 [00:11<00:00, 15.33it/s]Evaluating: 100%|██████████| 163/163 [00:11<00:00, 14.37it/s]
05/09/2022 18:34:31 - INFO - __main__ -     Evaluation done in total 11.341764 secs (0.008698 sec per example)
05/09/2022 18:34:35 - INFO - __main__ -   Results: {'exact': 57.226890756302524, 'f1': 75.13171646988019, 'total': 1190, 'HasAns_exact': 57.226890756302524, 'HasAns_f1': 75.13171646988019, 'HasAns_total': 1190, 'best_exact': 57.226890756302524, 'best_exact_thresh': 0.0, 'best_f1': 75.13171646988019, 'best_f1_thresh': 0.0}
  de 
2022-05-09 18:34:37.898890: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0
05/09/2022 18:34:40 - WARNING - __main__ -   Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, 16-bits training: False
You are using a model of type xlm-roberta to instantiate a model of type xlm. This is not supported for all configurations of models and can yield errors.
Some weights of the model checkpoint at /cluster/home/yifhou/scratch_yifan/qa/xtreme_xlm/outputs-adapter//squad/xlm_LR1e-5_EPOCH2.0_maxlen384_batchsize8_gradacc2 were not used when initializing XLMRobertaModel: ['base_model.encoder.layer.6.output.LayerNorm.weight', 'base_model.encoder.layer.5.output.LayerNorm.bias', 'base_model.encoder.layer.9.attention.output.dense.weight', 'base_model.encoder.layer.1.output.LayerNorm.bias', 'base_model.encoder.layer.3.intermediate.dense.bias', 'base_model.encoder.layer.7.intermediate.dense.weight', 'base_model.encoder.layer.2.attention.self.query.weight', 'base_model.encoder.layer.7.output.dense.weight', 'base_model.encoder.layer.5.intermediate.dense.weight', 'base_model.encoder.layer.10.attention.output.LayerNorm.bias', 'base_model.encoder.layer.0.attention.self.value.bias', 'base_model.encoder.layer.7.attention.output.dense.bias', 'base_model.encoder.layer.11.attention.self.query.bias', 'base_model.encoder.layer.1.attention.self.value.bias', 'base_model.encoder.layer.11.attention.self.key.bias', 'base_model.encoder.layer.11.attention.output.LayerNorm.weight', 'base_model.encoder.layer.2.attention.self.value.weight', 'base_model.encoder.layer.0.attention.output.dense.bias', 'base_model.encoder.layer.2.attention.self.key.weight', 'base_model.encoder.layer.5.attention.self.query.bias', 'base_model.encoder.layer.8.attention.output.LayerNorm.weight', 'base_model.encoder.layer.11.intermediate.dense.weight', 'base_model.encoder.layer.8.attention.self.query.bias', 'base_model.encoder.layer.11.attention.output.dense.bias', 'base_model.encoder.layer.2.output.dense.weight', 'base_model.encoder.layer.8.attention.self.value.weight', 'base_model.encoder.layer.3.attention.self.query.weight', 'base_model.encoder.layer.0.attention.self.query.bias', 'base_model.encoder.layer.4.attention.output.dense.bias', 'base_model.encoder.layer.11.output.LayerNorm.weight', 'base_model.encoder.layer.10.intermediate.dense.weight', 'base_model.encoder.layer.7.attention.self.query.bias', 'base_model.encoder.layer.0.output.LayerNorm.weight', 'base_model.encoder.layer.10.attention.self.value.weight', 'base_model.encoder.layer.8.attention.output.dense.bias', 'base_model.encoder.layer.4.attention.output.LayerNorm.bias', 'base_model.encoder.layer.2.attention.self.value.bias', 'base_model.encoder.layer.10.attention.output.dense.bias', 'base_model.encoder.layer.7.attention.self.query.weight', 'base_model.encoder.layer.8.attention.output.LayerNorm.bias', 'base_model.encoder.layer.8.attention.self.value.bias', 'base_model.encoder.layer.4.attention.self.key.weight', 'base_model.encoder.layer.1.attention.self.key.weight', 'base_model.encoder.layer.9.attention.self.query.weight', 'base_model.encoder.layer.10.output.dense.bias', 'base_model.encoder.layer.11.attention.self.query.weight', 'base_model.encoder.layer.6.attention.self.key.bias', 'base_model.encoder.layer.11.attention.self.key.weight', 'base_model.encoder.layer.8.output.LayerNorm.bias', 'base_model.encoder.layer.9.attention.output.LayerNorm.bias', 'base_model.encoder.layer.2.attention.self.query.bias', 'base_model.encoder.layer.3.output.LayerNorm.bias', 'base_model.encoder.layer.0.output.dense.weight', 'base_model.pooler.dense.weight', 'base_model.encoder.layer.10.output.dense.weight', 'base_model.encoder.layer.4.attention.output.dense.weight', 'base_model.encoder.layer.6.intermediate.dense.bias', 'base_model.encoder.layer.6.attention.self.query.weight', 'base_model.encoder.layer.1.intermediate.dense.bias', 'base_model.encoder.layer.11.output.dense.bias', 'base_model.encoder.layer.7.output.LayerNorm.bias', 'base_model.encoder.layer.11.attention.self.value.bias', 'base_model.encoder.layer.3.attention.output.LayerNorm.weight', 'base_model.encoder.layer.11.output.LayerNorm.bias', 'base_model.encoder.layer.3.output.dense.weight', 'base_model.encoder.layer.2.output.LayerNorm.bias', 'base_model.encoder.layer.2.attention.output.LayerNorm.bias', 'base_model.encoder.layer.3.attention.output.LayerNorm.bias', 'base_model.encoder.layer.0.attention.output.LayerNorm.bias', 'base_model.encoder.layer.10.attention.output.dense.weight', 'base_model.encoder.layer.0.intermediate.dense.bias', 'base_model.encoder.layer.9.attention.self.value.weight', 'base_model.encoder.layer.3.intermediate.dense.weight', 'base_model.encoder.layer.5.output.dense.bias', 'base_model.encoder.layer.5.output.LayerNorm.weight', 'base_model.encoder.layer.5.attention.self.query.weight', 'base_model.encoder.layer.9.intermediate.dense.weight', 'base_model.encoder.layer.3.attention.output.dense.weight', 'base_model.encoder.layer.0.attention.output.LayerNorm.weight', 'base_model.encoder.layer.4.attention.self.value.bias', 'base_model.encoder.layer.2.attention.self.key.bias', 'base_model.encoder.layer.3.attention.output.dense.bias', 'base_model.encoder.layer.5.intermediate.dense.bias', 'base_model.encoder.layer.11.attention.output.dense.weight', 'base_model.encoder.layer.6.attention.output.LayerNorm.bias', 'base_model.encoder.layer.8.intermediate.dense.bias', 'base_model.encoder.layer.4.attention.self.query.weight', 'base_model.encoder.layer.7.attention.output.LayerNorm.bias', 'base_model.encoder.layer.6.attention.output.dense.bias', 'base_model.encoder.layer.7.output.dense.bias', 'base_model.encoder.layer.4.attention.self.query.bias', 'base_model.encoder.layer.0.output.dense.bias', 'base_model.encoder.layer.3.attention.self.query.bias', 'base_model.encoder.layer.6.output.LayerNorm.bias', 'base_model.embeddings.word_embeddings.weight', 'base_model.encoder.layer.1.attention.output.dense.weight', 'base_model.encoder.layer.5.output.dense.weight', 'base_model.encoder.layer.1.attention.output.dense.bias', 'base_model.encoder.layer.2.output.dense.bias', 'base_model.encoder.layer.5.attention.self.key.bias', 'base_model.encoder.layer.2.attention.output.LayerNorm.weight', 'base_model.encoder.layer.9.attention.self.query.bias', 'base_model.encoder.layer.10.output.LayerNorm.weight', 'base_model.encoder.layer.6.output.dense.weight', 'base_model.encoder.layer.10.intermediate.dense.bias', 'base_model.encoder.layer.11.intermediate.dense.bias', 'base_model.encoder.layer.4.output.LayerNorm.weight', 'base_model.embeddings.LayerNorm.weight', 'base_model.encoder.layer.1.output.dense.weight', 'base_model.encoder.layer.2.intermediate.dense.bias', 'base_model.encoder.layer.9.intermediate.dense.bias', 'base_model.encoder.layer.10.output.LayerNorm.bias', 'base_model.encoder.layer.10.attention.self.value.bias', 'base_model.encoder.layer.7.attention.output.LayerNorm.weight', 'base_model.encoder.layer.9.output.LayerNorm.weight', 'base_model.encoder.layer.2.attention.output.dense.weight', 'base_model.encoder.layer.10.attention.self.key.bias', 'base_model.encoder.layer.8.output.dense.bias', 'base_model.encoder.layer.11.output.dense.weight', 'base_model.encoder.layer.9.output.dense.weight', 'base_model.encoder.layer.7.output.LayerNorm.weight', 'base_model.encoder.layer.2.intermediate.dense.weight', 'base_model.encoder.layer.11.attention.self.value.weight', 'base_model.encoder.layer.4.attention.self.key.bias', 'base_model.encoder.layer.7.attention.self.value.weight', 'base_model.encoder.layer.2.attention.output.dense.bias', 'base_model.encoder.layer.4.attention.output.LayerNorm.weight', 'base_model.encoder.layer.0.attention.self.value.weight', 'base_model.encoder.layer.1.intermediate.dense.weight', 'base_model.encoder.layer.8.output.LayerNorm.weight', 'base_model.encoder.layer.1.attention.output.LayerNorm.bias', 'base_model.encoder.layer.5.attention.self.value.weight', 'base_model.encoder.layer.6.attention.self.query.bias', 'base_model.encoder.layer.9.attention.self.key.weight', 'base_model.encoder.layer.11.attention.output.LayerNorm.bias', 'base_model.encoder.layer.6.attention.output.LayerNorm.weight', 'base_model.encoder.layer.8.attention.self.key.bias', 'base_model.encoder.layer.6.attention.self.key.weight', 'base_model.encoder.layer.10.attention.output.LayerNorm.weight', 'base_model.encoder.layer.0.attention.output.dense.weight', 'base_model.embeddings.position_embeddings.weight', 'base_model.encoder.layer.0.attention.self.key.weight', 'base_model.encoder.layer.9.attention.output.LayerNorm.weight', 'base_model.encoder.layer.2.output.LayerNorm.weight', 'base_model.encoder.layer.10.attention.self.query.bias', 'base_model.encoder.layer.5.attention.output.LayerNorm.bias', 'base_model.encoder.layer.8.attention.output.dense.weight', 'base_model.encoder.layer.3.attention.self.value.bias', 'base_model.encoder.layer.6.attention.self.value.weight', 'base_model.encoder.layer.6.attention.self.value.bias', 'base_model.encoder.layer.4.intermediate.dense.weight', 'base_model.encoder.layer.3.output.LayerNorm.weight', 'base_model.encoder.layer.0.output.LayerNorm.bias', 'base_model.pooler.dense.bias', 'base_model.encoder.layer.9.attention.self.value.bias', 'base_model.encoder.layer.9.attention.output.dense.bias', 'base_model.embeddings.LayerNorm.bias', 'base_model.encoder.layer.7.attention.self.key.bias', 'base_model.encoder.layer.5.attention.output.dense.weight', 'base_model.encoder.layer.1.attention.self.query.weight', 'base_model.encoder.layer.10.attention.self.key.weight', 'qa_outputs.weight', 'base_model.encoder.layer.7.attention.self.value.bias', 'qa_outputs.bias', 'base_model.encoder.layer.1.attention.output.LayerNorm.weight', 'base_model.encoder.layer.8.attention.self.key.weight', 'base_model.encoder.layer.1.output.dense.bias', 'base_model.embeddings.token_type_embeddings.weight', 'base_model.encoder.layer.4.output.dense.bias', 'base_model.encoder.layer.1.attention.self.value.weight', 'base_model.encoder.layer.3.output.dense.bias', 'base_model.encoder.layer.9.output.dense.bias', 'base_model.encoder.layer.7.attention.output.dense.weight', 'base_model.embeddings.position_ids', 'base_model.encoder.layer.1.output.LayerNorm.weight', 'base_model.encoder.layer.4.attention.self.value.weight', 'base_model.encoder.layer.6.attention.output.dense.weight', 'base_model.encoder.layer.4.intermediate.dense.bias', 'base_model.encoder.layer.1.attention.self.query.bias', 'base_model.encoder.layer.7.attention.self.key.weight', 'base_model.encoder.layer.5.attention.output.dense.bias', 'base_model.encoder.layer.9.attention.self.key.bias', 'base_model.encoder.layer.3.attention.self.key.weight', 'base_model.encoder.layer.6.intermediate.dense.weight', 'base_model.encoder.layer.8.intermediate.dense.weight', 'base_model.encoder.layer.4.output.LayerNorm.bias', 'base_model.encoder.layer.5.attention.output.LayerNorm.weight', 'base_model.encoder.layer.0.attention.self.key.bias', 'base_model.encoder.layer.8.output.dense.weight', 'base_model.encoder.layer.4.output.dense.weight', 'base_model.encoder.layer.8.attention.self.query.weight', 'base_model.encoder.layer.3.attention.self.key.bias', 'base_model.encoder.layer.0.attention.self.query.weight', 'base_model.encoder.layer.5.attention.self.key.weight', 'base_model.encoder.layer.9.output.LayerNorm.bias', 'base_model.encoder.layer.7.intermediate.dense.bias', 'base_model.encoder.layer.6.output.dense.bias', 'base_model.encoder.layer.1.attention.self.key.bias', 'base_model.encoder.layer.0.intermediate.dense.weight', 'base_model.encoder.layer.5.attention.self.value.bias', 'base_model.encoder.layer.3.attention.self.value.weight', 'base_model.encoder.layer.10.attention.self.query.weight']
- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of XLMRobertaModel were not initialized from the model checkpoint at /cluster/home/yifhou/scratch_yifan/qa/xtreme_xlm/outputs-adapter//squad/xlm_LR1e-5_EPOCH2.0_maxlen384_batchsize8_gradacc2 and are newly initialized: ['encoder.layer.0.attention.self.query.weight', 'encoder.layer.1.attention.output.LayerNorm.weight', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.10.attention.self.query.bias', 'encoder.layer.1.attention.self.value.bias', 'encoder.layer.10.attention.output.dense.bias', 'encoder.layer.8.output.dense.weight', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.5.attention.output.dense.bias', 'encoder.layer.7.attention.self.query.weight', 'pooler.dense.weight', 'encoder.layer.0.attention.self.value.bias', 'encoder.layer.7.attention.self.value.bias', 'encoder.layer.8.attention.self.value.weight', 'encoder.layer.0.attention.output.dense.weight', 'encoder.layer.2.attention.self.key.bias', 'encoder.layer.7.attention.output.LayerNorm.bias', 'encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.layer.9.attention.output.dense.weight', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.10.attention.self.query.weight', 'encoder.layer.6.output.dense.bias', 'encoder.layer.3.attention.self.key.bias', 'encoder.layer.9.output.LayerNorm.weight', 'encoder.layer.11.output.dense.weight', 'encoder.layer.11.output.LayerNorm.weight', 'encoder.layer.9.attention.self.value.bias', 'encoder.layer.9.intermediate.dense.bias', 'embeddings.LayerNorm.weight', 'encoder.layer.0.output.dense.bias', 'embeddings.token_type_embeddings.weight', 'encoder.layer.8.output.LayerNorm.weight', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.4.attention.self.key.weight', 'encoder.layer.5.attention.self.value.bias', 'encoder.layer.0.attention.self.value.weight', 'encoder.layer.6.attention.self.value.bias', 'encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.layer.11.attention.output.dense.weight', 'encoder.layer.9.attention.output.dense.bias', 'encoder.layer.11.attention.self.key.weight', 'encoder.layer.8.attention.output.LayerNorm.bias', 'encoder.layer.10.attention.output.LayerNorm.weight', 'encoder.layer.7.attention.self.key.bias', 'encoder.layer.9.attention.output.LayerNorm.bias', 'encoder.layer.2.attention.self.value.bias', 'encoder.layer.11.attention.self.value.weight', 'encoder.layer.6.attention.output.LayerNorm.bias', 'encoder.layer.1.attention.self.key.bias', 'encoder.layer.4.attention.output.dense.weight', 'encoder.layer.7.attention.output.LayerNorm.weight', 'encoder.layer.7.attention.self.value.weight', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.9.attention.self.query.weight', 'encoder.layer.2.attention.self.query.bias', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.3.attention.self.query.weight', 'encoder.layer.1.attention.self.key.weight', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.7.intermediate.dense.bias', 'encoder.layer.11.attention.self.key.bias', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.10.attention.output.LayerNorm.bias', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.7.attention.self.key.weight', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.9.attention.self.query.bias', 'encoder.layer.10.attention.self.key.weight', 'encoder.layer.3.output.dense.weight', 'encoder.layer.6.output.LayerNorm.weight', 'embeddings.position_embeddings.weight', 'encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.layer.5.output.LayerNorm.bias', 'encoder.layer.5.attention.self.value.weight', 'encoder.layer.6.output.dense.weight', 'encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.layer.10.attention.self.key.bias', 'encoder.layer.9.output.dense.weight', 'encoder.layer.4.attention.self.query.bias', 'encoder.layer.5.attention.output.LayerNorm.weight', 'encoder.layer.8.attention.output.dense.weight', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.0.attention.output.LayerNorm.weight', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.6.attention.self.key.bias', 'encoder.layer.4.attention.output.dense.bias', 'encoder.layer.11.output.dense.bias', 'pooler.dense.bias', 'encoder.layer.9.attention.self.value.weight', 'encoder.layer.6.attention.self.key.weight', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.4.attention.output.LayerNorm.bias', 'encoder.layer.9.output.dense.bias', 'encoder.layer.10.attention.self.value.bias', 'encoder.layer.11.attention.self.query.weight', 'encoder.layer.3.attention.output.dense.bias', 'encoder.layer.6.output.LayerNorm.bias', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.1.attention.self.value.weight', 'encoder.layer.5.output.dense.bias', 'encoder.layer.5.attention.output.dense.weight', 'encoder.layer.6.attention.self.value.weight', 'encoder.layer.9.attention.self.key.bias', 'encoder.layer.2.attention.output.dense.bias', 'encoder.layer.2.attention.output.LayerNorm.weight', 'encoder.layer.3.attention.self.value.bias', 'encoder.layer.8.attention.self.key.weight', 'encoder.layer.1.output.dense.weight', 'encoder.layer.3.attention.output.dense.weight', 'encoder.layer.5.attention.self.key.bias', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.10.output.dense.weight', 'encoder.layer.9.output.LayerNorm.bias', 'encoder.layer.11.attention.output.LayerNorm.weight', 'encoder.layer.5.output.dense.weight', 'encoder.layer.7.attention.output.dense.weight', 'encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.layer.0.attention.self.key.bias', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.4.attention.self.value.weight', 'encoder.layer.7.output.LayerNorm.bias', 'encoder.layer.9.attention.self.key.weight', 'encoder.layer.2.attention.output.LayerNorm.bias', 'encoder.layer.7.output.dense.bias', 'encoder.layer.1.attention.self.query.bias', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.11.attention.output.dense.bias', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.4.attention.self.key.bias', 'encoder.layer.8.attention.self.query.bias', 'encoder.layer.1.attention.output.dense.weight', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.11.attention.self.query.bias', 'encoder.layer.10.output.LayerNorm.weight', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.8.attention.output.dense.bias', 'encoder.layer.2.attention.self.query.weight', 'encoder.layer.4.output.dense.bias', 'encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.layer.0.output.dense.weight', 'encoder.layer.3.attention.self.query.bias', 'encoder.layer.8.attention.output.LayerNorm.weight', 'encoder.layer.4.attention.self.value.bias', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.5.attention.self.query.bias', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.8.attention.self.key.bias', 'encoder.layer.7.attention.self.query.bias', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.8.attention.self.query.weight', 'encoder.layer.3.attention.self.value.weight', 'encoder.layer.4.attention.self.query.weight', 'encoder.layer.8.output.LayerNorm.bias', 'encoder.layer.2.attention.output.dense.weight', 'encoder.layer.10.attention.output.dense.weight', 'encoder.layer.2.output.dense.weight', 'encoder.layer.6.attention.output.dense.weight', 'encoder.layer.3.attention.self.key.weight', 'encoder.layer.3.output.dense.bias', 'encoder.layer.8.output.dense.bias', 'encoder.layer.10.output.LayerNorm.bias', 'encoder.layer.0.attention.self.query.bias', 'encoder.layer.2.attention.self.key.weight', 'encoder.layer.5.attention.self.query.weight', 'encoder.layer.11.attention.self.value.bias', 'encoder.layer.10.intermediate.dense.weight', 'encoder.layer.1.attention.self.query.weight', 'encoder.layer.6.attention.output.LayerNorm.weight', 'encoder.layer.10.attention.self.value.weight', 'embeddings.word_embeddings.weight', 'encoder.layer.7.attention.output.dense.bias', 'encoder.layer.9.attention.output.LayerNorm.weight', 'encoder.layer.1.attention.output.dense.bias', 'encoder.layer.6.attention.self.query.weight', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.7.output.dense.weight', 'encoder.layer.2.attention.self.value.weight', 'encoder.layer.0.attention.self.key.weight', 'encoder.layer.1.output.dense.bias', 'encoder.layer.6.attention.self.query.bias', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.7.output.LayerNorm.weight', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.2.output.dense.bias', 'encoder.layer.0.attention.output.dense.bias', 'encoder.layer.4.attention.output.LayerNorm.weight', 'encoder.layer.8.attention.self.value.bias', 'encoder.layer.10.output.dense.bias', 'encoder.layer.5.attention.self.key.weight', 'embeddings.LayerNorm.bias', 'encoder.layer.11.output.LayerNorm.bias', 'encoder.layer.6.attention.output.dense.bias', 'encoder.layer.4.output.dense.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
05/09/2022 18:34:46 - INFO - __main__ -   lang2id = None
05/09/2022 18:34:50 - INFO - __main__ -   Training/evaluation parameters Namespace(adam_epsilon=1e-08, cache_dir='', config_name='', data_dir=None, device=device(type='cuda'), do_eval=True, do_lower_case=False, do_train=False, doc_stride=128, eval_all_checkpoints=False, eval_lang='de', evaluate_during_training=False, fp16=False, fp16_opt_level='O1', gradient_accumulation_steps=1, learning_rate=5e-05, local_rank=-1, logging_steps=50, max_answer_length=30, max_grad_norm=1.0, max_query_length=64, max_seq_length=384, max_steps=-1, model_name='xlm-KG', model_name_or_path='/cluster/home/yifhou/scratch_yifan/qa/xtreme_xlm/outputs-adapter//squad/xlm_LR1e-5_EPOCH2.0_maxlen384_batchsize8_gradacc2', model_type='xlm', modelkg_dir='/cluster/home/yifhou/scratch_yifan/qa/xtreme_xlm/adapter/xlm_adapter', n_best_size=20, n_gpu=1, no_cuda=False, null_score_diff_threshold=0.0, num_train_epochs=3.0, output_dir='/cluster/home/yifhou/scratch_yifan/qa/xtreme_xlm/outputs-adapter//squad/xlm_LR1e-5_EPOCH2.0_maxlen384_batchsize8_gradacc2/predictions/xquad/', overwrite_cache=False, overwrite_output_dir=False, per_gpu_eval_batch_size=8, per_gpu_train_batch_size=8, predict_file='/cluster/home/yifhou/scratch_yifan/qa/xtreme_xlm/download//xquad//xquad.de.json', save_steps=50, seed=42, server_ip='', server_port='', threads=1, tokenizer_name='', train_file=None, train_lang='en', verbose_logging=False, version_2_with_negative=False, warmup_steps=0, weight_decay=0.0)
05/09/2022 18:34:50 - INFO - __main__ -   Loading checkpoint /cluster/home/yifhou/scratch_yifan/qa/xtreme_xlm/outputs-adapter//squad/xlm_LR1e-5_EPOCH2.0_maxlen384_batchsize8_gradacc2 for evaluation
05/09/2022 18:34:50 - INFO - __main__ -   Evaluate the following checkpoints: ['/cluster/home/yifhou/scratch_yifan/qa/xtreme_xlm/outputs-adapter//squad/xlm_LR1e-5_EPOCH2.0_maxlen384_batchsize8_gradacc2']
Some weights of the model checkpoint at /cluster/home/yifhou/scratch_yifan/qa/xtreme_xlm/outputs-adapter//squad/xlm_LR1e-5_EPOCH2.0_maxlen384_batchsize8_gradacc2 were not used when initializing XLMRobertaModel: ['base_model.encoder.layer.6.output.LayerNorm.weight', 'base_model.encoder.layer.5.output.LayerNorm.bias', 'base_model.encoder.layer.9.attention.output.dense.weight', 'base_model.encoder.layer.1.output.LayerNorm.bias', 'base_model.encoder.layer.3.intermediate.dense.bias', 'base_model.encoder.layer.7.intermediate.dense.weight', 'base_model.encoder.layer.2.attention.self.query.weight', 'base_model.encoder.layer.7.output.dense.weight', 'base_model.encoder.layer.5.intermediate.dense.weight', 'base_model.encoder.layer.10.attention.output.LayerNorm.bias', 'base_model.encoder.layer.0.attention.self.value.bias', 'base_model.encoder.layer.7.attention.output.dense.bias', 'base_model.encoder.layer.11.attention.self.query.bias', 'base_model.encoder.layer.1.attention.self.value.bias', 'base_model.encoder.layer.11.attention.self.key.bias', 'base_model.encoder.layer.11.attention.output.LayerNorm.weight', 'base_model.encoder.layer.2.attention.self.value.weight', 'base_model.encoder.layer.0.attention.output.dense.bias', 'base_model.encoder.layer.2.attention.self.key.weight', 'base_model.encoder.layer.5.attention.self.query.bias', 'base_model.encoder.layer.8.attention.output.LayerNorm.weight', 'base_model.encoder.layer.11.intermediate.dense.weight', 'base_model.encoder.layer.8.attention.self.query.bias', 'base_model.encoder.layer.11.attention.output.dense.bias', 'base_model.encoder.layer.2.output.dense.weight', 'base_model.encoder.layer.8.attention.self.value.weight', 'base_model.encoder.layer.3.attention.self.query.weight', 'base_model.encoder.layer.0.attention.self.query.bias', 'base_model.encoder.layer.4.attention.output.dense.bias', 'base_model.encoder.layer.11.output.LayerNorm.weight', 'base_model.encoder.layer.10.intermediate.dense.weight', 'base_model.encoder.layer.7.attention.self.query.bias', 'base_model.encoder.layer.0.output.LayerNorm.weight', 'base_model.encoder.layer.10.attention.self.value.weight', 'base_model.encoder.layer.8.attention.output.dense.bias', 'base_model.encoder.layer.4.attention.output.LayerNorm.bias', 'base_model.encoder.layer.2.attention.self.value.bias', 'base_model.encoder.layer.10.attention.output.dense.bias', 'base_model.encoder.layer.7.attention.self.query.weight', 'base_model.encoder.layer.8.attention.output.LayerNorm.bias', 'base_model.encoder.layer.8.attention.self.value.bias', 'base_model.encoder.layer.4.attention.self.key.weight', 'base_model.encoder.layer.1.attention.self.key.weight', 'base_model.encoder.layer.9.attention.self.query.weight', 'base_model.encoder.layer.10.output.dense.bias', 'base_model.encoder.layer.11.attention.self.query.weight', 'base_model.encoder.layer.6.attention.self.key.bias', 'base_model.encoder.layer.11.attention.self.key.weight', 'base_model.encoder.layer.8.output.LayerNorm.bias', 'base_model.encoder.layer.9.attention.output.LayerNorm.bias', 'base_model.encoder.layer.2.attention.self.query.bias', 'base_model.encoder.layer.3.output.LayerNorm.bias', 'base_model.encoder.layer.0.output.dense.weight', 'base_model.pooler.dense.weight', 'base_model.encoder.layer.10.output.dense.weight', 'base_model.encoder.layer.4.attention.output.dense.weight', 'base_model.encoder.layer.6.intermediate.dense.bias', 'base_model.encoder.layer.6.attention.self.query.weight', 'base_model.encoder.layer.1.intermediate.dense.bias', 'base_model.encoder.layer.11.output.dense.bias', 'base_model.encoder.layer.7.output.LayerNorm.bias', 'base_model.encoder.layer.11.attention.self.value.bias', 'base_model.encoder.layer.3.attention.output.LayerNorm.weight', 'base_model.encoder.layer.11.output.LayerNorm.bias', 'base_model.encoder.layer.3.output.dense.weight', 'base_model.encoder.layer.2.output.LayerNorm.bias', 'base_model.encoder.layer.2.attention.output.LayerNorm.bias', 'base_model.encoder.layer.3.attention.output.LayerNorm.bias', 'base_model.encoder.layer.0.attention.output.LayerNorm.bias', 'base_model.encoder.layer.10.attention.output.dense.weight', 'base_model.encoder.layer.0.intermediate.dense.bias', 'base_model.encoder.layer.9.attention.self.value.weight', 'base_model.encoder.layer.3.intermediate.dense.weight', 'base_model.encoder.layer.5.output.dense.bias', 'base_model.encoder.layer.5.output.LayerNorm.weight', 'base_model.encoder.layer.5.attention.self.query.weight', 'base_model.encoder.layer.9.intermediate.dense.weight', 'base_model.encoder.layer.3.attention.output.dense.weight', 'base_model.encoder.layer.0.attention.output.LayerNorm.weight', 'base_model.encoder.layer.4.attention.self.value.bias', 'base_model.encoder.layer.2.attention.self.key.bias', 'base_model.encoder.layer.3.attention.output.dense.bias', 'base_model.encoder.layer.5.intermediate.dense.bias', 'base_model.encoder.layer.11.attention.output.dense.weight', 'base_model.encoder.layer.6.attention.output.LayerNorm.bias', 'base_model.encoder.layer.8.intermediate.dense.bias', 'base_model.encoder.layer.4.attention.self.query.weight', 'base_model.encoder.layer.7.attention.output.LayerNorm.bias', 'base_model.encoder.layer.6.attention.output.dense.bias', 'base_model.encoder.layer.7.output.dense.bias', 'base_model.encoder.layer.4.attention.self.query.bias', 'base_model.encoder.layer.0.output.dense.bias', 'base_model.encoder.layer.3.attention.self.query.bias', 'base_model.encoder.layer.6.output.LayerNorm.bias', 'base_model.embeddings.word_embeddings.weight', 'base_model.encoder.layer.1.attention.output.dense.weight', 'base_model.encoder.layer.5.output.dense.weight', 'base_model.encoder.layer.1.attention.output.dense.bias', 'base_model.encoder.layer.2.output.dense.bias', 'base_model.encoder.layer.5.attention.self.key.bias', 'base_model.encoder.layer.2.attention.output.LayerNorm.weight', 'base_model.encoder.layer.9.attention.self.query.bias', 'base_model.encoder.layer.10.output.LayerNorm.weight', 'base_model.encoder.layer.6.output.dense.weight', 'base_model.encoder.layer.10.intermediate.dense.bias', 'base_model.encoder.layer.11.intermediate.dense.bias', 'base_model.encoder.layer.4.output.LayerNorm.weight', 'base_model.embeddings.LayerNorm.weight', 'base_model.encoder.layer.1.output.dense.weight', 'base_model.encoder.layer.2.intermediate.dense.bias', 'base_model.encoder.layer.9.intermediate.dense.bias', 'base_model.encoder.layer.10.output.LayerNorm.bias', 'base_model.encoder.layer.10.attention.self.value.bias', 'base_model.encoder.layer.7.attention.output.LayerNorm.weight', 'base_model.encoder.layer.9.output.LayerNorm.weight', 'base_model.encoder.layer.2.attention.output.dense.weight', 'base_model.encoder.layer.10.attention.self.key.bias', 'base_model.encoder.layer.8.output.dense.bias', 'base_model.encoder.layer.11.output.dense.weight', 'base_model.encoder.layer.9.output.dense.weight', 'base_model.encoder.layer.7.output.LayerNorm.weight', 'base_model.encoder.layer.2.intermediate.dense.weight', 'base_model.encoder.layer.11.attention.self.value.weight', 'base_model.encoder.layer.4.attention.self.key.bias', 'base_model.encoder.layer.7.attention.self.value.weight', 'base_model.encoder.layer.2.attention.output.dense.bias', 'base_model.encoder.layer.4.attention.output.LayerNorm.weight', 'base_model.encoder.layer.0.attention.self.value.weight', 'base_model.encoder.layer.1.intermediate.dense.weight', 'base_model.encoder.layer.8.output.LayerNorm.weight', 'base_model.encoder.layer.1.attention.output.LayerNorm.bias', 'base_model.encoder.layer.5.attention.self.value.weight', 'base_model.encoder.layer.6.attention.self.query.bias', 'base_model.encoder.layer.9.attention.self.key.weight', 'base_model.encoder.layer.11.attention.output.LayerNorm.bias', 'base_model.encoder.layer.6.attention.output.LayerNorm.weight', 'base_model.encoder.layer.8.attention.self.key.bias', 'base_model.encoder.layer.6.attention.self.key.weight', 'base_model.encoder.layer.10.attention.output.LayerNorm.weight', 'base_model.encoder.layer.0.attention.output.dense.weight', 'base_model.embeddings.position_embeddings.weight', 'base_model.encoder.layer.0.attention.self.key.weight', 'base_model.encoder.layer.9.attention.output.LayerNorm.weight', 'base_model.encoder.layer.2.output.LayerNorm.weight', 'base_model.encoder.layer.10.attention.self.query.bias', 'base_model.encoder.layer.5.attention.output.LayerNorm.bias', 'base_model.encoder.layer.8.attention.output.dense.weight', 'base_model.encoder.layer.3.attention.self.value.bias', 'base_model.encoder.layer.6.attention.self.value.weight', 'base_model.encoder.layer.6.attention.self.value.bias', 'base_model.encoder.layer.4.intermediate.dense.weight', 'base_model.encoder.layer.3.output.LayerNorm.weight', 'base_model.encoder.layer.0.output.LayerNorm.bias', 'base_model.pooler.dense.bias', 'base_model.encoder.layer.9.attention.self.value.bias', 'base_model.encoder.layer.9.attention.output.dense.bias', 'base_model.embeddings.LayerNorm.bias', 'base_model.encoder.layer.7.attention.self.key.bias', 'base_model.encoder.layer.5.attention.output.dense.weight', 'base_model.encoder.layer.1.attention.self.query.weight', 'base_model.encoder.layer.10.attention.self.key.weight', 'qa_outputs.weight', 'base_model.encoder.layer.7.attention.self.value.bias', 'qa_outputs.bias', 'base_model.encoder.layer.1.attention.output.LayerNorm.weight', 'base_model.encoder.layer.8.attention.self.key.weight', 'base_model.encoder.layer.1.output.dense.bias', 'base_model.embeddings.token_type_embeddings.weight', 'base_model.encoder.layer.4.output.dense.bias', 'base_model.encoder.layer.1.attention.self.value.weight', 'base_model.encoder.layer.3.output.dense.bias', 'base_model.encoder.layer.9.output.dense.bias', 'base_model.encoder.layer.7.attention.output.dense.weight', 'base_model.embeddings.position_ids', 'base_model.encoder.layer.1.output.LayerNorm.weight', 'base_model.encoder.layer.4.attention.self.value.weight', 'base_model.encoder.layer.6.attention.output.dense.weight', 'base_model.encoder.layer.4.intermediate.dense.bias', 'base_model.encoder.layer.1.attention.self.query.bias', 'base_model.encoder.layer.7.attention.self.key.weight', 'base_model.encoder.layer.5.attention.output.dense.bias', 'base_model.encoder.layer.9.attention.self.key.bias', 'base_model.encoder.layer.3.attention.self.key.weight', 'base_model.encoder.layer.6.intermediate.dense.weight', 'base_model.encoder.layer.8.intermediate.dense.weight', 'base_model.encoder.layer.4.output.LayerNorm.bias', 'base_model.encoder.layer.5.attention.output.LayerNorm.weight', 'base_model.encoder.layer.0.attention.self.key.bias', 'base_model.encoder.layer.8.output.dense.weight', 'base_model.encoder.layer.4.output.dense.weight', 'base_model.encoder.layer.8.attention.self.query.weight', 'base_model.encoder.layer.3.attention.self.key.bias', 'base_model.encoder.layer.0.attention.self.query.weight', 'base_model.encoder.layer.5.attention.self.key.weight', 'base_model.encoder.layer.9.output.LayerNorm.bias', 'base_model.encoder.layer.7.intermediate.dense.bias', 'base_model.encoder.layer.6.output.dense.bias', 'base_model.encoder.layer.1.attention.self.key.bias', 'base_model.encoder.layer.0.intermediate.dense.weight', 'base_model.encoder.layer.5.attention.self.value.bias', 'base_model.encoder.layer.3.attention.self.value.weight', 'base_model.encoder.layer.10.attention.self.query.weight']
- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of XLMRobertaModel were not initialized from the model checkpoint at /cluster/home/yifhou/scratch_yifan/qa/xtreme_xlm/outputs-adapter//squad/xlm_LR1e-5_EPOCH2.0_maxlen384_batchsize8_gradacc2 and are newly initialized: ['encoder.layer.0.attention.self.query.weight', 'encoder.layer.1.attention.output.LayerNorm.weight', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.10.attention.self.query.bias', 'encoder.layer.1.attention.self.value.bias', 'encoder.layer.10.attention.output.dense.bias', 'encoder.layer.8.output.dense.weight', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.5.attention.output.dense.bias', 'encoder.layer.7.attention.self.query.weight', 'pooler.dense.weight', 'encoder.layer.0.attention.self.value.bias', 'encoder.layer.7.attention.self.value.bias', 'encoder.layer.8.attention.self.value.weight', 'encoder.layer.0.attention.output.dense.weight', 'encoder.layer.2.attention.self.key.bias', 'encoder.layer.7.attention.output.LayerNorm.bias', 'encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.layer.9.attention.output.dense.weight', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.10.attention.self.query.weight', 'encoder.layer.6.output.dense.bias', 'encoder.layer.3.attention.self.key.bias', 'encoder.layer.9.output.LayerNorm.weight', 'encoder.layer.11.output.dense.weight', 'encoder.layer.11.output.LayerNorm.weight', 'encoder.layer.9.attention.self.value.bias', 'encoder.layer.9.intermediate.dense.bias', 'embeddings.LayerNorm.weight', 'encoder.layer.0.output.dense.bias', 'embeddings.token_type_embeddings.weight', 'encoder.layer.8.output.LayerNorm.weight', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.4.attention.self.key.weight', 'encoder.layer.5.attention.self.value.bias', 'encoder.layer.0.attention.self.value.weight', 'encoder.layer.6.attention.self.value.bias', 'encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.layer.11.attention.output.dense.weight', 'encoder.layer.9.attention.output.dense.bias', 'encoder.layer.11.attention.self.key.weight', 'encoder.layer.8.attention.output.LayerNorm.bias', 'encoder.layer.10.attention.output.LayerNorm.weight', 'encoder.layer.7.attention.self.key.bias', 'encoder.layer.9.attention.output.LayerNorm.bias', 'encoder.layer.2.attention.self.value.bias', 'encoder.layer.11.attention.self.value.weight', 'encoder.layer.6.attention.output.LayerNorm.bias', 'encoder.layer.1.attention.self.key.bias', 'encoder.layer.4.attention.output.dense.weight', 'encoder.layer.7.attention.output.LayerNorm.weight', 'encoder.layer.7.attention.self.value.weight', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.9.attention.self.query.weight', 'encoder.layer.2.attention.self.query.bias', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.3.attention.self.query.weight', 'encoder.layer.1.attention.self.key.weight', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.7.intermediate.dense.bias', 'encoder.layer.11.attention.self.key.bias', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.10.attention.output.LayerNorm.bias', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.7.attention.self.key.weight', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.9.attention.self.query.bias', 'encoder.layer.10.attention.self.key.weight', 'encoder.layer.3.output.dense.weight', 'encoder.layer.6.output.LayerNorm.weight', 'embeddings.position_embeddings.weight', 'encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.layer.5.output.LayerNorm.bias', 'encoder.layer.5.attention.self.value.weight', 'encoder.layer.6.output.dense.weight', 'encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.layer.10.attention.self.key.bias', 'encoder.layer.9.output.dense.weight', 'encoder.layer.4.attention.self.query.bias', 'encoder.layer.5.attention.output.LayerNorm.weight', 'encoder.layer.8.attention.output.dense.weight', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.0.attention.output.LayerNorm.weight', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.6.attention.self.key.bias', 'encoder.layer.4.attention.output.dense.bias', 'encoder.layer.11.output.dense.bias', 'pooler.dense.bias', 'encoder.layer.9.attention.self.value.weight', 'encoder.layer.6.attention.self.key.weight', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.4.attention.output.LayerNorm.bias', 'encoder.layer.9.output.dense.bias', 'encoder.layer.10.attention.self.value.bias', 'encoder.layer.11.attention.self.query.weight', 'encoder.layer.3.attention.output.dense.bias', 'encoder.layer.6.output.LayerNorm.bias', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.1.attention.self.value.weight', 'encoder.layer.5.output.dense.bias', 'encoder.layer.5.attention.output.dense.weight', 'encoder.layer.6.attention.self.value.weight', 'encoder.layer.9.attention.self.key.bias', 'encoder.layer.2.attention.output.dense.bias', 'encoder.layer.2.attention.output.LayerNorm.weight', 'encoder.layer.3.attention.self.value.bias', 'encoder.layer.8.attention.self.key.weight', 'encoder.layer.1.output.dense.weight', 'encoder.layer.3.attention.output.dense.weight', 'encoder.layer.5.attention.self.key.bias', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.10.output.dense.weight', 'encoder.layer.9.output.LayerNorm.bias', 'encoder.layer.11.attention.output.LayerNorm.weight', 'encoder.layer.5.output.dense.weight', 'encoder.layer.7.attention.output.dense.weight', 'encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.layer.0.attention.self.key.bias', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.4.attention.self.value.weight', 'encoder.layer.7.output.LayerNorm.bias', 'encoder.layer.9.attention.self.key.weight', 'encoder.layer.2.attention.output.LayerNorm.bias', 'encoder.layer.7.output.dense.bias', 'encoder.layer.1.attention.self.query.bias', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.11.attention.output.dense.bias', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.4.attention.self.key.bias', 'encoder.layer.8.attention.self.query.bias', 'encoder.layer.1.attention.output.dense.weight', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.11.attention.self.query.bias', 'encoder.layer.10.output.LayerNorm.weight', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.8.attention.output.dense.bias', 'encoder.layer.2.attention.self.query.weight', 'encoder.layer.4.output.dense.bias', 'encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.layer.0.output.dense.weight', 'encoder.layer.3.attention.self.query.bias', 'encoder.layer.8.attention.output.LayerNorm.weight', 'encoder.layer.4.attention.self.value.bias', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.5.attention.self.query.bias', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.8.attention.self.key.bias', 'encoder.layer.7.attention.self.query.bias', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.8.attention.self.query.weight', 'encoder.layer.3.attention.self.value.weight', 'encoder.layer.4.attention.self.query.weight', 'encoder.layer.8.output.LayerNorm.bias', 'encoder.layer.2.attention.output.dense.weight', 'encoder.layer.10.attention.output.dense.weight', 'encoder.layer.2.output.dense.weight', 'encoder.layer.6.attention.output.dense.weight', 'encoder.layer.3.attention.self.key.weight', 'encoder.layer.3.output.dense.bias', 'encoder.layer.8.output.dense.bias', 'encoder.layer.10.output.LayerNorm.bias', 'encoder.layer.0.attention.self.query.bias', 'encoder.layer.2.attention.self.key.weight', 'encoder.layer.5.attention.self.query.weight', 'encoder.layer.11.attention.self.value.bias', 'encoder.layer.10.intermediate.dense.weight', 'encoder.layer.1.attention.self.query.weight', 'encoder.layer.6.attention.output.LayerNorm.weight', 'encoder.layer.10.attention.self.value.weight', 'embeddings.word_embeddings.weight', 'encoder.layer.7.attention.output.dense.bias', 'encoder.layer.9.attention.output.LayerNorm.weight', 'encoder.layer.1.attention.output.dense.bias', 'encoder.layer.6.attention.self.query.weight', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.7.output.dense.weight', 'encoder.layer.2.attention.self.value.weight', 'encoder.layer.0.attention.self.key.weight', 'encoder.layer.1.output.dense.bias', 'encoder.layer.6.attention.self.query.bias', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.7.output.LayerNorm.weight', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.2.output.dense.bias', 'encoder.layer.0.attention.output.dense.bias', 'encoder.layer.4.attention.output.LayerNorm.weight', 'encoder.layer.8.attention.self.value.bias', 'encoder.layer.10.output.dense.bias', 'encoder.layer.5.attention.self.key.weight', 'embeddings.LayerNorm.bias', 'encoder.layer.11.output.LayerNorm.bias', 'encoder.layer.6.attention.output.dense.bias', 'encoder.layer.4.output.dense.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
05/09/2022 18:34:57 - INFO - __main__ -   Creating features from dataset file at .
/cluster/home/yifhou/scratch_yifan/qa/xtreme_xlm/outputs-adapter//squad/xlm_LR1e-5_EPOCH2.0_maxlen384_batchsize8_gradacc2
XLMConfig {
  "architectures": [
    "XLMRobertaForMaskedLM"
  ],
  "asm": false,
  "attention_dropout": 0.1,
  "attention_probs_dropout_prob": 0.1,
  "bos_index": 0,
  "bos_token_id": 0,
  "causal": false,
  "dropout": 0.1,
  "emb_dim": 768,
  "embed_init_std": 0.02209708691207961,
  "end_n_top": 5,
  "eos_index": 1,
  "eos_token_id": 2,
  "gelu_activation": true,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "init_std": 0.02,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "is_encoder": true,
  "lang_id": 0,
  "layer_norm_eps": 1e-05,
  "mask_index": 5,
  "mask_token_id": 0,
  "max_position_embeddings": 514,
  "model_type": "xlm",
  "n_heads": 12,
  "n_langs": 1,
  "n_layers": 12,
  "output_past": true,
  "pad_index": 2,
  "pad_token_id": 1,
  "sinusoidal_embeddings": false,
  "start_n_top": 5,
  "summary_activation": null,
  "summary_first_dropout": 0.1,
  "summary_proj_to_labels": true,
  "summary_type": "first",
  "summary_use_proj": true,
  "transformers_version": "4.17.0",
  "type_vocab_size": 1,
  "unk_index": 3,
  "use_lang_emb": false,
  "vocab_size": 250002
}

  0%|          | 0/48 [00:00<?, ?it/s] 27%|██▋       | 13/48 [00:00<00:00, 119.20it/s] 52%|█████▏    | 25/48 [00:00<00:00, 97.20it/s]  73%|███████▎  | 35/48 [00:00<00:00, 96.26it/s]100%|██████████| 48/48 [00:00<00:00, 106.78it/s]
convert squad examples to features:   0%|          | 0/1190 [00:00<?, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.
convert squad examples to features:   0%|          | 1/1190 [00:00<03:24,  5.81it/s]convert squad examples to features:   5%|▌         | 65/1190 [00:00<00:05, 217.42it/s]convert squad examples to features:   8%|▊         | 97/1190 [00:00<00:04, 233.35it/s]convert squad examples to features:  11%|█         | 129/1190 [00:00<00:04, 239.00it/s]convert squad examples to features:  14%|█▎        | 161/1190 [00:00<00:03, 261.01it/s]convert squad examples to features:  16%|█▌        | 193/1190 [00:00<00:03, 274.53it/s]convert squad examples to features:  19%|█▉        | 225/1190 [00:00<00:03, 264.15it/s]convert squad examples to features:  22%|██▏       | 257/1190 [00:01<00:03, 266.12it/s]convert squad examples to features:  24%|██▍       | 289/1190 [00:01<00:03, 253.02it/s]convert squad examples to features:  27%|██▋       | 321/1190 [00:01<00:03, 252.87it/s]convert squad examples to features:  30%|██▉       | 353/1190 [00:01<00:03, 266.07it/s]convert squad examples to features:  32%|███▏      | 385/1190 [00:01<00:05, 136.78it/s]convert squad examples to features:  35%|███▌      | 417/1190 [00:02<00:04, 154.63it/s]convert squad examples to features:  38%|███▊      | 449/1190 [00:02<00:04, 167.19it/s]convert squad examples to features:  40%|████      | 481/1190 [00:02<00:03, 182.81it/s]convert squad examples to features:  43%|████▎     | 513/1190 [00:02<00:03, 196.25it/s]convert squad examples to features:  46%|████▌     | 545/1190 [00:02<00:03, 179.06it/s]convert squad examples to features:  48%|████▊     | 577/1190 [00:02<00:03, 196.40it/s]convert squad examples to features:  51%|█████     | 609/1190 [00:03<00:02, 195.12it/s]convert squad examples to features:  54%|█████▍    | 641/1190 [00:03<00:02, 194.38it/s]convert squad examples to features:  57%|█████▋    | 673/1190 [00:03<00:02, 195.52it/s]convert squad examples to features:  59%|█████▉    | 705/1190 [00:03<00:02, 214.84it/s]convert squad examples to features:  62%|██████▏   | 737/1190 [00:03<00:01, 227.03it/s]convert squad examples to features:  67%|██████▋   | 801/1190 [00:03<00:01, 255.18it/s]convert squad examples to features:  70%|███████   | 833/1190 [00:03<00:01, 236.04it/s]convert squad examples to features:  73%|███████▎  | 865/1190 [00:04<00:01, 247.29it/s]convert squad examples to features:  75%|███████▌  | 897/1190 [00:04<00:01, 234.33it/s]convert squad examples to features:  78%|███████▊  | 929/1190 [00:04<00:01, 245.90it/s]convert squad examples to features:  81%|████████  | 961/1190 [00:04<00:00, 245.22it/s]convert squad examples to features:  86%|████████▌ | 1025/1190 [00:04<00:00, 270.38it/s]convert squad examples to features:  89%|████████▉ | 1057/1190 [00:04<00:00, 276.30it/s]convert squad examples to features:  92%|█████████▏| 1089/1190 [00:04<00:00, 275.80it/s]convert squad examples to features:  94%|█████████▍| 1121/1190 [00:05<00:00, 253.17it/s]convert squad examples to features:  97%|█████████▋| 1153/1190 [00:05<00:00, 233.22it/s]convert squad examples to features: 100%|██████████| 1190/1190 [00:05<00:00, 227.74it/s]/cluster/project/sachan/yifan/softwares/anaconda/anaconda3/envs/xfactr/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2272: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

add example index and unique id:   0%|          | 0/1190 [00:00<?, ?it/s]add example index and unique id: 100%|██████████| 1190/1190 [00:00<00:00, 644777.39it/s]
05/09/2022 18:35:03 - INFO - __main__ -   Saving features into cached file ./cached_xquad.de.json_xlm_LR1e-5_EPOCH2.0_maxlen384_batchsize8_gradacc2_384_de
05/09/2022 18:35:04 - INFO - __main__ -   ***** Running evaluation  *****
05/09/2022 18:35:04 - INFO - __main__ -     Num examples = 1303
05/09/2022 18:35:04 - INFO - __main__ -     Batch size = 8
Evaluating:   0%|          | 0/163 [00:00<?, ?it/s]Evaluating:   1%|          | 1/163 [00:00<01:39,  1.63it/s]Evaluating:   2%|▏         | 3/163 [00:00<00:33,  4.72it/s]Evaluating:   3%|▎         | 5/163 [00:00<00:21,  7.35it/s]Evaluating:   4%|▍         | 7/163 [00:01<00:16,  9.48it/s]Evaluating:   6%|▌         | 9/163 [00:01<00:13, 11.03it/s]Evaluating:   7%|▋         | 11/163 [00:01<00:12, 12.18it/s]Evaluating:   8%|▊         | 13/163 [00:01<00:11, 13.06it/s]Evaluating:   9%|▉         | 15/163 [00:01<00:10, 13.74it/s]Evaluating:  10%|█         | 17/163 [00:01<00:10, 14.27it/s]Evaluating:  12%|█▏        | 19/163 [00:01<00:09, 14.53it/s]Evaluating:  13%|█▎        | 21/163 [00:01<00:09, 14.73it/s]Evaluating:  14%|█▍        | 23/163 [00:02<00:09, 15.02it/s]Evaluating:  15%|█▌        | 25/163 [00:02<00:09, 15.16it/s]Evaluating:  17%|█▋        | 27/163 [00:02<00:08, 15.22it/s]Evaluating:  18%|█▊        | 29/163 [00:02<00:08, 15.36it/s]Evaluating:  19%|█▉        | 31/163 [00:02<00:08, 15.40it/s]Evaluating:  20%|██        | 33/163 [00:02<00:08, 15.37it/s]Evaluating:  21%|██▏       | 35/163 [00:02<00:08, 15.36it/s]Evaluating:  23%|██▎       | 37/163 [00:02<00:08, 15.39it/s]Evaluating:  24%|██▍       | 39/163 [00:03<00:08, 15.37it/s]Evaluating:  25%|██▌       | 41/163 [00:03<00:07, 15.40it/s]Evaluating:  26%|██▋       | 43/163 [00:03<00:07, 15.35it/s]Evaluating:  28%|██▊       | 45/163 [00:03<00:07, 15.34it/s]Evaluating:  29%|██▉       | 47/163 [00:03<00:07, 15.37it/s]Evaluating:  30%|███       | 49/163 [00:03<00:07, 15.41it/s]Evaluating:  31%|███▏      | 51/163 [00:03<00:07, 15.42it/s]Evaluating:  33%|███▎      | 53/163 [00:04<00:07, 15.22it/s]Evaluating:  34%|███▎      | 55/163 [00:04<00:07, 15.16it/s]Evaluating:  35%|███▍      | 57/163 [00:04<00:06, 15.21it/s]Evaluating:  36%|███▌      | 59/163 [00:04<00:06, 15.16it/s]Evaluating:  37%|███▋      | 61/163 [00:04<00:06, 15.23it/s]Evaluating:  39%|███▊      | 63/163 [00:04<00:06, 15.29it/s]Evaluating:  40%|███▉      | 65/163 [00:04<00:06, 15.37it/s]Evaluating:  41%|████      | 67/163 [00:04<00:06, 15.41it/s]Evaluating:  42%|████▏     | 69/163 [00:05<00:06, 15.33it/s]Evaluating:  44%|████▎     | 71/163 [00:05<00:05, 15.38it/s]Evaluating:  45%|████▍     | 73/163 [00:05<00:05, 15.39it/s]Evaluating:  46%|████▌     | 75/163 [00:05<00:05, 15.41it/s]Evaluating:  47%|████▋     | 77/163 [00:05<00:05, 15.38it/s]Evaluating:  48%|████▊     | 79/163 [00:05<00:05, 15.31it/s]Evaluating:  50%|████▉     | 81/163 [00:05<00:05, 15.27it/s]Evaluating:  51%|█████     | 83/163 [00:05<00:05, 15.26it/s]Evaluating:  52%|█████▏    | 85/163 [00:06<00:05, 15.25it/s]Evaluating:  53%|█████▎    | 87/163 [00:06<00:04, 15.30it/s]Evaluating:  55%|█████▍    | 89/163 [00:06<00:04, 15.33it/s]Evaluating:  56%|█████▌    | 91/163 [00:06<00:04, 15.35it/s]Evaluating:  57%|█████▋    | 93/163 [00:06<00:04, 15.24it/s]Evaluating:  58%|█████▊    | 95/163 [00:06<00:04, 15.20it/s]Evaluating:  60%|█████▉    | 97/163 [00:06<00:04, 15.21it/s]Evaluating:  61%|██████    | 99/163 [00:07<00:04, 15.20it/s]Evaluating:  62%|██████▏   | 101/163 [00:07<00:04, 15.24it/s]Evaluating:  63%|██████▎   | 103/163 [00:07<00:03, 15.30it/s]Evaluating:  64%|██████▍   | 105/163 [00:07<00:03, 15.28it/s]Evaluating:  66%|██████▌   | 107/163 [00:07<00:03, 15.33it/s]Evaluating:  67%|██████▋   | 109/163 [00:07<00:03, 15.38it/s]Evaluating:  68%|██████▊   | 111/163 [00:07<00:03, 15.36it/s]Evaluating:  69%|██████▉   | 113/163 [00:07<00:03, 14.82it/s]Evaluating:  71%|███████   | 115/163 [00:08<00:03, 14.87it/s]Evaluating:  72%|███████▏  | 117/163 [00:08<00:03, 14.90it/s]Evaluating:  73%|███████▎  | 119/163 [00:08<00:02, 14.94it/s]Evaluating:  74%|███████▍  | 121/163 [00:08<00:02, 14.84it/s]Evaluating:  75%|███████▌  | 123/163 [00:08<00:02, 14.92it/s]Evaluating:  77%|███████▋  | 125/163 [00:08<00:02, 15.07it/s]Evaluating:  78%|███████▊  | 127/163 [00:08<00:02, 15.11it/s]Evaluating:  79%|███████▉  | 129/163 [00:09<00:03, 10.09it/s]Evaluating:  80%|████████  | 131/163 [00:09<00:02, 11.21it/s]Evaluating:  82%|████████▏ | 133/163 [00:09<00:02, 12.19it/s]Evaluating:  83%|████████▎ | 135/163 [00:09<00:02, 13.01it/s]Evaluating:  84%|████████▍ | 137/163 [00:09<00:01, 13.60it/s]Evaluating:  85%|████████▌ | 139/163 [00:09<00:01, 14.02it/s]Evaluating:  87%|████████▋ | 141/163 [00:10<00:01, 14.41it/s]Evaluating:  88%|████████▊ | 143/163 [00:10<00:01, 14.70it/s]Evaluating:  89%|████████▉ | 145/163 [00:10<00:01, 14.90it/s]Evaluating:  90%|█████████ | 147/163 [00:10<00:01, 15.07it/s]Evaluating:  91%|█████████▏| 149/163 [00:10<00:00, 15.22it/s]Evaluating:  93%|█████████▎| 151/163 [00:10<00:00, 15.29it/s]Evaluating:  94%|█████████▍| 153/163 [00:10<00:00, 15.29it/s]Evaluating:  95%|█████████▌| 155/163 [00:10<00:00, 15.26it/s]Evaluating:  96%|█████████▋| 157/163 [00:11<00:00, 15.21it/s]Evaluating:  98%|█████████▊| 159/163 [00:11<00:00, 15.20it/s]Evaluating:  99%|█████████▉| 161/163 [00:11<00:00, 15.21it/s]Evaluating: 100%|██████████| 163/163 [00:11<00:00, 15.46it/s]Evaluating: 100%|██████████| 163/163 [00:11<00:00, 14.25it/s]
05/09/2022 18:35:16 - INFO - __main__ -     Evaluation done in total 11.441741 secs (0.008781 sec per example)
05/09/2022 18:35:20 - INFO - __main__ -   Results: {'exact': 57.73109243697479, 'f1': 73.57198471094621, 'total': 1190, 'HasAns_exact': 57.73109243697479, 'HasAns_f1': 73.57198471094621, 'HasAns_total': 1190, 'best_exact': 57.73109243697479, 'best_exact_thresh': 0.0, 'best_f1': 73.57198471094621, 'best_f1_thresh': 0.0}
  el 
2022-05-09 18:35:22.895371: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0
05/09/2022 18:35:26 - WARNING - __main__ -   Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, 16-bits training: False
You are using a model of type xlm-roberta to instantiate a model of type xlm. This is not supported for all configurations of models and can yield errors.
Some weights of the model checkpoint at /cluster/home/yifhou/scratch_yifan/qa/xtreme_xlm/outputs-adapter//squad/xlm_LR1e-5_EPOCH2.0_maxlen384_batchsize8_gradacc2 were not used when initializing XLMRobertaModel: ['base_model.encoder.layer.8.attention.output.LayerNorm.bias', 'base_model.encoder.layer.2.output.LayerNorm.bias', 'base_model.encoder.layer.8.intermediate.dense.weight', 'base_model.encoder.layer.5.output.dense.bias', 'base_model.encoder.layer.11.attention.self.query.weight', 'base_model.encoder.layer.4.output.LayerNorm.bias', 'base_model.encoder.layer.5.attention.self.value.bias', 'base_model.encoder.layer.8.attention.self.key.bias', 'base_model.encoder.layer.1.output.LayerNorm.bias', 'base_model.encoder.layer.3.attention.output.dense.weight', 'base_model.encoder.layer.0.output.dense.weight', 'base_model.encoder.layer.11.attention.output.dense.weight', 'base_model.encoder.layer.7.attention.output.LayerNorm.weight', 'base_model.encoder.layer.3.attention.output.dense.bias', 'base_model.encoder.layer.2.attention.output.dense.weight', 'base_model.encoder.layer.11.output.dense.weight', 'base_model.encoder.layer.3.attention.self.key.bias', 'base_model.encoder.layer.8.attention.self.value.weight', 'base_model.encoder.layer.6.output.dense.weight', 'base_model.encoder.layer.2.output.dense.bias', 'base_model.pooler.dense.bias', 'base_model.encoder.layer.7.output.dense.bias', 'base_model.encoder.layer.3.intermediate.dense.bias', 'base_model.encoder.layer.9.attention.output.dense.bias', 'base_model.encoder.layer.1.attention.output.dense.weight', 'base_model.embeddings.LayerNorm.bias', 'base_model.encoder.layer.4.attention.self.value.bias', 'base_model.encoder.layer.9.attention.self.value.bias', 'base_model.encoder.layer.2.attention.self.value.weight', 'base_model.encoder.layer.5.output.LayerNorm.bias', 'base_model.encoder.layer.3.attention.self.query.weight', 'base_model.encoder.layer.6.attention.output.dense.weight', 'base_model.embeddings.word_embeddings.weight', 'base_model.embeddings.LayerNorm.weight', 'base_model.encoder.layer.9.output.dense.weight', 'base_model.encoder.layer.11.attention.self.value.weight', 'base_model.encoder.layer.0.attention.self.value.bias', 'base_model.encoder.layer.7.attention.self.query.weight', 'base_model.encoder.layer.1.attention.self.value.bias', 'base_model.encoder.layer.1.attention.output.LayerNorm.bias', 'base_model.encoder.layer.5.output.dense.weight', 'base_model.encoder.layer.7.output.dense.weight', 'base_model.encoder.layer.2.attention.output.LayerNorm.bias', 'base_model.encoder.layer.7.attention.self.key.bias', 'base_model.encoder.layer.1.attention.output.dense.bias', 'base_model.encoder.layer.5.attention.self.query.bias', 'base_model.encoder.layer.5.attention.output.dense.bias', 'base_model.encoder.layer.5.attention.output.LayerNorm.bias', 'base_model.encoder.layer.9.attention.self.key.bias', 'base_model.encoder.layer.6.attention.self.query.weight', 'base_model.encoder.layer.7.attention.self.query.bias', 'base_model.encoder.layer.5.attention.self.key.weight', 'base_model.encoder.layer.11.attention.self.value.bias', 'base_model.encoder.layer.1.output.LayerNorm.weight', 'base_model.encoder.layer.7.attention.output.dense.bias', 'base_model.encoder.layer.10.attention.output.dense.bias', 'base_model.encoder.layer.3.output.LayerNorm.weight', 'base_model.encoder.layer.2.output.LayerNorm.weight', 'base_model.encoder.layer.2.attention.self.key.weight', 'base_model.encoder.layer.9.intermediate.dense.bias', 'base_model.encoder.layer.5.intermediate.dense.weight', 'base_model.encoder.layer.8.attention.output.dense.weight', 'base_model.encoder.layer.7.intermediate.dense.bias', 'base_model.encoder.layer.11.intermediate.dense.bias', 'base_model.encoder.layer.1.attention.self.value.weight', 'qa_outputs.weight', 'base_model.encoder.layer.0.attention.self.value.weight', 'base_model.encoder.layer.2.attention.output.LayerNorm.weight', 'base_model.encoder.layer.0.attention.self.query.weight', 'base_model.encoder.layer.1.attention.output.LayerNorm.weight', 'base_model.encoder.layer.1.attention.self.key.bias', 'base_model.encoder.layer.4.attention.output.dense.weight', 'base_model.encoder.layer.8.attention.self.query.weight', 'base_model.encoder.layer.1.attention.self.query.bias', 'base_model.encoder.layer.4.attention.self.query.bias', 'base_model.encoder.layer.1.intermediate.dense.weight', 'base_model.encoder.layer.8.attention.output.LayerNorm.weight', 'base_model.encoder.layer.9.output.LayerNorm.weight', 'base_model.encoder.layer.11.output.LayerNorm.weight', 'base_model.encoder.layer.1.intermediate.dense.bias', 'base_model.encoder.layer.5.attention.output.dense.weight', 'base_model.encoder.layer.6.intermediate.dense.weight', 'base_model.encoder.layer.11.attention.self.query.bias', 'base_model.encoder.layer.9.attention.self.key.weight', 'base_model.encoder.layer.0.output.dense.bias', 'base_model.encoder.layer.8.output.dense.bias', 'base_model.encoder.layer.8.attention.output.dense.bias', 'base_model.encoder.layer.4.output.dense.weight', 'base_model.encoder.layer.6.attention.self.value.weight', 'base_model.encoder.layer.0.attention.output.dense.bias', 'base_model.encoder.layer.8.attention.self.value.bias', 'base_model.encoder.layer.10.intermediate.dense.bias', 'base_model.encoder.layer.9.output.LayerNorm.bias', 'base_model.encoder.layer.4.attention.self.query.weight', 'base_model.encoder.layer.6.output.LayerNorm.weight', 'base_model.encoder.layer.7.attention.self.value.bias', 'base_model.encoder.layer.7.attention.output.LayerNorm.bias', 'base_model.encoder.layer.10.output.dense.bias', 'base_model.encoder.layer.6.attention.self.key.weight', 'base_model.encoder.layer.7.attention.output.dense.weight', 'base_model.encoder.layer.10.attention.self.query.weight', 'base_model.encoder.layer.3.attention.self.value.bias', 'base_model.encoder.layer.0.output.LayerNorm.weight', 'base_model.encoder.layer.10.attention.self.query.bias', 'base_model.encoder.layer.7.attention.self.value.weight', 'base_model.encoder.layer.10.intermediate.dense.weight', 'base_model.encoder.layer.10.output.LayerNorm.weight', 'base_model.encoder.layer.0.intermediate.dense.weight', 'base_model.encoder.layer.7.attention.self.key.weight', 'base_model.encoder.layer.9.intermediate.dense.weight', 'base_model.encoder.layer.10.output.LayerNorm.bias', 'base_model.encoder.layer.3.output.LayerNorm.bias', 'base_model.encoder.layer.0.attention.output.LayerNorm.weight', 'base_model.encoder.layer.11.attention.output.dense.bias', 'base_model.encoder.layer.10.attention.self.key.bias', 'base_model.encoder.layer.9.attention.output.LayerNorm.bias', 'base_model.encoder.layer.2.attention.self.query.weight', 'base_model.encoder.layer.8.output.LayerNorm.bias', 'base_model.encoder.layer.2.attention.output.dense.bias', 'base_model.encoder.layer.1.attention.self.key.weight', 'base_model.encoder.layer.6.output.LayerNorm.bias', 'base_model.encoder.layer.11.output.dense.bias', 'base_model.encoder.layer.4.attention.output.LayerNorm.bias', 'base_model.encoder.layer.0.intermediate.dense.bias', 'base_model.encoder.layer.9.attention.output.dense.weight', 'base_model.encoder.layer.11.output.LayerNorm.bias', 'base_model.encoder.layer.7.output.LayerNorm.weight', 'base_model.encoder.layer.6.intermediate.dense.bias', 'base_model.encoder.layer.10.attention.output.LayerNorm.weight', 'base_model.pooler.dense.weight', 'base_model.encoder.layer.3.attention.output.LayerNorm.weight', 'base_model.encoder.layer.3.attention.self.query.bias', 'base_model.encoder.layer.10.attention.self.value.bias', 'base_model.encoder.layer.11.attention.self.key.bias', 'base_model.encoder.layer.4.output.dense.bias', 'base_model.encoder.layer.0.attention.self.query.bias', 'base_model.encoder.layer.7.output.LayerNorm.bias', 'base_model.encoder.layer.4.output.LayerNorm.weight', 'base_model.encoder.layer.7.intermediate.dense.weight', 'base_model.encoder.layer.10.attention.self.key.weight', 'base_model.encoder.layer.0.attention.self.key.weight', 'base_model.encoder.layer.3.output.dense.bias', 'base_model.encoder.layer.10.output.dense.weight', 'base_model.encoder.layer.0.attention.output.LayerNorm.bias', 'base_model.encoder.layer.5.attention.self.value.weight', 'base_model.encoder.layer.9.attention.output.LayerNorm.weight', 'base_model.encoder.layer.9.attention.self.value.weight', 'base_model.encoder.layer.10.attention.output.dense.weight', 'base_model.encoder.layer.5.attention.self.query.weight', 'qa_outputs.bias', 'base_model.encoder.layer.4.intermediate.dense.bias', 'base_model.encoder.layer.5.attention.output.LayerNorm.weight', 'base_model.encoder.layer.2.attention.self.value.bias', 'base_model.encoder.layer.2.intermediate.dense.weight', 'base_model.encoder.layer.6.attention.output.LayerNorm.weight', 'base_model.encoder.layer.4.attention.output.dense.bias', 'base_model.encoder.layer.2.attention.self.key.bias', 'base_model.encoder.layer.6.output.dense.bias', 'base_model.encoder.layer.10.attention.output.LayerNorm.bias', 'base_model.encoder.layer.4.attention.self.key.bias', 'base_model.encoder.layer.8.attention.self.key.weight', 'base_model.encoder.layer.6.attention.self.query.bias', 'base_model.encoder.layer.3.output.dense.weight', 'base_model.embeddings.position_ids', 'base_model.encoder.layer.4.intermediate.dense.weight', 'base_model.embeddings.position_embeddings.weight', 'base_model.encoder.layer.8.output.dense.weight', 'base_model.encoder.layer.3.attention.self.key.weight', 'base_model.encoder.layer.11.intermediate.dense.weight', 'base_model.encoder.layer.5.intermediate.dense.bias', 'base_model.encoder.layer.10.attention.self.value.weight', 'base_model.encoder.layer.1.output.dense.weight', 'base_model.encoder.layer.3.attention.output.LayerNorm.bias', 'base_model.encoder.layer.9.attention.self.query.bias', 'base_model.encoder.layer.11.attention.output.LayerNorm.weight', 'base_model.encoder.layer.6.attention.output.dense.bias', 'base_model.encoder.layer.8.output.LayerNorm.weight', 'base_model.encoder.layer.9.attention.self.query.weight', 'base_model.encoder.layer.11.attention.self.key.weight', 'base_model.encoder.layer.4.attention.output.LayerNorm.weight', 'base_model.encoder.layer.2.intermediate.dense.bias', 'base_model.encoder.layer.1.output.dense.bias', 'base_model.encoder.layer.6.attention.self.value.bias', 'base_model.encoder.layer.1.attention.self.query.weight', 'base_model.encoder.layer.0.attention.output.dense.weight', 'base_model.encoder.layer.4.attention.self.value.weight', 'base_model.encoder.layer.8.attention.self.query.bias', 'base_model.encoder.layer.11.attention.output.LayerNorm.bias', 'base_model.encoder.layer.0.output.LayerNorm.bias', 'base_model.encoder.layer.0.attention.self.key.bias', 'base_model.encoder.layer.2.attention.self.query.bias', 'base_model.encoder.layer.3.intermediate.dense.weight', 'base_model.encoder.layer.6.attention.output.LayerNorm.bias', 'base_model.encoder.layer.9.output.dense.bias', 'base_model.encoder.layer.6.attention.self.key.bias', 'base_model.encoder.layer.5.output.LayerNorm.weight', 'base_model.encoder.layer.4.attention.self.key.weight', 'base_model.encoder.layer.3.attention.self.value.weight', 'base_model.embeddings.token_type_embeddings.weight', 'base_model.encoder.layer.8.intermediate.dense.bias', 'base_model.encoder.layer.5.attention.self.key.bias', 'base_model.encoder.layer.2.output.dense.weight']
- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of XLMRobertaModel were not initialized from the model checkpoint at /cluster/home/yifhou/scratch_yifan/qa/xtreme_xlm/outputs-adapter//squad/xlm_LR1e-5_EPOCH2.0_maxlen384_batchsize8_gradacc2 and are newly initialized: ['encoder.layer.0.attention.output.dense.weight', 'encoder.layer.9.output.LayerNorm.bias', 'encoder.layer.1.output.dense.weight', 'encoder.layer.7.output.LayerNorm.bias', 'encoder.layer.1.attention.self.query.weight', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.3.attention.self.key.weight', 'encoder.layer.10.attention.self.query.weight', 'encoder.layer.6.output.dense.weight', 'embeddings.LayerNorm.bias', 'encoder.layer.4.output.dense.weight', 'encoder.layer.9.attention.output.LayerNorm.bias', 'embeddings.word_embeddings.weight', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.2.attention.self.value.weight', 'encoder.layer.11.attention.self.key.bias', 'encoder.layer.4.attention.self.value.bias', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.9.attention.self.value.bias', 'encoder.layer.2.attention.output.LayerNorm.weight', 'pooler.dense.bias', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.11.attention.self.key.weight', 'encoder.layer.1.attention.self.query.bias', 'encoder.layer.4.attention.output.LayerNorm.bias', 'encoder.layer.9.output.dense.weight', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.10.attention.self.query.bias', 'encoder.layer.7.attention.output.LayerNorm.weight', 'encoder.layer.7.attention.self.value.weight', 'encoder.layer.4.attention.self.query.weight', 'encoder.layer.8.output.dense.weight', 'embeddings.position_embeddings.weight', 'encoder.layer.8.attention.output.LayerNorm.bias', 'encoder.layer.10.attention.self.value.bias', 'encoder.layer.11.attention.self.value.bias', 'encoder.layer.6.output.LayerNorm.bias', 'encoder.layer.10.attention.output.LayerNorm.bias', 'encoder.layer.3.attention.output.dense.weight', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.3.attention.self.value.weight', 'encoder.layer.3.output.dense.weight', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.8.attention.self.key.bias', 'encoder.layer.2.attention.self.key.weight', 'encoder.layer.7.attention.output.dense.bias', 'encoder.layer.1.attention.self.value.weight', 'encoder.layer.5.attention.self.key.bias', 'encoder.layer.1.attention.output.LayerNorm.weight', 'encoder.layer.0.attention.self.value.bias', 'encoder.layer.4.attention.self.value.weight', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.11.output.LayerNorm.weight', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.0.output.dense.weight', 'encoder.layer.4.attention.output.dense.weight', 'encoder.layer.11.attention.self.query.weight', 'encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.8.attention.self.query.weight', 'encoder.layer.0.attention.self.key.weight', 'encoder.layer.9.attention.self.query.weight', 'encoder.layer.5.attention.self.value.weight', 'encoder.layer.9.attention.self.key.weight', 'encoder.layer.7.attention.self.key.bias', 'embeddings.token_type_embeddings.weight', 'encoder.layer.0.attention.output.LayerNorm.weight', 'encoder.layer.7.output.LayerNorm.weight', 'encoder.layer.11.output.dense.weight', 'encoder.layer.2.attention.output.dense.weight', 'encoder.layer.9.output.LayerNorm.weight', 'encoder.layer.0.attention.self.query.weight', 'encoder.layer.10.output.LayerNorm.bias', 'encoder.layer.0.output.dense.bias', 'encoder.layer.3.attention.output.dense.bias', 'encoder.layer.8.attention.self.query.bias', 'encoder.layer.10.attention.output.LayerNorm.weight', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.9.attention.self.value.weight', 'encoder.layer.3.attention.self.query.weight', 'encoder.layer.8.output.LayerNorm.bias', 'encoder.layer.5.output.dense.weight', 'encoder.layer.6.attention.self.value.weight', 'encoder.layer.4.attention.self.key.bias', 'encoder.layer.6.attention.output.LayerNorm.weight', 'encoder.layer.10.output.dense.bias', 'encoder.layer.5.output.dense.bias', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.8.output.dense.bias', 'encoder.layer.3.output.dense.bias', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.9.output.dense.bias', 'encoder.layer.2.output.dense.bias', 'encoder.layer.7.intermediate.dense.bias', 'encoder.layer.4.attention.output.dense.bias', 'encoder.layer.7.attention.self.key.weight', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.6.attention.self.key.bias', 'encoder.layer.11.attention.self.query.bias', 'encoder.layer.6.output.dense.bias', 'encoder.layer.1.attention.self.key.bias', 'encoder.layer.2.attention.output.dense.bias', 'encoder.layer.6.attention.self.value.bias', 'encoder.layer.10.attention.self.key.bias', 'encoder.layer.10.attention.self.value.weight', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.11.attention.output.dense.bias', 'encoder.layer.6.attention.output.dense.weight', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.layer.5.attention.output.LayerNorm.weight', 'encoder.layer.0.attention.self.value.weight', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.3.attention.self.key.bias', 'encoder.layer.7.attention.self.query.bias', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.0.attention.self.key.bias', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.8.attention.self.value.bias', 'encoder.layer.9.attention.self.key.bias', 'encoder.layer.5.attention.self.value.bias', 'encoder.layer.1.output.dense.bias', 'encoder.layer.2.attention.output.LayerNorm.bias', 'encoder.layer.9.attention.self.query.bias', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.layer.8.attention.output.LayerNorm.weight', 'encoder.layer.1.attention.output.dense.weight', 'encoder.layer.5.attention.output.dense.weight', 'encoder.layer.10.attention.self.key.weight', 'encoder.layer.8.attention.output.dense.bias', 'encoder.layer.6.attention.self.query.weight', 'encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.4.attention.self.key.weight', 'encoder.layer.10.output.dense.weight', 'encoder.layer.5.attention.output.dense.bias', 'encoder.layer.11.attention.output.LayerNorm.weight', 'encoder.layer.11.output.dense.bias', 'encoder.layer.0.attention.self.query.bias', 'encoder.layer.1.attention.self.value.bias', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.7.attention.output.dense.weight', 'encoder.layer.10.output.LayerNorm.weight', 'encoder.layer.7.attention.output.LayerNorm.bias', 'encoder.layer.0.attention.output.dense.bias', 'encoder.layer.3.attention.self.value.bias', 'encoder.layer.8.output.LayerNorm.weight', 'embeddings.LayerNorm.weight', 'encoder.layer.7.output.dense.weight', 'encoder.layer.10.attention.output.dense.weight', 'encoder.layer.6.attention.output.dense.bias', 'encoder.layer.11.attention.output.dense.weight', 'encoder.layer.6.attention.output.LayerNorm.bias', 'encoder.layer.4.output.dense.bias', 'encoder.layer.4.attention.self.query.bias', 'encoder.layer.9.attention.output.dense.bias', 'encoder.layer.10.attention.output.dense.bias', 'encoder.layer.7.output.dense.bias', 'encoder.layer.4.attention.output.LayerNorm.weight', 'encoder.layer.6.attention.self.query.bias', 'encoder.layer.9.attention.output.LayerNorm.weight', 'encoder.layer.5.attention.self.query.weight', 'encoder.layer.7.attention.self.query.weight', 'pooler.dense.weight', 'encoder.layer.3.attention.self.query.bias', 'encoder.layer.6.attention.self.key.weight', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.10.intermediate.dense.weight', 'encoder.layer.2.attention.self.query.weight', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.7.attention.self.value.bias', 'encoder.layer.8.attention.self.value.weight', 'encoder.layer.11.attention.self.value.weight', 'encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.layer.2.attention.self.value.bias', 'encoder.layer.8.attention.output.dense.weight', 'encoder.layer.2.attention.self.key.bias', 'encoder.layer.5.output.LayerNorm.bias', 'encoder.layer.2.output.dense.weight', 'encoder.layer.5.attention.self.query.bias', 'encoder.layer.9.attention.output.dense.weight', 'encoder.layer.11.output.LayerNorm.bias', 'encoder.layer.8.attention.self.key.weight', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.1.attention.self.key.weight', 'encoder.layer.2.attention.self.query.bias', 'encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.layer.5.attention.self.key.weight', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.1.attention.output.dense.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
05/09/2022 18:35:32 - INFO - __main__ -   lang2id = None
05/09/2022 18:35:36 - INFO - __main__ -   Training/evaluation parameters Namespace(adam_epsilon=1e-08, cache_dir='', config_name='', data_dir=None, device=device(type='cuda'), do_eval=True, do_lower_case=False, do_train=False, doc_stride=128, eval_all_checkpoints=False, eval_lang='el', evaluate_during_training=False, fp16=False, fp16_opt_level='O1', gradient_accumulation_steps=1, learning_rate=5e-05, local_rank=-1, logging_steps=50, max_answer_length=30, max_grad_norm=1.0, max_query_length=64, max_seq_length=384, max_steps=-1, model_name='xlm-KG', model_name_or_path='/cluster/home/yifhou/scratch_yifan/qa/xtreme_xlm/outputs-adapter//squad/xlm_LR1e-5_EPOCH2.0_maxlen384_batchsize8_gradacc2', model_type='xlm', modelkg_dir='/cluster/home/yifhou/scratch_yifan/qa/xtreme_xlm/adapter/xlm_adapter', n_best_size=20, n_gpu=1, no_cuda=False, null_score_diff_threshold=0.0, num_train_epochs=3.0, output_dir='/cluster/home/yifhou/scratch_yifan/qa/xtreme_xlm/outputs-adapter//squad/xlm_LR1e-5_EPOCH2.0_maxlen384_batchsize8_gradacc2/predictions/xquad/', overwrite_cache=False, overwrite_output_dir=False, per_gpu_eval_batch_size=8, per_gpu_train_batch_size=8, predict_file='/cluster/home/yifhou/scratch_yifan/qa/xtreme_xlm/download//xquad//xquad.el.json', save_steps=50, seed=42, server_ip='', server_port='', threads=1, tokenizer_name='', train_file=None, train_lang='en', verbose_logging=False, version_2_with_negative=False, warmup_steps=0, weight_decay=0.0)
05/09/2022 18:35:36 - INFO - __main__ -   Loading checkpoint /cluster/home/yifhou/scratch_yifan/qa/xtreme_xlm/outputs-adapter//squad/xlm_LR1e-5_EPOCH2.0_maxlen384_batchsize8_gradacc2 for evaluation
05/09/2022 18:35:36 - INFO - __main__ -   Evaluate the following checkpoints: ['/cluster/home/yifhou/scratch_yifan/qa/xtreme_xlm/outputs-adapter//squad/xlm_LR1e-5_EPOCH2.0_maxlen384_batchsize8_gradacc2']
Some weights of the model checkpoint at /cluster/home/yifhou/scratch_yifan/qa/xtreme_xlm/outputs-adapter//squad/xlm_LR1e-5_EPOCH2.0_maxlen384_batchsize8_gradacc2 were not used when initializing XLMRobertaModel: ['base_model.encoder.layer.8.attention.output.LayerNorm.bias', 'base_model.encoder.layer.2.output.LayerNorm.bias', 'base_model.encoder.layer.8.intermediate.dense.weight', 'base_model.encoder.layer.5.output.dense.bias', 'base_model.encoder.layer.11.attention.self.query.weight', 'base_model.encoder.layer.4.output.LayerNorm.bias', 'base_model.encoder.layer.5.attention.self.value.bias', 'base_model.encoder.layer.8.attention.self.key.bias', 'base_model.encoder.layer.1.output.LayerNorm.bias', 'base_model.encoder.layer.3.attention.output.dense.weight', 'base_model.encoder.layer.0.output.dense.weight', 'base_model.encoder.layer.11.attention.output.dense.weight', 'base_model.encoder.layer.7.attention.output.LayerNorm.weight', 'base_model.encoder.layer.3.attention.output.dense.bias', 'base_model.encoder.layer.2.attention.output.dense.weight', 'base_model.encoder.layer.11.output.dense.weight', 'base_model.encoder.layer.3.attention.self.key.bias', 'base_model.encoder.layer.8.attention.self.value.weight', 'base_model.encoder.layer.6.output.dense.weight', 'base_model.encoder.layer.2.output.dense.bias', 'base_model.pooler.dense.bias', 'base_model.encoder.layer.7.output.dense.bias', 'base_model.encoder.layer.3.intermediate.dense.bias', 'base_model.encoder.layer.9.attention.output.dense.bias', 'base_model.encoder.layer.1.attention.output.dense.weight', 'base_model.embeddings.LayerNorm.bias', 'base_model.encoder.layer.4.attention.self.value.bias', 'base_model.encoder.layer.9.attention.self.value.bias', 'base_model.encoder.layer.2.attention.self.value.weight', 'base_model.encoder.layer.5.output.LayerNorm.bias', 'base_model.encoder.layer.3.attention.self.query.weight', 'base_model.encoder.layer.6.attention.output.dense.weight', 'base_model.embeddings.word_embeddings.weight', 'base_model.embeddings.LayerNorm.weight', 'base_model.encoder.layer.9.output.dense.weight', 'base_model.encoder.layer.11.attention.self.value.weight', 'base_model.encoder.layer.0.attention.self.value.bias', 'base_model.encoder.layer.7.attention.self.query.weight', 'base_model.encoder.layer.1.attention.self.value.bias', 'base_model.encoder.layer.1.attention.output.LayerNorm.bias', 'base_model.encoder.layer.5.output.dense.weight', 'base_model.encoder.layer.7.output.dense.weight', 'base_model.encoder.layer.2.attention.output.LayerNorm.bias', 'base_model.encoder.layer.7.attention.self.key.bias', 'base_model.encoder.layer.1.attention.output.dense.bias', 'base_model.encoder.layer.5.attention.self.query.bias', 'base_model.encoder.layer.5.attention.output.dense.bias', 'base_model.encoder.layer.5.attention.output.LayerNorm.bias', 'base_model.encoder.layer.9.attention.self.key.bias', 'base_model.encoder.layer.6.attention.self.query.weight', 'base_model.encoder.layer.7.attention.self.query.bias', 'base_model.encoder.layer.5.attention.self.key.weight', 'base_model.encoder.layer.11.attention.self.value.bias', 'base_model.encoder.layer.1.output.LayerNorm.weight', 'base_model.encoder.layer.7.attention.output.dense.bias', 'base_model.encoder.layer.10.attention.output.dense.bias', 'base_model.encoder.layer.3.output.LayerNorm.weight', 'base_model.encoder.layer.2.output.LayerNorm.weight', 'base_model.encoder.layer.2.attention.self.key.weight', 'base_model.encoder.layer.9.intermediate.dense.bias', 'base_model.encoder.layer.5.intermediate.dense.weight', 'base_model.encoder.layer.8.attention.output.dense.weight', 'base_model.encoder.layer.7.intermediate.dense.bias', 'base_model.encoder.layer.11.intermediate.dense.bias', 'base_model.encoder.layer.1.attention.self.value.weight', 'qa_outputs.weight', 'base_model.encoder.layer.0.attention.self.value.weight', 'base_model.encoder.layer.2.attention.output.LayerNorm.weight', 'base_model.encoder.layer.0.attention.self.query.weight', 'base_model.encoder.layer.1.attention.output.LayerNorm.weight', 'base_model.encoder.layer.1.attention.self.key.bias', 'base_model.encoder.layer.4.attention.output.dense.weight', 'base_model.encoder.layer.8.attention.self.query.weight', 'base_model.encoder.layer.1.attention.self.query.bias', 'base_model.encoder.layer.4.attention.self.query.bias', 'base_model.encoder.layer.1.intermediate.dense.weight', 'base_model.encoder.layer.8.attention.output.LayerNorm.weight', 'base_model.encoder.layer.9.output.LayerNorm.weight', 'base_model.encoder.layer.11.output.LayerNorm.weight', 'base_model.encoder.layer.1.intermediate.dense.bias', 'base_model.encoder.layer.5.attention.output.dense.weight', 'base_model.encoder.layer.6.intermediate.dense.weight', 'base_model.encoder.layer.11.attention.self.query.bias', 'base_model.encoder.layer.9.attention.self.key.weight', 'base_model.encoder.layer.0.output.dense.bias', 'base_model.encoder.layer.8.output.dense.bias', 'base_model.encoder.layer.8.attention.output.dense.bias', 'base_model.encoder.layer.4.output.dense.weight', 'base_model.encoder.layer.6.attention.self.value.weight', 'base_model.encoder.layer.0.attention.output.dense.bias', 'base_model.encoder.layer.8.attention.self.value.bias', 'base_model.encoder.layer.10.intermediate.dense.bias', 'base_model.encoder.layer.9.output.LayerNorm.bias', 'base_model.encoder.layer.4.attention.self.query.weight', 'base_model.encoder.layer.6.output.LayerNorm.weight', 'base_model.encoder.layer.7.attention.self.value.bias', 'base_model.encoder.layer.7.attention.output.LayerNorm.bias', 'base_model.encoder.layer.10.output.dense.bias', 'base_model.encoder.layer.6.attention.self.key.weight', 'base_model.encoder.layer.7.attention.output.dense.weight', 'base_model.encoder.layer.10.attention.self.query.weight', 'base_model.encoder.layer.3.attention.self.value.bias', 'base_model.encoder.layer.0.output.LayerNorm.weight', 'base_model.encoder.layer.10.attention.self.query.bias', 'base_model.encoder.layer.7.attention.self.value.weight', 'base_model.encoder.layer.10.intermediate.dense.weight', 'base_model.encoder.layer.10.output.LayerNorm.weight', 'base_model.encoder.layer.0.intermediate.dense.weight', 'base_model.encoder.layer.7.attention.self.key.weight', 'base_model.encoder.layer.9.intermediate.dense.weight', 'base_model.encoder.layer.10.output.LayerNorm.bias', 'base_model.encoder.layer.3.output.LayerNorm.bias', 'base_model.encoder.layer.0.attention.output.LayerNorm.weight', 'base_model.encoder.layer.11.attention.output.dense.bias', 'base_model.encoder.layer.10.attention.self.key.bias', 'base_model.encoder.layer.9.attention.output.LayerNorm.bias', 'base_model.encoder.layer.2.attention.self.query.weight', 'base_model.encoder.layer.8.output.LayerNorm.bias', 'base_model.encoder.layer.2.attention.output.dense.bias', 'base_model.encoder.layer.1.attention.self.key.weight', 'base_model.encoder.layer.6.output.LayerNorm.bias', 'base_model.encoder.layer.11.output.dense.bias', 'base_model.encoder.layer.4.attention.output.LayerNorm.bias', 'base_model.encoder.layer.0.intermediate.dense.bias', 'base_model.encoder.layer.9.attention.output.dense.weight', 'base_model.encoder.layer.11.output.LayerNorm.bias', 'base_model.encoder.layer.7.output.LayerNorm.weight', 'base_model.encoder.layer.6.intermediate.dense.bias', 'base_model.encoder.layer.10.attention.output.LayerNorm.weight', 'base_model.pooler.dense.weight', 'base_model.encoder.layer.3.attention.output.LayerNorm.weight', 'base_model.encoder.layer.3.attention.self.query.bias', 'base_model.encoder.layer.10.attention.self.value.bias', 'base_model.encoder.layer.11.attention.self.key.bias', 'base_model.encoder.layer.4.output.dense.bias', 'base_model.encoder.layer.0.attention.self.query.bias', 'base_model.encoder.layer.7.output.LayerNorm.bias', 'base_model.encoder.layer.4.output.LayerNorm.weight', 'base_model.encoder.layer.7.intermediate.dense.weight', 'base_model.encoder.layer.10.attention.self.key.weight', 'base_model.encoder.layer.0.attention.self.key.weight', 'base_model.encoder.layer.3.output.dense.bias', 'base_model.encoder.layer.10.output.dense.weight', 'base_model.encoder.layer.0.attention.output.LayerNorm.bias', 'base_model.encoder.layer.5.attention.self.value.weight', 'base_model.encoder.layer.9.attention.output.LayerNorm.weight', 'base_model.encoder.layer.9.attention.self.value.weight', 'base_model.encoder.layer.10.attention.output.dense.weight', 'base_model.encoder.layer.5.attention.self.query.weight', 'qa_outputs.bias', 'base_model.encoder.layer.4.intermediate.dense.bias', 'base_model.encoder.layer.5.attention.output.LayerNorm.weight', 'base_model.encoder.layer.2.attention.self.value.bias', 'base_model.encoder.layer.2.intermediate.dense.weight', 'base_model.encoder.layer.6.attention.output.LayerNorm.weight', 'base_model.encoder.layer.4.attention.output.dense.bias', 'base_model.encoder.layer.2.attention.self.key.bias', 'base_model.encoder.layer.6.output.dense.bias', 'base_model.encoder.layer.10.attention.output.LayerNorm.bias', 'base_model.encoder.layer.4.attention.self.key.bias', 'base_model.encoder.layer.8.attention.self.key.weight', 'base_model.encoder.layer.6.attention.self.query.bias', 'base_model.encoder.layer.3.output.dense.weight', 'base_model.embeddings.position_ids', 'base_model.encoder.layer.4.intermediate.dense.weight', 'base_model.embeddings.position_embeddings.weight', 'base_model.encoder.layer.8.output.dense.weight', 'base_model.encoder.layer.3.attention.self.key.weight', 'base_model.encoder.layer.11.intermediate.dense.weight', 'base_model.encoder.layer.5.intermediate.dense.bias', 'base_model.encoder.layer.10.attention.self.value.weight', 'base_model.encoder.layer.1.output.dense.weight', 'base_model.encoder.layer.3.attention.output.LayerNorm.bias', 'base_model.encoder.layer.9.attention.self.query.bias', 'base_model.encoder.layer.11.attention.output.LayerNorm.weight', 'base_model.encoder.layer.6.attention.output.dense.bias', 'base_model.encoder.layer.8.output.LayerNorm.weight', 'base_model.encoder.layer.9.attention.self.query.weight', 'base_model.encoder.layer.11.attention.self.key.weight', 'base_model.encoder.layer.4.attention.output.LayerNorm.weight', 'base_model.encoder.layer.2.intermediate.dense.bias', 'base_model.encoder.layer.1.output.dense.bias', 'base_model.encoder.layer.6.attention.self.value.bias', 'base_model.encoder.layer.1.attention.self.query.weight', 'base_model.encoder.layer.0.attention.output.dense.weight', 'base_model.encoder.layer.4.attention.self.value.weight', 'base_model.encoder.layer.8.attention.self.query.bias', 'base_model.encoder.layer.11.attention.output.LayerNorm.bias', 'base_model.encoder.layer.0.output.LayerNorm.bias', 'base_model.encoder.layer.0.attention.self.key.bias', 'base_model.encoder.layer.2.attention.self.query.bias', 'base_model.encoder.layer.3.intermediate.dense.weight', 'base_model.encoder.layer.6.attention.output.LayerNorm.bias', 'base_model.encoder.layer.9.output.dense.bias', 'base_model.encoder.layer.6.attention.self.key.bias', 'base_model.encoder.layer.5.output.LayerNorm.weight', 'base_model.encoder.layer.4.attention.self.key.weight', 'base_model.encoder.layer.3.attention.self.value.weight', 'base_model.embeddings.token_type_embeddings.weight', 'base_model.encoder.layer.8.intermediate.dense.bias', 'base_model.encoder.layer.5.attention.self.key.bias', 'base_model.encoder.layer.2.output.dense.weight']
- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of XLMRobertaModel were not initialized from the model checkpoint at /cluster/home/yifhou/scratch_yifan/qa/xtreme_xlm/outputs-adapter//squad/xlm_LR1e-5_EPOCH2.0_maxlen384_batchsize8_gradacc2 and are newly initialized: ['encoder.layer.0.attention.output.dense.weight', 'encoder.layer.9.output.LayerNorm.bias', 'encoder.layer.1.output.dense.weight', 'encoder.layer.7.output.LayerNorm.bias', 'encoder.layer.1.attention.self.query.weight', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.3.attention.self.key.weight', 'encoder.layer.10.attention.self.query.weight', 'encoder.layer.6.output.dense.weight', 'embeddings.LayerNorm.bias', 'encoder.layer.4.output.dense.weight', 'encoder.layer.9.attention.output.LayerNorm.bias', 'embeddings.word_embeddings.weight', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.2.attention.self.value.weight', 'encoder.layer.11.attention.self.key.bias', 'encoder.layer.4.attention.self.value.bias', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.9.attention.self.value.bias', 'encoder.layer.2.attention.output.LayerNorm.weight', 'pooler.dense.bias', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.11.attention.self.key.weight', 'encoder.layer.1.attention.self.query.bias', 'encoder.layer.4.attention.output.LayerNorm.bias', 'encoder.layer.9.output.dense.weight', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.10.attention.self.query.bias', 'encoder.layer.7.attention.output.LayerNorm.weight', 'encoder.layer.7.attention.self.value.weight', 'encoder.layer.4.attention.self.query.weight', 'encoder.layer.8.output.dense.weight', 'embeddings.position_embeddings.weight', 'encoder.layer.8.attention.output.LayerNorm.bias', 'encoder.layer.10.attention.self.value.bias', 'encoder.layer.11.attention.self.value.bias', 'encoder.layer.6.output.LayerNorm.bias', 'encoder.layer.10.attention.output.LayerNorm.bias', 'encoder.layer.3.attention.output.dense.weight', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.3.attention.self.value.weight', 'encoder.layer.3.output.dense.weight', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.8.attention.self.key.bias', 'encoder.layer.2.attention.self.key.weight', 'encoder.layer.7.attention.output.dense.bias', 'encoder.layer.1.attention.self.value.weight', 'encoder.layer.5.attention.self.key.bias', 'encoder.layer.1.attention.output.LayerNorm.weight', 'encoder.layer.0.attention.self.value.bias', 'encoder.layer.4.attention.self.value.weight', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.11.output.LayerNorm.weight', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.0.output.dense.weight', 'encoder.layer.4.attention.output.dense.weight', 'encoder.layer.11.attention.self.query.weight', 'encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.8.attention.self.query.weight', 'encoder.layer.0.attention.self.key.weight', 'encoder.layer.9.attention.self.query.weight', 'encoder.layer.5.attention.self.value.weight', 'encoder.layer.9.attention.self.key.weight', 'encoder.layer.7.attention.self.key.bias', 'embeddings.token_type_embeddings.weight', 'encoder.layer.0.attention.output.LayerNorm.weight', 'encoder.layer.7.output.LayerNorm.weight', 'encoder.layer.11.output.dense.weight', 'encoder.layer.2.attention.output.dense.weight', 'encoder.layer.9.output.LayerNorm.weight', 'encoder.layer.0.attention.self.query.weight', 'encoder.layer.10.output.LayerNorm.bias', 'encoder.layer.0.output.dense.bias', 'encoder.layer.3.attention.output.dense.bias', 'encoder.layer.8.attention.self.query.bias', 'encoder.layer.10.attention.output.LayerNorm.weight', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.9.attention.self.value.weight', 'encoder.layer.3.attention.self.query.weight', 'encoder.layer.8.output.LayerNorm.bias', 'encoder.layer.5.output.dense.weight', 'encoder.layer.6.attention.self.value.weight', 'encoder.layer.4.attention.self.key.bias', 'encoder.layer.6.attention.output.LayerNorm.weight', 'encoder.layer.10.output.dense.bias', 'encoder.layer.5.output.dense.bias', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.8.output.dense.bias', 'encoder.layer.3.output.dense.bias', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.9.output.dense.bias', 'encoder.layer.2.output.dense.bias', 'encoder.layer.7.intermediate.dense.bias', 'encoder.layer.4.attention.output.dense.bias', 'encoder.layer.7.attention.self.key.weight', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.6.attention.self.key.bias', 'encoder.layer.11.attention.self.query.bias', 'encoder.layer.6.output.dense.bias', 'encoder.layer.1.attention.self.key.bias', 'encoder.layer.2.attention.output.dense.bias', 'encoder.layer.6.attention.self.value.bias', 'encoder.layer.10.attention.self.key.bias', 'encoder.layer.10.attention.self.value.weight', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.11.attention.output.dense.bias', 'encoder.layer.6.attention.output.dense.weight', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.layer.5.attention.output.LayerNorm.weight', 'encoder.layer.0.attention.self.value.weight', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.3.attention.self.key.bias', 'encoder.layer.7.attention.self.query.bias', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.0.attention.self.key.bias', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.8.attention.self.value.bias', 'encoder.layer.9.attention.self.key.bias', 'encoder.layer.5.attention.self.value.bias', 'encoder.layer.1.output.dense.bias', 'encoder.layer.2.attention.output.LayerNorm.bias', 'encoder.layer.9.attention.self.query.bias', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.layer.8.attention.output.LayerNorm.weight', 'encoder.layer.1.attention.output.dense.weight', 'encoder.layer.5.attention.output.dense.weight', 'encoder.layer.10.attention.self.key.weight', 'encoder.layer.8.attention.output.dense.bias', 'encoder.layer.6.attention.self.query.weight', 'encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.4.attention.self.key.weight', 'encoder.layer.10.output.dense.weight', 'encoder.layer.5.attention.output.dense.bias', 'encoder.layer.11.attention.output.LayerNorm.weight', 'encoder.layer.11.output.dense.bias', 'encoder.layer.0.attention.self.query.bias', 'encoder.layer.1.attention.self.value.bias', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.7.attention.output.dense.weight', 'encoder.layer.10.output.LayerNorm.weight', 'encoder.layer.7.attention.output.LayerNorm.bias', 'encoder.layer.0.attention.output.dense.bias', 'encoder.layer.3.attention.self.value.bias', 'encoder.layer.8.output.LayerNorm.weight', 'embeddings.LayerNorm.weight', 'encoder.layer.7.output.dense.weight', 'encoder.layer.10.attention.output.dense.weight', 'encoder.layer.6.attention.output.dense.bias', 'encoder.layer.11.attention.output.dense.weight', 'encoder.layer.6.attention.output.LayerNorm.bias', 'encoder.layer.4.output.dense.bias', 'encoder.layer.4.attention.self.query.bias', 'encoder.layer.9.attention.output.dense.bias', 'encoder.layer.10.attention.output.dense.bias', 'encoder.layer.7.output.dense.bias', 'encoder.layer.4.attention.output.LayerNorm.weight', 'encoder.layer.6.attention.self.query.bias', 'encoder.layer.9.attention.output.LayerNorm.weight', 'encoder.layer.5.attention.self.query.weight', 'encoder.layer.7.attention.self.query.weight', 'pooler.dense.weight', 'encoder.layer.3.attention.self.query.bias', 'encoder.layer.6.attention.self.key.weight', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.10.intermediate.dense.weight', 'encoder.layer.2.attention.self.query.weight', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.7.attention.self.value.bias', 'encoder.layer.8.attention.self.value.weight', 'encoder.layer.11.attention.self.value.weight', 'encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.layer.2.attention.self.value.bias', 'encoder.layer.8.attention.output.dense.weight', 'encoder.layer.2.attention.self.key.bias', 'encoder.layer.5.output.LayerNorm.bias', 'encoder.layer.2.output.dense.weight', 'encoder.layer.5.attention.self.query.bias', 'encoder.layer.9.attention.output.dense.weight', 'encoder.layer.11.output.LayerNorm.bias', 'encoder.layer.8.attention.self.key.weight', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.1.attention.self.key.weight', 'encoder.layer.2.attention.self.query.bias', 'encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.layer.5.attention.self.key.weight', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.1.attention.output.dense.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
05/09/2022 18:35:44 - INFO - __main__ -   Creating features from dataset file at .
/cluster/home/yifhou/scratch_yifan/qa/xtreme_xlm/outputs-adapter//squad/xlm_LR1e-5_EPOCH2.0_maxlen384_batchsize8_gradacc2
XLMConfig {
  "architectures": [
    "XLMRobertaForMaskedLM"
  ],
  "asm": false,
  "attention_dropout": 0.1,
  "attention_probs_dropout_prob": 0.1,
  "bos_index": 0,
  "bos_token_id": 0,
  "causal": false,
  "dropout": 0.1,
  "emb_dim": 768,
  "embed_init_std": 0.02209708691207961,
  "end_n_top": 5,
  "eos_index": 1,
  "eos_token_id": 2,
  "gelu_activation": true,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "init_std": 0.02,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "is_encoder": true,
  "lang_id": 0,
  "layer_norm_eps": 1e-05,
  "mask_index": 5,
  "mask_token_id": 0,
  "max_position_embeddings": 514,
  "model_type": "xlm",
  "n_heads": 12,
  "n_langs": 1,
  "n_layers": 12,
  "output_past": true,
  "pad_index": 2,
  "pad_token_id": 1,
  "sinusoidal_embeddings": false,
  "start_n_top": 5,
  "summary_activation": null,
  "summary_first_dropout": 0.1,
  "summary_proj_to_labels": true,
  "summary_type": "first",
  "summary_use_proj": true,
  "transformers_version": "4.17.0",
  "type_vocab_size": 1,
  "unk_index": 3,
  "use_lang_emb": false,
  "vocab_size": 250002
}

  0%|          | 0/48 [00:00<?, ?it/s] 21%|██        | 10/48 [00:00<00:00, 97.09it/s] 42%|████▏     | 20/48 [00:00<00:00, 83.23it/s] 60%|██████    | 29/48 [00:00<00:00, 81.63it/s] 81%|████████▏ | 39/48 [00:00<00:00, 84.07it/s]100%|██████████| 48/48 [00:00<00:00, 88.88it/s]
convert squad examples to features:   0%|          | 0/1190 [00:00<?, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.
convert squad examples to features:   0%|          | 1/1190 [00:00<03:35,  5.52it/s]convert squad examples to features:   5%|▌         | 65/1190 [00:00<00:07, 158.90it/s]convert squad examples to features:   8%|▊         | 97/1190 [00:00<00:06, 160.58it/s]convert squad examples to features:  14%|█▎        | 161/1190 [00:00<00:04, 219.73it/s]convert squad examples to features:  19%|█▉        | 225/1190 [00:01<00:03, 241.27it/s]convert squad examples to features:  22%|██▏       | 257/1190 [00:01<00:04, 226.63it/s]convert squad examples to features:  24%|██▍       | 289/1190 [00:01<00:04, 221.77it/s]convert squad examples to features:  27%|██▋       | 321/1190 [00:01<00:04, 209.91it/s]convert squad examples to features:  30%|██▉       | 353/1190 [00:01<00:03, 222.79it/s]convert squad examples to features:  32%|███▏      | 385/1190 [00:02<00:07, 113.24it/s]convert squad examples to features:  35%|███▌      | 417/1190 [00:02<00:06, 117.78it/s]convert squad examples to features:  38%|███▊      | 449/1190 [00:02<00:05, 125.64it/s]convert squad examples to features:  40%|████      | 481/1190 [00:02<00:05, 135.83it/s]convert squad examples to features:  43%|████▎     | 513/1190 [00:03<00:04, 150.04it/s]convert squad examples to features:  46%|████▌     | 545/1190 [00:03<00:04, 153.41it/s]convert squad examples to features:  48%|████▊     | 577/1190 [00:03<00:03, 168.18it/s]convert squad examples to features:  51%|█████     | 609/1190 [00:03<00:03, 160.02it/s]convert squad examples to features:  54%|█████▍    | 641/1190 [00:03<00:03, 167.63it/s]convert squad examples to features:  57%|█████▋    | 673/1190 [00:04<00:03, 159.68it/s]convert squad examples to features:  59%|█████▉    | 705/1190 [00:04<00:02, 173.03it/s]convert squad examples to features:  62%|██████▏   | 737/1190 [00:04<00:02, 186.87it/s]convert squad examples to features:  65%|██████▍   | 769/1190 [00:04<00:02, 203.26it/s]convert squad examples to features:  67%|██████▋   | 801/1190 [00:04<00:01, 216.93it/s]convert squad examples to features:  70%|███████   | 833/1190 [00:04<00:01, 190.51it/s]convert squad examples to features:  73%|███████▎  | 865/1190 [00:04<00:01, 203.89it/s]convert squad examples to features:  75%|███████▌  | 897/1190 [00:05<00:01, 191.67it/s]convert squad examples to features:  78%|███████▊  | 929/1190 [00:05<00:01, 188.29it/s]convert squad examples to features:  81%|████████  | 961/1190 [00:05<00:01, 197.28it/s]convert squad examples to features:  83%|████████▎ | 993/1190 [00:05<00:00, 207.71it/s]convert squad examples to features:  86%|████████▌ | 1025/1190 [00:05<00:00, 216.41it/s]convert squad examples to features:  89%|████████▉ | 1057/1190 [00:05<00:00, 219.37it/s]convert squad examples to features:  92%|█████████▏| 1089/1190 [00:06<00:00, 229.73it/s]convert squad examples to features:  94%|█████████▍| 1121/1190 [00:06<00:00, 226.61it/s]convert squad examples to features:  97%|█████████▋| 1153/1190 [00:06<00:00, 194.02it/s]convert squad examples to features: 100%|██████████| 1190/1190 [00:06<00:00, 185.52it/s]/cluster/project/sachan/yifan/softwares/anaconda/anaconda3/envs/xfactr/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2272: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

add example index and unique id:   0%|          | 0/1190 [00:00<?, ?it/s]add example index and unique id: 100%|██████████| 1190/1190 [00:00<00:00, 478223.80it/s]
05/09/2022 18:35:51 - INFO - __main__ -   Saving features into cached file ./cached_xquad.el.json_xlm_LR1e-5_EPOCH2.0_maxlen384_batchsize8_gradacc2_384_el
05/09/2022 18:35:53 - INFO - __main__ -   ***** Running evaluation  *****
05/09/2022 18:35:53 - INFO - __main__ -     Num examples = 1488
05/09/2022 18:35:53 - INFO - __main__ -     Batch size = 8
Evaluating:   0%|          | 0/186 [00:00<?, ?it/s]Evaluating:   1%|          | 1/186 [00:00<01:43,  1.78it/s]Evaluating:   2%|▏         | 3/186 [00:00<00:36,  5.03it/s]Evaluating:   3%|▎         | 5/186 [00:00<00:23,  7.60it/s]Evaluating:   4%|▍         | 7/186 [00:00<00:18,  9.66it/s]Evaluating:   5%|▍         | 9/186 [00:01<00:15, 11.23it/s]Evaluating:   6%|▌         | 11/186 [00:01<00:14, 12.34it/s]Evaluating:   7%|▋         | 13/186 [00:01<00:13, 13.27it/s]Evaluating:   8%|▊         | 15/186 [00:01<00:12, 13.92it/s]Evaluating:   9%|▉         | 17/186 [00:01<00:11, 14.37it/s]Evaluating:  10%|█         | 19/186 [00:01<00:11, 14.68it/s]Evaluating:  11%|█▏        | 21/186 [00:01<00:11, 14.88it/s]Evaluating:  12%|█▏        | 23/186 [00:02<00:10, 15.09it/s]Evaluating:  13%|█▎        | 25/186 [00:02<00:10, 15.17it/s]Evaluating:  15%|█▍        | 27/186 [00:02<00:10, 15.27it/s]Evaluating:  16%|█▌        | 29/186 [00:02<00:10, 14.85it/s]Evaluating:  17%|█▋        | 31/186 [00:02<00:10, 15.01it/s]Evaluating:  18%|█▊        | 33/186 [00:02<00:10, 15.17it/s]Evaluating:  19%|█▉        | 35/186 [00:02<00:09, 15.22it/s]Evaluating:  20%|█▉        | 37/186 [00:02<00:09, 15.33it/s]Evaluating:  21%|██        | 39/186 [00:03<00:09, 15.35it/s]Evaluating:  22%|██▏       | 41/186 [00:03<00:09, 15.39it/s]Evaluating:  23%|██▎       | 43/186 [00:03<00:09, 15.31it/s]Evaluating:  24%|██▍       | 45/186 [00:03<00:09, 15.31it/s]Evaluating:  25%|██▌       | 47/186 [00:03<00:09, 15.28it/s]Evaluating:  26%|██▋       | 49/186 [00:03<00:08, 15.34it/s]Evaluating:  27%|██▋       | 51/186 [00:03<00:08, 15.33it/s]Evaluating:  28%|██▊       | 53/186 [00:03<00:08, 15.35it/s]Evaluating:  30%|██▉       | 55/186 [00:04<00:08, 15.32it/s]Evaluating:  31%|███       | 57/186 [00:04<00:08, 15.32it/s]Evaluating:  32%|███▏      | 59/186 [00:04<00:08, 15.24it/s]Evaluating:  33%|███▎      | 61/186 [00:04<00:08, 15.20it/s]Evaluating:  34%|███▍      | 63/186 [00:04<00:08, 15.17it/s]Evaluating:  35%|███▍      | 65/186 [00:04<00:07, 15.16it/s]Evaluating:  36%|███▌      | 67/186 [00:04<00:07, 15.15it/s]Evaluating:  37%|███▋      | 69/186 [00:05<00:08, 14.59it/s]Evaluating:  38%|███▊      | 71/186 [00:05<00:07, 14.82it/s]Evaluating:  39%|███▉      | 73/186 [00:05<00:07, 14.98it/s]Evaluating:  40%|████      | 75/186 [00:05<00:07, 14.85it/s]Evaluating:  41%|████▏     | 77/186 [00:05<00:07, 14.96it/s]Evaluating:  42%|████▏     | 79/186 [00:05<00:07, 15.02it/s]Evaluating:  44%|████▎     | 81/186 [00:05<00:06, 15.13it/s]Evaluating:  45%|████▍     | 83/186 [00:05<00:06, 15.20it/s]Evaluating:  46%|████▌     | 85/186 [00:06<00:12,  8.42it/s]Evaluating:  47%|████▋     | 87/186 [00:06<00:10,  9.75it/s]Evaluating:  48%|████▊     | 89/186 [00:06<00:08, 10.95it/s]Evaluating:  49%|████▉     | 91/186 [00:06<00:07, 11.98it/s]Evaluating:  50%|█████     | 93/186 [00:06<00:07, 12.85it/s]Evaluating:  51%|█████     | 95/186 [00:07<00:06, 13.51it/s]Evaluating:  52%|█████▏    | 97/186 [00:07<00:06, 13.84it/s]Evaluating:  53%|█████▎    | 99/186 [00:07<00:06, 14.20it/s]Evaluating:  54%|█████▍    | 101/186 [00:07<00:05, 14.45it/s]Evaluating:  55%|█████▌    | 103/186 [00:07<00:05, 14.73it/s]Evaluating:  56%|█████▋    | 105/186 [00:07<00:05, 14.71it/s]Evaluating:  58%|█████▊    | 107/186 [00:07<00:05, 14.83it/s]Evaluating:  59%|█████▊    | 109/186 [00:08<00:05, 14.89it/s]Evaluating:  60%|█████▉    | 111/186 [00:08<00:05, 14.89it/s]Evaluating:  61%|██████    | 113/186 [00:08<00:04, 14.87it/s]Evaluating:  62%|██████▏   | 115/186 [00:08<00:04, 14.95it/s]Evaluating:  63%|██████▎   | 117/186 [00:08<00:04, 14.89it/s]Evaluating:  64%|██████▍   | 119/186 [00:08<00:04, 15.01it/s]Evaluating:  65%|██████▌   | 121/186 [00:08<00:04, 15.11it/s]Evaluating:  66%|██████▌   | 123/186 [00:08<00:04, 15.18it/s]Evaluating:  67%|██████▋   | 125/186 [00:09<00:04, 15.24it/s]Evaluating:  68%|██████▊   | 127/186 [00:09<00:03, 15.10it/s]Evaluating:  69%|██████▉   | 129/186 [00:09<00:03, 15.12it/s]Evaluating:  70%|███████   | 131/186 [00:09<00:03, 15.15it/s]Evaluating:  72%|███████▏  | 133/186 [00:09<00:03, 15.04it/s]Evaluating:  73%|███████▎  | 135/186 [00:09<00:03, 15.08it/s]Evaluating:  74%|███████▎  | 137/186 [00:09<00:03, 15.03it/s]Evaluating:  75%|███████▍  | 139/186 [00:10<00:03, 15.00it/s]Evaluating:  76%|███████▌  | 141/186 [00:10<00:03, 14.93it/s]Evaluating:  77%|███████▋  | 143/186 [00:10<00:02, 14.95it/s]Evaluating:  78%|███████▊  | 145/186 [00:10<00:02, 15.01it/s]Evaluating:  79%|███████▉  | 147/186 [00:10<00:02, 15.11it/s]Evaluating:  80%|████████  | 149/186 [00:10<00:02, 15.07it/s]Evaluating:  81%|████████  | 151/186 [00:10<00:02, 15.14it/s]Evaluating:  82%|████████▏ | 153/186 [00:10<00:02, 15.22it/s]Evaluating:  83%|████████▎ | 155/186 [00:11<00:02, 15.29it/s]Evaluating:  84%|████████▍ | 157/186 [00:11<00:01, 15.31it/s]Evaluating:  85%|████████▌ | 159/186 [00:11<00:01, 15.25it/s]Evaluating:  87%|████████▋ | 161/186 [00:11<00:01, 15.23it/s]Evaluating:  88%|████████▊ | 163/186 [00:11<00:01, 15.14it/s]Evaluating:  89%|████████▊ | 165/186 [00:11<00:01, 15.22it/s]Evaluating:  90%|████████▉ | 167/186 [00:11<00:01, 15.28it/s]Evaluating:  91%|█████████ | 169/186 [00:11<00:01, 15.22it/s]Evaluating:  92%|█████████▏| 171/186 [00:12<00:00, 15.25it/s]Evaluating:  93%|█████████▎| 173/186 [00:12<00:00, 15.21it/s]Evaluating:  94%|█████████▍| 175/186 [00:12<00:00, 15.27it/s]Evaluating:  95%|█████████▌| 177/186 [00:12<00:00, 15.29it/s]Evaluating:  96%|█████████▌| 179/186 [00:12<00:00, 15.32it/s]Evaluating:  97%|█████████▋| 181/186 [00:12<00:00, 15.33it/s]Evaluating:  98%|█████████▊| 183/186 [00:12<00:00, 15.28it/s]Evaluating:  99%|█████████▉| 185/186 [00:13<00:00, 15.18it/s]Evaluating: 100%|██████████| 186/186 [00:13<00:00, 14.18it/s]
05/09/2022 18:36:06 - INFO - __main__ -     Evaluation done in total 13.116864 secs (0.008815 sec per example)
05/09/2022 18:36:10 - INFO - __main__ -   Results: {'exact': 54.285714285714285, 'f1': 71.64875282531379, 'total': 1190, 'HasAns_exact': 54.285714285714285, 'HasAns_f1': 71.64875282531379, 'HasAns_total': 1190, 'best_exact': 54.285714285714285, 'best_exact_thresh': 0.0, 'best_f1': 71.64875282531379, 'best_f1_thresh': 0.0}
  ru 
2022-05-09 18:36:13.131903: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0
05/09/2022 18:36:15 - WARNING - __main__ -   Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, 16-bits training: False
You are using a model of type xlm-roberta to instantiate a model of type xlm. This is not supported for all configurations of models and can yield errors.
Some weights of the model checkpoint at /cluster/home/yifhou/scratch_yifan/qa/xtreme_xlm/outputs-adapter//squad/xlm_LR1e-5_EPOCH2.0_maxlen384_batchsize8_gradacc2 were not used when initializing XLMRobertaModel: ['qa_outputs.weight', 'base_model.encoder.layer.10.attention.self.key.bias', 'base_model.encoder.layer.6.intermediate.dense.weight', 'base_model.encoder.layer.9.attention.output.LayerNorm.weight', 'base_model.encoder.layer.0.attention.self.key.weight', 'base_model.embeddings.position_ids', 'base_model.encoder.layer.9.attention.self.query.bias', 'base_model.encoder.layer.4.output.LayerNorm.bias', 'base_model.encoder.layer.2.attention.output.dense.weight', 'base_model.encoder.layer.2.attention.self.key.bias', 'base_model.encoder.layer.3.attention.self.key.bias', 'base_model.encoder.layer.2.output.dense.bias', 'base_model.encoder.layer.9.attention.self.query.weight', 'base_model.embeddings.token_type_embeddings.weight', 'base_model.encoder.layer.3.output.dense.weight', 'base_model.encoder.layer.8.attention.self.value.weight', 'base_model.encoder.layer.5.attention.output.LayerNorm.bias', 'base_model.encoder.layer.9.attention.self.key.weight', 'base_model.encoder.layer.7.intermediate.dense.bias', 'base_model.encoder.layer.9.output.LayerNorm.bias', 'base_model.encoder.layer.5.attention.output.dense.bias', 'base_model.encoder.layer.10.attention.self.value.weight', 'base_model.encoder.layer.6.attention.self.value.bias', 'base_model.encoder.layer.6.attention.self.query.bias', 'base_model.encoder.layer.4.intermediate.dense.bias', 'base_model.encoder.layer.10.attention.self.value.bias', 'base_model.encoder.layer.11.attention.self.value.bias', 'base_model.encoder.layer.5.attention.self.query.weight', 'base_model.encoder.layer.0.output.dense.bias', 'base_model.encoder.layer.2.attention.self.key.weight', 'base_model.encoder.layer.9.attention.output.LayerNorm.bias', 'base_model.encoder.layer.11.attention.output.dense.bias', 'base_model.encoder.layer.11.attention.self.value.weight', 'base_model.encoder.layer.10.attention.output.LayerNorm.bias', 'base_model.encoder.layer.9.output.dense.weight', 'base_model.encoder.layer.7.attention.self.key.bias', 'base_model.encoder.layer.7.output.dense.bias', 'base_model.encoder.layer.8.attention.self.key.bias', 'base_model.encoder.layer.11.attention.self.query.weight', 'base_model.encoder.layer.10.output.dense.bias', 'base_model.encoder.layer.4.attention.self.value.bias', 'base_model.encoder.layer.2.intermediate.dense.weight', 'base_model.encoder.layer.3.attention.self.value.weight', 'base_model.encoder.layer.2.output.LayerNorm.bias', 'base_model.encoder.layer.6.output.LayerNorm.weight', 'base_model.encoder.layer.6.attention.self.key.bias', 'base_model.encoder.layer.10.attention.self.key.weight', 'base_model.encoder.layer.10.attention.self.query.bias', 'base_model.encoder.layer.6.attention.output.dense.bias', 'base_model.encoder.layer.7.attention.self.key.weight', 'base_model.encoder.layer.8.intermediate.dense.bias', 'base_model.encoder.layer.4.attention.self.value.weight', 'base_model.encoder.layer.0.attention.self.query.bias', 'base_model.encoder.layer.8.attention.self.query.weight', 'base_model.encoder.layer.0.attention.output.LayerNorm.bias', 'base_model.encoder.layer.3.intermediate.dense.weight', 'base_model.encoder.layer.2.attention.self.query.bias', 'base_model.encoder.layer.11.attention.self.key.bias', 'base_model.encoder.layer.4.output.LayerNorm.weight', 'base_model.encoder.layer.6.output.LayerNorm.bias', 'base_model.encoder.layer.0.output.dense.weight', 'base_model.encoder.layer.9.intermediate.dense.bias', 'base_model.encoder.layer.1.output.dense.bias', 'base_model.encoder.layer.1.attention.self.value.weight', 'base_model.encoder.layer.0.attention.output.dense.weight', 'base_model.encoder.layer.1.intermediate.dense.bias', 'base_model.encoder.layer.9.output.dense.bias', 'base_model.embeddings.LayerNorm.bias', 'base_model.encoder.layer.5.intermediate.dense.weight', 'base_model.encoder.layer.9.attention.self.key.bias', 'base_model.encoder.layer.10.output.LayerNorm.bias', 'base_model.encoder.layer.11.attention.output.dense.weight', 'base_model.encoder.layer.0.attention.output.dense.bias', 'base_model.encoder.layer.10.attention.output.LayerNorm.weight', 'base_model.encoder.layer.10.output.LayerNorm.weight', 'base_model.encoder.layer.5.attention.self.key.weight', 'base_model.encoder.layer.6.attention.self.query.weight', 'base_model.encoder.layer.8.output.dense.weight', 'base_model.embeddings.word_embeddings.weight', 'base_model.encoder.layer.11.attention.self.key.weight', 'base_model.encoder.layer.4.attention.output.dense.weight', 'base_model.encoder.layer.6.attention.output.dense.weight', 'base_model.encoder.layer.2.attention.self.value.weight', 'base_model.encoder.layer.2.intermediate.dense.bias', 'base_model.encoder.layer.7.attention.output.LayerNorm.weight', 'base_model.encoder.layer.0.output.LayerNorm.bias', 'base_model.encoder.layer.7.attention.output.dense.bias', 'base_model.encoder.layer.2.attention.self.value.bias', 'base_model.encoder.layer.3.attention.output.LayerNorm.weight', 'base_model.encoder.layer.5.attention.output.dense.weight', 'base_model.encoder.layer.10.attention.self.query.weight', 'base_model.encoder.layer.11.intermediate.dense.bias', 'base_model.encoder.layer.11.attention.output.LayerNorm.weight', 'base_model.encoder.layer.5.attention.self.value.bias', 'base_model.encoder.layer.5.output.dense.weight', 'base_model.encoder.layer.3.intermediate.dense.bias', 'base_model.encoder.layer.4.attention.self.query.bias', 'base_model.encoder.layer.10.attention.output.dense.bias', 'base_model.encoder.layer.10.output.dense.weight', 'base_model.encoder.layer.4.attention.self.query.weight', 'base_model.encoder.layer.2.attention.output.LayerNorm.weight', 'base_model.encoder.layer.6.output.dense.bias', 'base_model.encoder.layer.11.output.LayerNorm.bias', 'base_model.encoder.layer.0.attention.self.query.weight', 'base_model.encoder.layer.4.intermediate.dense.weight', 'base_model.encoder.layer.2.attention.output.dense.bias', 'base_model.encoder.layer.5.intermediate.dense.bias', 'base_model.encoder.layer.7.output.LayerNorm.bias', 'base_model.encoder.layer.10.intermediate.dense.weight', 'base_model.encoder.layer.4.attention.output.LayerNorm.bias', 'base_model.encoder.layer.7.attention.self.query.bias', 'base_model.encoder.layer.2.attention.self.query.weight', 'base_model.encoder.layer.5.attention.self.key.bias', 'base_model.encoder.layer.11.output.dense.bias', 'base_model.encoder.layer.8.attention.output.dense.weight', 'base_model.encoder.layer.1.attention.output.dense.bias', 'base_model.encoder.layer.3.attention.self.value.bias', 'base_model.encoder.layer.9.attention.output.dense.bias', 'base_model.encoder.layer.8.attention.output.LayerNorm.bias', 'base_model.encoder.layer.7.output.LayerNorm.weight', 'base_model.encoder.layer.6.attention.output.LayerNorm.bias', 'base_model.encoder.layer.8.attention.self.query.bias', 'base_model.encoder.layer.7.intermediate.dense.weight', 'base_model.embeddings.LayerNorm.weight', 'base_model.encoder.layer.1.attention.output.LayerNorm.weight', 'base_model.encoder.layer.5.attention.self.value.weight', 'base_model.encoder.layer.1.attention.self.key.weight', 'base_model.encoder.layer.1.output.dense.weight', 'base_model.encoder.layer.10.attention.output.dense.weight', 'base_model.encoder.layer.7.attention.output.dense.weight', 'base_model.encoder.layer.9.output.LayerNorm.weight', 'base_model.encoder.layer.11.attention.output.LayerNorm.bias', 'base_model.encoder.layer.0.attention.output.LayerNorm.weight', 'base_model.encoder.layer.5.attention.output.LayerNorm.weight', 'qa_outputs.bias', 'base_model.encoder.layer.11.output.LayerNorm.weight', 'base_model.encoder.layer.0.intermediate.dense.weight', 'base_model.encoder.layer.3.attention.self.query.weight', 'base_model.encoder.layer.2.attention.output.LayerNorm.bias', 'base_model.encoder.layer.0.attention.self.value.bias', 'base_model.encoder.layer.1.attention.self.query.bias', 'base_model.encoder.layer.3.attention.output.dense.weight', 'base_model.encoder.layer.3.attention.self.key.weight', 'base_model.encoder.layer.4.output.dense.weight', 'base_model.encoder.layer.0.intermediate.dense.bias', 'base_model.encoder.layer.3.attention.output.LayerNorm.bias', 'base_model.encoder.layer.8.output.dense.bias', 'base_model.encoder.layer.0.attention.self.value.weight', 'base_model.encoder.layer.3.output.LayerNorm.weight', 'base_model.encoder.layer.5.output.LayerNorm.weight', 'base_model.encoder.layer.7.output.dense.weight', 'base_model.encoder.layer.1.attention.self.query.weight', 'base_model.encoder.layer.4.attention.self.key.bias', 'base_model.encoder.layer.6.attention.self.value.weight', 'base_model.encoder.layer.9.attention.self.value.bias', 'base_model.encoder.layer.11.intermediate.dense.weight', 'base_model.encoder.layer.3.attention.self.query.bias', 'base_model.encoder.layer.3.output.dense.bias', 'base_model.encoder.layer.6.attention.self.key.weight', 'base_model.encoder.layer.6.attention.output.LayerNorm.weight', 'base_model.encoder.layer.6.output.dense.weight', 'base_model.encoder.layer.7.attention.self.value.bias', 'base_model.encoder.layer.0.attention.self.key.bias', 'base_model.encoder.layer.7.attention.self.value.weight', 'base_model.encoder.layer.4.attention.self.key.weight', 'base_model.encoder.layer.7.attention.output.LayerNorm.bias', 'base_model.encoder.layer.4.output.dense.bias', 'base_model.encoder.layer.8.attention.self.key.weight', 'base_model.encoder.layer.1.attention.self.key.bias', 'base_model.encoder.layer.11.output.dense.weight', 'base_model.embeddings.position_embeddings.weight', 'base_model.encoder.layer.2.output.dense.weight', 'base_model.encoder.layer.9.attention.output.dense.weight', 'base_model.encoder.layer.9.attention.self.value.weight', 'base_model.encoder.layer.2.output.LayerNorm.weight', 'base_model.encoder.layer.4.attention.output.dense.bias', 'base_model.encoder.layer.5.output.LayerNorm.bias', 'base_model.encoder.layer.1.attention.output.dense.weight', 'base_model.encoder.layer.3.attention.output.dense.bias', 'base_model.encoder.layer.8.output.LayerNorm.bias', 'base_model.encoder.layer.11.attention.self.query.bias', 'base_model.encoder.layer.9.intermediate.dense.weight', 'base_model.encoder.layer.1.output.LayerNorm.bias', 'base_model.encoder.layer.0.output.LayerNorm.weight', 'base_model.encoder.layer.1.attention.self.value.bias', 'base_model.encoder.layer.6.intermediate.dense.bias', 'base_model.encoder.layer.8.attention.output.LayerNorm.weight', 'base_model.encoder.layer.1.output.LayerNorm.weight', 'base_model.pooler.dense.bias', 'base_model.encoder.layer.7.attention.self.query.weight', 'base_model.encoder.layer.5.attention.self.query.bias', 'base_model.encoder.layer.8.attention.output.dense.bias', 'base_model.encoder.layer.5.output.dense.bias', 'base_model.encoder.layer.1.attention.output.LayerNorm.bias', 'base_model.encoder.layer.8.attention.self.value.bias', 'base_model.encoder.layer.8.intermediate.dense.weight', 'base_model.encoder.layer.1.intermediate.dense.weight', 'base_model.encoder.layer.10.intermediate.dense.bias', 'base_model.encoder.layer.8.output.LayerNorm.weight', 'base_model.pooler.dense.weight', 'base_model.encoder.layer.3.output.LayerNorm.bias', 'base_model.encoder.layer.4.attention.output.LayerNorm.weight']
- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of XLMRobertaModel were not initialized from the model checkpoint at /cluster/home/yifhou/scratch_yifan/qa/xtreme_xlm/outputs-adapter//squad/xlm_LR1e-5_EPOCH2.0_maxlen384_batchsize8_gradacc2 and are newly initialized: ['encoder.layer.2.attention.self.key.bias', 'encoder.layer.8.attention.self.value.weight', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.3.attention.self.value.weight', 'encoder.layer.5.attention.self.value.weight', 'encoder.layer.10.output.LayerNorm.bias', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.1.attention.output.LayerNorm.weight', 'encoder.layer.1.output.dense.bias', 'encoder.layer.2.attention.self.value.bias', 'encoder.layer.10.attention.self.key.bias', 'encoder.layer.11.attention.self.value.weight', 'encoder.layer.10.output.LayerNorm.weight', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.6.attention.self.value.bias', 'encoder.layer.0.attention.self.key.bias', 'embeddings.token_type_embeddings.weight', 'encoder.layer.1.attention.self.value.bias', 'encoder.layer.2.attention.output.LayerNorm.weight', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.7.attention.self.query.bias', 'encoder.layer.9.attention.self.query.bias', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.1.attention.self.key.weight', 'encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.10.attention.self.query.bias', 'encoder.layer.8.attention.output.LayerNorm.bias', 'encoder.layer.1.attention.self.query.bias', 'encoder.layer.9.attention.self.key.bias', 'encoder.layer.1.attention.self.key.bias', 'encoder.layer.10.attention.output.LayerNorm.bias', 'encoder.layer.10.attention.self.query.weight', 'encoder.layer.3.attention.self.query.bias', 'encoder.layer.11.output.dense.bias', 'encoder.layer.9.output.LayerNorm.bias', 'encoder.layer.6.attention.self.query.weight', 'encoder.layer.8.attention.self.query.bias', 'encoder.layer.11.attention.self.query.bias', 'encoder.layer.10.attention.output.dense.weight', 'encoder.layer.3.output.dense.bias', 'encoder.layer.11.attention.output.LayerNorm.weight', 'encoder.layer.10.intermediate.dense.weight', 'encoder.layer.9.attention.self.query.weight', 'encoder.layer.11.output.dense.weight', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.3.attention.output.dense.weight', 'encoder.layer.0.attention.output.dense.weight', 'encoder.layer.0.attention.output.LayerNorm.weight', 'encoder.layer.5.attention.output.dense.weight', 'encoder.layer.7.output.dense.weight', 'encoder.layer.4.output.dense.bias', 'encoder.layer.2.attention.self.query.weight', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.2.output.dense.bias', 'encoder.layer.2.output.dense.weight', 'encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.7.output.LayerNorm.bias', 'encoder.layer.5.attention.self.key.bias', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.9.attention.output.LayerNorm.weight', 'encoder.layer.6.attention.output.dense.weight', 'encoder.layer.11.output.LayerNorm.weight', 'encoder.layer.4.output.dense.weight', 'encoder.layer.6.attention.output.dense.bias', 'encoder.layer.1.attention.output.dense.weight', 'encoder.layer.10.attention.output.LayerNorm.weight', 'encoder.layer.2.attention.self.key.weight', 'encoder.layer.8.output.dense.bias', 'encoder.layer.5.output.dense.bias', 'embeddings.LayerNorm.weight', 'encoder.layer.4.attention.self.key.bias', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.layer.8.attention.output.dense.weight', 'encoder.layer.7.attention.self.key.weight', 'encoder.layer.10.attention.output.dense.bias', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.6.attention.self.value.weight', 'encoder.layer.9.output.LayerNorm.weight', 'encoder.layer.11.output.LayerNorm.bias', 'encoder.layer.4.attention.output.dense.weight', 'encoder.layer.1.output.dense.weight', 'encoder.layer.11.attention.self.key.weight', 'encoder.layer.8.attention.self.value.bias', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.3.output.dense.weight', 'encoder.layer.5.output.LayerNorm.bias', 'encoder.layer.3.attention.self.key.weight', 'encoder.layer.10.output.dense.weight', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.9.attention.self.key.weight', 'encoder.layer.6.attention.self.key.weight', 'encoder.layer.7.attention.self.key.bias', 'encoder.layer.2.attention.output.dense.weight', 'encoder.layer.9.output.dense.bias', 'encoder.layer.9.attention.output.dense.weight', 'encoder.layer.0.attention.self.value.bias', 'encoder.layer.2.attention.output.dense.bias', 'encoder.layer.4.attention.self.key.weight', 'encoder.layer.5.attention.output.dense.bias', 'encoder.layer.4.attention.self.query.bias', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.9.attention.self.value.weight', 'encoder.layer.0.attention.self.key.weight', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.1.attention.self.query.weight', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.9.attention.self.value.bias', 'encoder.layer.4.attention.self.value.weight', 'encoder.layer.6.intermediate.dense.weight', 'pooler.dense.bias', 'encoder.layer.6.attention.output.LayerNorm.bias', 'encoder.layer.5.attention.self.key.weight', 'encoder.layer.10.output.dense.bias', 'encoder.layer.9.attention.output.LayerNorm.bias', 'encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.layer.7.attention.self.value.bias', 'encoder.layer.10.attention.self.value.bias', 'encoder.layer.11.attention.self.value.bias', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.6.attention.output.LayerNorm.weight', 'encoder.layer.5.attention.output.LayerNorm.weight', 'encoder.layer.10.attention.self.key.weight', 'encoder.layer.4.attention.output.LayerNorm.weight', 'encoder.layer.7.attention.output.dense.bias', 'encoder.layer.6.output.dense.weight', 'encoder.layer.5.attention.self.query.bias', 'encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.layer.0.attention.self.value.weight', 'encoder.layer.7.attention.output.LayerNorm.bias', 'encoder.layer.11.attention.self.query.weight', 'pooler.dense.weight', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.8.output.LayerNorm.weight', 'encoder.layer.8.attention.self.key.bias', 'encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.layer.2.attention.self.query.bias', 'encoder.layer.11.attention.output.dense.bias', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.6.output.dense.bias', 'embeddings.word_embeddings.weight', 'encoder.layer.9.output.dense.weight', 'encoder.layer.0.output.dense.weight', 'encoder.layer.7.attention.output.LayerNorm.weight', 'encoder.layer.8.output.LayerNorm.bias', 'encoder.layer.7.attention.self.value.weight', 'encoder.layer.8.attention.output.LayerNorm.weight', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.11.attention.self.key.bias', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.0.output.dense.bias', 'encoder.layer.5.attention.self.query.weight', 'encoder.layer.9.attention.output.dense.bias', 'encoder.layer.0.attention.output.dense.bias', 'encoder.layer.6.output.LayerNorm.bias', 'encoder.layer.11.attention.output.dense.weight', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.6.attention.self.key.bias', 'encoder.layer.6.attention.self.query.bias', 'encoder.layer.4.attention.output.LayerNorm.bias', 'encoder.layer.7.attention.self.query.weight', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.3.attention.output.dense.bias', 'encoder.layer.0.attention.self.query.weight', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.layer.10.attention.self.value.weight', 'encoder.layer.1.attention.self.value.weight', 'encoder.layer.4.attention.self.query.weight', 'encoder.layer.5.attention.self.value.bias', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.8.attention.self.key.weight', 'encoder.layer.3.attention.self.query.weight', 'encoder.layer.8.attention.self.query.weight', 'encoder.layer.7.output.dense.bias', 'embeddings.LayerNorm.bias', 'encoder.layer.1.attention.output.dense.bias', 'encoder.layer.2.attention.self.value.weight', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.3.attention.self.value.bias', 'encoder.layer.2.attention.output.LayerNorm.bias', 'encoder.layer.0.attention.self.query.bias', 'encoder.layer.7.intermediate.dense.bias', 'encoder.layer.3.attention.self.key.bias', 'embeddings.position_embeddings.weight', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.4.attention.self.value.bias', 'encoder.layer.4.attention.output.dense.bias', 'encoder.layer.5.output.dense.weight', 'encoder.layer.8.output.dense.weight', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.8.attention.output.dense.bias', 'encoder.layer.7.attention.output.dense.weight', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.7.output.LayerNorm.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
05/09/2022 18:36:21 - INFO - __main__ -   lang2id = None
05/09/2022 18:36:25 - INFO - __main__ -   Training/evaluation parameters Namespace(adam_epsilon=1e-08, cache_dir='', config_name='', data_dir=None, device=device(type='cuda'), do_eval=True, do_lower_case=False, do_train=False, doc_stride=128, eval_all_checkpoints=False, eval_lang='ru', evaluate_during_training=False, fp16=False, fp16_opt_level='O1', gradient_accumulation_steps=1, learning_rate=5e-05, local_rank=-1, logging_steps=50, max_answer_length=30, max_grad_norm=1.0, max_query_length=64, max_seq_length=384, max_steps=-1, model_name='xlm-KG', model_name_or_path='/cluster/home/yifhou/scratch_yifan/qa/xtreme_xlm/outputs-adapter//squad/xlm_LR1e-5_EPOCH2.0_maxlen384_batchsize8_gradacc2', model_type='xlm', modelkg_dir='/cluster/home/yifhou/scratch_yifan/qa/xtreme_xlm/adapter/xlm_adapter', n_best_size=20, n_gpu=1, no_cuda=False, null_score_diff_threshold=0.0, num_train_epochs=3.0, output_dir='/cluster/home/yifhou/scratch_yifan/qa/xtreme_xlm/outputs-adapter//squad/xlm_LR1e-5_EPOCH2.0_maxlen384_batchsize8_gradacc2/predictions/xquad/', overwrite_cache=False, overwrite_output_dir=False, per_gpu_eval_batch_size=8, per_gpu_train_batch_size=8, predict_file='/cluster/home/yifhou/scratch_yifan/qa/xtreme_xlm/download//xquad//xquad.ru.json', save_steps=50, seed=42, server_ip='', server_port='', threads=1, tokenizer_name='', train_file=None, train_lang='en', verbose_logging=False, version_2_with_negative=False, warmup_steps=0, weight_decay=0.0)
05/09/2022 18:36:25 - INFO - __main__ -   Loading checkpoint /cluster/home/yifhou/scratch_yifan/qa/xtreme_xlm/outputs-adapter//squad/xlm_LR1e-5_EPOCH2.0_maxlen384_batchsize8_gradacc2 for evaluation
05/09/2022 18:36:25 - INFO - __main__ -   Evaluate the following checkpoints: ['/cluster/home/yifhou/scratch_yifan/qa/xtreme_xlm/outputs-adapter//squad/xlm_LR1e-5_EPOCH2.0_maxlen384_batchsize8_gradacc2']
Some weights of the model checkpoint at /cluster/home/yifhou/scratch_yifan/qa/xtreme_xlm/outputs-adapter//squad/xlm_LR1e-5_EPOCH2.0_maxlen384_batchsize8_gradacc2 were not used when initializing XLMRobertaModel: ['qa_outputs.weight', 'base_model.encoder.layer.10.attention.self.key.bias', 'base_model.encoder.layer.6.intermediate.dense.weight', 'base_model.encoder.layer.9.attention.output.LayerNorm.weight', 'base_model.encoder.layer.0.attention.self.key.weight', 'base_model.embeddings.position_ids', 'base_model.encoder.layer.9.attention.self.query.bias', 'base_model.encoder.layer.4.output.LayerNorm.bias', 'base_model.encoder.layer.2.attention.output.dense.weight', 'base_model.encoder.layer.2.attention.self.key.bias', 'base_model.encoder.layer.3.attention.self.key.bias', 'base_model.encoder.layer.2.output.dense.bias', 'base_model.encoder.layer.9.attention.self.query.weight', 'base_model.embeddings.token_type_embeddings.weight', 'base_model.encoder.layer.3.output.dense.weight', 'base_model.encoder.layer.8.attention.self.value.weight', 'base_model.encoder.layer.5.attention.output.LayerNorm.bias', 'base_model.encoder.layer.9.attention.self.key.weight', 'base_model.encoder.layer.7.intermediate.dense.bias', 'base_model.encoder.layer.9.output.LayerNorm.bias', 'base_model.encoder.layer.5.attention.output.dense.bias', 'base_model.encoder.layer.10.attention.self.value.weight', 'base_model.encoder.layer.6.attention.self.value.bias', 'base_model.encoder.layer.6.attention.self.query.bias', 'base_model.encoder.layer.4.intermediate.dense.bias', 'base_model.encoder.layer.10.attention.self.value.bias', 'base_model.encoder.layer.11.attention.self.value.bias', 'base_model.encoder.layer.5.attention.self.query.weight', 'base_model.encoder.layer.0.output.dense.bias', 'base_model.encoder.layer.2.attention.self.key.weight', 'base_model.encoder.layer.9.attention.output.LayerNorm.bias', 'base_model.encoder.layer.11.attention.output.dense.bias', 'base_model.encoder.layer.11.attention.self.value.weight', 'base_model.encoder.layer.10.attention.output.LayerNorm.bias', 'base_model.encoder.layer.9.output.dense.weight', 'base_model.encoder.layer.7.attention.self.key.bias', 'base_model.encoder.layer.7.output.dense.bias', 'base_model.encoder.layer.8.attention.self.key.bias', 'base_model.encoder.layer.11.attention.self.query.weight', 'base_model.encoder.layer.10.output.dense.bias', 'base_model.encoder.layer.4.attention.self.value.bias', 'base_model.encoder.layer.2.intermediate.dense.weight', 'base_model.encoder.layer.3.attention.self.value.weight', 'base_model.encoder.layer.2.output.LayerNorm.bias', 'base_model.encoder.layer.6.output.LayerNorm.weight', 'base_model.encoder.layer.6.attention.self.key.bias', 'base_model.encoder.layer.10.attention.self.key.weight', 'base_model.encoder.layer.10.attention.self.query.bias', 'base_model.encoder.layer.6.attention.output.dense.bias', 'base_model.encoder.layer.7.attention.self.key.weight', 'base_model.encoder.layer.8.intermediate.dense.bias', 'base_model.encoder.layer.4.attention.self.value.weight', 'base_model.encoder.layer.0.attention.self.query.bias', 'base_model.encoder.layer.8.attention.self.query.weight', 'base_model.encoder.layer.0.attention.output.LayerNorm.bias', 'base_model.encoder.layer.3.intermediate.dense.weight', 'base_model.encoder.layer.2.attention.self.query.bias', 'base_model.encoder.layer.11.attention.self.key.bias', 'base_model.encoder.layer.4.output.LayerNorm.weight', 'base_model.encoder.layer.6.output.LayerNorm.bias', 'base_model.encoder.layer.0.output.dense.weight', 'base_model.encoder.layer.9.intermediate.dense.bias', 'base_model.encoder.layer.1.output.dense.bias', 'base_model.encoder.layer.1.attention.self.value.weight', 'base_model.encoder.layer.0.attention.output.dense.weight', 'base_model.encoder.layer.1.intermediate.dense.bias', 'base_model.encoder.layer.9.output.dense.bias', 'base_model.embeddings.LayerNorm.bias', 'base_model.encoder.layer.5.intermediate.dense.weight', 'base_model.encoder.layer.9.attention.self.key.bias', 'base_model.encoder.layer.10.output.LayerNorm.bias', 'base_model.encoder.layer.11.attention.output.dense.weight', 'base_model.encoder.layer.0.attention.output.dense.bias', 'base_model.encoder.layer.10.attention.output.LayerNorm.weight', 'base_model.encoder.layer.10.output.LayerNorm.weight', 'base_model.encoder.layer.5.attention.self.key.weight', 'base_model.encoder.layer.6.attention.self.query.weight', 'base_model.encoder.layer.8.output.dense.weight', 'base_model.embeddings.word_embeddings.weight', 'base_model.encoder.layer.11.attention.self.key.weight', 'base_model.encoder.layer.4.attention.output.dense.weight', 'base_model.encoder.layer.6.attention.output.dense.weight', 'base_model.encoder.layer.2.attention.self.value.weight', 'base_model.encoder.layer.2.intermediate.dense.bias', 'base_model.encoder.layer.7.attention.output.LayerNorm.weight', 'base_model.encoder.layer.0.output.LayerNorm.bias', 'base_model.encoder.layer.7.attention.output.dense.bias', 'base_model.encoder.layer.2.attention.self.value.bias', 'base_model.encoder.layer.3.attention.output.LayerNorm.weight', 'base_model.encoder.layer.5.attention.output.dense.weight', 'base_model.encoder.layer.10.attention.self.query.weight', 'base_model.encoder.layer.11.intermediate.dense.bias', 'base_model.encoder.layer.11.attention.output.LayerNorm.weight', 'base_model.encoder.layer.5.attention.self.value.bias', 'base_model.encoder.layer.5.output.dense.weight', 'base_model.encoder.layer.3.intermediate.dense.bias', 'base_model.encoder.layer.4.attention.self.query.bias', 'base_model.encoder.layer.10.attention.output.dense.bias', 'base_model.encoder.layer.10.output.dense.weight', 'base_model.encoder.layer.4.attention.self.query.weight', 'base_model.encoder.layer.2.attention.output.LayerNorm.weight', 'base_model.encoder.layer.6.output.dense.bias', 'base_model.encoder.layer.11.output.LayerNorm.bias', 'base_model.encoder.layer.0.attention.self.query.weight', 'base_model.encoder.layer.4.intermediate.dense.weight', 'base_model.encoder.layer.2.attention.output.dense.bias', 'base_model.encoder.layer.5.intermediate.dense.bias', 'base_model.encoder.layer.7.output.LayerNorm.bias', 'base_model.encoder.layer.10.intermediate.dense.weight', 'base_model.encoder.layer.4.attention.output.LayerNorm.bias', 'base_model.encoder.layer.7.attention.self.query.bias', 'base_model.encoder.layer.2.attention.self.query.weight', 'base_model.encoder.layer.5.attention.self.key.bias', 'base_model.encoder.layer.11.output.dense.bias', 'base_model.encoder.layer.8.attention.output.dense.weight', 'base_model.encoder.layer.1.attention.output.dense.bias', 'base_model.encoder.layer.3.attention.self.value.bias', 'base_model.encoder.layer.9.attention.output.dense.bias', 'base_model.encoder.layer.8.attention.output.LayerNorm.bias', 'base_model.encoder.layer.7.output.LayerNorm.weight', 'base_model.encoder.layer.6.attention.output.LayerNorm.bias', 'base_model.encoder.layer.8.attention.self.query.bias', 'base_model.encoder.layer.7.intermediate.dense.weight', 'base_model.embeddings.LayerNorm.weight', 'base_model.encoder.layer.1.attention.output.LayerNorm.weight', 'base_model.encoder.layer.5.attention.self.value.weight', 'base_model.encoder.layer.1.attention.self.key.weight', 'base_model.encoder.layer.1.output.dense.weight', 'base_model.encoder.layer.10.attention.output.dense.weight', 'base_model.encoder.layer.7.attention.output.dense.weight', 'base_model.encoder.layer.9.output.LayerNorm.weight', 'base_model.encoder.layer.11.attention.output.LayerNorm.bias', 'base_model.encoder.layer.0.attention.output.LayerNorm.weight', 'base_model.encoder.layer.5.attention.output.LayerNorm.weight', 'qa_outputs.bias', 'base_model.encoder.layer.11.output.LayerNorm.weight', 'base_model.encoder.layer.0.intermediate.dense.weight', 'base_model.encoder.layer.3.attention.self.query.weight', 'base_model.encoder.layer.2.attention.output.LayerNorm.bias', 'base_model.encoder.layer.0.attention.self.value.bias', 'base_model.encoder.layer.1.attention.self.query.bias', 'base_model.encoder.layer.3.attention.output.dense.weight', 'base_model.encoder.layer.3.attention.self.key.weight', 'base_model.encoder.layer.4.output.dense.weight', 'base_model.encoder.layer.0.intermediate.dense.bias', 'base_model.encoder.layer.3.attention.output.LayerNorm.bias', 'base_model.encoder.layer.8.output.dense.bias', 'base_model.encoder.layer.0.attention.self.value.weight', 'base_model.encoder.layer.3.output.LayerNorm.weight', 'base_model.encoder.layer.5.output.LayerNorm.weight', 'base_model.encoder.layer.7.output.dense.weight', 'base_model.encoder.layer.1.attention.self.query.weight', 'base_model.encoder.layer.4.attention.self.key.bias', 'base_model.encoder.layer.6.attention.self.value.weight', 'base_model.encoder.layer.9.attention.self.value.bias', 'base_model.encoder.layer.11.intermediate.dense.weight', 'base_model.encoder.layer.3.attention.self.query.bias', 'base_model.encoder.layer.3.output.dense.bias', 'base_model.encoder.layer.6.attention.self.key.weight', 'base_model.encoder.layer.6.attention.output.LayerNorm.weight', 'base_model.encoder.layer.6.output.dense.weight', 'base_model.encoder.layer.7.attention.self.value.bias', 'base_model.encoder.layer.0.attention.self.key.bias', 'base_model.encoder.layer.7.attention.self.value.weight', 'base_model.encoder.layer.4.attention.self.key.weight', 'base_model.encoder.layer.7.attention.output.LayerNorm.bias', 'base_model.encoder.layer.4.output.dense.bias', 'base_model.encoder.layer.8.attention.self.key.weight', 'base_model.encoder.layer.1.attention.self.key.bias', 'base_model.encoder.layer.11.output.dense.weight', 'base_model.embeddings.position_embeddings.weight', 'base_model.encoder.layer.2.output.dense.weight', 'base_model.encoder.layer.9.attention.output.dense.weight', 'base_model.encoder.layer.9.attention.self.value.weight', 'base_model.encoder.layer.2.output.LayerNorm.weight', 'base_model.encoder.layer.4.attention.output.dense.bias', 'base_model.encoder.layer.5.output.LayerNorm.bias', 'base_model.encoder.layer.1.attention.output.dense.weight', 'base_model.encoder.layer.3.attention.output.dense.bias', 'base_model.encoder.layer.8.output.LayerNorm.bias', 'base_model.encoder.layer.11.attention.self.query.bias', 'base_model.encoder.layer.9.intermediate.dense.weight', 'base_model.encoder.layer.1.output.LayerNorm.bias', 'base_model.encoder.layer.0.output.LayerNorm.weight', 'base_model.encoder.layer.1.attention.self.value.bias', 'base_model.encoder.layer.6.intermediate.dense.bias', 'base_model.encoder.layer.8.attention.output.LayerNorm.weight', 'base_model.encoder.layer.1.output.LayerNorm.weight', 'base_model.pooler.dense.bias', 'base_model.encoder.layer.7.attention.self.query.weight', 'base_model.encoder.layer.5.attention.self.query.bias', 'base_model.encoder.layer.8.attention.output.dense.bias', 'base_model.encoder.layer.5.output.dense.bias', 'base_model.encoder.layer.1.attention.output.LayerNorm.bias', 'base_model.encoder.layer.8.attention.self.value.bias', 'base_model.encoder.layer.8.intermediate.dense.weight', 'base_model.encoder.layer.1.intermediate.dense.weight', 'base_model.encoder.layer.10.intermediate.dense.bias', 'base_model.encoder.layer.8.output.LayerNorm.weight', 'base_model.pooler.dense.weight', 'base_model.encoder.layer.3.output.LayerNorm.bias', 'base_model.encoder.layer.4.attention.output.LayerNorm.weight']
- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of XLMRobertaModel were not initialized from the model checkpoint at /cluster/home/yifhou/scratch_yifan/qa/xtreme_xlm/outputs-adapter//squad/xlm_LR1e-5_EPOCH2.0_maxlen384_batchsize8_gradacc2 and are newly initialized: ['encoder.layer.2.attention.self.key.bias', 'encoder.layer.8.attention.self.value.weight', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.3.attention.self.value.weight', 'encoder.layer.5.attention.self.value.weight', 'encoder.layer.10.output.LayerNorm.bias', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.1.attention.output.LayerNorm.weight', 'encoder.layer.1.output.dense.bias', 'encoder.layer.2.attention.self.value.bias', 'encoder.layer.10.attention.self.key.bias', 'encoder.layer.11.attention.self.value.weight', 'encoder.layer.10.output.LayerNorm.weight', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.6.attention.self.value.bias', 'encoder.layer.0.attention.self.key.bias', 'embeddings.token_type_embeddings.weight', 'encoder.layer.1.attention.self.value.bias', 'encoder.layer.2.attention.output.LayerNorm.weight', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.7.attention.self.query.bias', 'encoder.layer.9.attention.self.query.bias', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.1.attention.self.key.weight', 'encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.10.attention.self.query.bias', 'encoder.layer.8.attention.output.LayerNorm.bias', 'encoder.layer.1.attention.self.query.bias', 'encoder.layer.9.attention.self.key.bias', 'encoder.layer.1.attention.self.key.bias', 'encoder.layer.10.attention.output.LayerNorm.bias', 'encoder.layer.10.attention.self.query.weight', 'encoder.layer.3.attention.self.query.bias', 'encoder.layer.11.output.dense.bias', 'encoder.layer.9.output.LayerNorm.bias', 'encoder.layer.6.attention.self.query.weight', 'encoder.layer.8.attention.self.query.bias', 'encoder.layer.11.attention.self.query.bias', 'encoder.layer.10.attention.output.dense.weight', 'encoder.layer.3.output.dense.bias', 'encoder.layer.11.attention.output.LayerNorm.weight', 'encoder.layer.10.intermediate.dense.weight', 'encoder.layer.9.attention.self.query.weight', 'encoder.layer.11.output.dense.weight', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.3.attention.output.dense.weight', 'encoder.layer.0.attention.output.dense.weight', 'encoder.layer.0.attention.output.LayerNorm.weight', 'encoder.layer.5.attention.output.dense.weight', 'encoder.layer.7.output.dense.weight', 'encoder.layer.4.output.dense.bias', 'encoder.layer.2.attention.self.query.weight', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.2.output.dense.bias', 'encoder.layer.2.output.dense.weight', 'encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.7.output.LayerNorm.bias', 'encoder.layer.5.attention.self.key.bias', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.9.attention.output.LayerNorm.weight', 'encoder.layer.6.attention.output.dense.weight', 'encoder.layer.11.output.LayerNorm.weight', 'encoder.layer.4.output.dense.weight', 'encoder.layer.6.attention.output.dense.bias', 'encoder.layer.1.attention.output.dense.weight', 'encoder.layer.10.attention.output.LayerNorm.weight', 'encoder.layer.2.attention.self.key.weight', 'encoder.layer.8.output.dense.bias', 'encoder.layer.5.output.dense.bias', 'embeddings.LayerNorm.weight', 'encoder.layer.4.attention.self.key.bias', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.layer.8.attention.output.dense.weight', 'encoder.layer.7.attention.self.key.weight', 'encoder.layer.10.attention.output.dense.bias', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.6.attention.self.value.weight', 'encoder.layer.9.output.LayerNorm.weight', 'encoder.layer.11.output.LayerNorm.bias', 'encoder.layer.4.attention.output.dense.weight', 'encoder.layer.1.output.dense.weight', 'encoder.layer.11.attention.self.key.weight', 'encoder.layer.8.attention.self.value.bias', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.3.output.dense.weight', 'encoder.layer.5.output.LayerNorm.bias', 'encoder.layer.3.attention.self.key.weight', 'encoder.layer.10.output.dense.weight', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.9.attention.self.key.weight', 'encoder.layer.6.attention.self.key.weight', 'encoder.layer.7.attention.self.key.bias', 'encoder.layer.2.attention.output.dense.weight', 'encoder.layer.9.output.dense.bias', 'encoder.layer.9.attention.output.dense.weight', 'encoder.layer.0.attention.self.value.bias', 'encoder.layer.2.attention.output.dense.bias', 'encoder.layer.4.attention.self.key.weight', 'encoder.layer.5.attention.output.dense.bias', 'encoder.layer.4.attention.self.query.bias', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.9.attention.self.value.weight', 'encoder.layer.0.attention.self.key.weight', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.1.attention.self.query.weight', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.9.attention.self.value.bias', 'encoder.layer.4.attention.self.value.weight', 'encoder.layer.6.intermediate.dense.weight', 'pooler.dense.bias', 'encoder.layer.6.attention.output.LayerNorm.bias', 'encoder.layer.5.attention.self.key.weight', 'encoder.layer.10.output.dense.bias', 'encoder.layer.9.attention.output.LayerNorm.bias', 'encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.layer.7.attention.self.value.bias', 'encoder.layer.10.attention.self.value.bias', 'encoder.layer.11.attention.self.value.bias', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.6.attention.output.LayerNorm.weight', 'encoder.layer.5.attention.output.LayerNorm.weight', 'encoder.layer.10.attention.self.key.weight', 'encoder.layer.4.attention.output.LayerNorm.weight', 'encoder.layer.7.attention.output.dense.bias', 'encoder.layer.6.output.dense.weight', 'encoder.layer.5.attention.self.query.bias', 'encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.layer.0.attention.self.value.weight', 'encoder.layer.7.attention.output.LayerNorm.bias', 'encoder.layer.11.attention.self.query.weight', 'pooler.dense.weight', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.8.output.LayerNorm.weight', 'encoder.layer.8.attention.self.key.bias', 'encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.layer.2.attention.self.query.bias', 'encoder.layer.11.attention.output.dense.bias', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.6.output.dense.bias', 'embeddings.word_embeddings.weight', 'encoder.layer.9.output.dense.weight', 'encoder.layer.0.output.dense.weight', 'encoder.layer.7.attention.output.LayerNorm.weight', 'encoder.layer.8.output.LayerNorm.bias', 'encoder.layer.7.attention.self.value.weight', 'encoder.layer.8.attention.output.LayerNorm.weight', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.11.attention.self.key.bias', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.0.output.dense.bias', 'encoder.layer.5.attention.self.query.weight', 'encoder.layer.9.attention.output.dense.bias', 'encoder.layer.0.attention.output.dense.bias', 'encoder.layer.6.output.LayerNorm.bias', 'encoder.layer.11.attention.output.dense.weight', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.6.attention.self.key.bias', 'encoder.layer.6.attention.self.query.bias', 'encoder.layer.4.attention.output.LayerNorm.bias', 'encoder.layer.7.attention.self.query.weight', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.3.attention.output.dense.bias', 'encoder.layer.0.attention.self.query.weight', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.layer.10.attention.self.value.weight', 'encoder.layer.1.attention.self.value.weight', 'encoder.layer.4.attention.self.query.weight', 'encoder.layer.5.attention.self.value.bias', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.8.attention.self.key.weight', 'encoder.layer.3.attention.self.query.weight', 'encoder.layer.8.attention.self.query.weight', 'encoder.layer.7.output.dense.bias', 'embeddings.LayerNorm.bias', 'encoder.layer.1.attention.output.dense.bias', 'encoder.layer.2.attention.self.value.weight', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.3.attention.self.value.bias', 'encoder.layer.2.attention.output.LayerNorm.bias', 'encoder.layer.0.attention.self.query.bias', 'encoder.layer.7.intermediate.dense.bias', 'encoder.layer.3.attention.self.key.bias', 'embeddings.position_embeddings.weight', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.4.attention.self.value.bias', 'encoder.layer.4.attention.output.dense.bias', 'encoder.layer.5.output.dense.weight', 'encoder.layer.8.output.dense.weight', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.8.attention.output.dense.bias', 'encoder.layer.7.attention.output.dense.weight', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.7.output.LayerNorm.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
05/09/2022 18:36:33 - INFO - __main__ -   Creating features from dataset file at .
/cluster/home/yifhou/scratch_yifan/qa/xtreme_xlm/outputs-adapter//squad/xlm_LR1e-5_EPOCH2.0_maxlen384_batchsize8_gradacc2
XLMConfig {
  "architectures": [
    "XLMRobertaForMaskedLM"
  ],
  "asm": false,
  "attention_dropout": 0.1,
  "attention_probs_dropout_prob": 0.1,
  "bos_index": 0,
  "bos_token_id": 0,
  "causal": false,
  "dropout": 0.1,
  "emb_dim": 768,
  "embed_init_std": 0.02209708691207961,
  "end_n_top": 5,
  "eos_index": 1,
  "eos_token_id": 2,
  "gelu_activation": true,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "init_std": 0.02,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "is_encoder": true,
  "lang_id": 0,
  "layer_norm_eps": 1e-05,
  "mask_index": 5,
  "mask_token_id": 0,
  "max_position_embeddings": 514,
  "model_type": "xlm",
  "n_heads": 12,
  "n_langs": 1,
  "n_layers": 12,
  "output_past": true,
  "pad_index": 2,
  "pad_token_id": 1,
  "sinusoidal_embeddings": false,
  "start_n_top": 5,
  "summary_activation": null,
  "summary_first_dropout": 0.1,
  "summary_proj_to_labels": true,
  "summary_type": "first",
  "summary_use_proj": true,
  "transformers_version": "4.17.0",
  "type_vocab_size": 1,
  "unk_index": 3,
  "use_lang_emb": false,
  "vocab_size": 250002
}

  0%|          | 0/48 [00:00<?, ?it/s] 25%|██▌       | 12/48 [00:00<00:00, 107.76it/s] 48%|████▊     | 23/48 [00:00<00:00, 88.62it/s]  69%|██████▉   | 33/48 [00:00<00:00, 91.46it/s] 90%|████████▉ | 43/48 [00:00<00:00, 93.23it/s]100%|██████████| 48/48 [00:00<00:00, 96.32it/s]
convert squad examples to features:   0%|          | 0/1190 [00:00<?, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.
convert squad examples to features:   0%|          | 1/1190 [00:00<03:34,  5.53it/s]convert squad examples to features:   5%|▌         | 65/1190 [00:00<00:05, 193.98it/s]convert squad examples to features:  11%|█         | 129/1190 [00:00<00:04, 257.78it/s]convert squad examples to features:  16%|█▌        | 193/1190 [00:00<00:03, 290.22it/s]convert squad examples to features:  19%|█▉        | 225/1190 [00:00<00:03, 295.51it/s]convert squad examples to features:  22%|██▏       | 257/1190 [00:01<00:03, 263.95it/s]convert squad examples to features:  24%|██▍       | 289/1190 [00:01<00:03, 266.29it/s]convert squad examples to features:  27%|██▋       | 321/1190 [00:01<00:03, 247.55it/s]convert squad examples to features:  30%|██▉       | 353/1190 [00:01<00:03, 256.64it/s]convert squad examples to features:  32%|███▏      | 385/1190 [00:01<00:05, 138.55it/s]convert squad examples to features:  35%|███▌      | 417/1190 [00:02<00:05, 151.65it/s]convert squad examples to features:  38%|███▊      | 449/1190 [00:02<00:04, 167.02it/s]convert squad examples to features:  40%|████      | 481/1190 [00:02<00:04, 171.36it/s]convert squad examples to features:  43%|████▎     | 513/1190 [00:02<00:03, 179.51it/s]convert squad examples to features:  46%|████▌     | 545/1190 [00:02<00:03, 186.97it/s]convert squad examples to features:  48%|████▊     | 577/1190 [00:02<00:03, 193.09it/s]convert squad examples to features:  51%|█████     | 609/1190 [00:03<00:02, 197.55it/s]convert squad examples to features:  54%|█████▍    | 641/1190 [00:03<00:02, 191.65it/s]convert squad examples to features:  57%|█████▋    | 673/1190 [00:03<00:02, 196.25it/s]convert squad examples to features:  59%|█████▉    | 705/1190 [00:03<00:02, 210.88it/s]convert squad examples to features:  62%|██████▏   | 737/1190 [00:03<00:02, 218.34it/s]convert squad examples to features:  65%|██████▍   | 769/1190 [00:03<00:01, 238.88it/s]convert squad examples to features:  67%|██████▋   | 801/1190 [00:03<00:01, 252.89it/s]convert squad examples to features:  70%|███████   | 833/1190 [00:04<00:01, 213.77it/s]convert squad examples to features:  73%|███████▎  | 865/1190 [00:04<00:01, 213.78it/s]convert squad examples to features:  75%|███████▌  | 897/1190 [00:04<00:01, 205.95it/s]convert squad examples to features:  78%|███████▊  | 929/1190 [00:04<00:01, 199.98it/s]convert squad examples to features:  81%|████████  | 961/1190 [00:04<00:01, 206.51it/s]convert squad examples to features:  83%|████████▎ | 993/1190 [00:04<00:00, 226.87it/s]convert squad examples to features:  89%|████████▉ | 1057/1190 [00:04<00:00, 256.19it/s]convert squad examples to features:  92%|█████████▏| 1089/1190 [00:05<00:00, 239.78it/s]convert squad examples to features:  94%|█████████▍| 1121/1190 [00:05<00:00, 232.12it/s]convert squad examples to features:  97%|█████████▋| 1153/1190 [00:05<00:00, 213.93it/s]convert squad examples to features: 100%|██████████| 1190/1190 [00:05<00:00, 217.44it/s]/cluster/project/sachan/yifan/softwares/anaconda/anaconda3/envs/xfactr/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2272: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

add example index and unique id:   0%|          | 0/1190 [00:00<?, ?it/s]add example index and unique id: 100%|██████████| 1190/1190 [00:00<00:00, 253786.64it/s]
05/09/2022 18:36:40 - INFO - __main__ -   Saving features into cached file ./cached_xquad.ru.json_xlm_LR1e-5_EPOCH2.0_maxlen384_batchsize8_gradacc2_384_ru
05/09/2022 18:36:41 - INFO - __main__ -   ***** Running evaluation  *****
05/09/2022 18:36:41 - INFO - __main__ -     Num examples = 1332
05/09/2022 18:36:41 - INFO - __main__ -     Batch size = 8
Evaluating:   0%|          | 0/167 [00:00<?, ?it/s]Evaluating:   1%|          | 1/167 [00:00<02:13,  1.25it/s]Evaluating:   2%|▏         | 3/167 [00:00<00:42,  3.87it/s]Evaluating:   3%|▎         | 5/167 [00:01<00:25,  6.28it/s]Evaluating:   4%|▍         | 7/167 [00:01<00:19,  8.38it/s]Evaluating:   5%|▌         | 9/167 [00:01<00:15, 10.13it/s]Evaluating:   7%|▋         | 11/167 [00:01<00:13, 11.53it/s]Evaluating:   8%|▊         | 13/167 [00:01<00:12, 12.49it/s]Evaluating:   9%|▉         | 15/167 [00:01<00:11, 13.22it/s]Evaluating:  10%|█         | 17/167 [00:01<00:10, 13.85it/s]Evaluating:  11%|█▏        | 19/167 [00:01<00:10, 14.30it/s]Evaluating:  13%|█▎        | 21/167 [00:02<00:09, 14.69it/s]Evaluating:  14%|█▍        | 23/167 [00:02<00:09, 14.96it/s]Evaluating:  15%|█▍        | 25/167 [00:02<00:09, 15.08it/s]Evaluating:  16%|█▌        | 27/167 [00:02<00:09, 15.21it/s]Evaluating:  17%|█▋        | 29/167 [00:02<00:09, 15.18it/s]Evaluating:  19%|█▊        | 31/167 [00:02<00:08, 15.29it/s]Evaluating:  20%|█▉        | 33/167 [00:02<00:08, 15.27it/s]Evaluating:  21%|██        | 35/167 [00:03<00:08, 15.33it/s]Evaluating:  22%|██▏       | 37/167 [00:03<00:08, 15.31it/s]Evaluating:  23%|██▎       | 39/167 [00:03<00:08, 15.29it/s]Evaluating:  25%|██▍       | 41/167 [00:03<00:08, 15.30it/s]Evaluating:  26%|██▌       | 43/167 [00:03<00:08, 15.29it/s]Evaluating:  27%|██▋       | 45/167 [00:03<00:07, 15.31it/s]Evaluating:  28%|██▊       | 47/167 [00:03<00:07, 15.34it/s]Evaluating:  29%|██▉       | 49/167 [00:03<00:07, 15.41it/s]Evaluating:  31%|███       | 51/167 [00:04<00:07, 15.46it/s]Evaluating:  32%|███▏      | 53/167 [00:04<00:07, 15.44it/s]Evaluating:  33%|███▎      | 55/167 [00:04<00:07, 15.42it/s]Evaluating:  34%|███▍      | 57/167 [00:04<00:07, 15.31it/s]Evaluating:  35%|███▌      | 59/167 [00:04<00:07, 15.22it/s]Evaluating:  37%|███▋      | 61/167 [00:04<00:06, 15.16it/s]Evaluating:  38%|███▊      | 63/167 [00:04<00:06, 15.17it/s]Evaluating:  39%|███▉      | 65/167 [00:04<00:06, 15.08it/s]Evaluating:  40%|████      | 67/167 [00:05<00:06, 15.19it/s]Evaluating:  41%|████▏     | 69/167 [00:05<00:06, 15.21it/s]Evaluating:  43%|████▎     | 71/167 [00:05<00:06, 15.24it/s]Evaluating:  44%|████▎     | 73/167 [00:05<00:06, 15.23it/s]Evaluating:  45%|████▍     | 75/167 [00:05<00:06, 15.30it/s]Evaluating:  46%|████▌     | 77/167 [00:05<00:05, 15.34it/s]Evaluating:  47%|████▋     | 79/167 [00:05<00:05, 15.22it/s]Evaluating:  49%|████▊     | 81/167 [00:06<00:05, 15.26it/s]Evaluating:  50%|████▉     | 83/167 [00:06<00:05, 15.27it/s]Evaluating:  51%|█████     | 85/167 [00:06<00:05, 15.29it/s]Evaluating:  52%|█████▏    | 87/167 [00:06<00:05, 15.29it/s]Evaluating:  53%|█████▎    | 89/167 [00:06<00:05, 15.30it/s]Evaluating:  54%|█████▍    | 91/167 [00:06<00:05, 15.16it/s]Evaluating:  56%|█████▌    | 93/167 [00:06<00:05, 14.62it/s]Evaluating:  57%|█████▋    | 95/167 [00:06<00:04, 14.86it/s]Evaluating:  58%|█████▊    | 97/167 [00:07<00:04, 15.06it/s]Evaluating:  59%|█████▉    | 99/167 [00:07<00:04, 14.17it/s]Evaluating:  60%|██████    | 101/167 [00:07<00:04, 14.52it/s]Evaluating:  62%|██████▏   | 103/167 [00:07<00:04, 14.68it/s]Evaluating:  63%|██████▎   | 105/167 [00:07<00:04, 14.80it/s]Evaluating:  64%|██████▍   | 107/167 [00:07<00:04, 14.93it/s]Evaluating:  65%|██████▌   | 109/167 [00:07<00:03, 15.06it/s]Evaluating:  66%|██████▋   | 111/167 [00:08<00:03, 15.19it/s]Evaluating:  68%|██████▊   | 113/167 [00:08<00:06,  8.71it/s]Evaluating:  69%|██████▉   | 115/167 [00:08<00:05,  9.97it/s]Evaluating:  70%|███████   | 117/167 [00:08<00:04, 11.07it/s]Evaluating:  71%|███████▏  | 119/167 [00:08<00:03, 12.09it/s]Evaluating:  72%|███████▏  | 121/167 [00:09<00:03, 12.84it/s]Evaluating:  74%|███████▎  | 123/167 [00:09<00:03, 13.45it/s]Evaluating:  75%|███████▍  | 125/167 [00:09<00:03, 13.94it/s]Evaluating:  76%|███████▌  | 127/167 [00:09<00:02, 14.23it/s]Evaluating:  77%|███████▋  | 129/167 [00:09<00:02, 14.54it/s]Evaluating:  78%|███████▊  | 131/167 [00:09<00:02, 14.71it/s]Evaluating:  80%|███████▉  | 133/167 [00:09<00:02, 14.81it/s]Evaluating:  81%|████████  | 135/167 [00:09<00:02, 14.93it/s]Evaluating:  82%|████████▏ | 137/167 [00:10<00:01, 15.06it/s]Evaluating:  83%|████████▎ | 139/167 [00:10<00:01, 15.08it/s]Evaluating:  84%|████████▍ | 141/167 [00:10<00:01, 15.08it/s]Evaluating:  86%|████████▌ | 143/167 [00:10<00:01, 15.07it/s]Evaluating:  87%|████████▋ | 145/167 [00:10<00:01, 15.10it/s]Evaluating:  88%|████████▊ | 147/167 [00:10<00:01, 15.13it/s]Evaluating:  89%|████████▉ | 149/167 [00:10<00:01, 15.20it/s]Evaluating:  90%|█████████ | 151/167 [00:11<00:01, 15.21it/s]Evaluating:  92%|█████████▏| 153/167 [00:11<00:00, 15.29it/s]Evaluating:  93%|█████████▎| 155/167 [00:11<00:00, 15.35it/s]Evaluating:  94%|█████████▍| 157/167 [00:11<00:00, 15.30it/s]Evaluating:  95%|█████████▌| 159/167 [00:11<00:00, 15.23it/s]Evaluating:  96%|█████████▋| 161/167 [00:11<00:00, 15.28it/s]Evaluating:  98%|█████████▊| 163/167 [00:11<00:00, 15.31it/s]Evaluating:  99%|█████████▉| 165/167 [00:11<00:00, 15.25it/s]Evaluating: 100%|██████████| 167/167 [00:12<00:00, 16.40it/s]Evaluating: 100%|██████████| 167/167 [00:12<00:00, 13.89it/s]
05/09/2022 18:36:53 - INFO - __main__ -     Evaluation done in total 12.023037 secs (0.009026 sec per example)
05/09/2022 18:36:57 - INFO - __main__ -   Results: {'exact': 55.714285714285715, 'f1': 71.96959357254902, 'total': 1190, 'HasAns_exact': 55.714285714285715, 'HasAns_f1': 71.96959357254902, 'HasAns_total': 1190, 'best_exact': 55.714285714285715, 'best_exact_thresh': 0.0, 'best_f1': 71.96959357254902, 'best_f1_thresh': 0.0}
  tr 
2022-05-09 18:37:00.316465: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0
05/09/2022 18:37:04 - WARNING - __main__ -   Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, 16-bits training: False
You are using a model of type xlm-roberta to instantiate a model of type xlm. This is not supported for all configurations of models and can yield errors.
Some weights of the model checkpoint at /cluster/home/yifhou/scratch_yifan/qa/xtreme_xlm/outputs-adapter//squad/xlm_LR1e-5_EPOCH2.0_maxlen384_batchsize8_gradacc2 were not used when initializing XLMRobertaModel: ['base_model.encoder.layer.6.attention.self.key.weight', 'base_model.encoder.layer.8.output.LayerNorm.bias', 'base_model.encoder.layer.7.attention.self.key.bias', 'base_model.encoder.layer.8.intermediate.dense.weight', 'base_model.encoder.layer.1.output.dense.bias', 'base_model.encoder.layer.9.output.dense.weight', 'base_model.encoder.layer.11.attention.self.value.bias', 'base_model.encoder.layer.1.attention.self.value.bias', 'base_model.encoder.layer.11.attention.self.key.weight', 'base_model.encoder.layer.7.attention.output.dense.weight', 'base_model.encoder.layer.11.attention.output.LayerNorm.bias', 'base_model.encoder.layer.6.intermediate.dense.bias', 'base_model.encoder.layer.3.output.dense.bias', 'base_model.encoder.layer.0.attention.output.LayerNorm.weight', 'base_model.encoder.layer.11.attention.output.LayerNorm.weight', 'base_model.encoder.layer.9.attention.self.query.weight', 'base_model.encoder.layer.0.attention.self.value.bias', 'base_model.encoder.layer.2.output.LayerNorm.bias', 'base_model.encoder.layer.6.intermediate.dense.weight', 'base_model.encoder.layer.6.attention.output.dense.weight', 'base_model.encoder.layer.7.attention.self.value.bias', 'base_model.encoder.layer.11.attention.self.query.weight', 'base_model.encoder.layer.10.output.LayerNorm.weight', 'base_model.encoder.layer.5.attention.self.key.bias', 'base_model.encoder.layer.3.attention.output.LayerNorm.bias', 'base_model.encoder.layer.4.output.dense.weight', 'base_model.encoder.layer.1.attention.self.value.weight', 'base_model.encoder.layer.11.attention.output.dense.weight', 'base_model.encoder.layer.6.output.LayerNorm.weight', 'base_model.encoder.layer.8.attention.self.value.weight', 'base_model.encoder.layer.1.output.LayerNorm.weight', 'base_model.encoder.layer.2.attention.self.key.bias', 'base_model.encoder.layer.9.attention.output.dense.weight', 'base_model.encoder.layer.9.output.LayerNorm.bias', 'base_model.encoder.layer.1.attention.self.key.weight', 'base_model.encoder.layer.4.output.dense.bias', 'base_model.encoder.layer.10.attention.output.LayerNorm.weight', 'base_model.encoder.layer.6.attention.self.query.weight', 'base_model.encoder.layer.6.output.LayerNorm.bias', 'base_model.encoder.layer.1.attention.output.dense.weight', 'base_model.encoder.layer.10.attention.output.dense.weight', 'base_model.encoder.layer.0.intermediate.dense.bias', 'base_model.encoder.layer.0.attention.self.query.weight', 'base_model.encoder.layer.4.attention.self.key.bias', 'base_model.encoder.layer.4.attention.self.query.bias', 'base_model.pooler.dense.weight', 'base_model.encoder.layer.8.attention.output.LayerNorm.bias', 'base_model.encoder.layer.5.output.LayerNorm.weight', 'base_model.encoder.layer.0.attention.self.key.weight', 'base_model.encoder.layer.1.output.dense.weight', 'base_model.encoder.layer.2.attention.self.value.weight', 'base_model.encoder.layer.8.attention.self.query.bias', 'base_model.encoder.layer.7.output.LayerNorm.weight', 'base_model.encoder.layer.10.attention.self.value.bias', 'base_model.encoder.layer.11.intermediate.dense.weight', 'base_model.encoder.layer.6.attention.self.query.bias', 'base_model.encoder.layer.3.output.dense.weight', 'base_model.encoder.layer.6.attention.self.key.bias', 'base_model.encoder.layer.8.attention.self.key.weight', 'base_model.encoder.layer.11.attention.self.key.bias', 'base_model.encoder.layer.3.attention.output.LayerNorm.weight', 'base_model.encoder.layer.0.attention.self.key.bias', 'base_model.encoder.layer.3.attention.output.dense.bias', 'base_model.pooler.dense.bias', 'base_model.encoder.layer.2.attention.self.query.bias', 'base_model.encoder.layer.9.attention.self.key.bias', 'base_model.encoder.layer.11.attention.output.dense.bias', 'base_model.encoder.layer.11.output.LayerNorm.weight', 'base_model.embeddings.LayerNorm.weight', 'base_model.encoder.layer.9.output.LayerNorm.weight', 'base_model.encoder.layer.8.attention.self.value.bias', 'base_model.encoder.layer.2.intermediate.dense.bias', 'base_model.encoder.layer.7.attention.self.value.weight', 'base_model.encoder.layer.2.attention.self.value.bias', 'base_model.encoder.layer.5.output.dense.bias', 'base_model.encoder.layer.7.intermediate.dense.bias', 'base_model.encoder.layer.8.output.dense.weight', 'base_model.encoder.layer.0.intermediate.dense.weight', 'base_model.encoder.layer.2.intermediate.dense.weight', 'base_model.encoder.layer.4.attention.self.query.weight', 'base_model.encoder.layer.1.intermediate.dense.bias', 'base_model.encoder.layer.1.output.LayerNorm.bias', 'base_model.encoder.layer.11.attention.self.value.weight', 'base_model.encoder.layer.10.attention.self.value.weight', 'base_model.encoder.layer.0.output.LayerNorm.weight', 'base_model.encoder.layer.4.attention.output.dense.bias', 'base_model.encoder.layer.11.output.dense.weight', 'base_model.encoder.layer.4.output.LayerNorm.weight', 'base_model.encoder.layer.4.output.LayerNorm.bias', 'base_model.encoder.layer.5.output.LayerNorm.bias', 'base_model.encoder.layer.9.intermediate.dense.weight', 'base_model.encoder.layer.3.output.LayerNorm.weight', 'base_model.encoder.layer.6.attention.self.value.bias', 'base_model.encoder.layer.1.attention.self.query.weight', 'base_model.encoder.layer.5.intermediate.dense.bias', 'base_model.encoder.layer.1.attention.self.query.bias', 'base_model.encoder.layer.3.attention.output.dense.weight', 'base_model.embeddings.LayerNorm.bias', 'base_model.encoder.layer.8.output.LayerNorm.weight', 'base_model.encoder.layer.10.output.dense.bias', 'base_model.encoder.layer.7.attention.output.dense.bias', 'base_model.encoder.layer.10.intermediate.dense.bias', 'base_model.encoder.layer.9.intermediate.dense.bias', 'base_model.encoder.layer.5.attention.self.query.weight', 'base_model.encoder.layer.2.attention.output.dense.bias', 'base_model.encoder.layer.8.output.dense.bias', 'base_model.encoder.layer.3.attention.self.value.weight', 'base_model.encoder.layer.5.output.dense.weight', 'base_model.encoder.layer.7.attention.self.query.weight', 'base_model.encoder.layer.3.attention.self.key.weight', 'base_model.encoder.layer.3.attention.self.query.weight', 'base_model.encoder.layer.4.attention.self.value.weight', 'base_model.encoder.layer.7.output.dense.weight', 'base_model.encoder.layer.6.attention.self.value.weight', 'base_model.encoder.layer.9.output.dense.bias', 'base_model.encoder.layer.1.attention.output.LayerNorm.bias', 'base_model.encoder.layer.3.intermediate.dense.weight', 'base_model.encoder.layer.3.intermediate.dense.bias', 'base_model.embeddings.position_embeddings.weight', 'base_model.encoder.layer.1.attention.output.dense.bias', 'base_model.encoder.layer.10.attention.output.dense.bias', 'base_model.encoder.layer.6.attention.output.dense.bias', 'base_model.encoder.layer.8.intermediate.dense.bias', 'base_model.encoder.layer.3.output.LayerNorm.bias', 'base_model.encoder.layer.0.attention.output.dense.weight', 'base_model.encoder.layer.11.intermediate.dense.bias', 'base_model.encoder.layer.10.attention.self.key.bias', 'qa_outputs.bias', 'base_model.encoder.layer.6.attention.output.LayerNorm.bias', 'base_model.encoder.layer.8.attention.self.query.weight', 'base_model.encoder.layer.6.attention.output.LayerNorm.weight', 'base_model.encoder.layer.0.attention.output.dense.bias', 'base_model.encoder.layer.11.output.dense.bias', 'base_model.encoder.layer.0.attention.output.LayerNorm.bias', 'base_model.encoder.layer.8.attention.output.dense.weight', 'base_model.encoder.layer.0.output.dense.weight', 'base_model.encoder.layer.2.attention.output.dense.weight', 'base_model.encoder.layer.5.attention.self.value.weight', 'base_model.encoder.layer.10.attention.self.query.bias', 'base_model.encoder.layer.9.attention.self.value.bias', 'base_model.encoder.layer.0.attention.self.query.bias', 'base_model.encoder.layer.2.attention.self.key.weight', 'base_model.encoder.layer.0.output.dense.bias', 'base_model.encoder.layer.4.attention.output.dense.weight', 'base_model.encoder.layer.9.attention.output.dense.bias', 'base_model.encoder.layer.5.attention.output.dense.weight', 'base_model.encoder.layer.10.output.dense.weight', 'base_model.encoder.layer.2.attention.output.LayerNorm.bias', 'base_model.encoder.layer.7.attention.output.LayerNorm.weight', 'base_model.encoder.layer.9.attention.self.value.weight', 'base_model.encoder.layer.8.attention.output.LayerNorm.weight', 'base_model.encoder.layer.5.attention.self.query.bias', 'base_model.encoder.layer.9.attention.output.LayerNorm.weight', 'base_model.encoder.layer.5.attention.output.dense.bias', 'base_model.encoder.layer.10.intermediate.dense.weight', 'base_model.encoder.layer.5.attention.output.LayerNorm.bias', 'base_model.encoder.layer.7.attention.output.LayerNorm.bias', 'qa_outputs.weight', 'base_model.encoder.layer.5.attention.self.key.weight', 'base_model.encoder.layer.8.attention.self.key.bias', 'base_model.embeddings.word_embeddings.weight', 'base_model.encoder.layer.7.intermediate.dense.weight', 'base_model.embeddings.token_type_embeddings.weight', 'base_model.encoder.layer.4.attention.output.LayerNorm.bias', 'base_model.encoder.layer.7.attention.self.key.weight', 'base_model.encoder.layer.3.attention.self.key.bias', 'base_model.encoder.layer.9.attention.output.LayerNorm.bias', 'base_model.encoder.layer.7.attention.self.query.bias', 'base_model.encoder.layer.3.attention.self.value.bias', 'base_model.encoder.layer.1.attention.self.key.bias', 'base_model.encoder.layer.6.output.dense.bias', 'base_model.encoder.layer.11.output.LayerNorm.bias', 'base_model.encoder.layer.1.attention.output.LayerNorm.weight', 'base_model.encoder.layer.9.attention.self.key.weight', 'base_model.embeddings.position_ids', 'base_model.encoder.layer.2.output.dense.bias', 'base_model.encoder.layer.5.intermediate.dense.weight', 'base_model.encoder.layer.4.attention.output.LayerNorm.weight', 'base_model.encoder.layer.10.attention.self.query.weight', 'base_model.encoder.layer.10.attention.output.LayerNorm.bias', 'base_model.encoder.layer.8.attention.output.dense.bias', 'base_model.encoder.layer.6.output.dense.weight', 'base_model.encoder.layer.3.attention.self.query.bias', 'base_model.encoder.layer.0.output.LayerNorm.bias', 'base_model.encoder.layer.4.attention.self.value.bias', 'base_model.encoder.layer.7.output.LayerNorm.bias', 'base_model.encoder.layer.1.intermediate.dense.weight', 'base_model.encoder.layer.11.attention.self.query.bias', 'base_model.encoder.layer.2.output.dense.weight', 'base_model.encoder.layer.4.attention.self.key.weight', 'base_model.encoder.layer.2.attention.self.query.weight', 'base_model.encoder.layer.2.attention.output.LayerNorm.weight', 'base_model.encoder.layer.5.attention.self.value.bias', 'base_model.encoder.layer.4.intermediate.dense.weight', 'base_model.encoder.layer.5.attention.output.LayerNorm.weight', 'base_model.encoder.layer.4.intermediate.dense.bias', 'base_model.encoder.layer.7.output.dense.bias', 'base_model.encoder.layer.9.attention.self.query.bias', 'base_model.encoder.layer.0.attention.self.value.weight', 'base_model.encoder.layer.2.output.LayerNorm.weight', 'base_model.encoder.layer.10.attention.self.key.weight', 'base_model.encoder.layer.10.output.LayerNorm.bias']
- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of XLMRobertaModel were not initialized from the model checkpoint at /cluster/home/yifhou/scratch_yifan/qa/xtreme_xlm/outputs-adapter//squad/xlm_LR1e-5_EPOCH2.0_maxlen384_batchsize8_gradacc2 and are newly initialized: ['encoder.layer.7.attention.self.query.bias', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.7.attention.output.dense.bias', 'encoder.layer.7.attention.output.dense.weight', 'encoder.layer.5.attention.self.query.bias', 'encoder.layer.9.attention.output.dense.weight', 'encoder.layer.8.attention.self.value.bias', 'encoder.layer.4.attention.self.value.weight', 'encoder.layer.1.attention.self.query.bias', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.11.output.LayerNorm.weight', 'encoder.layer.0.attention.self.key.bias', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.11.attention.self.key.bias', 'encoder.layer.10.intermediate.dense.weight', 'encoder.layer.4.attention.output.dense.bias', 'encoder.layer.4.attention.self.key.bias', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.1.attention.self.key.weight', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.1.attention.output.dense.weight', 'encoder.layer.11.attention.output.LayerNorm.weight', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.layer.8.attention.output.LayerNorm.bias', 'encoder.layer.7.attention.self.value.weight', 'encoder.layer.11.attention.self.value.weight', 'encoder.layer.9.attention.output.dense.bias', 'pooler.dense.bias', 'encoder.layer.5.output.dense.bias', 'encoder.layer.8.attention.output.dense.weight', 'encoder.layer.10.attention.self.query.weight', 'encoder.layer.2.attention.output.LayerNorm.bias', 'encoder.layer.0.attention.self.key.weight', 'encoder.layer.2.attention.self.key.bias', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.7.attention.output.LayerNorm.weight', 'encoder.layer.9.attention.self.value.weight', 'encoder.layer.1.attention.output.LayerNorm.weight', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.10.output.LayerNorm.weight', 'encoder.layer.3.attention.self.key.bias', 'encoder.layer.7.attention.self.key.weight', 'encoder.layer.2.attention.self.value.weight', 'encoder.layer.11.output.dense.bias', 'encoder.layer.0.attention.self.value.weight', 'encoder.layer.0.output.dense.weight', 'encoder.layer.10.attention.output.LayerNorm.bias', 'encoder.layer.0.attention.self.query.bias', 'pooler.dense.weight', 'encoder.layer.10.attention.self.value.bias', 'encoder.layer.9.attention.output.LayerNorm.weight', 'encoder.layer.9.attention.self.key.weight', 'encoder.layer.1.attention.self.value.bias', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.layer.6.attention.self.key.weight', 'embeddings.position_embeddings.weight', 'encoder.layer.4.attention.output.LayerNorm.bias', 'encoder.layer.8.output.dense.weight', 'encoder.layer.7.output.dense.weight', 'encoder.layer.10.attention.output.dense.bias', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.0.attention.self.value.bias', 'embeddings.word_embeddings.weight', 'encoder.layer.0.output.dense.bias', 'encoder.layer.1.attention.self.key.bias', 'encoder.layer.5.attention.self.key.weight', 'encoder.layer.1.attention.self.query.weight', 'encoder.layer.5.attention.self.value.weight', 'encoder.layer.6.output.LayerNorm.bias', 'encoder.layer.2.attention.self.query.bias', 'encoder.layer.3.attention.output.dense.bias', 'encoder.layer.5.attention.self.key.bias', 'encoder.layer.4.output.dense.bias', 'encoder.layer.0.attention.output.LayerNorm.weight', 'encoder.layer.1.output.dense.bias', 'encoder.layer.3.attention.output.dense.weight', 'encoder.layer.4.attention.self.value.bias', 'encoder.layer.6.output.dense.weight', 'encoder.layer.9.output.dense.weight', 'encoder.layer.11.attention.self.value.bias', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.7.attention.self.query.weight', 'encoder.layer.5.attention.output.LayerNorm.weight', 'encoder.layer.7.attention.output.LayerNorm.bias', 'encoder.layer.5.attention.self.query.weight', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.11.output.LayerNorm.bias', 'encoder.layer.8.output.dense.bias', 'encoder.layer.10.output.dense.weight', 'encoder.layer.9.output.LayerNorm.weight', 'encoder.layer.8.attention.self.key.bias', 'encoder.layer.8.attention.self.query.bias', 'encoder.layer.6.attention.self.value.weight', 'encoder.layer.11.attention.self.query.bias', 'embeddings.LayerNorm.weight', 'encoder.layer.8.attention.self.query.weight', 'encoder.layer.0.attention.output.dense.weight', 'encoder.layer.3.output.dense.bias', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.3.attention.self.value.bias', 'encoder.layer.6.attention.self.value.bias', 'encoder.layer.6.attention.self.key.bias', 'encoder.layer.10.output.dense.bias', 'encoder.layer.7.attention.self.key.bias', 'encoder.layer.10.attention.self.value.weight', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.9.attention.self.value.bias', 'encoder.layer.2.attention.output.dense.weight', 'encoder.layer.2.output.dense.bias', 'encoder.layer.9.attention.self.key.bias', 'encoder.layer.3.attention.self.query.bias', 'encoder.layer.11.attention.output.dense.weight', 'encoder.layer.0.attention.output.dense.bias', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.7.output.LayerNorm.bias', 'embeddings.LayerNorm.bias', 'encoder.layer.3.attention.self.query.weight', 'encoder.layer.4.output.dense.weight', 'encoder.layer.9.attention.output.LayerNorm.bias', 'encoder.layer.8.output.LayerNorm.weight', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.3.attention.self.key.weight', 'encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.layer.10.attention.self.key.weight', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.1.attention.self.value.weight', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.7.intermediate.dense.bias', 'encoder.layer.3.attention.self.value.weight', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.4.attention.self.query.bias', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.8.attention.output.LayerNorm.weight', 'encoder.layer.5.attention.output.dense.bias', 'encoder.layer.2.output.dense.weight', 'encoder.layer.5.attention.output.dense.weight', 'encoder.layer.7.output.dense.bias', 'encoder.layer.10.output.LayerNorm.bias', 'encoder.layer.10.attention.self.key.bias', 'encoder.layer.6.output.dense.bias', 'encoder.layer.6.attention.self.query.weight', 'encoder.layer.9.attention.self.query.weight', 'encoder.layer.2.attention.output.LayerNorm.weight', 'encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.6.attention.output.dense.bias', 'encoder.layer.1.attention.output.dense.bias', 'encoder.layer.7.output.LayerNorm.weight', 'encoder.layer.1.output.dense.weight', 'encoder.layer.8.attention.self.key.weight', 'encoder.layer.11.attention.output.dense.bias', 'encoder.layer.2.attention.output.dense.bias', 'encoder.layer.9.output.LayerNorm.bias', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.5.attention.self.value.bias', 'encoder.layer.4.attention.output.LayerNorm.weight', 'encoder.layer.11.attention.self.key.weight', 'encoder.layer.6.attention.output.dense.weight', 'encoder.layer.6.attention.output.LayerNorm.bias', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.11.output.dense.weight', 'encoder.layer.10.attention.self.query.bias', 'encoder.layer.11.attention.self.query.weight', 'encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.layer.2.attention.self.value.bias', 'encoder.layer.0.attention.self.query.weight', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.3.output.dense.weight', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.4.attention.self.query.weight', 'encoder.layer.2.attention.self.key.weight', 'encoder.layer.9.output.dense.bias', 'encoder.layer.8.attention.output.dense.bias', 'encoder.layer.8.intermediate.dense.weight', 'embeddings.token_type_embeddings.weight', 'encoder.layer.9.attention.self.query.bias', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.4.attention.self.key.weight', 'encoder.layer.6.attention.output.LayerNorm.weight', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.8.attention.self.value.weight', 'encoder.layer.2.attention.self.query.weight', 'encoder.layer.10.attention.output.LayerNorm.weight', 'encoder.layer.5.output.dense.weight', 'encoder.layer.10.attention.output.dense.weight', 'encoder.layer.4.attention.output.dense.weight', 'encoder.layer.6.attention.self.query.bias', 'encoder.layer.5.output.LayerNorm.bias', 'encoder.layer.8.output.LayerNorm.bias', 'encoder.layer.7.attention.self.value.bias', 'encoder.layer.1.attention.output.LayerNorm.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
05/09/2022 18:37:11 - INFO - __main__ -   lang2id = None
05/09/2022 18:37:14 - INFO - __main__ -   Training/evaluation parameters Namespace(adam_epsilon=1e-08, cache_dir='', config_name='', data_dir=None, device=device(type='cuda'), do_eval=True, do_lower_case=False, do_train=False, doc_stride=128, eval_all_checkpoints=False, eval_lang='tr', evaluate_during_training=False, fp16=False, fp16_opt_level='O1', gradient_accumulation_steps=1, learning_rate=5e-05, local_rank=-1, logging_steps=50, max_answer_length=30, max_grad_norm=1.0, max_query_length=64, max_seq_length=384, max_steps=-1, model_name='xlm-KG', model_name_or_path='/cluster/home/yifhou/scratch_yifan/qa/xtreme_xlm/outputs-adapter//squad/xlm_LR1e-5_EPOCH2.0_maxlen384_batchsize8_gradacc2', model_type='xlm', modelkg_dir='/cluster/home/yifhou/scratch_yifan/qa/xtreme_xlm/adapter/xlm_adapter', n_best_size=20, n_gpu=1, no_cuda=False, null_score_diff_threshold=0.0, num_train_epochs=3.0, output_dir='/cluster/home/yifhou/scratch_yifan/qa/xtreme_xlm/outputs-adapter//squad/xlm_LR1e-5_EPOCH2.0_maxlen384_batchsize8_gradacc2/predictions/xquad/', overwrite_cache=False, overwrite_output_dir=False, per_gpu_eval_batch_size=8, per_gpu_train_batch_size=8, predict_file='/cluster/home/yifhou/scratch_yifan/qa/xtreme_xlm/download//xquad//xquad.tr.json', save_steps=50, seed=42, server_ip='', server_port='', threads=1, tokenizer_name='', train_file=None, train_lang='en', verbose_logging=False, version_2_with_negative=False, warmup_steps=0, weight_decay=0.0)
05/09/2022 18:37:14 - INFO - __main__ -   Loading checkpoint /cluster/home/yifhou/scratch_yifan/qa/xtreme_xlm/outputs-adapter//squad/xlm_LR1e-5_EPOCH2.0_maxlen384_batchsize8_gradacc2 for evaluation
05/09/2022 18:37:14 - INFO - __main__ -   Evaluate the following checkpoints: ['/cluster/home/yifhou/scratch_yifan/qa/xtreme_xlm/outputs-adapter//squad/xlm_LR1e-5_EPOCH2.0_maxlen384_batchsize8_gradacc2']
Some weights of the model checkpoint at /cluster/home/yifhou/scratch_yifan/qa/xtreme_xlm/outputs-adapter//squad/xlm_LR1e-5_EPOCH2.0_maxlen384_batchsize8_gradacc2 were not used when initializing XLMRobertaModel: ['base_model.encoder.layer.6.attention.self.key.weight', 'base_model.encoder.layer.8.output.LayerNorm.bias', 'base_model.encoder.layer.7.attention.self.key.bias', 'base_model.encoder.layer.8.intermediate.dense.weight', 'base_model.encoder.layer.1.output.dense.bias', 'base_model.encoder.layer.9.output.dense.weight', 'base_model.encoder.layer.11.attention.self.value.bias', 'base_model.encoder.layer.1.attention.self.value.bias', 'base_model.encoder.layer.11.attention.self.key.weight', 'base_model.encoder.layer.7.attention.output.dense.weight', 'base_model.encoder.layer.11.attention.output.LayerNorm.bias', 'base_model.encoder.layer.6.intermediate.dense.bias', 'base_model.encoder.layer.3.output.dense.bias', 'base_model.encoder.layer.0.attention.output.LayerNorm.weight', 'base_model.encoder.layer.11.attention.output.LayerNorm.weight', 'base_model.encoder.layer.9.attention.self.query.weight', 'base_model.encoder.layer.0.attention.self.value.bias', 'base_model.encoder.layer.2.output.LayerNorm.bias', 'base_model.encoder.layer.6.intermediate.dense.weight', 'base_model.encoder.layer.6.attention.output.dense.weight', 'base_model.encoder.layer.7.attention.self.value.bias', 'base_model.encoder.layer.11.attention.self.query.weight', 'base_model.encoder.layer.10.output.LayerNorm.weight', 'base_model.encoder.layer.5.attention.self.key.bias', 'base_model.encoder.layer.3.attention.output.LayerNorm.bias', 'base_model.encoder.layer.4.output.dense.weight', 'base_model.encoder.layer.1.attention.self.value.weight', 'base_model.encoder.layer.11.attention.output.dense.weight', 'base_model.encoder.layer.6.output.LayerNorm.weight', 'base_model.encoder.layer.8.attention.self.value.weight', 'base_model.encoder.layer.1.output.LayerNorm.weight', 'base_model.encoder.layer.2.attention.self.key.bias', 'base_model.encoder.layer.9.attention.output.dense.weight', 'base_model.encoder.layer.9.output.LayerNorm.bias', 'base_model.encoder.layer.1.attention.self.key.weight', 'base_model.encoder.layer.4.output.dense.bias', 'base_model.encoder.layer.10.attention.output.LayerNorm.weight', 'base_model.encoder.layer.6.attention.self.query.weight', 'base_model.encoder.layer.6.output.LayerNorm.bias', 'base_model.encoder.layer.1.attention.output.dense.weight', 'base_model.encoder.layer.10.attention.output.dense.weight', 'base_model.encoder.layer.0.intermediate.dense.bias', 'base_model.encoder.layer.0.attention.self.query.weight', 'base_model.encoder.layer.4.attention.self.key.bias', 'base_model.encoder.layer.4.attention.self.query.bias', 'base_model.pooler.dense.weight', 'base_model.encoder.layer.8.attention.output.LayerNorm.bias', 'base_model.encoder.layer.5.output.LayerNorm.weight', 'base_model.encoder.layer.0.attention.self.key.weight', 'base_model.encoder.layer.1.output.dense.weight', 'base_model.encoder.layer.2.attention.self.value.weight', 'base_model.encoder.layer.8.attention.self.query.bias', 'base_model.encoder.layer.7.output.LayerNorm.weight', 'base_model.encoder.layer.10.attention.self.value.bias', 'base_model.encoder.layer.11.intermediate.dense.weight', 'base_model.encoder.layer.6.attention.self.query.bias', 'base_model.encoder.layer.3.output.dense.weight', 'base_model.encoder.layer.6.attention.self.key.bias', 'base_model.encoder.layer.8.attention.self.key.weight', 'base_model.encoder.layer.11.attention.self.key.bias', 'base_model.encoder.layer.3.attention.output.LayerNorm.weight', 'base_model.encoder.layer.0.attention.self.key.bias', 'base_model.encoder.layer.3.attention.output.dense.bias', 'base_model.pooler.dense.bias', 'base_model.encoder.layer.2.attention.self.query.bias', 'base_model.encoder.layer.9.attention.self.key.bias', 'base_model.encoder.layer.11.attention.output.dense.bias', 'base_model.encoder.layer.11.output.LayerNorm.weight', 'base_model.embeddings.LayerNorm.weight', 'base_model.encoder.layer.9.output.LayerNorm.weight', 'base_model.encoder.layer.8.attention.self.value.bias', 'base_model.encoder.layer.2.intermediate.dense.bias', 'base_model.encoder.layer.7.attention.self.value.weight', 'base_model.encoder.layer.2.attention.self.value.bias', 'base_model.encoder.layer.5.output.dense.bias', 'base_model.encoder.layer.7.intermediate.dense.bias', 'base_model.encoder.layer.8.output.dense.weight', 'base_model.encoder.layer.0.intermediate.dense.weight', 'base_model.encoder.layer.2.intermediate.dense.weight', 'base_model.encoder.layer.4.attention.self.query.weight', 'base_model.encoder.layer.1.intermediate.dense.bias', 'base_model.encoder.layer.1.output.LayerNorm.bias', 'base_model.encoder.layer.11.attention.self.value.weight', 'base_model.encoder.layer.10.attention.self.value.weight', 'base_model.encoder.layer.0.output.LayerNorm.weight', 'base_model.encoder.layer.4.attention.output.dense.bias', 'base_model.encoder.layer.11.output.dense.weight', 'base_model.encoder.layer.4.output.LayerNorm.weight', 'base_model.encoder.layer.4.output.LayerNorm.bias', 'base_model.encoder.layer.5.output.LayerNorm.bias', 'base_model.encoder.layer.9.intermediate.dense.weight', 'base_model.encoder.layer.3.output.LayerNorm.weight', 'base_model.encoder.layer.6.attention.self.value.bias', 'base_model.encoder.layer.1.attention.self.query.weight', 'base_model.encoder.layer.5.intermediate.dense.bias', 'base_model.encoder.layer.1.attention.self.query.bias', 'base_model.encoder.layer.3.attention.output.dense.weight', 'base_model.embeddings.LayerNorm.bias', 'base_model.encoder.layer.8.output.LayerNorm.weight', 'base_model.encoder.layer.10.output.dense.bias', 'base_model.encoder.layer.7.attention.output.dense.bias', 'base_model.encoder.layer.10.intermediate.dense.bias', 'base_model.encoder.layer.9.intermediate.dense.bias', 'base_model.encoder.layer.5.attention.self.query.weight', 'base_model.encoder.layer.2.attention.output.dense.bias', 'base_model.encoder.layer.8.output.dense.bias', 'base_model.encoder.layer.3.attention.self.value.weight', 'base_model.encoder.layer.5.output.dense.weight', 'base_model.encoder.layer.7.attention.self.query.weight', 'base_model.encoder.layer.3.attention.self.key.weight', 'base_model.encoder.layer.3.attention.self.query.weight', 'base_model.encoder.layer.4.attention.self.value.weight', 'base_model.encoder.layer.7.output.dense.weight', 'base_model.encoder.layer.6.attention.self.value.weight', 'base_model.encoder.layer.9.output.dense.bias', 'base_model.encoder.layer.1.attention.output.LayerNorm.bias', 'base_model.encoder.layer.3.intermediate.dense.weight', 'base_model.encoder.layer.3.intermediate.dense.bias', 'base_model.embeddings.position_embeddings.weight', 'base_model.encoder.layer.1.attention.output.dense.bias', 'base_model.encoder.layer.10.attention.output.dense.bias', 'base_model.encoder.layer.6.attention.output.dense.bias', 'base_model.encoder.layer.8.intermediate.dense.bias', 'base_model.encoder.layer.3.output.LayerNorm.bias', 'base_model.encoder.layer.0.attention.output.dense.weight', 'base_model.encoder.layer.11.intermediate.dense.bias', 'base_model.encoder.layer.10.attention.self.key.bias', 'qa_outputs.bias', 'base_model.encoder.layer.6.attention.output.LayerNorm.bias', 'base_model.encoder.layer.8.attention.self.query.weight', 'base_model.encoder.layer.6.attention.output.LayerNorm.weight', 'base_model.encoder.layer.0.attention.output.dense.bias', 'base_model.encoder.layer.11.output.dense.bias', 'base_model.encoder.layer.0.attention.output.LayerNorm.bias', 'base_model.encoder.layer.8.attention.output.dense.weight', 'base_model.encoder.layer.0.output.dense.weight', 'base_model.encoder.layer.2.attention.output.dense.weight', 'base_model.encoder.layer.5.attention.self.value.weight', 'base_model.encoder.layer.10.attention.self.query.bias', 'base_model.encoder.layer.9.attention.self.value.bias', 'base_model.encoder.layer.0.attention.self.query.bias', 'base_model.encoder.layer.2.attention.self.key.weight', 'base_model.encoder.layer.0.output.dense.bias', 'base_model.encoder.layer.4.attention.output.dense.weight', 'base_model.encoder.layer.9.attention.output.dense.bias', 'base_model.encoder.layer.5.attention.output.dense.weight', 'base_model.encoder.layer.10.output.dense.weight', 'base_model.encoder.layer.2.attention.output.LayerNorm.bias', 'base_model.encoder.layer.7.attention.output.LayerNorm.weight', 'base_model.encoder.layer.9.attention.self.value.weight', 'base_model.encoder.layer.8.attention.output.LayerNorm.weight', 'base_model.encoder.layer.5.attention.self.query.bias', 'base_model.encoder.layer.9.attention.output.LayerNorm.weight', 'base_model.encoder.layer.5.attention.output.dense.bias', 'base_model.encoder.layer.10.intermediate.dense.weight', 'base_model.encoder.layer.5.attention.output.LayerNorm.bias', 'base_model.encoder.layer.7.attention.output.LayerNorm.bias', 'qa_outputs.weight', 'base_model.encoder.layer.5.attention.self.key.weight', 'base_model.encoder.layer.8.attention.self.key.bias', 'base_model.embeddings.word_embeddings.weight', 'base_model.encoder.layer.7.intermediate.dense.weight', 'base_model.embeddings.token_type_embeddings.weight', 'base_model.encoder.layer.4.attention.output.LayerNorm.bias', 'base_model.encoder.layer.7.attention.self.key.weight', 'base_model.encoder.layer.3.attention.self.key.bias', 'base_model.encoder.layer.9.attention.output.LayerNorm.bias', 'base_model.encoder.layer.7.attention.self.query.bias', 'base_model.encoder.layer.3.attention.self.value.bias', 'base_model.encoder.layer.1.attention.self.key.bias', 'base_model.encoder.layer.6.output.dense.bias', 'base_model.encoder.layer.11.output.LayerNorm.bias', 'base_model.encoder.layer.1.attention.output.LayerNorm.weight', 'base_model.encoder.layer.9.attention.self.key.weight', 'base_model.embeddings.position_ids', 'base_model.encoder.layer.2.output.dense.bias', 'base_model.encoder.layer.5.intermediate.dense.weight', 'base_model.encoder.layer.4.attention.output.LayerNorm.weight', 'base_model.encoder.layer.10.attention.self.query.weight', 'base_model.encoder.layer.10.attention.output.LayerNorm.bias', 'base_model.encoder.layer.8.attention.output.dense.bias', 'base_model.encoder.layer.6.output.dense.weight', 'base_model.encoder.layer.3.attention.self.query.bias', 'base_model.encoder.layer.0.output.LayerNorm.bias', 'base_model.encoder.layer.4.attention.self.value.bias', 'base_model.encoder.layer.7.output.LayerNorm.bias', 'base_model.encoder.layer.1.intermediate.dense.weight', 'base_model.encoder.layer.11.attention.self.query.bias', 'base_model.encoder.layer.2.output.dense.weight', 'base_model.encoder.layer.4.attention.self.key.weight', 'base_model.encoder.layer.2.attention.self.query.weight', 'base_model.encoder.layer.2.attention.output.LayerNorm.weight', 'base_model.encoder.layer.5.attention.self.value.bias', 'base_model.encoder.layer.4.intermediate.dense.weight', 'base_model.encoder.layer.5.attention.output.LayerNorm.weight', 'base_model.encoder.layer.4.intermediate.dense.bias', 'base_model.encoder.layer.7.output.dense.bias', 'base_model.encoder.layer.9.attention.self.query.bias', 'base_model.encoder.layer.0.attention.self.value.weight', 'base_model.encoder.layer.2.output.LayerNorm.weight', 'base_model.encoder.layer.10.attention.self.key.weight', 'base_model.encoder.layer.10.output.LayerNorm.bias']
- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of XLMRobertaModel were not initialized from the model checkpoint at /cluster/home/yifhou/scratch_yifan/qa/xtreme_xlm/outputs-adapter//squad/xlm_LR1e-5_EPOCH2.0_maxlen384_batchsize8_gradacc2 and are newly initialized: ['encoder.layer.7.attention.self.query.bias', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.7.attention.output.dense.bias', 'encoder.layer.7.attention.output.dense.weight', 'encoder.layer.5.attention.self.query.bias', 'encoder.layer.9.attention.output.dense.weight', 'encoder.layer.8.attention.self.value.bias', 'encoder.layer.4.attention.self.value.weight', 'encoder.layer.1.attention.self.query.bias', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.11.output.LayerNorm.weight', 'encoder.layer.0.attention.self.key.bias', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.11.attention.self.key.bias', 'encoder.layer.10.intermediate.dense.weight', 'encoder.layer.4.attention.output.dense.bias', 'encoder.layer.4.attention.self.key.bias', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.1.attention.self.key.weight', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.1.attention.output.dense.weight', 'encoder.layer.11.attention.output.LayerNorm.weight', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.layer.8.attention.output.LayerNorm.bias', 'encoder.layer.7.attention.self.value.weight', 'encoder.layer.11.attention.self.value.weight', 'encoder.layer.9.attention.output.dense.bias', 'pooler.dense.bias', 'encoder.layer.5.output.dense.bias', 'encoder.layer.8.attention.output.dense.weight', 'encoder.layer.10.attention.self.query.weight', 'encoder.layer.2.attention.output.LayerNorm.bias', 'encoder.layer.0.attention.self.key.weight', 'encoder.layer.2.attention.self.key.bias', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.7.attention.output.LayerNorm.weight', 'encoder.layer.9.attention.self.value.weight', 'encoder.layer.1.attention.output.LayerNorm.weight', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.10.output.LayerNorm.weight', 'encoder.layer.3.attention.self.key.bias', 'encoder.layer.7.attention.self.key.weight', 'encoder.layer.2.attention.self.value.weight', 'encoder.layer.11.output.dense.bias', 'encoder.layer.0.attention.self.value.weight', 'encoder.layer.0.output.dense.weight', 'encoder.layer.10.attention.output.LayerNorm.bias', 'encoder.layer.0.attention.self.query.bias', 'pooler.dense.weight', 'encoder.layer.10.attention.self.value.bias', 'encoder.layer.9.attention.output.LayerNorm.weight', 'encoder.layer.9.attention.self.key.weight', 'encoder.layer.1.attention.self.value.bias', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.layer.6.attention.self.key.weight', 'embeddings.position_embeddings.weight', 'encoder.layer.4.attention.output.LayerNorm.bias', 'encoder.layer.8.output.dense.weight', 'encoder.layer.7.output.dense.weight', 'encoder.layer.10.attention.output.dense.bias', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.0.attention.self.value.bias', 'embeddings.word_embeddings.weight', 'encoder.layer.0.output.dense.bias', 'encoder.layer.1.attention.self.key.bias', 'encoder.layer.5.attention.self.key.weight', 'encoder.layer.1.attention.self.query.weight', 'encoder.layer.5.attention.self.value.weight', 'encoder.layer.6.output.LayerNorm.bias', 'encoder.layer.2.attention.self.query.bias', 'encoder.layer.3.attention.output.dense.bias', 'encoder.layer.5.attention.self.key.bias', 'encoder.layer.4.output.dense.bias', 'encoder.layer.0.attention.output.LayerNorm.weight', 'encoder.layer.1.output.dense.bias', 'encoder.layer.3.attention.output.dense.weight', 'encoder.layer.4.attention.self.value.bias', 'encoder.layer.6.output.dense.weight', 'encoder.layer.9.output.dense.weight', 'encoder.layer.11.attention.self.value.bias', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.7.attention.self.query.weight', 'encoder.layer.5.attention.output.LayerNorm.weight', 'encoder.layer.7.attention.output.LayerNorm.bias', 'encoder.layer.5.attention.self.query.weight', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.11.output.LayerNorm.bias', 'encoder.layer.8.output.dense.bias', 'encoder.layer.10.output.dense.weight', 'encoder.layer.9.output.LayerNorm.weight', 'encoder.layer.8.attention.self.key.bias', 'encoder.layer.8.attention.self.query.bias', 'encoder.layer.6.attention.self.value.weight', 'encoder.layer.11.attention.self.query.bias', 'embeddings.LayerNorm.weight', 'encoder.layer.8.attention.self.query.weight', 'encoder.layer.0.attention.output.dense.weight', 'encoder.layer.3.output.dense.bias', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.3.attention.self.value.bias', 'encoder.layer.6.attention.self.value.bias', 'encoder.layer.6.attention.self.key.bias', 'encoder.layer.10.output.dense.bias', 'encoder.layer.7.attention.self.key.bias', 'encoder.layer.10.attention.self.value.weight', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.9.attention.self.value.bias', 'encoder.layer.2.attention.output.dense.weight', 'encoder.layer.2.output.dense.bias', 'encoder.layer.9.attention.self.key.bias', 'encoder.layer.3.attention.self.query.bias', 'encoder.layer.11.attention.output.dense.weight', 'encoder.layer.0.attention.output.dense.bias', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.7.output.LayerNorm.bias', 'embeddings.LayerNorm.bias', 'encoder.layer.3.attention.self.query.weight', 'encoder.layer.4.output.dense.weight', 'encoder.layer.9.attention.output.LayerNorm.bias', 'encoder.layer.8.output.LayerNorm.weight', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.3.attention.self.key.weight', 'encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.layer.10.attention.self.key.weight', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.1.attention.self.value.weight', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.7.intermediate.dense.bias', 'encoder.layer.3.attention.self.value.weight', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.4.attention.self.query.bias', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.8.attention.output.LayerNorm.weight', 'encoder.layer.5.attention.output.dense.bias', 'encoder.layer.2.output.dense.weight', 'encoder.layer.5.attention.output.dense.weight', 'encoder.layer.7.output.dense.bias', 'encoder.layer.10.output.LayerNorm.bias', 'encoder.layer.10.attention.self.key.bias', 'encoder.layer.6.output.dense.bias', 'encoder.layer.6.attention.self.query.weight', 'encoder.layer.9.attention.self.query.weight', 'encoder.layer.2.attention.output.LayerNorm.weight', 'encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.6.attention.output.dense.bias', 'encoder.layer.1.attention.output.dense.bias', 'encoder.layer.7.output.LayerNorm.weight', 'encoder.layer.1.output.dense.weight', 'encoder.layer.8.attention.self.key.weight', 'encoder.layer.11.attention.output.dense.bias', 'encoder.layer.2.attention.output.dense.bias', 'encoder.layer.9.output.LayerNorm.bias', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.5.attention.self.value.bias', 'encoder.layer.4.attention.output.LayerNorm.weight', 'encoder.layer.11.attention.self.key.weight', 'encoder.layer.6.attention.output.dense.weight', 'encoder.layer.6.attention.output.LayerNorm.bias', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.11.output.dense.weight', 'encoder.layer.10.attention.self.query.bias', 'encoder.layer.11.attention.self.query.weight', 'encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.layer.2.attention.self.value.bias', 'encoder.layer.0.attention.self.query.weight', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.3.output.dense.weight', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.4.attention.self.query.weight', 'encoder.layer.2.attention.self.key.weight', 'encoder.layer.9.output.dense.bias', 'encoder.layer.8.attention.output.dense.bias', 'encoder.layer.8.intermediate.dense.weight', 'embeddings.token_type_embeddings.weight', 'encoder.layer.9.attention.self.query.bias', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.4.attention.self.key.weight', 'encoder.layer.6.attention.output.LayerNorm.weight', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.8.attention.self.value.weight', 'encoder.layer.2.attention.self.query.weight', 'encoder.layer.10.attention.output.LayerNorm.weight', 'encoder.layer.5.output.dense.weight', 'encoder.layer.10.attention.output.dense.weight', 'encoder.layer.4.attention.output.dense.weight', 'encoder.layer.6.attention.self.query.bias', 'encoder.layer.5.output.LayerNorm.bias', 'encoder.layer.8.output.LayerNorm.bias', 'encoder.layer.7.attention.self.value.bias', 'encoder.layer.1.attention.output.LayerNorm.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
05/09/2022 18:37:22 - INFO - __main__ -   Creating features from dataset file at .
/cluster/home/yifhou/scratch_yifan/qa/xtreme_xlm/outputs-adapter//squad/xlm_LR1e-5_EPOCH2.0_maxlen384_batchsize8_gradacc2
XLMConfig {
  "architectures": [
    "XLMRobertaForMaskedLM"
  ],
  "asm": false,
  "attention_dropout": 0.1,
  "attention_probs_dropout_prob": 0.1,
  "bos_index": 0,
  "bos_token_id": 0,
  "causal": false,
  "dropout": 0.1,
  "emb_dim": 768,
  "embed_init_std": 0.02209708691207961,
  "end_n_top": 5,
  "eos_index": 1,
  "eos_token_id": 2,
  "gelu_activation": true,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "init_std": 0.02,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "is_encoder": true,
  "lang_id": 0,
  "layer_norm_eps": 1e-05,
  "mask_index": 5,
  "mask_token_id": 0,
  "max_position_embeddings": 514,
  "model_type": "xlm",
  "n_heads": 12,
  "n_langs": 1,
  "n_layers": 12,
  "output_past": true,
  "pad_index": 2,
  "pad_token_id": 1,
  "sinusoidal_embeddings": false,
  "start_n_top": 5,
  "summary_activation": null,
  "summary_first_dropout": 0.1,
  "summary_proj_to_labels": true,
  "summary_type": "first",
  "summary_use_proj": true,
  "transformers_version": "4.17.0",
  "type_vocab_size": 1,
  "unk_index": 3,
  "use_lang_emb": false,
  "vocab_size": 250002
}

  0%|          | 0/48 [00:00<?, ?it/s] 25%|██▌       | 12/48 [00:00<00:00, 104.55it/s] 48%|████▊     | 23/48 [00:00<00:00, 96.22it/s]  75%|███████▌  | 36/48 [00:00<00:00, 106.52it/s]100%|██████████| 48/48 [00:00<00:00, 109.86it/s]
convert squad examples to features:   0%|          | 0/1190 [00:00<?, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.
convert squad examples to features:   0%|          | 1/1190 [00:00<02:36,  7.59it/s]convert squad examples to features:   5%|▌         | 65/1190 [00:00<00:04, 253.33it/s]convert squad examples to features:   8%|▊         | 97/1190 [00:00<00:04, 271.87it/s]convert squad examples to features:  14%|█▎        | 161/1190 [00:00<00:03, 313.65it/s]convert squad examples to features:  19%|█▉        | 225/1190 [00:00<00:02, 331.20it/s]convert squad examples to features:  22%|██▏       | 258/1190 [00:00<00:03, 309.91it/s]convert squad examples to features:  24%|██▍       | 289/1190 [00:01<00:03, 290.04it/s]convert squad examples to features:  27%|██▋       | 321/1190 [00:01<00:03, 287.47it/s]convert squad examples to features:  30%|██▉       | 353/1190 [00:01<00:02, 290.01it/s]convert squad examples to features:  32%|███▏      | 385/1190 [00:01<00:05, 153.10it/s]convert squad examples to features:  35%|███▌      | 417/1190 [00:01<00:04, 167.91it/s]convert squad examples to features:  38%|███▊      | 449/1190 [00:01<00:03, 190.37it/s]convert squad examples to features:  40%|████      | 481/1190 [00:02<00:03, 210.91it/s]convert squad examples to features:  43%|████▎     | 513/1190 [00:02<00:02, 230.33it/s]convert squad examples to features:  46%|████▌     | 545/1190 [00:02<00:02, 228.71it/s]convert squad examples to features:  48%|████▊     | 577/1190 [00:02<00:02, 238.03it/s]convert squad examples to features:  51%|█████     | 609/1190 [00:02<00:02, 235.83it/s]convert squad examples to features:  54%|█████▍    | 641/1190 [00:02<00:02, 237.94it/s]convert squad examples to features:  57%|█████▋    | 673/1190 [00:02<00:02, 236.05it/s]convert squad examples to features:  59%|█████▉    | 705/1190 [00:02<00:01, 253.77it/s]convert squad examples to features:  65%|██████▍   | 769/1190 [00:03<00:01, 289.41it/s]convert squad examples to features:  67%|██████▋   | 801/1190 [00:03<00:01, 287.86it/s]convert squad examples to features:  70%|███████   | 833/1190 [00:03<00:01, 260.94it/s]convert squad examples to features:  73%|███████▎  | 865/1190 [00:03<00:01, 260.68it/s]convert squad examples to features:  75%|███████▌  | 897/1190 [00:03<00:01, 232.74it/s]convert squad examples to features:  78%|███████▊  | 929/1190 [00:03<00:01, 232.17it/s]convert squad examples to features:  81%|████████  | 961/1190 [00:03<00:00, 244.27it/s]convert squad examples to features:  86%|████████▌ | 1025/1190 [00:04<00:00, 255.18it/s]convert squad examples to features:  92%|█████████▏| 1089/1190 [00:04<00:00, 282.91it/s]convert squad examples to features:  94%|█████████▍| 1121/1190 [00:04<00:00, 257.72it/s]convert squad examples to features:  97%|█████████▋| 1153/1190 [00:04<00:00, 247.99it/s]convert squad examples to features: 100%|██████████| 1190/1190 [00:04<00:00, 253.14it/s]/cluster/project/sachan/yifan/softwares/anaconda/anaconda3/envs/xfactr/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2272: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

add example index and unique id:   0%|          | 0/1190 [00:00<?, ?it/s]add example index and unique id: 100%|██████████| 1190/1190 [00:00<00:00, 763417.22it/s]
05/09/2022 18:37:27 - INFO - __main__ -   Saving features into cached file ./cached_xquad.tr.json_xlm_LR1e-5_EPOCH2.0_maxlen384_batchsize8_gradacc2_384_tr
05/09/2022 18:37:28 - INFO - __main__ -   ***** Running evaluation  *****
05/09/2022 18:37:28 - INFO - __main__ -     Num examples = 1274
05/09/2022 18:37:28 - INFO - __main__ -     Batch size = 8
Evaluating:   0%|          | 0/160 [00:00<?, ?it/s]Evaluating:   1%|          | 1/160 [00:00<01:34,  1.68it/s]Evaluating:   2%|▏         | 3/160 [00:00<00:32,  4.83it/s]Evaluating:   3%|▎         | 5/160 [00:00<00:20,  7.43it/s]Evaluating:   4%|▍         | 7/160 [00:01<00:16,  9.51it/s]Evaluating:   6%|▌         | 9/160 [00:01<00:13, 11.03it/s]Evaluating:   7%|▋         | 11/160 [00:01<00:12, 12.28it/s]Evaluating:   8%|▊         | 13/160 [00:01<00:11, 13.16it/s]Evaluating:   9%|▉         | 15/160 [00:01<00:10, 13.77it/s]Evaluating:  11%|█         | 17/160 [00:01<00:10, 14.30it/s]Evaluating:  12%|█▏        | 19/160 [00:01<00:09, 14.69it/s]Evaluating:  13%|█▎        | 21/160 [00:01<00:09, 14.84it/s]Evaluating:  14%|█▍        | 23/160 [00:02<00:09, 14.98it/s]Evaluating:  16%|█▌        | 25/160 [00:02<00:08, 15.12it/s]Evaluating:  17%|█▋        | 27/160 [00:02<00:08, 15.24it/s]Evaluating:  18%|█▊        | 29/160 [00:02<00:08, 15.36it/s]Evaluating:  19%|█▉        | 31/160 [00:02<00:08, 15.39it/s]Evaluating:  21%|██        | 33/160 [00:02<00:08, 15.39it/s]Evaluating:  22%|██▏       | 35/160 [00:02<00:08, 15.43it/s]Evaluating:  23%|██▎       | 37/160 [00:02<00:08, 15.37it/s]Evaluating:  24%|██▍       | 39/160 [00:03<00:07, 15.41it/s]Evaluating:  26%|██▌       | 41/160 [00:03<00:07, 15.41it/s]Evaluating:  27%|██▋       | 43/160 [00:03<00:07, 15.36it/s]Evaluating:  28%|██▊       | 45/160 [00:03<00:07, 15.30it/s]Evaluating:  29%|██▉       | 47/160 [00:03<00:07, 15.28it/s]Evaluating:  31%|███       | 49/160 [00:03<00:07, 15.30it/s]Evaluating:  32%|███▏      | 51/160 [00:03<00:07, 15.29it/s]Evaluating:  33%|███▎      | 53/160 [00:03<00:07, 15.24it/s]Evaluating:  34%|███▍      | 55/160 [00:04<00:06, 15.17it/s]Evaluating:  36%|███▌      | 57/160 [00:04<00:06, 15.22it/s]Evaluating:  37%|███▋      | 59/160 [00:04<00:06, 15.18it/s]Evaluating:  38%|███▊      | 61/160 [00:04<00:06, 15.16it/s]Evaluating:  39%|███▉      | 63/160 [00:04<00:06, 15.25it/s]Evaluating:  41%|████      | 65/160 [00:04<00:06, 15.36it/s]Evaluating:  42%|████▏     | 67/160 [00:04<00:06, 15.37it/s]Evaluating:  43%|████▎     | 69/160 [00:05<00:05, 15.37it/s]Evaluating:  44%|████▍     | 71/160 [00:05<00:05, 15.35it/s]Evaluating:  46%|████▌     | 73/160 [00:05<00:05, 15.32it/s]Evaluating:  47%|████▋     | 75/160 [00:05<00:05, 15.33it/s]Evaluating:  48%|████▊     | 77/160 [00:05<00:05, 15.20it/s]Evaluating:  49%|████▉     | 79/160 [00:05<00:05, 15.19it/s]Evaluating:  51%|█████     | 81/160 [00:05<00:05, 15.23it/s]Evaluating:  52%|█████▏    | 83/160 [00:05<00:05, 15.18it/s]Evaluating:  53%|█████▎    | 85/160 [00:06<00:04, 15.22it/s]Evaluating:  54%|█████▍    | 87/160 [00:06<00:04, 15.20it/s]Evaluating:  56%|█████▌    | 89/160 [00:06<00:04, 15.24it/s]Evaluating:  57%|█████▋    | 91/160 [00:06<00:04, 15.29it/s]Evaluating:  58%|█████▊    | 93/160 [00:06<00:04, 15.27it/s]Evaluating:  59%|█████▉    | 95/160 [00:06<00:04, 15.30it/s]Evaluating:  61%|██████    | 97/160 [00:06<00:04, 15.31it/s]Evaluating:  62%|██████▏   | 99/160 [00:07<00:03, 15.26it/s]Evaluating:  63%|██████▎   | 101/160 [00:07<00:03, 15.21it/s]Evaluating:  64%|██████▍   | 103/160 [00:07<00:03, 15.18it/s]Evaluating:  66%|██████▌   | 105/160 [00:07<00:03, 15.19it/s]Evaluating:  67%|██████▋   | 107/160 [00:07<00:03, 15.20it/s]Evaluating:  68%|██████▊   | 109/160 [00:07<00:03, 15.27it/s]Evaluating:  69%|██████▉   | 111/160 [00:07<00:03, 15.30it/s]Evaluating:  71%|███████   | 113/160 [00:07<00:03, 14.66it/s]Evaluating:  72%|███████▏  | 115/160 [00:08<00:03, 14.87it/s]Evaluating:  73%|███████▎  | 117/160 [00:08<00:02, 14.99it/s]Evaluating:  74%|███████▍  | 119/160 [00:08<00:02, 15.11it/s]Evaluating:  76%|███████▌  | 121/160 [00:08<00:02, 15.15it/s]Evaluating:  77%|███████▋  | 123/160 [00:08<00:02, 15.22it/s]Evaluating:  78%|███████▊  | 125/160 [00:08<00:02, 15.30it/s]Evaluating:  79%|███████▉  | 127/160 [00:08<00:02, 15.28it/s]Evaluating:  81%|████████  | 129/160 [00:09<00:03,  9.22it/s]Evaluating:  82%|████████▏ | 131/160 [00:09<00:02, 10.50it/s]Evaluating:  83%|████████▎ | 133/160 [00:09<00:02, 11.59it/s]Evaluating:  84%|████████▍ | 135/160 [00:09<00:02, 12.47it/s]Evaluating:  86%|████████▌ | 137/160 [00:09<00:01, 13.27it/s]Evaluating:  87%|████████▋ | 139/160 [00:09<00:01, 13.82it/s]Evaluating:  88%|████████▊ | 141/160 [00:10<00:01, 14.21it/s]Evaluating:  89%|████████▉ | 143/160 [00:10<00:01, 14.57it/s]Evaluating:  91%|█████████ | 145/160 [00:10<00:01, 14.88it/s]Evaluating:  92%|█████████▏| 147/160 [00:10<00:00, 15.06it/s]Evaluating:  93%|█████████▎| 149/160 [00:10<00:00, 15.22it/s]Evaluating:  94%|█████████▍| 151/160 [00:10<00:00, 15.28it/s]Evaluating:  96%|█████████▌| 153/160 [00:10<00:00, 15.28it/s]Evaluating:  97%|█████████▋| 155/160 [00:10<00:00, 15.33it/s]Evaluating:  98%|█████████▊| 157/160 [00:11<00:00, 15.27it/s]Evaluating:  99%|█████████▉| 159/160 [00:11<00:00, 15.30it/s]Evaluating: 100%|██████████| 160/160 [00:11<00:00, 14.23it/s]
05/09/2022 18:37:39 - INFO - __main__ -     Evaluation done in total 11.244313 secs (0.008826 sec per example)
05/09/2022 18:37:44 - INFO - __main__ -   Results: {'exact': 49.075630252100844, 'f1': 65.326527703497, 'total': 1190, 'HasAns_exact': 49.075630252100844, 'HasAns_f1': 65.326527703497, 'HasAns_total': 1190, 'best_exact': 49.075630252100844, 'best_exact_thresh': 0.0, 'best_f1': 65.326527703497, 'best_f1_thresh': 0.0}
  ar 
2022-05-09 18:37:46.589163: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0
05/09/2022 18:37:49 - WARNING - __main__ -   Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, 16-bits training: False
You are using a model of type xlm-roberta to instantiate a model of type xlm. This is not supported for all configurations of models and can yield errors.
Some weights of the model checkpoint at /cluster/home/yifhou/scratch_yifan/qa/xtreme_xlm/outputs-adapter//squad/xlm_LR1e-5_EPOCH2.0_maxlen384_batchsize8_gradacc2 were not used when initializing XLMRobertaModel: ['base_model.encoder.layer.3.output.LayerNorm.bias', 'base_model.encoder.layer.3.attention.output.LayerNorm.bias', 'base_model.encoder.layer.8.output.LayerNorm.weight', 'base_model.encoder.layer.1.attention.self.value.bias', 'base_model.encoder.layer.0.intermediate.dense.bias', 'base_model.encoder.layer.0.attention.output.dense.bias', 'base_model.encoder.layer.6.attention.output.dense.bias', 'base_model.encoder.layer.0.attention.self.value.weight', 'base_model.encoder.layer.1.attention.self.value.weight', 'base_model.encoder.layer.1.intermediate.dense.bias', 'base_model.encoder.layer.11.output.LayerNorm.bias', 'base_model.encoder.layer.6.attention.self.query.bias', 'base_model.encoder.layer.11.output.LayerNorm.weight', 'base_model.encoder.layer.1.attention.output.dense.weight', 'base_model.encoder.layer.0.attention.self.key.bias', 'base_model.encoder.layer.5.attention.self.key.weight', 'base_model.encoder.layer.1.attention.self.key.bias', 'base_model.encoder.layer.10.output.dense.weight', 'base_model.encoder.layer.9.attention.output.dense.bias', 'base_model.encoder.layer.8.attention.self.key.weight', 'base_model.encoder.layer.11.attention.output.dense.bias', 'base_model.encoder.layer.9.attention.self.key.bias', 'base_model.encoder.layer.8.output.dense.weight', 'base_model.encoder.layer.11.attention.self.query.weight', 'base_model.encoder.layer.8.attention.self.key.bias', 'base_model.encoder.layer.8.attention.output.LayerNorm.bias', 'base_model.encoder.layer.9.intermediate.dense.weight', 'base_model.encoder.layer.4.output.dense.bias', 'base_model.encoder.layer.7.attention.output.LayerNorm.weight', 'base_model.encoder.layer.7.attention.self.query.weight', 'base_model.encoder.layer.6.output.dense.bias', 'base_model.encoder.layer.7.output.LayerNorm.bias', 'base_model.encoder.layer.5.intermediate.dense.weight', 'base_model.encoder.layer.7.output.dense.weight', 'base_model.encoder.layer.6.attention.output.LayerNorm.bias', 'base_model.encoder.layer.2.attention.self.value.weight', 'base_model.encoder.layer.6.output.LayerNorm.weight', 'base_model.encoder.layer.10.attention.output.dense.bias', 'base_model.encoder.layer.9.output.LayerNorm.bias', 'base_model.encoder.layer.11.output.dense.bias', 'base_model.encoder.layer.1.attention.output.dense.bias', 'base_model.encoder.layer.6.attention.self.key.bias', 'base_model.encoder.layer.11.attention.self.query.bias', 'base_model.encoder.layer.11.attention.output.dense.weight', 'base_model.encoder.layer.1.output.dense.weight', 'base_model.encoder.layer.9.output.LayerNorm.weight', 'base_model.encoder.layer.4.output.LayerNorm.bias', 'base_model.encoder.layer.5.attention.output.dense.weight', 'base_model.encoder.layer.0.attention.self.query.weight', 'base_model.encoder.layer.5.intermediate.dense.bias', 'base_model.encoder.layer.3.attention.output.dense.bias', 'base_model.encoder.layer.5.attention.output.dense.bias', 'base_model.encoder.layer.5.attention.self.query.bias', 'base_model.encoder.layer.10.output.LayerNorm.weight', 'base_model.encoder.layer.0.output.LayerNorm.weight', 'base_model.encoder.layer.0.output.dense.bias', 'base_model.encoder.layer.0.attention.self.query.bias', 'base_model.encoder.layer.6.output.dense.weight', 'base_model.encoder.layer.0.output.dense.weight', 'base_model.encoder.layer.3.attention.self.key.weight', 'base_model.encoder.layer.10.attention.self.value.weight', 'base_model.encoder.layer.7.attention.output.dense.weight', 'base_model.encoder.layer.10.attention.self.query.weight', 'base_model.embeddings.position_ids', 'base_model.encoder.layer.2.attention.self.query.bias', 'base_model.encoder.layer.5.attention.output.LayerNorm.bias', 'base_model.encoder.layer.9.intermediate.dense.bias', 'base_model.encoder.layer.0.attention.output.dense.weight', 'base_model.encoder.layer.9.output.dense.weight', 'base_model.encoder.layer.9.attention.self.value.weight', 'base_model.encoder.layer.0.output.LayerNorm.bias', 'base_model.encoder.layer.8.output.LayerNorm.bias', 'base_model.encoder.layer.10.attention.output.LayerNorm.bias', 'base_model.encoder.layer.4.attention.self.value.bias', 'base_model.encoder.layer.6.attention.self.query.weight', 'base_model.encoder.layer.7.output.LayerNorm.weight', 'base_model.encoder.layer.8.intermediate.dense.weight', 'base_model.encoder.layer.11.attention.output.LayerNorm.weight', 'base_model.encoder.layer.9.attention.output.LayerNorm.bias', 'base_model.embeddings.token_type_embeddings.weight', 'base_model.encoder.layer.2.attention.self.key.weight', 'base_model.encoder.layer.3.attention.self.value.bias', 'base_model.encoder.layer.8.output.dense.bias', 'base_model.encoder.layer.2.output.dense.bias', 'base_model.encoder.layer.11.attention.self.key.weight', 'base_model.encoder.layer.3.attention.self.query.bias', 'base_model.encoder.layer.2.attention.self.value.bias', 'base_model.encoder.layer.3.attention.self.key.bias', 'base_model.encoder.layer.11.attention.self.key.bias', 'base_model.encoder.layer.4.attention.self.value.weight', 'base_model.encoder.layer.1.output.LayerNorm.weight', 'base_model.encoder.layer.2.intermediate.dense.weight', 'base_model.encoder.layer.3.intermediate.dense.weight', 'base_model.encoder.layer.11.attention.self.value.weight', 'base_model.encoder.layer.10.attention.self.key.bias', 'base_model.encoder.layer.8.attention.self.query.weight', 'base_model.embeddings.LayerNorm.weight', 'base_model.encoder.layer.11.attention.self.value.bias', 'base_model.encoder.layer.9.attention.output.dense.weight', 'base_model.encoder.layer.8.attention.self.value.weight', 'base_model.encoder.layer.7.attention.output.LayerNorm.bias', 'base_model.encoder.layer.1.intermediate.dense.weight', 'base_model.encoder.layer.10.intermediate.dense.weight', 'base_model.encoder.layer.5.attention.self.value.bias', 'base_model.encoder.layer.1.attention.self.query.weight', 'base_model.encoder.layer.9.attention.output.LayerNorm.weight', 'base_model.encoder.layer.10.attention.output.LayerNorm.weight', 'qa_outputs.bias', 'base_model.encoder.layer.6.intermediate.dense.weight', 'base_model.encoder.layer.10.output.LayerNorm.bias', 'base_model.encoder.layer.9.attention.self.query.bias', 'base_model.encoder.layer.6.attention.self.value.weight', 'base_model.encoder.layer.3.attention.self.value.weight', 'base_model.encoder.layer.4.attention.self.key.weight', 'base_model.encoder.layer.9.output.dense.bias', 'base_model.encoder.layer.7.intermediate.dense.bias', 'base_model.encoder.layer.2.output.LayerNorm.bias', 'base_model.encoder.layer.3.attention.output.LayerNorm.weight', 'base_model.encoder.layer.4.attention.output.dense.weight', 'base_model.encoder.layer.5.attention.output.LayerNorm.weight', 'base_model.encoder.layer.1.output.dense.bias', 'base_model.encoder.layer.0.attention.self.value.bias', 'base_model.encoder.layer.1.attention.self.key.weight', 'base_model.encoder.layer.5.attention.self.value.weight', 'base_model.encoder.layer.11.output.dense.weight', 'base_model.embeddings.position_embeddings.weight', 'base_model.encoder.layer.4.attention.output.LayerNorm.bias', 'base_model.encoder.layer.7.attention.self.value.weight', 'base_model.encoder.layer.7.attention.self.query.bias', 'base_model.encoder.layer.4.intermediate.dense.weight', 'base_model.encoder.layer.3.output.dense.bias', 'base_model.encoder.layer.10.attention.self.key.weight', 'base_model.encoder.layer.0.attention.output.LayerNorm.weight', 'base_model.encoder.layer.2.attention.output.LayerNorm.bias', 'base_model.encoder.layer.9.attention.self.value.bias', 'base_model.encoder.layer.10.intermediate.dense.bias', 'base_model.encoder.layer.11.intermediate.dense.weight', 'base_model.encoder.layer.8.attention.self.query.bias', 'base_model.encoder.layer.7.attention.self.key.weight', 'base_model.encoder.layer.2.output.LayerNorm.weight', 'base_model.encoder.layer.6.attention.self.value.bias', 'base_model.encoder.layer.4.attention.self.query.weight', 'base_model.encoder.layer.2.attention.self.query.weight', 'base_model.encoder.layer.5.output.dense.weight', 'base_model.encoder.layer.3.output.LayerNorm.weight', 'base_model.encoder.layer.2.output.dense.weight', 'base_model.encoder.layer.4.output.dense.weight', 'base_model.encoder.layer.7.output.dense.bias', 'base_model.encoder.layer.11.intermediate.dense.bias', 'base_model.encoder.layer.6.attention.output.dense.weight', 'base_model.encoder.layer.3.attention.self.query.weight', 'base_model.encoder.layer.8.attention.output.LayerNorm.weight', 'base_model.encoder.layer.2.attention.output.LayerNorm.weight', 'base_model.embeddings.LayerNorm.bias', 'base_model.encoder.layer.9.attention.self.key.weight', 'base_model.encoder.layer.4.output.LayerNorm.weight', 'base_model.pooler.dense.weight', 'base_model.encoder.layer.6.output.LayerNorm.bias', 'base_model.encoder.layer.9.attention.self.query.weight', 'base_model.encoder.layer.2.attention.self.key.bias', 'base_model.encoder.layer.3.intermediate.dense.bias', 'base_model.encoder.layer.5.output.LayerNorm.bias', 'base_model.encoder.layer.1.output.LayerNorm.bias', 'base_model.encoder.layer.7.attention.self.key.bias', 'base_model.encoder.layer.10.attention.output.dense.weight', 'base_model.encoder.layer.7.attention.output.dense.bias', 'base_model.encoder.layer.6.attention.self.key.weight', 'base_model.encoder.layer.11.attention.output.LayerNorm.bias', 'base_model.encoder.layer.8.attention.self.value.bias', 'base_model.encoder.layer.5.output.dense.bias', 'base_model.encoder.layer.4.attention.self.query.bias', 'base_model.encoder.layer.7.attention.self.value.bias', 'base_model.encoder.layer.10.attention.self.query.bias', 'base_model.encoder.layer.0.intermediate.dense.weight', 'base_model.encoder.layer.0.attention.output.LayerNorm.bias', 'base_model.encoder.layer.1.attention.output.LayerNorm.weight', 'base_model.encoder.layer.5.attention.self.key.bias', 'base_model.encoder.layer.7.intermediate.dense.weight', 'base_model.encoder.layer.10.attention.self.value.bias', 'base_model.encoder.layer.10.output.dense.bias', 'base_model.embeddings.word_embeddings.weight', 'base_model.encoder.layer.1.attention.output.LayerNorm.bias', 'base_model.encoder.layer.4.attention.output.dense.bias', 'qa_outputs.weight', 'base_model.encoder.layer.2.intermediate.dense.bias', 'base_model.encoder.layer.4.attention.self.key.bias', 'base_model.encoder.layer.1.attention.self.query.bias', 'base_model.encoder.layer.5.attention.self.query.weight', 'base_model.encoder.layer.4.intermediate.dense.bias', 'base_model.encoder.layer.4.attention.output.LayerNorm.weight', 'base_model.encoder.layer.3.output.dense.weight', 'base_model.encoder.layer.2.attention.output.dense.bias', 'base_model.encoder.layer.8.attention.output.dense.weight', 'base_model.encoder.layer.8.attention.output.dense.bias', 'base_model.encoder.layer.8.intermediate.dense.bias', 'base_model.encoder.layer.0.attention.self.key.weight', 'base_model.encoder.layer.5.output.LayerNorm.weight', 'base_model.encoder.layer.2.attention.output.dense.weight', 'base_model.encoder.layer.6.intermediate.dense.bias', 'base_model.encoder.layer.3.attention.output.dense.weight', 'base_model.pooler.dense.bias', 'base_model.encoder.layer.6.attention.output.LayerNorm.weight']
- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of XLMRobertaModel were not initialized from the model checkpoint at /cluster/home/yifhou/scratch_yifan/qa/xtreme_xlm/outputs-adapter//squad/xlm_LR1e-5_EPOCH2.0_maxlen384_batchsize8_gradacc2 and are newly initialized: ['encoder.layer.0.attention.self.key.bias', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.3.attention.self.key.bias', 'encoder.layer.0.attention.self.value.bias', 'encoder.layer.4.attention.self.value.weight', 'encoder.layer.4.attention.output.dense.weight', 'encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.layer.10.attention.self.query.bias', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.5.intermediate.dense.weight', 'pooler.dense.bias', 'encoder.layer.9.output.dense.weight', 'encoder.layer.3.output.dense.bias', 'encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.layer.7.attention.self.value.bias', 'encoder.layer.1.attention.output.dense.bias', 'encoder.layer.5.attention.output.dense.bias', 'encoder.layer.2.attention.self.value.bias', 'encoder.layer.5.attention.self.query.bias', 'encoder.layer.9.attention.output.LayerNorm.weight', 'encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.11.output.dense.weight', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.6.attention.output.LayerNorm.bias', 'encoder.layer.8.attention.self.value.bias', 'encoder.layer.4.attention.output.LayerNorm.weight', 'encoder.layer.1.output.dense.bias', 'encoder.layer.8.attention.self.key.weight', 'encoder.layer.6.attention.output.dense.bias', 'encoder.layer.7.attention.output.dense.weight', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.11.attention.self.key.weight', 'encoder.layer.7.attention.self.key.bias', 'encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.layer.2.attention.self.key.weight', 'encoder.layer.6.attention.output.dense.weight', 'encoder.layer.8.attention.self.query.weight', 'encoder.layer.10.output.dense.weight', 'encoder.layer.1.attention.output.dense.weight', 'encoder.layer.11.attention.self.query.weight', 'encoder.layer.9.output.dense.bias', 'encoder.layer.9.attention.self.key.bias', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.3.attention.output.dense.weight', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.1.attention.self.query.weight', 'encoder.layer.2.attention.self.value.weight', 'encoder.layer.7.output.LayerNorm.weight', 'encoder.layer.10.attention.self.value.weight', 'encoder.layer.4.attention.output.LayerNorm.bias', 'encoder.layer.4.attention.self.key.weight', 'encoder.layer.10.attention.self.value.bias', 'encoder.layer.3.attention.self.value.weight', 'encoder.layer.5.attention.self.value.weight', 'encoder.layer.3.attention.self.value.bias', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.1.output.dense.weight', 'encoder.layer.5.attention.self.key.weight', 'encoder.layer.8.output.dense.weight', 'encoder.layer.10.attention.self.key.bias', 'encoder.layer.7.attention.self.query.bias', 'encoder.layer.11.attention.output.dense.weight', 'encoder.layer.7.attention.self.query.weight', 'encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.layer.5.output.dense.weight', 'encoder.layer.9.attention.output.dense.weight', 'encoder.layer.2.output.dense.bias', 'encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.layer.2.output.dense.weight', 'encoder.layer.5.output.dense.bias', 'embeddings.LayerNorm.bias', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.9.attention.self.value.weight', 'embeddings.word_embeddings.weight', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.11.attention.self.query.bias', 'encoder.layer.7.attention.self.key.weight', 'encoder.layer.9.attention.output.LayerNorm.bias', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.9.output.LayerNorm.weight', 'encoder.layer.9.attention.self.value.bias', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.6.attention.self.key.bias', 'encoder.layer.8.attention.output.LayerNorm.bias', 'embeddings.position_embeddings.weight', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.10.attention.output.LayerNorm.bias', 'encoder.layer.6.output.LayerNorm.bias', 'encoder.layer.1.attention.output.LayerNorm.weight', 'encoder.layer.6.output.dense.bias', 'encoder.layer.7.output.dense.weight', 'encoder.layer.0.attention.self.value.weight', 'encoder.layer.4.output.dense.weight', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.10.intermediate.dense.weight', 'encoder.layer.11.output.LayerNorm.bias', 'encoder.layer.11.attention.self.value.weight', 'encoder.layer.3.attention.output.dense.bias', 'encoder.layer.2.attention.output.dense.weight', 'encoder.layer.4.attention.self.value.bias', 'encoder.layer.0.attention.self.query.weight', 'encoder.layer.2.attention.self.query.weight', 'encoder.layer.9.attention.self.query.weight', 'encoder.layer.5.attention.output.LayerNorm.weight', 'encoder.layer.6.attention.self.value.weight', 'encoder.layer.10.output.LayerNorm.weight', 'encoder.layer.2.attention.self.key.bias', 'encoder.layer.10.attention.output.dense.bias', 'encoder.layer.2.attention.output.dense.bias', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.6.attention.self.value.bias', 'encoder.layer.9.attention.self.query.bias', 'encoder.layer.5.attention.output.dense.weight', 'encoder.layer.4.output.dense.bias', 'encoder.layer.10.output.LayerNorm.bias', 'encoder.layer.1.attention.self.key.bias', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.1.attention.self.key.weight', 'encoder.layer.2.attention.self.query.bias', 'encoder.layer.8.attention.self.value.weight', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.0.attention.self.query.bias', 'encoder.layer.11.attention.self.key.bias', 'encoder.layer.11.attention.self.value.bias', 'embeddings.token_type_embeddings.weight', 'encoder.layer.5.attention.self.key.bias', 'encoder.layer.8.attention.self.query.bias', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.0.attention.output.dense.weight', 'encoder.layer.0.attention.output.LayerNorm.weight', 'encoder.layer.1.attention.self.query.bias', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.7.output.LayerNorm.bias', 'encoder.layer.0.output.dense.weight', 'encoder.layer.7.attention.output.dense.bias', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.1.attention.self.value.bias', 'encoder.layer.3.attention.self.query.bias', 'encoder.layer.9.attention.output.dense.bias', 'encoder.layer.8.attention.self.key.bias', 'pooler.dense.weight', 'encoder.layer.6.attention.self.key.weight', 'encoder.layer.9.output.LayerNorm.bias', 'encoder.layer.4.attention.output.dense.bias', 'encoder.layer.7.attention.output.LayerNorm.bias', 'encoder.layer.10.output.dense.bias', 'encoder.layer.7.attention.output.LayerNorm.weight', 'encoder.layer.8.output.LayerNorm.weight', 'encoder.layer.5.attention.self.query.weight', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.10.attention.self.query.weight', 'encoder.layer.3.output.dense.weight', 'encoder.layer.3.attention.self.query.weight', 'encoder.layer.6.attention.self.query.weight', 'embeddings.LayerNorm.weight', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.8.attention.output.dense.bias', 'encoder.layer.6.attention.output.LayerNorm.weight', 'encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.layer.8.attention.output.dense.weight', 'encoder.layer.7.attention.self.value.weight', 'encoder.layer.8.output.LayerNorm.bias', 'encoder.layer.7.intermediate.dense.bias', 'encoder.layer.1.attention.self.value.weight', 'encoder.layer.10.attention.self.key.weight', 'encoder.layer.11.output.LayerNorm.weight', 'encoder.layer.11.output.dense.bias', 'encoder.layer.0.output.dense.bias', 'encoder.layer.3.attention.self.key.weight', 'encoder.layer.4.attention.self.query.bias', 'encoder.layer.0.attention.self.key.weight', 'encoder.layer.8.output.dense.bias', 'encoder.layer.0.attention.output.dense.bias', 'encoder.layer.7.output.dense.bias', 'encoder.layer.11.attention.output.dense.bias', 'encoder.layer.10.attention.output.dense.weight', 'encoder.layer.5.attention.self.value.bias', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.9.attention.self.key.weight', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.6.output.dense.weight', 'encoder.layer.8.attention.output.LayerNorm.weight', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.4.attention.self.query.weight', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.4.attention.self.key.bias', 'encoder.layer.11.attention.output.LayerNorm.weight', 'encoder.layer.6.attention.self.query.bias', 'encoder.layer.2.attention.output.LayerNorm.weight', 'encoder.layer.10.attention.output.LayerNorm.weight', 'encoder.layer.2.attention.output.LayerNorm.bias', 'encoder.layer.5.output.LayerNorm.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
05/09/2022 18:37:55 - INFO - __main__ -   lang2id = None
