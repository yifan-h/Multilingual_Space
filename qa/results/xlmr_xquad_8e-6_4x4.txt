Fine-tuning /cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/xlm-roberta-large on xquad using GPU 2
Load data from /cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/download/, and save models to /cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter/
************************
/cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/xlm-roberta-large
************************

Predictions on xquad
  en 
2022-05-09 19:47:58.513379: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0
05/09/2022 19:48:04 - WARNING - __main__ -   Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, 16-bits training: False
You are using a model of type xlm-roberta to instantiate a model of type xlm. This is not supported for all configurations of models and can yield errors.
Some weights of the model checkpoint at /cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//squad/xlm-KG_LR8e-6_EPOCH2.0_maxlen384_batchsize4_gradacc4 were not used when initializing XLMRobertaModel: ['base_model.encoder.layer.2.attention.self.value.weight', 'base_model.encoder.layer.7.output.LayerNorm.weight', 'base_model.encoder.layer.19.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.22.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.11.attention.self.query.weight', 'base_model.encoder.layer.11.attention.output.LayerNorm.weight', 'base_model.encoder.layer.15.attention.self.query.bias', 'base_model.encoder.layer.23.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.12.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.6.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.9.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.0.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.15.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.0.attention.output.dense.bias', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.17.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.16.attention.output.LayerNorm.bias', 'base_model.encoder.layer.8.attention.self.key.weight', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.3.intermediate.dense.bias', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.9.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.3.output.dense.weight', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.21.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.16.output.LayerNorm.bias', 'base_model.encoder.layer.0.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.10.output.LayerNorm.weight', 'base_model.encoder.layer.21.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.5.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.16.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.4.output.dense.bias', 'base_model.encoder.layer.16.output.dense.weight', 'base_model.encoder.layer.7.attention.output.LayerNorm.bias', 'base_model.encoder.layer.17.output.LayerNorm.bias', 'base_model.encoder.layer.13.output.dense.weight', 'base_model.encoder.layer.9.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.8.attention.output.dense.weight', 'base_model.encoder.layer.20.attention.output.LayerNorm.weight', 'base_model.encoder.layer.12.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.6.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.18.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.15.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.20.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.22.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.0.attention.output.LayerNorm.bias', 'base_model.encoder.layer.8.intermediate.dense.bias', 'base_model.encoder.layer.3.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.3.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.16.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.23.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.12.attention.self.key.bias', 'base_model.encoder.layer.11.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.22.attention.self.query.weight', 'base_model.encoder.layer.22.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.2.attention.self.key.bias', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.15.attention.self.value.weight', 'base_model.encoder.layer.16.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.10.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.5.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.13.attention.self.query.weight', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.22.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.1.output.dense.bias', 'base_model.encoder.layer.3.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.22.attention.self.value.weight', 'base_model.encoder.layer.0.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.20.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.5.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.12.output.dense.weight', 'base_model.encoder.layer.1.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.4.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.2.attention.self.value.bias', 'base_model.encoder.layer.8.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.10.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.19.output.LayerNorm.bias', 'base_model.encoder.layer.17.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.22.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.3.attention.output.dense.bias', 'base_model.encoder.layer.5.attention.self.query.bias', 'base_model.encoder.layer.8.output.LayerNorm.bias', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.14.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.5.attention.output.LayerNorm.weight', 'base_model.encoder.layer.6.attention.self.key.weight', 'base_model.encoder.layer.15.attention.self.value.bias', 'base_model.encoder.layer.18.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.18.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.14.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.1.attention.self.key.bias', 'base_model.encoder.layer.8.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.19.attention.output.dense.weight', 'base_model.encoder.layer.14.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.13.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.16.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.14.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.5.attention.self.key.weight', 'base_model.encoder.layer.17.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.19.attention.self.value.weight', 'base_model.encoder.layer.9.attention.self.query.bias', 'base_model.encoder.layer.3.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.4.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.3.attention.self.query.weight', 'base_model.encoder.layer.8.output.LayerNorm.weight', 'base_model.encoder.layer.5.attention.self.value.weight', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.9.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.21.attention.output.dense.bias', 'base_model.encoder.layer.15.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.13.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.5.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.12.attention.output.LayerNorm.weight', 'base_model.encoder.layer.9.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.15.output.dense.bias', 'base_model.encoder.layer.22.attention.self.key.weight', 'base_model.encoder.layer.23.attention.self.value.bias', 'base_model.encoder.layer.16.attention.self.query.weight', 'base_model.encoder.layer.11.output.dense.weight', 'base_model.encoder.layer.21.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.7.attention.output.LayerNorm.weight', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.20.attention.output.dense.weight', 'base_model.encoder.layer.4.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.11.attention.output.dense.bias', 'base_model.encoder.layer.16.attention.output.LayerNorm.weight', 'base_model.encoder.layer.5.attention.self.key.bias', 'base_model.encoder.layer.17.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.19.attention.self.value.bias', 'base_model.encoder.layer.9.intermediate.dense.weight', 'base_model.encoder.layer.7.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.4.intermediate.dense.weight', 'base_model.encoder.layer.10.output.dense.bias', 'base_model.encoder.layer.17.attention.self.query.weight', 'base_model.encoder.layer.5.intermediate.dense.weight', 'qa_outputs.weight', 'base_model.encoder.layer.8.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.20.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.18.output.dense.bias', 'base_model.encoder.layer.10.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.20.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.16.attention.self.key.bias', 'base_model.encoder.layer.9.attention.self.value.bias', 'base_model.encoder.layer.19.output.LayerNorm.weight', 'base_model.encoder.layer.22.attention.self.value.bias', 'base_model.encoder.layer.15.attention.output.LayerNorm.weight', 'base_model.encoder.layer.10.attention.self.query.bias', 'base_model.encoder.layer.10.intermediate.dense.weight', 'base_model.encoder.layer.12.output.LayerNorm.weight', 'base_model.encoder.layer.14.output.dense.weight', 'base_model.encoder.layer.20.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.22.attention.output.dense.weight', 'base_model.encoder.layer.13.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.2.output.dense.bias', 'base_model.encoder.layer.2.output.dense.weight', 'base_model.encoder.layer.3.attention.output.dense.weight', 'base_model.encoder.layer.13.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.4.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.13.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.7.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.11.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.8.attention.output.LayerNorm.weight', 'base_model.encoder.layer.2.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.17.attention.self.value.weight', 'base_model.encoder.layer.22.attention.output.LayerNorm.weight', 'base_model.encoder.layer.1.attention.output.dense.weight', 'base_model.encoder.layer.15.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.15.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.20.attention.self.query.bias', 'base_model.encoder.layer.19.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.16.intermediate.dense.bias', 'base_model.encoder.layer.13.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.20.output.dense.bias', 'base_model.encoder.layer.3.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.23.intermediate.dense.bias', 'base_model.encoder.layer.18.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.18.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.9.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.0.attention.output.LayerNorm.weight', 'base_model.encoder.layer.2.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.3.attention.output.LayerNorm.weight', 'base_model.encoder.layer.6.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.8.attention.self.value.weight', 'base_model.encoder.layer.22.attention.output.LayerNorm.bias', 'base_model.encoder.layer.10.output.dense.weight', 'base_model.encoder.layer.18.attention.output.LayerNorm.weight', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.12.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.17.attention.output.LayerNorm.weight', 'base_model.encoder.layer.16.output.dense.bias', 'base_model.encoder.layer.20.intermediate.dense.bias', 'base_model.encoder.layer.7.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.4.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.23.attention.output.LayerNorm.bias', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.21.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.7.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.22.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.15.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.13.attention.self.key.bias', 'base_model.encoder.layer.1.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.0.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.5.output.dense.weight', 'base_model.encoder.layer.19.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.6.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.13.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.7.attention.output.dense.bias', 'base_model.encoder.layer.20.intermediate.dense.weight', 'base_model.encoder.layer.18.attention.output.LayerNorm.bias', 'base_model.encoder.layer.23.attention.self.query.bias', 'base_model.encoder.layer.2.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.3.intermediate.dense.weight', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.5.output.LayerNorm.bias', 'base_model.encoder.layer.6.output.dense.weight', 'base_model.encoder.layer.16.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.18.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.19.attention.output.LayerNorm.bias', 'base_model.encoder.layer.9.output.LayerNorm.weight', 'base_model.encoder.layer.19.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.6.attention.output.LayerNorm.bias', 'base_model.encoder.layer.14.intermediate.dense.bias', 'base_model.encoder.layer.10.attention.self.key.weight', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.14.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.1.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.9.output.dense.weight', 'base_model.encoder.layer.20.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.21.output.dense.weight', 'base_model.encoder.layer.23.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.14.attention.self.query.bias', 'base_model.encoder.layer.4.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.22.attention.output.dense.bias', 'base_model.encoder.layer.11.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.10.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.11.attention.output.dense.weight', 'base_model.encoder.layer.3.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.5.attention.output.dense.bias', 'base_model.encoder.layer.13.attention.self.key.weight', 'base_model.encoder.layer.17.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.0.attention.self.query.weight', 'base_model.encoder.layer.1.intermediate.dense.bias', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.0.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.8.attention.self.query.bias', 'base_model.encoder.layer.2.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.13.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.7.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.19.intermediate.dense.weight', 'base_model.encoder.layer.7.attention.output.dense.weight', 'base_model.encoder.layer.16.attention.self.value.weight', 'base_model.encoder.layer.13.output.LayerNorm.weight', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.5.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.17.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.6.intermediate.dense.bias', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.2.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.15.output.dense.weight', 'base_model.encoder.layer.19.attention.output.LayerNorm.weight', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.4.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.14.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.20.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.23.attention.output.dense.weight', 'base_model.encoder.layer.20.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.10.attention.output.LayerNorm.bias', 'base_model.encoder.layer.19.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.12.intermediate.dense.weight', 'base_model.encoder.layer.12.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.4.output.dense.weight', 'base_model.encoder.layer.18.attention.self.query.weight', 'base_model.embeddings.LayerNorm.bias', 'base_model.encoder.layer.19.attention.output.dense.bias', 'base_model.encoder.layer.17.intermediate.dense.bias', 'base_model.encoder.layer.15.attention.self.query.weight', 'base_model.encoder.layer.21.attention.output.dense.weight', 'base_model.encoder.layer.7.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.8.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.15.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.12.attention.output.dense.weight', 'base_model.encoder.layer.16.attention.output.dense.weight', 'base_model.encoder.layer.16.attention.output.dense.bias', 'base_model.encoder.layer.15.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.18.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.8.attention.output.dense.bias', 'base_model.encoder.layer.9.attention.output.dense.weight', 'base_model.encoder.layer.9.output.LayerNorm.bias', 'base_model.encoder.layer.7.attention.self.query.weight', 'base_model.encoder.layer.18.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.19.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.9.attention.output.LayerNorm.bias', 'base_model.encoder.layer.0.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.12.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.9.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.14.attention.self.query.weight', 'base_model.encoder.layer.15.output.LayerNorm.bias', 'base_model.encoder.layer.23.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.22.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.15.attention.output.dense.weight', 'base_model.encoder.layer.2.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.16.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.15.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.5.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.10.output.LayerNorm.bias', 'base_model.encoder.layer.2.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.12.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.14.attention.self.value.weight', 'base_model.encoder.layer.17.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.5.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.15.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.16.intermediate.dense.weight', 'base_model.encoder.layer.15.intermediate.dense.weight', 'base_model.encoder.layer.17.output.LayerNorm.weight', 'base_model.encoder.layer.2.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.0.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.3.attention.self.query.bias', 'base_model.encoder.layer.11.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.4.attention.self.key.bias', 'base_model.encoder.layer.5.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.0.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.13.attention.self.value.weight', 'base_model.encoder.layer.17.attention.self.key.bias', 'base_model.encoder.layer.23.output.LayerNorm.weight', 'base_model.encoder.layer.0.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.1.attention.self.value.bias', 'base_model.encoder.layer.17.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.1.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.6.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.23.output.dense.bias', 'base_model.encoder.layer.2.intermediate.dense.weight', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.23.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.5.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.6.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.13.intermediate.dense.weight', 'base_model.encoder.layer.2.attention.self.query.weight', 'base_model.encoder.layer.1.output.LayerNorm.weight', 'base_model.encoder.layer.11.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.21.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.16.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.13.intermediate.dense.bias', 'base_model.encoder.layer.17.attention.self.query.bias', 'base_model.encoder.layer.18.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.0.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.10.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.8.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.8.attention.self.query.weight', 'base_model.encoder.layer.10.attention.self.value.bias', 'base_model.encoder.layer.18.output.LayerNorm.weight', 'base_model.encoder.layer.12.attention.self.query.weight', 'base_model.pooler.dense.bias', 'base_model.encoder.layer.10.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.19.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.4.output.LayerNorm.weight', 'base_model.encoder.layer.3.attention.self.value.bias', 'base_model.encoder.layer.10.attention.self.key.bias', 'base_model.encoder.layer.6.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.12.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.2.attention.output.LayerNorm.weight', 'base_model.encoder.layer.19.attention.self.query.bias', 'base_model.encoder.layer.4.attention.self.query.weight', 'base_model.encoder.layer.23.intermediate.dense.weight', 'base_model.encoder.layer.22.output.LayerNorm.weight', 'base_model.encoder.layer.4.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.6.attention.self.query.bias', 'base_model.encoder.layer.16.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.5.attention.output.dense.weight', 'base_model.encoder.layer.15.attention.output.LayerNorm.bias', 'base_model.encoder.layer.0.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.1.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.21.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.8.output.dense.weight', 'base_model.encoder.layer.17.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.6.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.6.attention.self.query.weight', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.8.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.11.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.0.attention.self.key.bias', 'base_model.encoder.layer.6.output.LayerNorm.bias', 'base_model.encoder.layer.21.attention.self.query.weight', 'base_model.encoder.layer.17.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.19.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.14.attention.output.LayerNorm.weight', 'base_model.encoder.layer.15.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.18.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.14.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.5.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.13.attention.self.value.bias', 'base_model.encoder.layer.15.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.8.attention.self.key.bias', 'base_model.encoder.layer.11.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.5.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.10.attention.output.LayerNorm.weight', 'base_model.encoder.layer.15.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.21.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.4.attention.self.value.bias', 'base_model.encoder.layer.21.intermediate.dense.weight', 'base_model.encoder.layer.10.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.11.intermediate.dense.weight', 'base_model.encoder.layer.9.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.12.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.21.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.1.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.0.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.22.attention.self.query.bias', 'base_model.encoder.layer.22.intermediate.dense.weight', 'base_model.encoder.layer.5.attention.self.query.weight', 'base_model.encoder.layer.3.attention.output.LayerNorm.bias', 'base_model.encoder.layer.6.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.7.attention.self.query.bias', 'base_model.encoder.layer.10.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.21.attention.self.value.weight', 'base_model.encoder.layer.10.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.18.attention.self.value.weight', 'base_model.encoder.layer.1.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.14.attention.output.dense.weight', 'base_model.encoder.layer.17.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.20.attention.self.value.bias', 'base_model.encoder.layer.3.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.6.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.13.attention.self.query.bias', 'base_model.encoder.layer.8.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.13.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.21.output.dense.bias', 'base_model.encoder.layer.8.attention.output.LayerNorm.bias', 'base_model.encoder.layer.5.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.0.attention.self.query.bias', 'base_model.encoder.layer.10.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.20.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.6.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.0.output.dense.weight', 'base_model.encoder.layer.2.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.0.attention.self.value.weight', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.10.attention.output.dense.bias', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.15.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.0.output.LayerNorm.weight', 'base_model.encoder.layer.2.intermediate.dense.bias', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.21.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.1.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.4.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.8.attention.self.value.bias', 'base_model.encoder.layer.7.intermediate.dense.weight', 'base_model.encoder.layer.2.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.16.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.20.output.LayerNorm.bias', 'base_model.encoder.layer.16.attention.self.query.bias', 'base_model.pooler.dense.weight', 'base_model.encoder.layer.16.attention.self.value.bias', 'base_model.encoder.layer.1.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.18.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.22.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.23.output.LayerNorm.bias', 'base_model.encoder.layer.12.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.16.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.2.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.6.attention.output.dense.bias', 'base_model.encoder.layer.21.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.19.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.1.attention.self.value.weight', 'base_model.encoder.layer.0.attention.output.dense.weight', 'base_model.encoder.layer.22.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.4.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.9.attention.self.value.weight', 'base_model.encoder.layer.11.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.20.attention.self.key.weight', 'base_model.encoder.layer.6.attention.output.LayerNorm.weight', 'base_model.encoder.layer.2.attention.output.dense.bias', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.12.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.19.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.17.output.dense.bias', 'base_model.encoder.layer.12.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.3.attention.self.key.weight', 'base_model.encoder.layer.4.attention.self.key.weight', 'base_model.encoder.layer.13.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.21.attention.self.value.bias', 'base_model.encoder.layer.23.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.14.attention.self.key.bias', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.19.output.dense.weight', 'base_model.encoder.layer.3.output.LayerNorm.weight', 'base_model.encoder.layer.3.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.7.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.18.attention.self.key.weight', 'base_model.encoder.layer.23.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.4.attention.output.LayerNorm.bias', 'base_model.encoder.layer.1.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.23.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.1.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.1.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.5.attention.output.LayerNorm.bias', 'base_model.encoder.layer.11.attention.self.key.weight', 'base_model.embeddings.word_embeddings.weight', 'base_model.encoder.layer.9.attention.self.key.weight', 'base_model.encoder.layer.12.attention.self.key.weight', 'base_model.encoder.layer.14.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.19.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.19.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.7.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.10.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.0.output.dense.bias', 'base_model.encoder.layer.11.attention.self.value.weight', 'base_model.encoder.layer.13.attention.output.LayerNorm.weight', 'base_model.encoder.layer.10.attention.self.value.weight', 'base_model.encoder.layer.16.attention.self.key.weight', 'base_model.encoder.layer.11.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.2.attention.self.query.bias', 'base_model.encoder.layer.16.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.3.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.21.attention.self.query.bias', 'base_model.encoder.layer.14.attention.self.value.bias', 'base_model.encoder.layer.20.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.2.attention.output.LayerNorm.bias', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.18.attention.self.key.bias', 'base_model.encoder.layer.1.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.17.attention.self.key.weight', 'base_model.encoder.layer.14.attention.self.key.weight', 'base_model.encoder.layer.5.output.LayerNorm.weight', 'base_model.encoder.layer.1.intermediate.dense.weight', 'base_model.encoder.layer.7.intermediate.dense.bias', 'base_model.encoder.layer.9.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.14.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.18.output.LayerNorm.bias', 'base_model.encoder.layer.1.attention.self.key.weight', 'base_model.encoder.layer.22.output.dense.weight', 'base_model.encoder.layer.23.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.2.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.4.attention.self.query.bias', 'base_model.encoder.layer.5.output.dense.bias', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.15.attention.output.dense.bias', 'base_model.encoder.layer.17.output.dense.weight', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.21.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.8.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.3.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.1.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.13.output.LayerNorm.bias', 'base_model.encoder.layer.21.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.0.attention.self.value.bias', 'base_model.encoder.layer.0.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.1.attention.output.LayerNorm.weight', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.13.attention.output.dense.weight', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.20.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.3.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.23.attention.self.query.weight', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.17.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.9.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.6.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.21.output.LayerNorm.weight', 'base_model.encoder.layer.21.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.3.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.18.attention.output.dense.bias', 'base_model.encoder.layer.15.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.14.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.2.attention.output.dense.weight', 'base_model.encoder.layer.2.output.LayerNorm.weight', 'base_model.encoder.layer.17.attention.output.LayerNorm.bias', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.6.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.7.attention.self.value.bias', 'base_model.encoder.layer.14.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.6.intermediate.dense.weight', 'base_model.encoder.layer.9.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.9.output.dense.bias', 'base_model.encoder.layer.8.output.dense.bias', 'base_model.encoder.layer.10.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.21.attention.output.LayerNorm.weight', 'base_model.encoder.layer.3.attention.self.key.bias', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.14.intermediate.dense.weight', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.4.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.3.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.17.attention.output.dense.bias', 'base_model.encoder.layer.12.intermediate.dense.bias', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.20.attention.output.LayerNorm.bias', 'base_model.encoder.layer.22.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.6.output.dense.bias', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.11.attention.self.key.bias', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.21.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.22.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.19.intermediate.dense.bias', 'base_model.encoder.layer.23.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.19.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.23.attention.self.key.weight', 'base_model.encoder.layer.15.attention.self.key.bias', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.23.attention.self.key.bias', 'base_model.encoder.layer.7.output.dense.weight', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.0.intermediate.dense.weight', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.1.attention.self.query.bias', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.16.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.22.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.14.output.LayerNorm.bias', 'base_model.encoder.layer.15.attention.self.key.weight', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.13.attention.output.LayerNorm.bias', 'base_model.encoder.layer.23.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.3.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.2.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.21.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.23.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.11.attention.output.LayerNorm.bias', 'base_model.encoder.layer.7.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.19.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.18.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.11.attention.self.query.bias', 'base_model.encoder.layer.2.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.12.attention.output.dense.bias', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.8.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.0.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.4.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.10.attention.output.dense.weight', 'base_model.encoder.layer.16.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.2.output.LayerNorm.bias', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.13.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.21.intermediate.dense.bias', 'base_model.encoder.layer.0.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.11.output.dense.bias', 'base_model.encoder.layer.22.output.dense.bias', 'base_model.encoder.layer.22.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.20.attention.self.key.bias', 'base_model.encoder.layer.9.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.11.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.12.attention.self.value.weight', 'base_model.encoder.layer.20.attention.self.value.weight', 'base_model.encoder.layer.1.output.LayerNorm.bias', 'base_model.encoder.layer.11.attention.self.value.bias', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.12.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.14.output.dense.bias', 'base_model.encoder.layer.23.attention.self.value.weight', 'qa_outputs.bias', 'base_model.encoder.layer.1.attention.self.query.weight', 'base_model.encoder.layer.6.attention.self.value.bias', 'base_model.encoder.layer.7.output.dense.bias', 'base_model.encoder.layer.5.intermediate.dense.bias', 'base_model.encoder.layer.10.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.14.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.16.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.7.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.9.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.11.output.LayerNorm.bias', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.11.intermediate.dense.bias', 'base_model.encoder.layer.22.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.7.attention.self.key.bias', 'base_model.encoder.layer.11.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.20.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.11.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.1.attention.output.dense.bias', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.1.attention.output.LayerNorm.bias', 'base_model.encoder.layer.23.output.adapters.ts.adapter_up.weight', 'base_model.embeddings.LayerNorm.weight', 'base_model.encoder.layer.14.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.16.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.1.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.8.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.12.output.dense.bias', 'base_model.encoder.layer.17.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.20.attention.output.dense.bias', 'base_model.encoder.layer.4.attention.output.dense.weight', 'base_model.encoder.layer.19.output.dense.bias', 'base_model.encoder.layer.20.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.18.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.13.output.dense.bias', 'base_model.encoder.layer.12.attention.output.LayerNorm.bias', 'base_model.encoder.layer.17.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.17.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.7.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.11.output.LayerNorm.weight', 'base_model.encoder.layer.15.output.LayerNorm.weight', 'base_model.encoder.layer.4.intermediate.dense.bias', 'base_model.encoder.layer.7.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.10.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.14.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.18.intermediate.dense.bias', 'base_model.encoder.layer.23.attention.output.LayerNorm.weight', 'base_model.encoder.layer.23.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.0.intermediate.dense.bias', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.14.attention.output.LayerNorm.bias', 'base_model.encoder.layer.7.attention.self.value.weight', 'base_model.encoder.layer.17.intermediate.dense.weight', 'base_model.encoder.layer.18.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.7.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.12.attention.self.query.bias', 'base_model.encoder.layer.19.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.20.output.LayerNorm.weight', 'base_model.encoder.layer.4.attention.self.value.weight', 'base_model.encoder.layer.13.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.6.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.15.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.13.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.0.output.LayerNorm.bias', 'base_model.encoder.layer.19.attention.self.key.bias', 'base_model.encoder.layer.18.output.dense.weight', 'base_model.encoder.layer.6.attention.self.value.weight', 'base_model.encoder.layer.2.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.11.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.8.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.12.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.14.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.6.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.14.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.3.output.dense.bias', 'base_model.encoder.layer.21.attention.output.LayerNorm.bias', 'base_model.encoder.layer.19.attention.self.query.weight', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.5.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.8.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.4.attention.output.LayerNorm.weight', 'base_model.encoder.layer.5.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.2.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.12.attention.self.value.bias', 'base_model.encoder.layer.3.output.LayerNorm.bias', 'base_model.encoder.layer.13.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.5.attention.self.value.bias', 'base_model.encoder.layer.14.attention.output.dense.bias', 'base_model.encoder.layer.20.attention.self.query.weight', 'base_model.encoder.layer.8.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.21.attention.self.key.weight', 'base_model.encoder.layer.4.output.LayerNorm.bias', 'base_model.encoder.layer.6.output.LayerNorm.weight', 'base_model.encoder.layer.15.intermediate.dense.bias', 'base_model.encoder.layer.16.output.LayerNorm.weight', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.19.attention.self.key.weight', 'base_model.encoder.layer.20.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.4.attention.output.dense.bias', 'base_model.encoder.layer.9.intermediate.dense.bias', 'base_model.encoder.layer.10.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.4.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.embeddings.token_type_embeddings.weight', 'base_model.encoder.layer.17.attention.self.value.bias', 'base_model.encoder.layer.18.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.22.output.LayerNorm.bias', 'base_model.encoder.layer.10.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.9.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.13.attention.output.dense.bias', 'base_model.encoder.layer.9.attention.self.key.bias', 'base_model.encoder.layer.19.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.5.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.8.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.18.attention.self.value.bias', 'base_model.encoder.layer.6.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.18.attention.self.query.bias', 'base_model.encoder.layer.20.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.11.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.18.attention.output.dense.weight', 'base_model.encoder.layer.5.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.23.attention.output.dense.bias', 'base_model.encoder.layer.4.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.9.attention.self.query.weight', 'base_model.encoder.layer.22.attention.self.key.bias', 'base_model.encoder.layer.9.attention.output.dense.bias', 'base_model.encoder.layer.4.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.20.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.21.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.0.attention.self.key.weight', 'base_model.encoder.layer.9.attention.output.LayerNorm.weight', 'base_model.encoder.layer.3.attention.self.value.weight', 'base_model.encoder.layer.7.output.LayerNorm.bias', 'base_model.encoder.layer.21.output.LayerNorm.bias', 'base_model.encoder.layer.9.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.13.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.20.output.dense.weight', 'base_model.encoder.layer.22.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.10.attention.self.query.weight', 'base_model.encoder.layer.14.output.LayerNorm.weight', 'base_model.encoder.layer.8.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.12.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.18.output.adapters.ep.adapter_up.weight', 'base_model.embeddings.position_ids', 'base_model.encoder.layer.0.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.21.attention.self.key.bias', 'base_model.encoder.layer.1.output.dense.weight', 'base_model.encoder.layer.4.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.17.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.9.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.12.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.7.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.17.attention.output.dense.weight', 'base_model.encoder.layer.12.output.LayerNorm.bias', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.embeddings.position_embeddings.weight', 'base_model.encoder.layer.2.attention.self.key.weight', 'base_model.encoder.layer.22.intermediate.dense.bias', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.18.intermediate.dense.weight', 'base_model.encoder.layer.23.output.dense.weight', 'base_model.encoder.layer.1.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.6.attention.self.key.bias', 'base_model.encoder.layer.11.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.23.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.22.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.11.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.8.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.23.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.3.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.10.intermediate.dense.bias', 'base_model.encoder.layer.12.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.7.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.8.intermediate.dense.weight', 'base_model.encoder.layer.16.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.7.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.7.attention.self.key.weight', 'base_model.encoder.layer.13.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.6.attention.output.dense.weight', 'base_model.encoder.layer.3.output.adapters.es.adapter_up.bias']
- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of XLMRobertaModel were not initialized from the model checkpoint at /cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//squad/xlm-KG_LR8e-6_EPOCH2.0_maxlen384_batchsize4_gradacc4 and are newly initialized: ['encoder.layer.10.intermediate.dense.weight', 'encoder.layer.9.attention.self.query.bias', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.18.output.LayerNorm.weight', 'encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.layer.3.attention.self.key.weight', 'encoder.layer.18.attention.self.key.bias', 'encoder.layer.15.attention.output.dense.bias', 'encoder.layer.21.attention.self.query.bias', 'encoder.layer.20.attention.output.dense.bias', 'encoder.layer.13.attention.self.value.weight', 'encoder.layer.6.attention.output.LayerNorm.weight', 'encoder.layer.20.attention.self.query.bias', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.5.attention.self.value.weight', 'encoder.layer.22.attention.output.dense.weight', 'encoder.layer.23.attention.self.key.bias', 'encoder.layer.8.attention.self.key.bias', 'encoder.layer.10.attention.self.key.weight', 'encoder.layer.1.attention.self.query.weight', 'encoder.layer.6.attention.self.query.weight', 'encoder.layer.11.attention.self.key.bias', 'encoder.layer.7.output.LayerNorm.bias', 'encoder.layer.1.attention.self.query.bias', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.17.attention.self.value.weight', 'encoder.layer.23.intermediate.dense.weight', 'embeddings.LayerNorm.weight', 'encoder.layer.15.output.LayerNorm.weight', 'encoder.layer.13.attention.output.dense.weight', 'encoder.layer.4.attention.self.value.weight', 'encoder.layer.21.intermediate.dense.bias', 'encoder.layer.13.attention.self.key.bias', 'encoder.layer.1.attention.output.dense.weight', 'encoder.layer.12.attention.output.dense.bias', 'encoder.layer.2.attention.output.LayerNorm.weight', 'encoder.layer.7.attention.output.dense.bias', 'encoder.layer.16.intermediate.dense.bias', 'encoder.layer.2.attention.output.dense.bias', 'encoder.layer.14.attention.self.key.weight', 'encoder.layer.14.output.LayerNorm.bias', 'encoder.layer.0.attention.output.dense.weight', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.19.output.LayerNorm.bias', 'encoder.layer.2.attention.output.LayerNorm.bias', 'encoder.layer.12.output.dense.weight', 'encoder.layer.7.intermediate.dense.bias', 'encoder.layer.15.attention.self.key.weight', 'encoder.layer.3.attention.self.query.bias', 'encoder.layer.22.attention.self.value.weight', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.10.attention.self.query.bias', 'encoder.layer.10.attention.self.query.weight', 'encoder.layer.22.attention.self.query.bias', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.19.attention.self.value.weight', 'encoder.layer.14.attention.self.value.bias', 'encoder.layer.18.output.dense.weight', 'encoder.layer.20.output.LayerNorm.bias', 'encoder.layer.7.attention.self.query.weight', 'encoder.layer.15.attention.output.dense.weight', 'encoder.layer.16.attention.output.LayerNorm.bias', 'encoder.layer.13.attention.self.value.bias', 'encoder.layer.13.attention.self.query.weight', 'encoder.layer.23.attention.output.dense.weight', 'encoder.layer.8.attention.self.query.bias', 'encoder.layer.10.attention.self.key.bias', 'encoder.layer.10.attention.output.dense.bias', 'encoder.layer.11.attention.self.value.weight', 'encoder.layer.23.output.LayerNorm.bias', 'encoder.layer.3.attention.output.dense.bias', 'encoder.layer.23.intermediate.dense.bias', 'encoder.layer.7.output.LayerNorm.weight', 'encoder.layer.9.attention.self.key.bias', 'encoder.layer.8.attention.self.query.weight', 'encoder.layer.15.intermediate.dense.weight', 'encoder.layer.7.attention.self.value.bias', 'encoder.layer.11.attention.output.dense.bias', 'encoder.layer.13.output.LayerNorm.bias', 'encoder.layer.22.attention.self.key.weight', 'encoder.layer.9.output.dense.bias', 'encoder.layer.21.attention.output.dense.bias', 'encoder.layer.20.output.dense.bias', 'encoder.layer.12.output.dense.bias', 'encoder.layer.10.attention.self.value.weight', 'encoder.layer.22.attention.self.value.bias', 'encoder.layer.11.output.dense.bias', 'encoder.layer.14.attention.self.key.bias', 'encoder.layer.0.attention.self.value.bias', 'encoder.layer.7.attention.self.key.bias', 'encoder.layer.17.attention.output.LayerNorm.bias', 'encoder.layer.22.attention.output.LayerNorm.bias', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.3.attention.output.dense.weight', 'encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.1.attention.output.LayerNorm.weight', 'encoder.layer.19.attention.self.query.bias', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.10.attention.output.LayerNorm.weight', 'encoder.layer.2.attention.self.key.bias', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.17.output.dense.weight', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.0.output.dense.weight', 'encoder.layer.22.intermediate.dense.weight', 'encoder.layer.16.output.dense.bias', 'encoder.layer.18.intermediate.dense.weight', 'encoder.layer.17.attention.self.key.weight', 'encoder.layer.16.attention.self.key.weight', 'encoder.layer.1.attention.self.value.bias', 'encoder.layer.17.output.dense.bias', 'encoder.layer.2.attention.self.value.weight', 'encoder.layer.3.attention.self.value.bias', 'encoder.layer.6.attention.output.dense.bias', 'encoder.layer.23.attention.output.dense.bias', 'encoder.layer.5.attention.self.value.bias', 'encoder.layer.6.output.dense.weight', 'encoder.layer.11.attention.self.query.bias', 'encoder.layer.19.attention.self.key.weight', 'encoder.layer.9.output.LayerNorm.weight', 'encoder.layer.0.attention.self.key.weight', 'encoder.layer.14.attention.output.LayerNorm.weight', 'encoder.layer.15.output.dense.weight', 'pooler.dense.bias', 'encoder.layer.3.attention.self.value.weight', 'encoder.layer.12.attention.output.dense.weight', 'encoder.layer.11.attention.output.dense.weight', 'encoder.layer.12.attention.self.query.bias', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.6.attention.self.value.bias', 'encoder.layer.16.output.LayerNorm.weight', 'encoder.layer.13.attention.self.query.bias', 'encoder.layer.17.output.LayerNorm.bias', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.10.attention.output.dense.weight', 'encoder.layer.17.attention.self.value.bias', 'encoder.layer.13.attention.output.LayerNorm.bias', 'encoder.layer.20.attention.self.key.weight', 'encoder.layer.18.attention.self.value.bias', 'encoder.layer.21.intermediate.dense.weight', 'encoder.layer.12.attention.output.LayerNorm.weight', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.20.attention.output.dense.weight', 'encoder.layer.19.attention.output.LayerNorm.bias', 'encoder.layer.6.attention.self.key.bias', 'encoder.layer.19.intermediate.dense.bias', 'encoder.layer.14.attention.self.query.bias', 'encoder.layer.6.output.LayerNorm.bias', 'encoder.layer.3.output.dense.bias', 'encoder.layer.9.attention.self.value.weight', 'encoder.layer.17.attention.self.query.weight', 'encoder.layer.18.attention.self.key.weight', 'encoder.layer.4.attention.self.query.bias', 'encoder.layer.3.attention.self.key.bias', 'encoder.layer.8.attention.self.value.bias', 'embeddings.position_embeddings.weight', 'encoder.layer.15.attention.self.value.bias', 'encoder.layer.17.intermediate.dense.bias', 'encoder.layer.18.output.dense.bias', 'encoder.layer.18.attention.output.LayerNorm.bias', 'encoder.layer.8.attention.self.key.weight', 'encoder.layer.4.attention.self.key.weight', 'encoder.layer.2.attention.self.value.bias', 'encoder.layer.15.output.LayerNorm.bias', 'encoder.layer.23.output.LayerNorm.weight', 'encoder.layer.4.output.dense.bias', 'encoder.layer.13.intermediate.dense.weight', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.4.attention.output.LayerNorm.bias', 'encoder.layer.2.attention.self.key.weight', 'encoder.layer.7.output.dense.bias', 'encoder.layer.15.attention.self.value.weight', 'encoder.layer.8.attention.self.value.weight', 'encoder.layer.23.attention.output.LayerNorm.bias', 'encoder.layer.11.attention.output.LayerNorm.weight', 'encoder.layer.15.attention.output.LayerNorm.weight', 'encoder.layer.6.attention.self.key.weight', 'encoder.layer.20.intermediate.dense.bias', 'encoder.layer.12.attention.self.key.bias', 'encoder.layer.18.attention.output.dense.weight', 'embeddings.word_embeddings.weight', 'encoder.layer.3.attention.self.query.weight', 'encoder.layer.23.attention.self.value.bias', 'encoder.layer.22.output.dense.weight', 'encoder.layer.16.attention.self.query.bias', 'encoder.layer.9.output.LayerNorm.bias', 'encoder.layer.11.output.LayerNorm.weight', 'encoder.layer.16.attention.output.LayerNorm.weight', 'encoder.layer.21.output.LayerNorm.weight', 'encoder.layer.11.intermediate.dense.weight', 'embeddings.token_type_embeddings.weight', 'encoder.layer.1.output.dense.weight', 'encoder.layer.14.attention.output.dense.weight', 'encoder.layer.15.attention.output.LayerNorm.bias', 'encoder.layer.17.attention.output.dense.weight', 'encoder.layer.0.attention.self.key.bias', 'encoder.layer.13.output.dense.bias', 'encoder.layer.3.output.dense.weight', 'encoder.layer.19.intermediate.dense.weight', 'encoder.layer.4.attention.output.dense.weight', 'encoder.layer.11.attention.self.key.weight', 'encoder.layer.9.output.dense.weight', 'encoder.layer.13.attention.output.dense.bias', 'encoder.layer.20.attention.self.value.bias', 'encoder.layer.1.attention.self.key.bias', 'encoder.layer.0.attention.self.value.weight', 'encoder.layer.14.intermediate.dense.weight', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.12.attention.self.value.weight', 'encoder.layer.9.attention.self.value.bias', 'encoder.layer.10.output.LayerNorm.weight', 'encoder.layer.14.output.dense.weight', 'encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.layer.15.attention.self.key.bias', 'encoder.layer.23.attention.self.query.weight', 'encoder.layer.11.attention.self.value.bias', 'encoder.layer.21.output.dense.weight', 'encoder.layer.1.attention.self.key.weight', 'encoder.layer.9.attention.output.dense.bias', 'encoder.layer.9.attention.output.LayerNorm.bias', 'encoder.layer.18.attention.output.LayerNorm.weight', 'encoder.layer.16.attention.self.value.bias', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.18.intermediate.dense.bias', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.14.attention.output.dense.bias', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.19.output.LayerNorm.weight', 'encoder.layer.12.output.LayerNorm.bias', 'encoder.layer.21.attention.self.value.weight', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.13.output.LayerNorm.weight', 'encoder.layer.5.attention.self.key.bias', 'encoder.layer.11.output.LayerNorm.bias', 'encoder.layer.12.output.LayerNorm.weight', 'encoder.layer.5.attention.output.LayerNorm.weight', 'encoder.layer.21.output.dense.bias', 'encoder.layer.22.attention.output.LayerNorm.weight', 'encoder.layer.14.attention.self.value.weight', 'encoder.layer.12.attention.self.key.weight', 'encoder.layer.7.attention.output.LayerNorm.weight', 'encoder.layer.2.attention.self.query.weight', 'encoder.layer.10.output.dense.weight', 'encoder.layer.15.attention.self.query.bias', 'encoder.layer.4.attention.output.LayerNorm.weight', 'encoder.layer.12.intermediate.dense.weight', 'encoder.layer.8.attention.output.dense.bias', 'encoder.layer.19.attention.self.value.bias', 'encoder.layer.17.attention.self.query.bias', 'encoder.layer.18.attention.self.query.weight', 'encoder.layer.0.attention.self.query.bias', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.2.output.dense.weight', 'encoder.layer.5.attention.self.query.weight', 'encoder.layer.5.attention.output.dense.weight', 'encoder.layer.11.attention.self.query.weight', 'encoder.layer.1.output.dense.bias', 'encoder.layer.17.output.LayerNorm.weight', 'encoder.layer.22.attention.self.query.weight', 'encoder.layer.13.attention.output.LayerNorm.weight', 'encoder.layer.10.output.dense.bias', 'encoder.layer.12.intermediate.dense.bias', 'encoder.layer.7.attention.self.query.bias', 'encoder.layer.20.attention.self.query.weight', 'encoder.layer.17.attention.output.LayerNorm.weight', 'encoder.layer.15.output.dense.bias', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.16.attention.output.dense.bias', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.21.attention.output.dense.weight', 'encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.layer.4.attention.output.dense.bias', 'encoder.layer.5.output.dense.bias', 'encoder.layer.8.attention.output.dense.weight', 'encoder.layer.5.attention.self.key.weight', 'encoder.layer.1.attention.self.value.weight', 'encoder.layer.22.output.LayerNorm.weight', 'encoder.layer.16.attention.self.key.bias', 'encoder.layer.14.output.LayerNorm.weight', 'encoder.layer.4.attention.self.query.weight', 'encoder.layer.11.output.dense.weight', 'encoder.layer.15.intermediate.dense.bias', 'encoder.layer.12.attention.self.value.bias', 'encoder.layer.6.attention.self.value.weight', 'encoder.layer.4.output.dense.weight', 'encoder.layer.6.attention.output.LayerNorm.bias', 'encoder.layer.19.attention.output.dense.bias', 'encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.layer.16.attention.output.dense.weight', 'encoder.layer.8.output.dense.weight', 'encoder.layer.21.attention.output.LayerNorm.weight', 'encoder.layer.5.output.LayerNorm.bias', 'encoder.layer.7.attention.self.value.weight', 'encoder.layer.21.output.LayerNorm.bias', 'encoder.layer.0.attention.self.query.weight', 'encoder.layer.23.output.dense.weight', 'encoder.layer.0.attention.output.dense.bias', 'encoder.layer.2.attention.output.dense.weight', 'encoder.layer.6.output.dense.bias', 'encoder.layer.8.attention.output.LayerNorm.weight', 'pooler.dense.weight', 'encoder.layer.23.attention.self.query.bias', 'encoder.layer.18.output.LayerNorm.bias', 'encoder.layer.12.attention.output.LayerNorm.bias', 'encoder.layer.20.attention.self.value.weight', 'encoder.layer.10.attention.self.value.bias', 'encoder.layer.19.attention.self.key.bias', 'encoder.layer.8.output.LayerNorm.bias', 'encoder.layer.17.attention.self.key.bias', 'encoder.layer.22.output.LayerNorm.bias', 'encoder.layer.13.intermediate.dense.bias', 'encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.layer.10.attention.output.LayerNorm.bias', 'encoder.layer.20.output.dense.weight', 'encoder.layer.5.output.dense.weight', 'encoder.layer.23.attention.self.value.weight', 'encoder.layer.10.output.LayerNorm.bias', 'encoder.layer.21.attention.self.query.weight', 'encoder.layer.6.attention.output.dense.weight', 'encoder.layer.7.attention.output.dense.weight', 'encoder.layer.7.output.dense.weight', 'encoder.layer.18.attention.output.dense.bias', 'encoder.layer.8.attention.output.LayerNorm.bias', 'encoder.layer.17.intermediate.dense.weight', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.16.output.LayerNorm.bias', 'encoder.layer.1.attention.output.dense.bias', 'encoder.layer.8.output.LayerNorm.weight', 'encoder.layer.14.intermediate.dense.bias', 'encoder.layer.9.attention.output.dense.weight', 'encoder.layer.13.output.dense.weight', 'encoder.layer.19.attention.output.dense.weight', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.9.attention.self.key.weight', 'encoder.layer.4.attention.self.key.bias', 'encoder.layer.16.attention.self.value.weight', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.14.attention.self.query.weight', 'encoder.layer.5.attention.self.query.bias', 'encoder.layer.7.attention.output.LayerNorm.bias', 'encoder.layer.12.attention.self.query.weight', 'encoder.layer.19.attention.self.query.weight', 'encoder.layer.13.attention.self.key.weight', 'encoder.layer.15.attention.self.query.weight', 'encoder.layer.14.output.dense.bias', 'encoder.layer.20.attention.output.LayerNorm.bias', 'encoder.layer.20.attention.output.LayerNorm.weight', 'encoder.layer.20.output.LayerNorm.weight', 'encoder.layer.21.attention.self.key.weight', 'encoder.layer.22.intermediate.dense.bias', 'encoder.layer.22.attention.output.dense.bias', 'encoder.layer.19.output.dense.bias', 'encoder.layer.2.output.dense.bias', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.8.output.dense.bias', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.0.attention.output.LayerNorm.weight', 'encoder.layer.14.attention.output.LayerNorm.bias', 'encoder.layer.16.output.dense.weight', 'encoder.layer.23.attention.output.LayerNorm.weight', 'encoder.layer.9.attention.self.query.weight', 'encoder.layer.20.attention.self.key.bias', 'encoder.layer.18.attention.self.query.bias', 'encoder.layer.21.attention.self.key.bias', 'encoder.layer.17.attention.output.dense.bias', 'encoder.layer.4.attention.self.value.bias', 'encoder.layer.7.attention.self.key.weight', 'embeddings.LayerNorm.bias', 'encoder.layer.21.attention.output.LayerNorm.bias', 'encoder.layer.20.intermediate.dense.weight', 'encoder.layer.0.output.dense.bias', 'encoder.layer.6.attention.self.query.bias', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.23.attention.self.key.weight', 'encoder.layer.19.attention.output.LayerNorm.weight', 'encoder.layer.2.attention.self.query.bias', 'encoder.layer.22.attention.self.key.bias', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.22.output.dense.bias', 'encoder.layer.18.attention.self.value.weight', 'encoder.layer.16.attention.self.query.weight', 'encoder.layer.21.attention.self.value.bias', 'encoder.layer.9.attention.output.LayerNorm.weight', 'encoder.layer.16.intermediate.dense.weight', 'encoder.layer.5.attention.output.dense.bias', 'encoder.layer.19.output.dense.weight', 'encoder.layer.23.output.dense.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Overwriting existing adapter 'ep'.
Overwriting existing adapter 'tp'.
Overwriting existing adapter 'es'.
Overwriting existing adapter 'ts'.
Overwriting existing adapter fusion module 'ep,tp,es,ts'
05/09/2022 19:48:28 - INFO - __main__ -   lang2id = None
05/09/2022 19:48:32 - INFO - __main__ -   Training/evaluation parameters Namespace(adam_epsilon=1e-08, cache_dir='', config_name='', data_dir=None, device=device(type='cuda'), do_eval=True, do_lower_case=False, do_train=False, doc_stride=128, eval_all_checkpoints=False, eval_lang='en', evaluate_during_training=False, fp16=False, fp16_opt_level='O1', gradient_accumulation_steps=1, learning_rate=5e-05, local_rank=-1, logging_steps=50, max_answer_length=30, max_grad_norm=1.0, max_query_length=64, max_seq_length=384, max_steps=-1, model_name='xlm-KG', model_name_or_path='/cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//squad/xlm-KG_LR8e-6_EPOCH2.0_maxlen384_batchsize4_gradacc4', model_type='xlm', modelkg_dir='/cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/adapter/xlmr_adapter', n_best_size=20, n_gpu=1, no_cuda=False, null_score_diff_threshold=0.0, num_train_epochs=3.0, output_dir='/cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//squad/xlm-KG_LR8e-6_EPOCH2.0_maxlen384_batchsize4_gradacc4/predictions/xquad/', overwrite_cache=False, overwrite_output_dir=False, per_gpu_eval_batch_size=8, per_gpu_train_batch_size=8, predict_file='/cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/download//xquad//xquad.en.json', save_steps=50, seed=42, server_ip='', server_port='', threads=1, tokenizer_name='', train_file=None, train_lang='en', verbose_logging=False, version_2_with_negative=False, warmup_steps=0, weight_decay=0.0)
05/09/2022 19:48:32 - INFO - __main__ -   Loading checkpoint /cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//squad/xlm-KG_LR8e-6_EPOCH2.0_maxlen384_batchsize4_gradacc4 for evaluation
05/09/2022 19:48:32 - INFO - __main__ -   Evaluate the following checkpoints: ['/cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//squad/xlm-KG_LR8e-6_EPOCH2.0_maxlen384_batchsize4_gradacc4']
Some weights of the model checkpoint at /cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//squad/xlm-KG_LR8e-6_EPOCH2.0_maxlen384_batchsize4_gradacc4 were not used when initializing XLMRobertaModel: ['base_model.encoder.layer.2.attention.self.value.weight', 'base_model.encoder.layer.7.output.LayerNorm.weight', 'base_model.encoder.layer.19.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.22.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.11.attention.self.query.weight', 'base_model.encoder.layer.11.attention.output.LayerNorm.weight', 'base_model.encoder.layer.15.attention.self.query.bias', 'base_model.encoder.layer.23.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.12.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.6.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.9.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.0.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.15.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.0.attention.output.dense.bias', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.17.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.16.attention.output.LayerNorm.bias', 'base_model.encoder.layer.8.attention.self.key.weight', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.3.intermediate.dense.bias', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.9.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.3.output.dense.weight', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.21.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.16.output.LayerNorm.bias', 'base_model.encoder.layer.0.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.10.output.LayerNorm.weight', 'base_model.encoder.layer.21.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.5.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.16.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.4.output.dense.bias', 'base_model.encoder.layer.16.output.dense.weight', 'base_model.encoder.layer.7.attention.output.LayerNorm.bias', 'base_model.encoder.layer.17.output.LayerNorm.bias', 'base_model.encoder.layer.13.output.dense.weight', 'base_model.encoder.layer.9.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.8.attention.output.dense.weight', 'base_model.encoder.layer.20.attention.output.LayerNorm.weight', 'base_model.encoder.layer.12.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.6.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.18.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.15.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.20.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.22.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.0.attention.output.LayerNorm.bias', 'base_model.encoder.layer.8.intermediate.dense.bias', 'base_model.encoder.layer.3.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.3.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.16.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.23.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.12.attention.self.key.bias', 'base_model.encoder.layer.11.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.22.attention.self.query.weight', 'base_model.encoder.layer.22.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.2.attention.self.key.bias', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.15.attention.self.value.weight', 'base_model.encoder.layer.16.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.10.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.5.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.13.attention.self.query.weight', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.22.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.1.output.dense.bias', 'base_model.encoder.layer.3.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.22.attention.self.value.weight', 'base_model.encoder.layer.0.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.20.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.5.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.12.output.dense.weight', 'base_model.encoder.layer.1.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.4.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.2.attention.self.value.bias', 'base_model.encoder.layer.8.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.10.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.19.output.LayerNorm.bias', 'base_model.encoder.layer.17.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.22.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.3.attention.output.dense.bias', 'base_model.encoder.layer.5.attention.self.query.bias', 'base_model.encoder.layer.8.output.LayerNorm.bias', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.14.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.5.attention.output.LayerNorm.weight', 'base_model.encoder.layer.6.attention.self.key.weight', 'base_model.encoder.layer.15.attention.self.value.bias', 'base_model.encoder.layer.18.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.18.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.14.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.1.attention.self.key.bias', 'base_model.encoder.layer.8.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.19.attention.output.dense.weight', 'base_model.encoder.layer.14.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.13.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.16.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.14.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.5.attention.self.key.weight', 'base_model.encoder.layer.17.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.19.attention.self.value.weight', 'base_model.encoder.layer.9.attention.self.query.bias', 'base_model.encoder.layer.3.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.4.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.3.attention.self.query.weight', 'base_model.encoder.layer.8.output.LayerNorm.weight', 'base_model.encoder.layer.5.attention.self.value.weight', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.9.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.21.attention.output.dense.bias', 'base_model.encoder.layer.15.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.13.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.5.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.12.attention.output.LayerNorm.weight', 'base_model.encoder.layer.9.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.15.output.dense.bias', 'base_model.encoder.layer.22.attention.self.key.weight', 'base_model.encoder.layer.23.attention.self.value.bias', 'base_model.encoder.layer.16.attention.self.query.weight', 'base_model.encoder.layer.11.output.dense.weight', 'base_model.encoder.layer.21.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.7.attention.output.LayerNorm.weight', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.20.attention.output.dense.weight', 'base_model.encoder.layer.4.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.11.attention.output.dense.bias', 'base_model.encoder.layer.16.attention.output.LayerNorm.weight', 'base_model.encoder.layer.5.attention.self.key.bias', 'base_model.encoder.layer.17.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.19.attention.self.value.bias', 'base_model.encoder.layer.9.intermediate.dense.weight', 'base_model.encoder.layer.7.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.4.intermediate.dense.weight', 'base_model.encoder.layer.10.output.dense.bias', 'base_model.encoder.layer.17.attention.self.query.weight', 'base_model.encoder.layer.5.intermediate.dense.weight', 'qa_outputs.weight', 'base_model.encoder.layer.8.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.20.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.18.output.dense.bias', 'base_model.encoder.layer.10.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.20.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.16.attention.self.key.bias', 'base_model.encoder.layer.9.attention.self.value.bias', 'base_model.encoder.layer.19.output.LayerNorm.weight', 'base_model.encoder.layer.22.attention.self.value.bias', 'base_model.encoder.layer.15.attention.output.LayerNorm.weight', 'base_model.encoder.layer.10.attention.self.query.bias', 'base_model.encoder.layer.10.intermediate.dense.weight', 'base_model.encoder.layer.12.output.LayerNorm.weight', 'base_model.encoder.layer.14.output.dense.weight', 'base_model.encoder.layer.20.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.22.attention.output.dense.weight', 'base_model.encoder.layer.13.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.2.output.dense.bias', 'base_model.encoder.layer.2.output.dense.weight', 'base_model.encoder.layer.3.attention.output.dense.weight', 'base_model.encoder.layer.13.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.4.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.13.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.7.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.11.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.8.attention.output.LayerNorm.weight', 'base_model.encoder.layer.2.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.17.attention.self.value.weight', 'base_model.encoder.layer.22.attention.output.LayerNorm.weight', 'base_model.encoder.layer.1.attention.output.dense.weight', 'base_model.encoder.layer.15.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.15.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.20.attention.self.query.bias', 'base_model.encoder.layer.19.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.16.intermediate.dense.bias', 'base_model.encoder.layer.13.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.20.output.dense.bias', 'base_model.encoder.layer.3.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.23.intermediate.dense.bias', 'base_model.encoder.layer.18.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.18.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.9.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.0.attention.output.LayerNorm.weight', 'base_model.encoder.layer.2.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.3.attention.output.LayerNorm.weight', 'base_model.encoder.layer.6.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.8.attention.self.value.weight', 'base_model.encoder.layer.22.attention.output.LayerNorm.bias', 'base_model.encoder.layer.10.output.dense.weight', 'base_model.encoder.layer.18.attention.output.LayerNorm.weight', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.12.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.17.attention.output.LayerNorm.weight', 'base_model.encoder.layer.16.output.dense.bias', 'base_model.encoder.layer.20.intermediate.dense.bias', 'base_model.encoder.layer.7.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.4.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.23.attention.output.LayerNorm.bias', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.21.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.7.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.22.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.15.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.13.attention.self.key.bias', 'base_model.encoder.layer.1.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.0.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.5.output.dense.weight', 'base_model.encoder.layer.19.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.6.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.13.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.7.attention.output.dense.bias', 'base_model.encoder.layer.20.intermediate.dense.weight', 'base_model.encoder.layer.18.attention.output.LayerNorm.bias', 'base_model.encoder.layer.23.attention.self.query.bias', 'base_model.encoder.layer.2.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.3.intermediate.dense.weight', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.5.output.LayerNorm.bias', 'base_model.encoder.layer.6.output.dense.weight', 'base_model.encoder.layer.16.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.18.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.19.attention.output.LayerNorm.bias', 'base_model.encoder.layer.9.output.LayerNorm.weight', 'base_model.encoder.layer.19.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.6.attention.output.LayerNorm.bias', 'base_model.encoder.layer.14.intermediate.dense.bias', 'base_model.encoder.layer.10.attention.self.key.weight', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.14.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.1.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.9.output.dense.weight', 'base_model.encoder.layer.20.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.21.output.dense.weight', 'base_model.encoder.layer.23.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.14.attention.self.query.bias', 'base_model.encoder.layer.4.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.22.attention.output.dense.bias', 'base_model.encoder.layer.11.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.10.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.11.attention.output.dense.weight', 'base_model.encoder.layer.3.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.5.attention.output.dense.bias', 'base_model.encoder.layer.13.attention.self.key.weight', 'base_model.encoder.layer.17.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.0.attention.self.query.weight', 'base_model.encoder.layer.1.intermediate.dense.bias', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.0.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.8.attention.self.query.bias', 'base_model.encoder.layer.2.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.13.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.7.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.19.intermediate.dense.weight', 'base_model.encoder.layer.7.attention.output.dense.weight', 'base_model.encoder.layer.16.attention.self.value.weight', 'base_model.encoder.layer.13.output.LayerNorm.weight', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.5.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.17.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.6.intermediate.dense.bias', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.2.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.15.output.dense.weight', 'base_model.encoder.layer.19.attention.output.LayerNorm.weight', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.4.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.14.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.20.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.23.attention.output.dense.weight', 'base_model.encoder.layer.20.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.10.attention.output.LayerNorm.bias', 'base_model.encoder.layer.19.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.12.intermediate.dense.weight', 'base_model.encoder.layer.12.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.4.output.dense.weight', 'base_model.encoder.layer.18.attention.self.query.weight', 'base_model.embeddings.LayerNorm.bias', 'base_model.encoder.layer.19.attention.output.dense.bias', 'base_model.encoder.layer.17.intermediate.dense.bias', 'base_model.encoder.layer.15.attention.self.query.weight', 'base_model.encoder.layer.21.attention.output.dense.weight', 'base_model.encoder.layer.7.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.8.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.15.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.12.attention.output.dense.weight', 'base_model.encoder.layer.16.attention.output.dense.weight', 'base_model.encoder.layer.16.attention.output.dense.bias', 'base_model.encoder.layer.15.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.18.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.8.attention.output.dense.bias', 'base_model.encoder.layer.9.attention.output.dense.weight', 'base_model.encoder.layer.9.output.LayerNorm.bias', 'base_model.encoder.layer.7.attention.self.query.weight', 'base_model.encoder.layer.18.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.19.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.9.attention.output.LayerNorm.bias', 'base_model.encoder.layer.0.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.12.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.9.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.14.attention.self.query.weight', 'base_model.encoder.layer.15.output.LayerNorm.bias', 'base_model.encoder.layer.23.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.22.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.15.attention.output.dense.weight', 'base_model.encoder.layer.2.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.16.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.15.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.5.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.10.output.LayerNorm.bias', 'base_model.encoder.layer.2.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.12.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.14.attention.self.value.weight', 'base_model.encoder.layer.17.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.5.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.15.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.16.intermediate.dense.weight', 'base_model.encoder.layer.15.intermediate.dense.weight', 'base_model.encoder.layer.17.output.LayerNorm.weight', 'base_model.encoder.layer.2.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.0.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.3.attention.self.query.bias', 'base_model.encoder.layer.11.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.4.attention.self.key.bias', 'base_model.encoder.layer.5.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.0.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.13.attention.self.value.weight', 'base_model.encoder.layer.17.attention.self.key.bias', 'base_model.encoder.layer.23.output.LayerNorm.weight', 'base_model.encoder.layer.0.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.1.attention.self.value.bias', 'base_model.encoder.layer.17.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.1.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.6.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.23.output.dense.bias', 'base_model.encoder.layer.2.intermediate.dense.weight', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.23.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.5.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.6.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.13.intermediate.dense.weight', 'base_model.encoder.layer.2.attention.self.query.weight', 'base_model.encoder.layer.1.output.LayerNorm.weight', 'base_model.encoder.layer.11.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.21.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.16.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.13.intermediate.dense.bias', 'base_model.encoder.layer.17.attention.self.query.bias', 'base_model.encoder.layer.18.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.0.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.10.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.8.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.8.attention.self.query.weight', 'base_model.encoder.layer.10.attention.self.value.bias', 'base_model.encoder.layer.18.output.LayerNorm.weight', 'base_model.encoder.layer.12.attention.self.query.weight', 'base_model.pooler.dense.bias', 'base_model.encoder.layer.10.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.19.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.4.output.LayerNorm.weight', 'base_model.encoder.layer.3.attention.self.value.bias', 'base_model.encoder.layer.10.attention.self.key.bias', 'base_model.encoder.layer.6.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.12.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.2.attention.output.LayerNorm.weight', 'base_model.encoder.layer.19.attention.self.query.bias', 'base_model.encoder.layer.4.attention.self.query.weight', 'base_model.encoder.layer.23.intermediate.dense.weight', 'base_model.encoder.layer.22.output.LayerNorm.weight', 'base_model.encoder.layer.4.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.6.attention.self.query.bias', 'base_model.encoder.layer.16.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.5.attention.output.dense.weight', 'base_model.encoder.layer.15.attention.output.LayerNorm.bias', 'base_model.encoder.layer.0.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.1.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.21.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.8.output.dense.weight', 'base_model.encoder.layer.17.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.6.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.6.attention.self.query.weight', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.8.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.11.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.0.attention.self.key.bias', 'base_model.encoder.layer.6.output.LayerNorm.bias', 'base_model.encoder.layer.21.attention.self.query.weight', 'base_model.encoder.layer.17.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.19.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.14.attention.output.LayerNorm.weight', 'base_model.encoder.layer.15.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.18.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.14.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.5.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.13.attention.self.value.bias', 'base_model.encoder.layer.15.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.8.attention.self.key.bias', 'base_model.encoder.layer.11.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.5.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.10.attention.output.LayerNorm.weight', 'base_model.encoder.layer.15.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.21.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.4.attention.self.value.bias', 'base_model.encoder.layer.21.intermediate.dense.weight', 'base_model.encoder.layer.10.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.11.intermediate.dense.weight', 'base_model.encoder.layer.9.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.12.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.21.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.1.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.0.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.22.attention.self.query.bias', 'base_model.encoder.layer.22.intermediate.dense.weight', 'base_model.encoder.layer.5.attention.self.query.weight', 'base_model.encoder.layer.3.attention.output.LayerNorm.bias', 'base_model.encoder.layer.6.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.7.attention.self.query.bias', 'base_model.encoder.layer.10.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.21.attention.self.value.weight', 'base_model.encoder.layer.10.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.18.attention.self.value.weight', 'base_model.encoder.layer.1.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.14.attention.output.dense.weight', 'base_model.encoder.layer.17.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.20.attention.self.value.bias', 'base_model.encoder.layer.3.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.6.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.13.attention.self.query.bias', 'base_model.encoder.layer.8.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.13.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.21.output.dense.bias', 'base_model.encoder.layer.8.attention.output.LayerNorm.bias', 'base_model.encoder.layer.5.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.0.attention.self.query.bias', 'base_model.encoder.layer.10.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.20.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.6.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.0.output.dense.weight', 'base_model.encoder.layer.2.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.0.attention.self.value.weight', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.10.attention.output.dense.bias', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.15.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.0.output.LayerNorm.weight', 'base_model.encoder.layer.2.intermediate.dense.bias', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.21.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.1.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.4.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.8.attention.self.value.bias', 'base_model.encoder.layer.7.intermediate.dense.weight', 'base_model.encoder.layer.2.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.16.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.20.output.LayerNorm.bias', 'base_model.encoder.layer.16.attention.self.query.bias', 'base_model.pooler.dense.weight', 'base_model.encoder.layer.16.attention.self.value.bias', 'base_model.encoder.layer.1.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.18.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.22.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.23.output.LayerNorm.bias', 'base_model.encoder.layer.12.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.16.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.2.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.6.attention.output.dense.bias', 'base_model.encoder.layer.21.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.19.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.1.attention.self.value.weight', 'base_model.encoder.layer.0.attention.output.dense.weight', 'base_model.encoder.layer.22.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.4.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.9.attention.self.value.weight', 'base_model.encoder.layer.11.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.20.attention.self.key.weight', 'base_model.encoder.layer.6.attention.output.LayerNorm.weight', 'base_model.encoder.layer.2.attention.output.dense.bias', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.12.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.19.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.17.output.dense.bias', 'base_model.encoder.layer.12.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.3.attention.self.key.weight', 'base_model.encoder.layer.4.attention.self.key.weight', 'base_model.encoder.layer.13.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.21.attention.self.value.bias', 'base_model.encoder.layer.23.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.14.attention.self.key.bias', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.19.output.dense.weight', 'base_model.encoder.layer.3.output.LayerNorm.weight', 'base_model.encoder.layer.3.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.7.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.18.attention.self.key.weight', 'base_model.encoder.layer.23.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.4.attention.output.LayerNorm.bias', 'base_model.encoder.layer.1.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.23.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.1.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.1.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.5.attention.output.LayerNorm.bias', 'base_model.encoder.layer.11.attention.self.key.weight', 'base_model.embeddings.word_embeddings.weight', 'base_model.encoder.layer.9.attention.self.key.weight', 'base_model.encoder.layer.12.attention.self.key.weight', 'base_model.encoder.layer.14.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.19.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.19.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.7.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.10.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.0.output.dense.bias', 'base_model.encoder.layer.11.attention.self.value.weight', 'base_model.encoder.layer.13.attention.output.LayerNorm.weight', 'base_model.encoder.layer.10.attention.self.value.weight', 'base_model.encoder.layer.16.attention.self.key.weight', 'base_model.encoder.layer.11.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.2.attention.self.query.bias', 'base_model.encoder.layer.16.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.3.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.21.attention.self.query.bias', 'base_model.encoder.layer.14.attention.self.value.bias', 'base_model.encoder.layer.20.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.2.attention.output.LayerNorm.bias', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.18.attention.self.key.bias', 'base_model.encoder.layer.1.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.17.attention.self.key.weight', 'base_model.encoder.layer.14.attention.self.key.weight', 'base_model.encoder.layer.5.output.LayerNorm.weight', 'base_model.encoder.layer.1.intermediate.dense.weight', 'base_model.encoder.layer.7.intermediate.dense.bias', 'base_model.encoder.layer.9.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.14.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.18.output.LayerNorm.bias', 'base_model.encoder.layer.1.attention.self.key.weight', 'base_model.encoder.layer.22.output.dense.weight', 'base_model.encoder.layer.23.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.2.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.4.attention.self.query.bias', 'base_model.encoder.layer.5.output.dense.bias', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.15.attention.output.dense.bias', 'base_model.encoder.layer.17.output.dense.weight', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.21.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.8.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.3.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.1.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.13.output.LayerNorm.bias', 'base_model.encoder.layer.21.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.0.attention.self.value.bias', 'base_model.encoder.layer.0.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.1.attention.output.LayerNorm.weight', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.13.attention.output.dense.weight', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.20.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.3.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.23.attention.self.query.weight', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.17.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.9.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.6.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.21.output.LayerNorm.weight', 'base_model.encoder.layer.21.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.3.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.18.attention.output.dense.bias', 'base_model.encoder.layer.15.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.14.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.2.attention.output.dense.weight', 'base_model.encoder.layer.2.output.LayerNorm.weight', 'base_model.encoder.layer.17.attention.output.LayerNorm.bias', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.6.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.7.attention.self.value.bias', 'base_model.encoder.layer.14.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.6.intermediate.dense.weight', 'base_model.encoder.layer.9.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.9.output.dense.bias', 'base_model.encoder.layer.8.output.dense.bias', 'base_model.encoder.layer.10.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.21.attention.output.LayerNorm.weight', 'base_model.encoder.layer.3.attention.self.key.bias', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.14.intermediate.dense.weight', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.4.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.3.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.17.attention.output.dense.bias', 'base_model.encoder.layer.12.intermediate.dense.bias', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.20.attention.output.LayerNorm.bias', 'base_model.encoder.layer.22.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.6.output.dense.bias', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.11.attention.self.key.bias', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.21.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.22.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.19.intermediate.dense.bias', 'base_model.encoder.layer.23.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.19.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.23.attention.self.key.weight', 'base_model.encoder.layer.15.attention.self.key.bias', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.23.attention.self.key.bias', 'base_model.encoder.layer.7.output.dense.weight', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.0.intermediate.dense.weight', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.1.attention.self.query.bias', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.16.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.22.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.14.output.LayerNorm.bias', 'base_model.encoder.layer.15.attention.self.key.weight', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.13.attention.output.LayerNorm.bias', 'base_model.encoder.layer.23.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.3.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.2.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.21.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.23.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.11.attention.output.LayerNorm.bias', 'base_model.encoder.layer.7.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.19.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.18.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.11.attention.self.query.bias', 'base_model.encoder.layer.2.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.12.attention.output.dense.bias', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.8.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.0.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.4.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.10.attention.output.dense.weight', 'base_model.encoder.layer.16.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.2.output.LayerNorm.bias', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.13.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.21.intermediate.dense.bias', 'base_model.encoder.layer.0.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.11.output.dense.bias', 'base_model.encoder.layer.22.output.dense.bias', 'base_model.encoder.layer.22.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.20.attention.self.key.bias', 'base_model.encoder.layer.9.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.11.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.12.attention.self.value.weight', 'base_model.encoder.layer.20.attention.self.value.weight', 'base_model.encoder.layer.1.output.LayerNorm.bias', 'base_model.encoder.layer.11.attention.self.value.bias', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.12.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.14.output.dense.bias', 'base_model.encoder.layer.23.attention.self.value.weight', 'qa_outputs.bias', 'base_model.encoder.layer.1.attention.self.query.weight', 'base_model.encoder.layer.6.attention.self.value.bias', 'base_model.encoder.layer.7.output.dense.bias', 'base_model.encoder.layer.5.intermediate.dense.bias', 'base_model.encoder.layer.10.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.14.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.16.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.7.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.9.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.11.output.LayerNorm.bias', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.11.intermediate.dense.bias', 'base_model.encoder.layer.22.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.7.attention.self.key.bias', 'base_model.encoder.layer.11.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.20.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.11.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.1.attention.output.dense.bias', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.1.attention.output.LayerNorm.bias', 'base_model.encoder.layer.23.output.adapters.ts.adapter_up.weight', 'base_model.embeddings.LayerNorm.weight', 'base_model.encoder.layer.14.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.16.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.1.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.8.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.12.output.dense.bias', 'base_model.encoder.layer.17.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.20.attention.output.dense.bias', 'base_model.encoder.layer.4.attention.output.dense.weight', 'base_model.encoder.layer.19.output.dense.bias', 'base_model.encoder.layer.20.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.18.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.13.output.dense.bias', 'base_model.encoder.layer.12.attention.output.LayerNorm.bias', 'base_model.encoder.layer.17.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.17.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.7.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.11.output.LayerNorm.weight', 'base_model.encoder.layer.15.output.LayerNorm.weight', 'base_model.encoder.layer.4.intermediate.dense.bias', 'base_model.encoder.layer.7.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.10.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.14.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.18.intermediate.dense.bias', 'base_model.encoder.layer.23.attention.output.LayerNorm.weight', 'base_model.encoder.layer.23.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.0.intermediate.dense.bias', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.14.attention.output.LayerNorm.bias', 'base_model.encoder.layer.7.attention.self.value.weight', 'base_model.encoder.layer.17.intermediate.dense.weight', 'base_model.encoder.layer.18.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.7.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.12.attention.self.query.bias', 'base_model.encoder.layer.19.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.20.output.LayerNorm.weight', 'base_model.encoder.layer.4.attention.self.value.weight', 'base_model.encoder.layer.13.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.6.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.15.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.13.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.0.output.LayerNorm.bias', 'base_model.encoder.layer.19.attention.self.key.bias', 'base_model.encoder.layer.18.output.dense.weight', 'base_model.encoder.layer.6.attention.self.value.weight', 'base_model.encoder.layer.2.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.11.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.8.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.12.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.14.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.6.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.14.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.3.output.dense.bias', 'base_model.encoder.layer.21.attention.output.LayerNorm.bias', 'base_model.encoder.layer.19.attention.self.query.weight', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.5.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.8.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.4.attention.output.LayerNorm.weight', 'base_model.encoder.layer.5.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.2.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.12.attention.self.value.bias', 'base_model.encoder.layer.3.output.LayerNorm.bias', 'base_model.encoder.layer.13.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.5.attention.self.value.bias', 'base_model.encoder.layer.14.attention.output.dense.bias', 'base_model.encoder.layer.20.attention.self.query.weight', 'base_model.encoder.layer.8.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.21.attention.self.key.weight', 'base_model.encoder.layer.4.output.LayerNorm.bias', 'base_model.encoder.layer.6.output.LayerNorm.weight', 'base_model.encoder.layer.15.intermediate.dense.bias', 'base_model.encoder.layer.16.output.LayerNorm.weight', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.19.attention.self.key.weight', 'base_model.encoder.layer.20.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.4.attention.output.dense.bias', 'base_model.encoder.layer.9.intermediate.dense.bias', 'base_model.encoder.layer.10.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.4.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.embeddings.token_type_embeddings.weight', 'base_model.encoder.layer.17.attention.self.value.bias', 'base_model.encoder.layer.18.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.22.output.LayerNorm.bias', 'base_model.encoder.layer.10.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.9.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.13.attention.output.dense.bias', 'base_model.encoder.layer.9.attention.self.key.bias', 'base_model.encoder.layer.19.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.5.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.8.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.18.attention.self.value.bias', 'base_model.encoder.layer.6.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.18.attention.self.query.bias', 'base_model.encoder.layer.20.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.11.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.18.attention.output.dense.weight', 'base_model.encoder.layer.5.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.23.attention.output.dense.bias', 'base_model.encoder.layer.4.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.9.attention.self.query.weight', 'base_model.encoder.layer.22.attention.self.key.bias', 'base_model.encoder.layer.9.attention.output.dense.bias', 'base_model.encoder.layer.4.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.20.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.21.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.0.attention.self.key.weight', 'base_model.encoder.layer.9.attention.output.LayerNorm.weight', 'base_model.encoder.layer.3.attention.self.value.weight', 'base_model.encoder.layer.7.output.LayerNorm.bias', 'base_model.encoder.layer.21.output.LayerNorm.bias', 'base_model.encoder.layer.9.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.13.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.20.output.dense.weight', 'base_model.encoder.layer.22.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.10.attention.self.query.weight', 'base_model.encoder.layer.14.output.LayerNorm.weight', 'base_model.encoder.layer.8.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.12.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.18.output.adapters.ep.adapter_up.weight', 'base_model.embeddings.position_ids', 'base_model.encoder.layer.0.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.21.attention.self.key.bias', 'base_model.encoder.layer.1.output.dense.weight', 'base_model.encoder.layer.4.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.17.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.9.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.12.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.7.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.17.attention.output.dense.weight', 'base_model.encoder.layer.12.output.LayerNorm.bias', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.embeddings.position_embeddings.weight', 'base_model.encoder.layer.2.attention.self.key.weight', 'base_model.encoder.layer.22.intermediate.dense.bias', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.18.intermediate.dense.weight', 'base_model.encoder.layer.23.output.dense.weight', 'base_model.encoder.layer.1.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.6.attention.self.key.bias', 'base_model.encoder.layer.11.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.23.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.22.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.11.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.8.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.23.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.3.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.10.intermediate.dense.bias', 'base_model.encoder.layer.12.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.7.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.8.intermediate.dense.weight', 'base_model.encoder.layer.16.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.7.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.7.attention.self.key.weight', 'base_model.encoder.layer.13.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.6.attention.output.dense.weight', 'base_model.encoder.layer.3.output.adapters.es.adapter_up.bias']
- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of XLMRobertaModel were not initialized from the model checkpoint at /cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//squad/xlm-KG_LR8e-6_EPOCH2.0_maxlen384_batchsize4_gradacc4 and are newly initialized: ['encoder.layer.10.intermediate.dense.weight', 'encoder.layer.9.attention.self.query.bias', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.18.output.LayerNorm.weight', 'encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.layer.3.attention.self.key.weight', 'encoder.layer.18.attention.self.key.bias', 'encoder.layer.15.attention.output.dense.bias', 'encoder.layer.21.attention.self.query.bias', 'encoder.layer.20.attention.output.dense.bias', 'encoder.layer.13.attention.self.value.weight', 'encoder.layer.6.attention.output.LayerNorm.weight', 'encoder.layer.20.attention.self.query.bias', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.5.attention.self.value.weight', 'encoder.layer.22.attention.output.dense.weight', 'encoder.layer.23.attention.self.key.bias', 'encoder.layer.8.attention.self.key.bias', 'encoder.layer.10.attention.self.key.weight', 'encoder.layer.1.attention.self.query.weight', 'encoder.layer.6.attention.self.query.weight', 'encoder.layer.11.attention.self.key.bias', 'encoder.layer.7.output.LayerNorm.bias', 'encoder.layer.1.attention.self.query.bias', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.17.attention.self.value.weight', 'encoder.layer.23.intermediate.dense.weight', 'embeddings.LayerNorm.weight', 'encoder.layer.15.output.LayerNorm.weight', 'encoder.layer.13.attention.output.dense.weight', 'encoder.layer.4.attention.self.value.weight', 'encoder.layer.21.intermediate.dense.bias', 'encoder.layer.13.attention.self.key.bias', 'encoder.layer.1.attention.output.dense.weight', 'encoder.layer.12.attention.output.dense.bias', 'encoder.layer.2.attention.output.LayerNorm.weight', 'encoder.layer.7.attention.output.dense.bias', 'encoder.layer.16.intermediate.dense.bias', 'encoder.layer.2.attention.output.dense.bias', 'encoder.layer.14.attention.self.key.weight', 'encoder.layer.14.output.LayerNorm.bias', 'encoder.layer.0.attention.output.dense.weight', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.19.output.LayerNorm.bias', 'encoder.layer.2.attention.output.LayerNorm.bias', 'encoder.layer.12.output.dense.weight', 'encoder.layer.7.intermediate.dense.bias', 'encoder.layer.15.attention.self.key.weight', 'encoder.layer.3.attention.self.query.bias', 'encoder.layer.22.attention.self.value.weight', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.10.attention.self.query.bias', 'encoder.layer.10.attention.self.query.weight', 'encoder.layer.22.attention.self.query.bias', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.19.attention.self.value.weight', 'encoder.layer.14.attention.self.value.bias', 'encoder.layer.18.output.dense.weight', 'encoder.layer.20.output.LayerNorm.bias', 'encoder.layer.7.attention.self.query.weight', 'encoder.layer.15.attention.output.dense.weight', 'encoder.layer.16.attention.output.LayerNorm.bias', 'encoder.layer.13.attention.self.value.bias', 'encoder.layer.13.attention.self.query.weight', 'encoder.layer.23.attention.output.dense.weight', 'encoder.layer.8.attention.self.query.bias', 'encoder.layer.10.attention.self.key.bias', 'encoder.layer.10.attention.output.dense.bias', 'encoder.layer.11.attention.self.value.weight', 'encoder.layer.23.output.LayerNorm.bias', 'encoder.layer.3.attention.output.dense.bias', 'encoder.layer.23.intermediate.dense.bias', 'encoder.layer.7.output.LayerNorm.weight', 'encoder.layer.9.attention.self.key.bias', 'encoder.layer.8.attention.self.query.weight', 'encoder.layer.15.intermediate.dense.weight', 'encoder.layer.7.attention.self.value.bias', 'encoder.layer.11.attention.output.dense.bias', 'encoder.layer.13.output.LayerNorm.bias', 'encoder.layer.22.attention.self.key.weight', 'encoder.layer.9.output.dense.bias', 'encoder.layer.21.attention.output.dense.bias', 'encoder.layer.20.output.dense.bias', 'encoder.layer.12.output.dense.bias', 'encoder.layer.10.attention.self.value.weight', 'encoder.layer.22.attention.self.value.bias', 'encoder.layer.11.output.dense.bias', 'encoder.layer.14.attention.self.key.bias', 'encoder.layer.0.attention.self.value.bias', 'encoder.layer.7.attention.self.key.bias', 'encoder.layer.17.attention.output.LayerNorm.bias', 'encoder.layer.22.attention.output.LayerNorm.bias', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.3.attention.output.dense.weight', 'encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.1.attention.output.LayerNorm.weight', 'encoder.layer.19.attention.self.query.bias', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.10.attention.output.LayerNorm.weight', 'encoder.layer.2.attention.self.key.bias', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.17.output.dense.weight', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.0.output.dense.weight', 'encoder.layer.22.intermediate.dense.weight', 'encoder.layer.16.output.dense.bias', 'encoder.layer.18.intermediate.dense.weight', 'encoder.layer.17.attention.self.key.weight', 'encoder.layer.16.attention.self.key.weight', 'encoder.layer.1.attention.self.value.bias', 'encoder.layer.17.output.dense.bias', 'encoder.layer.2.attention.self.value.weight', 'encoder.layer.3.attention.self.value.bias', 'encoder.layer.6.attention.output.dense.bias', 'encoder.layer.23.attention.output.dense.bias', 'encoder.layer.5.attention.self.value.bias', 'encoder.layer.6.output.dense.weight', 'encoder.layer.11.attention.self.query.bias', 'encoder.layer.19.attention.self.key.weight', 'encoder.layer.9.output.LayerNorm.weight', 'encoder.layer.0.attention.self.key.weight', 'encoder.layer.14.attention.output.LayerNorm.weight', 'encoder.layer.15.output.dense.weight', 'pooler.dense.bias', 'encoder.layer.3.attention.self.value.weight', 'encoder.layer.12.attention.output.dense.weight', 'encoder.layer.11.attention.output.dense.weight', 'encoder.layer.12.attention.self.query.bias', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.6.attention.self.value.bias', 'encoder.layer.16.output.LayerNorm.weight', 'encoder.layer.13.attention.self.query.bias', 'encoder.layer.17.output.LayerNorm.bias', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.10.attention.output.dense.weight', 'encoder.layer.17.attention.self.value.bias', 'encoder.layer.13.attention.output.LayerNorm.bias', 'encoder.layer.20.attention.self.key.weight', 'encoder.layer.18.attention.self.value.bias', 'encoder.layer.21.intermediate.dense.weight', 'encoder.layer.12.attention.output.LayerNorm.weight', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.20.attention.output.dense.weight', 'encoder.layer.19.attention.output.LayerNorm.bias', 'encoder.layer.6.attention.self.key.bias', 'encoder.layer.19.intermediate.dense.bias', 'encoder.layer.14.attention.self.query.bias', 'encoder.layer.6.output.LayerNorm.bias', 'encoder.layer.3.output.dense.bias', 'encoder.layer.9.attention.self.value.weight', 'encoder.layer.17.attention.self.query.weight', 'encoder.layer.18.attention.self.key.weight', 'encoder.layer.4.attention.self.query.bias', 'encoder.layer.3.attention.self.key.bias', 'encoder.layer.8.attention.self.value.bias', 'embeddings.position_embeddings.weight', 'encoder.layer.15.attention.self.value.bias', 'encoder.layer.17.intermediate.dense.bias', 'encoder.layer.18.output.dense.bias', 'encoder.layer.18.attention.output.LayerNorm.bias', 'encoder.layer.8.attention.self.key.weight', 'encoder.layer.4.attention.self.key.weight', 'encoder.layer.2.attention.self.value.bias', 'encoder.layer.15.output.LayerNorm.bias', 'encoder.layer.23.output.LayerNorm.weight', 'encoder.layer.4.output.dense.bias', 'encoder.layer.13.intermediate.dense.weight', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.4.attention.output.LayerNorm.bias', 'encoder.layer.2.attention.self.key.weight', 'encoder.layer.7.output.dense.bias', 'encoder.layer.15.attention.self.value.weight', 'encoder.layer.8.attention.self.value.weight', 'encoder.layer.23.attention.output.LayerNorm.bias', 'encoder.layer.11.attention.output.LayerNorm.weight', 'encoder.layer.15.attention.output.LayerNorm.weight', 'encoder.layer.6.attention.self.key.weight', 'encoder.layer.20.intermediate.dense.bias', 'encoder.layer.12.attention.self.key.bias', 'encoder.layer.18.attention.output.dense.weight', 'embeddings.word_embeddings.weight', 'encoder.layer.3.attention.self.query.weight', 'encoder.layer.23.attention.self.value.bias', 'encoder.layer.22.output.dense.weight', 'encoder.layer.16.attention.self.query.bias', 'encoder.layer.9.output.LayerNorm.bias', 'encoder.layer.11.output.LayerNorm.weight', 'encoder.layer.16.attention.output.LayerNorm.weight', 'encoder.layer.21.output.LayerNorm.weight', 'encoder.layer.11.intermediate.dense.weight', 'embeddings.token_type_embeddings.weight', 'encoder.layer.1.output.dense.weight', 'encoder.layer.14.attention.output.dense.weight', 'encoder.layer.15.attention.output.LayerNorm.bias', 'encoder.layer.17.attention.output.dense.weight', 'encoder.layer.0.attention.self.key.bias', 'encoder.layer.13.output.dense.bias', 'encoder.layer.3.output.dense.weight', 'encoder.layer.19.intermediate.dense.weight', 'encoder.layer.4.attention.output.dense.weight', 'encoder.layer.11.attention.self.key.weight', 'encoder.layer.9.output.dense.weight', 'encoder.layer.13.attention.output.dense.bias', 'encoder.layer.20.attention.self.value.bias', 'encoder.layer.1.attention.self.key.bias', 'encoder.layer.0.attention.self.value.weight', 'encoder.layer.14.intermediate.dense.weight', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.12.attention.self.value.weight', 'encoder.layer.9.attention.self.value.bias', 'encoder.layer.10.output.LayerNorm.weight', 'encoder.layer.14.output.dense.weight', 'encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.layer.15.attention.self.key.bias', 'encoder.layer.23.attention.self.query.weight', 'encoder.layer.11.attention.self.value.bias', 'encoder.layer.21.output.dense.weight', 'encoder.layer.1.attention.self.key.weight', 'encoder.layer.9.attention.output.dense.bias', 'encoder.layer.9.attention.output.LayerNorm.bias', 'encoder.layer.18.attention.output.LayerNorm.weight', 'encoder.layer.16.attention.self.value.bias', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.18.intermediate.dense.bias', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.14.attention.output.dense.bias', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.19.output.LayerNorm.weight', 'encoder.layer.12.output.LayerNorm.bias', 'encoder.layer.21.attention.self.value.weight', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.13.output.LayerNorm.weight', 'encoder.layer.5.attention.self.key.bias', 'encoder.layer.11.output.LayerNorm.bias', 'encoder.layer.12.output.LayerNorm.weight', 'encoder.layer.5.attention.output.LayerNorm.weight', 'encoder.layer.21.output.dense.bias', 'encoder.layer.22.attention.output.LayerNorm.weight', 'encoder.layer.14.attention.self.value.weight', 'encoder.layer.12.attention.self.key.weight', 'encoder.layer.7.attention.output.LayerNorm.weight', 'encoder.layer.2.attention.self.query.weight', 'encoder.layer.10.output.dense.weight', 'encoder.layer.15.attention.self.query.bias', 'encoder.layer.4.attention.output.LayerNorm.weight', 'encoder.layer.12.intermediate.dense.weight', 'encoder.layer.8.attention.output.dense.bias', 'encoder.layer.19.attention.self.value.bias', 'encoder.layer.17.attention.self.query.bias', 'encoder.layer.18.attention.self.query.weight', 'encoder.layer.0.attention.self.query.bias', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.2.output.dense.weight', 'encoder.layer.5.attention.self.query.weight', 'encoder.layer.5.attention.output.dense.weight', 'encoder.layer.11.attention.self.query.weight', 'encoder.layer.1.output.dense.bias', 'encoder.layer.17.output.LayerNorm.weight', 'encoder.layer.22.attention.self.query.weight', 'encoder.layer.13.attention.output.LayerNorm.weight', 'encoder.layer.10.output.dense.bias', 'encoder.layer.12.intermediate.dense.bias', 'encoder.layer.7.attention.self.query.bias', 'encoder.layer.20.attention.self.query.weight', 'encoder.layer.17.attention.output.LayerNorm.weight', 'encoder.layer.15.output.dense.bias', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.16.attention.output.dense.bias', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.21.attention.output.dense.weight', 'encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.layer.4.attention.output.dense.bias', 'encoder.layer.5.output.dense.bias', 'encoder.layer.8.attention.output.dense.weight', 'encoder.layer.5.attention.self.key.weight', 'encoder.layer.1.attention.self.value.weight', 'encoder.layer.22.output.LayerNorm.weight', 'encoder.layer.16.attention.self.key.bias', 'encoder.layer.14.output.LayerNorm.weight', 'encoder.layer.4.attention.self.query.weight', 'encoder.layer.11.output.dense.weight', 'encoder.layer.15.intermediate.dense.bias', 'encoder.layer.12.attention.self.value.bias', 'encoder.layer.6.attention.self.value.weight', 'encoder.layer.4.output.dense.weight', 'encoder.layer.6.attention.output.LayerNorm.bias', 'encoder.layer.19.attention.output.dense.bias', 'encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.layer.16.attention.output.dense.weight', 'encoder.layer.8.output.dense.weight', 'encoder.layer.21.attention.output.LayerNorm.weight', 'encoder.layer.5.output.LayerNorm.bias', 'encoder.layer.7.attention.self.value.weight', 'encoder.layer.21.output.LayerNorm.bias', 'encoder.layer.0.attention.self.query.weight', 'encoder.layer.23.output.dense.weight', 'encoder.layer.0.attention.output.dense.bias', 'encoder.layer.2.attention.output.dense.weight', 'encoder.layer.6.output.dense.bias', 'encoder.layer.8.attention.output.LayerNorm.weight', 'pooler.dense.weight', 'encoder.layer.23.attention.self.query.bias', 'encoder.layer.18.output.LayerNorm.bias', 'encoder.layer.12.attention.output.LayerNorm.bias', 'encoder.layer.20.attention.self.value.weight', 'encoder.layer.10.attention.self.value.bias', 'encoder.layer.19.attention.self.key.bias', 'encoder.layer.8.output.LayerNorm.bias', 'encoder.layer.17.attention.self.key.bias', 'encoder.layer.22.output.LayerNorm.bias', 'encoder.layer.13.intermediate.dense.bias', 'encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.layer.10.attention.output.LayerNorm.bias', 'encoder.layer.20.output.dense.weight', 'encoder.layer.5.output.dense.weight', 'encoder.layer.23.attention.self.value.weight', 'encoder.layer.10.output.LayerNorm.bias', 'encoder.layer.21.attention.self.query.weight', 'encoder.layer.6.attention.output.dense.weight', 'encoder.layer.7.attention.output.dense.weight', 'encoder.layer.7.output.dense.weight', 'encoder.layer.18.attention.output.dense.bias', 'encoder.layer.8.attention.output.LayerNorm.bias', 'encoder.layer.17.intermediate.dense.weight', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.16.output.LayerNorm.bias', 'encoder.layer.1.attention.output.dense.bias', 'encoder.layer.8.output.LayerNorm.weight', 'encoder.layer.14.intermediate.dense.bias', 'encoder.layer.9.attention.output.dense.weight', 'encoder.layer.13.output.dense.weight', 'encoder.layer.19.attention.output.dense.weight', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.9.attention.self.key.weight', 'encoder.layer.4.attention.self.key.bias', 'encoder.layer.16.attention.self.value.weight', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.14.attention.self.query.weight', 'encoder.layer.5.attention.self.query.bias', 'encoder.layer.7.attention.output.LayerNorm.bias', 'encoder.layer.12.attention.self.query.weight', 'encoder.layer.19.attention.self.query.weight', 'encoder.layer.13.attention.self.key.weight', 'encoder.layer.15.attention.self.query.weight', 'encoder.layer.14.output.dense.bias', 'encoder.layer.20.attention.output.LayerNorm.bias', 'encoder.layer.20.attention.output.LayerNorm.weight', 'encoder.layer.20.output.LayerNorm.weight', 'encoder.layer.21.attention.self.key.weight', 'encoder.layer.22.intermediate.dense.bias', 'encoder.layer.22.attention.output.dense.bias', 'encoder.layer.19.output.dense.bias', 'encoder.layer.2.output.dense.bias', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.8.output.dense.bias', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.0.attention.output.LayerNorm.weight', 'encoder.layer.14.attention.output.LayerNorm.bias', 'encoder.layer.16.output.dense.weight', 'encoder.layer.23.attention.output.LayerNorm.weight', 'encoder.layer.9.attention.self.query.weight', 'encoder.layer.20.attention.self.key.bias', 'encoder.layer.18.attention.self.query.bias', 'encoder.layer.21.attention.self.key.bias', 'encoder.layer.17.attention.output.dense.bias', 'encoder.layer.4.attention.self.value.bias', 'encoder.layer.7.attention.self.key.weight', 'embeddings.LayerNorm.bias', 'encoder.layer.21.attention.output.LayerNorm.bias', 'encoder.layer.20.intermediate.dense.weight', 'encoder.layer.0.output.dense.bias', 'encoder.layer.6.attention.self.query.bias', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.23.attention.self.key.weight', 'encoder.layer.19.attention.output.LayerNorm.weight', 'encoder.layer.2.attention.self.query.bias', 'encoder.layer.22.attention.self.key.bias', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.22.output.dense.bias', 'encoder.layer.18.attention.self.value.weight', 'encoder.layer.16.attention.self.query.weight', 'encoder.layer.21.attention.self.value.bias', 'encoder.layer.9.attention.output.LayerNorm.weight', 'encoder.layer.16.intermediate.dense.weight', 'encoder.layer.5.attention.output.dense.bias', 'encoder.layer.19.output.dense.weight', 'encoder.layer.23.output.dense.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Overwriting existing adapter 'ep'.
Overwriting existing adapter 'tp'.
Overwriting existing adapter 'es'.
Overwriting existing adapter 'ts'.
Overwriting existing adapter fusion module 'ep,tp,es,ts'
05/09/2022 19:49:00 - INFO - __main__ -   Creating features from dataset file at .
/cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//squad/xlm-KG_LR8e-6_EPOCH2.0_maxlen384_batchsize4_gradacc4
XLMConfig {
  "architectures": [
    "XLMRobertaForMaskedLM"
  ],
  "asm": false,
  "attention_dropout": 0.1,
  "attention_probs_dropout_prob": 0.1,
  "bos_index": 0,
  "bos_token_id": 0,
  "causal": false,
  "dropout": 0.1,
  "emb_dim": 1024,
  "embed_init_std": 0.02209708691207961,
  "end_n_top": 5,
  "eos_index": 1,
  "eos_token_id": 2,
  "gelu_activation": true,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "init_std": 0.02,
  "initializer_range": 0.02,
  "intermediate_size": 4096,
  "is_encoder": true,
  "lang_id": 0,
  "layer_norm_eps": 1e-05,
  "mask_index": 5,
  "mask_token_id": 0,
  "max_position_embeddings": 514,
  "model_type": "xlm",
  "n_heads": 16,
  "n_langs": 1,
  "n_layers": 24,
  "output_past": true,
  "pad_index": 2,
  "pad_token_id": 1,
  "sinusoidal_embeddings": false,
  "start_n_top": 5,
  "summary_activation": null,
  "summary_first_dropout": 0.1,
  "summary_proj_to_labels": true,
  "summary_type": "first",
  "summary_use_proj": true,
  "transformers_version": "4.17.0",
  "type_vocab_size": 1,
  "unk_index": 3,
  "use_lang_emb": false,
  "vocab_size": 250002
}

  0%|          | 0/48 [00:00<?, ?it/s] 33%|███▎      | 16/48 [00:00<00:00, 125.53it/s] 60%|██████    | 29/48 [00:00<00:00, 112.31it/s] 92%|█████████▏| 44/48 [00:00<00:00, 125.76it/s]100%|██████████| 48/48 [00:00<00:00, 125.78it/s]
convert squad examples to features:   0%|          | 0/1190 [00:00<?, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.
convert squad examples to features:   0%|          | 1/1190 [00:00<02:40,  7.42it/s]convert squad examples to features:   5%|▌         | 65/1190 [00:00<00:06, 184.38it/s]convert squad examples to features:   8%|▊         | 97/1190 [00:00<00:05, 210.66it/s]convert squad examples to features:  14%|█▎        | 161/1190 [00:00<00:03, 300.08it/s]convert squad examples to features:  19%|█▉        | 225/1190 [00:00<00:03, 312.12it/s]convert squad examples to features:  22%|██▏       | 257/1190 [00:00<00:03, 306.81it/s]convert squad examples to features:  24%|██▍       | 289/1190 [00:01<00:03, 289.75it/s]convert squad examples to features:  27%|██▋       | 321/1190 [00:01<00:03, 270.41it/s]convert squad examples to features:  30%|██▉       | 353/1190 [00:01<00:02, 280.65it/s]convert squad examples to features:  32%|███▏      | 385/1190 [00:01<00:04, 167.53it/s]convert squad examples to features:  35%|███▌      | 417/1190 [00:01<00:04, 182.71it/s]convert squad examples to features:  38%|███▊      | 449/1190 [00:01<00:03, 195.01it/s]convert squad examples to features:  40%|████      | 481/1190 [00:02<00:03, 211.68it/s]convert squad examples to features:  43%|████▎     | 513/1190 [00:02<00:03, 219.00it/s]convert squad examples to features:  46%|████▌     | 545/1190 [00:02<00:03, 214.52it/s]convert squad examples to features:  48%|████▊     | 577/1190 [00:02<00:02, 233.41it/s]convert squad examples to features:  51%|█████     | 609/1190 [00:02<00:02, 240.30it/s]convert squad examples to features:  54%|█████▍    | 641/1190 [00:02<00:02, 225.83it/s]convert squad examples to features:  57%|█████▋    | 673/1190 [00:02<00:02, 212.68it/s]convert squad examples to features:  59%|█████▉    | 705/1190 [00:03<00:02, 226.40it/s]convert squad examples to features:  62%|██████▏   | 737/1190 [00:03<00:01, 231.16it/s]convert squad examples to features:  65%|██████▍   | 769/1190 [00:03<00:01, 246.09it/s]convert squad examples to features:  70%|███████   | 833/1190 [00:03<00:01, 255.51it/s]convert squad examples to features:  73%|███████▎  | 865/1190 [00:03<00:01, 239.60it/s]convert squad examples to features:  75%|███████▌  | 897/1190 [00:03<00:01, 239.22it/s]convert squad examples to features:  78%|███████▊  | 929/1190 [00:03<00:01, 234.10it/s]convert squad examples to features:  83%|████████▎ | 993/1190 [00:04<00:00, 259.59it/s]convert squad examples to features:  89%|████████▉ | 1057/1190 [00:04<00:00, 275.22it/s]convert squad examples to features:  94%|█████████▍| 1121/1190 [00:04<00:00, 281.08it/s]convert squad examples to features:  97%|█████████▋| 1153/1190 [00:04<00:00, 262.38it/s]convert squad examples to features: 100%|██████████| 1190/1190 [00:04<00:00, 248.17it/s]/cluster/project/sachan/yifan/softwares/anaconda/anaconda3/envs/xfactr/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2272: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

add example index and unique id:   0%|          | 0/1190 [00:00<?, ?it/s]add example index and unique id: 100%|██████████| 1190/1190 [00:00<00:00, 784783.30it/s]
05/09/2022 19:49:05 - INFO - __main__ -   Saving features into cached file ./cached_xquad.en.json_xlm-KG_LR8e-6_EPOCH2.0_maxlen384_batchsize4_gradacc4_384_en
05/09/2022 19:49:06 - INFO - __main__ -   ***** Running evaluation  *****
05/09/2022 19:49:06 - INFO - __main__ -     Num examples = 1270
05/09/2022 19:49:06 - INFO - __main__ -     Batch size = 8
Evaluating:   0%|          | 0/159 [00:00<?, ?it/s]Evaluating:   1%|          | 1/159 [00:00<02:05,  1.26it/s]Evaluating:   1%|▏         | 2/159 [00:01<01:24,  1.87it/s]Evaluating:   2%|▏         | 3/159 [00:01<01:10,  2.20it/s]Evaluating:   3%|▎         | 4/159 [00:01<01:04,  2.40it/s]Evaluating:   3%|▎         | 5/159 [00:02<01:00,  2.54it/s]Evaluating:   4%|▍         | 6/159 [00:02<00:58,  2.63it/s]Evaluating:   4%|▍         | 7/159 [00:02<00:56,  2.68it/s]Evaluating:   5%|▌         | 8/159 [00:03<00:55,  2.72it/s]Evaluating:   6%|▌         | 9/159 [00:03<00:54,  2.75it/s]Evaluating:   6%|▋         | 10/159 [00:03<00:53,  2.77it/s]Evaluating:   7%|▋         | 11/159 [00:04<00:53,  2.78it/s]Evaluating:   8%|▊         | 12/159 [00:04<00:52,  2.78it/s]Evaluating:   8%|▊         | 13/159 [00:05<00:52,  2.79it/s]Evaluating:   9%|▉         | 14/159 [00:05<00:51,  2.80it/s]Evaluating:   9%|▉         | 15/159 [00:05<00:51,  2.81it/s]Evaluating:  10%|█         | 16/159 [00:06<00:50,  2.81it/s]Evaluating:  11%|█         | 17/159 [00:06<00:50,  2.82it/s]Evaluating:  11%|█▏        | 18/159 [00:06<00:49,  2.82it/s]Evaluating:  12%|█▏        | 19/159 [00:07<00:49,  2.82it/s]Evaluating:  13%|█▎        | 20/159 [00:07<00:49,  2.82it/s]Evaluating:  13%|█▎        | 21/159 [00:07<00:48,  2.82it/s]Evaluating:  14%|█▍        | 22/159 [00:08<00:48,  2.82it/s]Evaluating:  14%|█▍        | 23/159 [00:08<00:48,  2.82it/s]Evaluating:  15%|█▌        | 24/159 [00:08<00:48,  2.78it/s]Evaluating:  16%|█▌        | 25/159 [00:09<00:48,  2.78it/s]Evaluating:  16%|█▋        | 26/159 [00:09<00:47,  2.78it/s]Evaluating:  17%|█▋        | 27/159 [00:10<00:47,  2.79it/s]Evaluating:  18%|█▊        | 28/159 [00:10<00:46,  2.80it/s]Evaluating:  18%|█▊        | 29/159 [00:10<00:46,  2.80it/s]Evaluating:  19%|█▉        | 30/159 [00:11<00:46,  2.80it/s]Evaluating:  19%|█▉        | 31/159 [00:11<00:45,  2.80it/s]Evaluating:  20%|██        | 32/159 [00:11<00:45,  2.80it/s]Evaluating:  21%|██        | 33/159 [00:12<00:45,  2.80it/s]Evaluating:  21%|██▏       | 34/159 [00:12<00:44,  2.80it/s]Evaluating:  22%|██▏       | 35/159 [00:12<00:44,  2.80it/s]Evaluating:  23%|██▎       | 36/159 [00:13<00:44,  2.79it/s]Evaluating:  23%|██▎       | 37/159 [00:13<00:43,  2.80it/s]Evaluating:  24%|██▍       | 38/159 [00:13<00:43,  2.80it/s]Evaluating:  25%|██▍       | 39/159 [00:14<00:42,  2.80it/s]Evaluating:  25%|██▌       | 40/159 [00:14<00:42,  2.80it/s]Evaluating:  26%|██▌       | 41/159 [00:15<00:42,  2.80it/s]Evaluating:  26%|██▋       | 42/159 [00:15<00:41,  2.80it/s]Evaluating:  27%|██▋       | 43/159 [00:15<00:41,  2.80it/s]Evaluating:  28%|██▊       | 44/159 [00:16<00:41,  2.80it/s]Evaluating:  28%|██▊       | 45/159 [00:16<00:40,  2.80it/s]Evaluating:  29%|██▉       | 46/159 [00:16<00:40,  2.80it/s]Evaluating:  30%|██▉       | 47/159 [00:17<00:40,  2.79it/s]Evaluating:  30%|███       | 48/159 [00:17<00:39,  2.79it/s]Evaluating:  31%|███       | 49/159 [00:17<00:39,  2.79it/s]Evaluating:  31%|███▏      | 50/159 [00:18<00:39,  2.79it/s]Evaluating:  32%|███▏      | 51/159 [00:18<00:38,  2.78it/s]Evaluating:  33%|███▎      | 52/159 [00:19<00:38,  2.77it/s]Evaluating:  33%|███▎      | 53/159 [00:19<00:38,  2.75it/s]Evaluating:  34%|███▍      | 54/159 [00:19<00:38,  2.75it/s]Evaluating:  35%|███▍      | 55/159 [00:20<00:37,  2.75it/s]Evaluating:  35%|███▌      | 56/159 [00:20<00:37,  2.75it/s]Evaluating:  36%|███▌      | 57/159 [00:20<00:36,  2.76it/s]Evaluating:  36%|███▋      | 58/159 [00:21<00:36,  2.75it/s]Evaluating:  37%|███▋      | 59/159 [00:21<00:36,  2.76it/s]Evaluating:  38%|███▊      | 60/159 [00:21<00:35,  2.76it/s]Evaluating:  38%|███▊      | 61/159 [00:22<00:35,  2.77it/s]Evaluating:  39%|███▉      | 62/159 [00:22<00:34,  2.78it/s]Evaluating:  40%|███▉      | 63/159 [00:22<00:34,  2.78it/s]Evaluating:  40%|████      | 64/159 [00:23<00:34,  2.79it/s]Evaluating:  41%|████      | 65/159 [00:23<00:33,  2.78it/s]Evaluating:  42%|████▏     | 66/159 [00:24<00:33,  2.78it/s]Evaluating:  42%|████▏     | 67/159 [00:24<00:33,  2.79it/s]Evaluating:  43%|████▎     | 68/159 [00:24<00:32,  2.78it/s]Evaluating:  43%|████▎     | 69/159 [00:25<00:32,  2.79it/s]Evaluating:  44%|████▍     | 70/159 [00:25<00:31,  2.79it/s]Evaluating:  45%|████▍     | 71/159 [00:25<00:31,  2.79it/s]Evaluating:  45%|████▌     | 72/159 [00:26<00:31,  2.78it/s]Evaluating:  46%|████▌     | 73/159 [00:26<00:30,  2.78it/s]Evaluating:  47%|████▋     | 74/159 [00:26<00:30,  2.77it/s]Evaluating:  47%|████▋     | 75/159 [00:27<00:30,  2.77it/s]Evaluating:  48%|████▊     | 76/159 [00:27<00:29,  2.77it/s]Evaluating:  48%|████▊     | 77/159 [00:28<00:29,  2.78it/s]Evaluating:  49%|████▉     | 78/159 [00:28<00:29,  2.78it/s]Evaluating:  50%|████▉     | 79/159 [00:28<00:28,  2.78it/s]Evaluating:  50%|█████     | 80/159 [00:29<00:28,  2.78it/s]Evaluating:  51%|█████     | 81/159 [00:29<00:27,  2.79it/s]Evaluating:  52%|█████▏    | 82/159 [00:29<00:27,  2.79it/s]Evaluating:  52%|█████▏    | 83/159 [00:30<00:27,  2.79it/s]Evaluating:  53%|█████▎    | 84/159 [00:30<00:26,  2.78it/s]Evaluating:  53%|█████▎    | 85/159 [00:30<00:26,  2.77it/s]Evaluating:  54%|█████▍    | 86/159 [00:31<00:26,  2.77it/s]Evaluating:  55%|█████▍    | 87/159 [00:31<00:25,  2.77it/s]Evaluating:  55%|█████▌    | 88/159 [00:31<00:25,  2.77it/s]Evaluating:  56%|█████▌    | 89/159 [00:32<00:25,  2.78it/s]Evaluating:  57%|█████▋    | 90/159 [00:32<00:24,  2.77it/s]Evaluating:  57%|█████▋    | 91/159 [00:33<00:24,  2.77it/s]Evaluating:  58%|█████▊    | 92/159 [00:33<00:24,  2.76it/s]Evaluating:  58%|█████▊    | 93/159 [00:33<00:23,  2.76it/s]Evaluating:  59%|█████▉    | 94/159 [00:34<00:23,  2.75it/s]Evaluating:  60%|█████▉    | 95/159 [00:34<00:23,  2.77it/s]Evaluating:  60%|██████    | 96/159 [00:34<00:22,  2.77it/s]Evaluating:  61%|██████    | 97/159 [00:35<00:22,  2.78it/s]Evaluating:  62%|██████▏   | 98/159 [00:35<00:21,  2.78it/s]Evaluating:  62%|██████▏   | 99/159 [00:35<00:21,  2.78it/s]Evaluating:  63%|██████▎   | 100/159 [00:36<00:21,  2.79it/s]Evaluating:  64%|██████▎   | 101/159 [00:36<00:20,  2.78it/s]Evaluating:  64%|██████▍   | 102/159 [00:37<00:20,  2.79it/s]Evaluating:  65%|██████▍   | 103/159 [00:37<00:20,  2.79it/s]Evaluating:  65%|██████▌   | 104/159 [00:37<00:19,  2.80it/s]Evaluating:  66%|██████▌   | 105/159 [00:38<00:19,  2.80it/s]Evaluating:  67%|██████▋   | 106/159 [00:38<00:18,  2.80it/s]Evaluating:  67%|██████▋   | 107/159 [00:38<00:18,  2.80it/s]Evaluating:  68%|██████▊   | 108/159 [00:39<00:18,  2.79it/s]Evaluating:  69%|██████▊   | 109/159 [00:39<00:17,  2.78it/s]Evaluating:  69%|██████▉   | 110/159 [00:39<00:17,  2.79it/s]Evaluating:  70%|██████▉   | 111/159 [00:40<00:17,  2.79it/s]Evaluating:  70%|███████   | 112/159 [00:40<00:16,  2.79it/s]Evaluating:  71%|███████   | 113/159 [00:40<00:16,  2.79it/s]Evaluating:  72%|███████▏  | 114/159 [00:41<00:16,  2.78it/s]Evaluating:  72%|███████▏  | 115/159 [00:41<00:15,  2.78it/s]Evaluating:  73%|███████▎  | 116/159 [00:42<00:15,  2.78it/s]Evaluating:  74%|███████▎  | 117/159 [00:42<00:15,  2.78it/s]Evaluating:  74%|███████▍  | 118/159 [00:42<00:14,  2.78it/s]Evaluating:  75%|███████▍  | 119/159 [00:43<00:14,  2.78it/s]Evaluating:  75%|███████▌  | 120/159 [00:43<00:14,  2.77it/s]Evaluating:  76%|███████▌  | 121/159 [00:43<00:13,  2.78it/s]Evaluating:  77%|███████▋  | 122/159 [00:44<00:13,  2.77it/s]Evaluating:  77%|███████▋  | 123/159 [00:44<00:12,  2.77it/s]Evaluating:  78%|███████▊  | 124/159 [00:44<00:12,  2.78it/s]Evaluating:  79%|███████▊  | 125/159 [00:45<00:12,  2.77it/s]Evaluating:  79%|███████▉  | 126/159 [00:45<00:11,  2.77it/s]Evaluating:  80%|███████▉  | 127/159 [00:46<00:11,  2.77it/s]Evaluating:  81%|████████  | 128/159 [00:46<00:11,  2.77it/s]Evaluating:  81%|████████  | 129/159 [00:46<00:10,  2.78it/s]Evaluating:  82%|████████▏ | 130/159 [00:47<00:10,  2.78it/s]Evaluating:  82%|████████▏ | 131/159 [00:47<00:10,  2.79it/s]Evaluating:  83%|████████▎ | 132/159 [00:47<00:09,  2.79it/s]Evaluating:  84%|████████▎ | 133/159 [00:48<00:09,  2.79it/s]Evaluating:  84%|████████▍ | 134/159 [00:48<00:09,  2.78it/s]Evaluating:  85%|████████▍ | 135/159 [00:48<00:08,  2.78it/s]Evaluating:  86%|████████▌ | 136/159 [00:49<00:08,  2.78it/s]Evaluating:  86%|████████▌ | 137/159 [00:49<00:07,  2.78it/s]Evaluating:  87%|████████▋ | 138/159 [00:49<00:07,  2.78it/s]Evaluating:  87%|████████▋ | 139/159 [00:50<00:07,  2.78it/s]Evaluating:  88%|████████▊ | 140/159 [00:50<00:06,  2.78it/s]Evaluating:  89%|████████▊ | 141/159 [00:51<00:06,  2.77it/s]Evaluating:  89%|████████▉ | 142/159 [00:51<00:06,  2.77it/s]Evaluating:  90%|████████▉ | 143/159 [00:51<00:05,  2.78it/s]Evaluating:  91%|█████████ | 144/159 [00:52<00:05,  2.78it/s]Evaluating:  91%|█████████ | 145/159 [00:52<00:05,  2.77it/s]Evaluating:  92%|█████████▏| 146/159 [00:52<00:04,  2.77it/s]Evaluating:  92%|█████████▏| 147/159 [00:53<00:04,  2.78it/s]Evaluating:  93%|█████████▎| 148/159 [00:53<00:03,  2.78it/s]Evaluating:  94%|█████████▎| 149/159 [00:53<00:03,  2.78it/s]Evaluating:  94%|█████████▍| 150/159 [00:54<00:03,  2.78it/s]Evaluating:  95%|█████████▍| 151/159 [00:54<00:02,  2.78it/s]Evaluating:  96%|█████████▌| 152/159 [00:55<00:02,  2.78it/s]Evaluating:  96%|█████████▌| 153/159 [00:55<00:02,  2.78it/s]Evaluating:  97%|█████████▋| 154/159 [00:55<00:01,  2.78it/s]Evaluating:  97%|█████████▋| 155/159 [00:56<00:01,  2.78it/s]Evaluating:  98%|█████████▊| 156/159 [00:56<00:01,  2.79it/s]Evaluating:  99%|█████████▊| 157/159 [00:56<00:00,  2.78it/s]Evaluating:  99%|█████████▉| 158/159 [00:57<00:00,  2.78it/s]Evaluating: 100%|██████████| 159/159 [00:57<00:00,  3.02it/s]Evaluating: 100%|██████████| 159/159 [00:57<00:00,  2.77it/s]
05/09/2022 19:50:04 - INFO - __main__ -     Evaluation done in total 57.423118 secs (0.045215 sec per example)
05/09/2022 19:50:07 - INFO - __main__ -   Results: {'exact': 77.6470588235294, 'f1': 88.04320791209703, 'total': 1190, 'HasAns_exact': 77.6470588235294, 'HasAns_f1': 88.04320791209703, 'HasAns_total': 1190, 'best_exact': 77.6470588235294, 'best_exact_thresh': 0.0, 'best_f1': 88.04320791209703, 'best_f1_thresh': 0.0}
  es 
2022-05-09 19:50:10.201279: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0
05/09/2022 19:50:15 - WARNING - __main__ -   Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, 16-bits training: False
You are using a model of type xlm-roberta to instantiate a model of type xlm. This is not supported for all configurations of models and can yield errors.
Some weights of the model checkpoint at /cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//squad/xlm-KG_LR8e-6_EPOCH2.0_maxlen384_batchsize4_gradacc4 were not used when initializing XLMRobertaModel: ['base_model.encoder.layer.16.attention.self.query.bias', 'base_model.encoder.layer.14.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.15.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.18.attention.self.value.weight', 'base_model.encoder.layer.11.attention.self.value.weight', 'base_model.encoder.layer.2.attention.self.query.weight', 'base_model.encoder.layer.4.output.dense.bias', 'base_model.encoder.layer.15.output.LayerNorm.bias', 'base_model.encoder.layer.2.output.dense.bias', 'base_model.encoder.layer.15.attention.self.query.weight', 'base_model.encoder.layer.7.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.1.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.20.attention.output.LayerNorm.weight', 'base_model.encoder.layer.20.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.0.attention.output.LayerNorm.bias', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.23.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.21.attention.self.query.bias', 'base_model.encoder.layer.9.attention.self.key.bias', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.4.attention.self.value.bias', 'base_model.encoder.layer.7.attention.self.key.weight', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.3.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.6.attention.self.key.weight', 'base_model.encoder.layer.10.output.LayerNorm.weight', 'base_model.encoder.layer.1.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.4.output.dense.weight', 'base_model.encoder.layer.18.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.4.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.6.output.dense.weight', 'base_model.encoder.layer.16.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.20.attention.output.dense.weight', 'base_model.encoder.layer.19.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.18.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.7.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.6.attention.self.query.bias', 'base_model.encoder.layer.13.attention.output.LayerNorm.bias', 'base_model.encoder.layer.16.attention.self.key.weight', 'base_model.encoder.layer.1.attention.self.query.weight', 'base_model.encoder.layer.1.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.4.attention.output.dense.bias', 'base_model.encoder.layer.1.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.10.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.9.output.dense.weight', 'base_model.encoder.layer.9.attention.self.value.weight', 'base_model.encoder.layer.7.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.15.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.20.intermediate.dense.bias', 'base_model.encoder.layer.10.intermediate.dense.bias', 'base_model.encoder.layer.5.attention.self.key.weight', 'base_model.encoder.layer.8.attention.output.dense.weight', 'base_model.encoder.layer.23.attention.self.value.weight', 'base_model.encoder.layer.10.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.12.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.5.output.LayerNorm.weight', 'base_model.encoder.layer.8.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.10.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.20.attention.self.key.bias', 'base_model.encoder.layer.0.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.6.attention.self.value.bias', 'base_model.encoder.layer.6.output.LayerNorm.weight', 'base_model.encoder.layer.12.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.14.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.15.attention.self.key.weight', 'base_model.encoder.layer.19.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.18.attention.self.query.weight', 'base_model.encoder.layer.2.attention.output.dense.bias', 'base_model.encoder.layer.21.attention.output.dense.bias', 'base_model.encoder.layer.20.attention.self.key.weight', 'base_model.encoder.layer.0.output.dense.bias', 'base_model.encoder.layer.0.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.21.output.dense.weight', 'base_model.encoder.layer.10.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.11.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.5.attention.output.dense.weight', 'base_model.encoder.layer.13.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.12.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.22.attention.output.dense.weight', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.1.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.0.intermediate.dense.bias', 'base_model.encoder.layer.12.output.LayerNorm.weight', 'base_model.encoder.layer.13.intermediate.dense.weight', 'base_model.encoder.layer.15.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.21.attention.self.key.weight', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.20.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.23.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.0.output.dense.weight', 'base_model.encoder.layer.7.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.13.attention.output.dense.weight', 'base_model.encoder.layer.2.output.LayerNorm.weight', 'base_model.encoder.layer.22.intermediate.dense.weight', 'base_model.encoder.layer.11.attention.self.key.weight', 'base_model.encoder.layer.20.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.6.attention.output.LayerNorm.weight', 'base_model.encoder.layer.6.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.6.output.LayerNorm.bias', 'base_model.encoder.layer.15.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.22.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.17.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.12.attention.self.query.weight', 'base_model.encoder.layer.12.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.18.attention.self.key.bias', 'base_model.encoder.layer.13.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.15.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.12.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.15.output.dense.weight', 'base_model.encoder.layer.18.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.5.attention.self.key.bias', 'base_model.encoder.layer.18.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.6.intermediate.dense.bias', 'base_model.encoder.layer.6.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.5.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.21.output.dense.bias', 'base_model.encoder.layer.23.attention.self.key.weight', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.13.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.7.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.23.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.15.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.5.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.1.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.11.attention.self.query.weight', 'base_model.encoder.layer.1.attention.output.LayerNorm.weight', 'base_model.encoder.layer.7.output.LayerNorm.bias', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.3.attention.self.query.weight', 'base_model.encoder.layer.10.intermediate.dense.weight', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.3.attention.output.dense.weight', 'base_model.encoder.layer.17.output.dense.weight', 'base_model.encoder.layer.13.attention.self.query.weight', 'base_model.encoder.layer.18.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.9.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.14.attention.output.dense.bias', 'base_model.encoder.layer.16.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.1.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.19.output.dense.bias', 'base_model.encoder.layer.18.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.3.attention.output.dense.bias', 'base_model.encoder.layer.11.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.12.attention.output.LayerNorm.weight', 'base_model.encoder.layer.20.attention.output.dense.bias', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.12.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.8.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.3.output.adapters.ts.adapter_down.0.weight', 'base_model.embeddings.position_embeddings.weight', 'base_model.encoder.layer.22.intermediate.dense.bias', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.23.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.11.intermediate.dense.bias', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.9.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.1.attention.self.value.weight', 'base_model.encoder.layer.10.attention.self.key.bias', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.22.attention.self.value.bias', 'base_model.encoder.layer.2.output.dense.weight', 'base_model.encoder.layer.3.output.dense.bias', 'base_model.encoder.layer.0.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.2.attention.output.LayerNorm.bias', 'base_model.encoder.layer.9.attention.output.dense.bias', 'base_model.encoder.layer.6.attention.output.LayerNorm.bias', 'base_model.encoder.layer.13.attention.self.query.bias', 'base_model.encoder.layer.7.attention.self.query.weight', 'base_model.encoder.layer.22.output.LayerNorm.bias', 'base_model.encoder.layer.9.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.15.intermediate.dense.bias', 'base_model.encoder.layer.16.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.8.attention.self.key.weight', 'base_model.encoder.layer.0.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.15.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.18.output.LayerNorm.bias', 'base_model.encoder.layer.6.intermediate.dense.weight', 'base_model.encoder.layer.17.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.2.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.20.attention.self.query.weight', 'base_model.encoder.layer.11.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.15.attention.self.value.weight', 'base_model.encoder.layer.5.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.10.output.dense.bias', 'base_model.encoder.layer.3.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.13.output.dense.bias', 'base_model.encoder.layer.7.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.8.intermediate.dense.weight', 'base_model.encoder.layer.5.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.2.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.18.attention.output.dense.weight', 'base_model.encoder.layer.18.output.dense.weight', 'base_model.encoder.layer.7.output.LayerNorm.weight', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.2.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.11.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.14.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.23.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.19.output.LayerNorm.weight', 'base_model.encoder.layer.17.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.0.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.20.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.0.attention.self.key.weight', 'base_model.encoder.layer.5.attention.self.value.bias', 'base_model.encoder.layer.10.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.18.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.3.attention.self.key.weight', 'base_model.encoder.layer.21.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.0.attention.output.LayerNorm.weight', 'base_model.encoder.layer.9.output.dense.bias', 'base_model.encoder.layer.12.attention.self.key.bias', 'base_model.encoder.layer.5.attention.self.query.weight', 'base_model.encoder.layer.23.attention.output.dense.bias', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.8.attention.self.query.weight', 'base_model.encoder.layer.12.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.16.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.19.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.5.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.16.intermediate.dense.weight', 'base_model.encoder.layer.22.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.21.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.6.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.1.intermediate.dense.bias', 'base_model.encoder.layer.14.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.13.intermediate.dense.bias', 'base_model.encoder.layer.11.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.12.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.15.attention.output.LayerNorm.weight', 'base_model.encoder.layer.6.attention.self.query.weight', 'base_model.encoder.layer.18.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.3.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.18.intermediate.dense.weight', 'base_model.encoder.layer.1.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.0.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.1.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.15.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.17.attention.self.query.bias', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.10.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.10.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.7.attention.self.key.bias', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.19.intermediate.dense.bias', 'base_model.encoder.layer.14.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.21.attention.output.LayerNorm.weight', 'base_model.encoder.layer.4.intermediate.dense.bias', 'base_model.encoder.layer.6.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.11.attention.self.value.bias', 'base_model.encoder.layer.6.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.14.attention.output.LayerNorm.weight', 'base_model.encoder.layer.9.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.17.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.15.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.21.attention.self.value.bias', 'base_model.encoder.layer.22.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.23.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.7.attention.self.value.weight', 'base_model.encoder.layer.13.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.23.attention.self.value.bias', 'base_model.encoder.layer.4.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.14.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.16.output.LayerNorm.bias', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.23.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.13.attention.output.dense.bias', 'base_model.encoder.layer.0.attention.self.query.bias', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.20.attention.self.value.bias', 'base_model.encoder.layer.9.attention.self.query.bias', 'base_model.encoder.layer.12.intermediate.dense.bias', 'base_model.encoder.layer.4.attention.self.key.bias', 'base_model.encoder.layer.17.output.LayerNorm.bias', 'base_model.encoder.layer.13.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.11.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.17.attention.self.key.weight', 'base_model.encoder.layer.4.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.12.output.LayerNorm.bias', 'base_model.encoder.layer.15.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.7.output.adapters.es.adapter_up.bias', 'base_model.embeddings.LayerNorm.weight', 'base_model.encoder.layer.9.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.12.output.dense.bias', 'base_model.encoder.layer.4.output.LayerNorm.bias', 'base_model.encoder.layer.19.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.8.attention.self.key.bias', 'base_model.encoder.layer.4.attention.self.query.bias', 'base_model.encoder.layer.1.intermediate.dense.weight', 'base_model.encoder.layer.22.attention.self.key.weight', 'base_model.encoder.layer.17.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.17.attention.output.LayerNorm.bias', 'base_model.encoder.layer.9.intermediate.dense.weight', 'base_model.encoder.layer.9.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.10.attention.output.dense.bias', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.2.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.12.attention.self.value.bias', 'base_model.encoder.layer.13.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.3.output.LayerNorm.weight', 'base_model.encoder.layer.7.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.12.output.dense.weight', 'base_model.encoder.layer.10.attention.self.value.weight', 'base_model.encoder.layer.20.output.dense.weight', 'base_model.encoder.layer.16.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.2.output.LayerNorm.bias', 'base_model.encoder.layer.18.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.3.attention.self.value.weight', 'base_model.encoder.layer.1.output.dense.weight', 'base_model.encoder.layer.16.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.1.attention.self.query.bias', 'base_model.encoder.layer.10.attention.output.LayerNorm.weight', 'base_model.encoder.layer.19.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.22.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.22.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.10.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.12.attention.output.dense.bias', 'base_model.encoder.layer.20.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.4.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.17.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.22.output.LayerNorm.weight', 'base_model.encoder.layer.3.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.9.attention.self.value.bias', 'base_model.encoder.layer.14.output.dense.weight', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.5.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.16.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.1.attention.self.value.bias', 'base_model.encoder.layer.14.attention.self.query.weight', 'base_model.encoder.layer.17.attention.output.dense.weight', 'base_model.encoder.layer.0.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.2.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.4.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.15.output.dense.bias', 'base_model.encoder.layer.20.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.6.output.dense.bias', 'base_model.pooler.dense.weight', 'base_model.encoder.layer.9.intermediate.dense.bias', 'base_model.encoder.layer.6.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.15.attention.self.query.bias', 'base_model.encoder.layer.16.intermediate.dense.bias', 'base_model.encoder.layer.5.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.16.attention.output.LayerNorm.bias', 'base_model.encoder.layer.5.output.LayerNorm.bias', 'base_model.encoder.layer.23.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.20.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.13.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.11.intermediate.dense.weight', 'base_model.encoder.layer.21.intermediate.dense.bias', 'base_model.encoder.layer.6.attention.output.dense.weight', 'base_model.encoder.layer.13.output.LayerNorm.weight', 'base_model.encoder.layer.1.attention.output.LayerNorm.bias', 'base_model.encoder.layer.16.output.dense.weight', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.21.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.8.attention.self.value.bias', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.15.attention.output.LayerNorm.bias', 'base_model.encoder.layer.23.attention.self.key.bias', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.8.attention.output.dense.bias', 'base_model.encoder.layer.19.attention.output.dense.weight', 'base_model.encoder.layer.7.output.dense.bias', 'base_model.encoder.layer.16.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.17.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.21.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.5.intermediate.dense.weight', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.20.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.0.attention.self.value.bias', 'base_model.encoder.layer.22.attention.self.value.weight', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.10.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.21.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.9.output.LayerNorm.bias', 'base_model.encoder.layer.6.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.19.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.2.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.7.intermediate.dense.bias', 'base_model.encoder.layer.21.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.16.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.5.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.19.attention.output.LayerNorm.bias', 'base_model.encoder.layer.9.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.1.attention.output.dense.weight', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.23.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.8.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.21.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.3.intermediate.dense.weight', 'base_model.encoder.layer.5.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.1.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.2.attention.self.value.weight', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.15.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.4.attention.self.value.weight', 'base_model.encoder.layer.22.attention.output.LayerNorm.bias', 'base_model.encoder.layer.10.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.7.output.dense.weight', 'base_model.encoder.layer.1.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.2.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.9.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.6.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.7.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.0.attention.output.dense.bias', 'base_model.encoder.layer.4.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.10.attention.self.query.weight', 'base_model.encoder.layer.1.attention.self.key.bias', 'base_model.encoder.layer.17.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.19.attention.self.value.weight', 'base_model.encoder.layer.19.attention.output.LayerNorm.weight', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.5.intermediate.dense.bias', 'base_model.encoder.layer.20.output.LayerNorm.bias', 'base_model.encoder.layer.3.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.0.attention.self.value.weight', 'base_model.encoder.layer.4.output.LayerNorm.weight', 'base_model.encoder.layer.7.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.13.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.21.attention.output.LayerNorm.bias', 'base_model.encoder.layer.21.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.23.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.3.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.8.intermediate.dense.bias', 'base_model.encoder.layer.13.output.LayerNorm.bias', 'base_model.encoder.layer.17.attention.self.key.bias', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.5.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.2.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.0.attention.output.dense.weight', 'base_model.encoder.layer.4.attention.self.query.weight', 'base_model.encoder.layer.6.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.20.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.16.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.21.attention.self.query.weight', 'base_model.encoder.layer.23.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.20.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.0.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.11.attention.output.LayerNorm.bias', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.21.attention.output.dense.weight', 'base_model.encoder.layer.14.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.16.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.9.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.9.attention.self.key.weight', 'base_model.encoder.layer.12.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.5.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.23.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.19.output.LayerNorm.bias', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.10.attention.self.value.bias', 'base_model.encoder.layer.5.output.dense.weight', 'base_model.encoder.layer.20.attention.self.value.weight', 'base_model.encoder.layer.23.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.17.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.17.intermediate.dense.weight', 'base_model.encoder.layer.18.attention.output.LayerNorm.bias', 'base_model.encoder.layer.19.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.11.output.LayerNorm.bias', 'base_model.encoder.layer.12.attention.output.dense.weight', 'base_model.encoder.layer.21.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.14.output.LayerNorm.weight', 'base_model.encoder.layer.6.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.16.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.2.attention.self.key.bias', 'base_model.encoder.layer.16.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.9.attention.output.LayerNorm.bias', 'base_model.encoder.layer.2.attention.self.query.bias', 'base_model.encoder.layer.12.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.21.attention.self.key.bias', 'base_model.encoder.layer.18.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.19.attention.self.key.weight', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.15.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.8.attention.self.value.weight', 'base_model.encoder.layer.18.attention.self.query.bias', 'base_model.encoder.layer.2.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.23.attention.self.query.bias', 'base_model.encoder.layer.23.attention.output.LayerNorm.bias', 'base_model.encoder.layer.5.output.dense.bias', 'base_model.encoder.layer.19.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.2.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.16.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.10.attention.self.key.weight', 'base_model.encoder.layer.14.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.17.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.0.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.7.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.5.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.15.output.LayerNorm.weight', 'base_model.encoder.layer.13.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.20.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.4.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.14.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.17.attention.self.value.weight', 'base_model.encoder.layer.11.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.10.output.LayerNorm.bias', 'base_model.encoder.layer.13.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.0.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.11.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.17.output.dense.bias', 'base_model.encoder.layer.22.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.0.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.18.attention.output.LayerNorm.weight', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.19.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.6.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.22.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.3.attention.output.LayerNorm.bias', 'base_model.encoder.layer.19.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.16.attention.self.key.bias', 'base_model.encoder.layer.20.attention.output.LayerNorm.bias', 'base_model.encoder.layer.23.output.dense.weight', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.1.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.8.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.6.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.8.output.dense.bias', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.4.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.9.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.12.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.14.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.13.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.6.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.13.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.18.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.8.output.LayerNorm.bias', 'base_model.encoder.layer.17.intermediate.dense.bias', 'base_model.encoder.layer.8.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.11.output.dense.bias', 'base_model.encoder.layer.13.attention.self.key.bias', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.22.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.18.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.2.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.9.attention.output.dense.weight', 'base_model.encoder.layer.23.attention.output.dense.weight', 'base_model.encoder.layer.7.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.12.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'qa_outputs.bias', 'base_model.encoder.layer.17.output.LayerNorm.weight', 'base_model.encoder.layer.23.attention.output.LayerNorm.weight', 'base_model.encoder.layer.14.intermediate.dense.weight', 'base_model.encoder.layer.9.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.22.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.2.intermediate.dense.weight', 'base_model.encoder.layer.4.attention.output.LayerNorm.weight', 'base_model.encoder.layer.19.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.6.attention.self.key.bias', 'base_model.encoder.layer.19.attention.self.key.bias', 'base_model.encoder.layer.11.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.23.intermediate.dense.bias', 'base_model.encoder.layer.10.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.9.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.22.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.0.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.12.intermediate.dense.weight', 'base_model.encoder.layer.21.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.22.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.16.output.LayerNorm.weight', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.4.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.19.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.22.output.dense.bias', 'base_model.encoder.layer.11.attention.output.dense.weight', 'base_model.encoder.layer.23.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.3.attention.self.query.bias', 'base_model.encoder.layer.14.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.3.attention.output.LayerNorm.weight', 'base_model.encoder.layer.10.attention.output.LayerNorm.bias', 'base_model.encoder.layer.13.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.17.attention.self.value.bias', 'base_model.encoder.layer.17.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.20.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.9.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.19.output.dense.weight', 'base_model.encoder.layer.23.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.3.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.10.attention.output.dense.weight', 'base_model.encoder.layer.14.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.14.output.dense.bias', 'base_model.encoder.layer.6.attention.output.dense.bias', 'base_model.encoder.layer.0.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.17.attention.output.dense.bias', 'base_model.encoder.layer.7.attention.self.value.bias', 'base_model.encoder.layer.8.output.LayerNorm.weight', 'base_model.encoder.layer.21.attention.self.value.weight', 'base_model.encoder.layer.3.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.4.intermediate.dense.weight', 'base_model.encoder.layer.4.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.18.output.dense.bias', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.5.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.15.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.9.attention.output.LayerNorm.weight', 'base_model.encoder.layer.18.intermediate.dense.bias', 'base_model.encoder.layer.3.attention.self.value.bias', 'base_model.encoder.layer.4.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.12.attention.self.query.bias', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.18.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.0.output.LayerNorm.bias', 'base_model.encoder.layer.17.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.8.output.dense.weight', 'base_model.encoder.layer.22.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.14.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.10.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.19.intermediate.dense.weight', 'base_model.encoder.layer.7.attention.output.LayerNorm.bias', 'base_model.encoder.layer.17.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.19.attention.self.query.weight', 'base_model.embeddings.LayerNorm.bias', 'base_model.encoder.layer.14.attention.output.dense.weight', 'base_model.encoder.layer.1.attention.output.dense.bias', 'base_model.encoder.layer.9.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.8.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.16.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.7.attention.output.dense.weight', 'base_model.encoder.layer.19.attention.self.value.bias', 'base_model.encoder.layer.4.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.22.attention.output.dense.bias', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.2.attention.output.dense.weight', 'base_model.encoder.layer.14.attention.self.value.bias', 'base_model.encoder.layer.15.attention.self.key.bias', 'base_model.encoder.layer.3.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.18.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.21.intermediate.dense.weight', 'base_model.encoder.layer.10.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.1.output.LayerNorm.bias', 'base_model.encoder.layer.12.attention.self.value.weight', 'base_model.encoder.layer.11.output.LayerNorm.weight', 'base_model.encoder.layer.4.attention.output.LayerNorm.bias', 'base_model.encoder.layer.8.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.0.attention.self.key.bias', 'base_model.encoder.layer.16.output.dense.bias', 'base_model.encoder.layer.19.attention.self.query.bias', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.16.attention.output.LayerNorm.weight', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.7.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.3.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.7.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.11.output.dense.weight', 'base_model.encoder.layer.22.attention.self.key.bias', 'base_model.encoder.layer.1.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.1.attention.self.key.weight', 'base_model.encoder.layer.13.attention.self.value.bias', 'base_model.encoder.layer.8.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.16.attention.self.value.bias', 'base_model.encoder.layer.19.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.10.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.17.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.13.output.dense.weight', 'base_model.encoder.layer.8.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.20.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.21.output.LayerNorm.weight', 'base_model.encoder.layer.13.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.17.attention.self.query.weight', 'base_model.encoder.layer.7.attention.output.dense.bias', 'base_model.encoder.layer.5.attention.self.value.weight', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.4.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.7.attention.self.query.bias', 'base_model.encoder.layer.19.attention.output.dense.bias', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.6.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.2.attention.self.key.weight', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.15.attention.self.value.bias', 'base_model.encoder.layer.1.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.3.attention.self.key.bias', 'base_model.encoder.layer.5.attention.output.LayerNorm.weight', 'base_model.encoder.layer.4.attention.self.key.weight', 'base_model.encoder.layer.8.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.16.attention.output.dense.weight', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.1.output.LayerNorm.weight', 'base_model.encoder.layer.4.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.10.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.11.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.5.attention.self.query.bias', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.12.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.14.output.LayerNorm.bias', 'base_model.encoder.layer.14.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.14.attention.self.key.weight', 'base_model.encoder.layer.6.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.12.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.15.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.2.output.adapters.tp.adapter_up.bias', 'base_model.embeddings.position_ids', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.20.attention.self.query.bias', 'base_model.encoder.layer.0.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.18.attention.output.dense.bias', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.21.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.8.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.22.output.dense.weight', 'base_model.encoder.layer.9.attention.self.query.weight', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.5.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.16.attention.output.dense.bias', 'base_model.encoder.layer.18.attention.self.value.bias', 'base_model.encoder.layer.18.output.LayerNorm.weight', 'base_model.encoder.layer.20.output.dense.bias', 'base_model.encoder.layer.16.attention.self.query.weight', 'base_model.encoder.layer.19.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.1.output.dense.bias', 'base_model.encoder.layer.11.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.19.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.9.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.8.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.15.attention.output.dense.weight', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.12.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.8.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.14.attention.output.LayerNorm.bias', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.2.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.17.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.0.attention.self.query.weight', 'base_model.encoder.layer.6.output.adapters.ep.adapter_up.bias', 'qa_outputs.weight', 'base_model.encoder.layer.7.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.0.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.2.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.13.attention.self.value.weight', 'base_model.encoder.layer.2.attention.self.value.bias', 'base_model.encoder.layer.14.attention.self.key.bias', 'base_model.encoder.layer.16.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.8.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.2.intermediate.dense.bias', 'base_model.encoder.layer.21.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.11.attention.output.dense.bias', 'base_model.encoder.layer.23.output.dense.bias', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.14.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.22.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.11.output.adapters.tp.adapter_up.bias', 'base_model.embeddings.token_type_embeddings.weight', 'base_model.encoder.layer.21.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.22.attention.self.query.weight', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.13.attention.self.key.weight', 'base_model.encoder.layer.19.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.20.output.LayerNorm.weight', 'base_model.encoder.layer.23.output.LayerNorm.bias', 'base_model.encoder.layer.17.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.3.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.21.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.2.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.3.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.8.attention.self.query.bias', 'base_model.encoder.layer.5.attention.output.dense.bias', 'base_model.encoder.layer.15.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.23.attention.self.query.weight', 'base_model.encoder.layer.8.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.11.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.1.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.4.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.14.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.13.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.14.attention.self.value.weight', 'base_model.encoder.layer.15.attention.output.dense.bias', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.11.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.0.output.LayerNorm.weight', 'base_model.encoder.layer.8.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.11.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.16.attention.self.value.weight', 'base_model.encoder.layer.20.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.3.output.dense.weight', 'base_model.encoder.layer.11.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.21.output.LayerNorm.bias', 'base_model.encoder.layer.3.intermediate.dense.bias', 'base_model.pooler.dense.bias', 'base_model.encoder.layer.12.attention.output.LayerNorm.bias', 'base_model.encoder.layer.18.attention.self.key.weight', 'base_model.encoder.layer.5.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.13.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.8.attention.output.LayerNorm.weight', 'base_model.encoder.layer.11.attention.self.query.bias', 'base_model.encoder.layer.5.attention.output.LayerNorm.bias', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.1.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.22.attention.output.LayerNorm.weight', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.9.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.3.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.20.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.4.attention.output.dense.weight', 'base_model.encoder.layer.14.intermediate.dense.bias', 'base_model.encoder.layer.5.output.adapters.es.adapter_up.weight', 'base_model.embeddings.word_embeddings.weight', 'base_model.encoder.layer.8.attention.output.LayerNorm.bias', 'base_model.encoder.layer.23.output.LayerNorm.weight', 'base_model.encoder.layer.20.intermediate.dense.weight', 'base_model.encoder.layer.22.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.2.attention.output.LayerNorm.weight', 'base_model.encoder.layer.18.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.10.attention.self.query.bias', 'base_model.encoder.layer.21.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.14.attention.self.query.bias', 'base_model.encoder.layer.18.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.21.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.3.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.11.attention.output.LayerNorm.weight', 'base_model.encoder.layer.22.attention.self.query.bias', 'base_model.encoder.layer.7.intermediate.dense.weight', 'base_model.encoder.layer.23.intermediate.dense.weight', 'base_model.encoder.layer.9.output.LayerNorm.weight', 'base_model.encoder.layer.20.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.11.attention.self.key.bias', 'base_model.encoder.layer.22.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.15.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.22.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.7.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.3.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.10.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.3.output.LayerNorm.bias', 'base_model.encoder.layer.17.attention.output.LayerNorm.weight', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.0.intermediate.dense.weight', 'base_model.encoder.layer.23.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.13.attention.output.LayerNorm.weight', 'base_model.encoder.layer.0.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.6.attention.self.value.weight', 'base_model.encoder.layer.7.attention.output.LayerNorm.weight', 'base_model.encoder.layer.10.output.dense.weight', 'base_model.encoder.layer.15.intermediate.dense.weight', 'base_model.encoder.layer.4.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.12.attention.self.key.weight', 'base_model.encoder.layer.12.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.2.output.adapters.ep.adapter_up.bias']
- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of XLMRobertaModel were not initialized from the model checkpoint at /cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//squad/xlm-KG_LR8e-6_EPOCH2.0_maxlen384_batchsize4_gradacc4 and are newly initialized: ['encoder.layer.17.output.LayerNorm.weight', 'encoder.layer.6.output.dense.bias', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.14.output.LayerNorm.bias', 'encoder.layer.9.attention.self.key.weight', 'encoder.layer.6.attention.self.query.bias', 'encoder.layer.7.attention.output.dense.weight', 'encoder.layer.15.attention.self.value.weight', 'encoder.layer.13.intermediate.dense.bias', 'encoder.layer.22.attention.output.LayerNorm.bias', 'encoder.layer.15.output.dense.bias', 'encoder.layer.19.output.LayerNorm.weight', 'encoder.layer.13.attention.output.LayerNorm.bias', 'encoder.layer.18.attention.self.key.bias', 'encoder.layer.17.output.dense.weight', 'encoder.layer.12.attention.output.dense.weight', 'pooler.dense.weight', 'encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.layer.14.attention.self.value.bias', 'encoder.layer.1.attention.self.value.bias', 'encoder.layer.1.attention.self.key.weight', 'encoder.layer.5.attention.self.value.weight', 'encoder.layer.11.attention.output.LayerNorm.weight', 'encoder.layer.13.attention.self.key.weight', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.21.attention.output.LayerNorm.bias', 'encoder.layer.23.attention.self.key.weight', 'encoder.layer.0.attention.output.LayerNorm.weight', 'encoder.layer.2.attention.self.query.bias', 'encoder.layer.6.attention.self.value.weight', 'encoder.layer.22.attention.self.key.bias', 'encoder.layer.18.intermediate.dense.weight', 'encoder.layer.10.attention.self.key.weight', 'encoder.layer.16.output.LayerNorm.bias', 'encoder.layer.10.intermediate.dense.weight', 'encoder.layer.19.attention.self.key.bias', 'encoder.layer.13.attention.self.query.weight', 'encoder.layer.0.attention.self.key.bias', 'encoder.layer.4.attention.output.LayerNorm.weight', 'encoder.layer.10.attention.output.LayerNorm.bias', 'encoder.layer.20.output.LayerNorm.weight', 'encoder.layer.9.attention.self.value.bias', 'encoder.layer.19.output.dense.bias', 'encoder.layer.2.output.dense.bias', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.21.attention.output.dense.weight', 'encoder.layer.21.intermediate.dense.bias', 'encoder.layer.3.attention.self.query.weight', 'encoder.layer.14.intermediate.dense.weight', 'encoder.layer.22.attention.self.value.weight', 'encoder.layer.19.intermediate.dense.weight', 'encoder.layer.14.output.dense.weight', 'encoder.layer.22.attention.output.dense.bias', 'encoder.layer.22.output.dense.bias', 'encoder.layer.10.attention.output.dense.weight', 'encoder.layer.20.attention.self.value.bias', 'encoder.layer.22.attention.self.key.weight', 'encoder.layer.15.attention.self.key.weight', 'encoder.layer.0.attention.self.value.bias', 'encoder.layer.10.attention.output.dense.bias', 'encoder.layer.9.attention.self.query.weight', 'encoder.layer.21.output.LayerNorm.weight', 'encoder.layer.20.attention.self.key.weight', 'embeddings.LayerNorm.bias', 'encoder.layer.17.attention.self.key.bias', 'encoder.layer.11.output.LayerNorm.weight', 'encoder.layer.6.attention.self.key.weight', 'encoder.layer.6.output.dense.weight', 'encoder.layer.1.output.dense.weight', 'embeddings.token_type_embeddings.weight', 'encoder.layer.8.output.LayerNorm.weight', 'encoder.layer.22.attention.output.LayerNorm.weight', 'encoder.layer.10.attention.self.value.bias', 'encoder.layer.16.attention.self.query.bias', 'encoder.layer.8.attention.output.LayerNorm.weight', 'encoder.layer.9.output.LayerNorm.bias', 'encoder.layer.7.output.LayerNorm.weight', 'encoder.layer.20.attention.self.query.weight', 'encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.layer.13.attention.self.value.bias', 'encoder.layer.15.output.dense.weight', 'encoder.layer.15.attention.output.LayerNorm.weight', 'pooler.dense.bias', 'encoder.layer.21.output.LayerNorm.bias', 'encoder.layer.15.output.LayerNorm.weight', 'encoder.layer.5.output.dense.weight', 'encoder.layer.0.output.dense.weight', 'encoder.layer.23.output.LayerNorm.weight', 'encoder.layer.5.attention.self.query.bias', 'encoder.layer.11.output.LayerNorm.bias', 'encoder.layer.14.attention.self.key.bias', 'encoder.layer.14.intermediate.dense.bias', 'encoder.layer.18.attention.self.value.weight', 'encoder.layer.6.output.LayerNorm.bias', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.7.attention.self.value.bias', 'encoder.layer.14.attention.output.LayerNorm.bias', 'encoder.layer.18.output.dense.weight', 'encoder.layer.20.output.dense.bias', 'encoder.layer.21.attention.self.query.bias', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.12.attention.output.LayerNorm.weight', 'encoder.layer.8.attention.output.LayerNorm.bias', 'encoder.layer.15.attention.self.key.bias', 'encoder.layer.19.intermediate.dense.bias', 'encoder.layer.16.attention.self.value.weight', 'encoder.layer.3.attention.output.dense.bias', 'encoder.layer.7.attention.self.query.bias', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.20.attention.output.dense.weight', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.10.attention.output.LayerNorm.weight', 'encoder.layer.16.attention.self.value.bias', 'encoder.layer.9.output.LayerNorm.weight', 'encoder.layer.18.output.dense.bias', 'encoder.layer.21.intermediate.dense.weight', 'encoder.layer.4.attention.self.key.weight', 'encoder.layer.18.attention.self.value.bias', 'encoder.layer.13.output.dense.weight', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.14.attention.output.LayerNorm.weight', 'encoder.layer.23.output.dense.bias', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.19.attention.self.query.weight', 'encoder.layer.3.attention.self.query.bias', 'encoder.layer.8.attention.self.value.bias', 'encoder.layer.23.attention.output.LayerNorm.weight', 'encoder.layer.6.attention.output.LayerNorm.bias', 'encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.layer.23.output.dense.weight', 'encoder.layer.9.attention.self.key.bias', 'encoder.layer.12.attention.output.dense.bias', 'encoder.layer.16.attention.output.LayerNorm.bias', 'encoder.layer.11.attention.self.query.bias', 'encoder.layer.0.attention.output.dense.weight', 'encoder.layer.3.attention.output.dense.weight', 'encoder.layer.1.attention.self.value.weight', 'encoder.layer.7.output.dense.weight', 'encoder.layer.4.output.dense.bias', 'encoder.layer.14.attention.self.query.bias', 'encoder.layer.21.attention.output.LayerNorm.weight', 'encoder.layer.20.attention.output.LayerNorm.bias', 'encoder.layer.19.attention.self.value.weight', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.8.attention.self.query.bias', 'encoder.layer.11.attention.output.dense.bias', 'encoder.layer.11.attention.self.value.bias', 'encoder.layer.20.attention.output.LayerNorm.weight', 'encoder.layer.18.attention.self.query.bias', 'encoder.layer.14.output.dense.bias', 'encoder.layer.22.attention.output.dense.weight', 'encoder.layer.20.attention.self.query.bias', 'encoder.layer.14.attention.self.value.weight', 'encoder.layer.3.attention.self.key.weight', 'encoder.layer.10.output.dense.weight', 'encoder.layer.5.attention.output.LayerNorm.weight', 'encoder.layer.1.attention.output.dense.bias', 'encoder.layer.15.attention.self.value.bias', 'encoder.layer.13.attention.output.LayerNorm.weight', 'encoder.layer.18.attention.self.query.weight', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.15.attention.self.query.weight', 'encoder.layer.6.attention.output.dense.weight', 'encoder.layer.22.intermediate.dense.bias', 'encoder.layer.2.attention.output.LayerNorm.weight', 'encoder.layer.10.attention.self.value.weight', 'encoder.layer.23.attention.self.query.weight', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.8.output.dense.weight', 'encoder.layer.10.output.dense.bias', 'encoder.layer.22.output.dense.weight', 'encoder.layer.18.attention.output.LayerNorm.weight', 'encoder.layer.23.attention.output.dense.bias', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.18.attention.output.LayerNorm.bias', 'encoder.layer.17.intermediate.dense.bias', 'encoder.layer.22.attention.self.value.bias', 'encoder.layer.1.attention.output.dense.weight', 'encoder.layer.4.attention.self.query.bias', 'encoder.layer.21.output.dense.bias', 'embeddings.position_embeddings.weight', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.16.attention.output.dense.weight', 'encoder.layer.2.output.dense.weight', 'encoder.layer.5.attention.self.value.bias', 'encoder.layer.21.attention.output.dense.bias', 'encoder.layer.4.attention.output.dense.bias', 'encoder.layer.12.attention.self.query.bias', 'encoder.layer.7.intermediate.dense.bias', 'encoder.layer.15.intermediate.dense.bias', 'encoder.layer.9.output.dense.bias', 'encoder.layer.9.attention.self.query.bias', 'encoder.layer.2.attention.self.key.bias', 'encoder.layer.6.attention.self.query.weight', 'encoder.layer.11.attention.self.key.weight', 'encoder.layer.14.output.LayerNorm.weight', 'encoder.layer.23.attention.self.value.weight', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.11.attention.output.dense.weight', 'encoder.layer.19.output.dense.weight', 'encoder.layer.16.output.dense.bias', 'encoder.layer.0.output.dense.bias', 'encoder.layer.23.output.LayerNorm.bias', 'encoder.layer.13.attention.self.key.bias', 'encoder.layer.2.attention.output.dense.bias', 'encoder.layer.3.attention.self.value.weight', 'encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.layer.7.attention.output.LayerNorm.bias', 'encoder.layer.8.attention.self.value.weight', 'encoder.layer.12.attention.output.LayerNorm.bias', 'encoder.layer.5.attention.output.dense.weight', 'encoder.layer.15.intermediate.dense.weight', 'encoder.layer.13.attention.self.value.weight', 'encoder.layer.10.output.LayerNorm.weight', 'encoder.layer.2.attention.self.value.weight', 'encoder.layer.5.attention.self.key.weight', 'encoder.layer.1.attention.self.query.bias', 'encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.13.output.LayerNorm.bias', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.3.output.dense.weight', 'encoder.layer.8.attention.output.dense.bias', 'encoder.layer.13.attention.self.query.bias', 'encoder.layer.7.attention.self.key.bias', 'encoder.layer.4.attention.self.value.weight', 'encoder.layer.15.attention.self.query.bias', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.2.attention.self.query.weight', 'encoder.layer.16.attention.self.query.weight', 'encoder.layer.22.intermediate.dense.weight', 'encoder.layer.11.attention.self.value.weight', 'encoder.layer.5.attention.output.dense.bias', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.12.output.LayerNorm.bias', 'encoder.layer.12.attention.self.value.weight', 'encoder.layer.9.attention.output.dense.weight', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.15.attention.output.LayerNorm.bias', 'encoder.layer.19.attention.output.dense.weight', 'encoder.layer.22.output.LayerNorm.weight', 'encoder.layer.8.attention.self.query.weight', 'encoder.layer.12.output.dense.bias', 'encoder.layer.19.output.LayerNorm.bias', 'encoder.layer.4.attention.self.query.weight', 'encoder.layer.17.attention.self.value.bias', 'encoder.layer.8.output.LayerNorm.bias', 'encoder.layer.20.attention.output.dense.bias', 'encoder.layer.13.output.LayerNorm.weight', 'encoder.layer.11.output.dense.weight', 'encoder.layer.16.output.dense.weight', 'encoder.layer.5.output.dense.bias', 'encoder.layer.16.intermediate.dense.weight', 'encoder.layer.17.attention.output.dense.bias', 'encoder.layer.23.attention.output.LayerNorm.bias', 'encoder.layer.7.attention.self.key.weight', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.3.attention.self.key.bias', 'encoder.layer.12.attention.self.query.weight', 'encoder.layer.18.output.LayerNorm.bias', 'encoder.layer.21.output.dense.weight', 'encoder.layer.13.output.dense.bias', 'encoder.layer.3.attention.self.value.bias', 'encoder.layer.21.attention.self.key.weight', 'embeddings.word_embeddings.weight', 'encoder.layer.2.attention.self.value.bias', 'encoder.layer.17.attention.self.query.weight', 'encoder.layer.4.output.dense.weight', 'encoder.layer.23.intermediate.dense.bias', 'encoder.layer.6.attention.self.value.bias', 'encoder.layer.15.attention.output.dense.bias', 'encoder.layer.0.attention.self.value.weight', 'encoder.layer.18.attention.self.key.weight', 'encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.layer.16.attention.self.key.weight', 'encoder.layer.15.output.LayerNorm.bias', 'encoder.layer.14.attention.self.key.weight', 'encoder.layer.16.intermediate.dense.bias', 'encoder.layer.7.attention.output.LayerNorm.weight', 'encoder.layer.1.output.dense.bias', 'encoder.layer.2.attention.output.LayerNorm.bias', 'encoder.layer.1.attention.output.LayerNorm.weight', 'encoder.layer.3.output.dense.bias', 'encoder.layer.9.attention.self.value.weight', 'encoder.layer.8.attention.self.key.bias', 'encoder.layer.17.attention.output.LayerNorm.weight', 'encoder.layer.23.attention.self.value.bias', 'encoder.layer.21.attention.self.value.weight', 'encoder.layer.8.attention.self.key.weight', 'encoder.layer.10.attention.self.query.weight', 'encoder.layer.0.attention.output.dense.bias', 'encoder.layer.0.attention.self.query.weight', 'encoder.layer.4.attention.self.value.bias', 'embeddings.LayerNorm.weight', 'encoder.layer.18.output.LayerNorm.weight', 'encoder.layer.20.attention.self.value.weight', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.2.attention.output.dense.weight', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.12.attention.self.key.weight', 'encoder.layer.20.attention.self.key.bias', 'encoder.layer.17.attention.self.value.weight', 'encoder.layer.6.attention.output.dense.bias', 'encoder.layer.10.attention.self.key.bias', 'encoder.layer.5.attention.self.query.weight', 'encoder.layer.8.attention.output.dense.weight', 'encoder.layer.12.output.dense.weight', 'encoder.layer.16.attention.output.dense.bias', 'encoder.layer.17.output.LayerNorm.bias', 'encoder.layer.14.attention.output.dense.bias', 'encoder.layer.16.output.LayerNorm.weight', 'encoder.layer.14.attention.output.dense.weight', 'encoder.layer.19.attention.output.dense.bias', 'encoder.layer.4.attention.self.key.bias', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.5.output.LayerNorm.bias', 'encoder.layer.23.attention.output.dense.weight', 'encoder.layer.7.attention.self.query.weight', 'encoder.layer.0.attention.self.key.weight', 'encoder.layer.17.attention.output.LayerNorm.bias', 'encoder.layer.0.attention.self.query.bias', 'encoder.layer.23.intermediate.dense.weight', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.4.attention.output.LayerNorm.bias', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.21.attention.self.key.bias', 'encoder.layer.22.attention.self.query.weight', 'encoder.layer.12.attention.self.value.bias', 'encoder.layer.7.attention.self.value.weight', 'encoder.layer.13.attention.output.dense.bias', 'encoder.layer.17.output.dense.bias', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.16.attention.output.LayerNorm.weight', 'encoder.layer.17.attention.self.key.weight', 'encoder.layer.2.attention.self.key.weight', 'encoder.layer.9.output.dense.weight', 'encoder.layer.12.output.LayerNorm.weight', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.11.attention.self.key.bias', 'encoder.layer.21.attention.self.value.bias', 'encoder.layer.18.attention.output.dense.weight', 'encoder.layer.10.output.LayerNorm.bias', 'encoder.layer.15.attention.output.dense.weight', 'encoder.layer.6.attention.output.LayerNorm.weight', 'encoder.layer.5.attention.self.key.bias', 'encoder.layer.14.attention.self.query.weight', 'encoder.layer.1.attention.self.key.bias', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.13.intermediate.dense.weight', 'encoder.layer.7.output.LayerNorm.bias', 'encoder.layer.20.intermediate.dense.bias', 'encoder.layer.11.attention.self.query.weight', 'encoder.layer.22.output.LayerNorm.bias', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.17.attention.self.query.bias', 'encoder.layer.9.attention.output.LayerNorm.bias', 'encoder.layer.22.attention.self.query.bias', 'encoder.layer.9.attention.output.dense.bias', 'encoder.layer.19.attention.self.value.bias', 'encoder.layer.19.attention.self.query.bias', 'encoder.layer.6.attention.self.key.bias', 'encoder.layer.20.intermediate.dense.weight', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.21.attention.self.query.weight', 'encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.20.output.LayerNorm.bias', 'encoder.layer.4.attention.output.dense.weight', 'encoder.layer.7.output.dense.bias', 'encoder.layer.9.attention.output.LayerNorm.weight', 'encoder.layer.19.attention.self.key.weight', 'encoder.layer.23.attention.self.key.bias', 'encoder.layer.16.attention.self.key.bias', 'encoder.layer.11.output.dense.bias', 'encoder.layer.13.attention.output.dense.weight', 'encoder.layer.10.attention.self.query.bias', 'encoder.layer.19.attention.output.LayerNorm.bias', 'encoder.layer.8.output.dense.bias', 'encoder.layer.1.attention.self.query.weight', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.17.attention.output.dense.weight', 'encoder.layer.18.attention.output.dense.bias', 'encoder.layer.23.attention.self.query.bias', 'encoder.layer.20.output.dense.weight', 'encoder.layer.7.attention.output.dense.bias', 'encoder.layer.18.intermediate.dense.bias', 'encoder.layer.12.intermediate.dense.weight', 'encoder.layer.12.intermediate.dense.bias', 'encoder.layer.12.attention.self.key.bias', 'encoder.layer.17.intermediate.dense.weight', 'encoder.layer.19.attention.output.LayerNorm.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Overwriting existing adapter 'ep'.
Overwriting existing adapter 'tp'.
Overwriting existing adapter 'es'.
Overwriting existing adapter 'ts'.
Overwriting existing adapter fusion module 'ep,tp,es,ts'
05/09/2022 19:50:46 - INFO - __main__ -   lang2id = None
05/09/2022 19:50:50 - INFO - __main__ -   Training/evaluation parameters Namespace(adam_epsilon=1e-08, cache_dir='', config_name='', data_dir=None, device=device(type='cuda'), do_eval=True, do_lower_case=False, do_train=False, doc_stride=128, eval_all_checkpoints=False, eval_lang='es', evaluate_during_training=False, fp16=False, fp16_opt_level='O1', gradient_accumulation_steps=1, learning_rate=5e-05, local_rank=-1, logging_steps=50, max_answer_length=30, max_grad_norm=1.0, max_query_length=64, max_seq_length=384, max_steps=-1, model_name='xlm-KG', model_name_or_path='/cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//squad/xlm-KG_LR8e-6_EPOCH2.0_maxlen384_batchsize4_gradacc4', model_type='xlm', modelkg_dir='/cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/adapter/xlmr_adapter', n_best_size=20, n_gpu=1, no_cuda=False, null_score_diff_threshold=0.0, num_train_epochs=3.0, output_dir='/cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//squad/xlm-KG_LR8e-6_EPOCH2.0_maxlen384_batchsize4_gradacc4/predictions/xquad/', overwrite_cache=False, overwrite_output_dir=False, per_gpu_eval_batch_size=8, per_gpu_train_batch_size=8, predict_file='/cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/download//xquad//xquad.es.json', save_steps=50, seed=42, server_ip='', server_port='', threads=1, tokenizer_name='', train_file=None, train_lang='en', verbose_logging=False, version_2_with_negative=False, warmup_steps=0, weight_decay=0.0)
05/09/2022 19:50:50 - INFO - __main__ -   Loading checkpoint /cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//squad/xlm-KG_LR8e-6_EPOCH2.0_maxlen384_batchsize4_gradacc4 for evaluation
05/09/2022 19:50:50 - INFO - __main__ -   Evaluate the following checkpoints: ['/cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//squad/xlm-KG_LR8e-6_EPOCH2.0_maxlen384_batchsize4_gradacc4']
Some weights of the model checkpoint at /cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//squad/xlm-KG_LR8e-6_EPOCH2.0_maxlen384_batchsize4_gradacc4 were not used when initializing XLMRobertaModel: ['base_model.encoder.layer.16.attention.self.query.bias', 'base_model.encoder.layer.14.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.15.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.18.attention.self.value.weight', 'base_model.encoder.layer.11.attention.self.value.weight', 'base_model.encoder.layer.2.attention.self.query.weight', 'base_model.encoder.layer.4.output.dense.bias', 'base_model.encoder.layer.15.output.LayerNorm.bias', 'base_model.encoder.layer.2.output.dense.bias', 'base_model.encoder.layer.15.attention.self.query.weight', 'base_model.encoder.layer.7.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.1.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.20.attention.output.LayerNorm.weight', 'base_model.encoder.layer.20.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.0.attention.output.LayerNorm.bias', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.23.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.21.attention.self.query.bias', 'base_model.encoder.layer.9.attention.self.key.bias', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.4.attention.self.value.bias', 'base_model.encoder.layer.7.attention.self.key.weight', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.3.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.6.attention.self.key.weight', 'base_model.encoder.layer.10.output.LayerNorm.weight', 'base_model.encoder.layer.1.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.4.output.dense.weight', 'base_model.encoder.layer.18.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.4.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.6.output.dense.weight', 'base_model.encoder.layer.16.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.20.attention.output.dense.weight', 'base_model.encoder.layer.19.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.18.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.7.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.6.attention.self.query.bias', 'base_model.encoder.layer.13.attention.output.LayerNorm.bias', 'base_model.encoder.layer.16.attention.self.key.weight', 'base_model.encoder.layer.1.attention.self.query.weight', 'base_model.encoder.layer.1.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.4.attention.output.dense.bias', 'base_model.encoder.layer.1.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.10.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.9.output.dense.weight', 'base_model.encoder.layer.9.attention.self.value.weight', 'base_model.encoder.layer.7.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.15.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.20.intermediate.dense.bias', 'base_model.encoder.layer.10.intermediate.dense.bias', 'base_model.encoder.layer.5.attention.self.key.weight', 'base_model.encoder.layer.8.attention.output.dense.weight', 'base_model.encoder.layer.23.attention.self.value.weight', 'base_model.encoder.layer.10.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.12.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.5.output.LayerNorm.weight', 'base_model.encoder.layer.8.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.10.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.20.attention.self.key.bias', 'base_model.encoder.layer.0.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.6.attention.self.value.bias', 'base_model.encoder.layer.6.output.LayerNorm.weight', 'base_model.encoder.layer.12.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.14.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.15.attention.self.key.weight', 'base_model.encoder.layer.19.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.18.attention.self.query.weight', 'base_model.encoder.layer.2.attention.output.dense.bias', 'base_model.encoder.layer.21.attention.output.dense.bias', 'base_model.encoder.layer.20.attention.self.key.weight', 'base_model.encoder.layer.0.output.dense.bias', 'base_model.encoder.layer.0.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.21.output.dense.weight', 'base_model.encoder.layer.10.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.11.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.5.attention.output.dense.weight', 'base_model.encoder.layer.13.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.12.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.22.attention.output.dense.weight', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.1.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.0.intermediate.dense.bias', 'base_model.encoder.layer.12.output.LayerNorm.weight', 'base_model.encoder.layer.13.intermediate.dense.weight', 'base_model.encoder.layer.15.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.21.attention.self.key.weight', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.20.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.23.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.0.output.dense.weight', 'base_model.encoder.layer.7.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.13.attention.output.dense.weight', 'base_model.encoder.layer.2.output.LayerNorm.weight', 'base_model.encoder.layer.22.intermediate.dense.weight', 'base_model.encoder.layer.11.attention.self.key.weight', 'base_model.encoder.layer.20.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.6.attention.output.LayerNorm.weight', 'base_model.encoder.layer.6.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.6.output.LayerNorm.bias', 'base_model.encoder.layer.15.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.22.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.17.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.12.attention.self.query.weight', 'base_model.encoder.layer.12.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.18.attention.self.key.bias', 'base_model.encoder.layer.13.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.15.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.12.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.15.output.dense.weight', 'base_model.encoder.layer.18.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.5.attention.self.key.bias', 'base_model.encoder.layer.18.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.6.intermediate.dense.bias', 'base_model.encoder.layer.6.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.5.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.21.output.dense.bias', 'base_model.encoder.layer.23.attention.self.key.weight', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.13.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.7.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.23.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.15.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.5.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.1.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.11.attention.self.query.weight', 'base_model.encoder.layer.1.attention.output.LayerNorm.weight', 'base_model.encoder.layer.7.output.LayerNorm.bias', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.3.attention.self.query.weight', 'base_model.encoder.layer.10.intermediate.dense.weight', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.3.attention.output.dense.weight', 'base_model.encoder.layer.17.output.dense.weight', 'base_model.encoder.layer.13.attention.self.query.weight', 'base_model.encoder.layer.18.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.9.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.14.attention.output.dense.bias', 'base_model.encoder.layer.16.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.1.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.19.output.dense.bias', 'base_model.encoder.layer.18.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.3.attention.output.dense.bias', 'base_model.encoder.layer.11.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.12.attention.output.LayerNorm.weight', 'base_model.encoder.layer.20.attention.output.dense.bias', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.12.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.8.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.3.output.adapters.ts.adapter_down.0.weight', 'base_model.embeddings.position_embeddings.weight', 'base_model.encoder.layer.22.intermediate.dense.bias', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.23.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.11.intermediate.dense.bias', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.9.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.1.attention.self.value.weight', 'base_model.encoder.layer.10.attention.self.key.bias', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.22.attention.self.value.bias', 'base_model.encoder.layer.2.output.dense.weight', 'base_model.encoder.layer.3.output.dense.bias', 'base_model.encoder.layer.0.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.2.attention.output.LayerNorm.bias', 'base_model.encoder.layer.9.attention.output.dense.bias', 'base_model.encoder.layer.6.attention.output.LayerNorm.bias', 'base_model.encoder.layer.13.attention.self.query.bias', 'base_model.encoder.layer.7.attention.self.query.weight', 'base_model.encoder.layer.22.output.LayerNorm.bias', 'base_model.encoder.layer.9.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.15.intermediate.dense.bias', 'base_model.encoder.layer.16.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.8.attention.self.key.weight', 'base_model.encoder.layer.0.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.15.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.18.output.LayerNorm.bias', 'base_model.encoder.layer.6.intermediate.dense.weight', 'base_model.encoder.layer.17.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.2.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.20.attention.self.query.weight', 'base_model.encoder.layer.11.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.15.attention.self.value.weight', 'base_model.encoder.layer.5.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.10.output.dense.bias', 'base_model.encoder.layer.3.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.13.output.dense.bias', 'base_model.encoder.layer.7.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.8.intermediate.dense.weight', 'base_model.encoder.layer.5.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.2.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.18.attention.output.dense.weight', 'base_model.encoder.layer.18.output.dense.weight', 'base_model.encoder.layer.7.output.LayerNorm.weight', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.2.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.11.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.14.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.23.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.19.output.LayerNorm.weight', 'base_model.encoder.layer.17.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.0.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.20.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.0.attention.self.key.weight', 'base_model.encoder.layer.5.attention.self.value.bias', 'base_model.encoder.layer.10.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.18.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.3.attention.self.key.weight', 'base_model.encoder.layer.21.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.0.attention.output.LayerNorm.weight', 'base_model.encoder.layer.9.output.dense.bias', 'base_model.encoder.layer.12.attention.self.key.bias', 'base_model.encoder.layer.5.attention.self.query.weight', 'base_model.encoder.layer.23.attention.output.dense.bias', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.8.attention.self.query.weight', 'base_model.encoder.layer.12.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.16.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.19.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.5.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.16.intermediate.dense.weight', 'base_model.encoder.layer.22.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.21.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.6.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.1.intermediate.dense.bias', 'base_model.encoder.layer.14.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.13.intermediate.dense.bias', 'base_model.encoder.layer.11.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.12.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.15.attention.output.LayerNorm.weight', 'base_model.encoder.layer.6.attention.self.query.weight', 'base_model.encoder.layer.18.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.3.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.18.intermediate.dense.weight', 'base_model.encoder.layer.1.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.0.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.1.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.15.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.17.attention.self.query.bias', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.10.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.10.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.7.attention.self.key.bias', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.19.intermediate.dense.bias', 'base_model.encoder.layer.14.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.21.attention.output.LayerNorm.weight', 'base_model.encoder.layer.4.intermediate.dense.bias', 'base_model.encoder.layer.6.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.11.attention.self.value.bias', 'base_model.encoder.layer.6.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.14.attention.output.LayerNorm.weight', 'base_model.encoder.layer.9.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.17.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.15.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.21.attention.self.value.bias', 'base_model.encoder.layer.22.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.23.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.7.attention.self.value.weight', 'base_model.encoder.layer.13.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.23.attention.self.value.bias', 'base_model.encoder.layer.4.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.14.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.16.output.LayerNorm.bias', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.23.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.13.attention.output.dense.bias', 'base_model.encoder.layer.0.attention.self.query.bias', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.20.attention.self.value.bias', 'base_model.encoder.layer.9.attention.self.query.bias', 'base_model.encoder.layer.12.intermediate.dense.bias', 'base_model.encoder.layer.4.attention.self.key.bias', 'base_model.encoder.layer.17.output.LayerNorm.bias', 'base_model.encoder.layer.13.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.11.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.17.attention.self.key.weight', 'base_model.encoder.layer.4.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.12.output.LayerNorm.bias', 'base_model.encoder.layer.15.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.7.output.adapters.es.adapter_up.bias', 'base_model.embeddings.LayerNorm.weight', 'base_model.encoder.layer.9.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.12.output.dense.bias', 'base_model.encoder.layer.4.output.LayerNorm.bias', 'base_model.encoder.layer.19.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.8.attention.self.key.bias', 'base_model.encoder.layer.4.attention.self.query.bias', 'base_model.encoder.layer.1.intermediate.dense.weight', 'base_model.encoder.layer.22.attention.self.key.weight', 'base_model.encoder.layer.17.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.17.attention.output.LayerNorm.bias', 'base_model.encoder.layer.9.intermediate.dense.weight', 'base_model.encoder.layer.9.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.10.attention.output.dense.bias', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.2.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.12.attention.self.value.bias', 'base_model.encoder.layer.13.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.3.output.LayerNorm.weight', 'base_model.encoder.layer.7.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.12.output.dense.weight', 'base_model.encoder.layer.10.attention.self.value.weight', 'base_model.encoder.layer.20.output.dense.weight', 'base_model.encoder.layer.16.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.2.output.LayerNorm.bias', 'base_model.encoder.layer.18.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.3.attention.self.value.weight', 'base_model.encoder.layer.1.output.dense.weight', 'base_model.encoder.layer.16.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.1.attention.self.query.bias', 'base_model.encoder.layer.10.attention.output.LayerNorm.weight', 'base_model.encoder.layer.19.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.22.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.22.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.10.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.12.attention.output.dense.bias', 'base_model.encoder.layer.20.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.4.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.17.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.22.output.LayerNorm.weight', 'base_model.encoder.layer.3.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.9.attention.self.value.bias', 'base_model.encoder.layer.14.output.dense.weight', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.5.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.16.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.1.attention.self.value.bias', 'base_model.encoder.layer.14.attention.self.query.weight', 'base_model.encoder.layer.17.attention.output.dense.weight', 'base_model.encoder.layer.0.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.2.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.4.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.15.output.dense.bias', 'base_model.encoder.layer.20.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.6.output.dense.bias', 'base_model.pooler.dense.weight', 'base_model.encoder.layer.9.intermediate.dense.bias', 'base_model.encoder.layer.6.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.15.attention.self.query.bias', 'base_model.encoder.layer.16.intermediate.dense.bias', 'base_model.encoder.layer.5.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.16.attention.output.LayerNorm.bias', 'base_model.encoder.layer.5.output.LayerNorm.bias', 'base_model.encoder.layer.23.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.20.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.13.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.11.intermediate.dense.weight', 'base_model.encoder.layer.21.intermediate.dense.bias', 'base_model.encoder.layer.6.attention.output.dense.weight', 'base_model.encoder.layer.13.output.LayerNorm.weight', 'base_model.encoder.layer.1.attention.output.LayerNorm.bias', 'base_model.encoder.layer.16.output.dense.weight', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.21.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.8.attention.self.value.bias', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.15.attention.output.LayerNorm.bias', 'base_model.encoder.layer.23.attention.self.key.bias', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.8.attention.output.dense.bias', 'base_model.encoder.layer.19.attention.output.dense.weight', 'base_model.encoder.layer.7.output.dense.bias', 'base_model.encoder.layer.16.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.17.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.21.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.5.intermediate.dense.weight', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.20.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.0.attention.self.value.bias', 'base_model.encoder.layer.22.attention.self.value.weight', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.10.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.21.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.9.output.LayerNorm.bias', 'base_model.encoder.layer.6.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.19.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.2.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.7.intermediate.dense.bias', 'base_model.encoder.layer.21.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.16.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.5.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.19.attention.output.LayerNorm.bias', 'base_model.encoder.layer.9.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.1.attention.output.dense.weight', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.23.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.8.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.21.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.3.intermediate.dense.weight', 'base_model.encoder.layer.5.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.1.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.2.attention.self.value.weight', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.15.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.4.attention.self.value.weight', 'base_model.encoder.layer.22.attention.output.LayerNorm.bias', 'base_model.encoder.layer.10.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.7.output.dense.weight', 'base_model.encoder.layer.1.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.2.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.9.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.6.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.7.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.0.attention.output.dense.bias', 'base_model.encoder.layer.4.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.10.attention.self.query.weight', 'base_model.encoder.layer.1.attention.self.key.bias', 'base_model.encoder.layer.17.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.19.attention.self.value.weight', 'base_model.encoder.layer.19.attention.output.LayerNorm.weight', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.5.intermediate.dense.bias', 'base_model.encoder.layer.20.output.LayerNorm.bias', 'base_model.encoder.layer.3.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.0.attention.self.value.weight', 'base_model.encoder.layer.4.output.LayerNorm.weight', 'base_model.encoder.layer.7.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.13.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.21.attention.output.LayerNorm.bias', 'base_model.encoder.layer.21.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.23.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.3.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.8.intermediate.dense.bias', 'base_model.encoder.layer.13.output.LayerNorm.bias', 'base_model.encoder.layer.17.attention.self.key.bias', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.5.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.2.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.0.attention.output.dense.weight', 'base_model.encoder.layer.4.attention.self.query.weight', 'base_model.encoder.layer.6.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.20.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.16.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.21.attention.self.query.weight', 'base_model.encoder.layer.23.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.20.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.0.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.11.attention.output.LayerNorm.bias', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.21.attention.output.dense.weight', 'base_model.encoder.layer.14.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.16.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.9.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.9.attention.self.key.weight', 'base_model.encoder.layer.12.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.5.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.23.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.19.output.LayerNorm.bias', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.10.attention.self.value.bias', 'base_model.encoder.layer.5.output.dense.weight', 'base_model.encoder.layer.20.attention.self.value.weight', 'base_model.encoder.layer.23.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.17.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.17.intermediate.dense.weight', 'base_model.encoder.layer.18.attention.output.LayerNorm.bias', 'base_model.encoder.layer.19.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.11.output.LayerNorm.bias', 'base_model.encoder.layer.12.attention.output.dense.weight', 'base_model.encoder.layer.21.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.14.output.LayerNorm.weight', 'base_model.encoder.layer.6.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.16.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.2.attention.self.key.bias', 'base_model.encoder.layer.16.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.9.attention.output.LayerNorm.bias', 'base_model.encoder.layer.2.attention.self.query.bias', 'base_model.encoder.layer.12.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.21.attention.self.key.bias', 'base_model.encoder.layer.18.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.19.attention.self.key.weight', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.15.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.8.attention.self.value.weight', 'base_model.encoder.layer.18.attention.self.query.bias', 'base_model.encoder.layer.2.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.23.attention.self.query.bias', 'base_model.encoder.layer.23.attention.output.LayerNorm.bias', 'base_model.encoder.layer.5.output.dense.bias', 'base_model.encoder.layer.19.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.2.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.16.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.10.attention.self.key.weight', 'base_model.encoder.layer.14.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.17.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.0.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.7.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.5.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.15.output.LayerNorm.weight', 'base_model.encoder.layer.13.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.20.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.4.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.14.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.17.attention.self.value.weight', 'base_model.encoder.layer.11.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.10.output.LayerNorm.bias', 'base_model.encoder.layer.13.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.0.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.11.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.17.output.dense.bias', 'base_model.encoder.layer.22.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.0.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.18.attention.output.LayerNorm.weight', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.19.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.6.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.22.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.3.attention.output.LayerNorm.bias', 'base_model.encoder.layer.19.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.16.attention.self.key.bias', 'base_model.encoder.layer.20.attention.output.LayerNorm.bias', 'base_model.encoder.layer.23.output.dense.weight', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.1.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.8.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.6.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.8.output.dense.bias', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.4.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.9.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.12.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.14.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.13.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.6.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.13.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.18.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.8.output.LayerNorm.bias', 'base_model.encoder.layer.17.intermediate.dense.bias', 'base_model.encoder.layer.8.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.11.output.dense.bias', 'base_model.encoder.layer.13.attention.self.key.bias', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.22.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.18.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.2.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.9.attention.output.dense.weight', 'base_model.encoder.layer.23.attention.output.dense.weight', 'base_model.encoder.layer.7.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.12.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'qa_outputs.bias', 'base_model.encoder.layer.17.output.LayerNorm.weight', 'base_model.encoder.layer.23.attention.output.LayerNorm.weight', 'base_model.encoder.layer.14.intermediate.dense.weight', 'base_model.encoder.layer.9.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.22.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.2.intermediate.dense.weight', 'base_model.encoder.layer.4.attention.output.LayerNorm.weight', 'base_model.encoder.layer.19.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.6.attention.self.key.bias', 'base_model.encoder.layer.19.attention.self.key.bias', 'base_model.encoder.layer.11.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.23.intermediate.dense.bias', 'base_model.encoder.layer.10.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.9.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.22.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.0.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.12.intermediate.dense.weight', 'base_model.encoder.layer.21.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.22.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.16.output.LayerNorm.weight', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.4.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.19.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.22.output.dense.bias', 'base_model.encoder.layer.11.attention.output.dense.weight', 'base_model.encoder.layer.23.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.3.attention.self.query.bias', 'base_model.encoder.layer.14.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.3.attention.output.LayerNorm.weight', 'base_model.encoder.layer.10.attention.output.LayerNorm.bias', 'base_model.encoder.layer.13.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.17.attention.self.value.bias', 'base_model.encoder.layer.17.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.20.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.9.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.19.output.dense.weight', 'base_model.encoder.layer.23.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.3.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.10.attention.output.dense.weight', 'base_model.encoder.layer.14.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.14.output.dense.bias', 'base_model.encoder.layer.6.attention.output.dense.bias', 'base_model.encoder.layer.0.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.17.attention.output.dense.bias', 'base_model.encoder.layer.7.attention.self.value.bias', 'base_model.encoder.layer.8.output.LayerNorm.weight', 'base_model.encoder.layer.21.attention.self.value.weight', 'base_model.encoder.layer.3.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.4.intermediate.dense.weight', 'base_model.encoder.layer.4.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.18.output.dense.bias', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.5.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.15.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.9.attention.output.LayerNorm.weight', 'base_model.encoder.layer.18.intermediate.dense.bias', 'base_model.encoder.layer.3.attention.self.value.bias', 'base_model.encoder.layer.4.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.12.attention.self.query.bias', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.18.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.0.output.LayerNorm.bias', 'base_model.encoder.layer.17.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.8.output.dense.weight', 'base_model.encoder.layer.22.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.14.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.10.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.19.intermediate.dense.weight', 'base_model.encoder.layer.7.attention.output.LayerNorm.bias', 'base_model.encoder.layer.17.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.19.attention.self.query.weight', 'base_model.embeddings.LayerNorm.bias', 'base_model.encoder.layer.14.attention.output.dense.weight', 'base_model.encoder.layer.1.attention.output.dense.bias', 'base_model.encoder.layer.9.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.8.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.16.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.7.attention.output.dense.weight', 'base_model.encoder.layer.19.attention.self.value.bias', 'base_model.encoder.layer.4.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.22.attention.output.dense.bias', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.2.attention.output.dense.weight', 'base_model.encoder.layer.14.attention.self.value.bias', 'base_model.encoder.layer.15.attention.self.key.bias', 'base_model.encoder.layer.3.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.18.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.21.intermediate.dense.weight', 'base_model.encoder.layer.10.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.1.output.LayerNorm.bias', 'base_model.encoder.layer.12.attention.self.value.weight', 'base_model.encoder.layer.11.output.LayerNorm.weight', 'base_model.encoder.layer.4.attention.output.LayerNorm.bias', 'base_model.encoder.layer.8.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.0.attention.self.key.bias', 'base_model.encoder.layer.16.output.dense.bias', 'base_model.encoder.layer.19.attention.self.query.bias', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.16.attention.output.LayerNorm.weight', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.7.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.3.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.7.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.11.output.dense.weight', 'base_model.encoder.layer.22.attention.self.key.bias', 'base_model.encoder.layer.1.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.1.attention.self.key.weight', 'base_model.encoder.layer.13.attention.self.value.bias', 'base_model.encoder.layer.8.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.16.attention.self.value.bias', 'base_model.encoder.layer.19.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.10.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.17.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.13.output.dense.weight', 'base_model.encoder.layer.8.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.20.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.21.output.LayerNorm.weight', 'base_model.encoder.layer.13.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.17.attention.self.query.weight', 'base_model.encoder.layer.7.attention.output.dense.bias', 'base_model.encoder.layer.5.attention.self.value.weight', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.4.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.7.attention.self.query.bias', 'base_model.encoder.layer.19.attention.output.dense.bias', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.6.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.2.attention.self.key.weight', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.15.attention.self.value.bias', 'base_model.encoder.layer.1.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.3.attention.self.key.bias', 'base_model.encoder.layer.5.attention.output.LayerNorm.weight', 'base_model.encoder.layer.4.attention.self.key.weight', 'base_model.encoder.layer.8.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.16.attention.output.dense.weight', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.1.output.LayerNorm.weight', 'base_model.encoder.layer.4.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.10.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.11.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.5.attention.self.query.bias', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.12.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.14.output.LayerNorm.bias', 'base_model.encoder.layer.14.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.14.attention.self.key.weight', 'base_model.encoder.layer.6.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.12.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.15.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.2.output.adapters.tp.adapter_up.bias', 'base_model.embeddings.position_ids', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.20.attention.self.query.bias', 'base_model.encoder.layer.0.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.18.attention.output.dense.bias', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.21.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.8.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.22.output.dense.weight', 'base_model.encoder.layer.9.attention.self.query.weight', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.5.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.16.attention.output.dense.bias', 'base_model.encoder.layer.18.attention.self.value.bias', 'base_model.encoder.layer.18.output.LayerNorm.weight', 'base_model.encoder.layer.20.output.dense.bias', 'base_model.encoder.layer.16.attention.self.query.weight', 'base_model.encoder.layer.19.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.1.output.dense.bias', 'base_model.encoder.layer.11.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.19.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.9.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.8.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.15.attention.output.dense.weight', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.12.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.8.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.14.attention.output.LayerNorm.bias', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.2.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.17.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.0.attention.self.query.weight', 'base_model.encoder.layer.6.output.adapters.ep.adapter_up.bias', 'qa_outputs.weight', 'base_model.encoder.layer.7.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.0.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.2.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.13.attention.self.value.weight', 'base_model.encoder.layer.2.attention.self.value.bias', 'base_model.encoder.layer.14.attention.self.key.bias', 'base_model.encoder.layer.16.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.8.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.2.intermediate.dense.bias', 'base_model.encoder.layer.21.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.11.attention.output.dense.bias', 'base_model.encoder.layer.23.output.dense.bias', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.14.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.22.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.11.output.adapters.tp.adapter_up.bias', 'base_model.embeddings.token_type_embeddings.weight', 'base_model.encoder.layer.21.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.22.attention.self.query.weight', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.13.attention.self.key.weight', 'base_model.encoder.layer.19.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.20.output.LayerNorm.weight', 'base_model.encoder.layer.23.output.LayerNorm.bias', 'base_model.encoder.layer.17.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.3.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.21.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.2.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.3.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.8.attention.self.query.bias', 'base_model.encoder.layer.5.attention.output.dense.bias', 'base_model.encoder.layer.15.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.23.attention.self.query.weight', 'base_model.encoder.layer.8.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.11.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.1.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.4.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.14.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.13.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.14.attention.self.value.weight', 'base_model.encoder.layer.15.attention.output.dense.bias', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.11.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.0.output.LayerNorm.weight', 'base_model.encoder.layer.8.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.11.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.16.attention.self.value.weight', 'base_model.encoder.layer.20.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.3.output.dense.weight', 'base_model.encoder.layer.11.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.21.output.LayerNorm.bias', 'base_model.encoder.layer.3.intermediate.dense.bias', 'base_model.pooler.dense.bias', 'base_model.encoder.layer.12.attention.output.LayerNorm.bias', 'base_model.encoder.layer.18.attention.self.key.weight', 'base_model.encoder.layer.5.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.13.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.8.attention.output.LayerNorm.weight', 'base_model.encoder.layer.11.attention.self.query.bias', 'base_model.encoder.layer.5.attention.output.LayerNorm.bias', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.1.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.22.attention.output.LayerNorm.weight', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.9.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.3.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.20.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.4.attention.output.dense.weight', 'base_model.encoder.layer.14.intermediate.dense.bias', 'base_model.encoder.layer.5.output.adapters.es.adapter_up.weight', 'base_model.embeddings.word_embeddings.weight', 'base_model.encoder.layer.8.attention.output.LayerNorm.bias', 'base_model.encoder.layer.23.output.LayerNorm.weight', 'base_model.encoder.layer.20.intermediate.dense.weight', 'base_model.encoder.layer.22.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.2.attention.output.LayerNorm.weight', 'base_model.encoder.layer.18.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.10.attention.self.query.bias', 'base_model.encoder.layer.21.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.14.attention.self.query.bias', 'base_model.encoder.layer.18.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.21.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.3.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.11.attention.output.LayerNorm.weight', 'base_model.encoder.layer.22.attention.self.query.bias', 'base_model.encoder.layer.7.intermediate.dense.weight', 'base_model.encoder.layer.23.intermediate.dense.weight', 'base_model.encoder.layer.9.output.LayerNorm.weight', 'base_model.encoder.layer.20.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.11.attention.self.key.bias', 'base_model.encoder.layer.22.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.15.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.22.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.7.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.3.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.10.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.3.output.LayerNorm.bias', 'base_model.encoder.layer.17.attention.output.LayerNorm.weight', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.0.intermediate.dense.weight', 'base_model.encoder.layer.23.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.13.attention.output.LayerNorm.weight', 'base_model.encoder.layer.0.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.6.attention.self.value.weight', 'base_model.encoder.layer.7.attention.output.LayerNorm.weight', 'base_model.encoder.layer.10.output.dense.weight', 'base_model.encoder.layer.15.intermediate.dense.weight', 'base_model.encoder.layer.4.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.12.attention.self.key.weight', 'base_model.encoder.layer.12.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.2.output.adapters.ep.adapter_up.bias']
- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of XLMRobertaModel were not initialized from the model checkpoint at /cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//squad/xlm-KG_LR8e-6_EPOCH2.0_maxlen384_batchsize4_gradacc4 and are newly initialized: ['encoder.layer.17.output.LayerNorm.weight', 'encoder.layer.6.output.dense.bias', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.14.output.LayerNorm.bias', 'encoder.layer.9.attention.self.key.weight', 'encoder.layer.6.attention.self.query.bias', 'encoder.layer.7.attention.output.dense.weight', 'encoder.layer.15.attention.self.value.weight', 'encoder.layer.13.intermediate.dense.bias', 'encoder.layer.22.attention.output.LayerNorm.bias', 'encoder.layer.15.output.dense.bias', 'encoder.layer.19.output.LayerNorm.weight', 'encoder.layer.13.attention.output.LayerNorm.bias', 'encoder.layer.18.attention.self.key.bias', 'encoder.layer.17.output.dense.weight', 'encoder.layer.12.attention.output.dense.weight', 'pooler.dense.weight', 'encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.layer.14.attention.self.value.bias', 'encoder.layer.1.attention.self.value.bias', 'encoder.layer.1.attention.self.key.weight', 'encoder.layer.5.attention.self.value.weight', 'encoder.layer.11.attention.output.LayerNorm.weight', 'encoder.layer.13.attention.self.key.weight', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.21.attention.output.LayerNorm.bias', 'encoder.layer.23.attention.self.key.weight', 'encoder.layer.0.attention.output.LayerNorm.weight', 'encoder.layer.2.attention.self.query.bias', 'encoder.layer.6.attention.self.value.weight', 'encoder.layer.22.attention.self.key.bias', 'encoder.layer.18.intermediate.dense.weight', 'encoder.layer.10.attention.self.key.weight', 'encoder.layer.16.output.LayerNorm.bias', 'encoder.layer.10.intermediate.dense.weight', 'encoder.layer.19.attention.self.key.bias', 'encoder.layer.13.attention.self.query.weight', 'encoder.layer.0.attention.self.key.bias', 'encoder.layer.4.attention.output.LayerNorm.weight', 'encoder.layer.10.attention.output.LayerNorm.bias', 'encoder.layer.20.output.LayerNorm.weight', 'encoder.layer.9.attention.self.value.bias', 'encoder.layer.19.output.dense.bias', 'encoder.layer.2.output.dense.bias', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.21.attention.output.dense.weight', 'encoder.layer.21.intermediate.dense.bias', 'encoder.layer.3.attention.self.query.weight', 'encoder.layer.14.intermediate.dense.weight', 'encoder.layer.22.attention.self.value.weight', 'encoder.layer.19.intermediate.dense.weight', 'encoder.layer.14.output.dense.weight', 'encoder.layer.22.attention.output.dense.bias', 'encoder.layer.22.output.dense.bias', 'encoder.layer.10.attention.output.dense.weight', 'encoder.layer.20.attention.self.value.bias', 'encoder.layer.22.attention.self.key.weight', 'encoder.layer.15.attention.self.key.weight', 'encoder.layer.0.attention.self.value.bias', 'encoder.layer.10.attention.output.dense.bias', 'encoder.layer.9.attention.self.query.weight', 'encoder.layer.21.output.LayerNorm.weight', 'encoder.layer.20.attention.self.key.weight', 'embeddings.LayerNorm.bias', 'encoder.layer.17.attention.self.key.bias', 'encoder.layer.11.output.LayerNorm.weight', 'encoder.layer.6.attention.self.key.weight', 'encoder.layer.6.output.dense.weight', 'encoder.layer.1.output.dense.weight', 'embeddings.token_type_embeddings.weight', 'encoder.layer.8.output.LayerNorm.weight', 'encoder.layer.22.attention.output.LayerNorm.weight', 'encoder.layer.10.attention.self.value.bias', 'encoder.layer.16.attention.self.query.bias', 'encoder.layer.8.attention.output.LayerNorm.weight', 'encoder.layer.9.output.LayerNorm.bias', 'encoder.layer.7.output.LayerNorm.weight', 'encoder.layer.20.attention.self.query.weight', 'encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.layer.13.attention.self.value.bias', 'encoder.layer.15.output.dense.weight', 'encoder.layer.15.attention.output.LayerNorm.weight', 'pooler.dense.bias', 'encoder.layer.21.output.LayerNorm.bias', 'encoder.layer.15.output.LayerNorm.weight', 'encoder.layer.5.output.dense.weight', 'encoder.layer.0.output.dense.weight', 'encoder.layer.23.output.LayerNorm.weight', 'encoder.layer.5.attention.self.query.bias', 'encoder.layer.11.output.LayerNorm.bias', 'encoder.layer.14.attention.self.key.bias', 'encoder.layer.14.intermediate.dense.bias', 'encoder.layer.18.attention.self.value.weight', 'encoder.layer.6.output.LayerNorm.bias', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.7.attention.self.value.bias', 'encoder.layer.14.attention.output.LayerNorm.bias', 'encoder.layer.18.output.dense.weight', 'encoder.layer.20.output.dense.bias', 'encoder.layer.21.attention.self.query.bias', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.12.attention.output.LayerNorm.weight', 'encoder.layer.8.attention.output.LayerNorm.bias', 'encoder.layer.15.attention.self.key.bias', 'encoder.layer.19.intermediate.dense.bias', 'encoder.layer.16.attention.self.value.weight', 'encoder.layer.3.attention.output.dense.bias', 'encoder.layer.7.attention.self.query.bias', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.20.attention.output.dense.weight', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.10.attention.output.LayerNorm.weight', 'encoder.layer.16.attention.self.value.bias', 'encoder.layer.9.output.LayerNorm.weight', 'encoder.layer.18.output.dense.bias', 'encoder.layer.21.intermediate.dense.weight', 'encoder.layer.4.attention.self.key.weight', 'encoder.layer.18.attention.self.value.bias', 'encoder.layer.13.output.dense.weight', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.14.attention.output.LayerNorm.weight', 'encoder.layer.23.output.dense.bias', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.19.attention.self.query.weight', 'encoder.layer.3.attention.self.query.bias', 'encoder.layer.8.attention.self.value.bias', 'encoder.layer.23.attention.output.LayerNorm.weight', 'encoder.layer.6.attention.output.LayerNorm.bias', 'encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.layer.23.output.dense.weight', 'encoder.layer.9.attention.self.key.bias', 'encoder.layer.12.attention.output.dense.bias', 'encoder.layer.16.attention.output.LayerNorm.bias', 'encoder.layer.11.attention.self.query.bias', 'encoder.layer.0.attention.output.dense.weight', 'encoder.layer.3.attention.output.dense.weight', 'encoder.layer.1.attention.self.value.weight', 'encoder.layer.7.output.dense.weight', 'encoder.layer.4.output.dense.bias', 'encoder.layer.14.attention.self.query.bias', 'encoder.layer.21.attention.output.LayerNorm.weight', 'encoder.layer.20.attention.output.LayerNorm.bias', 'encoder.layer.19.attention.self.value.weight', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.8.attention.self.query.bias', 'encoder.layer.11.attention.output.dense.bias', 'encoder.layer.11.attention.self.value.bias', 'encoder.layer.20.attention.output.LayerNorm.weight', 'encoder.layer.18.attention.self.query.bias', 'encoder.layer.14.output.dense.bias', 'encoder.layer.22.attention.output.dense.weight', 'encoder.layer.20.attention.self.query.bias', 'encoder.layer.14.attention.self.value.weight', 'encoder.layer.3.attention.self.key.weight', 'encoder.layer.10.output.dense.weight', 'encoder.layer.5.attention.output.LayerNorm.weight', 'encoder.layer.1.attention.output.dense.bias', 'encoder.layer.15.attention.self.value.bias', 'encoder.layer.13.attention.output.LayerNorm.weight', 'encoder.layer.18.attention.self.query.weight', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.15.attention.self.query.weight', 'encoder.layer.6.attention.output.dense.weight', 'encoder.layer.22.intermediate.dense.bias', 'encoder.layer.2.attention.output.LayerNorm.weight', 'encoder.layer.10.attention.self.value.weight', 'encoder.layer.23.attention.self.query.weight', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.8.output.dense.weight', 'encoder.layer.10.output.dense.bias', 'encoder.layer.22.output.dense.weight', 'encoder.layer.18.attention.output.LayerNorm.weight', 'encoder.layer.23.attention.output.dense.bias', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.18.attention.output.LayerNorm.bias', 'encoder.layer.17.intermediate.dense.bias', 'encoder.layer.22.attention.self.value.bias', 'encoder.layer.1.attention.output.dense.weight', 'encoder.layer.4.attention.self.query.bias', 'encoder.layer.21.output.dense.bias', 'embeddings.position_embeddings.weight', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.16.attention.output.dense.weight', 'encoder.layer.2.output.dense.weight', 'encoder.layer.5.attention.self.value.bias', 'encoder.layer.21.attention.output.dense.bias', 'encoder.layer.4.attention.output.dense.bias', 'encoder.layer.12.attention.self.query.bias', 'encoder.layer.7.intermediate.dense.bias', 'encoder.layer.15.intermediate.dense.bias', 'encoder.layer.9.output.dense.bias', 'encoder.layer.9.attention.self.query.bias', 'encoder.layer.2.attention.self.key.bias', 'encoder.layer.6.attention.self.query.weight', 'encoder.layer.11.attention.self.key.weight', 'encoder.layer.14.output.LayerNorm.weight', 'encoder.layer.23.attention.self.value.weight', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.11.attention.output.dense.weight', 'encoder.layer.19.output.dense.weight', 'encoder.layer.16.output.dense.bias', 'encoder.layer.0.output.dense.bias', 'encoder.layer.23.output.LayerNorm.bias', 'encoder.layer.13.attention.self.key.bias', 'encoder.layer.2.attention.output.dense.bias', 'encoder.layer.3.attention.self.value.weight', 'encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.layer.7.attention.output.LayerNorm.bias', 'encoder.layer.8.attention.self.value.weight', 'encoder.layer.12.attention.output.LayerNorm.bias', 'encoder.layer.5.attention.output.dense.weight', 'encoder.layer.15.intermediate.dense.weight', 'encoder.layer.13.attention.self.value.weight', 'encoder.layer.10.output.LayerNorm.weight', 'encoder.layer.2.attention.self.value.weight', 'encoder.layer.5.attention.self.key.weight', 'encoder.layer.1.attention.self.query.bias', 'encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.13.output.LayerNorm.bias', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.3.output.dense.weight', 'encoder.layer.8.attention.output.dense.bias', 'encoder.layer.13.attention.self.query.bias', 'encoder.layer.7.attention.self.key.bias', 'encoder.layer.4.attention.self.value.weight', 'encoder.layer.15.attention.self.query.bias', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.2.attention.self.query.weight', 'encoder.layer.16.attention.self.query.weight', 'encoder.layer.22.intermediate.dense.weight', 'encoder.layer.11.attention.self.value.weight', 'encoder.layer.5.attention.output.dense.bias', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.12.output.LayerNorm.bias', 'encoder.layer.12.attention.self.value.weight', 'encoder.layer.9.attention.output.dense.weight', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.15.attention.output.LayerNorm.bias', 'encoder.layer.19.attention.output.dense.weight', 'encoder.layer.22.output.LayerNorm.weight', 'encoder.layer.8.attention.self.query.weight', 'encoder.layer.12.output.dense.bias', 'encoder.layer.19.output.LayerNorm.bias', 'encoder.layer.4.attention.self.query.weight', 'encoder.layer.17.attention.self.value.bias', 'encoder.layer.8.output.LayerNorm.bias', 'encoder.layer.20.attention.output.dense.bias', 'encoder.layer.13.output.LayerNorm.weight', 'encoder.layer.11.output.dense.weight', 'encoder.layer.16.output.dense.weight', 'encoder.layer.5.output.dense.bias', 'encoder.layer.16.intermediate.dense.weight', 'encoder.layer.17.attention.output.dense.bias', 'encoder.layer.23.attention.output.LayerNorm.bias', 'encoder.layer.7.attention.self.key.weight', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.3.attention.self.key.bias', 'encoder.layer.12.attention.self.query.weight', 'encoder.layer.18.output.LayerNorm.bias', 'encoder.layer.21.output.dense.weight', 'encoder.layer.13.output.dense.bias', 'encoder.layer.3.attention.self.value.bias', 'encoder.layer.21.attention.self.key.weight', 'embeddings.word_embeddings.weight', 'encoder.layer.2.attention.self.value.bias', 'encoder.layer.17.attention.self.query.weight', 'encoder.layer.4.output.dense.weight', 'encoder.layer.23.intermediate.dense.bias', 'encoder.layer.6.attention.self.value.bias', 'encoder.layer.15.attention.output.dense.bias', 'encoder.layer.0.attention.self.value.weight', 'encoder.layer.18.attention.self.key.weight', 'encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.layer.16.attention.self.key.weight', 'encoder.layer.15.output.LayerNorm.bias', 'encoder.layer.14.attention.self.key.weight', 'encoder.layer.16.intermediate.dense.bias', 'encoder.layer.7.attention.output.LayerNorm.weight', 'encoder.layer.1.output.dense.bias', 'encoder.layer.2.attention.output.LayerNorm.bias', 'encoder.layer.1.attention.output.LayerNorm.weight', 'encoder.layer.3.output.dense.bias', 'encoder.layer.9.attention.self.value.weight', 'encoder.layer.8.attention.self.key.bias', 'encoder.layer.17.attention.output.LayerNorm.weight', 'encoder.layer.23.attention.self.value.bias', 'encoder.layer.21.attention.self.value.weight', 'encoder.layer.8.attention.self.key.weight', 'encoder.layer.10.attention.self.query.weight', 'encoder.layer.0.attention.output.dense.bias', 'encoder.layer.0.attention.self.query.weight', 'encoder.layer.4.attention.self.value.bias', 'embeddings.LayerNorm.weight', 'encoder.layer.18.output.LayerNorm.weight', 'encoder.layer.20.attention.self.value.weight', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.2.attention.output.dense.weight', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.12.attention.self.key.weight', 'encoder.layer.20.attention.self.key.bias', 'encoder.layer.17.attention.self.value.weight', 'encoder.layer.6.attention.output.dense.bias', 'encoder.layer.10.attention.self.key.bias', 'encoder.layer.5.attention.self.query.weight', 'encoder.layer.8.attention.output.dense.weight', 'encoder.layer.12.output.dense.weight', 'encoder.layer.16.attention.output.dense.bias', 'encoder.layer.17.output.LayerNorm.bias', 'encoder.layer.14.attention.output.dense.bias', 'encoder.layer.16.output.LayerNorm.weight', 'encoder.layer.14.attention.output.dense.weight', 'encoder.layer.19.attention.output.dense.bias', 'encoder.layer.4.attention.self.key.bias', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.5.output.LayerNorm.bias', 'encoder.layer.23.attention.output.dense.weight', 'encoder.layer.7.attention.self.query.weight', 'encoder.layer.0.attention.self.key.weight', 'encoder.layer.17.attention.output.LayerNorm.bias', 'encoder.layer.0.attention.self.query.bias', 'encoder.layer.23.intermediate.dense.weight', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.4.attention.output.LayerNorm.bias', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.21.attention.self.key.bias', 'encoder.layer.22.attention.self.query.weight', 'encoder.layer.12.attention.self.value.bias', 'encoder.layer.7.attention.self.value.weight', 'encoder.layer.13.attention.output.dense.bias', 'encoder.layer.17.output.dense.bias', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.16.attention.output.LayerNorm.weight', 'encoder.layer.17.attention.self.key.weight', 'encoder.layer.2.attention.self.key.weight', 'encoder.layer.9.output.dense.weight', 'encoder.layer.12.output.LayerNorm.weight', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.11.attention.self.key.bias', 'encoder.layer.21.attention.self.value.bias', 'encoder.layer.18.attention.output.dense.weight', 'encoder.layer.10.output.LayerNorm.bias', 'encoder.layer.15.attention.output.dense.weight', 'encoder.layer.6.attention.output.LayerNorm.weight', 'encoder.layer.5.attention.self.key.bias', 'encoder.layer.14.attention.self.query.weight', 'encoder.layer.1.attention.self.key.bias', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.13.intermediate.dense.weight', 'encoder.layer.7.output.LayerNorm.bias', 'encoder.layer.20.intermediate.dense.bias', 'encoder.layer.11.attention.self.query.weight', 'encoder.layer.22.output.LayerNorm.bias', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.17.attention.self.query.bias', 'encoder.layer.9.attention.output.LayerNorm.bias', 'encoder.layer.22.attention.self.query.bias', 'encoder.layer.9.attention.output.dense.bias', 'encoder.layer.19.attention.self.value.bias', 'encoder.layer.19.attention.self.query.bias', 'encoder.layer.6.attention.self.key.bias', 'encoder.layer.20.intermediate.dense.weight', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.21.attention.self.query.weight', 'encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.20.output.LayerNorm.bias', 'encoder.layer.4.attention.output.dense.weight', 'encoder.layer.7.output.dense.bias', 'encoder.layer.9.attention.output.LayerNorm.weight', 'encoder.layer.19.attention.self.key.weight', 'encoder.layer.23.attention.self.key.bias', 'encoder.layer.16.attention.self.key.bias', 'encoder.layer.11.output.dense.bias', 'encoder.layer.13.attention.output.dense.weight', 'encoder.layer.10.attention.self.query.bias', 'encoder.layer.19.attention.output.LayerNorm.bias', 'encoder.layer.8.output.dense.bias', 'encoder.layer.1.attention.self.query.weight', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.17.attention.output.dense.weight', 'encoder.layer.18.attention.output.dense.bias', 'encoder.layer.23.attention.self.query.bias', 'encoder.layer.20.output.dense.weight', 'encoder.layer.7.attention.output.dense.bias', 'encoder.layer.18.intermediate.dense.bias', 'encoder.layer.12.intermediate.dense.weight', 'encoder.layer.12.intermediate.dense.bias', 'encoder.layer.12.attention.self.key.bias', 'encoder.layer.17.intermediate.dense.weight', 'encoder.layer.19.attention.output.LayerNorm.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Overwriting existing adapter 'ep'.
Overwriting existing adapter 'tp'.
Overwriting existing adapter 'es'.
Overwriting existing adapter 'ts'.
Overwriting existing adapter fusion module 'ep,tp,es,ts'
05/09/2022 19:51:32 - INFO - __main__ -   Creating features from dataset file at .
/cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//squad/xlm-KG_LR8e-6_EPOCH2.0_maxlen384_batchsize4_gradacc4
XLMConfig {
  "architectures": [
    "XLMRobertaForMaskedLM"
  ],
  "asm": false,
  "attention_dropout": 0.1,
  "attention_probs_dropout_prob": 0.1,
  "bos_index": 0,
  "bos_token_id": 0,
  "causal": false,
  "dropout": 0.1,
  "emb_dim": 1024,
  "embed_init_std": 0.02209708691207961,
  "end_n_top": 5,
  "eos_index": 1,
  "eos_token_id": 2,
  "gelu_activation": true,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "init_std": 0.02,
  "initializer_range": 0.02,
  "intermediate_size": 4096,
  "is_encoder": true,
  "lang_id": 0,
  "layer_norm_eps": 1e-05,
  "mask_index": 5,
  "mask_token_id": 0,
  "max_position_embeddings": 514,
  "model_type": "xlm",
  "n_heads": 16,
  "n_langs": 1,
  "n_layers": 24,
  "output_past": true,
  "pad_index": 2,
  "pad_token_id": 1,
  "sinusoidal_embeddings": false,
  "start_n_top": 5,
  "summary_activation": null,
  "summary_first_dropout": 0.1,
  "summary_proj_to_labels": true,
  "summary_type": "first",
  "summary_use_proj": true,
  "transformers_version": "4.17.0",
  "type_vocab_size": 1,
  "unk_index": 3,
  "use_lang_emb": false,
  "vocab_size": 250002
}

  0%|          | 0/48 [00:00<?, ?it/s] 21%|██        | 10/48 [00:00<00:00, 97.87it/s] 42%|████▏     | 20/48 [00:00<00:00, 79.10it/s] 62%|██████▎   | 30/48 [00:00<00:00, 84.54it/s] 81%|████████▏ | 39/48 [00:00<00:00, 84.50it/s]100%|██████████| 48/48 [00:00<00:00, 90.80it/s]
convert squad examples to features:   0%|          | 0/1190 [00:00<?, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.
convert squad examples to features:   0%|          | 1/1190 [00:00<04:22,  4.53it/s]convert squad examples to features:   5%|▌         | 65/1190 [00:00<00:06, 162.24it/s]convert squad examples to features:   8%|▊         | 97/1190 [00:00<00:05, 189.36it/s]convert squad examples to features:  11%|█         | 129/1190 [00:00<00:04, 215.37it/s]convert squad examples to features:  14%|█▎        | 161/1190 [00:00<00:04, 223.04it/s]convert squad examples to features:  19%|█▉        | 225/1190 [00:01<00:03, 253.43it/s]convert squad examples to features:  22%|██▏       | 257/1190 [00:01<00:03, 243.42it/s]convert squad examples to features:  24%|██▍       | 289/1190 [00:01<00:03, 239.68it/s]convert squad examples to features:  27%|██▋       | 321/1190 [00:01<00:03, 231.12it/s]convert squad examples to features:  30%|██▉       | 353/1190 [00:01<00:03, 223.98it/s]convert squad examples to features:  32%|███▏      | 385/1190 [00:02<00:06, 129.55it/s]convert squad examples to features:  35%|███▌      | 417/1190 [00:02<00:05, 146.30it/s]convert squad examples to features:  38%|███▊      | 449/1190 [00:02<00:04, 158.47it/s]convert squad examples to features:  40%|████      | 481/1190 [00:02<00:04, 162.53it/s]convert squad examples to features:  43%|████▎     | 513/1190 [00:02<00:04, 167.75it/s]convert squad examples to features:  46%|████▌     | 545/1190 [00:03<00:03, 161.32it/s]convert squad examples to features:  48%|████▊     | 577/1190 [00:03<00:03, 179.40it/s]convert squad examples to features:  51%|█████     | 609/1190 [00:03<00:03, 184.28it/s]convert squad examples to features:  54%|█████▍    | 641/1190 [00:03<00:02, 185.52it/s]convert squad examples to features:  57%|█████▋    | 673/1190 [00:03<00:02, 176.03it/s]convert squad examples to features:  59%|█████▉    | 705/1190 [00:03<00:02, 181.53it/s]convert squad examples to features:  62%|██████▏   | 737/1190 [00:04<00:02, 180.92it/s]convert squad examples to features:  65%|██████▍   | 769/1190 [00:04<00:02, 194.18it/s]convert squad examples to features:  67%|██████▋   | 801/1190 [00:04<00:01, 219.22it/s]convert squad examples to features:  70%|███████   | 833/1190 [00:04<00:01, 193.86it/s]convert squad examples to features:  73%|███████▎  | 865/1190 [00:04<00:01, 208.18it/s]convert squad examples to features:  75%|███████▌  | 897/1190 [00:04<00:01, 210.24it/s]convert squad examples to features:  78%|███████▊  | 929/1190 [00:04<00:01, 217.83it/s]convert squad examples to features:  81%|████████  | 961/1190 [00:05<00:00, 229.60it/s]convert squad examples to features:  83%|████████▎ | 993/1190 [00:05<00:00, 236.77it/s]convert squad examples to features:  86%|████████▌ | 1025/1190 [00:05<00:00, 243.96it/s]convert squad examples to features:  92%|█████████▏| 1089/1190 [00:05<00:00, 269.70it/s]convert squad examples to features:  94%|█████████▍| 1121/1190 [00:05<00:00, 262.44it/s]convert squad examples to features:  97%|█████████▋| 1153/1190 [00:05<00:00, 246.80it/s]convert squad examples to features: 100%|██████████| 1190/1190 [00:05<00:00, 205.82it/s]/cluster/project/sachan/yifan/softwares/anaconda/anaconda3/envs/xfactr/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2272: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

add example index and unique id:   0%|          | 0/1190 [00:00<?, ?it/s]add example index and unique id: 100%|██████████| 1190/1190 [00:00<00:00, 686361.63it/s]
05/09/2022 19:51:39 - INFO - __main__ -   Saving features into cached file ./cached_xquad.es.json_xlm-KG_LR8e-6_EPOCH2.0_maxlen384_batchsize4_gradacc4_384_es
05/09/2022 19:51:40 - INFO - __main__ -   ***** Running evaluation  *****
05/09/2022 19:51:40 - INFO - __main__ -     Num examples = 1304
05/09/2022 19:51:40 - INFO - __main__ -     Batch size = 8
Evaluating:   0%|          | 0/163 [00:00<?, ?it/s]Evaluating:   1%|          | 1/163 [00:00<02:03,  1.32it/s]Evaluating:   1%|          | 2/163 [00:01<01:24,  1.91it/s]Evaluating:   2%|▏         | 3/163 [00:01<01:11,  2.23it/s]Evaluating:   2%|▏         | 4/163 [00:01<01:05,  2.43it/s]Evaluating:   3%|▎         | 5/163 [00:02<01:01,  2.56it/s]Evaluating:   4%|▎         | 6/163 [00:02<00:59,  2.62it/s]Evaluating:   4%|▍         | 7/163 [00:02<00:58,  2.68it/s]Evaluating:   5%|▍         | 8/163 [00:03<00:56,  2.72it/s]Evaluating:   6%|▌         | 9/163 [00:03<00:56,  2.74it/s]Evaluating:   6%|▌         | 10/163 [00:03<00:55,  2.75it/s]Evaluating:   7%|▋         | 11/163 [00:04<00:55,  2.74it/s]Evaluating:   7%|▋         | 12/163 [00:04<00:54,  2.75it/s]Evaluating:   8%|▊         | 13/163 [00:05<00:54,  2.77it/s]Evaluating:   9%|▊         | 14/163 [00:05<00:53,  2.78it/s]Evaluating:   9%|▉         | 15/163 [00:05<00:53,  2.78it/s]Evaluating:  10%|▉         | 16/163 [00:06<00:52,  2.79it/s]Evaluating:  10%|█         | 17/163 [00:06<00:52,  2.80it/s]Evaluating:  11%|█         | 18/163 [00:06<00:51,  2.81it/s]Evaluating:  12%|█▏        | 19/163 [00:07<00:51,  2.81it/s]Evaluating:  12%|█▏        | 20/163 [00:07<00:50,  2.81it/s]Evaluating:  13%|█▎        | 21/163 [00:07<00:50,  2.80it/s]Evaluating:  13%|█▎        | 22/163 [00:08<00:50,  2.81it/s]Evaluating:  14%|█▍        | 23/163 [00:08<00:49,  2.81it/s]Evaluating:  15%|█▍        | 24/163 [00:08<00:49,  2.82it/s]Evaluating:  15%|█▌        | 25/163 [00:09<00:49,  2.77it/s]Evaluating:  16%|█▌        | 26/163 [00:09<00:49,  2.78it/s]Evaluating:  17%|█▋        | 27/163 [00:10<00:48,  2.79it/s]Evaluating:  17%|█▋        | 28/163 [00:10<00:48,  2.80it/s]Evaluating:  18%|█▊        | 29/163 [00:10<00:47,  2.80it/s]Evaluating:  18%|█▊        | 30/163 [00:11<00:47,  2.81it/s]Evaluating:  19%|█▉        | 31/163 [00:11<00:46,  2.81it/s]Evaluating:  20%|█▉        | 32/163 [00:11<00:46,  2.81it/s]Evaluating:  20%|██        | 33/163 [00:12<00:46,  2.81it/s]Evaluating:  21%|██        | 34/163 [00:12<00:45,  2.81it/s]Evaluating:  21%|██▏       | 35/163 [00:12<00:45,  2.82it/s]Evaluating:  22%|██▏       | 36/163 [00:13<00:45,  2.81it/s]Evaluating:  23%|██▎       | 37/163 [00:13<00:44,  2.81it/s]Evaluating:  23%|██▎       | 38/163 [00:13<00:44,  2.79it/s]Evaluating:  24%|██▍       | 39/163 [00:14<00:44,  2.79it/s]Evaluating:  25%|██▍       | 40/163 [00:14<00:44,  2.78it/s]Evaluating:  25%|██▌       | 41/163 [00:15<00:43,  2.79it/s]Evaluating:  26%|██▌       | 42/163 [00:15<00:43,  2.78it/s]Evaluating:  26%|██▋       | 43/163 [00:15<00:43,  2.78it/s]Evaluating:  27%|██▋       | 44/163 [00:16<00:42,  2.78it/s]Evaluating:  28%|██▊       | 45/163 [00:16<00:42,  2.78it/s]Evaluating:  28%|██▊       | 46/163 [00:16<00:41,  2.79it/s]Evaluating:  29%|██▉       | 47/163 [00:17<00:41,  2.79it/s]Evaluating:  29%|██▉       | 48/163 [00:17<00:41,  2.79it/s]Evaluating:  30%|███       | 49/163 [00:17<00:40,  2.79it/s]Evaluating:  31%|███       | 50/163 [00:18<00:40,  2.79it/s]Evaluating:  31%|███▏      | 51/163 [00:18<00:40,  2.79it/s]Evaluating:  32%|███▏      | 52/163 [00:19<00:40,  2.76it/s]Evaluating:  33%|███▎      | 53/163 [00:19<00:39,  2.76it/s]Evaluating:  33%|███▎      | 54/163 [00:19<00:39,  2.76it/s]Evaluating:  34%|███▎      | 55/163 [00:20<00:39,  2.75it/s]Evaluating:  34%|███▍      | 56/163 [00:20<00:38,  2.76it/s]Evaluating:  35%|███▍      | 57/163 [00:20<00:38,  2.76it/s]Evaluating:  36%|███▌      | 58/163 [00:21<00:38,  2.76it/s]Evaluating:  36%|███▌      | 59/163 [00:21<00:37,  2.76it/s]Evaluating:  37%|███▋      | 60/163 [00:21<00:37,  2.77it/s]Evaluating:  37%|███▋      | 61/163 [00:22<00:36,  2.77it/s]Evaluating:  38%|███▊      | 62/163 [00:22<00:36,  2.77it/s]Evaluating:  39%|███▊      | 63/163 [00:22<00:36,  2.77it/s]Evaluating:  39%|███▉      | 64/163 [00:23<00:35,  2.77it/s]Evaluating:  40%|███▉      | 65/163 [00:23<00:35,  2.77it/s]Evaluating:  40%|████      | 66/163 [00:24<00:34,  2.78it/s]Evaluating:  41%|████      | 67/163 [00:24<00:34,  2.79it/s]Evaluating:  42%|████▏     | 68/163 [00:24<00:34,  2.78it/s]Evaluating:  42%|████▏     | 69/163 [00:25<00:33,  2.77it/s]Evaluating:  43%|████▎     | 70/163 [00:25<00:33,  2.77it/s]Evaluating:  44%|████▎     | 71/163 [00:25<00:33,  2.75it/s]Evaluating:  44%|████▍     | 72/163 [00:26<00:32,  2.76it/s]Evaluating:  45%|████▍     | 73/163 [00:26<00:32,  2.76it/s]Evaluating:  45%|████▌     | 74/163 [00:26<00:32,  2.77it/s]Evaluating:  46%|████▌     | 75/163 [00:27<00:31,  2.77it/s]Evaluating:  47%|████▋     | 76/163 [00:27<00:31,  2.77it/s]Evaluating:  47%|████▋     | 77/163 [00:28<00:31,  2.77it/s]Evaluating:  48%|████▊     | 78/163 [00:28<00:30,  2.77it/s]Evaluating:  48%|████▊     | 79/163 [00:28<00:30,  2.76it/s]Evaluating:  49%|████▉     | 80/163 [00:29<00:30,  2.76it/s]Evaluating:  50%|████▉     | 81/163 [00:29<00:29,  2.76it/s]Evaluating:  50%|█████     | 82/163 [00:29<00:29,  2.77it/s]Evaluating:  51%|█████     | 83/163 [00:30<00:28,  2.77it/s]Evaluating:  52%|█████▏    | 84/163 [00:30<00:28,  2.76it/s]Evaluating:  52%|█████▏    | 85/163 [00:30<00:28,  2.76it/s]Evaluating:  53%|█████▎    | 86/163 [00:31<00:27,  2.75it/s]Evaluating:  53%|█████▎    | 87/163 [00:31<00:27,  2.74it/s]Evaluating:  54%|█████▍    | 88/163 [00:32<00:27,  2.74it/s]Evaluating:  55%|█████▍    | 89/163 [00:32<00:26,  2.75it/s]Evaluating:  55%|█████▌    | 90/163 [00:32<00:26,  2.76it/s]Evaluating:  56%|█████▌    | 91/163 [00:33<00:26,  2.76it/s]Evaluating:  56%|█████▋    | 92/163 [00:33<00:25,  2.76it/s]Evaluating:  57%|█████▋    | 93/163 [00:33<00:25,  2.77it/s]Evaluating:  58%|█████▊    | 94/163 [00:34<00:24,  2.77it/s]Evaluating:  58%|█████▊    | 95/163 [00:34<00:24,  2.77it/s]Evaluating:  59%|█████▉    | 96/163 [00:34<00:24,  2.75it/s]Evaluating:  60%|█████▉    | 97/163 [00:35<00:23,  2.75it/s]Evaluating:  60%|██████    | 98/163 [00:35<00:23,  2.76it/s]Evaluating:  61%|██████    | 99/163 [00:36<00:23,  2.76it/s]Evaluating:  61%|██████▏   | 100/163 [00:36<00:22,  2.76it/s]Evaluating:  62%|██████▏   | 101/163 [00:36<00:22,  2.75it/s]Evaluating:  63%|██████▎   | 102/163 [00:37<00:22,  2.76it/s]Evaluating:  63%|██████▎   | 103/163 [00:37<00:21,  2.75it/s]Evaluating:  64%|██████▍   | 104/163 [00:37<00:21,  2.76it/s]Evaluating:  64%|██████▍   | 105/163 [00:38<00:21,  2.76it/s]Evaluating:  65%|██████▌   | 106/163 [00:38<00:20,  2.75it/s]Evaluating:  66%|██████▌   | 107/163 [00:38<00:20,  2.75it/s]Evaluating:  66%|██████▋   | 108/163 [00:39<00:19,  2.76it/s]Evaluating:  67%|██████▋   | 109/163 [00:39<00:19,  2.76it/s]Evaluating:  67%|██████▋   | 110/163 [00:40<00:19,  2.77it/s]Evaluating:  68%|██████▊   | 111/163 [00:40<00:18,  2.77it/s]Evaluating:  69%|██████▊   | 112/163 [00:40<00:18,  2.78it/s]Evaluating:  69%|██████▉   | 113/163 [00:41<00:18,  2.75it/s]Evaluating:  70%|██████▉   | 114/163 [00:41<00:17,  2.76it/s]Evaluating:  71%|███████   | 115/163 [00:41<00:17,  2.76it/s]Evaluating:  71%|███████   | 116/163 [00:42<00:17,  2.75it/s]Evaluating:  72%|███████▏  | 117/163 [00:42<00:16,  2.75it/s]Evaluating:  72%|███████▏  | 118/163 [00:42<00:16,  2.75it/s]Evaluating:  73%|███████▎  | 119/163 [00:43<00:16,  2.75it/s]Evaluating:  74%|███████▎  | 120/163 [00:43<00:15,  2.76it/s]Evaluating:  74%|███████▍  | 121/163 [00:44<00:15,  2.76it/s]Evaluating:  75%|███████▍  | 122/163 [00:44<00:14,  2.77it/s]Evaluating:  75%|███████▌  | 123/163 [00:44<00:14,  2.74it/s]Evaluating:  76%|███████▌  | 124/163 [00:45<00:14,  2.71it/s]Evaluating:  77%|███████▋  | 125/163 [00:45<00:13,  2.72it/s]Evaluating:  77%|███████▋  | 126/163 [00:45<00:13,  2.73it/s]Evaluating:  78%|███████▊  | 127/163 [00:46<00:13,  2.74it/s]Evaluating:  79%|███████▊  | 128/163 [00:46<00:12,  2.74it/s]Evaluating:  79%|███████▉  | 129/163 [00:46<00:12,  2.74it/s]Evaluating:  80%|███████▉  | 130/163 [00:47<00:12,  2.74it/s]Evaluating:  80%|████████  | 131/163 [00:47<00:11,  2.71it/s]Evaluating:  81%|████████  | 132/163 [00:48<00:11,  2.69it/s]Evaluating:  82%|████████▏ | 133/163 [00:48<00:11,  2.67it/s]Evaluating:  82%|████████▏ | 134/163 [00:48<00:10,  2.70it/s]Evaluating:  83%|████████▎ | 135/163 [00:49<00:10,  2.71it/s]Evaluating:  83%|████████▎ | 136/163 [00:49<00:09,  2.73it/s]Evaluating:  84%|████████▍ | 137/163 [00:49<00:09,  2.74it/s]Evaluating:  85%|████████▍ | 138/163 [00:50<00:09,  2.75it/s]Evaluating:  85%|████████▌ | 139/163 [00:50<00:08,  2.76it/s]Evaluating:  86%|████████▌ | 140/163 [00:50<00:08,  2.77it/s]Evaluating:  87%|████████▋ | 141/163 [00:51<00:08,  2.73it/s]Evaluating:  87%|████████▋ | 142/163 [00:51<00:07,  2.74it/s]Evaluating:  88%|████████▊ | 143/163 [00:52<00:07,  2.74it/s]Evaluating:  88%|████████▊ | 144/163 [00:52<00:06,  2.75it/s]Evaluating:  89%|████████▉ | 145/163 [00:52<00:06,  2.76it/s]Evaluating:  90%|████████▉ | 146/163 [00:53<00:06,  2.77it/s]Evaluating:  90%|█████████ | 147/163 [00:53<00:05,  2.74it/s]Evaluating:  91%|█████████ | 148/163 [00:53<00:05,  2.74it/s]Evaluating:  91%|█████████▏| 149/163 [00:54<00:05,  2.74it/s]Evaluating:  92%|█████████▏| 150/163 [00:54<00:04,  2.75it/s]Evaluating:  93%|█████████▎| 151/163 [00:54<00:04,  2.75it/s]Evaluating:  93%|█████████▎| 152/163 [00:55<00:03,  2.76it/s]Evaluating:  94%|█████████▍| 153/163 [00:55<00:03,  2.76it/s]Evaluating:  94%|█████████▍| 154/163 [00:56<00:03,  2.77it/s]Evaluating:  95%|█████████▌| 155/163 [00:56<00:02,  2.77it/s]Evaluating:  96%|█████████▌| 156/163 [00:56<00:02,  2.77it/s]Evaluating:  96%|█████████▋| 157/163 [00:57<00:02,  2.77it/s]Evaluating:  97%|█████████▋| 158/163 [00:57<00:01,  2.77it/s]Evaluating:  98%|█████████▊| 159/163 [00:57<00:01,  2.77it/s]Evaluating:  98%|█████████▊| 160/163 [00:58<00:01,  2.77it/s]Evaluating:  99%|█████████▉| 161/163 [00:58<00:00,  2.76it/s]Evaluating:  99%|█████████▉| 162/163 [00:58<00:00,  2.76it/s]Evaluating: 100%|██████████| 163/163 [00:59<00:00,  2.77it/s]Evaluating: 100%|██████████| 163/163 [00:59<00:00,  2.75it/s]
05/09/2022 19:52:39 - INFO - __main__ -     Evaluation done in total 59.302463 secs (0.045477 sec per example)
05/09/2022 19:52:43 - INFO - __main__ -   Results: {'exact': 64.36974789915966, 'f1': 82.40808832747321, 'total': 1190, 'HasAns_exact': 64.36974789915966, 'HasAns_f1': 82.40808832747321, 'HasAns_total': 1190, 'best_exact': 64.36974789915966, 'best_exact_thresh': 0.0, 'best_f1': 82.40808832747321, 'best_f1_thresh': 0.0}
  de 
2022-05-09 19:52:46.846961: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0
05/09/2022 19:52:49 - WARNING - __main__ -   Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, 16-bits training: False
You are using a model of type xlm-roberta to instantiate a model of type xlm. This is not supported for all configurations of models and can yield errors.
Some weights of the model checkpoint at /cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//squad/xlm-KG_LR8e-6_EPOCH2.0_maxlen384_batchsize4_gradacc4 were not used when initializing XLMRobertaModel: ['base_model.encoder.layer.11.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.23.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.18.output.LayerNorm.bias', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.18.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.3.output.adapters.tp.adapter_down.0.bias', 'base_model.embeddings.LayerNorm.bias', 'base_model.encoder.layer.15.attention.self.query.bias', 'base_model.encoder.layer.20.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.22.attention.output.LayerNorm.bias', 'base_model.encoder.layer.23.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.1.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.1.attention.output.dense.bias', 'base_model.embeddings.LayerNorm.weight', 'base_model.encoder.layer.6.attention.self.query.weight', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.8.attention.output.dense.weight', 'base_model.encoder.layer.8.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.9.attention.self.key.weight', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.22.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.7.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.17.attention.self.value.bias', 'base_model.encoder.layer.11.intermediate.dense.weight', 'base_model.encoder.layer.21.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.1.attention.self.key.weight', 'base_model.encoder.layer.12.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.22.attention.self.value.weight', 'base_model.encoder.layer.0.output.dense.bias', 'qa_outputs.weight', 'base_model.encoder.layer.2.attention.self.query.weight', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.23.attention.self.value.weight', 'base_model.encoder.layer.6.attention.self.key.weight', 'base_model.encoder.layer.5.attention.self.query.bias', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.8.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.1.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.11.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.12.attention.output.dense.weight', 'base_model.encoder.layer.7.attention.self.key.weight', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.3.attention.self.value.bias', 'base_model.encoder.layer.14.attention.self.key.bias', 'base_model.encoder.layer.21.attention.self.key.weight', 'base_model.encoder.layer.23.attention.self.query.weight', 'base_model.encoder.layer.13.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.20.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.16.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.4.attention.output.dense.weight', 'base_model.encoder.layer.16.attention.output.dense.bias', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.4.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.19.attention.output.LayerNorm.weight', 'base_model.encoder.layer.22.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.3.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.8.intermediate.dense.bias', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.5.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.7.output.LayerNorm.bias', 'base_model.encoder.layer.7.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.14.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.21.attention.self.query.bias', 'base_model.encoder.layer.21.attention.self.key.bias', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.6.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.3.attention.self.key.bias', 'base_model.encoder.layer.3.attention.output.dense.weight', 'base_model.encoder.layer.4.attention.self.query.bias', 'base_model.encoder.layer.2.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.2.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.4.attention.self.key.bias', 'base_model.encoder.layer.7.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.8.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.10.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.13.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.23.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.14.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.8.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.5.attention.output.dense.bias', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.10.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.21.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.9.intermediate.dense.bias', 'base_model.encoder.layer.2.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.21.output.LayerNorm.bias', 'base_model.encoder.layer.21.output.adapters.tp.adapter_up.bias', 'base_model.pooler.dense.bias', 'base_model.encoder.layer.13.attention.self.query.weight', 'base_model.encoder.layer.18.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.13.attention.self.value.weight', 'base_model.encoder.layer.20.intermediate.dense.bias', 'base_model.encoder.layer.3.intermediate.dense.bias', 'base_model.encoder.layer.23.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.16.attention.self.key.weight', 'base_model.encoder.layer.15.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.23.attention.self.key.weight', 'base_model.encoder.layer.13.attention.self.key.bias', 'base_model.encoder.layer.6.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.15.attention.self.key.weight', 'base_model.encoder.layer.22.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.8.output.LayerNorm.bias', 'base_model.encoder.layer.12.output.dense.weight', 'base_model.encoder.layer.0.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.0.attention.self.query.bias', 'base_model.encoder.layer.5.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.4.attention.output.LayerNorm.weight', 'base_model.encoder.layer.2.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.9.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.11.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.17.attention.output.LayerNorm.weight', 'base_model.encoder.layer.22.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.15.attention.self.value.bias', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.23.output.LayerNorm.bias', 'base_model.encoder.layer.2.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.7.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.10.output.LayerNorm.bias', 'base_model.encoder.layer.13.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.23.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.1.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.7.attention.self.query.weight', 'base_model.encoder.layer.9.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.3.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.10.attention.self.query.bias', 'base_model.encoder.layer.3.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.14.attention.output.dense.bias', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.5.intermediate.dense.bias', 'base_model.encoder.layer.16.attention.self.query.bias', 'base_model.encoder.layer.11.attention.output.dense.bias', 'base_model.encoder.layer.13.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.1.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.18.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.23.attention.output.dense.bias', 'base_model.encoder.layer.13.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.20.attention.self.query.bias', 'base_model.encoder.layer.13.attention.output.dense.weight', 'base_model.encoder.layer.18.intermediate.dense.bias', 'base_model.encoder.layer.13.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.14.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.17.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.19.attention.output.dense.bias', 'base_model.encoder.layer.19.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.12.output.dense.bias', 'base_model.encoder.layer.16.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.22.intermediate.dense.bias', 'base_model.encoder.layer.11.attention.self.key.bias', 'base_model.encoder.layer.18.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.22.output.LayerNorm.weight', 'base_model.encoder.layer.4.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.3.attention.output.dense.bias', 'base_model.encoder.layer.3.output.dense.bias', 'base_model.encoder.layer.17.attention.output.LayerNorm.bias', 'base_model.encoder.layer.17.attention.self.key.weight', 'base_model.encoder.layer.0.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.17.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.4.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.12.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.10.intermediate.dense.weight', 'base_model.encoder.layer.8.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.12.attention.self.key.bias', 'base_model.encoder.layer.19.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.10.attention.self.value.weight', 'base_model.encoder.layer.22.attention.self.key.weight', 'base_model.encoder.layer.7.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.15.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.12.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.1.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.5.attention.output.dense.weight', 'base_model.encoder.layer.11.attention.output.LayerNorm.bias', 'base_model.encoder.layer.13.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.11.attention.self.value.bias', 'base_model.encoder.layer.4.attention.self.value.bias', 'base_model.encoder.layer.2.output.LayerNorm.weight', 'base_model.encoder.layer.19.attention.output.LayerNorm.bias', 'base_model.encoder.layer.18.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.22.attention.self.query.bias', 'base_model.encoder.layer.18.attention.output.dense.weight', 'base_model.encoder.layer.21.attention.output.dense.weight', 'base_model.encoder.layer.10.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.4.output.dense.weight', 'base_model.encoder.layer.6.attention.self.value.weight', 'base_model.encoder.layer.1.output.LayerNorm.bias', 'base_model.encoder.layer.8.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.4.attention.output.dense.bias', 'base_model.encoder.layer.23.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.11.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.23.attention.output.dense.weight', 'base_model.encoder.layer.6.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.14.output.LayerNorm.weight', 'base_model.encoder.layer.4.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.11.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.13.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.14.attention.self.value.bias', 'base_model.encoder.layer.16.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.9.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.15.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.20.attention.output.LayerNorm.bias', 'base_model.encoder.layer.2.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.12.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.11.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.9.output.dense.bias', 'base_model.encoder.layer.9.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.19.output.LayerNorm.weight', 'base_model.encoder.layer.9.attention.output.LayerNorm.weight', 'base_model.encoder.layer.17.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.11.output.LayerNorm.weight', 'base_model.encoder.layer.2.intermediate.dense.bias', 'base_model.encoder.layer.5.output.dense.weight', 'base_model.encoder.layer.19.attention.self.value.bias', 'base_model.encoder.layer.10.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.14.attention.output.LayerNorm.weight', 'base_model.encoder.layer.1.output.dense.weight', 'base_model.encoder.layer.13.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.10.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.18.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.2.attention.output.LayerNorm.weight', 'base_model.encoder.layer.9.output.dense.weight', 'base_model.encoder.layer.11.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.1.intermediate.dense.weight', 'base_model.encoder.layer.11.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.9.attention.self.query.bias', 'base_model.encoder.layer.1.output.LayerNorm.weight', 'base_model.encoder.layer.12.output.LayerNorm.weight', 'base_model.encoder.layer.7.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.23.attention.self.value.bias', 'base_model.encoder.layer.1.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.7.output.dense.weight', 'base_model.encoder.layer.7.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.11.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.5.attention.output.LayerNorm.weight', 'base_model.encoder.layer.6.attention.self.value.bias', 'base_model.encoder.layer.0.attention.self.key.bias', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.3.output.LayerNorm.bias', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.21.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.0.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.9.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.6.attention.output.LayerNorm.bias', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.16.output.LayerNorm.bias', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.1.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.0.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.15.output.LayerNorm.bias', 'base_model.encoder.layer.14.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.6.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.9.attention.output.dense.weight', 'base_model.encoder.layer.10.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.11.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.13.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.16.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.7.attention.self.value.weight', 'base_model.encoder.layer.15.intermediate.dense.weight', 'base_model.encoder.layer.17.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.21.output.dense.weight', 'base_model.encoder.layer.10.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.8.attention.self.value.bias', 'base_model.encoder.layer.21.output.dense.bias', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.4.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.1.output.dense.bias', 'base_model.embeddings.position_ids', 'base_model.encoder.layer.21.attention.output.dense.bias', 'base_model.encoder.layer.20.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.15.attention.output.dense.bias', 'base_model.encoder.layer.13.output.dense.weight', 'base_model.encoder.layer.9.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.5.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.11.attention.output.LayerNorm.weight', 'base_model.encoder.layer.19.intermediate.dense.weight', 'base_model.encoder.layer.23.output.dense.bias', 'base_model.encoder.layer.6.output.dense.weight', 'base_model.encoder.layer.17.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.19.attention.output.dense.weight', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.21.output.LayerNorm.weight', 'base_model.encoder.layer.12.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.10.attention.self.query.weight', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.0.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.14.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.15.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.15.attention.self.key.bias', 'base_model.encoder.layer.2.attention.output.dense.bias', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.21.attention.self.value.weight', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.7.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.14.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.16.attention.self.value.weight', 'base_model.encoder.layer.1.attention.output.LayerNorm.bias', 'base_model.encoder.layer.19.output.LayerNorm.bias', 'base_model.encoder.layer.5.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.12.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.12.attention.self.query.bias', 'base_model.encoder.layer.2.attention.output.dense.weight', 'base_model.encoder.layer.4.attention.self.key.weight', 'base_model.encoder.layer.20.output.dense.bias', 'base_model.encoder.layer.23.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.23.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.20.output.LayerNorm.bias', 'base_model.encoder.layer.17.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.13.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.7.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.12.attention.self.query.weight', 'base_model.encoder.layer.15.attention.self.query.weight', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.15.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.18.output.dense.weight', 'base_model.encoder.layer.18.attention.self.key.weight', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.11.output.LayerNorm.bias', 'base_model.encoder.layer.14.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.19.attention.self.value.weight', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.17.attention.self.value.weight', 'base_model.encoder.layer.20.intermediate.dense.weight', 'base_model.encoder.layer.1.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.23.output.LayerNorm.weight', 'base_model.encoder.layer.6.attention.output.dense.bias', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.9.attention.output.LayerNorm.bias', 'base_model.encoder.layer.12.attention.output.LayerNorm.weight', 'base_model.encoder.layer.13.intermediate.dense.weight', 'base_model.encoder.layer.14.attention.output.dense.weight', 'base_model.encoder.layer.10.attention.output.LayerNorm.bias', 'base_model.encoder.layer.6.intermediate.dense.weight', 'base_model.encoder.layer.22.attention.output.dense.weight', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.0.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.20.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.0.intermediate.dense.weight', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.4.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.20.attention.output.LayerNorm.weight', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.19.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.12.output.LayerNorm.bias', 'base_model.encoder.layer.17.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.23.attention.self.query.bias', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.1.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.5.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.2.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.10.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.11.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.22.output.dense.bias', 'base_model.encoder.layer.10.attention.output.dense.bias', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.7.attention.output.dense.weight', 'base_model.encoder.layer.2.output.LayerNorm.bias', 'base_model.encoder.layer.7.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.16.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.10.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.21.attention.output.LayerNorm.weight', 'base_model.encoder.layer.21.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.2.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.0.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.20.attention.output.dense.bias', 'base_model.encoder.layer.13.output.LayerNorm.weight', 'base_model.encoder.layer.4.intermediate.dense.weight', 'base_model.encoder.layer.15.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.16.output.dense.weight', 'base_model.encoder.layer.6.attention.self.key.bias', 'base_model.encoder.layer.19.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.16.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.7.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.15.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.5.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.18.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.1.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.10.intermediate.dense.bias', 'base_model.encoder.layer.2.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.7.attention.output.LayerNorm.weight', 'base_model.encoder.layer.1.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.3.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.14.attention.self.value.weight', 'base_model.encoder.layer.16.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.20.attention.output.dense.weight', 'base_model.encoder.layer.20.attention.self.key.weight', 'base_model.encoder.layer.15.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.15.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.16.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.3.output.LayerNorm.weight', 'base_model.encoder.layer.6.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.9.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.14.intermediate.dense.bias', 'base_model.encoder.layer.0.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.3.intermediate.dense.weight', 'base_model.encoder.layer.11.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.6.attention.output.dense.weight', 'base_model.encoder.layer.1.attention.output.LayerNorm.weight', 'base_model.encoder.layer.5.attention.self.query.weight', 'base_model.encoder.layer.2.output.dense.weight', 'base_model.encoder.layer.3.attention.self.key.weight', 'base_model.encoder.layer.11.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.6.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.12.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.20.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.5.intermediate.dense.weight', 'base_model.encoder.layer.10.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.14.output.dense.bias', 'base_model.encoder.layer.15.output.dense.weight', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.8.attention.self.value.weight', 'base_model.encoder.layer.21.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.0.output.LayerNorm.weight', 'base_model.encoder.layer.6.output.LayerNorm.weight', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.11.attention.self.query.bias', 'base_model.encoder.layer.14.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.7.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.12.attention.output.LayerNorm.bias', 'base_model.encoder.layer.19.attention.self.key.bias', 'base_model.encoder.layer.3.attention.self.value.weight', 'base_model.encoder.layer.21.attention.self.value.bias', 'base_model.encoder.layer.1.attention.output.dense.weight', 'base_model.encoder.layer.5.output.LayerNorm.bias', 'base_model.encoder.layer.15.output.LayerNorm.weight', 'base_model.encoder.layer.6.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.17.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.13.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.20.attention.self.value.bias', 'base_model.encoder.layer.13.attention.self.key.weight', 'base_model.encoder.layer.20.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.22.attention.self.key.bias', 'base_model.encoder.layer.23.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.2.output.dense.bias', 'base_model.encoder.layer.6.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.0.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.3.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.4.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.10.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.14.intermediate.dense.weight', 'base_model.encoder.layer.3.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.22.attention.output.LayerNorm.weight', 'base_model.encoder.layer.5.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.14.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.21.intermediate.dense.bias', 'base_model.encoder.layer.8.attention.self.key.bias', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.23.output.dense.weight', 'base_model.encoder.layer.10.attention.self.value.bias', 'base_model.encoder.layer.18.output.LayerNorm.weight', 'base_model.encoder.layer.21.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.1.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.1.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.3.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.18.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.10.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.17.attention.self.key.bias', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.18.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.22.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.22.attention.output.dense.bias', 'base_model.encoder.layer.17.attention.output.dense.bias', 'base_model.encoder.layer.11.attention.output.dense.weight', 'base_model.encoder.layer.22.attention.self.query.weight', 'base_model.encoder.layer.13.intermediate.dense.bias', 'base_model.encoder.layer.1.attention.self.value.bias', 'base_model.encoder.layer.19.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.12.attention.self.key.weight', 'base_model.encoder.layer.13.attention.output.LayerNorm.bias', 'base_model.encoder.layer.0.output.LayerNorm.bias', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.17.intermediate.dense.bias', 'base_model.encoder.layer.17.output.dense.bias', 'base_model.encoder.layer.18.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.6.intermediate.dense.bias', 'base_model.encoder.layer.21.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.8.attention.self.key.weight', 'base_model.encoder.layer.7.intermediate.dense.bias', 'base_model.encoder.layer.9.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.10.output.dense.weight', 'base_model.encoder.layer.11.attention.self.query.weight', 'base_model.encoder.layer.17.attention.output.dense.weight', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.5.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.18.attention.output.dense.bias', 'base_model.encoder.layer.17.output.LayerNorm.bias', 'base_model.encoder.layer.21.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.2.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.8.attention.output.LayerNorm.bias', 'base_model.encoder.layer.10.attention.output.dense.weight', 'base_model.encoder.layer.23.intermediate.dense.bias', 'base_model.encoder.layer.21.attention.output.LayerNorm.bias', 'base_model.encoder.layer.4.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.16.attention.self.query.weight', 'base_model.encoder.layer.0.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.0.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.4.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.10.output.dense.bias', 'base_model.encoder.layer.11.attention.self.value.weight', 'base_model.encoder.layer.17.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.7.attention.self.key.bias', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.21.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.2.intermediate.dense.weight', 'base_model.encoder.layer.6.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.7.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.14.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.18.attention.output.LayerNorm.weight', 'base_model.encoder.layer.11.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.5.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.19.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.2.attention.self.key.bias', 'base_model.encoder.layer.8.attention.output.LayerNorm.weight', 'base_model.encoder.layer.20.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.19.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.8.attention.self.query.bias', 'base_model.encoder.layer.2.attention.self.query.bias', 'base_model.embeddings.position_embeddings.weight', 'base_model.encoder.layer.6.output.dense.bias', 'base_model.encoder.layer.20.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.9.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.9.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.17.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.10.attention.self.key.weight', 'base_model.encoder.layer.19.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.3.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.3.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.0.attention.self.value.weight', 'base_model.encoder.layer.4.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.1.attention.self.value.weight', 'base_model.encoder.layer.2.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.18.attention.self.query.bias', 'base_model.encoder.layer.5.output.dense.bias', 'base_model.encoder.layer.6.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.11.intermediate.dense.bias', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.8.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.11.attention.self.key.weight', 'base_model.encoder.layer.23.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.0.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.10.attention.self.key.bias', 'base_model.encoder.layer.23.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.16.intermediate.dense.weight', 'base_model.encoder.layer.14.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.1.attention.self.query.weight', 'base_model.encoder.layer.18.attention.output.LayerNorm.bias', 'base_model.encoder.layer.19.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.8.output.dense.bias', 'base_model.encoder.layer.8.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.22.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.17.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.5.attention.self.value.weight', 'base_model.encoder.layer.1.attention.self.query.bias', 'base_model.encoder.layer.9.attention.self.key.bias', 'base_model.encoder.layer.1.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.16.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.8.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.9.attention.self.value.weight', 'base_model.encoder.layer.0.intermediate.dense.bias', 'base_model.encoder.layer.11.output.dense.bias', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.22.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.2.attention.self.value.weight', 'base_model.encoder.layer.4.intermediate.dense.bias', 'base_model.encoder.layer.3.attention.output.LayerNorm.weight', 'base_model.encoder.layer.18.attention.self.value.weight', 'base_model.encoder.layer.10.output.LayerNorm.weight', 'base_model.encoder.layer.1.intermediate.dense.bias', 'base_model.encoder.layer.13.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.19.attention.self.query.bias', 'base_model.encoder.layer.9.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.17.output.dense.weight', 'base_model.encoder.layer.0.attention.output.dense.weight', 'base_model.encoder.layer.5.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.18.attention.self.key.bias', 'base_model.encoder.layer.4.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.22.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.1.attention.self.key.bias', 'base_model.encoder.layer.15.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.9.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.8.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.22.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.8.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.13.output.dense.bias', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.4.attention.self.query.weight', 'base_model.encoder.layer.9.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.10.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.14.output.dense.weight', 'base_model.encoder.layer.15.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.16.attention.output.dense.weight', 'base_model.encoder.layer.20.attention.self.key.bias', 'base_model.encoder.layer.12.attention.output.dense.bias', 'base_model.encoder.layer.3.output.adapters.es.adapter_up.weight', 'base_model.pooler.dense.weight', 'base_model.encoder.layer.3.attention.self.query.weight', 'base_model.encoder.layer.21.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.embeddings.word_embeddings.weight', 'base_model.encoder.layer.8.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.5.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.20.output.LayerNorm.weight', 'base_model.encoder.layer.22.output.dense.weight', 'base_model.encoder.layer.6.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.19.attention.self.query.weight', 'base_model.encoder.layer.0.attention.self.query.weight', 'base_model.encoder.layer.7.attention.self.query.bias', 'base_model.encoder.layer.13.attention.output.dense.bias', 'base_model.encoder.layer.15.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.4.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.0.output.dense.weight', 'base_model.encoder.layer.22.output.LayerNorm.bias', 'base_model.encoder.layer.19.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.19.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.20.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.3.attention.self.query.bias', 'base_model.encoder.layer.12.attention.self.value.bias', 'base_model.encoder.layer.0.attention.output.LayerNorm.weight', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.5.attention.self.key.bias', 'base_model.encoder.layer.11.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.22.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.4.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.5.attention.self.key.weight', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.21.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.17.attention.self.query.bias', 'base_model.encoder.layer.16.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.9.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.17.output.LayerNorm.weight', 'base_model.encoder.layer.7.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.5.attention.output.LayerNorm.bias', 'base_model.encoder.layer.23.intermediate.dense.weight', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.22.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.2.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.23.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.4.output.LayerNorm.weight', 'base_model.encoder.layer.22.attention.self.value.bias', 'base_model.encoder.layer.8.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.17.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.5.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.20.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.22.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.2.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.10.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.14.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.5.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.15.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.9.intermediate.dense.weight', 'base_model.encoder.layer.10.attention.output.LayerNorm.weight', 'base_model.encoder.layer.18.output.dense.bias', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.6.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.23.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.9.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.20.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.15.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.6.attention.self.query.bias', 'base_model.encoder.layer.12.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.19.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.20.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.0.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.9.attention.output.dense.bias', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.20.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.8.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.3.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.6.attention.output.LayerNorm.weight', 'base_model.encoder.layer.6.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.4.attention.self.value.weight', 'base_model.encoder.layer.4.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.13.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.10.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.20.attention.self.query.weight', 'base_model.encoder.layer.22.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.1.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.23.attention.self.key.bias', 'base_model.encoder.layer.18.attention.self.value.bias', 'base_model.encoder.layer.17.intermediate.dense.weight', 'base_model.encoder.layer.12.intermediate.dense.weight', 'base_model.encoder.layer.18.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.19.output.dense.bias', 'base_model.encoder.layer.22.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.15.attention.self.value.weight', 'base_model.encoder.layer.2.attention.output.LayerNorm.bias', 'base_model.encoder.layer.13.attention.output.LayerNorm.weight', 'base_model.encoder.layer.14.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.19.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.14.output.LayerNorm.bias', 'base_model.encoder.layer.19.attention.self.key.weight', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.12.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.0.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.15.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.18.intermediate.dense.weight', 'base_model.encoder.layer.4.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.19.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.12.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.5.output.LayerNorm.weight', 'base_model.encoder.layer.17.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.15.attention.output.LayerNorm.bias', 'base_model.encoder.layer.19.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.7.output.dense.bias', 'base_model.encoder.layer.15.intermediate.dense.bias', 'base_model.encoder.layer.20.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.23.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.0.attention.output.LayerNorm.bias', 'base_model.encoder.layer.8.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.1.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.3.attention.output.LayerNorm.bias', 'base_model.encoder.layer.5.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.12.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.21.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.14.attention.self.key.weight', 'base_model.encoder.layer.0.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.12.attention.self.value.weight', 'base_model.encoder.layer.0.attention.output.dense.bias', 'base_model.encoder.layer.10.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.16.intermediate.dense.bias', 'base_model.encoder.layer.20.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.3.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.4.output.dense.bias', 'base_model.encoder.layer.3.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.6.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.9.output.LayerNorm.bias', 'base_model.encoder.layer.23.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.8.attention.output.dense.bias', 'base_model.encoder.layer.12.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.13.attention.self.query.bias', 'base_model.encoder.layer.18.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.21.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.16.attention.self.value.bias', 'base_model.encoder.layer.23.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.22.intermediate.dense.weight', 'base_model.encoder.layer.3.output.dense.weight', 'base_model.encoder.layer.16.attention.self.key.bias', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.14.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.5.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.5.attention.self.value.bias', 'base_model.encoder.layer.3.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.19.output.dense.weight', 'base_model.encoder.layer.7.attention.output.dense.bias', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.14.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.embeddings.token_type_embeddings.weight', 'base_model.encoder.layer.9.attention.self.value.bias', 'base_model.encoder.layer.16.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.7.intermediate.dense.weight', 'base_model.encoder.layer.15.attention.output.dense.weight', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.12.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.13.output.LayerNorm.bias', 'base_model.encoder.layer.9.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.20.attention.self.value.weight', 'base_model.encoder.layer.2.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.21.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.8.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.2.attention.self.value.bias', 'base_model.encoder.layer.16.output.dense.bias', 'base_model.encoder.layer.7.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.22.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.21.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.14.attention.self.query.weight', 'base_model.encoder.layer.16.attention.output.LayerNorm.bias', 'base_model.encoder.layer.16.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.20.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.16.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.14.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.12.intermediate.dense.bias', 'base_model.encoder.layer.20.output.dense.weight', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.8.intermediate.dense.weight', 'base_model.encoder.layer.6.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.7.attention.self.value.bias', 'base_model.encoder.layer.8.output.LayerNorm.weight', 'base_model.encoder.layer.2.attention.self.key.weight', 'base_model.encoder.layer.23.attention.output.LayerNorm.bias', 'base_model.encoder.layer.21.intermediate.dense.weight', 'base_model.encoder.layer.2.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'qa_outputs.bias', 'base_model.encoder.layer.4.output.LayerNorm.bias', 'base_model.encoder.layer.9.output.LayerNorm.weight', 'base_model.encoder.layer.12.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.15.output.dense.bias', 'base_model.encoder.layer.18.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.4.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.18.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.12.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.18.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.8.output.dense.weight', 'base_model.encoder.layer.15.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.16.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.17.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.7.attention.output.LayerNorm.bias', 'base_model.encoder.layer.15.attention.output.LayerNorm.weight', 'base_model.encoder.layer.16.output.LayerNorm.weight', 'base_model.encoder.layer.14.attention.self.query.bias', 'base_model.encoder.layer.14.attention.output.LayerNorm.bias', 'base_model.encoder.layer.4.attention.output.LayerNorm.bias', 'base_model.encoder.layer.17.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.17.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.0.attention.self.value.bias', 'base_model.encoder.layer.13.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.18.attention.self.query.weight', 'base_model.encoder.layer.13.attention.self.value.bias', 'base_model.encoder.layer.17.attention.self.query.weight', 'base_model.encoder.layer.7.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.16.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.11.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.3.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.18.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.22.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.16.attention.output.LayerNorm.weight', 'base_model.encoder.layer.7.output.LayerNorm.weight', 'base_model.encoder.layer.12.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.16.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.0.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.5.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.23.attention.output.LayerNorm.weight', 'base_model.encoder.layer.0.attention.self.key.weight', 'base_model.encoder.layer.2.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.9.attention.self.query.weight', 'base_model.encoder.layer.8.attention.self.query.weight', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.19.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.11.output.dense.weight', 'base_model.encoder.layer.19.intermediate.dense.bias', 'base_model.encoder.layer.21.attention.self.query.weight', 'base_model.encoder.layer.13.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.6.output.LayerNorm.bias', 'base_model.encoder.layer.6.output.adapters.ep.adapter_down.0.bias']
- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of XLMRobertaModel were not initialized from the model checkpoint at /cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//squad/xlm-KG_LR8e-6_EPOCH2.0_maxlen384_batchsize4_gradacc4 and are newly initialized: ['encoder.layer.23.attention.output.dense.weight', 'encoder.layer.1.attention.output.dense.bias', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.19.attention.output.dense.bias', 'encoder.layer.6.output.LayerNorm.bias', 'encoder.layer.10.attention.self.value.bias', 'encoder.layer.23.attention.output.LayerNorm.weight', 'encoder.layer.22.intermediate.dense.bias', 'encoder.layer.13.output.dense.bias', 'encoder.layer.10.attention.self.key.weight', 'encoder.layer.9.attention.self.query.bias', 'encoder.layer.12.attention.self.key.bias', 'encoder.layer.4.output.dense.bias', 'encoder.layer.3.attention.self.value.weight', 'encoder.layer.9.attention.self.key.weight', 'encoder.layer.9.attention.output.dense.weight', 'encoder.layer.7.attention.self.key.weight', 'encoder.layer.13.output.LayerNorm.weight', 'encoder.layer.10.attention.output.LayerNorm.bias', 'encoder.layer.16.intermediate.dense.weight', 'encoder.layer.21.output.LayerNorm.weight', 'encoder.layer.17.attention.output.LayerNorm.weight', 'encoder.layer.21.output.LayerNorm.bias', 'encoder.layer.12.output.dense.weight', 'encoder.layer.17.output.LayerNorm.bias', 'encoder.layer.21.attention.self.key.bias', 'encoder.layer.13.attention.output.LayerNorm.bias', 'encoder.layer.0.output.dense.weight', 'encoder.layer.8.attention.self.query.bias', 'encoder.layer.18.attention.self.key.bias', 'encoder.layer.5.attention.self.value.bias', 'encoder.layer.7.attention.output.LayerNorm.bias', 'encoder.layer.14.output.LayerNorm.weight', 'encoder.layer.15.output.dense.bias', 'encoder.layer.1.attention.self.key.weight', 'encoder.layer.21.attention.self.query.weight', 'encoder.layer.19.attention.output.LayerNorm.weight', 'encoder.layer.1.attention.self.query.bias', 'encoder.layer.14.attention.self.value.bias', 'encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.layer.1.attention.self.value.weight', 'encoder.layer.20.intermediate.dense.bias', 'encoder.layer.12.intermediate.dense.weight', 'encoder.layer.22.output.dense.weight', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.17.attention.self.key.bias', 'encoder.layer.14.intermediate.dense.weight', 'encoder.layer.10.attention.output.LayerNorm.weight', 'encoder.layer.6.attention.output.dense.weight', 'encoder.layer.15.attention.self.value.bias', 'encoder.layer.18.output.dense.weight', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.12.attention.output.dense.bias', 'encoder.layer.22.attention.self.key.weight', 'encoder.layer.13.output.LayerNorm.bias', 'encoder.layer.12.output.LayerNorm.weight', 'encoder.layer.11.output.LayerNorm.bias', 'encoder.layer.9.output.LayerNorm.bias', 'encoder.layer.5.output.dense.weight', 'encoder.layer.4.attention.output.dense.weight', 'encoder.layer.20.output.LayerNorm.weight', 'encoder.layer.23.attention.self.value.bias', 'encoder.layer.15.attention.self.query.weight', 'encoder.layer.7.output.LayerNorm.bias', 'encoder.layer.3.attention.self.query.weight', 'encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.layer.1.attention.output.LayerNorm.weight', 'encoder.layer.17.attention.output.dense.weight', 'encoder.layer.3.attention.self.query.bias', 'encoder.layer.11.attention.output.LayerNorm.weight', 'encoder.layer.18.attention.output.LayerNorm.weight', 'encoder.layer.2.output.dense.weight', 'encoder.layer.4.attention.self.value.bias', 'encoder.layer.22.attention.output.dense.bias', 'encoder.layer.12.attention.output.LayerNorm.weight', 'encoder.layer.12.attention.output.dense.weight', 'encoder.layer.5.output.dense.bias', 'encoder.layer.22.attention.self.query.bias', 'encoder.layer.20.attention.self.value.weight', 'encoder.layer.12.output.dense.bias', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.2.attention.output.LayerNorm.weight', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.19.output.dense.bias', 'encoder.layer.11.attention.self.query.weight', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.10.attention.output.dense.weight', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.5.attention.self.value.weight', 'encoder.layer.11.attention.self.value.bias', 'encoder.layer.15.intermediate.dense.bias', 'encoder.layer.8.attention.output.LayerNorm.bias', 'encoder.layer.20.attention.self.value.bias', 'encoder.layer.3.attention.output.dense.bias', 'encoder.layer.4.attention.self.value.weight', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.16.attention.self.value.bias', 'encoder.layer.10.attention.self.value.weight', 'encoder.layer.4.attention.output.LayerNorm.bias', 'encoder.layer.13.attention.output.LayerNorm.weight', 'encoder.layer.18.intermediate.dense.weight', 'encoder.layer.9.attention.output.LayerNorm.bias', 'encoder.layer.19.attention.self.query.weight', 'encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.layer.10.output.dense.weight', 'encoder.layer.16.intermediate.dense.bias', 'encoder.layer.10.intermediate.dense.weight', 'encoder.layer.16.attention.self.value.weight', 'encoder.layer.10.output.dense.bias', 'encoder.layer.0.attention.self.query.bias', 'encoder.layer.19.attention.self.value.bias', 'encoder.layer.14.attention.self.key.bias', 'encoder.layer.14.attention.self.query.weight', 'encoder.layer.19.intermediate.dense.bias', 'encoder.layer.8.attention.output.dense.weight', 'encoder.layer.7.output.dense.bias', 'encoder.layer.19.output.LayerNorm.bias', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.13.attention.self.query.weight', 'encoder.layer.21.output.dense.weight', 'encoder.layer.15.output.LayerNorm.bias', 'encoder.layer.21.attention.output.dense.weight', 'encoder.layer.8.output.dense.bias', 'encoder.layer.20.attention.output.dense.bias', 'encoder.layer.13.attention.self.value.weight', 'encoder.layer.20.output.dense.weight', 'encoder.layer.19.attention.self.key.bias', 'encoder.layer.23.output.dense.bias', 'encoder.layer.18.attention.self.value.bias', 'encoder.layer.23.intermediate.dense.bias', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.9.attention.self.key.bias', 'encoder.layer.9.attention.output.dense.bias', 'encoder.layer.1.output.dense.bias', 'encoder.layer.5.attention.output.dense.weight', 'encoder.layer.17.attention.output.dense.bias', 'encoder.layer.18.intermediate.dense.bias', 'encoder.layer.11.attention.self.key.weight', 'encoder.layer.10.attention.output.dense.bias', 'encoder.layer.14.attention.output.LayerNorm.weight', 'embeddings.LayerNorm.weight', 'encoder.layer.7.attention.output.dense.weight', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.12.attention.self.query.weight', 'encoder.layer.9.attention.self.query.weight', 'encoder.layer.4.attention.output.LayerNorm.weight', 'encoder.layer.17.attention.self.query.bias', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.8.output.LayerNorm.weight', 'encoder.layer.20.attention.output.dense.weight', 'encoder.layer.21.intermediate.dense.weight', 'encoder.layer.2.attention.output.dense.weight', 'encoder.layer.16.output.LayerNorm.weight', 'encoder.layer.12.attention.self.value.bias', 'encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.layer.8.attention.self.query.weight', 'encoder.layer.15.attention.self.key.weight', 'encoder.layer.17.intermediate.dense.weight', 'encoder.layer.10.attention.self.query.bias', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.11.attention.self.value.weight', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.14.output.dense.bias', 'encoder.layer.13.output.dense.weight', 'encoder.layer.17.attention.self.key.weight', 'encoder.layer.3.attention.self.key.bias', 'encoder.layer.0.attention.output.dense.weight', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.8.attention.self.value.bias', 'encoder.layer.12.attention.output.LayerNorm.bias', 'encoder.layer.12.attention.self.query.bias', 'encoder.layer.18.attention.output.LayerNorm.bias', 'embeddings.token_type_embeddings.weight', 'encoder.layer.6.attention.self.key.weight', 'encoder.layer.23.output.dense.weight', 'encoder.layer.4.attention.self.query.bias', 'encoder.layer.16.attention.output.LayerNorm.weight', 'encoder.layer.5.attention.output.dense.bias', 'encoder.layer.11.output.dense.bias', 'encoder.layer.17.output.dense.weight', 'encoder.layer.1.attention.self.value.bias', 'encoder.layer.6.attention.output.LayerNorm.weight', 'encoder.layer.6.output.dense.weight', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.14.attention.output.dense.weight', 'encoder.layer.19.attention.self.query.bias', 'encoder.layer.2.attention.self.value.bias', 'encoder.layer.6.attention.self.value.bias', 'encoder.layer.13.attention.self.key.bias', 'encoder.layer.14.output.dense.weight', 'embeddings.position_embeddings.weight', 'encoder.layer.16.attention.self.query.bias', 'encoder.layer.16.attention.self.query.weight', 'encoder.layer.8.attention.self.key.bias', 'encoder.layer.18.output.LayerNorm.bias', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.19.intermediate.dense.weight', 'encoder.layer.2.attention.self.query.bias', 'encoder.layer.10.attention.self.query.weight', 'encoder.layer.1.attention.self.query.weight', 'encoder.layer.16.output.LayerNorm.bias', 'encoder.layer.8.attention.self.key.weight', 'encoder.layer.17.intermediate.dense.bias', 'encoder.layer.0.attention.self.key.bias', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.23.attention.self.value.weight', 'encoder.layer.6.attention.self.query.bias', 'encoder.layer.20.output.dense.bias', 'pooler.dense.bias', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.2.output.dense.bias', 'encoder.layer.0.output.dense.bias', 'encoder.layer.17.attention.output.LayerNorm.bias', 'encoder.layer.5.attention.output.LayerNorm.weight', 'encoder.layer.4.attention.self.key.weight', 'encoder.layer.16.attention.output.dense.bias', 'encoder.layer.2.attention.output.dense.bias', 'encoder.layer.15.output.LayerNorm.weight', 'encoder.layer.7.attention.self.query.weight', 'encoder.layer.7.attention.self.key.bias', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.12.output.LayerNorm.bias', 'encoder.layer.3.attention.self.value.bias', 'encoder.layer.23.attention.self.query.bias', 'encoder.layer.8.attention.self.value.weight', 'encoder.layer.7.attention.self.value.bias', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.16.attention.output.dense.weight', 'encoder.layer.21.intermediate.dense.bias', 'encoder.layer.6.attention.self.value.weight', 'encoder.layer.14.intermediate.dense.bias', 'encoder.layer.15.attention.output.dense.weight', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.2.attention.self.value.weight', 'encoder.layer.23.attention.self.query.weight', 'encoder.layer.20.attention.self.query.weight', 'encoder.layer.12.intermediate.dense.bias', 'encoder.layer.15.attention.output.dense.bias', 'encoder.layer.13.attention.output.dense.weight', 'encoder.layer.22.attention.self.query.weight', 'encoder.layer.1.output.dense.weight', 'encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.6.attention.self.query.weight', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.15.attention.output.LayerNorm.weight', 'encoder.layer.5.output.LayerNorm.bias', 'encoder.layer.16.output.dense.bias', 'encoder.layer.22.attention.self.value.bias', 'encoder.layer.23.intermediate.dense.weight', 'encoder.layer.22.output.LayerNorm.bias', 'encoder.layer.21.attention.self.value.weight', 'encoder.layer.14.attention.output.dense.bias', 'encoder.layer.19.attention.output.LayerNorm.bias', 'encoder.layer.8.output.dense.weight', 'encoder.layer.22.attention.self.key.bias', 'encoder.layer.11.attention.output.dense.bias', 'encoder.layer.6.attention.output.LayerNorm.bias', 'encoder.layer.14.attention.self.key.weight', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.layer.5.attention.self.key.bias', 'encoder.layer.14.attention.self.query.bias', 'encoder.layer.0.attention.self.key.weight', 'encoder.layer.21.attention.self.key.weight', 'encoder.layer.0.attention.self.value.bias', 'encoder.layer.11.output.LayerNorm.weight', 'encoder.layer.0.attention.output.LayerNorm.weight', 'encoder.layer.3.attention.self.key.weight', 'encoder.layer.3.output.dense.weight', 'encoder.layer.19.attention.self.key.weight', 'encoder.layer.5.attention.self.key.weight', 'encoder.layer.7.attention.output.LayerNorm.weight', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.11.attention.output.dense.weight', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.4.attention.self.query.weight', 'encoder.layer.5.attention.self.query.bias', 'encoder.layer.19.output.dense.weight', 'encoder.layer.9.output.dense.weight', 'encoder.layer.9.output.dense.bias', 'encoder.layer.7.intermediate.dense.bias', 'encoder.layer.22.attention.output.LayerNorm.weight', 'encoder.layer.15.attention.self.query.bias', 'pooler.dense.weight', 'encoder.layer.4.attention.output.dense.bias', 'encoder.layer.19.attention.output.dense.weight', 'encoder.layer.10.attention.self.key.bias', 'embeddings.word_embeddings.weight', 'encoder.layer.5.attention.self.query.weight', 'encoder.layer.7.attention.self.value.weight', 'encoder.layer.2.attention.self.key.weight', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.15.attention.self.value.weight', 'encoder.layer.13.attention.self.value.bias', 'encoder.layer.20.intermediate.dense.weight', 'encoder.layer.12.attention.self.value.weight', 'encoder.layer.10.output.LayerNorm.weight', 'encoder.layer.13.intermediate.dense.weight', 'encoder.layer.18.attention.self.key.weight', 'encoder.layer.15.output.dense.weight', 'encoder.layer.22.intermediate.dense.weight', 'encoder.layer.4.attention.self.key.bias', 'encoder.layer.2.attention.output.LayerNorm.bias', 'encoder.layer.6.attention.self.key.bias', 'encoder.layer.13.attention.self.query.bias', 'encoder.layer.10.output.LayerNorm.bias', 'encoder.layer.13.intermediate.dense.bias', 'encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.21.attention.output.LayerNorm.bias', 'encoder.layer.0.attention.self.value.weight', 'encoder.layer.7.attention.output.dense.bias', 'encoder.layer.15.attention.output.LayerNorm.bias', 'encoder.layer.0.attention.output.dense.bias', 'encoder.layer.18.attention.output.dense.weight', 'encoder.layer.1.attention.output.dense.weight', 'encoder.layer.11.attention.self.key.bias', 'encoder.layer.21.attention.output.dense.bias', 'encoder.layer.18.attention.self.query.bias', 'encoder.layer.16.attention.output.LayerNorm.bias', 'encoder.layer.17.output.LayerNorm.weight', 'encoder.layer.9.attention.self.value.bias', 'embeddings.LayerNorm.bias', 'encoder.layer.6.output.dense.bias', 'encoder.layer.20.attention.self.key.weight', 'encoder.layer.7.output.LayerNorm.weight', 'encoder.layer.18.attention.self.query.weight', 'encoder.layer.22.attention.output.dense.weight', 'encoder.layer.20.attention.output.LayerNorm.bias', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.14.output.LayerNorm.bias', 'encoder.layer.9.attention.self.value.weight', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.18.attention.output.dense.bias', 'encoder.layer.7.output.dense.weight', 'encoder.layer.15.attention.self.key.bias', 'encoder.layer.17.attention.self.query.weight', 'encoder.layer.11.output.dense.weight', 'encoder.layer.23.attention.self.key.weight', 'encoder.layer.22.output.dense.bias', 'encoder.layer.18.attention.self.value.weight', 'encoder.layer.16.attention.self.key.bias', 'encoder.layer.8.attention.output.dense.bias', 'encoder.layer.14.attention.output.LayerNorm.bias', 'encoder.layer.4.output.dense.weight', 'encoder.layer.3.attention.output.dense.weight', 'encoder.layer.18.output.LayerNorm.weight', 'encoder.layer.8.attention.output.LayerNorm.weight', 'encoder.layer.20.attention.output.LayerNorm.weight', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.1.attention.self.key.bias', 'encoder.layer.16.output.dense.weight', 'encoder.layer.0.attention.self.query.weight', 'encoder.layer.21.attention.self.value.bias', 'encoder.layer.20.attention.self.key.bias', 'encoder.layer.21.attention.output.LayerNorm.weight', 'encoder.layer.9.output.LayerNorm.weight', 'encoder.layer.17.attention.self.value.bias', 'encoder.layer.22.attention.output.LayerNorm.bias', 'encoder.layer.11.attention.self.query.bias', 'encoder.layer.22.output.LayerNorm.weight', 'encoder.layer.21.attention.self.query.bias', 'encoder.layer.14.attention.self.value.weight', 'encoder.layer.15.intermediate.dense.weight', 'encoder.layer.7.attention.self.query.bias', 'encoder.layer.20.attention.self.query.bias', 'encoder.layer.13.attention.output.dense.bias', 'encoder.layer.17.attention.self.value.weight', 'encoder.layer.23.attention.output.LayerNorm.bias', 'encoder.layer.23.output.LayerNorm.bias', 'encoder.layer.6.attention.output.dense.bias', 'encoder.layer.22.attention.self.value.weight', 'encoder.layer.16.attention.self.key.weight', 'encoder.layer.23.attention.self.key.bias', 'encoder.layer.12.attention.self.key.weight', 'encoder.layer.2.attention.self.query.weight', 'encoder.layer.2.attention.self.key.bias', 'encoder.layer.13.attention.self.key.weight', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.20.output.LayerNorm.bias', 'encoder.layer.8.output.LayerNorm.bias', 'encoder.layer.18.output.dense.bias', 'encoder.layer.3.output.dense.bias', 'encoder.layer.9.attention.output.LayerNorm.weight', 'encoder.layer.19.output.LayerNorm.weight', 'encoder.layer.19.attention.self.value.weight', 'encoder.layer.23.output.LayerNorm.weight', 'encoder.layer.23.attention.output.dense.bias', 'encoder.layer.17.output.dense.bias', 'encoder.layer.21.output.dense.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Overwriting existing adapter 'ep'.
Overwriting existing adapter 'tp'.
Overwriting existing adapter 'es'.
Overwriting existing adapter 'ts'.
Overwriting existing adapter fusion module 'ep,tp,es,ts'
05/09/2022 19:53:25 - INFO - __main__ -   lang2id = None
05/09/2022 19:53:28 - INFO - __main__ -   Training/evaluation parameters Namespace(adam_epsilon=1e-08, cache_dir='', config_name='', data_dir=None, device=device(type='cuda'), do_eval=True, do_lower_case=False, do_train=False, doc_stride=128, eval_all_checkpoints=False, eval_lang='de', evaluate_during_training=False, fp16=False, fp16_opt_level='O1', gradient_accumulation_steps=1, learning_rate=5e-05, local_rank=-1, logging_steps=50, max_answer_length=30, max_grad_norm=1.0, max_query_length=64, max_seq_length=384, max_steps=-1, model_name='xlm-KG', model_name_or_path='/cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//squad/xlm-KG_LR8e-6_EPOCH2.0_maxlen384_batchsize4_gradacc4', model_type='xlm', modelkg_dir='/cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/adapter/xlmr_adapter', n_best_size=20, n_gpu=1, no_cuda=False, null_score_diff_threshold=0.0, num_train_epochs=3.0, output_dir='/cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//squad/xlm-KG_LR8e-6_EPOCH2.0_maxlen384_batchsize4_gradacc4/predictions/xquad/', overwrite_cache=False, overwrite_output_dir=False, per_gpu_eval_batch_size=8, per_gpu_train_batch_size=8, predict_file='/cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/download//xquad//xquad.de.json', save_steps=50, seed=42, server_ip='', server_port='', threads=1, tokenizer_name='', train_file=None, train_lang='en', verbose_logging=False, version_2_with_negative=False, warmup_steps=0, weight_decay=0.0)
05/09/2022 19:53:28 - INFO - __main__ -   Loading checkpoint /cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//squad/xlm-KG_LR8e-6_EPOCH2.0_maxlen384_batchsize4_gradacc4 for evaluation
05/09/2022 19:53:28 - INFO - __main__ -   Evaluate the following checkpoints: ['/cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//squad/xlm-KG_LR8e-6_EPOCH2.0_maxlen384_batchsize4_gradacc4']
Some weights of the model checkpoint at /cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//squad/xlm-KG_LR8e-6_EPOCH2.0_maxlen384_batchsize4_gradacc4 were not used when initializing XLMRobertaModel: ['base_model.encoder.layer.11.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.23.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.18.output.LayerNorm.bias', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.18.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.3.output.adapters.tp.adapter_down.0.bias', 'base_model.embeddings.LayerNorm.bias', 'base_model.encoder.layer.15.attention.self.query.bias', 'base_model.encoder.layer.20.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.22.attention.output.LayerNorm.bias', 'base_model.encoder.layer.23.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.1.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.1.attention.output.dense.bias', 'base_model.embeddings.LayerNorm.weight', 'base_model.encoder.layer.6.attention.self.query.weight', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.8.attention.output.dense.weight', 'base_model.encoder.layer.8.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.9.attention.self.key.weight', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.22.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.7.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.17.attention.self.value.bias', 'base_model.encoder.layer.11.intermediate.dense.weight', 'base_model.encoder.layer.21.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.1.attention.self.key.weight', 'base_model.encoder.layer.12.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.22.attention.self.value.weight', 'base_model.encoder.layer.0.output.dense.bias', 'qa_outputs.weight', 'base_model.encoder.layer.2.attention.self.query.weight', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.23.attention.self.value.weight', 'base_model.encoder.layer.6.attention.self.key.weight', 'base_model.encoder.layer.5.attention.self.query.bias', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.8.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.1.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.11.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.12.attention.output.dense.weight', 'base_model.encoder.layer.7.attention.self.key.weight', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.3.attention.self.value.bias', 'base_model.encoder.layer.14.attention.self.key.bias', 'base_model.encoder.layer.21.attention.self.key.weight', 'base_model.encoder.layer.23.attention.self.query.weight', 'base_model.encoder.layer.13.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.20.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.16.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.4.attention.output.dense.weight', 'base_model.encoder.layer.16.attention.output.dense.bias', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.4.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.19.attention.output.LayerNorm.weight', 'base_model.encoder.layer.22.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.3.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.8.intermediate.dense.bias', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.5.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.7.output.LayerNorm.bias', 'base_model.encoder.layer.7.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.14.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.21.attention.self.query.bias', 'base_model.encoder.layer.21.attention.self.key.bias', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.6.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.3.attention.self.key.bias', 'base_model.encoder.layer.3.attention.output.dense.weight', 'base_model.encoder.layer.4.attention.self.query.bias', 'base_model.encoder.layer.2.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.2.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.4.attention.self.key.bias', 'base_model.encoder.layer.7.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.8.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.10.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.13.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.23.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.14.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.8.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.5.attention.output.dense.bias', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.10.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.21.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.9.intermediate.dense.bias', 'base_model.encoder.layer.2.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.21.output.LayerNorm.bias', 'base_model.encoder.layer.21.output.adapters.tp.adapter_up.bias', 'base_model.pooler.dense.bias', 'base_model.encoder.layer.13.attention.self.query.weight', 'base_model.encoder.layer.18.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.13.attention.self.value.weight', 'base_model.encoder.layer.20.intermediate.dense.bias', 'base_model.encoder.layer.3.intermediate.dense.bias', 'base_model.encoder.layer.23.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.16.attention.self.key.weight', 'base_model.encoder.layer.15.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.23.attention.self.key.weight', 'base_model.encoder.layer.13.attention.self.key.bias', 'base_model.encoder.layer.6.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.15.attention.self.key.weight', 'base_model.encoder.layer.22.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.8.output.LayerNorm.bias', 'base_model.encoder.layer.12.output.dense.weight', 'base_model.encoder.layer.0.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.0.attention.self.query.bias', 'base_model.encoder.layer.5.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.4.attention.output.LayerNorm.weight', 'base_model.encoder.layer.2.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.9.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.11.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.17.attention.output.LayerNorm.weight', 'base_model.encoder.layer.22.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.15.attention.self.value.bias', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.23.output.LayerNorm.bias', 'base_model.encoder.layer.2.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.7.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.10.output.LayerNorm.bias', 'base_model.encoder.layer.13.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.23.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.1.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.7.attention.self.query.weight', 'base_model.encoder.layer.9.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.3.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.10.attention.self.query.bias', 'base_model.encoder.layer.3.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.14.attention.output.dense.bias', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.5.intermediate.dense.bias', 'base_model.encoder.layer.16.attention.self.query.bias', 'base_model.encoder.layer.11.attention.output.dense.bias', 'base_model.encoder.layer.13.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.1.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.18.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.23.attention.output.dense.bias', 'base_model.encoder.layer.13.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.20.attention.self.query.bias', 'base_model.encoder.layer.13.attention.output.dense.weight', 'base_model.encoder.layer.18.intermediate.dense.bias', 'base_model.encoder.layer.13.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.14.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.17.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.19.attention.output.dense.bias', 'base_model.encoder.layer.19.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.12.output.dense.bias', 'base_model.encoder.layer.16.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.22.intermediate.dense.bias', 'base_model.encoder.layer.11.attention.self.key.bias', 'base_model.encoder.layer.18.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.22.output.LayerNorm.weight', 'base_model.encoder.layer.4.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.3.attention.output.dense.bias', 'base_model.encoder.layer.3.output.dense.bias', 'base_model.encoder.layer.17.attention.output.LayerNorm.bias', 'base_model.encoder.layer.17.attention.self.key.weight', 'base_model.encoder.layer.0.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.17.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.4.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.12.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.10.intermediate.dense.weight', 'base_model.encoder.layer.8.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.12.attention.self.key.bias', 'base_model.encoder.layer.19.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.10.attention.self.value.weight', 'base_model.encoder.layer.22.attention.self.key.weight', 'base_model.encoder.layer.7.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.15.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.12.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.1.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.5.attention.output.dense.weight', 'base_model.encoder.layer.11.attention.output.LayerNorm.bias', 'base_model.encoder.layer.13.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.11.attention.self.value.bias', 'base_model.encoder.layer.4.attention.self.value.bias', 'base_model.encoder.layer.2.output.LayerNorm.weight', 'base_model.encoder.layer.19.attention.output.LayerNorm.bias', 'base_model.encoder.layer.18.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.22.attention.self.query.bias', 'base_model.encoder.layer.18.attention.output.dense.weight', 'base_model.encoder.layer.21.attention.output.dense.weight', 'base_model.encoder.layer.10.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.4.output.dense.weight', 'base_model.encoder.layer.6.attention.self.value.weight', 'base_model.encoder.layer.1.output.LayerNorm.bias', 'base_model.encoder.layer.8.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.4.attention.output.dense.bias', 'base_model.encoder.layer.23.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.11.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.23.attention.output.dense.weight', 'base_model.encoder.layer.6.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.14.output.LayerNorm.weight', 'base_model.encoder.layer.4.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.11.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.13.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.14.attention.self.value.bias', 'base_model.encoder.layer.16.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.9.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.15.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.20.attention.output.LayerNorm.bias', 'base_model.encoder.layer.2.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.12.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.11.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.9.output.dense.bias', 'base_model.encoder.layer.9.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.19.output.LayerNorm.weight', 'base_model.encoder.layer.9.attention.output.LayerNorm.weight', 'base_model.encoder.layer.17.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.11.output.LayerNorm.weight', 'base_model.encoder.layer.2.intermediate.dense.bias', 'base_model.encoder.layer.5.output.dense.weight', 'base_model.encoder.layer.19.attention.self.value.bias', 'base_model.encoder.layer.10.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.14.attention.output.LayerNorm.weight', 'base_model.encoder.layer.1.output.dense.weight', 'base_model.encoder.layer.13.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.10.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.18.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.2.attention.output.LayerNorm.weight', 'base_model.encoder.layer.9.output.dense.weight', 'base_model.encoder.layer.11.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.1.intermediate.dense.weight', 'base_model.encoder.layer.11.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.9.attention.self.query.bias', 'base_model.encoder.layer.1.output.LayerNorm.weight', 'base_model.encoder.layer.12.output.LayerNorm.weight', 'base_model.encoder.layer.7.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.23.attention.self.value.bias', 'base_model.encoder.layer.1.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.7.output.dense.weight', 'base_model.encoder.layer.7.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.11.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.5.attention.output.LayerNorm.weight', 'base_model.encoder.layer.6.attention.self.value.bias', 'base_model.encoder.layer.0.attention.self.key.bias', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.3.output.LayerNorm.bias', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.21.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.0.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.9.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.6.attention.output.LayerNorm.bias', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.16.output.LayerNorm.bias', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.1.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.0.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.15.output.LayerNorm.bias', 'base_model.encoder.layer.14.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.6.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.9.attention.output.dense.weight', 'base_model.encoder.layer.10.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.11.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.13.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.16.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.7.attention.self.value.weight', 'base_model.encoder.layer.15.intermediate.dense.weight', 'base_model.encoder.layer.17.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.21.output.dense.weight', 'base_model.encoder.layer.10.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.8.attention.self.value.bias', 'base_model.encoder.layer.21.output.dense.bias', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.4.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.1.output.dense.bias', 'base_model.embeddings.position_ids', 'base_model.encoder.layer.21.attention.output.dense.bias', 'base_model.encoder.layer.20.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.15.attention.output.dense.bias', 'base_model.encoder.layer.13.output.dense.weight', 'base_model.encoder.layer.9.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.5.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.11.attention.output.LayerNorm.weight', 'base_model.encoder.layer.19.intermediate.dense.weight', 'base_model.encoder.layer.23.output.dense.bias', 'base_model.encoder.layer.6.output.dense.weight', 'base_model.encoder.layer.17.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.19.attention.output.dense.weight', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.21.output.LayerNorm.weight', 'base_model.encoder.layer.12.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.10.attention.self.query.weight', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.0.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.14.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.15.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.15.attention.self.key.bias', 'base_model.encoder.layer.2.attention.output.dense.bias', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.21.attention.self.value.weight', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.7.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.14.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.16.attention.self.value.weight', 'base_model.encoder.layer.1.attention.output.LayerNorm.bias', 'base_model.encoder.layer.19.output.LayerNorm.bias', 'base_model.encoder.layer.5.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.12.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.12.attention.self.query.bias', 'base_model.encoder.layer.2.attention.output.dense.weight', 'base_model.encoder.layer.4.attention.self.key.weight', 'base_model.encoder.layer.20.output.dense.bias', 'base_model.encoder.layer.23.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.23.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.20.output.LayerNorm.bias', 'base_model.encoder.layer.17.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.13.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.7.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.12.attention.self.query.weight', 'base_model.encoder.layer.15.attention.self.query.weight', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.15.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.18.output.dense.weight', 'base_model.encoder.layer.18.attention.self.key.weight', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.11.output.LayerNorm.bias', 'base_model.encoder.layer.14.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.19.attention.self.value.weight', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.17.attention.self.value.weight', 'base_model.encoder.layer.20.intermediate.dense.weight', 'base_model.encoder.layer.1.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.23.output.LayerNorm.weight', 'base_model.encoder.layer.6.attention.output.dense.bias', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.9.attention.output.LayerNorm.bias', 'base_model.encoder.layer.12.attention.output.LayerNorm.weight', 'base_model.encoder.layer.13.intermediate.dense.weight', 'base_model.encoder.layer.14.attention.output.dense.weight', 'base_model.encoder.layer.10.attention.output.LayerNorm.bias', 'base_model.encoder.layer.6.intermediate.dense.weight', 'base_model.encoder.layer.22.attention.output.dense.weight', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.0.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.20.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.0.intermediate.dense.weight', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.4.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.20.attention.output.LayerNorm.weight', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.19.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.12.output.LayerNorm.bias', 'base_model.encoder.layer.17.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.23.attention.self.query.bias', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.1.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.5.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.2.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.10.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.11.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.22.output.dense.bias', 'base_model.encoder.layer.10.attention.output.dense.bias', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.7.attention.output.dense.weight', 'base_model.encoder.layer.2.output.LayerNorm.bias', 'base_model.encoder.layer.7.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.16.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.10.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.21.attention.output.LayerNorm.weight', 'base_model.encoder.layer.21.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.2.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.0.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.20.attention.output.dense.bias', 'base_model.encoder.layer.13.output.LayerNorm.weight', 'base_model.encoder.layer.4.intermediate.dense.weight', 'base_model.encoder.layer.15.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.16.output.dense.weight', 'base_model.encoder.layer.6.attention.self.key.bias', 'base_model.encoder.layer.19.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.16.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.7.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.15.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.5.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.18.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.1.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.10.intermediate.dense.bias', 'base_model.encoder.layer.2.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.7.attention.output.LayerNorm.weight', 'base_model.encoder.layer.1.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.3.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.14.attention.self.value.weight', 'base_model.encoder.layer.16.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.20.attention.output.dense.weight', 'base_model.encoder.layer.20.attention.self.key.weight', 'base_model.encoder.layer.15.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.15.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.16.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.3.output.LayerNorm.weight', 'base_model.encoder.layer.6.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.9.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.14.intermediate.dense.bias', 'base_model.encoder.layer.0.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.3.intermediate.dense.weight', 'base_model.encoder.layer.11.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.6.attention.output.dense.weight', 'base_model.encoder.layer.1.attention.output.LayerNorm.weight', 'base_model.encoder.layer.5.attention.self.query.weight', 'base_model.encoder.layer.2.output.dense.weight', 'base_model.encoder.layer.3.attention.self.key.weight', 'base_model.encoder.layer.11.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.6.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.12.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.20.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.5.intermediate.dense.weight', 'base_model.encoder.layer.10.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.14.output.dense.bias', 'base_model.encoder.layer.15.output.dense.weight', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.8.attention.self.value.weight', 'base_model.encoder.layer.21.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.0.output.LayerNorm.weight', 'base_model.encoder.layer.6.output.LayerNorm.weight', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.11.attention.self.query.bias', 'base_model.encoder.layer.14.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.7.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.12.attention.output.LayerNorm.bias', 'base_model.encoder.layer.19.attention.self.key.bias', 'base_model.encoder.layer.3.attention.self.value.weight', 'base_model.encoder.layer.21.attention.self.value.bias', 'base_model.encoder.layer.1.attention.output.dense.weight', 'base_model.encoder.layer.5.output.LayerNorm.bias', 'base_model.encoder.layer.15.output.LayerNorm.weight', 'base_model.encoder.layer.6.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.17.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.13.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.20.attention.self.value.bias', 'base_model.encoder.layer.13.attention.self.key.weight', 'base_model.encoder.layer.20.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.22.attention.self.key.bias', 'base_model.encoder.layer.23.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.2.output.dense.bias', 'base_model.encoder.layer.6.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.0.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.3.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.4.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.10.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.14.intermediate.dense.weight', 'base_model.encoder.layer.3.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.22.attention.output.LayerNorm.weight', 'base_model.encoder.layer.5.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.14.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.21.intermediate.dense.bias', 'base_model.encoder.layer.8.attention.self.key.bias', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.23.output.dense.weight', 'base_model.encoder.layer.10.attention.self.value.bias', 'base_model.encoder.layer.18.output.LayerNorm.weight', 'base_model.encoder.layer.21.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.1.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.1.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.3.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.18.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.10.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.17.attention.self.key.bias', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.18.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.22.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.22.attention.output.dense.bias', 'base_model.encoder.layer.17.attention.output.dense.bias', 'base_model.encoder.layer.11.attention.output.dense.weight', 'base_model.encoder.layer.22.attention.self.query.weight', 'base_model.encoder.layer.13.intermediate.dense.bias', 'base_model.encoder.layer.1.attention.self.value.bias', 'base_model.encoder.layer.19.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.12.attention.self.key.weight', 'base_model.encoder.layer.13.attention.output.LayerNorm.bias', 'base_model.encoder.layer.0.output.LayerNorm.bias', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.17.intermediate.dense.bias', 'base_model.encoder.layer.17.output.dense.bias', 'base_model.encoder.layer.18.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.6.intermediate.dense.bias', 'base_model.encoder.layer.21.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.8.attention.self.key.weight', 'base_model.encoder.layer.7.intermediate.dense.bias', 'base_model.encoder.layer.9.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.10.output.dense.weight', 'base_model.encoder.layer.11.attention.self.query.weight', 'base_model.encoder.layer.17.attention.output.dense.weight', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.5.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.18.attention.output.dense.bias', 'base_model.encoder.layer.17.output.LayerNorm.bias', 'base_model.encoder.layer.21.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.2.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.8.attention.output.LayerNorm.bias', 'base_model.encoder.layer.10.attention.output.dense.weight', 'base_model.encoder.layer.23.intermediate.dense.bias', 'base_model.encoder.layer.21.attention.output.LayerNorm.bias', 'base_model.encoder.layer.4.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.16.attention.self.query.weight', 'base_model.encoder.layer.0.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.0.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.4.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.10.output.dense.bias', 'base_model.encoder.layer.11.attention.self.value.weight', 'base_model.encoder.layer.17.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.7.attention.self.key.bias', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.21.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.2.intermediate.dense.weight', 'base_model.encoder.layer.6.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.7.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.14.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.18.attention.output.LayerNorm.weight', 'base_model.encoder.layer.11.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.5.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.19.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.2.attention.self.key.bias', 'base_model.encoder.layer.8.attention.output.LayerNorm.weight', 'base_model.encoder.layer.20.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.19.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.8.attention.self.query.bias', 'base_model.encoder.layer.2.attention.self.query.bias', 'base_model.embeddings.position_embeddings.weight', 'base_model.encoder.layer.6.output.dense.bias', 'base_model.encoder.layer.20.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.9.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.9.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.17.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.10.attention.self.key.weight', 'base_model.encoder.layer.19.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.3.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.3.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.0.attention.self.value.weight', 'base_model.encoder.layer.4.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.1.attention.self.value.weight', 'base_model.encoder.layer.2.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.18.attention.self.query.bias', 'base_model.encoder.layer.5.output.dense.bias', 'base_model.encoder.layer.6.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.11.intermediate.dense.bias', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.8.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.11.attention.self.key.weight', 'base_model.encoder.layer.23.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.0.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.10.attention.self.key.bias', 'base_model.encoder.layer.23.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.16.intermediate.dense.weight', 'base_model.encoder.layer.14.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.1.attention.self.query.weight', 'base_model.encoder.layer.18.attention.output.LayerNorm.bias', 'base_model.encoder.layer.19.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.8.output.dense.bias', 'base_model.encoder.layer.8.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.22.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.17.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.5.attention.self.value.weight', 'base_model.encoder.layer.1.attention.self.query.bias', 'base_model.encoder.layer.9.attention.self.key.bias', 'base_model.encoder.layer.1.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.16.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.8.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.9.attention.self.value.weight', 'base_model.encoder.layer.0.intermediate.dense.bias', 'base_model.encoder.layer.11.output.dense.bias', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.22.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.2.attention.self.value.weight', 'base_model.encoder.layer.4.intermediate.dense.bias', 'base_model.encoder.layer.3.attention.output.LayerNorm.weight', 'base_model.encoder.layer.18.attention.self.value.weight', 'base_model.encoder.layer.10.output.LayerNorm.weight', 'base_model.encoder.layer.1.intermediate.dense.bias', 'base_model.encoder.layer.13.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.19.attention.self.query.bias', 'base_model.encoder.layer.9.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.17.output.dense.weight', 'base_model.encoder.layer.0.attention.output.dense.weight', 'base_model.encoder.layer.5.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.18.attention.self.key.bias', 'base_model.encoder.layer.4.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.22.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.1.attention.self.key.bias', 'base_model.encoder.layer.15.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.9.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.8.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.22.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.8.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.13.output.dense.bias', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.4.attention.self.query.weight', 'base_model.encoder.layer.9.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.10.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.14.output.dense.weight', 'base_model.encoder.layer.15.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.16.attention.output.dense.weight', 'base_model.encoder.layer.20.attention.self.key.bias', 'base_model.encoder.layer.12.attention.output.dense.bias', 'base_model.encoder.layer.3.output.adapters.es.adapter_up.weight', 'base_model.pooler.dense.weight', 'base_model.encoder.layer.3.attention.self.query.weight', 'base_model.encoder.layer.21.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.embeddings.word_embeddings.weight', 'base_model.encoder.layer.8.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.5.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.20.output.LayerNorm.weight', 'base_model.encoder.layer.22.output.dense.weight', 'base_model.encoder.layer.6.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.19.attention.self.query.weight', 'base_model.encoder.layer.0.attention.self.query.weight', 'base_model.encoder.layer.7.attention.self.query.bias', 'base_model.encoder.layer.13.attention.output.dense.bias', 'base_model.encoder.layer.15.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.4.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.0.output.dense.weight', 'base_model.encoder.layer.22.output.LayerNorm.bias', 'base_model.encoder.layer.19.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.19.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.20.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.3.attention.self.query.bias', 'base_model.encoder.layer.12.attention.self.value.bias', 'base_model.encoder.layer.0.attention.output.LayerNorm.weight', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.5.attention.self.key.bias', 'base_model.encoder.layer.11.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.22.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.4.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.5.attention.self.key.weight', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.21.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.17.attention.self.query.bias', 'base_model.encoder.layer.16.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.9.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.17.output.LayerNorm.weight', 'base_model.encoder.layer.7.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.5.attention.output.LayerNorm.bias', 'base_model.encoder.layer.23.intermediate.dense.weight', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.22.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.2.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.23.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.4.output.LayerNorm.weight', 'base_model.encoder.layer.22.attention.self.value.bias', 'base_model.encoder.layer.8.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.17.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.5.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.20.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.22.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.2.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.10.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.14.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.5.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.15.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.9.intermediate.dense.weight', 'base_model.encoder.layer.10.attention.output.LayerNorm.weight', 'base_model.encoder.layer.18.output.dense.bias', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.6.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.23.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.9.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.20.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.15.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.6.attention.self.query.bias', 'base_model.encoder.layer.12.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.19.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.20.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.0.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.9.attention.output.dense.bias', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.20.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.8.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.3.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.6.attention.output.LayerNorm.weight', 'base_model.encoder.layer.6.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.4.attention.self.value.weight', 'base_model.encoder.layer.4.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.13.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.10.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.20.attention.self.query.weight', 'base_model.encoder.layer.22.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.1.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.23.attention.self.key.bias', 'base_model.encoder.layer.18.attention.self.value.bias', 'base_model.encoder.layer.17.intermediate.dense.weight', 'base_model.encoder.layer.12.intermediate.dense.weight', 'base_model.encoder.layer.18.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.19.output.dense.bias', 'base_model.encoder.layer.22.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.15.attention.self.value.weight', 'base_model.encoder.layer.2.attention.output.LayerNorm.bias', 'base_model.encoder.layer.13.attention.output.LayerNorm.weight', 'base_model.encoder.layer.14.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.19.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.14.output.LayerNorm.bias', 'base_model.encoder.layer.19.attention.self.key.weight', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.12.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.0.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.15.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.18.intermediate.dense.weight', 'base_model.encoder.layer.4.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.19.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.12.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.5.output.LayerNorm.weight', 'base_model.encoder.layer.17.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.15.attention.output.LayerNorm.bias', 'base_model.encoder.layer.19.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.7.output.dense.bias', 'base_model.encoder.layer.15.intermediate.dense.bias', 'base_model.encoder.layer.20.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.23.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.0.attention.output.LayerNorm.bias', 'base_model.encoder.layer.8.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.1.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.3.attention.output.LayerNorm.bias', 'base_model.encoder.layer.5.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.12.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.21.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.14.attention.self.key.weight', 'base_model.encoder.layer.0.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.12.attention.self.value.weight', 'base_model.encoder.layer.0.attention.output.dense.bias', 'base_model.encoder.layer.10.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.16.intermediate.dense.bias', 'base_model.encoder.layer.20.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.3.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.4.output.dense.bias', 'base_model.encoder.layer.3.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.6.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.9.output.LayerNorm.bias', 'base_model.encoder.layer.23.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.8.attention.output.dense.bias', 'base_model.encoder.layer.12.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.13.attention.self.query.bias', 'base_model.encoder.layer.18.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.21.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.16.attention.self.value.bias', 'base_model.encoder.layer.23.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.22.intermediate.dense.weight', 'base_model.encoder.layer.3.output.dense.weight', 'base_model.encoder.layer.16.attention.self.key.bias', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.14.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.5.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.5.attention.self.value.bias', 'base_model.encoder.layer.3.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.19.output.dense.weight', 'base_model.encoder.layer.7.attention.output.dense.bias', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.14.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.embeddings.token_type_embeddings.weight', 'base_model.encoder.layer.9.attention.self.value.bias', 'base_model.encoder.layer.16.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.7.intermediate.dense.weight', 'base_model.encoder.layer.15.attention.output.dense.weight', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.12.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.13.output.LayerNorm.bias', 'base_model.encoder.layer.9.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.20.attention.self.value.weight', 'base_model.encoder.layer.2.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.21.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.8.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.2.attention.self.value.bias', 'base_model.encoder.layer.16.output.dense.bias', 'base_model.encoder.layer.7.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.22.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.21.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.14.attention.self.query.weight', 'base_model.encoder.layer.16.attention.output.LayerNorm.bias', 'base_model.encoder.layer.16.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.20.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.16.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.14.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.12.intermediate.dense.bias', 'base_model.encoder.layer.20.output.dense.weight', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.8.intermediate.dense.weight', 'base_model.encoder.layer.6.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.7.attention.self.value.bias', 'base_model.encoder.layer.8.output.LayerNorm.weight', 'base_model.encoder.layer.2.attention.self.key.weight', 'base_model.encoder.layer.23.attention.output.LayerNorm.bias', 'base_model.encoder.layer.21.intermediate.dense.weight', 'base_model.encoder.layer.2.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'qa_outputs.bias', 'base_model.encoder.layer.4.output.LayerNorm.bias', 'base_model.encoder.layer.9.output.LayerNorm.weight', 'base_model.encoder.layer.12.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.15.output.dense.bias', 'base_model.encoder.layer.18.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.4.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.18.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.12.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.18.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.8.output.dense.weight', 'base_model.encoder.layer.15.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.16.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.17.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.7.attention.output.LayerNorm.bias', 'base_model.encoder.layer.15.attention.output.LayerNorm.weight', 'base_model.encoder.layer.16.output.LayerNorm.weight', 'base_model.encoder.layer.14.attention.self.query.bias', 'base_model.encoder.layer.14.attention.output.LayerNorm.bias', 'base_model.encoder.layer.4.attention.output.LayerNorm.bias', 'base_model.encoder.layer.17.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.17.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.0.attention.self.value.bias', 'base_model.encoder.layer.13.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.18.attention.self.query.weight', 'base_model.encoder.layer.13.attention.self.value.bias', 'base_model.encoder.layer.17.attention.self.query.weight', 'base_model.encoder.layer.7.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.16.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.11.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.3.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.18.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.22.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.16.attention.output.LayerNorm.weight', 'base_model.encoder.layer.7.output.LayerNorm.weight', 'base_model.encoder.layer.12.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.16.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.0.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.5.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.23.attention.output.LayerNorm.weight', 'base_model.encoder.layer.0.attention.self.key.weight', 'base_model.encoder.layer.2.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.9.attention.self.query.weight', 'base_model.encoder.layer.8.attention.self.query.weight', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.19.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.11.output.dense.weight', 'base_model.encoder.layer.19.intermediate.dense.bias', 'base_model.encoder.layer.21.attention.self.query.weight', 'base_model.encoder.layer.13.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.6.output.LayerNorm.bias', 'base_model.encoder.layer.6.output.adapters.ep.adapter_down.0.bias']
- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of XLMRobertaModel were not initialized from the model checkpoint at /cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//squad/xlm-KG_LR8e-6_EPOCH2.0_maxlen384_batchsize4_gradacc4 and are newly initialized: ['encoder.layer.23.attention.output.dense.weight', 'encoder.layer.1.attention.output.dense.bias', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.19.attention.output.dense.bias', 'encoder.layer.6.output.LayerNorm.bias', 'encoder.layer.10.attention.self.value.bias', 'encoder.layer.23.attention.output.LayerNorm.weight', 'encoder.layer.22.intermediate.dense.bias', 'encoder.layer.13.output.dense.bias', 'encoder.layer.10.attention.self.key.weight', 'encoder.layer.9.attention.self.query.bias', 'encoder.layer.12.attention.self.key.bias', 'encoder.layer.4.output.dense.bias', 'encoder.layer.3.attention.self.value.weight', 'encoder.layer.9.attention.self.key.weight', 'encoder.layer.9.attention.output.dense.weight', 'encoder.layer.7.attention.self.key.weight', 'encoder.layer.13.output.LayerNorm.weight', 'encoder.layer.10.attention.output.LayerNorm.bias', 'encoder.layer.16.intermediate.dense.weight', 'encoder.layer.21.output.LayerNorm.weight', 'encoder.layer.17.attention.output.LayerNorm.weight', 'encoder.layer.21.output.LayerNorm.bias', 'encoder.layer.12.output.dense.weight', 'encoder.layer.17.output.LayerNorm.bias', 'encoder.layer.21.attention.self.key.bias', 'encoder.layer.13.attention.output.LayerNorm.bias', 'encoder.layer.0.output.dense.weight', 'encoder.layer.8.attention.self.query.bias', 'encoder.layer.18.attention.self.key.bias', 'encoder.layer.5.attention.self.value.bias', 'encoder.layer.7.attention.output.LayerNorm.bias', 'encoder.layer.14.output.LayerNorm.weight', 'encoder.layer.15.output.dense.bias', 'encoder.layer.1.attention.self.key.weight', 'encoder.layer.21.attention.self.query.weight', 'encoder.layer.19.attention.output.LayerNorm.weight', 'encoder.layer.1.attention.self.query.bias', 'encoder.layer.14.attention.self.value.bias', 'encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.layer.1.attention.self.value.weight', 'encoder.layer.20.intermediate.dense.bias', 'encoder.layer.12.intermediate.dense.weight', 'encoder.layer.22.output.dense.weight', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.17.attention.self.key.bias', 'encoder.layer.14.intermediate.dense.weight', 'encoder.layer.10.attention.output.LayerNorm.weight', 'encoder.layer.6.attention.output.dense.weight', 'encoder.layer.15.attention.self.value.bias', 'encoder.layer.18.output.dense.weight', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.12.attention.output.dense.bias', 'encoder.layer.22.attention.self.key.weight', 'encoder.layer.13.output.LayerNorm.bias', 'encoder.layer.12.output.LayerNorm.weight', 'encoder.layer.11.output.LayerNorm.bias', 'encoder.layer.9.output.LayerNorm.bias', 'encoder.layer.5.output.dense.weight', 'encoder.layer.4.attention.output.dense.weight', 'encoder.layer.20.output.LayerNorm.weight', 'encoder.layer.23.attention.self.value.bias', 'encoder.layer.15.attention.self.query.weight', 'encoder.layer.7.output.LayerNorm.bias', 'encoder.layer.3.attention.self.query.weight', 'encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.layer.1.attention.output.LayerNorm.weight', 'encoder.layer.17.attention.output.dense.weight', 'encoder.layer.3.attention.self.query.bias', 'encoder.layer.11.attention.output.LayerNorm.weight', 'encoder.layer.18.attention.output.LayerNorm.weight', 'encoder.layer.2.output.dense.weight', 'encoder.layer.4.attention.self.value.bias', 'encoder.layer.22.attention.output.dense.bias', 'encoder.layer.12.attention.output.LayerNorm.weight', 'encoder.layer.12.attention.output.dense.weight', 'encoder.layer.5.output.dense.bias', 'encoder.layer.22.attention.self.query.bias', 'encoder.layer.20.attention.self.value.weight', 'encoder.layer.12.output.dense.bias', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.2.attention.output.LayerNorm.weight', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.19.output.dense.bias', 'encoder.layer.11.attention.self.query.weight', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.10.attention.output.dense.weight', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.5.attention.self.value.weight', 'encoder.layer.11.attention.self.value.bias', 'encoder.layer.15.intermediate.dense.bias', 'encoder.layer.8.attention.output.LayerNorm.bias', 'encoder.layer.20.attention.self.value.bias', 'encoder.layer.3.attention.output.dense.bias', 'encoder.layer.4.attention.self.value.weight', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.16.attention.self.value.bias', 'encoder.layer.10.attention.self.value.weight', 'encoder.layer.4.attention.output.LayerNorm.bias', 'encoder.layer.13.attention.output.LayerNorm.weight', 'encoder.layer.18.intermediate.dense.weight', 'encoder.layer.9.attention.output.LayerNorm.bias', 'encoder.layer.19.attention.self.query.weight', 'encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.layer.10.output.dense.weight', 'encoder.layer.16.intermediate.dense.bias', 'encoder.layer.10.intermediate.dense.weight', 'encoder.layer.16.attention.self.value.weight', 'encoder.layer.10.output.dense.bias', 'encoder.layer.0.attention.self.query.bias', 'encoder.layer.19.attention.self.value.bias', 'encoder.layer.14.attention.self.key.bias', 'encoder.layer.14.attention.self.query.weight', 'encoder.layer.19.intermediate.dense.bias', 'encoder.layer.8.attention.output.dense.weight', 'encoder.layer.7.output.dense.bias', 'encoder.layer.19.output.LayerNorm.bias', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.13.attention.self.query.weight', 'encoder.layer.21.output.dense.weight', 'encoder.layer.15.output.LayerNorm.bias', 'encoder.layer.21.attention.output.dense.weight', 'encoder.layer.8.output.dense.bias', 'encoder.layer.20.attention.output.dense.bias', 'encoder.layer.13.attention.self.value.weight', 'encoder.layer.20.output.dense.weight', 'encoder.layer.19.attention.self.key.bias', 'encoder.layer.23.output.dense.bias', 'encoder.layer.18.attention.self.value.bias', 'encoder.layer.23.intermediate.dense.bias', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.9.attention.self.key.bias', 'encoder.layer.9.attention.output.dense.bias', 'encoder.layer.1.output.dense.bias', 'encoder.layer.5.attention.output.dense.weight', 'encoder.layer.17.attention.output.dense.bias', 'encoder.layer.18.intermediate.dense.bias', 'encoder.layer.11.attention.self.key.weight', 'encoder.layer.10.attention.output.dense.bias', 'encoder.layer.14.attention.output.LayerNorm.weight', 'embeddings.LayerNorm.weight', 'encoder.layer.7.attention.output.dense.weight', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.12.attention.self.query.weight', 'encoder.layer.9.attention.self.query.weight', 'encoder.layer.4.attention.output.LayerNorm.weight', 'encoder.layer.17.attention.self.query.bias', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.8.output.LayerNorm.weight', 'encoder.layer.20.attention.output.dense.weight', 'encoder.layer.21.intermediate.dense.weight', 'encoder.layer.2.attention.output.dense.weight', 'encoder.layer.16.output.LayerNorm.weight', 'encoder.layer.12.attention.self.value.bias', 'encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.layer.8.attention.self.query.weight', 'encoder.layer.15.attention.self.key.weight', 'encoder.layer.17.intermediate.dense.weight', 'encoder.layer.10.attention.self.query.bias', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.11.attention.self.value.weight', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.14.output.dense.bias', 'encoder.layer.13.output.dense.weight', 'encoder.layer.17.attention.self.key.weight', 'encoder.layer.3.attention.self.key.bias', 'encoder.layer.0.attention.output.dense.weight', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.8.attention.self.value.bias', 'encoder.layer.12.attention.output.LayerNorm.bias', 'encoder.layer.12.attention.self.query.bias', 'encoder.layer.18.attention.output.LayerNorm.bias', 'embeddings.token_type_embeddings.weight', 'encoder.layer.6.attention.self.key.weight', 'encoder.layer.23.output.dense.weight', 'encoder.layer.4.attention.self.query.bias', 'encoder.layer.16.attention.output.LayerNorm.weight', 'encoder.layer.5.attention.output.dense.bias', 'encoder.layer.11.output.dense.bias', 'encoder.layer.17.output.dense.weight', 'encoder.layer.1.attention.self.value.bias', 'encoder.layer.6.attention.output.LayerNorm.weight', 'encoder.layer.6.output.dense.weight', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.14.attention.output.dense.weight', 'encoder.layer.19.attention.self.query.bias', 'encoder.layer.2.attention.self.value.bias', 'encoder.layer.6.attention.self.value.bias', 'encoder.layer.13.attention.self.key.bias', 'encoder.layer.14.output.dense.weight', 'embeddings.position_embeddings.weight', 'encoder.layer.16.attention.self.query.bias', 'encoder.layer.16.attention.self.query.weight', 'encoder.layer.8.attention.self.key.bias', 'encoder.layer.18.output.LayerNorm.bias', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.19.intermediate.dense.weight', 'encoder.layer.2.attention.self.query.bias', 'encoder.layer.10.attention.self.query.weight', 'encoder.layer.1.attention.self.query.weight', 'encoder.layer.16.output.LayerNorm.bias', 'encoder.layer.8.attention.self.key.weight', 'encoder.layer.17.intermediate.dense.bias', 'encoder.layer.0.attention.self.key.bias', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.23.attention.self.value.weight', 'encoder.layer.6.attention.self.query.bias', 'encoder.layer.20.output.dense.bias', 'pooler.dense.bias', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.2.output.dense.bias', 'encoder.layer.0.output.dense.bias', 'encoder.layer.17.attention.output.LayerNorm.bias', 'encoder.layer.5.attention.output.LayerNorm.weight', 'encoder.layer.4.attention.self.key.weight', 'encoder.layer.16.attention.output.dense.bias', 'encoder.layer.2.attention.output.dense.bias', 'encoder.layer.15.output.LayerNorm.weight', 'encoder.layer.7.attention.self.query.weight', 'encoder.layer.7.attention.self.key.bias', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.12.output.LayerNorm.bias', 'encoder.layer.3.attention.self.value.bias', 'encoder.layer.23.attention.self.query.bias', 'encoder.layer.8.attention.self.value.weight', 'encoder.layer.7.attention.self.value.bias', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.16.attention.output.dense.weight', 'encoder.layer.21.intermediate.dense.bias', 'encoder.layer.6.attention.self.value.weight', 'encoder.layer.14.intermediate.dense.bias', 'encoder.layer.15.attention.output.dense.weight', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.2.attention.self.value.weight', 'encoder.layer.23.attention.self.query.weight', 'encoder.layer.20.attention.self.query.weight', 'encoder.layer.12.intermediate.dense.bias', 'encoder.layer.15.attention.output.dense.bias', 'encoder.layer.13.attention.output.dense.weight', 'encoder.layer.22.attention.self.query.weight', 'encoder.layer.1.output.dense.weight', 'encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.6.attention.self.query.weight', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.15.attention.output.LayerNorm.weight', 'encoder.layer.5.output.LayerNorm.bias', 'encoder.layer.16.output.dense.bias', 'encoder.layer.22.attention.self.value.bias', 'encoder.layer.23.intermediate.dense.weight', 'encoder.layer.22.output.LayerNorm.bias', 'encoder.layer.21.attention.self.value.weight', 'encoder.layer.14.attention.output.dense.bias', 'encoder.layer.19.attention.output.LayerNorm.bias', 'encoder.layer.8.output.dense.weight', 'encoder.layer.22.attention.self.key.bias', 'encoder.layer.11.attention.output.dense.bias', 'encoder.layer.6.attention.output.LayerNorm.bias', 'encoder.layer.14.attention.self.key.weight', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.layer.5.attention.self.key.bias', 'encoder.layer.14.attention.self.query.bias', 'encoder.layer.0.attention.self.key.weight', 'encoder.layer.21.attention.self.key.weight', 'encoder.layer.0.attention.self.value.bias', 'encoder.layer.11.output.LayerNorm.weight', 'encoder.layer.0.attention.output.LayerNorm.weight', 'encoder.layer.3.attention.self.key.weight', 'encoder.layer.3.output.dense.weight', 'encoder.layer.19.attention.self.key.weight', 'encoder.layer.5.attention.self.key.weight', 'encoder.layer.7.attention.output.LayerNorm.weight', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.11.attention.output.dense.weight', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.4.attention.self.query.weight', 'encoder.layer.5.attention.self.query.bias', 'encoder.layer.19.output.dense.weight', 'encoder.layer.9.output.dense.weight', 'encoder.layer.9.output.dense.bias', 'encoder.layer.7.intermediate.dense.bias', 'encoder.layer.22.attention.output.LayerNorm.weight', 'encoder.layer.15.attention.self.query.bias', 'pooler.dense.weight', 'encoder.layer.4.attention.output.dense.bias', 'encoder.layer.19.attention.output.dense.weight', 'encoder.layer.10.attention.self.key.bias', 'embeddings.word_embeddings.weight', 'encoder.layer.5.attention.self.query.weight', 'encoder.layer.7.attention.self.value.weight', 'encoder.layer.2.attention.self.key.weight', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.15.attention.self.value.weight', 'encoder.layer.13.attention.self.value.bias', 'encoder.layer.20.intermediate.dense.weight', 'encoder.layer.12.attention.self.value.weight', 'encoder.layer.10.output.LayerNorm.weight', 'encoder.layer.13.intermediate.dense.weight', 'encoder.layer.18.attention.self.key.weight', 'encoder.layer.15.output.dense.weight', 'encoder.layer.22.intermediate.dense.weight', 'encoder.layer.4.attention.self.key.bias', 'encoder.layer.2.attention.output.LayerNorm.bias', 'encoder.layer.6.attention.self.key.bias', 'encoder.layer.13.attention.self.query.bias', 'encoder.layer.10.output.LayerNorm.bias', 'encoder.layer.13.intermediate.dense.bias', 'encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.21.attention.output.LayerNorm.bias', 'encoder.layer.0.attention.self.value.weight', 'encoder.layer.7.attention.output.dense.bias', 'encoder.layer.15.attention.output.LayerNorm.bias', 'encoder.layer.0.attention.output.dense.bias', 'encoder.layer.18.attention.output.dense.weight', 'encoder.layer.1.attention.output.dense.weight', 'encoder.layer.11.attention.self.key.bias', 'encoder.layer.21.attention.output.dense.bias', 'encoder.layer.18.attention.self.query.bias', 'encoder.layer.16.attention.output.LayerNorm.bias', 'encoder.layer.17.output.LayerNorm.weight', 'encoder.layer.9.attention.self.value.bias', 'embeddings.LayerNorm.bias', 'encoder.layer.6.output.dense.bias', 'encoder.layer.20.attention.self.key.weight', 'encoder.layer.7.output.LayerNorm.weight', 'encoder.layer.18.attention.self.query.weight', 'encoder.layer.22.attention.output.dense.weight', 'encoder.layer.20.attention.output.LayerNorm.bias', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.14.output.LayerNorm.bias', 'encoder.layer.9.attention.self.value.weight', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.18.attention.output.dense.bias', 'encoder.layer.7.output.dense.weight', 'encoder.layer.15.attention.self.key.bias', 'encoder.layer.17.attention.self.query.weight', 'encoder.layer.11.output.dense.weight', 'encoder.layer.23.attention.self.key.weight', 'encoder.layer.22.output.dense.bias', 'encoder.layer.18.attention.self.value.weight', 'encoder.layer.16.attention.self.key.bias', 'encoder.layer.8.attention.output.dense.bias', 'encoder.layer.14.attention.output.LayerNorm.bias', 'encoder.layer.4.output.dense.weight', 'encoder.layer.3.attention.output.dense.weight', 'encoder.layer.18.output.LayerNorm.weight', 'encoder.layer.8.attention.output.LayerNorm.weight', 'encoder.layer.20.attention.output.LayerNorm.weight', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.1.attention.self.key.bias', 'encoder.layer.16.output.dense.weight', 'encoder.layer.0.attention.self.query.weight', 'encoder.layer.21.attention.self.value.bias', 'encoder.layer.20.attention.self.key.bias', 'encoder.layer.21.attention.output.LayerNorm.weight', 'encoder.layer.9.output.LayerNorm.weight', 'encoder.layer.17.attention.self.value.bias', 'encoder.layer.22.attention.output.LayerNorm.bias', 'encoder.layer.11.attention.self.query.bias', 'encoder.layer.22.output.LayerNorm.weight', 'encoder.layer.21.attention.self.query.bias', 'encoder.layer.14.attention.self.value.weight', 'encoder.layer.15.intermediate.dense.weight', 'encoder.layer.7.attention.self.query.bias', 'encoder.layer.20.attention.self.query.bias', 'encoder.layer.13.attention.output.dense.bias', 'encoder.layer.17.attention.self.value.weight', 'encoder.layer.23.attention.output.LayerNorm.bias', 'encoder.layer.23.output.LayerNorm.bias', 'encoder.layer.6.attention.output.dense.bias', 'encoder.layer.22.attention.self.value.weight', 'encoder.layer.16.attention.self.key.weight', 'encoder.layer.23.attention.self.key.bias', 'encoder.layer.12.attention.self.key.weight', 'encoder.layer.2.attention.self.query.weight', 'encoder.layer.2.attention.self.key.bias', 'encoder.layer.13.attention.self.key.weight', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.20.output.LayerNorm.bias', 'encoder.layer.8.output.LayerNorm.bias', 'encoder.layer.18.output.dense.bias', 'encoder.layer.3.output.dense.bias', 'encoder.layer.9.attention.output.LayerNorm.weight', 'encoder.layer.19.output.LayerNorm.weight', 'encoder.layer.19.attention.self.value.weight', 'encoder.layer.23.output.LayerNorm.weight', 'encoder.layer.23.attention.output.dense.bias', 'encoder.layer.17.output.dense.bias', 'encoder.layer.21.output.dense.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Overwriting existing adapter 'ep'.
Overwriting existing adapter 'tp'.
Overwriting existing adapter 'es'.
Overwriting existing adapter 'ts'.
Overwriting existing adapter fusion module 'ep,tp,es,ts'
05/09/2022 19:54:07 - INFO - __main__ -   Creating features from dataset file at .
/cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//squad/xlm-KG_LR8e-6_EPOCH2.0_maxlen384_batchsize4_gradacc4
XLMConfig {
  "architectures": [
    "XLMRobertaForMaskedLM"
  ],
  "asm": false,
  "attention_dropout": 0.1,
  "attention_probs_dropout_prob": 0.1,
  "bos_index": 0,
  "bos_token_id": 0,
  "causal": false,
  "dropout": 0.1,
  "emb_dim": 1024,
  "embed_init_std": 0.02209708691207961,
  "end_n_top": 5,
  "eos_index": 1,
  "eos_token_id": 2,
  "gelu_activation": true,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "init_std": 0.02,
  "initializer_range": 0.02,
  "intermediate_size": 4096,
  "is_encoder": true,
  "lang_id": 0,
  "layer_norm_eps": 1e-05,
  "mask_index": 5,
  "mask_token_id": 0,
  "max_position_embeddings": 514,
  "model_type": "xlm",
  "n_heads": 16,
  "n_langs": 1,
  "n_layers": 24,
  "output_past": true,
  "pad_index": 2,
  "pad_token_id": 1,
  "sinusoidal_embeddings": false,
  "start_n_top": 5,
  "summary_activation": null,
  "summary_first_dropout": 0.1,
  "summary_proj_to_labels": true,
  "summary_type": "first",
  "summary_use_proj": true,
  "transformers_version": "4.17.0",
  "type_vocab_size": 1,
  "unk_index": 3,
  "use_lang_emb": false,
  "vocab_size": 250002
}

  0%|          | 0/48 [00:00<?, ?it/s] 29%|██▉       | 14/48 [00:00<00:00, 131.47it/s] 58%|█████▊    | 28/48 [00:00<00:00, 98.19it/s]  81%|████████▏ | 39/48 [00:00<00:00, 95.66it/s]100%|██████████| 48/48 [00:00<00:00, 98.90it/s]
convert squad examples to features:   0%|          | 0/1190 [00:00<?, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.
convert squad examples to features:   0%|          | 1/1190 [00:00<03:02,  6.50it/s]convert squad examples to features:   5%|▌         | 65/1190 [00:00<00:05, 204.63it/s]convert squad examples to features:   8%|▊         | 97/1190 [00:00<00:04, 236.56it/s]convert squad examples to features:  14%|█▎        | 161/1190 [00:00<00:03, 296.85it/s]convert squad examples to features:  16%|█▌        | 193/1190 [00:00<00:03, 299.32it/s]convert squad examples to features:  19%|█▉        | 225/1190 [00:00<00:03, 287.61it/s]convert squad examples to features:  22%|██▏       | 257/1190 [00:01<00:03, 265.30it/s]convert squad examples to features:  24%|██▍       | 289/1190 [00:01<00:03, 246.42it/s]convert squad examples to features:  27%|██▋       | 321/1190 [00:01<00:03, 220.60it/s]convert squad examples to features:  30%|██▉       | 353/1190 [00:01<00:03, 216.36it/s]convert squad examples to features:  32%|███▏      | 385/1190 [00:02<00:06, 124.19it/s]convert squad examples to features:  35%|███▌      | 417/1190 [00:02<00:05, 145.18it/s]convert squad examples to features:  38%|███▊      | 449/1190 [00:02<00:04, 163.27it/s]convert squad examples to features:  40%|████      | 481/1190 [00:02<00:04, 177.20it/s]convert squad examples to features:  43%|████▎     | 513/1190 [00:02<00:03, 192.92it/s]convert squad examples to features:  46%|████▌     | 545/1190 [00:02<00:03, 194.58it/s]convert squad examples to features:  48%|████▊     | 577/1190 [00:02<00:02, 205.12it/s]convert squad examples to features:  51%|█████     | 609/1190 [00:03<00:02, 208.01it/s]convert squad examples to features:  54%|█████▍    | 641/1190 [00:03<00:02, 186.92it/s]convert squad examples to features:  57%|█████▋    | 673/1190 [00:03<00:02, 193.08it/s]convert squad examples to features:  59%|█████▉    | 705/1190 [00:03<00:02, 203.95it/s]convert squad examples to features:  62%|██████▏   | 737/1190 [00:03<00:02, 208.41it/s]convert squad examples to features:  65%|██████▍   | 769/1190 [00:03<00:01, 222.17it/s]convert squad examples to features:  67%|██████▋   | 801/1190 [00:03<00:01, 235.61it/s]convert squad examples to features:  70%|███████   | 833/1190 [00:04<00:01, 206.55it/s]convert squad examples to features:  73%|███████▎  | 865/1190 [00:04<00:01, 221.31it/s]convert squad examples to features:  75%|███████▌  | 897/1190 [00:04<00:01, 206.53it/s]convert squad examples to features:  78%|███████▊  | 929/1190 [00:04<00:01, 202.21it/s]convert squad examples to features:  81%|████████  | 961/1190 [00:04<00:01, 207.46it/s]convert squad examples to features:  83%|████████▎ | 993/1190 [00:04<00:00, 226.06it/s]convert squad examples to features:  86%|████████▌ | 1025/1190 [00:04<00:00, 229.77it/s]convert squad examples to features:  92%|█████████▏| 1089/1190 [00:05<00:00, 253.44it/s]convert squad examples to features:  94%|█████████▍| 1121/1190 [00:05<00:00, 246.87it/s]convert squad examples to features:  97%|█████████▋| 1153/1190 [00:05<00:00, 217.35it/s]convert squad examples to features: 100%|██████████| 1190/1190 [00:05<00:00, 215.77it/s]/cluster/project/sachan/yifan/softwares/anaconda/anaconda3/envs/xfactr/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2272: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

add example index and unique id:   0%|          | 0/1190 [00:00<?, ?it/s]add example index and unique id: 100%|██████████| 1190/1190 [00:00<00:00, 955074.96it/s]
05/09/2022 19:54:13 - INFO - __main__ -   Saving features into cached file ./cached_xquad.de.json_xlm-KG_LR8e-6_EPOCH2.0_maxlen384_batchsize4_gradacc4_384_de
05/09/2022 19:54:14 - INFO - __main__ -   ***** Running evaluation  *****
05/09/2022 19:54:14 - INFO - __main__ -     Num examples = 1303
05/09/2022 19:54:14 - INFO - __main__ -     Batch size = 8
Evaluating:   0%|          | 0/163 [00:00<?, ?it/s]Evaluating:   1%|          | 1/163 [00:00<02:28,  1.09it/s]Evaluating:   1%|          | 2/163 [00:01<01:35,  1.69it/s]Evaluating:   2%|▏         | 3/163 [00:01<01:17,  2.06it/s]Evaluating:   2%|▏         | 4/163 [00:01<01:09,  2.30it/s]Evaluating:   3%|▎         | 5/163 [00:02<01:04,  2.46it/s]Evaluating:   4%|▎         | 6/163 [00:02<01:01,  2.57it/s]Evaluating:   4%|▍         | 7/163 [00:03<00:58,  2.65it/s]Evaluating:   5%|▍         | 8/163 [00:03<00:57,  2.70it/s]Evaluating:   6%|▌         | 9/163 [00:03<00:56,  2.71it/s]Evaluating:   6%|▌         | 10/163 [00:04<00:56,  2.73it/s]Evaluating:   7%|▋         | 11/163 [00:04<00:55,  2.73it/s]Evaluating:   7%|▋         | 12/163 [00:04<00:55,  2.74it/s]Evaluating:   8%|▊         | 13/163 [00:05<00:54,  2.75it/s]Evaluating:   9%|▊         | 14/163 [00:05<00:54,  2.75it/s]Evaluating:   9%|▉         | 15/163 [00:05<00:53,  2.77it/s]Evaluating:  10%|▉         | 16/163 [00:06<00:52,  2.78it/s]Evaluating:  10%|█         | 17/163 [00:06<00:52,  2.79it/s]Evaluating:  11%|█         | 18/163 [00:07<00:51,  2.80it/s]Evaluating:  12%|█▏        | 19/163 [00:07<00:51,  2.80it/s]Evaluating:  12%|█▏        | 20/163 [00:07<00:50,  2.80it/s]Evaluating:  13%|█▎        | 21/163 [00:08<00:50,  2.80it/s]Evaluating:  13%|█▎        | 22/163 [00:08<00:50,  2.81it/s]Evaluating:  14%|█▍        | 23/163 [00:08<00:49,  2.81it/s]Evaluating:  15%|█▍        | 24/163 [00:09<00:49,  2.78it/s]Evaluating:  15%|█▌        | 25/163 [00:09<00:50,  2.74it/s]Evaluating:  16%|█▌        | 26/163 [00:09<00:49,  2.76it/s]Evaluating:  17%|█▋        | 27/163 [00:10<00:49,  2.77it/s]Evaluating:  17%|█▋        | 28/163 [00:10<00:49,  2.72it/s]Evaluating:  18%|█▊        | 29/163 [00:10<00:48,  2.74it/s]Evaluating:  18%|█▊        | 30/163 [00:11<00:48,  2.76it/s]Evaluating:  19%|█▉        | 31/163 [00:11<00:47,  2.77it/s]Evaluating:  20%|█▉        | 32/163 [00:12<00:47,  2.77it/s]Evaluating:  20%|██        | 33/163 [00:12<00:46,  2.78it/s]Evaluating:  21%|██        | 34/163 [00:12<00:47,  2.73it/s]Evaluating:  21%|██▏       | 35/163 [00:13<00:46,  2.74it/s]Evaluating:  22%|██▏       | 36/163 [00:13<00:46,  2.74it/s]Evaluating:  23%|██▎       | 37/163 [00:13<00:45,  2.76it/s]Evaluating:  23%|██▎       | 38/163 [00:14<00:45,  2.76it/s]Evaluating:  24%|██▍       | 39/163 [00:14<00:44,  2.77it/s]Evaluating:  25%|██▍       | 40/163 [00:14<00:44,  2.75it/s]Evaluating:  25%|██▌       | 41/163 [00:15<00:44,  2.76it/s]Evaluating:  26%|██▌       | 42/163 [00:15<00:43,  2.77it/s]Evaluating:  26%|██▋       | 43/163 [00:16<00:43,  2.76it/s]Evaluating:  27%|██▋       | 44/163 [00:16<00:43,  2.76it/s]Evaluating:  28%|██▊       | 45/163 [00:16<00:43,  2.70it/s]Evaluating:  28%|██▊       | 46/163 [00:17<00:42,  2.72it/s]Evaluating:  29%|██▉       | 47/163 [00:17<00:42,  2.74it/s]Evaluating:  29%|██▉       | 48/163 [00:17<00:41,  2.76it/s]Evaluating:  30%|███       | 49/163 [00:18<00:41,  2.76it/s]Evaluating:  31%|███       | 50/163 [00:18<00:40,  2.77it/s]Evaluating:  31%|███▏      | 51/163 [00:18<00:40,  2.77it/s]Evaluating:  32%|███▏      | 52/163 [00:19<00:40,  2.77it/s]Evaluating:  33%|███▎      | 53/163 [00:19<00:39,  2.77it/s]Evaluating:  33%|███▎      | 54/163 [00:20<00:39,  2.76it/s]Evaluating:  34%|███▎      | 55/163 [00:20<00:39,  2.76it/s]Evaluating:  34%|███▍      | 56/163 [00:20<00:38,  2.75it/s]Evaluating:  35%|███▍      | 57/163 [00:21<00:38,  2.75it/s]Evaluating:  36%|███▌      | 58/163 [00:21<00:38,  2.73it/s]Evaluating:  36%|███▌      | 59/163 [00:21<00:38,  2.69it/s]Evaluating:  37%|███▋      | 60/163 [00:22<00:37,  2.71it/s]Evaluating:  37%|███▋      | 61/163 [00:22<00:37,  2.73it/s]Evaluating:  38%|███▊      | 62/163 [00:22<00:36,  2.74it/s]Evaluating:  39%|███▊      | 63/163 [00:23<00:36,  2.75it/s]Evaluating:  39%|███▉      | 64/163 [00:23<00:35,  2.75it/s]Evaluating:  40%|███▉      | 65/163 [00:24<00:35,  2.77it/s]Evaluating:  40%|████      | 66/163 [00:24<00:35,  2.76it/s]Evaluating:  41%|████      | 67/163 [00:24<00:34,  2.76it/s]Evaluating:  42%|████▏     | 68/163 [00:25<00:34,  2.77it/s]Evaluating:  42%|████▏     | 69/163 [00:25<00:33,  2.77it/s]Evaluating:  43%|████▎     | 70/163 [00:25<00:33,  2.77it/s]Evaluating:  44%|████▎     | 71/163 [00:26<00:33,  2.77it/s]Evaluating:  44%|████▍     | 72/163 [00:26<00:32,  2.78it/s]Evaluating:  45%|████▍     | 73/163 [00:26<00:32,  2.78it/s]Evaluating:  45%|████▌     | 74/163 [00:27<00:31,  2.78it/s]Evaluating:  46%|████▌     | 75/163 [00:27<00:31,  2.78it/s]Evaluating:  47%|████▋     | 76/163 [00:28<00:31,  2.78it/s]Evaluating:  47%|████▋     | 77/163 [00:28<00:31,  2.77it/s]Evaluating:  48%|████▊     | 78/163 [00:28<00:30,  2.77it/s]Evaluating:  48%|████▊     | 79/163 [00:29<00:30,  2.78it/s]Evaluating:  49%|████▉     | 80/163 [00:29<00:29,  2.77it/s]Evaluating:  50%|████▉     | 81/163 [00:29<00:29,  2.77it/s]Evaluating:  50%|█████     | 82/163 [00:30<00:29,  2.77it/s]Evaluating:  51%|█████     | 83/163 [00:30<00:28,  2.78it/s]Evaluating:  52%|█████▏    | 84/163 [00:30<00:28,  2.78it/s]Evaluating:  52%|█████▏    | 85/163 [00:31<00:28,  2.78it/s]Evaluating:  53%|█████▎    | 86/163 [00:31<00:27,  2.76it/s]Evaluating:  53%|█████▎    | 87/163 [00:32<00:27,  2.77it/s]Evaluating:  54%|█████▍    | 88/163 [00:32<00:27,  2.77it/s]Evaluating:  55%|█████▍    | 89/163 [00:32<00:26,  2.77it/s]Evaluating:  55%|█████▌    | 90/163 [00:33<00:26,  2.77it/s]Evaluating:  56%|█████▌    | 91/163 [00:33<00:25,  2.77it/s]Evaluating:  56%|█████▋    | 92/163 [00:33<00:25,  2.77it/s]Evaluating:  57%|█████▋    | 93/163 [00:34<00:25,  2.77it/s]Evaluating:  58%|█████▊    | 94/163 [00:34<00:24,  2.76it/s]Evaluating:  58%|█████▊    | 95/163 [00:34<00:24,  2.76it/s]Evaluating:  59%|█████▉    | 96/163 [00:35<00:24,  2.75it/s]Evaluating:  60%|█████▉    | 97/163 [00:35<00:23,  2.75it/s]Evaluating:  60%|██████    | 98/163 [00:35<00:23,  2.76it/s]Evaluating:  61%|██████    | 99/163 [00:36<00:23,  2.77it/s]Evaluating:  61%|██████▏   | 100/163 [00:36<00:22,  2.77it/s]Evaluating:  62%|██████▏   | 101/163 [00:37<00:22,  2.77it/s]Evaluating:  63%|██████▎   | 102/163 [00:37<00:22,  2.76it/s]Evaluating:  63%|██████▎   | 103/163 [00:37<00:21,  2.76it/s]Evaluating:  64%|██████▍   | 104/163 [00:38<00:21,  2.76it/s]Evaluating:  64%|██████▍   | 105/163 [00:38<00:21,  2.76it/s]Evaluating:  65%|██████▌   | 106/163 [00:38<00:20,  2.76it/s]Evaluating:  66%|██████▌   | 107/163 [00:39<00:20,  2.77it/s]Evaluating:  66%|██████▋   | 108/163 [00:39<00:19,  2.77it/s]Evaluating:  67%|██████▋   | 109/163 [00:39<00:19,  2.77it/s]Evaluating:  67%|██████▋   | 110/163 [00:40<00:19,  2.77it/s]Evaluating:  68%|██████▊   | 111/163 [00:40<00:18,  2.77it/s]Evaluating:  69%|██████▊   | 112/163 [00:41<00:18,  2.77it/s]Evaluating:  69%|██████▉   | 113/163 [00:41<00:18,  2.76it/s]Evaluating:  70%|██████▉   | 114/163 [00:41<00:17,  2.76it/s]Evaluating:  71%|███████   | 115/163 [00:42<00:17,  2.76it/s]Evaluating:  71%|███████   | 116/163 [00:42<00:17,  2.75it/s]Evaluating:  72%|███████▏  | 117/163 [00:42<00:16,  2.74it/s]Evaluating:  72%|███████▏  | 118/163 [00:43<00:16,  2.74it/s]Evaluating:  73%|███████▎  | 119/163 [00:43<00:16,  2.73it/s]Evaluating:  74%|███████▎  | 120/163 [00:43<00:15,  2.72it/s]Evaluating:  74%|███████▍  | 121/163 [00:44<00:15,  2.72it/s]Evaluating:  75%|███████▍  | 122/163 [00:44<00:14,  2.74it/s]Evaluating:  75%|███████▌  | 123/163 [00:45<00:14,  2.75it/s]Evaluating:  76%|███████▌  | 124/163 [00:45<00:14,  2.75it/s]Evaluating:  77%|███████▋  | 125/163 [00:45<00:13,  2.76it/s]Evaluating:  77%|███████▋  | 126/163 [00:46<00:13,  2.75it/s]Evaluating:  78%|███████▊  | 127/163 [00:46<00:13,  2.75it/s]Evaluating:  79%|███████▊  | 128/163 [00:46<00:12,  2.75it/s]Evaluating:  79%|███████▉  | 129/163 [00:47<00:12,  2.75it/s]Evaluating:  80%|███████▉  | 130/163 [00:47<00:12,  2.75it/s]Evaluating:  80%|████████  | 131/163 [00:47<00:11,  2.74it/s]Evaluating:  81%|████████  | 132/163 [00:48<00:11,  2.75it/s]Evaluating:  82%|████████▏ | 133/163 [00:48<00:10,  2.76it/s]Evaluating:  82%|████████▏ | 134/163 [00:49<00:10,  2.77it/s]Evaluating:  83%|████████▎ | 135/163 [00:49<00:10,  2.77it/s]Evaluating:  83%|████████▎ | 136/163 [00:49<00:09,  2.75it/s]Evaluating:  84%|████████▍ | 137/163 [00:50<00:09,  2.76it/s]Evaluating:  85%|████████▍ | 138/163 [00:50<00:09,  2.76it/s]Evaluating:  85%|████████▌ | 139/163 [00:50<00:08,  2.76it/s]Evaluating:  86%|████████▌ | 140/163 [00:51<00:08,  2.75it/s]Evaluating:  87%|████████▋ | 141/163 [00:51<00:07,  2.75it/s]Evaluating:  87%|████████▋ | 142/163 [00:51<00:07,  2.76it/s]Evaluating:  88%|████████▊ | 143/163 [00:52<00:07,  2.76it/s]Evaluating:  88%|████████▊ | 144/163 [00:52<00:06,  2.77it/s]Evaluating:  89%|████████▉ | 145/163 [00:53<00:06,  2.76it/s]Evaluating:  90%|████████▉ | 146/163 [00:53<00:06,  2.75it/s]Evaluating:  90%|█████████ | 147/163 [00:53<00:05,  2.75it/s]Evaluating:  91%|█████████ | 148/163 [00:54<00:05,  2.76it/s]Evaluating:  91%|█████████▏| 149/163 [00:54<00:05,  2.77it/s]Evaluating:  92%|█████████▏| 150/163 [00:54<00:04,  2.77it/s]Evaluating:  93%|█████████▎| 151/163 [00:55<00:04,  2.77it/s]Evaluating:  93%|█████████▎| 152/163 [00:55<00:03,  2.77it/s]Evaluating:  94%|█████████▍| 153/163 [00:55<00:03,  2.77it/s]Evaluating:  94%|█████████▍| 154/163 [00:56<00:03,  2.77it/s]Evaluating:  95%|█████████▌| 155/163 [00:56<00:02,  2.76it/s]Evaluating:  96%|█████████▌| 156/163 [00:57<00:02,  2.76it/s]Evaluating:  96%|█████████▋| 157/163 [00:57<00:02,  2.76it/s]Evaluating:  97%|█████████▋| 158/163 [00:57<00:01,  2.76it/s]Evaluating:  98%|█████████▊| 159/163 [00:58<00:01,  2.76it/s]Evaluating:  98%|█████████▊| 160/163 [00:58<00:01,  2.75it/s]Evaluating:  99%|█████████▉| 161/163 [00:58<00:00,  2.74it/s]Evaluating:  99%|█████████▉| 162/163 [00:59<00:00,  2.73it/s]Evaluating: 100%|██████████| 163/163 [00:59<00:00,  2.81it/s]Evaluating: 100%|██████████| 163/163 [00:59<00:00,  2.74it/s]
05/09/2022 19:55:14 - INFO - __main__ -     Evaluation done in total 59.540307 secs (0.045695 sec per example)
05/09/2022 19:55:18 - INFO - __main__ -   Results: {'exact': 62.773109243697476, 'f1': 79.59377694927097, 'total': 1190, 'HasAns_exact': 62.773109243697476, 'HasAns_f1': 79.59377694927097, 'HasAns_total': 1190, 'best_exact': 62.773109243697476, 'best_exact_thresh': 0.0, 'best_f1': 79.59377694927097, 'best_f1_thresh': 0.0}
  el 
2022-05-09 19:55:21.251153: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0
05/09/2022 19:55:23 - WARNING - __main__ -   Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, 16-bits training: False
You are using a model of type xlm-roberta to instantiate a model of type xlm. This is not supported for all configurations of models and can yield errors.
Some weights of the model checkpoint at /cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//squad/xlm-KG_LR8e-6_EPOCH2.0_maxlen384_batchsize4_gradacc4 were not used when initializing XLMRobertaModel: ['base_model.encoder.layer.17.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.3.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.20.output.LayerNorm.weight', 'base_model.encoder.layer.2.attention.output.dense.weight', 'base_model.encoder.layer.14.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.15.attention.self.value.weight', 'base_model.encoder.layer.15.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.22.output.dense.bias', 'base_model.encoder.layer.12.output.dense.weight', 'base_model.encoder.layer.13.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.3.attention.self.value.weight', 'base_model.encoder.layer.11.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.8.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.16.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.20.attention.output.dense.bias', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.3.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.0.intermediate.dense.weight', 'base_model.encoder.layer.11.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.0.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.12.output.LayerNorm.bias', 'base_model.encoder.layer.5.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.8.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.1.attention.self.value.weight', 'base_model.encoder.layer.6.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.13.output.LayerNorm.weight', 'base_model.encoder.layer.14.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.21.attention.self.value.bias', 'base_model.encoder.layer.18.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.13.attention.self.key.weight', 'base_model.encoder.layer.21.attention.output.LayerNorm.bias', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.11.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.18.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.20.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.20.attention.output.dense.weight', 'base_model.encoder.layer.0.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.6.attention.output.LayerNorm.bias', 'base_model.encoder.layer.10.attention.self.value.bias', 'base_model.encoder.layer.20.output.dense.weight', 'base_model.encoder.layer.1.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.2.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.5.attention.self.query.weight', 'base_model.encoder.layer.13.intermediate.dense.bias', 'base_model.encoder.layer.10.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.15.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.18.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.18.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.22.attention.output.LayerNorm.weight', 'base_model.encoder.layer.19.intermediate.dense.weight', 'base_model.encoder.layer.23.attention.output.LayerNorm.bias', 'base_model.encoder.layer.18.attention.self.value.weight', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.17.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.18.output.LayerNorm.bias', 'base_model.encoder.layer.6.intermediate.dense.weight', 'base_model.encoder.layer.7.attention.output.LayerNorm.weight', 'base_model.encoder.layer.8.attention.self.query.weight', 'base_model.encoder.layer.4.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.14.output.dense.bias', 'base_model.encoder.layer.7.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.22.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.1.attention.output.dense.bias', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.16.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.2.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.5.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.1.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.12.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.20.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.17.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.10.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.6.attention.output.dense.bias', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.2.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.12.intermediate.dense.weight', 'base_model.encoder.layer.3.attention.output.LayerNorm.weight', 'base_model.encoder.layer.8.attention.output.dense.weight', 'base_model.encoder.layer.14.attention.output.dense.weight', 'base_model.encoder.layer.19.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.10.attention.output.dense.weight', 'base_model.encoder.layer.6.attention.output.dense.weight', 'base_model.encoder.layer.22.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.22.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.16.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.1.attention.self.key.weight', 'base_model.encoder.layer.11.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.10.attention.self.query.bias', 'base_model.encoder.layer.17.output.dense.bias', 'base_model.encoder.layer.23.output.LayerNorm.weight', 'base_model.encoder.layer.23.attention.output.dense.weight', 'base_model.encoder.layer.18.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.10.output.LayerNorm.bias', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.9.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.17.output.LayerNorm.weight', 'base_model.encoder.layer.20.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.13.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.14.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.20.intermediate.dense.weight', 'base_model.encoder.layer.5.output.LayerNorm.weight', 'base_model.encoder.layer.13.attention.output.LayerNorm.bias', 'base_model.encoder.layer.7.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.6.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.16.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.embeddings.token_type_embeddings.weight', 'base_model.embeddings.LayerNorm.weight', 'base_model.encoder.layer.0.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.13.attention.output.LayerNorm.weight', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.9.output.dense.bias', 'base_model.encoder.layer.14.output.dense.weight', 'base_model.encoder.layer.2.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.21.output.LayerNorm.weight', 'base_model.encoder.layer.12.attention.self.query.weight', 'base_model.encoder.layer.19.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.16.attention.self.query.bias', 'base_model.encoder.layer.18.attention.output.dense.weight', 'base_model.encoder.layer.0.output.LayerNorm.bias', 'base_model.encoder.layer.15.output.dense.bias', 'base_model.encoder.layer.5.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.6.attention.self.value.bias', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.8.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.4.output.adapters.ts.adapter_down.0.bias', 'qa_outputs.bias', 'base_model.encoder.layer.11.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.14.intermediate.dense.bias', 'base_model.encoder.layer.7.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.18.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.0.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.0.attention.self.value.bias', 'base_model.encoder.layer.4.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.15.attention.self.query.weight', 'base_model.encoder.layer.13.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.15.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.8.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.18.attention.output.dense.bias', 'base_model.encoder.layer.11.output.LayerNorm.bias', 'base_model.encoder.layer.4.output.LayerNorm.bias', 'base_model.encoder.layer.18.output.LayerNorm.weight', 'base_model.encoder.layer.15.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.18.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.0.attention.self.value.weight', 'base_model.encoder.layer.20.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.19.attention.self.value.bias', 'base_model.encoder.layer.21.attention.self.key.bias', 'base_model.encoder.layer.7.intermediate.dense.bias', 'base_model.encoder.layer.2.attention.output.LayerNorm.bias', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.22.attention.self.value.weight', 'base_model.encoder.layer.3.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.6.intermediate.dense.bias', 'base_model.encoder.layer.6.output.LayerNorm.bias', 'base_model.encoder.layer.1.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.12.output.dense.bias', 'base_model.encoder.layer.16.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.7.attention.output.LayerNorm.bias', 'base_model.encoder.layer.2.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.12.attention.self.key.weight', 'base_model.encoder.layer.14.attention.self.query.weight', 'base_model.encoder.layer.9.attention.self.key.bias', 'base_model.encoder.layer.8.output.LayerNorm.weight', 'base_model.encoder.layer.19.output.dense.weight', 'base_model.encoder.layer.10.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.19.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.9.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.1.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.21.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.21.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.3.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.7.attention.self.value.bias', 'base_model.encoder.layer.13.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.8.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.14.attention.output.LayerNorm.bias', 'base_model.encoder.layer.14.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.0.attention.self.key.bias', 'base_model.encoder.layer.1.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.23.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.3.attention.output.LayerNorm.bias', 'base_model.encoder.layer.13.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.1.attention.output.dense.weight', 'base_model.encoder.layer.10.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.8.attention.output.LayerNorm.weight', 'base_model.encoder.layer.17.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.12.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.9.attention.output.LayerNorm.weight', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.19.attention.self.value.weight', 'base_model.encoder.layer.17.attention.self.query.bias', 'base_model.encoder.layer.11.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.13.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.21.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.6.attention.self.key.weight', 'base_model.encoder.layer.4.attention.self.value.bias', 'base_model.encoder.layer.20.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.15.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.12.attention.self.value.weight', 'base_model.encoder.layer.22.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.0.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.12.attention.output.LayerNorm.weight', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.11.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.15.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.7.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.8.attention.self.value.weight', 'base_model.encoder.layer.23.attention.self.value.weight', 'base_model.encoder.layer.22.output.adapters.ep.adapter_up.weight', 'base_model.pooler.dense.bias', 'base_model.encoder.layer.8.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.22.intermediate.dense.weight', 'base_model.encoder.layer.18.output.dense.weight', 'base_model.encoder.layer.8.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.8.output.dense.weight', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.16.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.21.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.23.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.3.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.4.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.14.attention.self.key.weight', 'base_model.encoder.layer.16.intermediate.dense.bias', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.0.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.22.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.15.attention.output.LayerNorm.weight', 'base_model.encoder.layer.22.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.17.output.LayerNorm.bias', 'base_model.encoder.layer.12.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.21.attention.output.LayerNorm.weight', 'base_model.encoder.layer.22.intermediate.dense.bias', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.1.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.19.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.1.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.19.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.1.attention.output.LayerNorm.weight', 'base_model.encoder.layer.7.attention.self.value.weight', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.8.attention.output.dense.bias', 'base_model.encoder.layer.12.attention.self.key.bias', 'base_model.encoder.layer.18.attention.self.key.bias', 'base_model.encoder.layer.10.attention.self.query.weight', 'base_model.encoder.layer.4.attention.output.LayerNorm.bias', 'base_model.encoder.layer.15.attention.output.LayerNorm.bias', 'base_model.encoder.layer.5.output.adapters.ts.adapter_up.weight', 'base_model.embeddings.word_embeddings.weight', 'base_model.encoder.layer.15.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.20.attention.self.key.weight', 'base_model.encoder.layer.23.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.8.intermediate.dense.bias', 'base_model.encoder.layer.10.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.13.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.0.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.16.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.10.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.16.attention.self.query.weight', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.3.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.18.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.9.output.dense.weight', 'base_model.encoder.layer.11.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.18.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.5.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.10.attention.output.LayerNorm.bias', 'base_model.encoder.layer.20.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.6.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.7.attention.output.dense.weight', 'base_model.encoder.layer.11.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.7.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.15.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.10.attention.self.value.weight', 'base_model.encoder.layer.5.attention.self.value.bias', 'base_model.encoder.layer.7.attention.self.query.bias', 'base_model.encoder.layer.9.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.1.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.7.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.7.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.23.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.14.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.15.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.3.attention.output.dense.weight', 'base_model.encoder.layer.19.intermediate.dense.bias', 'base_model.encoder.layer.20.attention.output.LayerNorm.weight', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.11.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.15.intermediate.dense.bias', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.17.attention.output.dense.bias', 'base_model.encoder.layer.4.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.14.intermediate.dense.weight', 'base_model.encoder.layer.12.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.3.attention.self.key.weight', 'base_model.encoder.layer.1.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.16.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.5.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.5.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.12.attention.self.value.bias', 'base_model.encoder.layer.12.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.16.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.23.output.LayerNorm.bias', 'base_model.encoder.layer.16.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.16.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.12.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.21.intermediate.dense.weight', 'base_model.encoder.layer.0.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.1.output.dense.weight', 'base_model.encoder.layer.15.output.LayerNorm.weight', 'base_model.encoder.layer.11.attention.output.LayerNorm.bias', 'base_model.encoder.layer.15.output.dense.weight', 'base_model.encoder.layer.0.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.14.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.2.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.18.output.dense.bias', 'base_model.encoder.layer.20.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.19.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.5.output.dense.weight', 'base_model.encoder.layer.0.intermediate.dense.bias', 'base_model.encoder.layer.13.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.17.output.dense.weight', 'base_model.encoder.layer.20.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.17.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.19.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.2.attention.self.query.weight', 'base_model.encoder.layer.1.output.dense.bias', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.23.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.20.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.1.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.6.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.1.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.11.output.dense.bias', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.8.attention.self.query.bias', 'base_model.encoder.layer.6.output.dense.weight', 'base_model.encoder.layer.18.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.3.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.22.attention.self.query.bias', 'base_model.pooler.dense.weight', 'base_model.encoder.layer.9.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.1.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.22.output.LayerNorm.weight', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.15.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.11.attention.self.value.bias', 'base_model.encoder.layer.9.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.13.attention.self.value.weight', 'base_model.encoder.layer.1.output.LayerNorm.weight', 'base_model.encoder.layer.11.output.dense.weight', 'base_model.encoder.layer.15.attention.self.query.bias', 'base_model.encoder.layer.17.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.21.attention.self.query.weight', 'base_model.encoder.layer.14.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.22.attention.self.value.bias', 'base_model.encoder.layer.6.output.LayerNorm.weight', 'base_model.encoder.layer.10.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.5.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.6.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.21.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.9.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.10.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.9.attention.self.value.weight', 'base_model.encoder.layer.7.output.dense.weight', 'base_model.encoder.layer.20.output.LayerNorm.bias', 'base_model.encoder.layer.23.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.6.attention.self.key.bias', 'base_model.encoder.layer.15.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.13.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.8.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.11.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.7.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.2.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.6.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.19.attention.self.query.weight', 'base_model.encoder.layer.21.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.8.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.21.output.dense.weight', 'base_model.encoder.layer.14.attention.self.value.bias', 'base_model.encoder.layer.9.attention.self.query.bias', 'base_model.encoder.layer.4.attention.self.value.weight', 'base_model.encoder.layer.7.output.LayerNorm.bias', 'base_model.encoder.layer.0.attention.output.LayerNorm.bias', 'base_model.encoder.layer.3.output.LayerNorm.weight', 'base_model.encoder.layer.16.intermediate.dense.weight', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.20.attention.self.value.weight', 'base_model.encoder.layer.14.output.LayerNorm.weight', 'base_model.encoder.layer.23.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.9.output.LayerNorm.bias', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.13.attention.output.dense.bias', 'base_model.encoder.layer.13.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.14.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.21.attention.self.query.bias', 'base_model.encoder.layer.13.attention.self.query.weight', 'base_model.encoder.layer.2.output.LayerNorm.weight', 'base_model.encoder.layer.8.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.23.attention.self.key.bias', 'base_model.encoder.layer.9.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.7.attention.self.key.weight', 'base_model.encoder.layer.0.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.10.output.dense.weight', 'base_model.encoder.layer.17.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.20.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.6.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.14.attention.output.dense.bias', 'base_model.encoder.layer.21.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.5.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.20.attention.self.key.bias', 'base_model.encoder.layer.3.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.6.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.11.intermediate.dense.weight', 'base_model.encoder.layer.11.attention.self.key.bias', 'base_model.encoder.layer.2.attention.self.value.weight', 'base_model.encoder.layer.13.attention.self.query.bias', 'base_model.encoder.layer.0.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.17.attention.output.LayerNorm.bias', 'base_model.encoder.layer.11.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.19.attention.output.LayerNorm.bias', 'base_model.encoder.layer.20.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.20.output.dense.bias', 'base_model.encoder.layer.3.attention.self.key.bias', 'base_model.encoder.layer.0.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.21.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.19.attention.self.key.bias', 'base_model.encoder.layer.3.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.9.output.LayerNorm.weight', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.23.attention.self.value.bias', 'base_model.encoder.layer.8.intermediate.dense.weight', 'base_model.encoder.layer.2.attention.self.value.bias', 'base_model.encoder.layer.10.intermediate.dense.bias', 'base_model.encoder.layer.17.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.16.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.4.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.20.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.1.attention.self.key.bias', 'base_model.encoder.layer.14.attention.self.value.weight', 'base_model.encoder.layer.15.intermediate.dense.weight', 'base_model.encoder.layer.6.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.22.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.5.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.14.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.10.attention.output.dense.bias', 'base_model.encoder.layer.18.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.10.attention.self.key.bias', 'base_model.encoder.layer.23.attention.self.key.weight', 'base_model.encoder.layer.4.intermediate.dense.bias', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.14.output.LayerNorm.bias', 'base_model.encoder.layer.16.attention.self.key.bias', 'base_model.encoder.layer.9.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.10.attention.self.key.weight', 'base_model.encoder.layer.12.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.18.attention.output.LayerNorm.bias', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.1.attention.self.query.bias', 'base_model.encoder.layer.12.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.6.attention.self.query.bias', 'base_model.encoder.layer.12.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.16.output.LayerNorm.weight', 'base_model.encoder.layer.19.attention.output.dense.bias', 'base_model.encoder.layer.18.attention.self.key.weight', 'base_model.encoder.layer.9.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.17.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.0.output.LayerNorm.weight', 'base_model.encoder.layer.21.output.LayerNorm.bias', 'base_model.encoder.layer.14.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.4.output.dense.weight', 'base_model.encoder.layer.22.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.22.attention.output.dense.bias', 'base_model.encoder.layer.9.attention.self.value.bias', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.7.output.dense.bias', 'base_model.encoder.layer.13.output.dense.weight', 'base_model.encoder.layer.0.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.16.attention.output.dense.weight', 'base_model.encoder.layer.7.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.23.output.dense.bias', 'base_model.encoder.layer.16.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.2.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.4.attention.output.dense.weight', 'base_model.encoder.layer.21.attention.self.key.weight', 'base_model.encoder.layer.8.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.20.attention.self.query.weight', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.0.attention.output.LayerNorm.weight', 'base_model.encoder.layer.15.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.6.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.23.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.15.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.16.attention.self.value.weight', 'base_model.encoder.layer.5.attention.self.key.bias', 'base_model.encoder.layer.18.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.8.output.LayerNorm.bias', 'base_model.encoder.layer.2.attention.output.dense.bias', 'base_model.encoder.layer.7.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.5.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.3.output.LayerNorm.bias', 'base_model.encoder.layer.15.attention.self.key.weight', 'base_model.encoder.layer.8.attention.self.key.bias', 'base_model.encoder.layer.19.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.23.attention.self.query.weight', 'base_model.encoder.layer.2.intermediate.dense.weight', 'base_model.encoder.layer.10.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.11.attention.self.query.weight', 'base_model.encoder.layer.2.output.LayerNorm.bias', 'base_model.encoder.layer.4.attention.self.key.bias', 'base_model.encoder.layer.2.output.dense.bias', 'base_model.encoder.layer.5.attention.output.LayerNorm.bias', 'base_model.encoder.layer.5.output.LayerNorm.bias', 'base_model.encoder.layer.7.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.14.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.19.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.3.intermediate.dense.bias', 'base_model.encoder.layer.4.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.23.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.3.output.dense.bias', 'base_model.encoder.layer.6.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.9.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.10.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.8.attention.self.key.weight', 'base_model.encoder.layer.18.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.19.attention.self.key.weight', 'base_model.encoder.layer.6.attention.self.value.weight', 'base_model.encoder.layer.5.intermediate.dense.bias', 'base_model.encoder.layer.10.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.17.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.20.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.15.attention.output.dense.bias', 'base_model.encoder.layer.4.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.19.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.7.attention.output.dense.bias', 'base_model.encoder.layer.10.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.15.output.LayerNorm.bias', 'base_model.encoder.layer.15.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.12.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.1.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.10.intermediate.dense.weight', 'base_model.encoder.layer.17.intermediate.dense.weight', 'base_model.encoder.layer.11.attention.output.LayerNorm.weight', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.4.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.23.attention.output.LayerNorm.weight', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.3.attention.self.query.bias', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.18.attention.self.value.bias', 'base_model.encoder.layer.17.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.13.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.17.attention.output.LayerNorm.weight', 'base_model.encoder.layer.3.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.15.attention.self.value.bias', 'base_model.encoder.layer.6.attention.self.query.weight', 'base_model.encoder.layer.19.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.21.attention.output.dense.bias', 'base_model.encoder.layer.0.attention.output.dense.weight', 'base_model.encoder.layer.12.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.13.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.6.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.11.attention.self.key.weight', 'base_model.encoder.layer.2.attention.self.key.bias', 'base_model.encoder.layer.12.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.0.attention.self.query.bias', 'base_model.encoder.layer.8.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.10.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.4.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.13.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.19.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.22.attention.output.dense.weight', 'base_model.encoder.layer.2.attention.self.query.bias', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.21.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.11.attention.output.dense.weight', 'base_model.encoder.layer.8.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.9.intermediate.dense.weight', 'base_model.encoder.layer.9.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.22.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.9.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.2.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.21.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.7.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.17.attention.self.key.bias', 'base_model.encoder.layer.21.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.9.intermediate.dense.bias', 'base_model.encoder.layer.9.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.23.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.3.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.9.attention.output.dense.bias', 'base_model.encoder.layer.4.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.17.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.5.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.15.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.4.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.16.attention.self.value.bias', 'base_model.encoder.layer.13.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.12.attention.output.dense.bias', 'base_model.encoder.layer.19.output.LayerNorm.weight', 'base_model.encoder.layer.5.attention.self.query.bias', 'base_model.encoder.layer.4.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.5.attention.output.LayerNorm.weight', 'base_model.encoder.layer.18.attention.self.query.bias', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.19.attention.output.LayerNorm.weight', 'base_model.encoder.layer.2.output.dense.weight', 'base_model.encoder.layer.12.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.6.output.dense.bias', 'base_model.encoder.layer.6.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.1.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.14.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.20.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.5.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.13.attention.self.value.bias', 'base_model.encoder.layer.13.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.11.attention.self.value.weight', 'base_model.encoder.layer.1.intermediate.dense.weight', 'base_model.encoder.layer.4.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.14.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.19.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.3.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.23.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.20.intermediate.dense.bias', 'base_model.encoder.layer.9.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.11.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.3.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.22.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.1.attention.self.value.bias', 'base_model.encoder.layer.20.attention.self.value.bias', 'base_model.encoder.layer.5.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.21.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.21.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.2.intermediate.dense.bias', 'base_model.encoder.layer.22.output.LayerNorm.bias', 'base_model.encoder.layer.7.attention.self.key.bias', 'base_model.encoder.layer.4.attention.self.key.weight', 'base_model.encoder.layer.17.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.15.attention.self.key.bias', 'base_model.encoder.layer.5.attention.self.key.weight', 'base_model.encoder.layer.16.attention.output.dense.bias', 'base_model.embeddings.position_ids', 'base_model.encoder.layer.7.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.19.attention.self.query.bias', 'base_model.encoder.layer.4.attention.output.LayerNorm.weight', 'base_model.encoder.layer.22.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.0.attention.output.dense.bias', 'base_model.encoder.layer.0.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.1.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.17.attention.self.value.weight', 'base_model.encoder.layer.22.attention.self.key.bias', 'base_model.encoder.layer.4.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.10.output.LayerNorm.weight', 'base_model.encoder.layer.17.attention.self.key.weight', 'base_model.encoder.layer.21.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.7.output.LayerNorm.weight', 'base_model.encoder.layer.7.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.11.attention.output.dense.bias', 'base_model.encoder.layer.9.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.18.attention.output.LayerNorm.weight', 'base_model.encoder.layer.16.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.14.attention.output.LayerNorm.weight', 'base_model.encoder.layer.18.intermediate.dense.bias', 'base_model.encoder.layer.5.intermediate.dense.weight', 'base_model.encoder.layer.3.attention.self.value.bias', 'base_model.encoder.layer.2.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.9.attention.self.key.weight', 'base_model.encoder.layer.16.attention.output.LayerNorm.weight', 'base_model.encoder.layer.14.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.7.attention.self.query.weight', 'base_model.encoder.layer.15.attention.output.dense.weight', 'base_model.encoder.layer.23.intermediate.dense.bias', 'base_model.encoder.layer.2.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.13.output.dense.bias', 'base_model.embeddings.position_embeddings.weight', 'base_model.encoder.layer.12.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.5.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.3.attention.output.dense.bias', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.3.attention.self.query.weight', 'base_model.encoder.layer.12.attention.output.dense.weight', 'base_model.encoder.layer.20.attention.self.query.bias', 'base_model.encoder.layer.16.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.0.attention.self.key.weight', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.12.output.LayerNorm.weight', 'base_model.encoder.layer.13.output.LayerNorm.bias', 'base_model.encoder.layer.11.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.1.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.2.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.16.output.LayerNorm.bias', 'base_model.encoder.layer.2.output.adapters.ts.adapter_up.bias', 'qa_outputs.weight', 'base_model.encoder.layer.4.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.20.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.23.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.17.attention.self.value.bias', 'base_model.encoder.layer.5.output.dense.bias', 'base_model.encoder.layer.16.output.dense.weight', 'base_model.encoder.layer.2.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.4.attention.output.dense.bias', 'base_model.encoder.layer.4.intermediate.dense.weight', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.6.attention.output.LayerNorm.weight', 'base_model.encoder.layer.17.attention.output.dense.weight', 'base_model.encoder.layer.16.attention.self.key.weight', 'base_model.encoder.layer.22.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.21.attention.output.dense.weight', 'base_model.encoder.layer.5.attention.output.dense.weight', 'base_model.encoder.layer.11.attention.self.query.bias', 'base_model.encoder.layer.19.output.dense.bias', 'base_model.encoder.layer.18.intermediate.dense.weight', 'base_model.encoder.layer.14.attention.self.query.bias', 'base_model.encoder.layer.20.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.23.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.22.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.5.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.23.attention.output.dense.bias', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.2.attention.output.LayerNorm.weight', 'base_model.encoder.layer.12.attention.self.query.bias', 'base_model.encoder.layer.3.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.8.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.18.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.5.attention.output.dense.bias', 'base_model.encoder.layer.22.output.dense.weight', 'base_model.encoder.layer.6.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.23.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.10.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.9.attention.output.dense.weight', 'base_model.encoder.layer.1.output.LayerNorm.bias', 'base_model.encoder.layer.16.output.dense.bias', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.3.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.12.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.11.intermediate.dense.bias', 'base_model.encoder.layer.13.intermediate.dense.weight', 'base_model.encoder.layer.21.output.dense.bias', 'base_model.encoder.layer.23.output.dense.weight', 'base_model.encoder.layer.0.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.8.attention.output.LayerNorm.bias', 'base_model.encoder.layer.17.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.11.output.LayerNorm.weight', 'base_model.encoder.layer.19.output.LayerNorm.bias', 'base_model.encoder.layer.12.intermediate.dense.bias', 'base_model.encoder.layer.21.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.19.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.1.attention.output.LayerNorm.bias', 'base_model.encoder.layer.7.intermediate.dense.weight', 'base_model.encoder.layer.23.attention.self.query.bias', 'base_model.encoder.layer.5.attention.self.value.weight', 'base_model.encoder.layer.20.attention.output.LayerNorm.bias', 'base_model.encoder.layer.3.output.dense.weight', 'base_model.encoder.layer.1.intermediate.dense.bias', 'base_model.encoder.layer.18.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.22.attention.output.LayerNorm.bias', 'base_model.encoder.layer.11.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.10.output.dense.bias', 'base_model.encoder.layer.14.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.17.attention.self.query.weight', 'base_model.encoder.layer.17.intermediate.dense.bias', 'base_model.encoder.layer.7.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.16.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.6.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.0.output.dense.bias', 'base_model.encoder.layer.14.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.8.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.19.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.23.intermediate.dense.weight', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.2.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.18.attention.self.query.weight', 'base_model.encoder.layer.4.output.LayerNorm.weight', 'base_model.encoder.layer.19.attention.output.dense.weight', 'base_model.encoder.layer.12.attention.output.LayerNorm.bias', 'base_model.encoder.layer.21.intermediate.dense.bias', 'base_model.encoder.layer.9.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.7.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.3.intermediate.dense.weight', 'base_model.encoder.layer.8.attention.self.value.bias', 'base_model.encoder.layer.22.attention.self.query.weight', 'base_model.encoder.layer.0.attention.self.query.weight', 'base_model.encoder.layer.8.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.6.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.14.attention.self.key.bias', 'base_model.encoder.layer.22.attention.self.key.weight', 'base_model.encoder.layer.4.attention.self.query.weight', 'base_model.encoder.layer.17.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.1.attention.self.query.weight', 'base_model.encoder.layer.9.attention.output.LayerNorm.bias', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.10.attention.output.LayerNorm.weight', 'base_model.encoder.layer.21.attention.self.value.weight', 'base_model.encoder.layer.10.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.13.attention.output.dense.weight', 'base_model.encoder.layer.0.output.dense.weight', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.21.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.11.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.2.attention.self.key.weight', 'base_model.embeddings.LayerNorm.bias', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.13.attention.self.key.bias', 'base_model.encoder.layer.18.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.16.attention.output.LayerNorm.bias', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.22.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.15.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.3.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.4.output.dense.bias', 'base_model.encoder.layer.23.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.2.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.12.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.9.attention.self.query.weight', 'base_model.encoder.layer.8.output.dense.bias', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.22.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.4.attention.self.query.bias', 'base_model.encoder.layer.13.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.19.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.17.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.0.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.10.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.23.output.adapters.tp.adapter_down.0.weight']
- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of XLMRobertaModel were not initialized from the model checkpoint at /cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//squad/xlm-KG_LR8e-6_EPOCH2.0_maxlen384_batchsize4_gradacc4 and are newly initialized: ['encoder.layer.11.attention.self.key.bias', 'encoder.layer.18.attention.self.value.bias', 'encoder.layer.13.intermediate.dense.weight', 'encoder.layer.12.attention.output.LayerNorm.bias', 'encoder.layer.22.output.dense.bias', 'encoder.layer.5.attention.self.value.bias', 'encoder.layer.21.output.dense.weight', 'encoder.layer.3.attention.self.value.weight', 'encoder.layer.3.attention.output.dense.bias', 'encoder.layer.23.attention.self.key.bias', 'encoder.layer.20.output.LayerNorm.bias', 'encoder.layer.17.attention.self.value.bias', 'encoder.layer.13.attention.output.dense.weight', 'encoder.layer.11.attention.output.dense.weight', 'encoder.layer.19.attention.self.query.weight', 'encoder.layer.0.attention.self.value.weight', 'encoder.layer.18.attention.self.query.bias', 'encoder.layer.5.output.dense.bias', 'encoder.layer.7.attention.output.dense.weight', 'encoder.layer.21.output.LayerNorm.weight', 'encoder.layer.22.output.dense.weight', 'encoder.layer.12.attention.self.key.bias', 'encoder.layer.9.attention.output.dense.bias', 'encoder.layer.21.output.LayerNorm.bias', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.1.attention.self.key.weight', 'encoder.layer.9.attention.self.query.bias', 'encoder.layer.6.output.LayerNorm.bias', 'encoder.layer.14.attention.self.key.bias', 'pooler.dense.bias', 'encoder.layer.5.attention.self.key.weight', 'encoder.layer.9.attention.self.value.bias', 'encoder.layer.5.attention.output.LayerNorm.weight', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.7.output.dense.bias', 'encoder.layer.16.intermediate.dense.weight', 'encoder.layer.20.attention.self.key.bias', 'embeddings.LayerNorm.bias', 'encoder.layer.19.attention.output.LayerNorm.bias', 'encoder.layer.1.attention.self.query.weight', 'encoder.layer.6.attention.self.key.weight', 'encoder.layer.4.attention.self.query.weight', 'encoder.layer.6.attention.output.dense.bias', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.3.attention.self.key.bias', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.15.attention.self.query.bias', 'encoder.layer.3.output.dense.bias', 'encoder.layer.3.attention.output.dense.weight', 'encoder.layer.23.attention.output.LayerNorm.weight', 'encoder.layer.1.output.dense.bias', 'encoder.layer.19.output.LayerNorm.bias', 'embeddings.word_embeddings.weight', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.17.attention.self.value.weight', 'encoder.layer.17.attention.output.dense.bias', 'encoder.layer.12.attention.self.value.weight', 'encoder.layer.10.attention.output.dense.weight', 'encoder.layer.22.attention.self.key.weight', 'encoder.layer.2.attention.self.query.bias', 'encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.12.attention.self.key.weight', 'encoder.layer.22.attention.output.dense.weight', 'encoder.layer.16.attention.self.query.weight', 'encoder.layer.14.attention.output.LayerNorm.weight', 'encoder.layer.13.output.LayerNorm.bias', 'encoder.layer.16.attention.self.value.bias', 'encoder.layer.15.output.dense.weight', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.17.attention.self.query.weight', 'encoder.layer.3.attention.self.value.bias', 'encoder.layer.17.output.dense.weight', 'encoder.layer.19.attention.output.LayerNorm.weight', 'encoder.layer.13.output.dense.weight', 'encoder.layer.22.attention.self.query.bias', 'encoder.layer.23.attention.output.LayerNorm.bias', 'encoder.layer.16.output.LayerNorm.bias', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.13.attention.self.query.bias', 'encoder.layer.4.attention.self.query.bias', 'encoder.layer.22.attention.self.value.bias', 'encoder.layer.23.attention.self.value.weight', 'encoder.layer.16.attention.self.query.bias', 'encoder.layer.18.attention.output.dense.bias', 'encoder.layer.12.attention.output.dense.weight', 'encoder.layer.15.attention.output.LayerNorm.bias', 'encoder.layer.15.attention.output.dense.weight', 'encoder.layer.22.output.LayerNorm.bias', 'encoder.layer.4.output.dense.bias', 'encoder.layer.18.attention.self.key.bias', 'encoder.layer.14.attention.self.value.weight', 'encoder.layer.23.attention.output.dense.bias', 'encoder.layer.16.attention.self.key.bias', 'encoder.layer.20.attention.output.dense.weight', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.9.attention.self.query.weight', 'encoder.layer.10.attention.self.query.weight', 'encoder.layer.8.attention.self.query.weight', 'encoder.layer.21.attention.output.dense.bias', 'encoder.layer.11.attention.self.key.weight', 'encoder.layer.12.output.dense.weight', 'encoder.layer.22.attention.self.query.weight', 'encoder.layer.14.attention.output.dense.weight', 'encoder.layer.1.attention.self.query.bias', 'encoder.layer.11.attention.self.value.weight', 'encoder.layer.13.attention.self.query.weight', 'encoder.layer.10.output.LayerNorm.bias', 'encoder.layer.16.attention.output.dense.weight', 'encoder.layer.19.intermediate.dense.bias', 'encoder.layer.20.attention.self.query.bias', 'encoder.layer.7.output.dense.weight', 'encoder.layer.11.output.LayerNorm.weight', 'encoder.layer.15.attention.output.dense.bias', 'encoder.layer.9.attention.self.value.weight', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.14.output.LayerNorm.bias', 'encoder.layer.23.intermediate.dense.bias', 'encoder.layer.19.attention.output.dense.weight', 'encoder.layer.0.output.dense.bias', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.11.output.dense.bias', 'encoder.layer.22.attention.output.dense.bias', 'encoder.layer.21.attention.output.dense.weight', 'encoder.layer.9.output.dense.weight', 'encoder.layer.0.output.dense.weight', 'encoder.layer.18.intermediate.dense.bias', 'encoder.layer.9.attention.self.key.weight', 'encoder.layer.2.attention.output.LayerNorm.bias', 'encoder.layer.4.attention.output.LayerNorm.bias', 'encoder.layer.6.attention.self.query.weight', 'encoder.layer.10.output.dense.weight', 'encoder.layer.15.output.dense.bias', 'encoder.layer.20.attention.self.query.weight', 'encoder.layer.17.intermediate.dense.weight', 'encoder.layer.8.attention.output.dense.bias', 'encoder.layer.22.intermediate.dense.weight', 'encoder.layer.13.attention.self.key.weight', 'encoder.layer.19.output.dense.weight', 'encoder.layer.3.attention.self.query.bias', 'embeddings.LayerNorm.weight', 'encoder.layer.6.output.dense.weight', 'encoder.layer.17.attention.self.query.bias', 'encoder.layer.2.output.dense.bias', 'encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.layer.10.attention.output.LayerNorm.weight', 'encoder.layer.9.attention.output.dense.weight', 'encoder.layer.14.output.dense.bias', 'encoder.layer.4.attention.output.dense.bias', 'encoder.layer.13.attention.self.key.bias', 'encoder.layer.20.output.LayerNorm.weight', 'encoder.layer.17.attention.self.key.bias', 'encoder.layer.7.attention.self.key.weight', 'encoder.layer.19.output.dense.bias', 'encoder.layer.5.attention.output.dense.weight', 'encoder.layer.6.attention.self.value.bias', 'encoder.layer.14.output.dense.weight', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.10.output.dense.bias', 'encoder.layer.23.attention.self.key.weight', 'encoder.layer.4.attention.output.dense.weight', 'encoder.layer.18.output.LayerNorm.weight', 'encoder.layer.8.attention.self.key.weight', 'encoder.layer.19.attention.self.key.weight', 'encoder.layer.21.output.dense.bias', 'encoder.layer.19.intermediate.dense.weight', 'encoder.layer.6.attention.self.query.bias', 'encoder.layer.14.attention.self.key.weight', 'encoder.layer.22.attention.self.key.bias', 'encoder.layer.19.attention.self.query.bias', 'encoder.layer.22.attention.self.value.weight', 'encoder.layer.0.attention.self.value.bias', 'encoder.layer.21.intermediate.dense.bias', 'encoder.layer.6.attention.self.value.weight', 'encoder.layer.17.output.dense.bias', 'encoder.layer.4.attention.self.value.bias', 'encoder.layer.17.intermediate.dense.bias', 'encoder.layer.0.attention.self.key.bias', 'encoder.layer.12.output.LayerNorm.bias', 'encoder.layer.11.attention.output.LayerNorm.weight', 'encoder.layer.18.attention.output.LayerNorm.bias', 'encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.layer.15.output.LayerNorm.weight', 'encoder.layer.15.output.LayerNorm.bias', 'encoder.layer.14.attention.self.query.bias', 'encoder.layer.21.attention.self.query.bias', 'encoder.layer.3.attention.self.query.weight', 'encoder.layer.16.attention.output.dense.bias', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.9.output.LayerNorm.weight', 'encoder.layer.19.attention.self.value.bias', 'encoder.layer.5.attention.self.key.bias', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.14.output.LayerNorm.weight', 'encoder.layer.20.attention.self.key.weight', 'encoder.layer.1.attention.output.dense.weight', 'encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.22.intermediate.dense.bias', 'encoder.layer.18.output.dense.bias', 'encoder.layer.16.output.LayerNorm.weight', 'encoder.layer.4.attention.self.key.weight', 'encoder.layer.11.attention.self.query.weight', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.20.output.dense.weight', 'encoder.layer.22.attention.output.LayerNorm.weight', 'encoder.layer.21.intermediate.dense.weight', 'embeddings.token_type_embeddings.weight', 'encoder.layer.15.intermediate.dense.weight', 'encoder.layer.8.attention.self.query.bias', 'encoder.layer.0.attention.output.dense.bias', 'encoder.layer.2.attention.self.value.weight', 'encoder.layer.12.attention.output.dense.bias', 'encoder.layer.18.attention.output.dense.weight', 'encoder.layer.16.attention.output.LayerNorm.bias', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.6.attention.output.LayerNorm.bias', 'encoder.layer.2.attention.output.dense.weight', 'encoder.layer.10.attention.self.query.bias', 'encoder.layer.20.attention.output.LayerNorm.weight', 'encoder.layer.16.attention.self.key.weight', 'encoder.layer.14.attention.self.value.bias', 'encoder.layer.21.attention.self.value.weight', 'encoder.layer.10.attention.output.LayerNorm.bias', 'encoder.layer.13.attention.output.LayerNorm.bias', 'encoder.layer.5.attention.self.value.weight', 'encoder.layer.5.output.LayerNorm.bias', 'encoder.layer.12.output.LayerNorm.weight', 'encoder.layer.3.output.dense.weight', 'encoder.layer.18.attention.output.LayerNorm.weight', 'encoder.layer.13.attention.output.dense.bias', 'encoder.layer.12.attention.self.query.weight', 'encoder.layer.18.output.dense.weight', 'encoder.layer.18.attention.self.key.weight', 'encoder.layer.5.output.dense.weight', 'encoder.layer.11.output.dense.weight', 'encoder.layer.23.output.LayerNorm.bias', 'encoder.layer.7.attention.self.query.weight', 'encoder.layer.14.attention.output.LayerNorm.bias', 'encoder.layer.14.attention.self.query.weight', 'encoder.layer.1.attention.self.value.weight', 'encoder.layer.22.attention.output.LayerNorm.bias', 'encoder.layer.7.intermediate.dense.bias', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.16.output.dense.bias', 'encoder.layer.18.output.LayerNorm.bias', 'encoder.layer.21.attention.output.LayerNorm.weight', 'encoder.layer.2.attention.self.key.bias', 'encoder.layer.20.attention.self.value.weight', 'encoder.layer.13.attention.output.LayerNorm.weight', 'encoder.layer.15.attention.output.LayerNorm.weight', 'encoder.layer.12.attention.self.query.bias', 'encoder.layer.23.output.LayerNorm.weight', 'encoder.layer.22.output.LayerNorm.weight', 'encoder.layer.23.attention.self.query.bias', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.13.intermediate.dense.bias', 'encoder.layer.20.output.dense.bias', 'encoder.layer.12.intermediate.dense.bias', 'encoder.layer.10.attention.self.key.weight', 'encoder.layer.21.attention.self.query.weight', 'encoder.layer.7.output.LayerNorm.bias', 'encoder.layer.11.output.LayerNorm.bias', 'encoder.layer.20.intermediate.dense.bias', 'encoder.layer.17.attention.self.key.weight', 'encoder.layer.21.attention.output.LayerNorm.bias', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.8.output.LayerNorm.bias', 'encoder.layer.7.output.LayerNorm.weight', 'encoder.layer.16.output.dense.weight', 'encoder.layer.10.output.LayerNorm.weight', 'encoder.layer.15.attention.self.key.bias', 'encoder.layer.7.attention.output.LayerNorm.weight', 'encoder.layer.2.output.dense.weight', 'encoder.layer.7.attention.output.LayerNorm.bias', 'encoder.layer.23.attention.output.dense.weight', 'encoder.layer.8.attention.output.LayerNorm.bias', 'encoder.layer.20.attention.output.LayerNorm.bias', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.4.attention.self.key.bias', 'encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.layer.10.attention.output.dense.bias', 'encoder.layer.5.attention.output.dense.bias', 'encoder.layer.2.attention.self.query.weight', 'encoder.layer.1.attention.self.key.bias', 'encoder.layer.13.attention.self.value.weight', 'encoder.layer.8.output.dense.bias', 'encoder.layer.8.output.LayerNorm.weight', 'encoder.layer.9.output.LayerNorm.bias', 'encoder.layer.20.attention.output.dense.bias', 'encoder.layer.13.output.LayerNorm.weight', 'encoder.layer.11.attention.self.value.bias', 'encoder.layer.12.output.dense.bias', 'encoder.layer.0.attention.output.dense.weight', 'encoder.layer.5.attention.self.query.bias', 'encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.layer.15.attention.self.value.weight', 'encoder.layer.19.attention.output.dense.bias', 'encoder.layer.16.attention.output.LayerNorm.weight', 'encoder.layer.9.attention.output.LayerNorm.bias', 'encoder.layer.19.attention.self.value.weight', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.0.attention.output.LayerNorm.weight', 'encoder.layer.12.intermediate.dense.weight', 'encoder.layer.4.attention.output.LayerNorm.weight', 'encoder.layer.18.attention.self.query.weight', 'encoder.layer.2.attention.output.LayerNorm.weight', 'encoder.layer.2.attention.output.dense.bias', 'encoder.layer.7.attention.self.query.bias', 'encoder.layer.1.attention.self.value.bias', 'encoder.layer.8.attention.output.dense.weight', 'encoder.layer.6.attention.output.dense.weight', 'encoder.layer.4.output.dense.weight', 'encoder.layer.19.attention.self.key.bias', 'encoder.layer.8.attention.output.LayerNorm.weight', 'encoder.layer.18.intermediate.dense.weight', 'encoder.layer.1.output.dense.weight', 'encoder.layer.17.attention.output.LayerNorm.weight', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.13.attention.self.value.bias', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.15.intermediate.dense.bias', 'encoder.layer.15.attention.self.key.weight', 'encoder.layer.8.attention.self.key.bias', 'encoder.layer.21.attention.self.key.bias', 'encoder.layer.1.attention.output.dense.bias', 'encoder.layer.15.attention.self.query.weight', 'encoder.layer.9.attention.self.key.bias', 'encoder.layer.10.intermediate.dense.weight', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.0.attention.self.query.bias', 'encoder.layer.23.intermediate.dense.weight', 'encoder.layer.17.output.LayerNorm.bias', 'encoder.layer.6.output.dense.bias', 'encoder.layer.9.output.dense.bias', 'encoder.layer.7.attention.output.dense.bias', 'encoder.layer.8.output.dense.weight', 'encoder.layer.11.attention.output.dense.bias', 'encoder.layer.10.attention.self.value.weight', 'encoder.layer.6.attention.output.LayerNorm.weight', 'encoder.layer.17.output.LayerNorm.weight', 'encoder.layer.2.attention.self.value.bias', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.8.attention.self.value.weight', 'encoder.layer.17.attention.output.LayerNorm.bias', 'encoder.layer.23.output.dense.weight', 'encoder.layer.10.attention.self.value.bias', 'encoder.layer.7.attention.self.value.bias', 'encoder.layer.10.attention.self.key.bias', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.23.attention.self.value.bias', 'encoder.layer.14.attention.output.dense.bias', 'encoder.layer.17.attention.output.dense.weight', 'encoder.layer.12.attention.output.LayerNorm.weight', 'encoder.layer.20.intermediate.dense.weight', 'encoder.layer.12.attention.self.value.bias', 'encoder.layer.14.intermediate.dense.bias', 'encoder.layer.2.attention.self.key.weight', 'encoder.layer.13.output.dense.bias', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.15.attention.self.value.bias', 'pooler.dense.weight', 'encoder.layer.0.output.LayerNorm.weight', 'embeddings.position_embeddings.weight', 'encoder.layer.0.attention.self.key.weight', 'encoder.layer.9.attention.output.LayerNorm.weight', 'encoder.layer.11.attention.self.query.bias', 'encoder.layer.18.attention.self.value.weight', 'encoder.layer.16.attention.self.value.weight', 'encoder.layer.21.attention.self.value.bias', 'encoder.layer.1.attention.output.LayerNorm.weight', 'encoder.layer.23.attention.self.query.weight', 'encoder.layer.5.attention.self.query.weight', 'encoder.layer.19.output.LayerNorm.weight', 'encoder.layer.16.intermediate.dense.bias', 'encoder.layer.23.output.dense.bias', 'encoder.layer.0.attention.self.query.weight', 'encoder.layer.8.attention.self.value.bias', 'encoder.layer.14.intermediate.dense.weight', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.6.attention.self.key.bias', 'encoder.layer.4.attention.self.value.weight', 'encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.layer.7.attention.self.value.weight', 'encoder.layer.21.attention.self.key.weight', 'encoder.layer.7.attention.self.key.bias', 'encoder.layer.20.attention.self.value.bias', 'encoder.layer.3.attention.self.key.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Overwriting existing adapter 'ep'.
Overwriting existing adapter 'tp'.
Overwriting existing adapter 'es'.
Overwriting existing adapter 'ts'.
Overwriting existing adapter fusion module 'ep,tp,es,ts'
05/09/2022 19:55:53 - INFO - __main__ -   lang2id = None
05/09/2022 19:55:56 - INFO - __main__ -   Training/evaluation parameters Namespace(adam_epsilon=1e-08, cache_dir='', config_name='', data_dir=None, device=device(type='cuda'), do_eval=True, do_lower_case=False, do_train=False, doc_stride=128, eval_all_checkpoints=False, eval_lang='el', evaluate_during_training=False, fp16=False, fp16_opt_level='O1', gradient_accumulation_steps=1, learning_rate=5e-05, local_rank=-1, logging_steps=50, max_answer_length=30, max_grad_norm=1.0, max_query_length=64, max_seq_length=384, max_steps=-1, model_name='xlm-KG', model_name_or_path='/cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//squad/xlm-KG_LR8e-6_EPOCH2.0_maxlen384_batchsize4_gradacc4', model_type='xlm', modelkg_dir='/cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/adapter/xlmr_adapter', n_best_size=20, n_gpu=1, no_cuda=False, null_score_diff_threshold=0.0, num_train_epochs=3.0, output_dir='/cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//squad/xlm-KG_LR8e-6_EPOCH2.0_maxlen384_batchsize4_gradacc4/predictions/xquad/', overwrite_cache=False, overwrite_output_dir=False, per_gpu_eval_batch_size=8, per_gpu_train_batch_size=8, predict_file='/cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/download//xquad//xquad.el.json', save_steps=50, seed=42, server_ip='', server_port='', threads=1, tokenizer_name='', train_file=None, train_lang='en', verbose_logging=False, version_2_with_negative=False, warmup_steps=0, weight_decay=0.0)
05/09/2022 19:55:56 - INFO - __main__ -   Loading checkpoint /cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//squad/xlm-KG_LR8e-6_EPOCH2.0_maxlen384_batchsize4_gradacc4 for evaluation
05/09/2022 19:55:56 - INFO - __main__ -   Evaluate the following checkpoints: ['/cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//squad/xlm-KG_LR8e-6_EPOCH2.0_maxlen384_batchsize4_gradacc4']
Some weights of the model checkpoint at /cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//squad/xlm-KG_LR8e-6_EPOCH2.0_maxlen384_batchsize4_gradacc4 were not used when initializing XLMRobertaModel: ['base_model.encoder.layer.17.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.3.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.20.output.LayerNorm.weight', 'base_model.encoder.layer.2.attention.output.dense.weight', 'base_model.encoder.layer.14.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.15.attention.self.value.weight', 'base_model.encoder.layer.15.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.22.output.dense.bias', 'base_model.encoder.layer.12.output.dense.weight', 'base_model.encoder.layer.13.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.3.attention.self.value.weight', 'base_model.encoder.layer.11.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.8.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.16.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.20.attention.output.dense.bias', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.3.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.0.intermediate.dense.weight', 'base_model.encoder.layer.11.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.0.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.12.output.LayerNorm.bias', 'base_model.encoder.layer.5.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.8.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.1.attention.self.value.weight', 'base_model.encoder.layer.6.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.13.output.LayerNorm.weight', 'base_model.encoder.layer.14.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.21.attention.self.value.bias', 'base_model.encoder.layer.18.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.13.attention.self.key.weight', 'base_model.encoder.layer.21.attention.output.LayerNorm.bias', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.11.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.18.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.20.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.20.attention.output.dense.weight', 'base_model.encoder.layer.0.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.6.attention.output.LayerNorm.bias', 'base_model.encoder.layer.10.attention.self.value.bias', 'base_model.encoder.layer.20.output.dense.weight', 'base_model.encoder.layer.1.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.2.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.5.attention.self.query.weight', 'base_model.encoder.layer.13.intermediate.dense.bias', 'base_model.encoder.layer.10.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.15.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.18.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.18.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.22.attention.output.LayerNorm.weight', 'base_model.encoder.layer.19.intermediate.dense.weight', 'base_model.encoder.layer.23.attention.output.LayerNorm.bias', 'base_model.encoder.layer.18.attention.self.value.weight', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.17.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.18.output.LayerNorm.bias', 'base_model.encoder.layer.6.intermediate.dense.weight', 'base_model.encoder.layer.7.attention.output.LayerNorm.weight', 'base_model.encoder.layer.8.attention.self.query.weight', 'base_model.encoder.layer.4.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.14.output.dense.bias', 'base_model.encoder.layer.7.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.22.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.1.attention.output.dense.bias', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.16.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.2.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.5.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.1.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.12.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.20.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.17.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.10.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.6.attention.output.dense.bias', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.2.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.12.intermediate.dense.weight', 'base_model.encoder.layer.3.attention.output.LayerNorm.weight', 'base_model.encoder.layer.8.attention.output.dense.weight', 'base_model.encoder.layer.14.attention.output.dense.weight', 'base_model.encoder.layer.19.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.10.attention.output.dense.weight', 'base_model.encoder.layer.6.attention.output.dense.weight', 'base_model.encoder.layer.22.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.22.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.16.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.1.attention.self.key.weight', 'base_model.encoder.layer.11.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.10.attention.self.query.bias', 'base_model.encoder.layer.17.output.dense.bias', 'base_model.encoder.layer.23.output.LayerNorm.weight', 'base_model.encoder.layer.23.attention.output.dense.weight', 'base_model.encoder.layer.18.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.10.output.LayerNorm.bias', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.9.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.17.output.LayerNorm.weight', 'base_model.encoder.layer.20.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.13.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.14.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.20.intermediate.dense.weight', 'base_model.encoder.layer.5.output.LayerNorm.weight', 'base_model.encoder.layer.13.attention.output.LayerNorm.bias', 'base_model.encoder.layer.7.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.6.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.16.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.embeddings.token_type_embeddings.weight', 'base_model.embeddings.LayerNorm.weight', 'base_model.encoder.layer.0.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.13.attention.output.LayerNorm.weight', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.9.output.dense.bias', 'base_model.encoder.layer.14.output.dense.weight', 'base_model.encoder.layer.2.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.21.output.LayerNorm.weight', 'base_model.encoder.layer.12.attention.self.query.weight', 'base_model.encoder.layer.19.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.16.attention.self.query.bias', 'base_model.encoder.layer.18.attention.output.dense.weight', 'base_model.encoder.layer.0.output.LayerNorm.bias', 'base_model.encoder.layer.15.output.dense.bias', 'base_model.encoder.layer.5.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.6.attention.self.value.bias', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.8.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.4.output.adapters.ts.adapter_down.0.bias', 'qa_outputs.bias', 'base_model.encoder.layer.11.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.14.intermediate.dense.bias', 'base_model.encoder.layer.7.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.18.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.0.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.0.attention.self.value.bias', 'base_model.encoder.layer.4.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.15.attention.self.query.weight', 'base_model.encoder.layer.13.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.15.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.8.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.18.attention.output.dense.bias', 'base_model.encoder.layer.11.output.LayerNorm.bias', 'base_model.encoder.layer.4.output.LayerNorm.bias', 'base_model.encoder.layer.18.output.LayerNorm.weight', 'base_model.encoder.layer.15.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.18.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.0.attention.self.value.weight', 'base_model.encoder.layer.20.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.19.attention.self.value.bias', 'base_model.encoder.layer.21.attention.self.key.bias', 'base_model.encoder.layer.7.intermediate.dense.bias', 'base_model.encoder.layer.2.attention.output.LayerNorm.bias', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.22.attention.self.value.weight', 'base_model.encoder.layer.3.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.6.intermediate.dense.bias', 'base_model.encoder.layer.6.output.LayerNorm.bias', 'base_model.encoder.layer.1.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.12.output.dense.bias', 'base_model.encoder.layer.16.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.7.attention.output.LayerNorm.bias', 'base_model.encoder.layer.2.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.12.attention.self.key.weight', 'base_model.encoder.layer.14.attention.self.query.weight', 'base_model.encoder.layer.9.attention.self.key.bias', 'base_model.encoder.layer.8.output.LayerNorm.weight', 'base_model.encoder.layer.19.output.dense.weight', 'base_model.encoder.layer.10.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.19.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.9.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.1.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.21.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.21.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.3.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.7.attention.self.value.bias', 'base_model.encoder.layer.13.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.8.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.14.attention.output.LayerNorm.bias', 'base_model.encoder.layer.14.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.0.attention.self.key.bias', 'base_model.encoder.layer.1.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.23.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.3.attention.output.LayerNorm.bias', 'base_model.encoder.layer.13.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.1.attention.output.dense.weight', 'base_model.encoder.layer.10.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.8.attention.output.LayerNorm.weight', 'base_model.encoder.layer.17.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.12.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.9.attention.output.LayerNorm.weight', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.19.attention.self.value.weight', 'base_model.encoder.layer.17.attention.self.query.bias', 'base_model.encoder.layer.11.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.13.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.21.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.6.attention.self.key.weight', 'base_model.encoder.layer.4.attention.self.value.bias', 'base_model.encoder.layer.20.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.15.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.12.attention.self.value.weight', 'base_model.encoder.layer.22.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.0.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.12.attention.output.LayerNorm.weight', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.11.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.15.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.7.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.8.attention.self.value.weight', 'base_model.encoder.layer.23.attention.self.value.weight', 'base_model.encoder.layer.22.output.adapters.ep.adapter_up.weight', 'base_model.pooler.dense.bias', 'base_model.encoder.layer.8.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.22.intermediate.dense.weight', 'base_model.encoder.layer.18.output.dense.weight', 'base_model.encoder.layer.8.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.8.output.dense.weight', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.16.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.21.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.23.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.3.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.4.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.14.attention.self.key.weight', 'base_model.encoder.layer.16.intermediate.dense.bias', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.0.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.22.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.15.attention.output.LayerNorm.weight', 'base_model.encoder.layer.22.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.17.output.LayerNorm.bias', 'base_model.encoder.layer.12.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.21.attention.output.LayerNorm.weight', 'base_model.encoder.layer.22.intermediate.dense.bias', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.1.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.19.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.1.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.19.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.1.attention.output.LayerNorm.weight', 'base_model.encoder.layer.7.attention.self.value.weight', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.8.attention.output.dense.bias', 'base_model.encoder.layer.12.attention.self.key.bias', 'base_model.encoder.layer.18.attention.self.key.bias', 'base_model.encoder.layer.10.attention.self.query.weight', 'base_model.encoder.layer.4.attention.output.LayerNorm.bias', 'base_model.encoder.layer.15.attention.output.LayerNorm.bias', 'base_model.encoder.layer.5.output.adapters.ts.adapter_up.weight', 'base_model.embeddings.word_embeddings.weight', 'base_model.encoder.layer.15.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.20.attention.self.key.weight', 'base_model.encoder.layer.23.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.8.intermediate.dense.bias', 'base_model.encoder.layer.10.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.13.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.0.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.16.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.10.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.16.attention.self.query.weight', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.3.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.18.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.9.output.dense.weight', 'base_model.encoder.layer.11.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.18.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.5.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.10.attention.output.LayerNorm.bias', 'base_model.encoder.layer.20.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.6.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.7.attention.output.dense.weight', 'base_model.encoder.layer.11.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.7.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.15.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.10.attention.self.value.weight', 'base_model.encoder.layer.5.attention.self.value.bias', 'base_model.encoder.layer.7.attention.self.query.bias', 'base_model.encoder.layer.9.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.1.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.7.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.7.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.23.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.14.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.15.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.3.attention.output.dense.weight', 'base_model.encoder.layer.19.intermediate.dense.bias', 'base_model.encoder.layer.20.attention.output.LayerNorm.weight', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.11.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.15.intermediate.dense.bias', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.17.attention.output.dense.bias', 'base_model.encoder.layer.4.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.14.intermediate.dense.weight', 'base_model.encoder.layer.12.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.3.attention.self.key.weight', 'base_model.encoder.layer.1.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.16.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.5.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.5.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.12.attention.self.value.bias', 'base_model.encoder.layer.12.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.16.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.23.output.LayerNorm.bias', 'base_model.encoder.layer.16.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.16.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.12.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.21.intermediate.dense.weight', 'base_model.encoder.layer.0.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.1.output.dense.weight', 'base_model.encoder.layer.15.output.LayerNorm.weight', 'base_model.encoder.layer.11.attention.output.LayerNorm.bias', 'base_model.encoder.layer.15.output.dense.weight', 'base_model.encoder.layer.0.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.14.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.2.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.18.output.dense.bias', 'base_model.encoder.layer.20.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.19.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.5.output.dense.weight', 'base_model.encoder.layer.0.intermediate.dense.bias', 'base_model.encoder.layer.13.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.17.output.dense.weight', 'base_model.encoder.layer.20.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.17.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.19.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.2.attention.self.query.weight', 'base_model.encoder.layer.1.output.dense.bias', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.23.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.20.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.1.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.6.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.1.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.11.output.dense.bias', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.8.attention.self.query.bias', 'base_model.encoder.layer.6.output.dense.weight', 'base_model.encoder.layer.18.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.3.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.22.attention.self.query.bias', 'base_model.pooler.dense.weight', 'base_model.encoder.layer.9.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.1.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.22.output.LayerNorm.weight', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.15.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.11.attention.self.value.bias', 'base_model.encoder.layer.9.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.13.attention.self.value.weight', 'base_model.encoder.layer.1.output.LayerNorm.weight', 'base_model.encoder.layer.11.output.dense.weight', 'base_model.encoder.layer.15.attention.self.query.bias', 'base_model.encoder.layer.17.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.21.attention.self.query.weight', 'base_model.encoder.layer.14.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.22.attention.self.value.bias', 'base_model.encoder.layer.6.output.LayerNorm.weight', 'base_model.encoder.layer.10.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.5.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.6.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.21.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.9.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.10.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.9.attention.self.value.weight', 'base_model.encoder.layer.7.output.dense.weight', 'base_model.encoder.layer.20.output.LayerNorm.bias', 'base_model.encoder.layer.23.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.6.attention.self.key.bias', 'base_model.encoder.layer.15.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.13.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.8.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.11.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.7.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.2.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.6.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.19.attention.self.query.weight', 'base_model.encoder.layer.21.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.8.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.21.output.dense.weight', 'base_model.encoder.layer.14.attention.self.value.bias', 'base_model.encoder.layer.9.attention.self.query.bias', 'base_model.encoder.layer.4.attention.self.value.weight', 'base_model.encoder.layer.7.output.LayerNorm.bias', 'base_model.encoder.layer.0.attention.output.LayerNorm.bias', 'base_model.encoder.layer.3.output.LayerNorm.weight', 'base_model.encoder.layer.16.intermediate.dense.weight', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.20.attention.self.value.weight', 'base_model.encoder.layer.14.output.LayerNorm.weight', 'base_model.encoder.layer.23.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.9.output.LayerNorm.bias', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.13.attention.output.dense.bias', 'base_model.encoder.layer.13.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.14.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.21.attention.self.query.bias', 'base_model.encoder.layer.13.attention.self.query.weight', 'base_model.encoder.layer.2.output.LayerNorm.weight', 'base_model.encoder.layer.8.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.23.attention.self.key.bias', 'base_model.encoder.layer.9.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.7.attention.self.key.weight', 'base_model.encoder.layer.0.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.10.output.dense.weight', 'base_model.encoder.layer.17.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.20.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.6.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.14.attention.output.dense.bias', 'base_model.encoder.layer.21.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.5.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.20.attention.self.key.bias', 'base_model.encoder.layer.3.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.6.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.11.intermediate.dense.weight', 'base_model.encoder.layer.11.attention.self.key.bias', 'base_model.encoder.layer.2.attention.self.value.weight', 'base_model.encoder.layer.13.attention.self.query.bias', 'base_model.encoder.layer.0.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.17.attention.output.LayerNorm.bias', 'base_model.encoder.layer.11.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.19.attention.output.LayerNorm.bias', 'base_model.encoder.layer.20.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.20.output.dense.bias', 'base_model.encoder.layer.3.attention.self.key.bias', 'base_model.encoder.layer.0.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.21.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.19.attention.self.key.bias', 'base_model.encoder.layer.3.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.9.output.LayerNorm.weight', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.23.attention.self.value.bias', 'base_model.encoder.layer.8.intermediate.dense.weight', 'base_model.encoder.layer.2.attention.self.value.bias', 'base_model.encoder.layer.10.intermediate.dense.bias', 'base_model.encoder.layer.17.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.16.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.4.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.20.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.1.attention.self.key.bias', 'base_model.encoder.layer.14.attention.self.value.weight', 'base_model.encoder.layer.15.intermediate.dense.weight', 'base_model.encoder.layer.6.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.22.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.5.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.14.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.10.attention.output.dense.bias', 'base_model.encoder.layer.18.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.10.attention.self.key.bias', 'base_model.encoder.layer.23.attention.self.key.weight', 'base_model.encoder.layer.4.intermediate.dense.bias', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.14.output.LayerNorm.bias', 'base_model.encoder.layer.16.attention.self.key.bias', 'base_model.encoder.layer.9.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.10.attention.self.key.weight', 'base_model.encoder.layer.12.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.18.attention.output.LayerNorm.bias', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.1.attention.self.query.bias', 'base_model.encoder.layer.12.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.6.attention.self.query.bias', 'base_model.encoder.layer.12.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.16.output.LayerNorm.weight', 'base_model.encoder.layer.19.attention.output.dense.bias', 'base_model.encoder.layer.18.attention.self.key.weight', 'base_model.encoder.layer.9.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.17.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.0.output.LayerNorm.weight', 'base_model.encoder.layer.21.output.LayerNorm.bias', 'base_model.encoder.layer.14.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.4.output.dense.weight', 'base_model.encoder.layer.22.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.22.attention.output.dense.bias', 'base_model.encoder.layer.9.attention.self.value.bias', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.7.output.dense.bias', 'base_model.encoder.layer.13.output.dense.weight', 'base_model.encoder.layer.0.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.16.attention.output.dense.weight', 'base_model.encoder.layer.7.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.23.output.dense.bias', 'base_model.encoder.layer.16.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.2.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.4.attention.output.dense.weight', 'base_model.encoder.layer.21.attention.self.key.weight', 'base_model.encoder.layer.8.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.20.attention.self.query.weight', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.0.attention.output.LayerNorm.weight', 'base_model.encoder.layer.15.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.6.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.23.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.15.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.16.attention.self.value.weight', 'base_model.encoder.layer.5.attention.self.key.bias', 'base_model.encoder.layer.18.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.8.output.LayerNorm.bias', 'base_model.encoder.layer.2.attention.output.dense.bias', 'base_model.encoder.layer.7.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.5.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.3.output.LayerNorm.bias', 'base_model.encoder.layer.15.attention.self.key.weight', 'base_model.encoder.layer.8.attention.self.key.bias', 'base_model.encoder.layer.19.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.23.attention.self.query.weight', 'base_model.encoder.layer.2.intermediate.dense.weight', 'base_model.encoder.layer.10.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.11.attention.self.query.weight', 'base_model.encoder.layer.2.output.LayerNorm.bias', 'base_model.encoder.layer.4.attention.self.key.bias', 'base_model.encoder.layer.2.output.dense.bias', 'base_model.encoder.layer.5.attention.output.LayerNorm.bias', 'base_model.encoder.layer.5.output.LayerNorm.bias', 'base_model.encoder.layer.7.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.14.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.19.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.3.intermediate.dense.bias', 'base_model.encoder.layer.4.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.23.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.3.output.dense.bias', 'base_model.encoder.layer.6.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.9.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.10.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.8.attention.self.key.weight', 'base_model.encoder.layer.18.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.19.attention.self.key.weight', 'base_model.encoder.layer.6.attention.self.value.weight', 'base_model.encoder.layer.5.intermediate.dense.bias', 'base_model.encoder.layer.10.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.17.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.20.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.15.attention.output.dense.bias', 'base_model.encoder.layer.4.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.19.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.7.attention.output.dense.bias', 'base_model.encoder.layer.10.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.15.output.LayerNorm.bias', 'base_model.encoder.layer.15.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.12.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.1.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.10.intermediate.dense.weight', 'base_model.encoder.layer.17.intermediate.dense.weight', 'base_model.encoder.layer.11.attention.output.LayerNorm.weight', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.4.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.23.attention.output.LayerNorm.weight', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.3.attention.self.query.bias', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.18.attention.self.value.bias', 'base_model.encoder.layer.17.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.13.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.17.attention.output.LayerNorm.weight', 'base_model.encoder.layer.3.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.15.attention.self.value.bias', 'base_model.encoder.layer.6.attention.self.query.weight', 'base_model.encoder.layer.19.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.21.attention.output.dense.bias', 'base_model.encoder.layer.0.attention.output.dense.weight', 'base_model.encoder.layer.12.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.13.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.6.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.11.attention.self.key.weight', 'base_model.encoder.layer.2.attention.self.key.bias', 'base_model.encoder.layer.12.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.0.attention.self.query.bias', 'base_model.encoder.layer.8.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.10.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.4.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.13.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.19.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.22.attention.output.dense.weight', 'base_model.encoder.layer.2.attention.self.query.bias', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.21.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.11.attention.output.dense.weight', 'base_model.encoder.layer.8.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.9.intermediate.dense.weight', 'base_model.encoder.layer.9.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.22.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.9.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.2.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.21.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.7.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.17.attention.self.key.bias', 'base_model.encoder.layer.21.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.9.intermediate.dense.bias', 'base_model.encoder.layer.9.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.23.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.3.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.9.attention.output.dense.bias', 'base_model.encoder.layer.4.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.17.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.5.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.15.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.4.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.16.attention.self.value.bias', 'base_model.encoder.layer.13.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.12.attention.output.dense.bias', 'base_model.encoder.layer.19.output.LayerNorm.weight', 'base_model.encoder.layer.5.attention.self.query.bias', 'base_model.encoder.layer.4.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.5.attention.output.LayerNorm.weight', 'base_model.encoder.layer.18.attention.self.query.bias', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.19.attention.output.LayerNorm.weight', 'base_model.encoder.layer.2.output.dense.weight', 'base_model.encoder.layer.12.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.6.output.dense.bias', 'base_model.encoder.layer.6.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.1.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.14.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.20.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.5.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.13.attention.self.value.bias', 'base_model.encoder.layer.13.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.11.attention.self.value.weight', 'base_model.encoder.layer.1.intermediate.dense.weight', 'base_model.encoder.layer.4.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.14.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.19.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.3.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.23.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.20.intermediate.dense.bias', 'base_model.encoder.layer.9.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.11.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.3.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.22.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.1.attention.self.value.bias', 'base_model.encoder.layer.20.attention.self.value.bias', 'base_model.encoder.layer.5.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.21.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.21.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.2.intermediate.dense.bias', 'base_model.encoder.layer.22.output.LayerNorm.bias', 'base_model.encoder.layer.7.attention.self.key.bias', 'base_model.encoder.layer.4.attention.self.key.weight', 'base_model.encoder.layer.17.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.15.attention.self.key.bias', 'base_model.encoder.layer.5.attention.self.key.weight', 'base_model.encoder.layer.16.attention.output.dense.bias', 'base_model.embeddings.position_ids', 'base_model.encoder.layer.7.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.19.attention.self.query.bias', 'base_model.encoder.layer.4.attention.output.LayerNorm.weight', 'base_model.encoder.layer.22.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.0.attention.output.dense.bias', 'base_model.encoder.layer.0.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.1.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.17.attention.self.value.weight', 'base_model.encoder.layer.22.attention.self.key.bias', 'base_model.encoder.layer.4.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.10.output.LayerNorm.weight', 'base_model.encoder.layer.17.attention.self.key.weight', 'base_model.encoder.layer.21.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.7.output.LayerNorm.weight', 'base_model.encoder.layer.7.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.11.attention.output.dense.bias', 'base_model.encoder.layer.9.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.18.attention.output.LayerNorm.weight', 'base_model.encoder.layer.16.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.14.attention.output.LayerNorm.weight', 'base_model.encoder.layer.18.intermediate.dense.bias', 'base_model.encoder.layer.5.intermediate.dense.weight', 'base_model.encoder.layer.3.attention.self.value.bias', 'base_model.encoder.layer.2.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.9.attention.self.key.weight', 'base_model.encoder.layer.16.attention.output.LayerNorm.weight', 'base_model.encoder.layer.14.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.7.attention.self.query.weight', 'base_model.encoder.layer.15.attention.output.dense.weight', 'base_model.encoder.layer.23.intermediate.dense.bias', 'base_model.encoder.layer.2.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.13.output.dense.bias', 'base_model.embeddings.position_embeddings.weight', 'base_model.encoder.layer.12.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.5.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.3.attention.output.dense.bias', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.3.attention.self.query.weight', 'base_model.encoder.layer.12.attention.output.dense.weight', 'base_model.encoder.layer.20.attention.self.query.bias', 'base_model.encoder.layer.16.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.0.attention.self.key.weight', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.12.output.LayerNorm.weight', 'base_model.encoder.layer.13.output.LayerNorm.bias', 'base_model.encoder.layer.11.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.1.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.2.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.16.output.LayerNorm.bias', 'base_model.encoder.layer.2.output.adapters.ts.adapter_up.bias', 'qa_outputs.weight', 'base_model.encoder.layer.4.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.20.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.23.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.17.attention.self.value.bias', 'base_model.encoder.layer.5.output.dense.bias', 'base_model.encoder.layer.16.output.dense.weight', 'base_model.encoder.layer.2.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.4.attention.output.dense.bias', 'base_model.encoder.layer.4.intermediate.dense.weight', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.6.attention.output.LayerNorm.weight', 'base_model.encoder.layer.17.attention.output.dense.weight', 'base_model.encoder.layer.16.attention.self.key.weight', 'base_model.encoder.layer.22.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.21.attention.output.dense.weight', 'base_model.encoder.layer.5.attention.output.dense.weight', 'base_model.encoder.layer.11.attention.self.query.bias', 'base_model.encoder.layer.19.output.dense.bias', 'base_model.encoder.layer.18.intermediate.dense.weight', 'base_model.encoder.layer.14.attention.self.query.bias', 'base_model.encoder.layer.20.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.23.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.22.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.5.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.23.attention.output.dense.bias', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.2.attention.output.LayerNorm.weight', 'base_model.encoder.layer.12.attention.self.query.bias', 'base_model.encoder.layer.3.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.8.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.18.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.5.attention.output.dense.bias', 'base_model.encoder.layer.22.output.dense.weight', 'base_model.encoder.layer.6.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.23.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.10.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.9.attention.output.dense.weight', 'base_model.encoder.layer.1.output.LayerNorm.bias', 'base_model.encoder.layer.16.output.dense.bias', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.3.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.12.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.11.intermediate.dense.bias', 'base_model.encoder.layer.13.intermediate.dense.weight', 'base_model.encoder.layer.21.output.dense.bias', 'base_model.encoder.layer.23.output.dense.weight', 'base_model.encoder.layer.0.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.8.attention.output.LayerNorm.bias', 'base_model.encoder.layer.17.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.11.output.LayerNorm.weight', 'base_model.encoder.layer.19.output.LayerNorm.bias', 'base_model.encoder.layer.12.intermediate.dense.bias', 'base_model.encoder.layer.21.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.19.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.1.attention.output.LayerNorm.bias', 'base_model.encoder.layer.7.intermediate.dense.weight', 'base_model.encoder.layer.23.attention.self.query.bias', 'base_model.encoder.layer.5.attention.self.value.weight', 'base_model.encoder.layer.20.attention.output.LayerNorm.bias', 'base_model.encoder.layer.3.output.dense.weight', 'base_model.encoder.layer.1.intermediate.dense.bias', 'base_model.encoder.layer.18.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.22.attention.output.LayerNorm.bias', 'base_model.encoder.layer.11.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.10.output.dense.bias', 'base_model.encoder.layer.14.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.17.attention.self.query.weight', 'base_model.encoder.layer.17.intermediate.dense.bias', 'base_model.encoder.layer.7.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.16.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.6.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.0.output.dense.bias', 'base_model.encoder.layer.14.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.8.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.19.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.23.intermediate.dense.weight', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.2.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.18.attention.self.query.weight', 'base_model.encoder.layer.4.output.LayerNorm.weight', 'base_model.encoder.layer.19.attention.output.dense.weight', 'base_model.encoder.layer.12.attention.output.LayerNorm.bias', 'base_model.encoder.layer.21.intermediate.dense.bias', 'base_model.encoder.layer.9.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.7.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.3.intermediate.dense.weight', 'base_model.encoder.layer.8.attention.self.value.bias', 'base_model.encoder.layer.22.attention.self.query.weight', 'base_model.encoder.layer.0.attention.self.query.weight', 'base_model.encoder.layer.8.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.6.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.14.attention.self.key.bias', 'base_model.encoder.layer.22.attention.self.key.weight', 'base_model.encoder.layer.4.attention.self.query.weight', 'base_model.encoder.layer.17.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.1.attention.self.query.weight', 'base_model.encoder.layer.9.attention.output.LayerNorm.bias', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.10.attention.output.LayerNorm.weight', 'base_model.encoder.layer.21.attention.self.value.weight', 'base_model.encoder.layer.10.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.13.attention.output.dense.weight', 'base_model.encoder.layer.0.output.dense.weight', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.21.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.11.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.2.attention.self.key.weight', 'base_model.embeddings.LayerNorm.bias', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.13.attention.self.key.bias', 'base_model.encoder.layer.18.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.16.attention.output.LayerNorm.bias', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.22.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.15.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.3.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.4.output.dense.bias', 'base_model.encoder.layer.23.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.2.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.12.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.9.attention.self.query.weight', 'base_model.encoder.layer.8.output.dense.bias', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.22.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.4.attention.self.query.bias', 'base_model.encoder.layer.13.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.19.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.17.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.0.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.10.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.23.output.adapters.tp.adapter_down.0.weight']
- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of XLMRobertaModel were not initialized from the model checkpoint at /cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//squad/xlm-KG_LR8e-6_EPOCH2.0_maxlen384_batchsize4_gradacc4 and are newly initialized: ['encoder.layer.11.attention.self.key.bias', 'encoder.layer.18.attention.self.value.bias', 'encoder.layer.13.intermediate.dense.weight', 'encoder.layer.12.attention.output.LayerNorm.bias', 'encoder.layer.22.output.dense.bias', 'encoder.layer.5.attention.self.value.bias', 'encoder.layer.21.output.dense.weight', 'encoder.layer.3.attention.self.value.weight', 'encoder.layer.3.attention.output.dense.bias', 'encoder.layer.23.attention.self.key.bias', 'encoder.layer.20.output.LayerNorm.bias', 'encoder.layer.17.attention.self.value.bias', 'encoder.layer.13.attention.output.dense.weight', 'encoder.layer.11.attention.output.dense.weight', 'encoder.layer.19.attention.self.query.weight', 'encoder.layer.0.attention.self.value.weight', 'encoder.layer.18.attention.self.query.bias', 'encoder.layer.5.output.dense.bias', 'encoder.layer.7.attention.output.dense.weight', 'encoder.layer.21.output.LayerNorm.weight', 'encoder.layer.22.output.dense.weight', 'encoder.layer.12.attention.self.key.bias', 'encoder.layer.9.attention.output.dense.bias', 'encoder.layer.21.output.LayerNorm.bias', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.1.attention.self.key.weight', 'encoder.layer.9.attention.self.query.bias', 'encoder.layer.6.output.LayerNorm.bias', 'encoder.layer.14.attention.self.key.bias', 'pooler.dense.bias', 'encoder.layer.5.attention.self.key.weight', 'encoder.layer.9.attention.self.value.bias', 'encoder.layer.5.attention.output.LayerNorm.weight', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.7.output.dense.bias', 'encoder.layer.16.intermediate.dense.weight', 'encoder.layer.20.attention.self.key.bias', 'embeddings.LayerNorm.bias', 'encoder.layer.19.attention.output.LayerNorm.bias', 'encoder.layer.1.attention.self.query.weight', 'encoder.layer.6.attention.self.key.weight', 'encoder.layer.4.attention.self.query.weight', 'encoder.layer.6.attention.output.dense.bias', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.3.attention.self.key.bias', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.15.attention.self.query.bias', 'encoder.layer.3.output.dense.bias', 'encoder.layer.3.attention.output.dense.weight', 'encoder.layer.23.attention.output.LayerNorm.weight', 'encoder.layer.1.output.dense.bias', 'encoder.layer.19.output.LayerNorm.bias', 'embeddings.word_embeddings.weight', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.17.attention.self.value.weight', 'encoder.layer.17.attention.output.dense.bias', 'encoder.layer.12.attention.self.value.weight', 'encoder.layer.10.attention.output.dense.weight', 'encoder.layer.22.attention.self.key.weight', 'encoder.layer.2.attention.self.query.bias', 'encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.12.attention.self.key.weight', 'encoder.layer.22.attention.output.dense.weight', 'encoder.layer.16.attention.self.query.weight', 'encoder.layer.14.attention.output.LayerNorm.weight', 'encoder.layer.13.output.LayerNorm.bias', 'encoder.layer.16.attention.self.value.bias', 'encoder.layer.15.output.dense.weight', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.17.attention.self.query.weight', 'encoder.layer.3.attention.self.value.bias', 'encoder.layer.17.output.dense.weight', 'encoder.layer.19.attention.output.LayerNorm.weight', 'encoder.layer.13.output.dense.weight', 'encoder.layer.22.attention.self.query.bias', 'encoder.layer.23.attention.output.LayerNorm.bias', 'encoder.layer.16.output.LayerNorm.bias', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.13.attention.self.query.bias', 'encoder.layer.4.attention.self.query.bias', 'encoder.layer.22.attention.self.value.bias', 'encoder.layer.23.attention.self.value.weight', 'encoder.layer.16.attention.self.query.bias', 'encoder.layer.18.attention.output.dense.bias', 'encoder.layer.12.attention.output.dense.weight', 'encoder.layer.15.attention.output.LayerNorm.bias', 'encoder.layer.15.attention.output.dense.weight', 'encoder.layer.22.output.LayerNorm.bias', 'encoder.layer.4.output.dense.bias', 'encoder.layer.18.attention.self.key.bias', 'encoder.layer.14.attention.self.value.weight', 'encoder.layer.23.attention.output.dense.bias', 'encoder.layer.16.attention.self.key.bias', 'encoder.layer.20.attention.output.dense.weight', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.9.attention.self.query.weight', 'encoder.layer.10.attention.self.query.weight', 'encoder.layer.8.attention.self.query.weight', 'encoder.layer.21.attention.output.dense.bias', 'encoder.layer.11.attention.self.key.weight', 'encoder.layer.12.output.dense.weight', 'encoder.layer.22.attention.self.query.weight', 'encoder.layer.14.attention.output.dense.weight', 'encoder.layer.1.attention.self.query.bias', 'encoder.layer.11.attention.self.value.weight', 'encoder.layer.13.attention.self.query.weight', 'encoder.layer.10.output.LayerNorm.bias', 'encoder.layer.16.attention.output.dense.weight', 'encoder.layer.19.intermediate.dense.bias', 'encoder.layer.20.attention.self.query.bias', 'encoder.layer.7.output.dense.weight', 'encoder.layer.11.output.LayerNorm.weight', 'encoder.layer.15.attention.output.dense.bias', 'encoder.layer.9.attention.self.value.weight', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.14.output.LayerNorm.bias', 'encoder.layer.23.intermediate.dense.bias', 'encoder.layer.19.attention.output.dense.weight', 'encoder.layer.0.output.dense.bias', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.11.output.dense.bias', 'encoder.layer.22.attention.output.dense.bias', 'encoder.layer.21.attention.output.dense.weight', 'encoder.layer.9.output.dense.weight', 'encoder.layer.0.output.dense.weight', 'encoder.layer.18.intermediate.dense.bias', 'encoder.layer.9.attention.self.key.weight', 'encoder.layer.2.attention.output.LayerNorm.bias', 'encoder.layer.4.attention.output.LayerNorm.bias', 'encoder.layer.6.attention.self.query.weight', 'encoder.layer.10.output.dense.weight', 'encoder.layer.15.output.dense.bias', 'encoder.layer.20.attention.self.query.weight', 'encoder.layer.17.intermediate.dense.weight', 'encoder.layer.8.attention.output.dense.bias', 'encoder.layer.22.intermediate.dense.weight', 'encoder.layer.13.attention.self.key.weight', 'encoder.layer.19.output.dense.weight', 'encoder.layer.3.attention.self.query.bias', 'embeddings.LayerNorm.weight', 'encoder.layer.6.output.dense.weight', 'encoder.layer.17.attention.self.query.bias', 'encoder.layer.2.output.dense.bias', 'encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.layer.10.attention.output.LayerNorm.weight', 'encoder.layer.9.attention.output.dense.weight', 'encoder.layer.14.output.dense.bias', 'encoder.layer.4.attention.output.dense.bias', 'encoder.layer.13.attention.self.key.bias', 'encoder.layer.20.output.LayerNorm.weight', 'encoder.layer.17.attention.self.key.bias', 'encoder.layer.7.attention.self.key.weight', 'encoder.layer.19.output.dense.bias', 'encoder.layer.5.attention.output.dense.weight', 'encoder.layer.6.attention.self.value.bias', 'encoder.layer.14.output.dense.weight', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.10.output.dense.bias', 'encoder.layer.23.attention.self.key.weight', 'encoder.layer.4.attention.output.dense.weight', 'encoder.layer.18.output.LayerNorm.weight', 'encoder.layer.8.attention.self.key.weight', 'encoder.layer.19.attention.self.key.weight', 'encoder.layer.21.output.dense.bias', 'encoder.layer.19.intermediate.dense.weight', 'encoder.layer.6.attention.self.query.bias', 'encoder.layer.14.attention.self.key.weight', 'encoder.layer.22.attention.self.key.bias', 'encoder.layer.19.attention.self.query.bias', 'encoder.layer.22.attention.self.value.weight', 'encoder.layer.0.attention.self.value.bias', 'encoder.layer.21.intermediate.dense.bias', 'encoder.layer.6.attention.self.value.weight', 'encoder.layer.17.output.dense.bias', 'encoder.layer.4.attention.self.value.bias', 'encoder.layer.17.intermediate.dense.bias', 'encoder.layer.0.attention.self.key.bias', 'encoder.layer.12.output.LayerNorm.bias', 'encoder.layer.11.attention.output.LayerNorm.weight', 'encoder.layer.18.attention.output.LayerNorm.bias', 'encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.layer.15.output.LayerNorm.weight', 'encoder.layer.15.output.LayerNorm.bias', 'encoder.layer.14.attention.self.query.bias', 'encoder.layer.21.attention.self.query.bias', 'encoder.layer.3.attention.self.query.weight', 'encoder.layer.16.attention.output.dense.bias', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.9.output.LayerNorm.weight', 'encoder.layer.19.attention.self.value.bias', 'encoder.layer.5.attention.self.key.bias', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.14.output.LayerNorm.weight', 'encoder.layer.20.attention.self.key.weight', 'encoder.layer.1.attention.output.dense.weight', 'encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.22.intermediate.dense.bias', 'encoder.layer.18.output.dense.bias', 'encoder.layer.16.output.LayerNorm.weight', 'encoder.layer.4.attention.self.key.weight', 'encoder.layer.11.attention.self.query.weight', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.20.output.dense.weight', 'encoder.layer.22.attention.output.LayerNorm.weight', 'encoder.layer.21.intermediate.dense.weight', 'embeddings.token_type_embeddings.weight', 'encoder.layer.15.intermediate.dense.weight', 'encoder.layer.8.attention.self.query.bias', 'encoder.layer.0.attention.output.dense.bias', 'encoder.layer.2.attention.self.value.weight', 'encoder.layer.12.attention.output.dense.bias', 'encoder.layer.18.attention.output.dense.weight', 'encoder.layer.16.attention.output.LayerNorm.bias', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.6.attention.output.LayerNorm.bias', 'encoder.layer.2.attention.output.dense.weight', 'encoder.layer.10.attention.self.query.bias', 'encoder.layer.20.attention.output.LayerNorm.weight', 'encoder.layer.16.attention.self.key.weight', 'encoder.layer.14.attention.self.value.bias', 'encoder.layer.21.attention.self.value.weight', 'encoder.layer.10.attention.output.LayerNorm.bias', 'encoder.layer.13.attention.output.LayerNorm.bias', 'encoder.layer.5.attention.self.value.weight', 'encoder.layer.5.output.LayerNorm.bias', 'encoder.layer.12.output.LayerNorm.weight', 'encoder.layer.3.output.dense.weight', 'encoder.layer.18.attention.output.LayerNorm.weight', 'encoder.layer.13.attention.output.dense.bias', 'encoder.layer.12.attention.self.query.weight', 'encoder.layer.18.output.dense.weight', 'encoder.layer.18.attention.self.key.weight', 'encoder.layer.5.output.dense.weight', 'encoder.layer.11.output.dense.weight', 'encoder.layer.23.output.LayerNorm.bias', 'encoder.layer.7.attention.self.query.weight', 'encoder.layer.14.attention.output.LayerNorm.bias', 'encoder.layer.14.attention.self.query.weight', 'encoder.layer.1.attention.self.value.weight', 'encoder.layer.22.attention.output.LayerNorm.bias', 'encoder.layer.7.intermediate.dense.bias', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.16.output.dense.bias', 'encoder.layer.18.output.LayerNorm.bias', 'encoder.layer.21.attention.output.LayerNorm.weight', 'encoder.layer.2.attention.self.key.bias', 'encoder.layer.20.attention.self.value.weight', 'encoder.layer.13.attention.output.LayerNorm.weight', 'encoder.layer.15.attention.output.LayerNorm.weight', 'encoder.layer.12.attention.self.query.bias', 'encoder.layer.23.output.LayerNorm.weight', 'encoder.layer.22.output.LayerNorm.weight', 'encoder.layer.23.attention.self.query.bias', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.13.intermediate.dense.bias', 'encoder.layer.20.output.dense.bias', 'encoder.layer.12.intermediate.dense.bias', 'encoder.layer.10.attention.self.key.weight', 'encoder.layer.21.attention.self.query.weight', 'encoder.layer.7.output.LayerNorm.bias', 'encoder.layer.11.output.LayerNorm.bias', 'encoder.layer.20.intermediate.dense.bias', 'encoder.layer.17.attention.self.key.weight', 'encoder.layer.21.attention.output.LayerNorm.bias', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.8.output.LayerNorm.bias', 'encoder.layer.7.output.LayerNorm.weight', 'encoder.layer.16.output.dense.weight', 'encoder.layer.10.output.LayerNorm.weight', 'encoder.layer.15.attention.self.key.bias', 'encoder.layer.7.attention.output.LayerNorm.weight', 'encoder.layer.2.output.dense.weight', 'encoder.layer.7.attention.output.LayerNorm.bias', 'encoder.layer.23.attention.output.dense.weight', 'encoder.layer.8.attention.output.LayerNorm.bias', 'encoder.layer.20.attention.output.LayerNorm.bias', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.4.attention.self.key.bias', 'encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.layer.10.attention.output.dense.bias', 'encoder.layer.5.attention.output.dense.bias', 'encoder.layer.2.attention.self.query.weight', 'encoder.layer.1.attention.self.key.bias', 'encoder.layer.13.attention.self.value.weight', 'encoder.layer.8.output.dense.bias', 'encoder.layer.8.output.LayerNorm.weight', 'encoder.layer.9.output.LayerNorm.bias', 'encoder.layer.20.attention.output.dense.bias', 'encoder.layer.13.output.LayerNorm.weight', 'encoder.layer.11.attention.self.value.bias', 'encoder.layer.12.output.dense.bias', 'encoder.layer.0.attention.output.dense.weight', 'encoder.layer.5.attention.self.query.bias', 'encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.layer.15.attention.self.value.weight', 'encoder.layer.19.attention.output.dense.bias', 'encoder.layer.16.attention.output.LayerNorm.weight', 'encoder.layer.9.attention.output.LayerNorm.bias', 'encoder.layer.19.attention.self.value.weight', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.0.attention.output.LayerNorm.weight', 'encoder.layer.12.intermediate.dense.weight', 'encoder.layer.4.attention.output.LayerNorm.weight', 'encoder.layer.18.attention.self.query.weight', 'encoder.layer.2.attention.output.LayerNorm.weight', 'encoder.layer.2.attention.output.dense.bias', 'encoder.layer.7.attention.self.query.bias', 'encoder.layer.1.attention.self.value.bias', 'encoder.layer.8.attention.output.dense.weight', 'encoder.layer.6.attention.output.dense.weight', 'encoder.layer.4.output.dense.weight', 'encoder.layer.19.attention.self.key.bias', 'encoder.layer.8.attention.output.LayerNorm.weight', 'encoder.layer.18.intermediate.dense.weight', 'encoder.layer.1.output.dense.weight', 'encoder.layer.17.attention.output.LayerNorm.weight', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.13.attention.self.value.bias', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.15.intermediate.dense.bias', 'encoder.layer.15.attention.self.key.weight', 'encoder.layer.8.attention.self.key.bias', 'encoder.layer.21.attention.self.key.bias', 'encoder.layer.1.attention.output.dense.bias', 'encoder.layer.15.attention.self.query.weight', 'encoder.layer.9.attention.self.key.bias', 'encoder.layer.10.intermediate.dense.weight', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.0.attention.self.query.bias', 'encoder.layer.23.intermediate.dense.weight', 'encoder.layer.17.output.LayerNorm.bias', 'encoder.layer.6.output.dense.bias', 'encoder.layer.9.output.dense.bias', 'encoder.layer.7.attention.output.dense.bias', 'encoder.layer.8.output.dense.weight', 'encoder.layer.11.attention.output.dense.bias', 'encoder.layer.10.attention.self.value.weight', 'encoder.layer.6.attention.output.LayerNorm.weight', 'encoder.layer.17.output.LayerNorm.weight', 'encoder.layer.2.attention.self.value.bias', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.8.attention.self.value.weight', 'encoder.layer.17.attention.output.LayerNorm.bias', 'encoder.layer.23.output.dense.weight', 'encoder.layer.10.attention.self.value.bias', 'encoder.layer.7.attention.self.value.bias', 'encoder.layer.10.attention.self.key.bias', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.23.attention.self.value.bias', 'encoder.layer.14.attention.output.dense.bias', 'encoder.layer.17.attention.output.dense.weight', 'encoder.layer.12.attention.output.LayerNorm.weight', 'encoder.layer.20.intermediate.dense.weight', 'encoder.layer.12.attention.self.value.bias', 'encoder.layer.14.intermediate.dense.bias', 'encoder.layer.2.attention.self.key.weight', 'encoder.layer.13.output.dense.bias', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.15.attention.self.value.bias', 'pooler.dense.weight', 'encoder.layer.0.output.LayerNorm.weight', 'embeddings.position_embeddings.weight', 'encoder.layer.0.attention.self.key.weight', 'encoder.layer.9.attention.output.LayerNorm.weight', 'encoder.layer.11.attention.self.query.bias', 'encoder.layer.18.attention.self.value.weight', 'encoder.layer.16.attention.self.value.weight', 'encoder.layer.21.attention.self.value.bias', 'encoder.layer.1.attention.output.LayerNorm.weight', 'encoder.layer.23.attention.self.query.weight', 'encoder.layer.5.attention.self.query.weight', 'encoder.layer.19.output.LayerNorm.weight', 'encoder.layer.16.intermediate.dense.bias', 'encoder.layer.23.output.dense.bias', 'encoder.layer.0.attention.self.query.weight', 'encoder.layer.8.attention.self.value.bias', 'encoder.layer.14.intermediate.dense.weight', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.6.attention.self.key.bias', 'encoder.layer.4.attention.self.value.weight', 'encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.layer.7.attention.self.value.weight', 'encoder.layer.21.attention.self.key.weight', 'encoder.layer.7.attention.self.key.bias', 'encoder.layer.20.attention.self.value.bias', 'encoder.layer.3.attention.self.key.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Overwriting existing adapter 'ep'.
Overwriting existing adapter 'tp'.
Overwriting existing adapter 'es'.
Overwriting existing adapter 'ts'.
Overwriting existing adapter fusion module 'ep,tp,es,ts'
05/09/2022 19:56:40 - INFO - __main__ -   Creating features from dataset file at .
/cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//squad/xlm-KG_LR8e-6_EPOCH2.0_maxlen384_batchsize4_gradacc4
XLMConfig {
  "architectures": [
    "XLMRobertaForMaskedLM"
  ],
  "asm": false,
  "attention_dropout": 0.1,
  "attention_probs_dropout_prob": 0.1,
  "bos_index": 0,
  "bos_token_id": 0,
  "causal": false,
  "dropout": 0.1,
  "emb_dim": 1024,
  "embed_init_std": 0.02209708691207961,
  "end_n_top": 5,
  "eos_index": 1,
  "eos_token_id": 2,
  "gelu_activation": true,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "init_std": 0.02,
  "initializer_range": 0.02,
  "intermediate_size": 4096,
  "is_encoder": true,
  "lang_id": 0,
  "layer_norm_eps": 1e-05,
  "mask_index": 5,
  "mask_token_id": 0,
  "max_position_embeddings": 514,
  "model_type": "xlm",
  "n_heads": 16,
  "n_langs": 1,
  "n_layers": 24,
  "output_past": true,
  "pad_index": 2,
  "pad_token_id": 1,
  "sinusoidal_embeddings": false,
  "start_n_top": 5,
  "summary_activation": null,
  "summary_first_dropout": 0.1,
  "summary_proj_to_labels": true,
  "summary_type": "first",
  "summary_use_proj": true,
  "transformers_version": "4.17.0",
  "type_vocab_size": 1,
  "unk_index": 3,
  "use_lang_emb": false,
  "vocab_size": 250002
}

  0%|          | 0/48 [00:00<?, ?it/s] 27%|██▋       | 13/48 [00:00<00:00, 126.14it/s] 54%|█████▍    | 26/48 [00:00<00:00, 91.57it/s]  75%|███████▌  | 36/48 [00:00<00:00, 90.90it/s]100%|██████████| 48/48 [00:00<00:00, 99.88it/s]100%|██████████| 48/48 [00:00<00:00, 98.71it/s]
convert squad examples to features:   0%|          | 0/1190 [00:00<?, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.
convert squad examples to features:   0%|          | 1/1190 [00:00<03:55,  5.05it/s]convert squad examples to features:   3%|▎         | 33/1190 [00:00<00:08, 134.83it/s]convert squad examples to features:   5%|▌         | 65/1190 [00:00<00:06, 178.40it/s]convert squad examples to features:   8%|▊         | 97/1190 [00:00<00:05, 203.16it/s]convert squad examples to features:  11%|█         | 129/1190 [00:00<00:04, 234.00it/s]convert squad examples to features:  14%|█▎        | 161/1190 [00:00<00:04, 252.43it/s]convert squad examples to features:  19%|█▉        | 225/1190 [00:00<00:03, 275.51it/s]convert squad examples to features:  22%|██▏       | 257/1190 [00:01<00:03, 251.69it/s]convert squad examples to features:  24%|██▍       | 289/1190 [00:01<00:03, 228.90it/s]convert squad examples to features:  27%|██▋       | 321/1190 [00:01<00:03, 223.09it/s]convert squad examples to features:  30%|██▉       | 353/1190 [00:01<00:03, 230.31it/s]convert squad examples to features:  32%|███▏      | 385/1190 [00:02<00:07, 113.08it/s]convert squad examples to features:  35%|███▌      | 417/1190 [00:02<00:06, 119.45it/s]convert squad examples to features:  38%|███▊      | 449/1190 [00:02<00:05, 124.21it/s]convert squad examples to features:  40%|████      | 481/1190 [00:02<00:05, 140.32it/s]convert squad examples to features:  43%|████▎     | 513/1190 [00:03<00:04, 144.70it/s]convert squad examples to features:  46%|████▌     | 545/1190 [00:03<00:04, 142.00it/s]convert squad examples to features:  48%|████▊     | 577/1190 [00:03<00:03, 154.95it/s]convert squad examples to features:  51%|█████     | 609/1190 [00:03<00:03, 153.01it/s]convert squad examples to features:  54%|█████▍    | 641/1190 [00:03<00:03, 155.46it/s]convert squad examples to features:  57%|█████▋    | 673/1190 [00:04<00:03, 146.72it/s]convert squad examples to features:  59%|█████▉    | 705/1190 [00:04<00:03, 156.00it/s]convert squad examples to features:  62%|██████▏   | 737/1190 [00:04<00:02, 172.11it/s]convert squad examples to features:  65%|██████▍   | 769/1190 [00:04<00:02, 181.99it/s]convert squad examples to features:  67%|██████▋   | 801/1190 [00:04<00:02, 183.57it/s]convert squad examples to features:  70%|███████   | 833/1190 [00:05<00:02, 165.85it/s]convert squad examples to features:  73%|███████▎  | 865/1190 [00:05<00:01, 170.99it/s]convert squad examples to features:  75%|███████▌  | 897/1190 [00:05<00:01, 158.38it/s]convert squad examples to features:  78%|███████▊  | 929/1190 [00:05<00:01, 161.42it/s]convert squad examples to features:  81%|████████  | 961/1190 [00:05<00:01, 170.18it/s]convert squad examples to features:  83%|████████▎ | 993/1190 [00:05<00:01, 175.27it/s]convert squad examples to features:  86%|████████▌ | 1025/1190 [00:06<00:00, 184.63it/s]convert squad examples to features:  89%|████████▉ | 1057/1190 [00:06<00:00, 194.51it/s]convert squad examples to features:  92%|█████████▏| 1089/1190 [00:06<00:00, 201.65it/s]convert squad examples to features:  94%|█████████▍| 1121/1190 [00:06<00:00, 181.72it/s]convert squad examples to features:  97%|█████████▋| 1153/1190 [00:06<00:00, 180.38it/s]convert squad examples to features: 100%|██████████| 1190/1190 [00:06<00:00, 175.43it/s]/cluster/project/sachan/yifan/softwares/anaconda/anaconda3/envs/xfactr/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2272: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

add example index and unique id:   0%|          | 0/1190 [00:00<?, ?it/s]add example index and unique id: 100%|██████████| 1190/1190 [00:00<00:00, 505952.54it/s]
05/09/2022 19:56:48 - INFO - __main__ -   Saving features into cached file ./cached_xquad.el.json_xlm-KG_LR8e-6_EPOCH2.0_maxlen384_batchsize4_gradacc4_384_el
05/09/2022 19:56:50 - INFO - __main__ -   ***** Running evaluation  *****
05/09/2022 19:56:50 - INFO - __main__ -     Num examples = 1488
05/09/2022 19:56:50 - INFO - __main__ -     Batch size = 8
Evaluating:   0%|          | 0/186 [00:00<?, ?it/s]Evaluating:   1%|          | 1/186 [00:00<02:52,  1.07it/s]Evaluating:   1%|          | 2/186 [00:01<01:50,  1.67it/s]Evaluating:   2%|▏         | 3/186 [00:01<01:29,  2.04it/s]Evaluating:   2%|▏         | 4/186 [00:02<01:19,  2.28it/s]Evaluating:   3%|▎         | 5/186 [00:02<01:14,  2.44it/s]Evaluating:   3%|▎         | 6/186 [00:02<01:10,  2.56it/s]Evaluating:   4%|▍         | 7/186 [00:03<01:07,  2.64it/s]Evaluating:   4%|▍         | 8/186 [00:03<01:05,  2.70it/s]Evaluating:   5%|▍         | 9/186 [00:03<01:05,  2.72it/s]Evaluating:   5%|▌         | 10/186 [00:04<01:04,  2.73it/s]Evaluating:   6%|▌         | 11/186 [00:04<01:03,  2.75it/s]Evaluating:   6%|▋         | 12/186 [00:04<01:02,  2.77it/s]Evaluating:   7%|▋         | 13/186 [00:05<01:02,  2.77it/s]Evaluating:   8%|▊         | 14/186 [00:05<01:02,  2.77it/s]Evaluating:   8%|▊         | 15/186 [00:05<01:01,  2.78it/s]Evaluating:   9%|▊         | 16/186 [00:06<01:01,  2.77it/s]Evaluating:   9%|▉         | 17/186 [00:06<01:00,  2.77it/s]Evaluating:  10%|▉         | 18/186 [00:07<01:00,  2.78it/s]Evaluating:  10%|█         | 19/186 [00:07<00:59,  2.79it/s]Evaluating:  11%|█         | 20/186 [00:07<00:59,  2.79it/s]Evaluating:  11%|█▏        | 21/186 [00:08<00:59,  2.79it/s]Evaluating:  12%|█▏        | 22/186 [00:08<00:58,  2.79it/s]Evaluating:  12%|█▏        | 23/186 [00:08<00:58,  2.79it/s]Evaluating:  13%|█▎        | 24/186 [00:09<00:57,  2.80it/s]Evaluating:  13%|█▎        | 25/186 [00:09<00:58,  2.78it/s]Evaluating:  14%|█▍        | 26/186 [00:09<00:57,  2.78it/s]Evaluating:  15%|█▍        | 27/186 [00:10<00:57,  2.75it/s]Evaluating:  15%|█▌        | 28/186 [00:10<00:57,  2.75it/s]Evaluating:  16%|█▌        | 29/186 [00:10<00:56,  2.77it/s]Evaluating:  16%|█▌        | 30/186 [00:11<00:56,  2.78it/s]Evaluating:  17%|█▋        | 31/186 [00:11<00:55,  2.78it/s]Evaluating:  17%|█▋        | 32/186 [00:12<00:55,  2.78it/s]Evaluating:  18%|█▊        | 33/186 [00:12<00:54,  2.79it/s]Evaluating:  18%|█▊        | 34/186 [00:12<00:54,  2.79it/s]Evaluating:  19%|█▉        | 35/186 [00:13<00:53,  2.80it/s]Evaluating:  19%|█▉        | 36/186 [00:13<00:53,  2.80it/s]Evaluating:  20%|█▉        | 37/186 [00:13<00:53,  2.79it/s]Evaluating:  20%|██        | 38/186 [00:14<00:53,  2.78it/s]Evaluating:  21%|██        | 39/186 [00:14<00:52,  2.78it/s]Evaluating:  22%|██▏       | 40/186 [00:14<00:52,  2.77it/s]Evaluating:  22%|██▏       | 41/186 [00:15<00:52,  2.77it/s]Evaluating:  23%|██▎       | 42/186 [00:15<00:51,  2.77it/s]Evaluating:  23%|██▎       | 43/186 [00:16<00:51,  2.78it/s]Evaluating:  24%|██▎       | 44/186 [00:16<00:51,  2.77it/s]Evaluating:  24%|██▍       | 45/186 [00:16<00:51,  2.76it/s]Evaluating:  25%|██▍       | 46/186 [00:17<00:50,  2.76it/s]Evaluating:  25%|██▌       | 47/186 [00:17<00:50,  2.77it/s]Evaluating:  26%|██▌       | 48/186 [00:17<00:49,  2.77it/s]Evaluating:  26%|██▋       | 49/186 [00:18<00:49,  2.78it/s]Evaluating:  27%|██▋       | 50/186 [00:18<00:48,  2.78it/s]Evaluating:  27%|██▋       | 51/186 [00:18<00:48,  2.78it/s]Evaluating:  28%|██▊       | 52/186 [00:19<00:48,  2.76it/s]Evaluating:  28%|██▊       | 53/186 [00:19<00:48,  2.76it/s]Evaluating:  29%|██▉       | 54/186 [00:20<00:47,  2.76it/s]Evaluating:  30%|██▉       | 55/186 [00:20<00:47,  2.76it/s]Evaluating:  30%|███       | 56/186 [00:20<00:47,  2.76it/s]Evaluating:  31%|███       | 57/186 [00:21<00:46,  2.76it/s]Evaluating:  31%|███       | 58/186 [00:21<00:46,  2.77it/s]Evaluating:  32%|███▏      | 59/186 [00:21<00:45,  2.77it/s]Evaluating:  32%|███▏      | 60/186 [00:22<00:45,  2.76it/s]Evaluating:  33%|███▎      | 61/186 [00:22<00:45,  2.76it/s]Evaluating:  33%|███▎      | 62/186 [00:22<00:44,  2.76it/s]Evaluating:  34%|███▍      | 63/186 [00:23<00:44,  2.75it/s]Evaluating:  34%|███▍      | 64/186 [00:23<00:44,  2.75it/s]Evaluating:  35%|███▍      | 65/186 [00:23<00:44,  2.75it/s]Evaluating:  35%|███▌      | 66/186 [00:24<00:43,  2.74it/s]Evaluating:  36%|███▌      | 67/186 [00:24<00:43,  2.74it/s]Evaluating:  37%|███▋      | 68/186 [00:25<00:43,  2.74it/s]Evaluating:  37%|███▋      | 69/186 [00:25<00:42,  2.74it/s]Evaluating:  38%|███▊      | 70/186 [00:25<00:42,  2.75it/s]Evaluating:  38%|███▊      | 71/186 [00:26<00:41,  2.75it/s]Evaluating:  39%|███▊      | 72/186 [00:26<00:41,  2.76it/s]Evaluating:  39%|███▉      | 73/186 [00:26<00:40,  2.76it/s]Evaluating:  40%|███▉      | 74/186 [00:27<00:40,  2.77it/s]Evaluating:  40%|████      | 75/186 [00:27<00:39,  2.78it/s]Evaluating:  41%|████      | 76/186 [00:27<00:39,  2.78it/s]Evaluating:  41%|████▏     | 77/186 [00:28<00:39,  2.77it/s]Evaluating:  42%|████▏     | 78/186 [00:28<00:38,  2.77it/s]Evaluating:  42%|████▏     | 79/186 [00:29<00:38,  2.77it/s]Evaluating:  43%|████▎     | 80/186 [00:29<00:38,  2.77it/s]Evaluating:  44%|████▎     | 81/186 [00:29<00:37,  2.77it/s]Evaluating:  44%|████▍     | 82/186 [00:30<00:37,  2.77it/s]Evaluating:  45%|████▍     | 83/186 [00:30<00:37,  2.77it/s]Evaluating:  45%|████▌     | 84/186 [00:30<00:36,  2.78it/s]Evaluating:  46%|████▌     | 85/186 [00:31<00:36,  2.77it/s]Evaluating:  46%|████▌     | 86/186 [00:31<00:36,  2.77it/s]Evaluating:  47%|████▋     | 87/186 [00:31<00:35,  2.76it/s]Evaluating:  47%|████▋     | 88/186 [00:32<00:35,  2.76it/s]Evaluating:  48%|████▊     | 89/186 [00:32<00:35,  2.72it/s]Evaluating:  48%|████▊     | 90/186 [00:33<00:35,  2.73it/s]Evaluating:  49%|████▉     | 91/186 [00:33<00:35,  2.69it/s]Evaluating:  49%|████▉     | 92/186 [00:33<00:34,  2.69it/s]Evaluating:  50%|█████     | 93/186 [00:34<00:35,  2.64it/s]Evaluating:  51%|█████     | 94/186 [00:34<00:34,  2.67it/s]Evaluating:  51%|█████     | 95/186 [00:34<00:33,  2.69it/s]Evaluating:  52%|█████▏    | 96/186 [00:35<00:33,  2.71it/s]Evaluating:  52%|█████▏    | 97/186 [00:35<00:32,  2.73it/s]Evaluating:  53%|█████▎    | 98/186 [00:36<00:32,  2.72it/s]Evaluating:  53%|█████▎    | 99/186 [00:36<00:31,  2.72it/s]Evaluating:  54%|█████▍    | 100/186 [00:36<00:31,  2.73it/s]Evaluating:  54%|█████▍    | 101/186 [00:37<00:31,  2.74it/s]Evaluating:  55%|█████▍    | 102/186 [00:37<00:30,  2.75it/s]Evaluating:  55%|█████▌    | 103/186 [00:37<00:30,  2.75it/s]Evaluating:  56%|█████▌    | 104/186 [00:38<00:29,  2.75it/s]Evaluating:  56%|█████▋    | 105/186 [00:38<00:29,  2.75it/s]Evaluating:  57%|█████▋    | 106/186 [00:38<00:29,  2.75it/s]Evaluating:  58%|█████▊    | 107/186 [00:39<00:28,  2.75it/s]Evaluating:  58%|█████▊    | 108/186 [00:39<00:28,  2.75it/s]Evaluating:  59%|█████▊    | 109/186 [00:40<00:28,  2.75it/s]Evaluating:  59%|█████▉    | 110/186 [00:40<00:27,  2.75it/s]Evaluating:  60%|█████▉    | 111/186 [00:40<00:27,  2.74it/s]Evaluating:  60%|██████    | 112/186 [00:41<00:27,  2.74it/s]Evaluating:  61%|██████    | 113/186 [00:41<00:26,  2.73it/s]Evaluating:  61%|██████▏   | 114/186 [00:41<00:26,  2.73it/s]Evaluating:  62%|██████▏   | 115/186 [00:42<00:25,  2.74it/s]Evaluating:  62%|██████▏   | 116/186 [00:42<00:25,  2.75it/s]Evaluating:  63%|██████▎   | 117/186 [00:42<00:25,  2.75it/s]Evaluating:  63%|██████▎   | 118/186 [00:43<00:24,  2.75it/s]Evaluating:  64%|██████▍   | 119/186 [00:43<00:24,  2.75it/s]Evaluating:  65%|██████▍   | 120/186 [00:44<00:23,  2.75it/s]Evaluating:  65%|██████▌   | 121/186 [00:44<00:23,  2.75it/s]Evaluating:  66%|██████▌   | 122/186 [00:44<00:23,  2.74it/s]Evaluating:  66%|██████▌   | 123/186 [00:45<00:22,  2.75it/s]Evaluating:  67%|██████▋   | 124/186 [00:45<00:22,  2.76it/s]Evaluating:  67%|██████▋   | 125/186 [00:45<00:22,  2.73it/s]Evaluating:  68%|██████▊   | 126/186 [00:46<00:21,  2.75it/s]Evaluating:  68%|██████▊   | 127/186 [00:46<00:21,  2.75it/s]Evaluating:  69%|██████▉   | 128/186 [00:46<00:21,  2.76it/s]Evaluating:  69%|██████▉   | 129/186 [00:47<00:20,  2.76it/s]Evaluating:  70%|██████▉   | 130/186 [00:47<00:20,  2.76it/s]Evaluating:  70%|███████   | 131/186 [00:48<00:19,  2.77it/s]Evaluating:  71%|███████   | 132/186 [00:48<00:19,  2.76it/s]Evaluating:  72%|███████▏  | 133/186 [00:48<00:19,  2.76it/s]Evaluating:  72%|███████▏  | 134/186 [00:49<00:18,  2.76it/s]Evaluating:  73%|███████▎  | 135/186 [00:49<00:18,  2.76it/s]Evaluating:  73%|███████▎  | 136/186 [00:49<00:18,  2.76it/s]Evaluating:  74%|███████▎  | 137/186 [00:50<00:17,  2.75it/s]Evaluating:  74%|███████▍  | 138/186 [00:50<00:17,  2.75it/s]Evaluating:  75%|███████▍  | 139/186 [00:50<00:17,  2.76it/s]Evaluating:  75%|███████▌  | 140/186 [00:51<00:16,  2.75it/s]Evaluating:  76%|███████▌  | 141/186 [00:51<00:16,  2.75it/s]Evaluating:  76%|███████▋  | 142/186 [00:52<00:15,  2.75it/s]Evaluating:  77%|███████▋  | 143/186 [00:52<00:15,  2.75it/s]Evaluating:  77%|███████▋  | 144/186 [00:52<00:15,  2.76it/s]Evaluating:  78%|███████▊  | 145/186 [00:53<00:14,  2.76it/s]Evaluating:  78%|███████▊  | 146/186 [00:53<00:14,  2.75it/s]Evaluating:  79%|███████▉  | 147/186 [00:53<00:14,  2.76it/s]Evaluating:  80%|███████▉  | 148/186 [00:54<00:13,  2.76it/s]Evaluating:  80%|████████  | 149/186 [00:54<00:13,  2.76it/s]Evaluating:  81%|████████  | 150/186 [00:54<00:13,  2.75it/s]Evaluating:  81%|████████  | 151/186 [00:55<00:12,  2.75it/s]Evaluating:  82%|████████▏ | 152/186 [00:55<00:12,  2.74it/s]Evaluating:  82%|████████▏ | 153/186 [00:56<00:11,  2.75it/s]Evaluating:  83%|████████▎ | 154/186 [00:56<00:11,  2.75it/s]Evaluating:  83%|████████▎ | 155/186 [00:56<00:11,  2.76it/s]Evaluating:  84%|████████▍ | 156/186 [00:57<00:10,  2.76it/s]Evaluating:  84%|████████▍ | 157/186 [00:57<00:10,  2.76it/s]Evaluating:  85%|████████▍ | 158/186 [00:57<00:10,  2.76it/s]Evaluating:  85%|████████▌ | 159/186 [00:58<00:09,  2.76it/s]Evaluating:  86%|████████▌ | 160/186 [00:58<00:09,  2.76it/s]Evaluating:  87%|████████▋ | 161/186 [00:58<00:09,  2.72it/s]Evaluating:  87%|████████▋ | 162/186 [00:59<00:08,  2.74it/s]Evaluating:  88%|████████▊ | 163/186 [00:59<00:08,  2.74it/s]Evaluating:  88%|████████▊ | 164/186 [01:00<00:08,  2.73it/s]Evaluating:  89%|████████▊ | 165/186 [01:00<00:07,  2.75it/s]Evaluating:  89%|████████▉ | 166/186 [01:00<00:07,  2.75it/s]Evaluating:  90%|████████▉ | 167/186 [01:01<00:06,  2.76it/s]Evaluating:  90%|█████████ | 168/186 [01:01<00:06,  2.76it/s]Evaluating:  91%|█████████ | 169/186 [01:01<00:06,  2.76it/s]Evaluating:  91%|█████████▏| 170/186 [01:02<00:05,  2.76it/s]Evaluating:  92%|█████████▏| 171/186 [01:02<00:05,  2.76it/s]Evaluating:  92%|█████████▏| 172/186 [01:02<00:05,  2.76it/s]Evaluating:  93%|█████████▎| 173/186 [01:03<00:04,  2.76it/s]Evaluating:  94%|█████████▎| 174/186 [01:03<00:04,  2.76it/s]Evaluating:  94%|█████████▍| 175/186 [01:04<00:03,  2.75it/s]Evaluating:  95%|█████████▍| 176/186 [01:04<00:03,  2.75it/s]Evaluating:  95%|█████████▌| 177/186 [01:04<00:03,  2.74it/s]Evaluating:  96%|█████████▌| 178/186 [01:05<00:02,  2.75it/s]Evaluating:  96%|█████████▌| 179/186 [01:05<00:02,  2.73it/s]Evaluating:  97%|█████████▋| 180/186 [01:05<00:02,  2.74it/s]Evaluating:  97%|█████████▋| 181/186 [01:06<00:01,  2.75it/s]Evaluating:  98%|█████████▊| 182/186 [01:06<00:01,  2.75it/s]Evaluating:  98%|█████████▊| 183/186 [01:06<00:01,  2.75it/s]Evaluating:  99%|█████████▉| 184/186 [01:07<00:00,  2.75it/s]Evaluating:  99%|█████████▉| 185/186 [01:07<00:00,  2.75it/s]Evaluating: 100%|██████████| 186/186 [01:08<00:00,  2.75it/s]Evaluating: 100%|██████████| 186/186 [01:08<00:00,  2.73it/s]
05/09/2022 19:57:58 - INFO - __main__ -     Evaluation done in total 68.021172 secs (0.045713 sec per example)
05/09/2022 19:58:02 - INFO - __main__ -   Results: {'exact': 61.260504201680675, 'f1': 79.1771355694199, 'total': 1190, 'HasAns_exact': 61.260504201680675, 'HasAns_f1': 79.1771355694199, 'HasAns_total': 1190, 'best_exact': 61.260504201680675, 'best_exact_thresh': 0.0, 'best_f1': 79.1771355694199, 'best_f1_thresh': 0.0}
  ru 
2022-05-09 19:58:04.422472: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0
05/09/2022 19:58:06 - WARNING - __main__ -   Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, 16-bits training: False
You are using a model of type xlm-roberta to instantiate a model of type xlm. This is not supported for all configurations of models and can yield errors.
Some weights of the model checkpoint at /cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//squad/xlm-KG_LR8e-6_EPOCH2.0_maxlen384_batchsize4_gradacc4 were not used when initializing XLMRobertaModel: ['base_model.encoder.layer.1.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.10.attention.output.LayerNorm.weight', 'base_model.encoder.layer.4.attention.self.query.bias', 'base_model.encoder.layer.10.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.19.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.0.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.3.output.LayerNorm.bias', 'base_model.encoder.layer.8.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.21.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.15.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.20.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.17.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.16.attention.output.LayerNorm.weight', 'base_model.encoder.layer.5.attention.self.value.bias', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.20.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.17.intermediate.dense.bias', 'base_model.encoder.layer.14.output.dense.weight', 'base_model.encoder.layer.2.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.8.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.23.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.21.intermediate.dense.bias', 'base_model.encoder.layer.13.attention.output.dense.bias', 'base_model.encoder.layer.21.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.23.attention.self.query.weight', 'base_model.encoder.layer.7.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.4.output.LayerNorm.bias', 'base_model.encoder.layer.5.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.2.output.dense.weight', 'base_model.encoder.layer.10.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.13.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.20.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.13.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.20.output.dense.bias', 'base_model.encoder.layer.19.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.16.attention.self.key.bias', 'base_model.encoder.layer.20.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.12.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.22.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.10.intermediate.dense.bias', 'base_model.encoder.layer.18.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.1.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.15.attention.self.value.weight', 'base_model.encoder.layer.18.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.15.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.2.intermediate.dense.bias', 'base_model.encoder.layer.6.attention.output.LayerNorm.weight', 'base_model.encoder.layer.22.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.10.output.LayerNorm.weight', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.16.attention.self.query.weight', 'base_model.encoder.layer.8.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.1.attention.output.dense.bias', 'base_model.encoder.layer.19.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.11.attention.self.query.bias', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.15.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.18.attention.self.value.bias', 'base_model.encoder.layer.21.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.22.attention.self.value.bias', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.0.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.17.intermediate.dense.weight', 'base_model.encoder.layer.21.attention.output.LayerNorm.bias', 'base_model.encoder.layer.23.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.8.output.dense.bias', 'base_model.encoder.layer.1.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.20.attention.self.value.bias', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.7.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.8.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.9.output.LayerNorm.weight', 'base_model.encoder.layer.9.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.17.attention.output.LayerNorm.bias', 'base_model.encoder.layer.11.attention.self.key.bias', 'base_model.encoder.layer.7.attention.self.key.weight', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.16.output.LayerNorm.bias', 'base_model.encoder.layer.14.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.5.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.8.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.0.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.14.attention.output.dense.bias', 'base_model.encoder.layer.12.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.13.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.6.output.dense.bias', 'base_model.encoder.layer.23.attention.self.query.bias', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.23.attention.output.LayerNorm.bias', 'base_model.encoder.layer.10.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.21.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.2.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.0.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.6.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.10.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.21.output.LayerNorm.weight', 'base_model.encoder.layer.14.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.10.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.1.attention.self.key.bias', 'base_model.encoder.layer.18.attention.self.query.bias', 'base_model.encoder.layer.2.attention.self.query.weight', 'base_model.encoder.layer.2.attention.output.LayerNorm.weight', 'base_model.encoder.layer.16.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.19.attention.self.query.bias', 'base_model.encoder.layer.22.output.dense.weight', 'base_model.encoder.layer.19.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.18.intermediate.dense.bias', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.0.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.17.attention.self.key.bias', 'base_model.encoder.layer.3.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.10.attention.output.LayerNorm.bias', 'base_model.encoder.layer.2.attention.self.key.weight', 'base_model.encoder.layer.0.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.14.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.22.output.LayerNorm.bias', 'base_model.encoder.layer.5.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.0.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.3.attention.self.query.bias', 'base_model.encoder.layer.19.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.12.attention.output.LayerNorm.weight', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.1.output.dense.weight', 'base_model.encoder.layer.15.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.3.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.21.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.2.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.10.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.3.output.LayerNorm.weight', 'base_model.encoder.layer.11.output.dense.bias', 'base_model.encoder.layer.23.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.13.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.12.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.23.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.18.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.22.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.23.attention.self.value.weight', 'base_model.encoder.layer.16.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.18.attention.self.value.weight', 'base_model.encoder.layer.14.attention.output.LayerNorm.bias', 'base_model.encoder.layer.17.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.20.intermediate.dense.bias', 'base_model.encoder.layer.11.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.8.attention.output.dense.bias', 'base_model.encoder.layer.14.output.LayerNorm.weight', 'base_model.encoder.layer.14.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.18.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.20.intermediate.dense.weight', 'base_model.encoder.layer.20.output.LayerNorm.bias', 'base_model.encoder.layer.20.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.7.attention.output.LayerNorm.weight', 'base_model.encoder.layer.6.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.3.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.13.attention.self.query.weight', 'base_model.encoder.layer.9.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.1.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.16.output.dense.weight', 'base_model.encoder.layer.20.output.dense.weight', 'base_model.encoder.layer.15.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.3.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.8.attention.self.value.bias', 'base_model.encoder.layer.15.attention.self.key.bias', 'base_model.encoder.layer.13.attention.self.key.weight', 'base_model.encoder.layer.20.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.6.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.15.intermediate.dense.weight', 'base_model.encoder.layer.11.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.16.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.15.output.LayerNorm.bias', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.23.attention.self.key.bias', 'base_model.encoder.layer.23.output.LayerNorm.bias', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.22.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.12.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.18.attention.output.LayerNorm.weight', 'base_model.encoder.layer.3.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.6.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.11.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.2.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.0.attention.self.query.bias', 'base_model.encoder.layer.6.attention.self.value.bias', 'base_model.encoder.layer.9.attention.self.key.bias', 'base_model.encoder.layer.11.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.17.output.dense.bias', 'base_model.encoder.layer.15.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.6.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.22.attention.output.LayerNorm.weight', 'base_model.encoder.layer.14.attention.self.key.bias', 'base_model.encoder.layer.12.output.LayerNorm.bias', 'base_model.encoder.layer.9.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.1.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.11.attention.self.key.weight', 'base_model.encoder.layer.15.attention.self.query.bias', 'base_model.encoder.layer.6.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.21.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.20.attention.output.dense.bias', 'base_model.encoder.layer.19.intermediate.dense.weight', 'base_model.encoder.layer.16.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.4.attention.self.key.bias', 'base_model.encoder.layer.6.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.20.output.LayerNorm.weight', 'base_model.encoder.layer.3.attention.self.value.weight', 'base_model.encoder.layer.7.attention.self.value.bias', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.9.output.dense.bias', 'base_model.encoder.layer.22.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.8.attention.self.query.weight', 'base_model.encoder.layer.5.attention.output.LayerNorm.bias', 'base_model.encoder.layer.14.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.8.attention.output.LayerNorm.bias', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.16.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.5.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.15.output.LayerNorm.weight', 'base_model.encoder.layer.13.output.dense.weight', 'base_model.encoder.layer.8.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.11.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.3.attention.self.key.bias', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.21.intermediate.dense.weight', 'base_model.encoder.layer.14.output.adapters.ts.adapter_up.weight', 'base_model.embeddings.LayerNorm.weight', 'base_model.encoder.layer.17.attention.self.key.weight', 'base_model.encoder.layer.18.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.15.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.5.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.17.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.19.attention.self.query.weight', 'base_model.encoder.layer.23.output.dense.weight', 'base_model.encoder.layer.0.attention.output.LayerNorm.weight', 'base_model.encoder.layer.5.attention.self.key.bias', 'base_model.encoder.layer.15.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.21.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.19.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.6.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.1.attention.self.value.bias', 'base_model.encoder.layer.3.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.3.attention.output.dense.weight', 'base_model.encoder.layer.1.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.7.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.12.intermediate.dense.bias', 'base_model.encoder.layer.23.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.4.attention.output.LayerNorm.weight', 'base_model.encoder.layer.7.attention.output.dense.bias', 'base_model.encoder.layer.3.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.9.output.dense.weight', 'base_model.encoder.layer.2.attention.self.key.bias', 'base_model.encoder.layer.10.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.14.attention.self.key.weight', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.11.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.21.attention.self.key.weight', 'base_model.encoder.layer.3.output.dense.bias', 'base_model.encoder.layer.17.attention.self.value.bias', 'base_model.encoder.layer.17.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.1.attention.self.value.weight', 'base_model.encoder.layer.15.output.dense.bias', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.18.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.1.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.4.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.11.attention.output.LayerNorm.weight', 'base_model.encoder.layer.14.output.dense.bias', 'base_model.encoder.layer.19.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.16.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.15.attention.self.key.weight', 'base_model.encoder.layer.9.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.22.intermediate.dense.bias', 'base_model.encoder.layer.13.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.11.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.17.output.LayerNorm.bias', 'base_model.encoder.layer.12.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.20.attention.output.dense.weight', 'base_model.encoder.layer.10.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.14.attention.self.query.weight', 'base_model.encoder.layer.4.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.4.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.1.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.16.attention.self.query.bias', 'base_model.encoder.layer.19.attention.self.value.weight', 'base_model.encoder.layer.7.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.7.intermediate.dense.bias', 'base_model.encoder.layer.19.attention.output.LayerNorm.bias', 'base_model.encoder.layer.8.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.19.output.LayerNorm.bias', 'base_model.encoder.layer.15.attention.self.value.bias', 'base_model.encoder.layer.5.output.LayerNorm.bias', 'base_model.encoder.layer.11.attention.output.dense.weight', 'base_model.encoder.layer.10.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.15.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.23.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.18.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.9.attention.self.value.bias', 'base_model.encoder.layer.6.attention.self.query.weight', 'base_model.encoder.layer.0.attention.self.key.weight', 'base_model.encoder.layer.7.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.5.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.19.attention.self.key.weight', 'base_model.encoder.layer.11.output.LayerNorm.weight', 'base_model.encoder.layer.20.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.8.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.16.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.1.output.LayerNorm.bias', 'base_model.encoder.layer.5.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.23.output.LayerNorm.weight', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.embeddings.position_embeddings.weight', 'base_model.encoder.layer.2.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.20.attention.self.value.weight', 'base_model.encoder.layer.14.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.8.attention.self.key.weight', 'base_model.encoder.layer.15.output.dense.weight', 'base_model.encoder.layer.10.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.17.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.0.attention.output.LayerNorm.bias', 'base_model.encoder.layer.8.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.9.attention.self.query.weight', 'base_model.encoder.layer.9.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.15.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.22.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.22.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.23.output.dense.bias', 'base_model.encoder.layer.20.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.9.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.12.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.20.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.5.output.dense.bias', 'base_model.encoder.layer.9.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.13.intermediate.dense.bias', 'base_model.encoder.layer.16.output.dense.bias', 'base_model.encoder.layer.18.attention.output.dense.bias', 'base_model.encoder.layer.18.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.11.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.18.attention.self.query.weight', 'base_model.encoder.layer.19.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.22.attention.self.key.weight', 'base_model.encoder.layer.9.attention.output.LayerNorm.weight', 'base_model.encoder.layer.19.attention.output.dense.bias', 'base_model.encoder.layer.6.attention.self.value.weight', 'base_model.encoder.layer.0.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.20.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.7.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.9.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.12.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.11.intermediate.dense.weight', 'base_model.encoder.layer.7.intermediate.dense.weight', 'base_model.encoder.layer.23.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.16.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.19.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.14.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.8.attention.self.query.bias', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.18.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.13.output.dense.bias', 'base_model.encoder.layer.8.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.21.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.12.attention.output.LayerNorm.bias', 'base_model.encoder.layer.22.attention.self.key.bias', 'base_model.encoder.layer.21.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.1.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.2.attention.self.value.bias', 'base_model.encoder.layer.5.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.3.intermediate.dense.bias', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.22.output.dense.bias', 'base_model.encoder.layer.19.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.0.attention.self.query.weight', 'base_model.encoder.layer.3.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.11.output.dense.weight', 'base_model.encoder.layer.1.intermediate.dense.bias', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.18.output.dense.weight', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.21.output.LayerNorm.bias', 'base_model.encoder.layer.21.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.2.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.1.output.LayerNorm.weight', 'base_model.encoder.layer.5.attention.self.query.weight', 'base_model.encoder.layer.12.output.LayerNorm.weight', 'base_model.encoder.layer.10.attention.output.dense.bias', 'base_model.encoder.layer.9.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.21.output.dense.weight', 'base_model.encoder.layer.7.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.6.attention.output.dense.bias', 'base_model.encoder.layer.16.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.7.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.5.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.4.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.0.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.18.output.LayerNorm.weight', 'qa_outputs.weight', 'base_model.encoder.layer.14.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.7.output.LayerNorm.weight', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.4.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.11.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.3.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.pooler.dense.bias', 'base_model.encoder.layer.14.output.LayerNorm.bias', 'base_model.encoder.layer.6.attention.self.key.weight', 'base_model.encoder.layer.14.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.16.attention.self.value.weight', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.14.attention.self.value.bias', 'base_model.encoder.layer.7.attention.self.key.bias', 'base_model.encoder.layer.8.attention.self.key.bias', 'base_model.encoder.layer.16.attention.output.dense.bias', 'base_model.encoder.layer.8.attention.output.dense.weight', 'base_model.encoder.layer.0.attention.self.key.bias', 'base_model.encoder.layer.10.output.LayerNorm.bias', 'base_model.encoder.layer.8.attention.self.value.weight', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.18.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.9.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.20.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.5.output.dense.weight', 'base_model.encoder.layer.11.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.22.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.9.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.13.attention.self.query.bias', 'base_model.encoder.layer.4.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.4.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.4.output.dense.weight', 'base_model.encoder.layer.20.attention.output.LayerNorm.bias', 'base_model.encoder.layer.10.attention.self.key.bias', 'base_model.encoder.layer.23.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.18.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.12.attention.self.query.bias', 'base_model.encoder.layer.17.output.adapters.ep.adapter_down.0.weight', 'base_model.pooler.dense.weight', 'base_model.encoder.layer.0.intermediate.dense.weight', 'base_model.encoder.layer.0.attention.output.dense.bias', 'base_model.encoder.layer.7.output.dense.bias', 'base_model.encoder.layer.0.output.dense.weight', 'base_model.encoder.layer.0.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.1.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.8.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.1.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.6.attention.self.query.bias', 'base_model.encoder.layer.2.intermediate.dense.weight', 'base_model.encoder.layer.8.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.11.attention.self.value.bias', 'base_model.encoder.layer.1.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.13.output.LayerNorm.bias', 'base_model.encoder.layer.8.intermediate.dense.bias', 'base_model.encoder.layer.17.attention.self.value.weight', 'base_model.encoder.layer.7.output.dense.weight', 'base_model.encoder.layer.10.attention.self.query.bias', 'base_model.encoder.layer.13.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.3.attention.self.key.weight', 'base_model.encoder.layer.7.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.18.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.5.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.13.attention.output.dense.weight', 'base_model.encoder.layer.10.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.22.attention.output.dense.bias', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.7.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.4.intermediate.dense.bias', 'base_model.encoder.layer.9.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.8.output.LayerNorm.weight', 'base_model.encoder.layer.0.intermediate.dense.bias', 'base_model.encoder.layer.11.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.5.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.23.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.13.intermediate.dense.weight', 'base_model.encoder.layer.2.attention.self.value.weight', 'base_model.encoder.layer.14.intermediate.dense.bias', 'base_model.encoder.layer.16.attention.output.dense.weight', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.17.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.17.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.16.attention.self.key.weight', 'base_model.encoder.layer.20.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.2.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.3.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.22.output.LayerNorm.weight', 'base_model.encoder.layer.17.attention.output.dense.bias', 'base_model.encoder.layer.21.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.22.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.17.attention.self.query.weight', 'base_model.encoder.layer.19.output.LayerNorm.weight', 'base_model.encoder.layer.0.attention.output.dense.weight', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.19.attention.self.value.bias', 'base_model.encoder.layer.5.attention.output.dense.bias', 'base_model.encoder.layer.5.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.13.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.15.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.15.attention.self.query.weight', 'base_model.encoder.layer.1.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.10.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.6.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.embeddings.position_ids', 'base_model.encoder.layer.23.attention.output.LayerNorm.weight', 'base_model.encoder.layer.23.attention.output.dense.weight', 'base_model.encoder.layer.12.intermediate.dense.weight', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.23.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.8.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.16.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.22.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.21.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.0.output.dense.bias', 'base_model.encoder.layer.9.attention.self.query.bias', 'base_model.encoder.layer.7.output.LayerNorm.bias', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.21.output.dense.bias', 'base_model.encoder.layer.9.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.21.attention.output.dense.weight', 'base_model.encoder.layer.12.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.19.attention.self.key.bias', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.23.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.11.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.7.attention.self.query.bias', 'base_model.encoder.layer.13.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.14.attention.output.LayerNorm.weight', 'base_model.encoder.layer.2.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.20.attention.self.query.bias', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.7.attention.output.dense.weight', 'base_model.encoder.layer.1.attention.output.dense.weight', 'base_model.encoder.layer.11.attention.self.query.weight', 'base_model.encoder.layer.23.attention.output.dense.bias', 'base_model.encoder.layer.20.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.4.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.9.intermediate.dense.weight', 'base_model.encoder.layer.13.attention.self.value.weight', 'base_model.encoder.layer.19.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.16.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.21.attention.self.value.weight', 'base_model.encoder.layer.22.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.23.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.15.attention.output.LayerNorm.bias', 'base_model.encoder.layer.17.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.6.output.LayerNorm.weight', 'base_model.encoder.layer.14.attention.self.value.weight', 'base_model.encoder.layer.4.attention.self.key.weight', 'base_model.encoder.layer.1.attention.self.query.bias', 'base_model.encoder.layer.8.output.dense.weight', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.embeddings.word_embeddings.weight', 'base_model.encoder.layer.11.attention.self.value.weight', 'base_model.encoder.layer.9.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.18.output.LayerNorm.bias', 'base_model.encoder.layer.21.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.18.attention.output.dense.weight', 'base_model.encoder.layer.4.attention.output.dense.weight', 'base_model.encoder.layer.10.attention.self.query.weight', 'base_model.encoder.layer.13.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.9.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.4.attention.self.value.weight', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.17.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.8.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.1.output.dense.bias', 'base_model.encoder.layer.23.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.12.attention.self.key.weight', 'base_model.encoder.layer.12.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.10.attention.self.key.weight', 'base_model.encoder.layer.6.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.15.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.9.output.LayerNorm.bias', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.5.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.5.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.6.intermediate.dense.bias', 'base_model.encoder.layer.3.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.14.attention.output.dense.weight', 'base_model.encoder.layer.17.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.15.attention.output.LayerNorm.weight', 'base_model.encoder.layer.3.attention.output.LayerNorm.weight', 'base_model.encoder.layer.18.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.4.attention.self.query.weight', 'base_model.encoder.layer.2.output.LayerNorm.weight', 'base_model.encoder.layer.23.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.3.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.19.output.adapters.es.adapter_up.weight', 'qa_outputs.bias', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.15.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.1.intermediate.dense.weight', 'base_model.encoder.layer.17.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.3.intermediate.dense.weight', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.2.attention.output.dense.bias', 'base_model.encoder.layer.3.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.5.attention.self.key.weight', 'base_model.encoder.layer.18.attention.self.key.weight', 'base_model.encoder.layer.10.attention.self.value.weight', 'base_model.encoder.layer.21.attention.output.LayerNorm.weight', 'base_model.encoder.layer.22.attention.self.query.bias', 'base_model.encoder.layer.23.attention.self.key.weight', 'base_model.encoder.layer.2.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.14.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.6.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.7.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.16.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.13.attention.output.LayerNorm.weight', 'base_model.encoder.layer.17.output.dense.weight', 'base_model.encoder.layer.9.attention.self.key.weight', 'base_model.encoder.layer.10.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.2.attention.output.dense.weight', 'base_model.encoder.layer.3.attention.output.LayerNorm.bias', 'base_model.encoder.layer.0.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.2.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.8.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.14.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.7.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.6.intermediate.dense.weight', 'base_model.encoder.layer.21.attention.output.dense.bias', 'base_model.encoder.layer.5.attention.output.dense.weight', 'base_model.encoder.layer.4.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.16.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.13.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.19.output.dense.bias', 'base_model.encoder.layer.15.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.18.attention.self.key.bias', 'base_model.encoder.layer.12.attention.self.value.bias', 'base_model.encoder.layer.2.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.9.attention.output.dense.weight', 'base_model.encoder.layer.10.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.11.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.23.attention.self.value.bias', 'base_model.encoder.layer.21.attention.self.value.bias', 'base_model.encoder.layer.11.output.LayerNorm.bias', 'base_model.encoder.layer.4.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.1.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.10.output.dense.bias', 'base_model.encoder.layer.12.attention.self.query.weight', 'base_model.encoder.layer.12.attention.output.dense.bias', 'base_model.encoder.layer.0.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.6.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.22.attention.output.LayerNorm.bias', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.12.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.6.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.4.attention.self.value.bias', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.5.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.21.attention.self.key.bias', 'base_model.encoder.layer.12.attention.self.key.bias', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.4.output.LayerNorm.weight', 'base_model.encoder.layer.14.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.23.intermediate.dense.weight', 'base_model.encoder.layer.12.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.10.attention.output.dense.weight', 'base_model.encoder.layer.5.intermediate.dense.bias', 'base_model.encoder.layer.8.intermediate.dense.weight', 'base_model.encoder.layer.7.attention.self.value.weight', 'base_model.encoder.layer.2.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.12.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.6.output.LayerNorm.bias', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.13.attention.self.key.bias', 'base_model.encoder.layer.20.attention.self.query.weight', 'base_model.encoder.layer.12.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.13.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.5.attention.self.query.bias', 'base_model.encoder.layer.6.output.dense.weight', 'base_model.encoder.layer.16.attention.output.LayerNorm.bias', 'base_model.encoder.layer.19.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.2.attention.output.LayerNorm.bias', 'base_model.encoder.layer.4.intermediate.dense.weight', 'base_model.encoder.layer.0.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.0.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.1.attention.output.LayerNorm.bias', 'base_model.encoder.layer.22.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.14.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.6.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.5.attention.output.LayerNorm.weight', 'base_model.encoder.layer.0.attention.self.value.bias', 'base_model.encoder.layer.3.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.23.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.19.output.dense.weight', 'base_model.encoder.layer.9.attention.self.value.weight', 'base_model.encoder.layer.16.output.LayerNorm.weight', 'base_model.encoder.layer.22.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.7.attention.self.query.weight', 'base_model.encoder.layer.0.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.3.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.22.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.22.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.17.output.LayerNorm.weight', 'base_model.encoder.layer.1.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.18.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.3.output.dense.weight', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.14.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.7.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.3.attention.self.value.bias', 'base_model.encoder.layer.1.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.19.attention.output.LayerNorm.weight', 'base_model.encoder.layer.4.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.8.output.LayerNorm.bias', 'base_model.encoder.layer.13.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.19.intermediate.dense.bias', 'base_model.encoder.layer.14.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.20.attention.self.key.weight', 'base_model.encoder.layer.0.output.LayerNorm.bias', 'base_model.encoder.layer.15.attention.output.dense.weight', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.13.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.7.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.7.attention.output.LayerNorm.bias', 'base_model.encoder.layer.18.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.5.intermediate.dense.weight', 'base_model.encoder.layer.2.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.12.output.dense.bias', 'base_model.encoder.layer.8.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.1.attention.self.query.weight', 'base_model.encoder.layer.4.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.5.attention.self.value.weight', 'base_model.encoder.layer.19.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.22.attention.self.value.weight', 'base_model.encoder.layer.9.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.5.output.LayerNorm.weight', 'base_model.encoder.layer.6.attention.self.key.bias', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.5.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.23.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.15.intermediate.dense.bias', 'base_model.encoder.layer.0.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.20.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.2.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.15.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.1.attention.self.key.weight', 'base_model.encoder.layer.13.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.11.attention.output.dense.bias', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.12.attention.output.dense.weight', 'base_model.encoder.layer.16.intermediate.dense.bias', 'base_model.encoder.layer.12.attention.self.value.weight', 'base_model.encoder.layer.4.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.10.output.dense.weight', 'base_model.encoder.layer.18.intermediate.dense.weight', 'base_model.encoder.layer.17.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.11.attention.output.LayerNorm.bias', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.3.attention.output.dense.bias', 'base_model.encoder.layer.0.attention.self.value.weight', 'base_model.encoder.layer.11.intermediate.dense.bias', 'base_model.encoder.layer.16.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.17.attention.output.LayerNorm.weight', 'base_model.encoder.layer.6.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.6.attention.output.dense.weight', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.18.output.dense.bias', 'base_model.encoder.layer.11.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.15.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.21.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.10.intermediate.dense.weight', 'base_model.encoder.layer.16.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.2.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.13.output.LayerNorm.weight', 'base_model.encoder.layer.16.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.21.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.9.intermediate.dense.bias', 'base_model.encoder.layer.3.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.21.attention.self.query.bias', 'base_model.encoder.layer.10.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.19.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.21.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.4.output.dense.bias', 'base_model.encoder.layer.12.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.20.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.4.attention.output.dense.bias', 'base_model.encoder.layer.9.attention.output.dense.bias', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.2.output.LayerNorm.bias', 'base_model.encoder.layer.4.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.23.intermediate.dense.bias', 'base_model.encoder.layer.18.attention.output.LayerNorm.bias', 'base_model.embeddings.token_type_embeddings.weight', 'base_model.embeddings.LayerNorm.bias', 'base_model.encoder.layer.2.attention.self.query.bias', 'base_model.encoder.layer.13.attention.output.LayerNorm.bias', 'base_model.encoder.layer.9.attention.output.LayerNorm.bias', 'base_model.encoder.layer.18.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.4.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.17.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.13.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.2.output.dense.bias', 'base_model.encoder.layer.22.attention.output.dense.weight', 'base_model.encoder.layer.17.attention.output.dense.weight', 'base_model.encoder.layer.17.attention.self.query.bias', 'base_model.encoder.layer.7.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.17.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.21.attention.self.query.weight', 'base_model.encoder.layer.13.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.13.attention.self.value.bias', 'base_model.encoder.layer.4.attention.output.LayerNorm.bias', 'base_model.encoder.layer.11.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.12.output.dense.weight', 'base_model.encoder.layer.16.attention.self.value.bias', 'base_model.encoder.layer.4.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.22.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.2.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.8.attention.output.LayerNorm.weight', 'base_model.encoder.layer.10.attention.self.value.bias', 'base_model.encoder.layer.11.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.12.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.14.attention.self.query.bias', 'base_model.encoder.layer.14.intermediate.dense.weight', 'base_model.encoder.layer.20.attention.output.LayerNorm.weight', 'base_model.encoder.layer.7.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.6.attention.output.LayerNorm.bias', 'base_model.encoder.layer.22.attention.self.query.weight', 'base_model.encoder.layer.10.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.19.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.20.attention.self.key.bias', 'base_model.encoder.layer.16.intermediate.dense.weight', 'base_model.encoder.layer.6.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.19.attention.output.dense.weight', 'base_model.encoder.layer.1.attention.output.LayerNorm.weight', 'base_model.encoder.layer.15.attention.output.dense.bias', 'base_model.encoder.layer.0.output.LayerNorm.weight', 'base_model.encoder.layer.3.attention.self.query.weight', 'base_model.encoder.layer.22.intermediate.dense.weight', 'base_model.encoder.layer.12.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.17.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.20.output.adapters.tp.adapter_down.0.bias']
- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of XLMRobertaModel were not initialized from the model checkpoint at /cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//squad/xlm-KG_LR8e-6_EPOCH2.0_maxlen384_batchsize4_gradacc4 and are newly initialized: ['encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.13.attention.self.key.bias', 'encoder.layer.5.attention.self.query.bias', 'encoder.layer.10.attention.self.key.bias', 'encoder.layer.11.attention.self.key.weight', 'encoder.layer.19.attention.output.LayerNorm.bias', 'encoder.layer.23.attention.self.value.weight', 'encoder.layer.10.output.LayerNorm.bias', 'encoder.layer.15.attention.self.key.weight', 'encoder.layer.2.attention.output.dense.weight', 'encoder.layer.17.output.dense.weight', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.2.attention.self.key.bias', 'encoder.layer.11.attention.output.LayerNorm.weight', 'encoder.layer.5.output.dense.bias', 'encoder.layer.2.attention.self.value.weight', 'encoder.layer.8.attention.self.value.bias', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.18.output.LayerNorm.weight', 'encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.layer.2.attention.self.value.bias', 'encoder.layer.12.intermediate.dense.bias', 'encoder.layer.8.attention.self.key.weight', 'encoder.layer.14.attention.self.query.weight', 'encoder.layer.12.output.dense.bias', 'encoder.layer.11.attention.output.dense.weight', 'encoder.layer.6.output.dense.weight', 'encoder.layer.22.output.dense.weight', 'encoder.layer.10.output.LayerNorm.weight', 'encoder.layer.12.output.dense.weight', 'encoder.layer.22.output.LayerNorm.bias', 'encoder.layer.16.intermediate.dense.bias', 'encoder.layer.22.attention.self.key.bias', 'encoder.layer.10.attention.output.LayerNorm.bias', 'encoder.layer.8.output.LayerNorm.bias', 'encoder.layer.0.attention.self.query.bias', 'encoder.layer.6.attention.self.query.weight', 'encoder.layer.22.attention.self.query.bias', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.12.attention.self.key.bias', 'encoder.layer.17.attention.self.query.weight', 'encoder.layer.17.output.LayerNorm.bias', 'encoder.layer.9.attention.self.value.bias', 'encoder.layer.9.output.dense.weight', 'encoder.layer.15.attention.output.LayerNorm.weight', 'encoder.layer.8.attention.self.query.bias', 'encoder.layer.16.output.LayerNorm.bias', 'encoder.layer.21.attention.output.dense.bias', 'encoder.layer.7.output.LayerNorm.weight', 'encoder.layer.4.attention.self.value.bias', 'encoder.layer.7.attention.output.LayerNorm.bias', 'encoder.layer.3.attention.self.query.weight', 'encoder.layer.17.attention.self.query.bias', 'encoder.layer.10.attention.self.value.weight', 'encoder.layer.19.attention.output.dense.weight', 'encoder.layer.20.output.dense.weight', 'encoder.layer.17.output.LayerNorm.weight', 'encoder.layer.0.attention.output.LayerNorm.weight', 'encoder.layer.0.attention.self.key.weight', 'encoder.layer.6.attention.self.value.weight', 'encoder.layer.7.intermediate.dense.bias', 'encoder.layer.9.attention.self.key.weight', 'encoder.layer.10.attention.output.dense.weight', 'encoder.layer.22.attention.self.query.weight', 'encoder.layer.7.output.dense.bias', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.15.output.LayerNorm.weight', 'encoder.layer.19.attention.self.key.weight', 'encoder.layer.12.output.LayerNorm.weight', 'encoder.layer.8.attention.self.value.weight', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.3.attention.self.key.bias', 'encoder.layer.8.output.dense.bias', 'encoder.layer.5.attention.self.key.bias', 'encoder.layer.9.attention.output.LayerNorm.bias', 'encoder.layer.9.attention.self.query.weight', 'encoder.layer.6.attention.self.key.weight', 'encoder.layer.11.attention.output.dense.bias', 'encoder.layer.18.output.dense.bias', 'encoder.layer.9.output.LayerNorm.bias', 'encoder.layer.13.output.dense.weight', 'encoder.layer.0.attention.output.dense.weight', 'encoder.layer.4.attention.self.value.weight', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.12.attention.self.key.weight', 'embeddings.token_type_embeddings.weight', 'encoder.layer.13.attention.output.dense.bias', 'encoder.layer.14.attention.self.query.bias', 'encoder.layer.18.attention.output.LayerNorm.weight', 'encoder.layer.15.attention.self.value.bias', 'encoder.layer.16.attention.self.query.weight', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.9.attention.output.dense.bias', 'encoder.layer.17.attention.output.LayerNorm.weight', 'encoder.layer.7.attention.output.dense.weight', 'embeddings.LayerNorm.bias', 'encoder.layer.17.attention.output.dense.weight', 'encoder.layer.7.attention.self.query.weight', 'encoder.layer.10.intermediate.dense.weight', 'encoder.layer.22.attention.output.dense.bias', 'encoder.layer.6.attention.self.query.bias', 'encoder.layer.10.attention.output.dense.bias', 'encoder.layer.15.attention.self.query.weight', 'encoder.layer.0.attention.self.value.bias', 'embeddings.position_embeddings.weight', 'encoder.layer.15.output.LayerNorm.bias', 'embeddings.word_embeddings.weight', 'encoder.layer.13.attention.self.value.weight', 'encoder.layer.15.attention.output.dense.weight', 'encoder.layer.16.output.LayerNorm.weight', 'encoder.layer.16.attention.output.dense.weight', 'encoder.layer.3.output.dense.weight', 'encoder.layer.19.attention.self.query.bias', 'encoder.layer.23.attention.output.dense.weight', 'encoder.layer.19.attention.self.query.weight', 'encoder.layer.21.output.LayerNorm.weight', 'encoder.layer.5.attention.output.dense.bias', 'encoder.layer.6.attention.output.dense.bias', 'encoder.layer.19.output.dense.bias', 'encoder.layer.14.output.dense.weight', 'encoder.layer.2.output.dense.weight', 'encoder.layer.4.attention.self.query.weight', 'encoder.layer.19.intermediate.dense.bias', 'encoder.layer.0.attention.self.query.weight', 'encoder.layer.3.attention.self.key.weight', 'encoder.layer.3.attention.output.dense.weight', 'encoder.layer.11.attention.self.value.weight', 'encoder.layer.12.intermediate.dense.weight', 'encoder.layer.2.attention.self.query.bias', 'encoder.layer.0.output.dense.weight', 'encoder.layer.17.attention.output.dense.bias', 'encoder.layer.18.intermediate.dense.weight', 'encoder.layer.8.output.dense.weight', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.20.attention.output.LayerNorm.weight', 'encoder.layer.12.attention.output.dense.weight', 'encoder.layer.11.attention.self.query.bias', 'encoder.layer.18.attention.self.key.bias', 'encoder.layer.15.intermediate.dense.weight', 'encoder.layer.15.attention.output.dense.bias', 'encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.19.attention.output.dense.bias', 'encoder.layer.16.attention.self.value.weight', 'encoder.layer.18.attention.self.query.bias', 'encoder.layer.3.attention.output.dense.bias', 'encoder.layer.5.attention.self.query.weight', 'encoder.layer.23.attention.self.query.weight', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.17.intermediate.dense.bias', 'encoder.layer.13.attention.output.dense.weight', 'encoder.layer.21.attention.self.key.weight', 'encoder.layer.1.attention.self.key.bias', 'encoder.layer.20.attention.output.dense.bias', 'encoder.layer.5.attention.output.LayerNorm.weight', 'encoder.layer.18.attention.output.LayerNorm.bias', 'encoder.layer.6.attention.output.LayerNorm.weight', 'encoder.layer.8.output.LayerNorm.weight', 'encoder.layer.4.attention.output.LayerNorm.weight', 'encoder.layer.7.attention.self.value.weight', 'encoder.layer.20.attention.self.key.bias', 'encoder.layer.4.output.dense.bias', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.22.attention.self.key.weight', 'encoder.layer.9.attention.output.LayerNorm.weight', 'encoder.layer.3.attention.self.value.weight', 'encoder.layer.2.attention.self.key.weight', 'encoder.layer.12.attention.self.value.bias', 'encoder.layer.14.output.LayerNorm.weight', 'encoder.layer.23.attention.output.LayerNorm.weight', 'encoder.layer.9.attention.self.key.bias', 'encoder.layer.17.output.dense.bias', 'encoder.layer.1.attention.self.query.weight', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.6.output.dense.bias', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.11.attention.self.query.weight', 'encoder.layer.10.output.dense.bias', 'encoder.layer.19.attention.self.value.bias', 'encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.layer.11.output.dense.bias', 'encoder.layer.23.output.LayerNorm.weight', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.12.attention.output.LayerNorm.weight', 'encoder.layer.23.attention.self.key.weight', 'encoder.layer.4.attention.output.dense.weight', 'encoder.layer.2.attention.output.dense.bias', 'encoder.layer.13.output.LayerNorm.weight', 'encoder.layer.19.attention.self.value.weight', 'encoder.layer.22.output.dense.bias', 'encoder.layer.15.output.dense.weight', 'encoder.layer.23.intermediate.dense.weight', 'encoder.layer.14.attention.self.key.bias', 'encoder.layer.11.attention.self.value.bias', 'encoder.layer.23.attention.output.LayerNorm.bias', 'encoder.layer.0.attention.output.dense.bias', 'encoder.layer.16.output.dense.weight', 'encoder.layer.21.attention.self.value.weight', 'encoder.layer.22.attention.output.dense.weight', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.16.attention.self.key.weight', 'encoder.layer.5.attention.self.value.bias', 'encoder.layer.16.attention.output.dense.bias', 'encoder.layer.7.attention.self.value.bias', 'encoder.layer.13.attention.self.query.weight', 'encoder.layer.23.attention.output.dense.bias', 'encoder.layer.23.output.dense.bias', 'encoder.layer.15.attention.self.query.bias', 'encoder.layer.18.attention.self.query.weight', 'encoder.layer.2.attention.output.LayerNorm.weight', 'encoder.layer.21.output.dense.bias', 'encoder.layer.14.attention.output.dense.bias', 'encoder.layer.21.attention.output.LayerNorm.bias', 'encoder.layer.10.attention.self.query.weight', 'encoder.layer.6.output.LayerNorm.bias', 'encoder.layer.23.output.LayerNorm.bias', 'encoder.layer.3.attention.self.query.bias', 'encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.layer.3.attention.self.value.bias', 'encoder.layer.18.output.LayerNorm.bias', 'encoder.layer.12.attention.self.query.weight', 'encoder.layer.7.output.LayerNorm.bias', 'encoder.layer.1.output.dense.weight', 'encoder.layer.17.intermediate.dense.weight', 'encoder.layer.17.attention.self.key.weight', 'encoder.layer.13.output.LayerNorm.bias', 'encoder.layer.0.attention.self.key.bias', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.14.intermediate.dense.weight', 'encoder.layer.17.attention.self.value.bias', 'encoder.layer.6.attention.output.LayerNorm.bias', 'encoder.layer.21.attention.self.key.bias', 'encoder.layer.16.output.dense.bias', 'encoder.layer.20.output.dense.bias', 'encoder.layer.5.attention.output.dense.weight', 'encoder.layer.17.attention.self.value.weight', 'encoder.layer.14.output.dense.bias', 'encoder.layer.20.output.LayerNorm.weight', 'encoder.layer.13.attention.output.LayerNorm.weight', 'encoder.layer.8.attention.output.dense.bias', 'encoder.layer.0.attention.self.value.weight', 'encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.4.attention.output.LayerNorm.bias', 'encoder.layer.20.output.LayerNorm.bias', 'encoder.layer.23.attention.self.query.bias', 'encoder.layer.8.attention.output.LayerNorm.bias', 'encoder.layer.7.attention.self.key.bias', 'encoder.layer.20.attention.self.query.weight', 'encoder.layer.2.attention.output.LayerNorm.bias', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.11.output.dense.weight', 'encoder.layer.12.attention.self.value.weight', 'encoder.layer.4.attention.self.key.bias', 'encoder.layer.20.intermediate.dense.bias', 'encoder.layer.16.attention.self.key.bias', 'encoder.layer.14.attention.output.LayerNorm.bias', 'encoder.layer.21.attention.self.query.bias', 'encoder.layer.20.intermediate.dense.weight', 'encoder.layer.19.attention.output.LayerNorm.weight', 'encoder.layer.10.output.dense.weight', 'encoder.layer.5.output.LayerNorm.bias', 'encoder.layer.18.attention.self.key.weight', 'encoder.layer.21.intermediate.dense.weight', 'encoder.layer.6.attention.output.dense.weight', 'encoder.layer.6.attention.self.key.bias', 'encoder.layer.22.attention.output.LayerNorm.weight', 'encoder.layer.9.output.dense.bias', 'encoder.layer.19.attention.self.key.bias', 'encoder.layer.13.attention.self.query.bias', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.20.attention.self.value.bias', 'encoder.layer.8.attention.output.LayerNorm.weight', 'encoder.layer.8.attention.self.query.weight', 'encoder.layer.16.attention.self.query.bias', 'encoder.layer.4.output.dense.weight', 'encoder.layer.19.output.LayerNorm.bias', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.14.attention.output.LayerNorm.weight', 'encoder.layer.1.attention.self.query.bias', 'encoder.layer.7.attention.self.key.weight', 'encoder.layer.5.output.dense.weight', 'encoder.layer.12.output.LayerNorm.bias', 'encoder.layer.20.attention.output.LayerNorm.bias', 'encoder.layer.1.attention.output.dense.bias', 'encoder.layer.9.attention.self.query.bias', 'encoder.layer.9.attention.output.dense.weight', 'encoder.layer.20.attention.self.value.weight', 'encoder.layer.18.attention.self.value.bias', 'encoder.layer.1.attention.self.value.weight', 'encoder.layer.1.output.dense.bias', 'encoder.layer.20.attention.self.key.weight', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.0.output.dense.bias', 'encoder.layer.19.output.dense.weight', 'encoder.layer.16.attention.self.value.bias', 'encoder.layer.22.attention.output.LayerNorm.bias', 'embeddings.LayerNorm.weight', 'encoder.layer.14.attention.output.dense.weight', 'encoder.layer.4.attention.output.dense.bias', 'encoder.layer.19.intermediate.dense.weight', 'encoder.layer.16.attention.output.LayerNorm.bias', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.13.attention.output.LayerNorm.bias', 'encoder.layer.22.intermediate.dense.weight', 'encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.layer.10.attention.self.key.weight', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.13.intermediate.dense.bias', 'encoder.layer.4.attention.self.query.bias', 'encoder.layer.2.attention.self.query.weight', 'encoder.layer.22.intermediate.dense.bias', 'encoder.layer.20.attention.self.query.bias', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.1.attention.self.value.bias', 'encoder.layer.18.intermediate.dense.bias', 'encoder.layer.14.output.LayerNorm.bias', 'encoder.layer.22.attention.self.value.weight', 'encoder.layer.3.output.dense.bias', 'encoder.layer.16.attention.output.LayerNorm.weight', 'encoder.layer.22.output.LayerNorm.weight', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.7.attention.self.query.bias', 'encoder.layer.13.intermediate.dense.weight', 'encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.23.intermediate.dense.bias', 'encoder.layer.11.output.LayerNorm.weight', 'encoder.layer.22.attention.self.value.bias', 'pooler.dense.bias', 'encoder.layer.10.attention.output.LayerNorm.weight', 'encoder.layer.15.attention.output.LayerNorm.bias', 'encoder.layer.19.output.LayerNorm.weight', 'encoder.layer.5.attention.self.key.weight', 'encoder.layer.14.attention.self.value.weight', 'encoder.layer.14.attention.self.value.bias', 'encoder.layer.18.attention.self.value.weight', 'encoder.layer.12.attention.output.LayerNorm.bias', 'encoder.layer.13.attention.self.key.weight', 'encoder.layer.15.attention.self.value.weight', 'encoder.layer.10.attention.self.query.bias', 'encoder.layer.11.output.LayerNorm.bias', 'encoder.layer.4.attention.self.key.weight', 'encoder.layer.21.intermediate.dense.bias', 'encoder.layer.5.attention.self.value.weight', 'encoder.layer.13.attention.self.value.bias', 'encoder.layer.12.attention.output.dense.bias', 'encoder.layer.11.attention.self.key.bias', 'encoder.layer.7.attention.output.dense.bias', 'encoder.layer.21.attention.self.query.weight', 'encoder.layer.18.attention.output.dense.bias', 'encoder.layer.7.attention.output.LayerNorm.weight', 'encoder.layer.1.attention.output.LayerNorm.weight', 'encoder.layer.17.attention.output.LayerNorm.bias', 'encoder.layer.20.attention.output.dense.weight', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.15.output.dense.bias', 'encoder.layer.17.attention.self.key.bias', 'encoder.layer.21.attention.self.value.bias', 'encoder.layer.6.attention.self.value.bias', 'encoder.layer.21.output.LayerNorm.bias', 'encoder.layer.8.attention.self.key.bias', 'encoder.layer.18.attention.output.dense.weight', 'encoder.layer.15.attention.self.key.bias', 'encoder.layer.14.attention.self.key.weight', 'encoder.layer.21.attention.output.dense.weight', 'encoder.layer.2.output.dense.bias', 'encoder.layer.23.output.dense.weight', 'encoder.layer.23.attention.self.key.bias', 'encoder.layer.23.attention.self.value.bias', 'encoder.layer.14.intermediate.dense.bias', 'encoder.layer.12.attention.self.query.bias', 'encoder.layer.9.attention.self.value.weight', 'encoder.layer.21.output.dense.weight', 'pooler.dense.weight', 'encoder.layer.9.output.LayerNorm.weight', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.18.output.dense.weight', 'encoder.layer.13.output.dense.bias', 'encoder.layer.10.attention.self.value.bias', 'encoder.layer.7.output.dense.weight', 'encoder.layer.15.intermediate.dense.bias', 'encoder.layer.16.intermediate.dense.weight', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.1.attention.output.dense.weight', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.8.attention.output.dense.weight', 'encoder.layer.1.attention.self.key.weight', 'encoder.layer.21.attention.output.LayerNorm.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Overwriting existing adapter 'ep'.
Overwriting existing adapter 'tp'.
Overwriting existing adapter 'es'.
Overwriting existing adapter 'ts'.
Overwriting existing adapter fusion module 'ep,tp,es,ts'
05/09/2022 19:58:32 - INFO - __main__ -   lang2id = None
05/09/2022 19:58:36 - INFO - __main__ -   Training/evaluation parameters Namespace(adam_epsilon=1e-08, cache_dir='', config_name='', data_dir=None, device=device(type='cuda'), do_eval=True, do_lower_case=False, do_train=False, doc_stride=128, eval_all_checkpoints=False, eval_lang='ru', evaluate_during_training=False, fp16=False, fp16_opt_level='O1', gradient_accumulation_steps=1, learning_rate=5e-05, local_rank=-1, logging_steps=50, max_answer_length=30, max_grad_norm=1.0, max_query_length=64, max_seq_length=384, max_steps=-1, model_name='xlm-KG', model_name_or_path='/cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//squad/xlm-KG_LR8e-6_EPOCH2.0_maxlen384_batchsize4_gradacc4', model_type='xlm', modelkg_dir='/cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/adapter/xlmr_adapter', n_best_size=20, n_gpu=1, no_cuda=False, null_score_diff_threshold=0.0, num_train_epochs=3.0, output_dir='/cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//squad/xlm-KG_LR8e-6_EPOCH2.0_maxlen384_batchsize4_gradacc4/predictions/xquad/', overwrite_cache=False, overwrite_output_dir=False, per_gpu_eval_batch_size=8, per_gpu_train_batch_size=8, predict_file='/cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/download//xquad//xquad.ru.json', save_steps=50, seed=42, server_ip='', server_port='', threads=1, tokenizer_name='', train_file=None, train_lang='en', verbose_logging=False, version_2_with_negative=False, warmup_steps=0, weight_decay=0.0)
05/09/2022 19:58:36 - INFO - __main__ -   Loading checkpoint /cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//squad/xlm-KG_LR8e-6_EPOCH2.0_maxlen384_batchsize4_gradacc4 for evaluation
05/09/2022 19:58:36 - INFO - __main__ -   Evaluate the following checkpoints: ['/cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//squad/xlm-KG_LR8e-6_EPOCH2.0_maxlen384_batchsize4_gradacc4']
Some weights of the model checkpoint at /cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//squad/xlm-KG_LR8e-6_EPOCH2.0_maxlen384_batchsize4_gradacc4 were not used when initializing XLMRobertaModel: ['base_model.encoder.layer.1.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.10.attention.output.LayerNorm.weight', 'base_model.encoder.layer.4.attention.self.query.bias', 'base_model.encoder.layer.10.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.19.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.0.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.3.output.LayerNorm.bias', 'base_model.encoder.layer.8.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.21.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.15.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.20.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.17.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.16.attention.output.LayerNorm.weight', 'base_model.encoder.layer.5.attention.self.value.bias', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.20.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.17.intermediate.dense.bias', 'base_model.encoder.layer.14.output.dense.weight', 'base_model.encoder.layer.2.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.8.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.23.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.21.intermediate.dense.bias', 'base_model.encoder.layer.13.attention.output.dense.bias', 'base_model.encoder.layer.21.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.23.attention.self.query.weight', 'base_model.encoder.layer.7.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.4.output.LayerNorm.bias', 'base_model.encoder.layer.5.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.2.output.dense.weight', 'base_model.encoder.layer.10.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.13.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.20.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.13.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.20.output.dense.bias', 'base_model.encoder.layer.19.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.16.attention.self.key.bias', 'base_model.encoder.layer.20.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.12.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.22.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.10.intermediate.dense.bias', 'base_model.encoder.layer.18.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.1.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.15.attention.self.value.weight', 'base_model.encoder.layer.18.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.15.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.2.intermediate.dense.bias', 'base_model.encoder.layer.6.attention.output.LayerNorm.weight', 'base_model.encoder.layer.22.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.10.output.LayerNorm.weight', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.16.attention.self.query.weight', 'base_model.encoder.layer.8.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.1.attention.output.dense.bias', 'base_model.encoder.layer.19.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.11.attention.self.query.bias', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.15.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.18.attention.self.value.bias', 'base_model.encoder.layer.21.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.22.attention.self.value.bias', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.0.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.17.intermediate.dense.weight', 'base_model.encoder.layer.21.attention.output.LayerNorm.bias', 'base_model.encoder.layer.23.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.8.output.dense.bias', 'base_model.encoder.layer.1.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.20.attention.self.value.bias', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.7.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.8.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.9.output.LayerNorm.weight', 'base_model.encoder.layer.9.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.17.attention.output.LayerNorm.bias', 'base_model.encoder.layer.11.attention.self.key.bias', 'base_model.encoder.layer.7.attention.self.key.weight', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.16.output.LayerNorm.bias', 'base_model.encoder.layer.14.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.5.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.8.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.0.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.14.attention.output.dense.bias', 'base_model.encoder.layer.12.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.13.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.6.output.dense.bias', 'base_model.encoder.layer.23.attention.self.query.bias', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.23.attention.output.LayerNorm.bias', 'base_model.encoder.layer.10.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.21.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.2.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.0.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.6.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.10.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.21.output.LayerNorm.weight', 'base_model.encoder.layer.14.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.10.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.1.attention.self.key.bias', 'base_model.encoder.layer.18.attention.self.query.bias', 'base_model.encoder.layer.2.attention.self.query.weight', 'base_model.encoder.layer.2.attention.output.LayerNorm.weight', 'base_model.encoder.layer.16.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.19.attention.self.query.bias', 'base_model.encoder.layer.22.output.dense.weight', 'base_model.encoder.layer.19.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.18.intermediate.dense.bias', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.0.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.17.attention.self.key.bias', 'base_model.encoder.layer.3.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.10.attention.output.LayerNorm.bias', 'base_model.encoder.layer.2.attention.self.key.weight', 'base_model.encoder.layer.0.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.14.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.22.output.LayerNorm.bias', 'base_model.encoder.layer.5.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.0.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.3.attention.self.query.bias', 'base_model.encoder.layer.19.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.12.attention.output.LayerNorm.weight', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.1.output.dense.weight', 'base_model.encoder.layer.15.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.3.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.21.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.2.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.10.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.3.output.LayerNorm.weight', 'base_model.encoder.layer.11.output.dense.bias', 'base_model.encoder.layer.23.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.13.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.12.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.23.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.18.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.22.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.23.attention.self.value.weight', 'base_model.encoder.layer.16.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.18.attention.self.value.weight', 'base_model.encoder.layer.14.attention.output.LayerNorm.bias', 'base_model.encoder.layer.17.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.20.intermediate.dense.bias', 'base_model.encoder.layer.11.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.8.attention.output.dense.bias', 'base_model.encoder.layer.14.output.LayerNorm.weight', 'base_model.encoder.layer.14.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.18.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.20.intermediate.dense.weight', 'base_model.encoder.layer.20.output.LayerNorm.bias', 'base_model.encoder.layer.20.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.7.attention.output.LayerNorm.weight', 'base_model.encoder.layer.6.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.3.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.13.attention.self.query.weight', 'base_model.encoder.layer.9.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.1.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.16.output.dense.weight', 'base_model.encoder.layer.20.output.dense.weight', 'base_model.encoder.layer.15.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.3.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.8.attention.self.value.bias', 'base_model.encoder.layer.15.attention.self.key.bias', 'base_model.encoder.layer.13.attention.self.key.weight', 'base_model.encoder.layer.20.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.6.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.15.intermediate.dense.weight', 'base_model.encoder.layer.11.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.16.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.15.output.LayerNorm.bias', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.23.attention.self.key.bias', 'base_model.encoder.layer.23.output.LayerNorm.bias', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.22.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.12.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.18.attention.output.LayerNorm.weight', 'base_model.encoder.layer.3.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.6.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.11.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.2.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.0.attention.self.query.bias', 'base_model.encoder.layer.6.attention.self.value.bias', 'base_model.encoder.layer.9.attention.self.key.bias', 'base_model.encoder.layer.11.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.17.output.dense.bias', 'base_model.encoder.layer.15.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.6.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.22.attention.output.LayerNorm.weight', 'base_model.encoder.layer.14.attention.self.key.bias', 'base_model.encoder.layer.12.output.LayerNorm.bias', 'base_model.encoder.layer.9.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.1.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.11.attention.self.key.weight', 'base_model.encoder.layer.15.attention.self.query.bias', 'base_model.encoder.layer.6.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.21.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.20.attention.output.dense.bias', 'base_model.encoder.layer.19.intermediate.dense.weight', 'base_model.encoder.layer.16.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.4.attention.self.key.bias', 'base_model.encoder.layer.6.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.20.output.LayerNorm.weight', 'base_model.encoder.layer.3.attention.self.value.weight', 'base_model.encoder.layer.7.attention.self.value.bias', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.9.output.dense.bias', 'base_model.encoder.layer.22.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.8.attention.self.query.weight', 'base_model.encoder.layer.5.attention.output.LayerNorm.bias', 'base_model.encoder.layer.14.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.8.attention.output.LayerNorm.bias', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.16.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.5.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.15.output.LayerNorm.weight', 'base_model.encoder.layer.13.output.dense.weight', 'base_model.encoder.layer.8.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.11.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.3.attention.self.key.bias', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.21.intermediate.dense.weight', 'base_model.encoder.layer.14.output.adapters.ts.adapter_up.weight', 'base_model.embeddings.LayerNorm.weight', 'base_model.encoder.layer.17.attention.self.key.weight', 'base_model.encoder.layer.18.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.15.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.5.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.17.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.19.attention.self.query.weight', 'base_model.encoder.layer.23.output.dense.weight', 'base_model.encoder.layer.0.attention.output.LayerNorm.weight', 'base_model.encoder.layer.5.attention.self.key.bias', 'base_model.encoder.layer.15.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.21.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.19.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.6.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.1.attention.self.value.bias', 'base_model.encoder.layer.3.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.3.attention.output.dense.weight', 'base_model.encoder.layer.1.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.7.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.12.intermediate.dense.bias', 'base_model.encoder.layer.23.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.4.attention.output.LayerNorm.weight', 'base_model.encoder.layer.7.attention.output.dense.bias', 'base_model.encoder.layer.3.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.9.output.dense.weight', 'base_model.encoder.layer.2.attention.self.key.bias', 'base_model.encoder.layer.10.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.14.attention.self.key.weight', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.11.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.21.attention.self.key.weight', 'base_model.encoder.layer.3.output.dense.bias', 'base_model.encoder.layer.17.attention.self.value.bias', 'base_model.encoder.layer.17.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.1.attention.self.value.weight', 'base_model.encoder.layer.15.output.dense.bias', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.18.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.1.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.4.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.11.attention.output.LayerNorm.weight', 'base_model.encoder.layer.14.output.dense.bias', 'base_model.encoder.layer.19.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.16.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.15.attention.self.key.weight', 'base_model.encoder.layer.9.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.22.intermediate.dense.bias', 'base_model.encoder.layer.13.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.11.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.17.output.LayerNorm.bias', 'base_model.encoder.layer.12.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.20.attention.output.dense.weight', 'base_model.encoder.layer.10.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.14.attention.self.query.weight', 'base_model.encoder.layer.4.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.4.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.1.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.16.attention.self.query.bias', 'base_model.encoder.layer.19.attention.self.value.weight', 'base_model.encoder.layer.7.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.7.intermediate.dense.bias', 'base_model.encoder.layer.19.attention.output.LayerNorm.bias', 'base_model.encoder.layer.8.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.19.output.LayerNorm.bias', 'base_model.encoder.layer.15.attention.self.value.bias', 'base_model.encoder.layer.5.output.LayerNorm.bias', 'base_model.encoder.layer.11.attention.output.dense.weight', 'base_model.encoder.layer.10.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.15.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.23.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.18.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.9.attention.self.value.bias', 'base_model.encoder.layer.6.attention.self.query.weight', 'base_model.encoder.layer.0.attention.self.key.weight', 'base_model.encoder.layer.7.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.5.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.19.attention.self.key.weight', 'base_model.encoder.layer.11.output.LayerNorm.weight', 'base_model.encoder.layer.20.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.8.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.16.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.1.output.LayerNorm.bias', 'base_model.encoder.layer.5.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.23.output.LayerNorm.weight', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.embeddings.position_embeddings.weight', 'base_model.encoder.layer.2.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.20.attention.self.value.weight', 'base_model.encoder.layer.14.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.8.attention.self.key.weight', 'base_model.encoder.layer.15.output.dense.weight', 'base_model.encoder.layer.10.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.17.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.0.attention.output.LayerNorm.bias', 'base_model.encoder.layer.8.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.9.attention.self.query.weight', 'base_model.encoder.layer.9.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.15.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.22.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.22.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.23.output.dense.bias', 'base_model.encoder.layer.20.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.9.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.12.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.20.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.5.output.dense.bias', 'base_model.encoder.layer.9.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.13.intermediate.dense.bias', 'base_model.encoder.layer.16.output.dense.bias', 'base_model.encoder.layer.18.attention.output.dense.bias', 'base_model.encoder.layer.18.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.11.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.18.attention.self.query.weight', 'base_model.encoder.layer.19.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.22.attention.self.key.weight', 'base_model.encoder.layer.9.attention.output.LayerNorm.weight', 'base_model.encoder.layer.19.attention.output.dense.bias', 'base_model.encoder.layer.6.attention.self.value.weight', 'base_model.encoder.layer.0.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.20.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.7.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.9.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.12.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.11.intermediate.dense.weight', 'base_model.encoder.layer.7.intermediate.dense.weight', 'base_model.encoder.layer.23.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.16.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.19.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.14.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.8.attention.self.query.bias', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.18.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.13.output.dense.bias', 'base_model.encoder.layer.8.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.21.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.12.attention.output.LayerNorm.bias', 'base_model.encoder.layer.22.attention.self.key.bias', 'base_model.encoder.layer.21.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.1.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.2.attention.self.value.bias', 'base_model.encoder.layer.5.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.3.intermediate.dense.bias', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.22.output.dense.bias', 'base_model.encoder.layer.19.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.0.attention.self.query.weight', 'base_model.encoder.layer.3.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.11.output.dense.weight', 'base_model.encoder.layer.1.intermediate.dense.bias', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.18.output.dense.weight', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.21.output.LayerNorm.bias', 'base_model.encoder.layer.21.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.2.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.1.output.LayerNorm.weight', 'base_model.encoder.layer.5.attention.self.query.weight', 'base_model.encoder.layer.12.output.LayerNorm.weight', 'base_model.encoder.layer.10.attention.output.dense.bias', 'base_model.encoder.layer.9.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.21.output.dense.weight', 'base_model.encoder.layer.7.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.6.attention.output.dense.bias', 'base_model.encoder.layer.16.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.7.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.5.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.4.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.0.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.18.output.LayerNorm.weight', 'qa_outputs.weight', 'base_model.encoder.layer.14.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.7.output.LayerNorm.weight', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.4.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.11.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.3.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.pooler.dense.bias', 'base_model.encoder.layer.14.output.LayerNorm.bias', 'base_model.encoder.layer.6.attention.self.key.weight', 'base_model.encoder.layer.14.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.16.attention.self.value.weight', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.14.attention.self.value.bias', 'base_model.encoder.layer.7.attention.self.key.bias', 'base_model.encoder.layer.8.attention.self.key.bias', 'base_model.encoder.layer.16.attention.output.dense.bias', 'base_model.encoder.layer.8.attention.output.dense.weight', 'base_model.encoder.layer.0.attention.self.key.bias', 'base_model.encoder.layer.10.output.LayerNorm.bias', 'base_model.encoder.layer.8.attention.self.value.weight', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.18.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.9.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.20.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.5.output.dense.weight', 'base_model.encoder.layer.11.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.22.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.9.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.13.attention.self.query.bias', 'base_model.encoder.layer.4.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.4.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.4.output.dense.weight', 'base_model.encoder.layer.20.attention.output.LayerNorm.bias', 'base_model.encoder.layer.10.attention.self.key.bias', 'base_model.encoder.layer.23.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.18.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.12.attention.self.query.bias', 'base_model.encoder.layer.17.output.adapters.ep.adapter_down.0.weight', 'base_model.pooler.dense.weight', 'base_model.encoder.layer.0.intermediate.dense.weight', 'base_model.encoder.layer.0.attention.output.dense.bias', 'base_model.encoder.layer.7.output.dense.bias', 'base_model.encoder.layer.0.output.dense.weight', 'base_model.encoder.layer.0.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.1.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.8.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.1.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.6.attention.self.query.bias', 'base_model.encoder.layer.2.intermediate.dense.weight', 'base_model.encoder.layer.8.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.11.attention.self.value.bias', 'base_model.encoder.layer.1.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.13.output.LayerNorm.bias', 'base_model.encoder.layer.8.intermediate.dense.bias', 'base_model.encoder.layer.17.attention.self.value.weight', 'base_model.encoder.layer.7.output.dense.weight', 'base_model.encoder.layer.10.attention.self.query.bias', 'base_model.encoder.layer.13.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.3.attention.self.key.weight', 'base_model.encoder.layer.7.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.18.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.5.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.13.attention.output.dense.weight', 'base_model.encoder.layer.10.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.22.attention.output.dense.bias', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.7.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.4.intermediate.dense.bias', 'base_model.encoder.layer.9.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.8.output.LayerNorm.weight', 'base_model.encoder.layer.0.intermediate.dense.bias', 'base_model.encoder.layer.11.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.5.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.23.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.13.intermediate.dense.weight', 'base_model.encoder.layer.2.attention.self.value.weight', 'base_model.encoder.layer.14.intermediate.dense.bias', 'base_model.encoder.layer.16.attention.output.dense.weight', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.17.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.17.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.16.attention.self.key.weight', 'base_model.encoder.layer.20.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.2.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.3.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.22.output.LayerNorm.weight', 'base_model.encoder.layer.17.attention.output.dense.bias', 'base_model.encoder.layer.21.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.22.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.17.attention.self.query.weight', 'base_model.encoder.layer.19.output.LayerNorm.weight', 'base_model.encoder.layer.0.attention.output.dense.weight', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.19.attention.self.value.bias', 'base_model.encoder.layer.5.attention.output.dense.bias', 'base_model.encoder.layer.5.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.13.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.15.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.15.attention.self.query.weight', 'base_model.encoder.layer.1.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.10.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.6.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.embeddings.position_ids', 'base_model.encoder.layer.23.attention.output.LayerNorm.weight', 'base_model.encoder.layer.23.attention.output.dense.weight', 'base_model.encoder.layer.12.intermediate.dense.weight', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.23.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.8.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.16.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.22.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.21.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.0.output.dense.bias', 'base_model.encoder.layer.9.attention.self.query.bias', 'base_model.encoder.layer.7.output.LayerNorm.bias', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.21.output.dense.bias', 'base_model.encoder.layer.9.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.21.attention.output.dense.weight', 'base_model.encoder.layer.12.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.19.attention.self.key.bias', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.23.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.11.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.7.attention.self.query.bias', 'base_model.encoder.layer.13.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.14.attention.output.LayerNorm.weight', 'base_model.encoder.layer.2.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.20.attention.self.query.bias', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.7.attention.output.dense.weight', 'base_model.encoder.layer.1.attention.output.dense.weight', 'base_model.encoder.layer.11.attention.self.query.weight', 'base_model.encoder.layer.23.attention.output.dense.bias', 'base_model.encoder.layer.20.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.4.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.9.intermediate.dense.weight', 'base_model.encoder.layer.13.attention.self.value.weight', 'base_model.encoder.layer.19.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.16.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.21.attention.self.value.weight', 'base_model.encoder.layer.22.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.23.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.15.attention.output.LayerNorm.bias', 'base_model.encoder.layer.17.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.6.output.LayerNorm.weight', 'base_model.encoder.layer.14.attention.self.value.weight', 'base_model.encoder.layer.4.attention.self.key.weight', 'base_model.encoder.layer.1.attention.self.query.bias', 'base_model.encoder.layer.8.output.dense.weight', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.embeddings.word_embeddings.weight', 'base_model.encoder.layer.11.attention.self.value.weight', 'base_model.encoder.layer.9.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.18.output.LayerNorm.bias', 'base_model.encoder.layer.21.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.18.attention.output.dense.weight', 'base_model.encoder.layer.4.attention.output.dense.weight', 'base_model.encoder.layer.10.attention.self.query.weight', 'base_model.encoder.layer.13.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.9.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.4.attention.self.value.weight', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.17.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.8.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.1.output.dense.bias', 'base_model.encoder.layer.23.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.12.attention.self.key.weight', 'base_model.encoder.layer.12.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.10.attention.self.key.weight', 'base_model.encoder.layer.6.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.15.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.9.output.LayerNorm.bias', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.5.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.5.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.6.intermediate.dense.bias', 'base_model.encoder.layer.3.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.14.attention.output.dense.weight', 'base_model.encoder.layer.17.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.15.attention.output.LayerNorm.weight', 'base_model.encoder.layer.3.attention.output.LayerNorm.weight', 'base_model.encoder.layer.18.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.4.attention.self.query.weight', 'base_model.encoder.layer.2.output.LayerNorm.weight', 'base_model.encoder.layer.23.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.3.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.19.output.adapters.es.adapter_up.weight', 'qa_outputs.bias', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.15.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.1.intermediate.dense.weight', 'base_model.encoder.layer.17.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.3.intermediate.dense.weight', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.2.attention.output.dense.bias', 'base_model.encoder.layer.3.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.5.attention.self.key.weight', 'base_model.encoder.layer.18.attention.self.key.weight', 'base_model.encoder.layer.10.attention.self.value.weight', 'base_model.encoder.layer.21.attention.output.LayerNorm.weight', 'base_model.encoder.layer.22.attention.self.query.bias', 'base_model.encoder.layer.23.attention.self.key.weight', 'base_model.encoder.layer.2.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.14.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.6.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.7.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.16.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.13.attention.output.LayerNorm.weight', 'base_model.encoder.layer.17.output.dense.weight', 'base_model.encoder.layer.9.attention.self.key.weight', 'base_model.encoder.layer.10.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.2.attention.output.dense.weight', 'base_model.encoder.layer.3.attention.output.LayerNorm.bias', 'base_model.encoder.layer.0.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.2.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.8.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.14.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.7.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.6.intermediate.dense.weight', 'base_model.encoder.layer.21.attention.output.dense.bias', 'base_model.encoder.layer.5.attention.output.dense.weight', 'base_model.encoder.layer.4.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.16.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.13.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.19.output.dense.bias', 'base_model.encoder.layer.15.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.18.attention.self.key.bias', 'base_model.encoder.layer.12.attention.self.value.bias', 'base_model.encoder.layer.2.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.9.attention.output.dense.weight', 'base_model.encoder.layer.10.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.11.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.23.attention.self.value.bias', 'base_model.encoder.layer.21.attention.self.value.bias', 'base_model.encoder.layer.11.output.LayerNorm.bias', 'base_model.encoder.layer.4.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.1.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.10.output.dense.bias', 'base_model.encoder.layer.12.attention.self.query.weight', 'base_model.encoder.layer.12.attention.output.dense.bias', 'base_model.encoder.layer.0.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.6.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.22.attention.output.LayerNorm.bias', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.12.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.6.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.4.attention.self.value.bias', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.5.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.21.attention.self.key.bias', 'base_model.encoder.layer.12.attention.self.key.bias', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.4.output.LayerNorm.weight', 'base_model.encoder.layer.14.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.23.intermediate.dense.weight', 'base_model.encoder.layer.12.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.10.attention.output.dense.weight', 'base_model.encoder.layer.5.intermediate.dense.bias', 'base_model.encoder.layer.8.intermediate.dense.weight', 'base_model.encoder.layer.7.attention.self.value.weight', 'base_model.encoder.layer.2.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.12.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.6.output.LayerNorm.bias', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.13.attention.self.key.bias', 'base_model.encoder.layer.20.attention.self.query.weight', 'base_model.encoder.layer.12.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.13.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.5.attention.self.query.bias', 'base_model.encoder.layer.6.output.dense.weight', 'base_model.encoder.layer.16.attention.output.LayerNorm.bias', 'base_model.encoder.layer.19.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.2.attention.output.LayerNorm.bias', 'base_model.encoder.layer.4.intermediate.dense.weight', 'base_model.encoder.layer.0.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.0.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.1.attention.output.LayerNorm.bias', 'base_model.encoder.layer.22.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.14.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.6.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.5.attention.output.LayerNorm.weight', 'base_model.encoder.layer.0.attention.self.value.bias', 'base_model.encoder.layer.3.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.23.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.19.output.dense.weight', 'base_model.encoder.layer.9.attention.self.value.weight', 'base_model.encoder.layer.16.output.LayerNorm.weight', 'base_model.encoder.layer.22.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.7.attention.self.query.weight', 'base_model.encoder.layer.0.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.3.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.22.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.22.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.17.output.LayerNorm.weight', 'base_model.encoder.layer.1.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.18.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.3.output.dense.weight', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.14.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.7.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.3.attention.self.value.bias', 'base_model.encoder.layer.1.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.19.attention.output.LayerNorm.weight', 'base_model.encoder.layer.4.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.8.output.LayerNorm.bias', 'base_model.encoder.layer.13.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.19.intermediate.dense.bias', 'base_model.encoder.layer.14.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.20.attention.self.key.weight', 'base_model.encoder.layer.0.output.LayerNorm.bias', 'base_model.encoder.layer.15.attention.output.dense.weight', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.13.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.7.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.7.attention.output.LayerNorm.bias', 'base_model.encoder.layer.18.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.5.intermediate.dense.weight', 'base_model.encoder.layer.2.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.12.output.dense.bias', 'base_model.encoder.layer.8.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.1.attention.self.query.weight', 'base_model.encoder.layer.4.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.5.attention.self.value.weight', 'base_model.encoder.layer.19.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.22.attention.self.value.weight', 'base_model.encoder.layer.9.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.5.output.LayerNorm.weight', 'base_model.encoder.layer.6.attention.self.key.bias', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.5.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.23.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.15.intermediate.dense.bias', 'base_model.encoder.layer.0.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.20.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.2.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.15.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.1.attention.self.key.weight', 'base_model.encoder.layer.13.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.11.attention.output.dense.bias', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.12.attention.output.dense.weight', 'base_model.encoder.layer.16.intermediate.dense.bias', 'base_model.encoder.layer.12.attention.self.value.weight', 'base_model.encoder.layer.4.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.10.output.dense.weight', 'base_model.encoder.layer.18.intermediate.dense.weight', 'base_model.encoder.layer.17.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.11.attention.output.LayerNorm.bias', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.3.attention.output.dense.bias', 'base_model.encoder.layer.0.attention.self.value.weight', 'base_model.encoder.layer.11.intermediate.dense.bias', 'base_model.encoder.layer.16.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.17.attention.output.LayerNorm.weight', 'base_model.encoder.layer.6.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.6.attention.output.dense.weight', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.18.output.dense.bias', 'base_model.encoder.layer.11.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.15.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.21.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.10.intermediate.dense.weight', 'base_model.encoder.layer.16.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.2.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.13.output.LayerNorm.weight', 'base_model.encoder.layer.16.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.21.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.9.intermediate.dense.bias', 'base_model.encoder.layer.3.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.21.attention.self.query.bias', 'base_model.encoder.layer.10.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.19.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.21.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.4.output.dense.bias', 'base_model.encoder.layer.12.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.20.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.4.attention.output.dense.bias', 'base_model.encoder.layer.9.attention.output.dense.bias', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.2.output.LayerNorm.bias', 'base_model.encoder.layer.4.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.23.intermediate.dense.bias', 'base_model.encoder.layer.18.attention.output.LayerNorm.bias', 'base_model.embeddings.token_type_embeddings.weight', 'base_model.embeddings.LayerNorm.bias', 'base_model.encoder.layer.2.attention.self.query.bias', 'base_model.encoder.layer.13.attention.output.LayerNorm.bias', 'base_model.encoder.layer.9.attention.output.LayerNorm.bias', 'base_model.encoder.layer.18.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.4.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.17.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.13.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.2.output.dense.bias', 'base_model.encoder.layer.22.attention.output.dense.weight', 'base_model.encoder.layer.17.attention.output.dense.weight', 'base_model.encoder.layer.17.attention.self.query.bias', 'base_model.encoder.layer.7.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.17.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.21.attention.self.query.weight', 'base_model.encoder.layer.13.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.13.attention.self.value.bias', 'base_model.encoder.layer.4.attention.output.LayerNorm.bias', 'base_model.encoder.layer.11.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.12.output.dense.weight', 'base_model.encoder.layer.16.attention.self.value.bias', 'base_model.encoder.layer.4.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.22.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.2.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.8.attention.output.LayerNorm.weight', 'base_model.encoder.layer.10.attention.self.value.bias', 'base_model.encoder.layer.11.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.12.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.14.attention.self.query.bias', 'base_model.encoder.layer.14.intermediate.dense.weight', 'base_model.encoder.layer.20.attention.output.LayerNorm.weight', 'base_model.encoder.layer.7.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.6.attention.output.LayerNorm.bias', 'base_model.encoder.layer.22.attention.self.query.weight', 'base_model.encoder.layer.10.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.19.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.20.attention.self.key.bias', 'base_model.encoder.layer.16.intermediate.dense.weight', 'base_model.encoder.layer.6.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.19.attention.output.dense.weight', 'base_model.encoder.layer.1.attention.output.LayerNorm.weight', 'base_model.encoder.layer.15.attention.output.dense.bias', 'base_model.encoder.layer.0.output.LayerNorm.weight', 'base_model.encoder.layer.3.attention.self.query.weight', 'base_model.encoder.layer.22.intermediate.dense.weight', 'base_model.encoder.layer.12.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.17.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.20.output.adapters.tp.adapter_down.0.bias']
- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of XLMRobertaModel were not initialized from the model checkpoint at /cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//squad/xlm-KG_LR8e-6_EPOCH2.0_maxlen384_batchsize4_gradacc4 and are newly initialized: ['encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.13.attention.self.key.bias', 'encoder.layer.5.attention.self.query.bias', 'encoder.layer.10.attention.self.key.bias', 'encoder.layer.11.attention.self.key.weight', 'encoder.layer.19.attention.output.LayerNorm.bias', 'encoder.layer.23.attention.self.value.weight', 'encoder.layer.10.output.LayerNorm.bias', 'encoder.layer.15.attention.self.key.weight', 'encoder.layer.2.attention.output.dense.weight', 'encoder.layer.17.output.dense.weight', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.2.attention.self.key.bias', 'encoder.layer.11.attention.output.LayerNorm.weight', 'encoder.layer.5.output.dense.bias', 'encoder.layer.2.attention.self.value.weight', 'encoder.layer.8.attention.self.value.bias', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.18.output.LayerNorm.weight', 'encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.layer.2.attention.self.value.bias', 'encoder.layer.12.intermediate.dense.bias', 'encoder.layer.8.attention.self.key.weight', 'encoder.layer.14.attention.self.query.weight', 'encoder.layer.12.output.dense.bias', 'encoder.layer.11.attention.output.dense.weight', 'encoder.layer.6.output.dense.weight', 'encoder.layer.22.output.dense.weight', 'encoder.layer.10.output.LayerNorm.weight', 'encoder.layer.12.output.dense.weight', 'encoder.layer.22.output.LayerNorm.bias', 'encoder.layer.16.intermediate.dense.bias', 'encoder.layer.22.attention.self.key.bias', 'encoder.layer.10.attention.output.LayerNorm.bias', 'encoder.layer.8.output.LayerNorm.bias', 'encoder.layer.0.attention.self.query.bias', 'encoder.layer.6.attention.self.query.weight', 'encoder.layer.22.attention.self.query.bias', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.12.attention.self.key.bias', 'encoder.layer.17.attention.self.query.weight', 'encoder.layer.17.output.LayerNorm.bias', 'encoder.layer.9.attention.self.value.bias', 'encoder.layer.9.output.dense.weight', 'encoder.layer.15.attention.output.LayerNorm.weight', 'encoder.layer.8.attention.self.query.bias', 'encoder.layer.16.output.LayerNorm.bias', 'encoder.layer.21.attention.output.dense.bias', 'encoder.layer.7.output.LayerNorm.weight', 'encoder.layer.4.attention.self.value.bias', 'encoder.layer.7.attention.output.LayerNorm.bias', 'encoder.layer.3.attention.self.query.weight', 'encoder.layer.17.attention.self.query.bias', 'encoder.layer.10.attention.self.value.weight', 'encoder.layer.19.attention.output.dense.weight', 'encoder.layer.20.output.dense.weight', 'encoder.layer.17.output.LayerNorm.weight', 'encoder.layer.0.attention.output.LayerNorm.weight', 'encoder.layer.0.attention.self.key.weight', 'encoder.layer.6.attention.self.value.weight', 'encoder.layer.7.intermediate.dense.bias', 'encoder.layer.9.attention.self.key.weight', 'encoder.layer.10.attention.output.dense.weight', 'encoder.layer.22.attention.self.query.weight', 'encoder.layer.7.output.dense.bias', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.15.output.LayerNorm.weight', 'encoder.layer.19.attention.self.key.weight', 'encoder.layer.12.output.LayerNorm.weight', 'encoder.layer.8.attention.self.value.weight', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.3.attention.self.key.bias', 'encoder.layer.8.output.dense.bias', 'encoder.layer.5.attention.self.key.bias', 'encoder.layer.9.attention.output.LayerNorm.bias', 'encoder.layer.9.attention.self.query.weight', 'encoder.layer.6.attention.self.key.weight', 'encoder.layer.11.attention.output.dense.bias', 'encoder.layer.18.output.dense.bias', 'encoder.layer.9.output.LayerNorm.bias', 'encoder.layer.13.output.dense.weight', 'encoder.layer.0.attention.output.dense.weight', 'encoder.layer.4.attention.self.value.weight', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.12.attention.self.key.weight', 'embeddings.token_type_embeddings.weight', 'encoder.layer.13.attention.output.dense.bias', 'encoder.layer.14.attention.self.query.bias', 'encoder.layer.18.attention.output.LayerNorm.weight', 'encoder.layer.15.attention.self.value.bias', 'encoder.layer.16.attention.self.query.weight', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.9.attention.output.dense.bias', 'encoder.layer.17.attention.output.LayerNorm.weight', 'encoder.layer.7.attention.output.dense.weight', 'embeddings.LayerNorm.bias', 'encoder.layer.17.attention.output.dense.weight', 'encoder.layer.7.attention.self.query.weight', 'encoder.layer.10.intermediate.dense.weight', 'encoder.layer.22.attention.output.dense.bias', 'encoder.layer.6.attention.self.query.bias', 'encoder.layer.10.attention.output.dense.bias', 'encoder.layer.15.attention.self.query.weight', 'encoder.layer.0.attention.self.value.bias', 'embeddings.position_embeddings.weight', 'encoder.layer.15.output.LayerNorm.bias', 'embeddings.word_embeddings.weight', 'encoder.layer.13.attention.self.value.weight', 'encoder.layer.15.attention.output.dense.weight', 'encoder.layer.16.output.LayerNorm.weight', 'encoder.layer.16.attention.output.dense.weight', 'encoder.layer.3.output.dense.weight', 'encoder.layer.19.attention.self.query.bias', 'encoder.layer.23.attention.output.dense.weight', 'encoder.layer.19.attention.self.query.weight', 'encoder.layer.21.output.LayerNorm.weight', 'encoder.layer.5.attention.output.dense.bias', 'encoder.layer.6.attention.output.dense.bias', 'encoder.layer.19.output.dense.bias', 'encoder.layer.14.output.dense.weight', 'encoder.layer.2.output.dense.weight', 'encoder.layer.4.attention.self.query.weight', 'encoder.layer.19.intermediate.dense.bias', 'encoder.layer.0.attention.self.query.weight', 'encoder.layer.3.attention.self.key.weight', 'encoder.layer.3.attention.output.dense.weight', 'encoder.layer.11.attention.self.value.weight', 'encoder.layer.12.intermediate.dense.weight', 'encoder.layer.2.attention.self.query.bias', 'encoder.layer.0.output.dense.weight', 'encoder.layer.17.attention.output.dense.bias', 'encoder.layer.18.intermediate.dense.weight', 'encoder.layer.8.output.dense.weight', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.20.attention.output.LayerNorm.weight', 'encoder.layer.12.attention.output.dense.weight', 'encoder.layer.11.attention.self.query.bias', 'encoder.layer.18.attention.self.key.bias', 'encoder.layer.15.intermediate.dense.weight', 'encoder.layer.15.attention.output.dense.bias', 'encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.19.attention.output.dense.bias', 'encoder.layer.16.attention.self.value.weight', 'encoder.layer.18.attention.self.query.bias', 'encoder.layer.3.attention.output.dense.bias', 'encoder.layer.5.attention.self.query.weight', 'encoder.layer.23.attention.self.query.weight', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.17.intermediate.dense.bias', 'encoder.layer.13.attention.output.dense.weight', 'encoder.layer.21.attention.self.key.weight', 'encoder.layer.1.attention.self.key.bias', 'encoder.layer.20.attention.output.dense.bias', 'encoder.layer.5.attention.output.LayerNorm.weight', 'encoder.layer.18.attention.output.LayerNorm.bias', 'encoder.layer.6.attention.output.LayerNorm.weight', 'encoder.layer.8.output.LayerNorm.weight', 'encoder.layer.4.attention.output.LayerNorm.weight', 'encoder.layer.7.attention.self.value.weight', 'encoder.layer.20.attention.self.key.bias', 'encoder.layer.4.output.dense.bias', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.22.attention.self.key.weight', 'encoder.layer.9.attention.output.LayerNorm.weight', 'encoder.layer.3.attention.self.value.weight', 'encoder.layer.2.attention.self.key.weight', 'encoder.layer.12.attention.self.value.bias', 'encoder.layer.14.output.LayerNorm.weight', 'encoder.layer.23.attention.output.LayerNorm.weight', 'encoder.layer.9.attention.self.key.bias', 'encoder.layer.17.output.dense.bias', 'encoder.layer.1.attention.self.query.weight', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.6.output.dense.bias', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.11.attention.self.query.weight', 'encoder.layer.10.output.dense.bias', 'encoder.layer.19.attention.self.value.bias', 'encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.layer.11.output.dense.bias', 'encoder.layer.23.output.LayerNorm.weight', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.12.attention.output.LayerNorm.weight', 'encoder.layer.23.attention.self.key.weight', 'encoder.layer.4.attention.output.dense.weight', 'encoder.layer.2.attention.output.dense.bias', 'encoder.layer.13.output.LayerNorm.weight', 'encoder.layer.19.attention.self.value.weight', 'encoder.layer.22.output.dense.bias', 'encoder.layer.15.output.dense.weight', 'encoder.layer.23.intermediate.dense.weight', 'encoder.layer.14.attention.self.key.bias', 'encoder.layer.11.attention.self.value.bias', 'encoder.layer.23.attention.output.LayerNorm.bias', 'encoder.layer.0.attention.output.dense.bias', 'encoder.layer.16.output.dense.weight', 'encoder.layer.21.attention.self.value.weight', 'encoder.layer.22.attention.output.dense.weight', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.16.attention.self.key.weight', 'encoder.layer.5.attention.self.value.bias', 'encoder.layer.16.attention.output.dense.bias', 'encoder.layer.7.attention.self.value.bias', 'encoder.layer.13.attention.self.query.weight', 'encoder.layer.23.attention.output.dense.bias', 'encoder.layer.23.output.dense.bias', 'encoder.layer.15.attention.self.query.bias', 'encoder.layer.18.attention.self.query.weight', 'encoder.layer.2.attention.output.LayerNorm.weight', 'encoder.layer.21.output.dense.bias', 'encoder.layer.14.attention.output.dense.bias', 'encoder.layer.21.attention.output.LayerNorm.bias', 'encoder.layer.10.attention.self.query.weight', 'encoder.layer.6.output.LayerNorm.bias', 'encoder.layer.23.output.LayerNorm.bias', 'encoder.layer.3.attention.self.query.bias', 'encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.layer.3.attention.self.value.bias', 'encoder.layer.18.output.LayerNorm.bias', 'encoder.layer.12.attention.self.query.weight', 'encoder.layer.7.output.LayerNorm.bias', 'encoder.layer.1.output.dense.weight', 'encoder.layer.17.intermediate.dense.weight', 'encoder.layer.17.attention.self.key.weight', 'encoder.layer.13.output.LayerNorm.bias', 'encoder.layer.0.attention.self.key.bias', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.14.intermediate.dense.weight', 'encoder.layer.17.attention.self.value.bias', 'encoder.layer.6.attention.output.LayerNorm.bias', 'encoder.layer.21.attention.self.key.bias', 'encoder.layer.16.output.dense.bias', 'encoder.layer.20.output.dense.bias', 'encoder.layer.5.attention.output.dense.weight', 'encoder.layer.17.attention.self.value.weight', 'encoder.layer.14.output.dense.bias', 'encoder.layer.20.output.LayerNorm.weight', 'encoder.layer.13.attention.output.LayerNorm.weight', 'encoder.layer.8.attention.output.dense.bias', 'encoder.layer.0.attention.self.value.weight', 'encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.4.attention.output.LayerNorm.bias', 'encoder.layer.20.output.LayerNorm.bias', 'encoder.layer.23.attention.self.query.bias', 'encoder.layer.8.attention.output.LayerNorm.bias', 'encoder.layer.7.attention.self.key.bias', 'encoder.layer.20.attention.self.query.weight', 'encoder.layer.2.attention.output.LayerNorm.bias', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.11.output.dense.weight', 'encoder.layer.12.attention.self.value.weight', 'encoder.layer.4.attention.self.key.bias', 'encoder.layer.20.intermediate.dense.bias', 'encoder.layer.16.attention.self.key.bias', 'encoder.layer.14.attention.output.LayerNorm.bias', 'encoder.layer.21.attention.self.query.bias', 'encoder.layer.20.intermediate.dense.weight', 'encoder.layer.19.attention.output.LayerNorm.weight', 'encoder.layer.10.output.dense.weight', 'encoder.layer.5.output.LayerNorm.bias', 'encoder.layer.18.attention.self.key.weight', 'encoder.layer.21.intermediate.dense.weight', 'encoder.layer.6.attention.output.dense.weight', 'encoder.layer.6.attention.self.key.bias', 'encoder.layer.22.attention.output.LayerNorm.weight', 'encoder.layer.9.output.dense.bias', 'encoder.layer.19.attention.self.key.bias', 'encoder.layer.13.attention.self.query.bias', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.20.attention.self.value.bias', 'encoder.layer.8.attention.output.LayerNorm.weight', 'encoder.layer.8.attention.self.query.weight', 'encoder.layer.16.attention.self.query.bias', 'encoder.layer.4.output.dense.weight', 'encoder.layer.19.output.LayerNorm.bias', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.14.attention.output.LayerNorm.weight', 'encoder.layer.1.attention.self.query.bias', 'encoder.layer.7.attention.self.key.weight', 'encoder.layer.5.output.dense.weight', 'encoder.layer.12.output.LayerNorm.bias', 'encoder.layer.20.attention.output.LayerNorm.bias', 'encoder.layer.1.attention.output.dense.bias', 'encoder.layer.9.attention.self.query.bias', 'encoder.layer.9.attention.output.dense.weight', 'encoder.layer.20.attention.self.value.weight', 'encoder.layer.18.attention.self.value.bias', 'encoder.layer.1.attention.self.value.weight', 'encoder.layer.1.output.dense.bias', 'encoder.layer.20.attention.self.key.weight', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.0.output.dense.bias', 'encoder.layer.19.output.dense.weight', 'encoder.layer.16.attention.self.value.bias', 'encoder.layer.22.attention.output.LayerNorm.bias', 'embeddings.LayerNorm.weight', 'encoder.layer.14.attention.output.dense.weight', 'encoder.layer.4.attention.output.dense.bias', 'encoder.layer.19.intermediate.dense.weight', 'encoder.layer.16.attention.output.LayerNorm.bias', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.13.attention.output.LayerNorm.bias', 'encoder.layer.22.intermediate.dense.weight', 'encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.layer.10.attention.self.key.weight', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.13.intermediate.dense.bias', 'encoder.layer.4.attention.self.query.bias', 'encoder.layer.2.attention.self.query.weight', 'encoder.layer.22.intermediate.dense.bias', 'encoder.layer.20.attention.self.query.bias', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.1.attention.self.value.bias', 'encoder.layer.18.intermediate.dense.bias', 'encoder.layer.14.output.LayerNorm.bias', 'encoder.layer.22.attention.self.value.weight', 'encoder.layer.3.output.dense.bias', 'encoder.layer.16.attention.output.LayerNorm.weight', 'encoder.layer.22.output.LayerNorm.weight', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.7.attention.self.query.bias', 'encoder.layer.13.intermediate.dense.weight', 'encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.23.intermediate.dense.bias', 'encoder.layer.11.output.LayerNorm.weight', 'encoder.layer.22.attention.self.value.bias', 'pooler.dense.bias', 'encoder.layer.10.attention.output.LayerNorm.weight', 'encoder.layer.15.attention.output.LayerNorm.bias', 'encoder.layer.19.output.LayerNorm.weight', 'encoder.layer.5.attention.self.key.weight', 'encoder.layer.14.attention.self.value.weight', 'encoder.layer.14.attention.self.value.bias', 'encoder.layer.18.attention.self.value.weight', 'encoder.layer.12.attention.output.LayerNorm.bias', 'encoder.layer.13.attention.self.key.weight', 'encoder.layer.15.attention.self.value.weight', 'encoder.layer.10.attention.self.query.bias', 'encoder.layer.11.output.LayerNorm.bias', 'encoder.layer.4.attention.self.key.weight', 'encoder.layer.21.intermediate.dense.bias', 'encoder.layer.5.attention.self.value.weight', 'encoder.layer.13.attention.self.value.bias', 'encoder.layer.12.attention.output.dense.bias', 'encoder.layer.11.attention.self.key.bias', 'encoder.layer.7.attention.output.dense.bias', 'encoder.layer.21.attention.self.query.weight', 'encoder.layer.18.attention.output.dense.bias', 'encoder.layer.7.attention.output.LayerNorm.weight', 'encoder.layer.1.attention.output.LayerNorm.weight', 'encoder.layer.17.attention.output.LayerNorm.bias', 'encoder.layer.20.attention.output.dense.weight', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.15.output.dense.bias', 'encoder.layer.17.attention.self.key.bias', 'encoder.layer.21.attention.self.value.bias', 'encoder.layer.6.attention.self.value.bias', 'encoder.layer.21.output.LayerNorm.bias', 'encoder.layer.8.attention.self.key.bias', 'encoder.layer.18.attention.output.dense.weight', 'encoder.layer.15.attention.self.key.bias', 'encoder.layer.14.attention.self.key.weight', 'encoder.layer.21.attention.output.dense.weight', 'encoder.layer.2.output.dense.bias', 'encoder.layer.23.output.dense.weight', 'encoder.layer.23.attention.self.key.bias', 'encoder.layer.23.attention.self.value.bias', 'encoder.layer.14.intermediate.dense.bias', 'encoder.layer.12.attention.self.query.bias', 'encoder.layer.9.attention.self.value.weight', 'encoder.layer.21.output.dense.weight', 'pooler.dense.weight', 'encoder.layer.9.output.LayerNorm.weight', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.18.output.dense.weight', 'encoder.layer.13.output.dense.bias', 'encoder.layer.10.attention.self.value.bias', 'encoder.layer.7.output.dense.weight', 'encoder.layer.15.intermediate.dense.bias', 'encoder.layer.16.intermediate.dense.weight', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.1.attention.output.dense.weight', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.8.attention.output.dense.weight', 'encoder.layer.1.attention.self.key.weight', 'encoder.layer.21.attention.output.LayerNorm.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Overwriting existing adapter 'ep'.
Overwriting existing adapter 'tp'.
Overwriting existing adapter 'es'.
Overwriting existing adapter 'ts'.
Overwriting existing adapter fusion module 'ep,tp,es,ts'
05/09/2022 19:59:13 - INFO - __main__ -   Creating features from dataset file at .
/cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//squad/xlm-KG_LR8e-6_EPOCH2.0_maxlen384_batchsize4_gradacc4
XLMConfig {
  "architectures": [
    "XLMRobertaForMaskedLM"
  ],
  "asm": false,
  "attention_dropout": 0.1,
  "attention_probs_dropout_prob": 0.1,
  "bos_index": 0,
  "bos_token_id": 0,
  "causal": false,
  "dropout": 0.1,
  "emb_dim": 1024,
  "embed_init_std": 0.02209708691207961,
  "end_n_top": 5,
  "eos_index": 1,
  "eos_token_id": 2,
  "gelu_activation": true,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "init_std": 0.02,
  "initializer_range": 0.02,
  "intermediate_size": 4096,
  "is_encoder": true,
  "lang_id": 0,
  "layer_norm_eps": 1e-05,
  "mask_index": 5,
  "mask_token_id": 0,
  "max_position_embeddings": 514,
  "model_type": "xlm",
  "n_heads": 16,
  "n_langs": 1,
  "n_layers": 24,
  "output_past": true,
  "pad_index": 2,
  "pad_token_id": 1,
  "sinusoidal_embeddings": false,
  "start_n_top": 5,
  "summary_activation": null,
  "summary_first_dropout": 0.1,
  "summary_proj_to_labels": true,
  "summary_type": "first",
  "summary_use_proj": true,
  "transformers_version": "4.17.0",
  "type_vocab_size": 1,
  "unk_index": 3,
  "use_lang_emb": false,
  "vocab_size": 250002
}

  0%|          | 0/48 [00:00<?, ?it/s] 23%|██▎       | 11/48 [00:00<00:00, 101.25it/s] 46%|████▌     | 22/48 [00:00<00:00, 82.34it/s]  65%|██████▍   | 31/48 [00:00<00:00, 81.10it/s] 83%|████████▎ | 40/48 [00:00<00:00, 84.13it/s]100%|██████████| 48/48 [00:00<00:00, 89.33it/s]
convert squad examples to features:   0%|          | 0/1190 [00:00<?, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.
convert squad examples to features:   0%|          | 1/1190 [00:00<03:51,  5.14it/s]convert squad examples to features:   5%|▌         | 65/1190 [00:00<00:05, 194.02it/s]convert squad examples to features:   8%|▊         | 97/1190 [00:00<00:05, 211.15it/s]convert squad examples to features:  14%|█▎        | 161/1190 [00:00<00:03, 271.62it/s]convert squad examples to features:  16%|█▌        | 193/1190 [00:00<00:03, 272.65it/s]convert squad examples to features:  22%|██▏       | 257/1190 [00:01<00:03, 271.88it/s]convert squad examples to features:  24%|██▍       | 289/1190 [00:01<00:03, 258.94it/s]convert squad examples to features:  27%|██▋       | 321/1190 [00:01<00:03, 231.10it/s]convert squad examples to features:  30%|██▉       | 353/1190 [00:01<00:03, 232.98it/s]convert squad examples to features:  32%|███▏      | 385/1190 [00:02<00:06, 133.01it/s]convert squad examples to features:  35%|███▌      | 417/1190 [00:02<00:05, 145.21it/s]convert squad examples to features:  38%|███▊      | 449/1190 [00:02<00:04, 152.87it/s]convert squad examples to features:  40%|████      | 481/1190 [00:02<00:04, 161.44it/s]convert squad examples to features:  43%|████▎     | 513/1190 [00:02<00:04, 163.56it/s]convert squad examples to features:  46%|████▌     | 545/1190 [00:02<00:03, 174.51it/s]convert squad examples to features:  48%|████▊     | 577/1190 [00:03<00:03, 186.72it/s]convert squad examples to features:  51%|█████     | 609/1190 [00:03<00:03, 186.85it/s]convert squad examples to features:  54%|█████▍    | 641/1190 [00:03<00:02, 183.45it/s]convert squad examples to features:  57%|█████▋    | 673/1190 [00:03<00:02, 175.08it/s]convert squad examples to features:  59%|█████▉    | 705/1190 [00:03<00:02, 184.58it/s]convert squad examples to features:  62%|██████▏   | 737/1190 [00:03<00:02, 199.95it/s]convert squad examples to features:  65%|██████▍   | 769/1190 [00:04<00:01, 210.96it/s]convert squad examples to features:  67%|██████▋   | 801/1190 [00:04<00:01, 228.30it/s]convert squad examples to features:  70%|███████   | 833/1190 [00:04<00:01, 201.68it/s]convert squad examples to features:  73%|███████▎  | 865/1190 [00:04<00:01, 210.75it/s]convert squad examples to features:  75%|███████▌  | 897/1190 [00:04<00:01, 196.69it/s]convert squad examples to features:  78%|███████▊  | 929/1190 [00:04<00:01, 198.60it/s]convert squad examples to features:  81%|████████  | 961/1190 [00:04<00:01, 210.75it/s]convert squad examples to features:  83%|████████▎ | 993/1190 [00:05<00:00, 216.67it/s]convert squad examples to features:  86%|████████▌ | 1025/1190 [00:05<00:00, 216.78it/s]convert squad examples to features:  89%|████████▉ | 1057/1190 [00:05<00:00, 226.38it/s]convert squad examples to features:  92%|█████████▏| 1089/1190 [00:05<00:00, 239.71it/s]convert squad examples to features:  94%|█████████▍| 1121/1190 [00:05<00:00, 231.70it/s]convert squad examples to features:  97%|█████████▋| 1153/1190 [00:05<00:00, 229.25it/s]convert squad examples to features: 100%|██████████| 1190/1190 [00:05<00:00, 206.68it/s]
add example index and unique id:   0%|          | 0/1190 [00:00<?, ?it/s]add example index and unique id: 100%|██████████| 1190/1190 [00:00<00:00, 515143.13it/s]
05/09/2022 19:59:19 - INFO - __main__ -   Saving features into cached file ./cached_xquad.ru.json_xlm-KG_LR8e-6_EPOCH2.0_maxlen384_batchsize4_gradacc4_384_ru
05/09/2022 19:59:20 - INFO - __main__ -   ***** Running evaluation  *****
05/09/2022 19:59:20 - INFO - __main__ -     Num examples = 1332
05/09/2022 19:59:20 - INFO - __main__ -     Batch size = 8
Evaluating:   0%|          | 0/167 [00:00<?, ?it/s]Evaluating:   1%|          | 1/167 [00:00<02:25,  1.14it/s]Evaluating:   1%|          | 2/167 [00:01<01:34,  1.74it/s]Evaluating:   2%|▏         | 3/167 [00:01<01:18,  2.10it/s]Evaluating:   2%|▏         | 4/167 [00:01<01:10,  2.32it/s]Evaluating:   3%|▎         | 5/167 [00:02<01:05,  2.47it/s]Evaluating:   4%|▎         | 6/167 [00:02<01:02,  2.58it/s]Evaluating:   4%|▍         | 7/167 [00:03<01:00,  2.64it/s]Evaluating:   5%|▍         | 8/167 [00:03<00:58,  2.70it/s]Evaluating:   5%|▌         | 9/167 [00:03<00:57,  2.73it/s]Evaluating:   6%|▌         | 10/167 [00:04<00:58,  2.70it/s]Evaluating:   7%|▋         | 11/167 [00:04<00:57,  2.71it/s]Evaluating:   7%|▋         | 12/167 [00:04<00:57,  2.71it/s]Evaluating:   8%|▊         | 13/167 [00:05<00:56,  2.74it/s]Evaluating:   8%|▊         | 14/167 [00:05<00:55,  2.73it/s]Evaluating:   9%|▉         | 15/167 [00:05<00:55,  2.75it/s]Evaluating:  10%|▉         | 16/167 [00:06<00:54,  2.77it/s]Evaluating:  10%|█         | 17/167 [00:06<00:54,  2.77it/s]Evaluating:  11%|█         | 18/167 [00:07<00:53,  2.78it/s]Evaluating:  11%|█▏        | 19/167 [00:07<00:52,  2.79it/s]Evaluating:  12%|█▏        | 20/167 [00:07<00:52,  2.79it/s]Evaluating:  13%|█▎        | 21/167 [00:08<00:52,  2.79it/s]Evaluating:  13%|█▎        | 22/167 [00:08<00:52,  2.79it/s]Evaluating:  14%|█▍        | 23/167 [00:08<00:51,  2.80it/s]Evaluating:  14%|█▍        | 24/167 [00:09<00:50,  2.81it/s]Evaluating:  15%|█▍        | 25/167 [00:09<00:50,  2.80it/s]Evaluating:  16%|█▌        | 26/167 [00:09<00:50,  2.80it/s]Evaluating:  16%|█▌        | 27/167 [00:10<00:49,  2.81it/s]Evaluating:  17%|█▋        | 28/167 [00:10<00:49,  2.80it/s]Evaluating:  17%|█▋        | 29/167 [00:10<00:49,  2.81it/s]Evaluating:  18%|█▊        | 30/167 [00:11<00:48,  2.80it/s]Evaluating:  19%|█▊        | 31/167 [00:11<00:48,  2.78it/s]Evaluating:  19%|█▉        | 32/167 [00:12<00:48,  2.79it/s]Evaluating:  20%|█▉        | 33/167 [00:12<00:47,  2.79it/s]Evaluating:  20%|██        | 34/167 [00:12<00:47,  2.79it/s]Evaluating:  21%|██        | 35/167 [00:13<00:48,  2.71it/s]Evaluating:  22%|██▏       | 36/167 [00:13<00:47,  2.74it/s]Evaluating:  22%|██▏       | 37/167 [00:13<00:47,  2.73it/s]Evaluating:  23%|██▎       | 38/167 [00:14<00:47,  2.72it/s]Evaluating:  23%|██▎       | 39/167 [00:14<00:47,  2.72it/s]Evaluating:  24%|██▍       | 40/167 [00:14<00:46,  2.74it/s]Evaluating:  25%|██▍       | 41/167 [00:15<00:46,  2.72it/s]Evaluating:  25%|██▌       | 42/167 [00:15<00:46,  2.66it/s]Evaluating:  26%|██▌       | 43/167 [00:16<00:46,  2.69it/s]Evaluating:  26%|██▋       | 44/167 [00:16<00:45,  2.72it/s]Evaluating:  27%|██▋       | 45/167 [00:16<00:44,  2.74it/s]Evaluating:  28%|██▊       | 46/167 [00:17<00:43,  2.76it/s]Evaluating:  28%|██▊       | 47/167 [00:17<00:43,  2.76it/s]Evaluating:  29%|██▊       | 48/167 [00:17<00:43,  2.76it/s]Evaluating:  29%|██▉       | 49/167 [00:18<00:42,  2.76it/s]Evaluating:  30%|██▉       | 50/167 [00:18<00:42,  2.77it/s]Evaluating:  31%|███       | 51/167 [00:18<00:41,  2.77it/s]Evaluating:  31%|███       | 52/167 [00:19<00:41,  2.77it/s]Evaluating:  32%|███▏      | 53/167 [00:19<00:41,  2.76it/s]Evaluating:  32%|███▏      | 54/167 [00:20<00:41,  2.75it/s]Evaluating:  33%|███▎      | 55/167 [00:20<00:40,  2.75it/s]Evaluating:  34%|███▎      | 56/167 [00:20<00:40,  2.75it/s]Evaluating:  34%|███▍      | 57/167 [00:21<00:39,  2.75it/s]Evaluating:  35%|███▍      | 58/167 [00:21<00:39,  2.75it/s]Evaluating:  35%|███▌      | 59/167 [00:21<00:39,  2.75it/s]Evaluating:  36%|███▌      | 60/167 [00:22<00:38,  2.74it/s]Evaluating:  37%|███▋      | 61/167 [00:22<00:38,  2.74it/s]Evaluating:  37%|███▋      | 62/167 [00:22<00:38,  2.73it/s]Evaluating:  38%|███▊      | 63/167 [00:23<00:38,  2.74it/s]Evaluating:  38%|███▊      | 64/167 [00:23<00:37,  2.75it/s]Evaluating:  39%|███▉      | 65/167 [00:24<00:37,  2.75it/s]Evaluating:  40%|███▉      | 66/167 [00:24<00:36,  2.76it/s]Evaluating:  40%|████      | 67/167 [00:24<00:36,  2.76it/s]Evaluating:  41%|████      | 68/167 [00:25<00:35,  2.76it/s]Evaluating:  41%|████▏     | 69/167 [00:25<00:35,  2.76it/s]Evaluating:  42%|████▏     | 70/167 [00:25<00:35,  2.75it/s]Evaluating:  43%|████▎     | 71/167 [00:26<00:34,  2.76it/s]Evaluating:  43%|████▎     | 72/167 [00:26<00:34,  2.76it/s]Evaluating:  44%|████▎     | 73/167 [00:26<00:34,  2.76it/s]Evaluating:  44%|████▍     | 74/167 [00:27<00:33,  2.77it/s]Evaluating:  45%|████▍     | 75/167 [00:27<00:33,  2.76it/s]Evaluating:  46%|████▌     | 76/167 [00:28<00:32,  2.76it/s]Evaluating:  46%|████▌     | 77/167 [00:28<00:32,  2.77it/s]Evaluating:  47%|████▋     | 78/167 [00:28<00:32,  2.77it/s]Evaluating:  47%|████▋     | 79/167 [00:29<00:31,  2.77it/s]Evaluating:  48%|████▊     | 80/167 [00:29<00:31,  2.76it/s]Evaluating:  49%|████▊     | 81/167 [00:29<00:31,  2.77it/s]Evaluating:  49%|████▉     | 82/167 [00:30<00:30,  2.77it/s]Evaluating:  50%|████▉     | 83/167 [00:30<00:30,  2.77it/s]Evaluating:  50%|█████     | 84/167 [00:30<00:29,  2.77it/s]Evaluating:  51%|█████     | 85/167 [00:31<00:29,  2.77it/s]Evaluating:  51%|█████▏    | 86/167 [00:31<00:29,  2.77it/s]Evaluating:  52%|█████▏    | 87/167 [00:32<00:28,  2.76it/s]Evaluating:  53%|█████▎    | 88/167 [00:32<00:28,  2.75it/s]Evaluating:  53%|█████▎    | 89/167 [00:32<00:28,  2.76it/s]Evaluating:  54%|█████▍    | 90/167 [00:33<00:27,  2.76it/s]Evaluating:  54%|█████▍    | 91/167 [00:33<00:27,  2.75it/s]Evaluating:  55%|█████▌    | 92/167 [00:33<00:27,  2.75it/s]Evaluating:  56%|█████▌    | 93/167 [00:34<00:26,  2.75it/s]Evaluating:  56%|█████▋    | 94/167 [00:34<00:26,  2.76it/s]Evaluating:  57%|█████▋    | 95/167 [00:34<00:26,  2.76it/s]Evaluating:  57%|█████▋    | 96/167 [00:35<00:25,  2.76it/s]Evaluating:  58%|█████▊    | 97/167 [00:35<00:25,  2.76it/s]Evaluating:  59%|█████▊    | 98/167 [00:36<00:25,  2.71it/s]Evaluating:  59%|█████▉    | 99/167 [00:36<00:25,  2.70it/s]Evaluating:  60%|█████▉    | 100/167 [00:36<00:24,  2.72it/s]Evaluating:  60%|██████    | 101/167 [00:37<00:24,  2.73it/s]Evaluating:  61%|██████    | 102/167 [00:37<00:23,  2.74it/s]Evaluating:  62%|██████▏   | 103/167 [00:37<00:23,  2.75it/s]Evaluating:  62%|██████▏   | 104/167 [00:38<00:22,  2.75it/s]Evaluating:  63%|██████▎   | 105/167 [00:38<00:22,  2.74it/s]Evaluating:  63%|██████▎   | 106/167 [00:38<00:22,  2.67it/s]Evaluating:  64%|██████▍   | 107/167 [00:39<00:22,  2.70it/s]Evaluating:  65%|██████▍   | 108/167 [00:39<00:21,  2.72it/s]Evaluating:  65%|██████▌   | 109/167 [00:40<00:21,  2.72it/s]Evaluating:  66%|██████▌   | 110/167 [00:40<00:20,  2.72it/s]Evaluating:  66%|██████▋   | 111/167 [00:40<00:20,  2.70it/s]Evaluating:  67%|██████▋   | 112/167 [00:41<00:20,  2.72it/s]Evaluating:  68%|██████▊   | 113/167 [00:41<00:19,  2.73it/s]Evaluating:  68%|██████▊   | 114/167 [00:41<00:19,  2.73it/s]Evaluating:  69%|██████▉   | 115/167 [00:42<00:18,  2.74it/s]Evaluating:  69%|██████▉   | 116/167 [00:42<00:18,  2.75it/s]Evaluating:  70%|███████   | 117/167 [00:42<00:18,  2.74it/s]Evaluating:  71%|███████   | 118/167 [00:43<00:17,  2.74it/s]Evaluating:  71%|███████▏  | 119/167 [00:43<00:17,  2.73it/s]Evaluating:  72%|███████▏  | 120/167 [00:44<00:17,  2.73it/s]Evaluating:  72%|███████▏  | 121/167 [00:44<00:16,  2.74it/s]Evaluating:  73%|███████▎  | 122/167 [00:44<00:16,  2.75it/s]Evaluating:  74%|███████▎  | 123/167 [00:45<00:15,  2.75it/s]Evaluating:  74%|███████▍  | 124/167 [00:45<00:15,  2.69it/s]Evaluating:  75%|███████▍  | 125/167 [00:45<00:15,  2.70it/s]Evaluating:  75%|███████▌  | 126/167 [00:46<00:15,  2.72it/s]Evaluating:  76%|███████▌  | 127/167 [00:46<00:14,  2.71it/s]Evaluating:  77%|███████▋  | 128/167 [00:47<00:14,  2.72it/s]Evaluating:  77%|███████▋  | 129/167 [00:47<00:13,  2.73it/s]Evaluating:  78%|███████▊  | 130/167 [00:47<00:13,  2.74it/s]Evaluating:  78%|███████▊  | 131/167 [00:48<00:13,  2.75it/s]Evaluating:  79%|███████▉  | 132/167 [00:48<00:12,  2.75it/s]Evaluating:  80%|███████▉  | 133/167 [00:48<00:12,  2.75it/s]Evaluating:  80%|████████  | 134/167 [00:49<00:12,  2.74it/s]Evaluating:  81%|████████  | 135/167 [00:49<00:11,  2.75it/s]Evaluating:  81%|████████▏ | 136/167 [00:49<00:11,  2.75it/s]Evaluating:  82%|████████▏ | 137/167 [00:50<00:10,  2.76it/s]Evaluating:  83%|████████▎ | 138/167 [00:50<00:10,  2.76it/s]Evaluating:  83%|████████▎ | 139/167 [00:51<00:10,  2.77it/s]Evaluating:  84%|████████▍ | 140/167 [00:51<00:09,  2.72it/s]Evaluating:  84%|████████▍ | 141/167 [00:51<00:09,  2.73it/s]Evaluating:  85%|████████▌ | 142/167 [00:52<00:09,  2.74it/s]Evaluating:  86%|████████▌ | 143/167 [00:52<00:08,  2.75it/s]Evaluating:  86%|████████▌ | 144/167 [00:52<00:08,  2.73it/s]Evaluating:  87%|████████▋ | 145/167 [00:53<00:08,  2.74it/s]Evaluating:  87%|████████▋ | 146/167 [00:53<00:07,  2.74it/s]Evaluating:  88%|████████▊ | 147/167 [00:53<00:07,  2.74it/s]Evaluating:  89%|████████▊ | 148/167 [00:54<00:06,  2.76it/s]Evaluating:  89%|████████▉ | 149/167 [00:54<00:06,  2.74it/s]Evaluating:  90%|████████▉ | 150/167 [00:55<00:06,  2.73it/s]Evaluating:  90%|█████████ | 151/167 [00:55<00:05,  2.67it/s]Evaluating:  91%|█████████ | 152/167 [00:55<00:05,  2.69it/s]Evaluating:  92%|█████████▏| 153/167 [00:56<00:05,  2.71it/s]Evaluating:  92%|█████████▏| 154/167 [00:56<00:04,  2.72it/s]Evaluating:  93%|█████████▎| 155/167 [00:56<00:04,  2.70it/s]Evaluating:  93%|█████████▎| 156/167 [00:57<00:04,  2.71it/s]Evaluating:  94%|█████████▍| 157/167 [00:57<00:03,  2.70it/s]Evaluating:  95%|█████████▍| 158/167 [00:58<00:03,  2.67it/s]Evaluating:  95%|█████████▌| 159/167 [00:58<00:02,  2.69it/s]Evaluating:  96%|█████████▌| 160/167 [00:58<00:02,  2.71it/s]Evaluating:  96%|█████████▋| 161/167 [00:59<00:02,  2.72it/s]Evaluating:  97%|█████████▋| 162/167 [00:59<00:01,  2.74it/s]Evaluating:  98%|█████████▊| 163/167 [00:59<00:01,  2.75it/s]Evaluating:  98%|█████████▊| 164/167 [01:00<00:01,  2.64it/s]Evaluating:  99%|█████████▉| 165/167 [01:00<00:00,  2.67it/s]Evaluating:  99%|█████████▉| 166/167 [01:01<00:00,  2.63it/s]Evaluating: 100%|██████████| 167/167 [01:01<00:00,  3.09it/s]Evaluating: 100%|██████████| 167/167 [01:01<00:00,  2.73it/s]
05/09/2022 20:00:22 - INFO - __main__ -     Evaluation done in total 61.209902 secs (0.045953 sec per example)
05/09/2022 20:00:25 - INFO - __main__ -   Results: {'exact': 63.61344537815126, 'f1': 79.68640180443315, 'total': 1190, 'HasAns_exact': 63.61344537815126, 'HasAns_f1': 79.68640180443315, 'HasAns_total': 1190, 'best_exact': 63.61344537815126, 'best_exact_thresh': 0.0, 'best_f1': 79.68640180443315, 'best_f1_thresh': 0.0}
  tr 
2022-05-09 20:00:28.612001: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0
05/09/2022 20:00:34 - WARNING - __main__ -   Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, 16-bits training: False
You are using a model of type xlm-roberta to instantiate a model of type xlm. This is not supported for all configurations of models and can yield errors.
Some weights of the model checkpoint at /cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//squad/xlm-KG_LR8e-6_EPOCH2.0_maxlen384_batchsize4_gradacc4 were not used when initializing XLMRobertaModel: ['base_model.encoder.layer.1.output.LayerNorm.bias', 'base_model.encoder.layer.22.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.2.attention.self.key.bias', 'base_model.encoder.layer.6.attention.output.dense.bias', 'base_model.encoder.layer.1.attention.self.value.bias', 'base_model.encoder.layer.19.attention.output.LayerNorm.bias', 'base_model.encoder.layer.10.attention.output.dense.weight', 'base_model.encoder.layer.6.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.21.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.13.attention.self.value.bias', 'base_model.encoder.layer.21.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.17.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.9.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.18.attention.output.dense.bias', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.19.attention.self.query.bias', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.19.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.6.attention.self.key.weight', 'base_model.encoder.layer.1.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.3.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.17.attention.self.key.bias', 'base_model.encoder.layer.2.attention.self.query.weight', 'base_model.encoder.layer.0.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.17.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.18.attention.output.dense.weight', 'base_model.encoder.layer.15.attention.self.query.bias', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.15.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.22.attention.output.dense.bias', 'base_model.encoder.layer.6.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.13.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.13.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.15.intermediate.dense.weight', 'base_model.encoder.layer.3.attention.self.value.bias', 'base_model.encoder.layer.8.attention.output.LayerNorm.weight', 'base_model.encoder.layer.23.intermediate.dense.weight', 'base_model.encoder.layer.10.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.17.attention.output.LayerNorm.bias', 'base_model.encoder.layer.6.attention.self.value.bias', 'base_model.encoder.layer.21.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.19.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.21.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.6.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.4.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.0.attention.self.query.weight', 'base_model.encoder.layer.9.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.17.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.22.output.dense.bias', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.0.attention.self.key.bias', 'base_model.encoder.layer.12.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.9.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.13.intermediate.dense.bias', 'base_model.encoder.layer.13.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.3.output.LayerNorm.weight', 'base_model.encoder.layer.3.output.dense.weight', 'base_model.encoder.layer.5.attention.output.LayerNorm.bias', 'base_model.encoder.layer.9.attention.output.dense.weight', 'base_model.encoder.layer.10.output.adapters.ts.adapter_up.bias', 'base_model.embeddings.position_embeddings.weight', 'base_model.encoder.layer.7.attention.self.key.weight', 'base_model.encoder.layer.19.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.21.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.0.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.18.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.17.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.18.attention.self.query.bias', 'base_model.encoder.layer.20.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.6.attention.output.dense.weight', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.3.attention.self.value.weight', 'base_model.encoder.layer.8.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.1.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.2.output.LayerNorm.bias', 'base_model.encoder.layer.18.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.22.output.dense.weight', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.2.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.13.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.21.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.23.output.adapters.ep.adapter_up.bias', 'base_model.pooler.dense.weight', 'base_model.encoder.layer.18.attention.self.value.bias', 'base_model.encoder.layer.1.attention.output.LayerNorm.weight', 'base_model.encoder.layer.10.attention.self.query.weight', 'base_model.encoder.layer.14.attention.self.value.bias', 'base_model.encoder.layer.6.attention.self.query.bias', 'base_model.encoder.layer.12.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.17.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.5.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.17.attention.self.value.weight', 'base_model.encoder.layer.12.intermediate.dense.bias', 'base_model.encoder.layer.23.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.17.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.3.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.9.attention.output.LayerNorm.weight', 'base_model.encoder.layer.17.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.10.output.adapters.tp.adapter_down.0.bias', 'qa_outputs.weight', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.5.attention.self.key.weight', 'base_model.encoder.layer.23.output.dense.bias', 'base_model.embeddings.position_ids', 'base_model.encoder.layer.10.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.16.output.LayerNorm.bias', 'base_model.encoder.layer.21.attention.self.key.weight', 'base_model.encoder.layer.14.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.22.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.19.attention.self.key.weight', 'base_model.encoder.layer.18.attention.output.LayerNorm.bias', 'base_model.encoder.layer.19.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.5.output.dense.bias', 'base_model.encoder.layer.11.output.LayerNorm.weight', 'base_model.encoder.layer.11.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.20.intermediate.dense.bias', 'base_model.encoder.layer.18.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.22.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.20.attention.self.value.weight', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.19.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.17.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.5.attention.self.query.bias', 'base_model.encoder.layer.10.attention.self.query.bias', 'base_model.encoder.layer.5.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.22.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.0.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.9.attention.output.LayerNorm.bias', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.18.output.LayerNorm.weight', 'base_model.encoder.layer.0.attention.output.LayerNorm.weight', 'base_model.encoder.layer.14.attention.self.value.weight', 'base_model.encoder.layer.15.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.12.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.18.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.20.intermediate.dense.weight', 'base_model.encoder.layer.1.attention.self.query.weight', 'base_model.encoder.layer.15.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.1.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.17.attention.self.query.bias', 'base_model.encoder.layer.4.attention.self.query.bias', 'base_model.encoder.layer.15.attention.self.value.bias', 'base_model.encoder.layer.0.attention.self.key.weight', 'base_model.encoder.layer.10.attention.self.key.weight', 'base_model.encoder.layer.8.attention.output.dense.weight', 'base_model.encoder.layer.14.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.21.output.LayerNorm.bias', 'base_model.encoder.layer.0.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.8.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.22.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.3.attention.self.key.weight', 'base_model.encoder.layer.6.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.4.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.17.output.LayerNorm.weight', 'base_model.encoder.layer.3.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.14.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.20.attention.output.LayerNorm.bias', 'base_model.encoder.layer.15.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.2.output.adapters.es.adapter_down.0.weight', 'base_model.pooler.dense.bias', 'base_model.encoder.layer.0.attention.output.LayerNorm.bias', 'base_model.encoder.layer.9.attention.self.value.bias', 'base_model.encoder.layer.11.output.LayerNorm.bias', 'base_model.encoder.layer.1.attention.self.value.weight', 'base_model.encoder.layer.3.attention.self.query.weight', 'base_model.encoder.layer.5.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.22.attention.self.value.weight', 'base_model.encoder.layer.7.output.LayerNorm.weight', 'base_model.encoder.layer.12.output.LayerNorm.bias', 'base_model.encoder.layer.20.attention.output.dense.weight', 'base_model.encoder.layer.7.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.18.output.LayerNorm.bias', 'base_model.encoder.layer.9.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.21.attention.output.LayerNorm.weight', 'base_model.encoder.layer.7.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.2.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.11.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.15.attention.output.LayerNorm.weight', 'base_model.encoder.layer.16.attention.output.dense.bias', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.6.output.dense.bias', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.16.output.dense.weight', 'base_model.encoder.layer.20.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.21.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.13.attention.self.query.bias', 'base_model.encoder.layer.21.attention.self.query.weight', 'base_model.encoder.layer.5.attention.self.query.weight', 'base_model.encoder.layer.22.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.16.attention.output.LayerNorm.bias', 'base_model.encoder.layer.13.output.dense.bias', 'base_model.encoder.layer.0.intermediate.dense.bias', 'base_model.encoder.layer.19.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.0.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.7.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.13.output.dense.weight', 'base_model.encoder.layer.14.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.19.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.16.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.13.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.7.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.2.intermediate.dense.weight', 'base_model.encoder.layer.1.attention.self.key.bias', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.20.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.0.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.14.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.2.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.5.intermediate.dense.bias', 'base_model.encoder.layer.6.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.7.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.15.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.5.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.13.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.12.attention.output.LayerNorm.weight', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.14.attention.output.LayerNorm.bias', 'base_model.encoder.layer.13.intermediate.dense.weight', 'base_model.encoder.layer.18.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.23.attention.self.value.bias', 'base_model.encoder.layer.2.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.14.output.dense.weight', 'base_model.encoder.layer.6.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.19.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.23.attention.self.query.weight', 'base_model.encoder.layer.17.attention.self.value.bias', 'base_model.encoder.layer.16.intermediate.dense.bias', 'base_model.encoder.layer.17.attention.output.LayerNorm.weight', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.13.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.20.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.20.output.dense.bias', 'base_model.encoder.layer.11.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.23.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.1.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.0.output.dense.weight', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.3.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.1.output.LayerNorm.weight', 'base_model.encoder.layer.12.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.1.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.15.output.dense.weight', 'base_model.encoder.layer.12.intermediate.dense.weight', 'base_model.encoder.layer.15.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.20.attention.self.query.bias', 'base_model.encoder.layer.18.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.16.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.14.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.12.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.12.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.16.attention.self.key.bias', 'base_model.encoder.layer.7.attention.self.value.bias', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.19.attention.output.dense.weight', 'base_model.encoder.layer.14.attention.output.dense.weight', 'base_model.embeddings.LayerNorm.bias', 'base_model.encoder.layer.11.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.2.attention.output.dense.weight', 'base_model.encoder.layer.18.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.10.output.LayerNorm.weight', 'base_model.encoder.layer.21.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.22.attention.self.value.bias', 'base_model.encoder.layer.11.attention.self.value.weight', 'base_model.encoder.layer.10.attention.output.LayerNorm.weight', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.12.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.20.output.LayerNorm.weight', 'base_model.encoder.layer.7.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.0.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.4.attention.self.key.weight', 'base_model.encoder.layer.13.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.22.attention.output.LayerNorm.weight', 'base_model.encoder.layer.18.attention.self.key.weight', 'base_model.encoder.layer.7.attention.self.key.bias', 'base_model.encoder.layer.0.attention.self.query.bias', 'base_model.encoder.layer.2.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.19.attention.self.key.bias', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.19.output.LayerNorm.bias', 'base_model.encoder.layer.10.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.23.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.5.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.12.attention.self.query.weight', 'base_model.encoder.layer.16.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.7.attention.self.query.weight', 'base_model.encoder.layer.16.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.8.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.8.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.15.attention.self.key.bias', 'base_model.encoder.layer.4.attention.output.LayerNorm.bias', 'base_model.encoder.layer.6.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.13.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.18.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.20.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.12.output.LayerNorm.weight', 'base_model.encoder.layer.7.attention.output.dense.bias', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.21.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.0.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.7.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.21.intermediate.dense.weight', 'base_model.encoder.layer.14.output.LayerNorm.bias', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.18.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.18.attention.self.query.weight', 'base_model.encoder.layer.12.attention.self.query.bias', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.20.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.4.attention.output.dense.weight', 'base_model.encoder.layer.14.attention.self.query.weight', 'base_model.encoder.layer.3.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.9.attention.self.value.weight', 'base_model.encoder.layer.20.output.LayerNorm.bias', 'base_model.encoder.layer.7.intermediate.dense.weight', 'base_model.encoder.layer.9.intermediate.dense.weight', 'base_model.encoder.layer.9.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.20.output.adapters.ep.adapter_down.0.bias', 'base_model.embeddings.LayerNorm.weight', 'base_model.encoder.layer.11.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.17.output.dense.weight', 'base_model.encoder.layer.21.attention.self.value.weight', 'base_model.encoder.layer.4.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.4.output.LayerNorm.weight', 'base_model.encoder.layer.19.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.17.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.7.attention.self.value.weight', 'base_model.encoder.layer.1.attention.output.dense.weight', 'base_model.encoder.layer.11.output.dense.bias', 'base_model.encoder.layer.4.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.20.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.15.attention.output.dense.weight', 'base_model.encoder.layer.23.output.LayerNorm.weight', 'base_model.encoder.layer.16.output.LayerNorm.weight', 'base_model.encoder.layer.22.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.1.attention.self.key.weight', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.0.output.LayerNorm.bias', 'base_model.encoder.layer.22.attention.self.query.bias', 'base_model.encoder.layer.10.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.14.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.21.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.2.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.8.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.18.output.dense.bias', 'base_model.encoder.layer.18.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.20.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.6.attention.output.LayerNorm.bias', 'base_model.encoder.layer.9.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.19.intermediate.dense.weight', 'base_model.encoder.layer.8.attention.self.query.weight', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.3.output.dense.bias', 'base_model.encoder.layer.16.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.19.attention.self.value.weight', 'base_model.encoder.layer.16.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.12.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.8.attention.output.LayerNorm.bias', 'base_model.encoder.layer.0.output.dense.bias', 'base_model.encoder.layer.0.attention.self.value.weight', 'base_model.encoder.layer.8.output.dense.weight', 'base_model.encoder.layer.19.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.6.output.LayerNorm.bias', 'base_model.encoder.layer.6.output.LayerNorm.weight', 'base_model.encoder.layer.15.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.10.attention.self.value.bias', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.14.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.21.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.4.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.9.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.14.attention.output.LayerNorm.weight', 'base_model.encoder.layer.16.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.14.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.20.attention.self.key.bias', 'base_model.encoder.layer.17.attention.output.dense.weight', 'base_model.encoder.layer.11.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.20.attention.output.dense.bias', 'base_model.encoder.layer.17.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.23.attention.self.query.bias', 'base_model.encoder.layer.0.attention.self.value.bias', 'base_model.encoder.layer.0.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.3.attention.output.LayerNorm.weight', 'base_model.encoder.layer.11.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.12.attention.self.value.bias', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.2.output.dense.bias', 'base_model.encoder.layer.11.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.1.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.5.attention.output.dense.weight', 'base_model.encoder.layer.7.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.10.output.LayerNorm.bias', 'base_model.encoder.layer.10.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.2.attention.output.dense.bias', 'base_model.encoder.layer.5.output.LayerNorm.bias', 'base_model.encoder.layer.12.attention.self.key.bias', 'base_model.encoder.layer.5.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.2.attention.output.LayerNorm.weight', 'base_model.encoder.layer.5.output.dense.weight', 'base_model.encoder.layer.8.attention.self.value.weight', 'base_model.encoder.layer.12.attention.self.value.weight', 'base_model.encoder.layer.22.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.14.attention.output.dense.bias', 'base_model.encoder.layer.8.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.14.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.6.attention.self.key.bias', 'base_model.encoder.layer.7.output.LayerNorm.bias', 'base_model.encoder.layer.1.attention.output.dense.bias', 'base_model.encoder.layer.6.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.6.output.dense.weight', 'base_model.encoder.layer.7.attention.output.dense.weight', 'base_model.encoder.layer.10.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.10.attention.output.LayerNorm.bias', 'base_model.encoder.layer.21.attention.output.dense.bias', 'base_model.encoder.layer.4.intermediate.dense.weight', 'base_model.encoder.layer.16.output.dense.bias', 'base_model.encoder.layer.22.attention.self.query.weight', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.5.attention.self.value.bias', 'base_model.encoder.layer.11.attention.output.dense.weight', 'base_model.encoder.layer.4.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.23.attention.output.LayerNorm.bias', 'base_model.embeddings.token_type_embeddings.weight', 'base_model.encoder.layer.15.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.0.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.4.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.21.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.14.intermediate.dense.bias', 'base_model.encoder.layer.4.output.dense.weight', 'base_model.encoder.layer.3.intermediate.dense.bias', 'base_model.encoder.layer.21.attention.output.LayerNorm.bias', 'base_model.encoder.layer.10.output.dense.weight', 'base_model.encoder.layer.13.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.8.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.22.intermediate.dense.bias', 'base_model.encoder.layer.17.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.16.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.12.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.18.attention.self.value.weight', 'base_model.encoder.layer.22.attention.self.key.weight', 'base_model.encoder.layer.21.attention.self.key.bias', 'base_model.encoder.layer.9.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.10.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.2.attention.self.query.bias', 'base_model.encoder.layer.8.attention.self.query.bias', 'base_model.encoder.layer.2.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.8.output.dense.bias', 'base_model.encoder.layer.1.attention.output.LayerNorm.bias', 'base_model.encoder.layer.12.attention.output.dense.bias', 'base_model.encoder.layer.6.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.15.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.3.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.4.attention.self.query.weight', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.7.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.20.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.1.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.7.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.10.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.10.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.13.attention.output.LayerNorm.bias', 'base_model.encoder.layer.15.output.dense.bias', 'base_model.encoder.layer.17.output.dense.bias', 'base_model.encoder.layer.2.attention.output.LayerNorm.bias', 'base_model.encoder.layer.21.output.dense.weight', 'base_model.encoder.layer.6.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.8.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.3.attention.self.query.bias', 'base_model.encoder.layer.21.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.22.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.5.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.21.intermediate.dense.bias', 'base_model.encoder.layer.6.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.9.attention.output.dense.bias', 'base_model.encoder.layer.9.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.7.output.dense.bias', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.1.output.dense.weight', 'base_model.encoder.layer.3.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.5.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.9.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.1.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.9.attention.self.query.bias', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.8.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.0.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.3.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.13.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.17.intermediate.dense.bias', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.9.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.11.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.23.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.21.output.dense.bias', 'base_model.encoder.layer.16.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.1.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.13.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.23.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.4.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.8.attention.output.dense.bias', 'base_model.encoder.layer.23.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.6.intermediate.dense.weight', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.2.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.4.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.1.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.8.output.LayerNorm.bias', 'base_model.encoder.layer.2.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.22.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.20.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.0.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.3.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.7.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.15.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.7.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.20.attention.self.key.weight', 'base_model.encoder.layer.13.attention.output.dense.weight', 'base_model.encoder.layer.11.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.17.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.10.output.dense.bias', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.15.output.LayerNorm.bias', 'base_model.encoder.layer.17.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.22.output.LayerNorm.bias', 'base_model.encoder.layer.13.attention.output.dense.bias', 'base_model.encoder.layer.17.intermediate.dense.weight', 'base_model.encoder.layer.4.attention.output.dense.bias', 'base_model.encoder.layer.4.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.9.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.2.output.dense.weight', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.23.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.4.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.18.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.0.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.7.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.18.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.21.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.1.attention.self.query.bias', 'base_model.encoder.layer.1.intermediate.dense.bias', 'base_model.encoder.layer.12.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.14.attention.self.query.bias', 'base_model.encoder.layer.8.attention.self.key.weight', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.8.intermediate.dense.weight', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.7.attention.output.LayerNorm.weight', 'base_model.encoder.layer.2.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.23.attention.self.key.bias', 'base_model.encoder.layer.16.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.23.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.6.intermediate.dense.bias', 'base_model.encoder.layer.15.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.11.attention.self.query.bias', 'base_model.encoder.layer.7.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.5.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.11.attention.self.query.weight', 'base_model.encoder.layer.18.attention.output.LayerNorm.weight', 'base_model.encoder.layer.15.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.12.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.4.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.14.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.12.output.dense.weight', 'base_model.encoder.layer.8.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.7.attention.output.LayerNorm.bias', 'base_model.encoder.layer.3.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.12.attention.output.dense.weight', 'base_model.encoder.layer.19.output.dense.weight', 'base_model.encoder.layer.11.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.18.intermediate.dense.bias', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.21.output.LayerNorm.weight', 'base_model.encoder.layer.3.attention.output.LayerNorm.bias', 'base_model.encoder.layer.3.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.20.attention.self.value.bias', 'base_model.encoder.layer.6.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.11.output.dense.weight', 'base_model.encoder.layer.0.output.LayerNorm.weight', 'base_model.encoder.layer.23.attention.output.dense.weight', 'base_model.encoder.layer.1.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.6.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.9.output.LayerNorm.weight', 'base_model.encoder.layer.19.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.4.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.19.attention.output.LayerNorm.weight', 'base_model.encoder.layer.18.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.19.attention.self.value.bias', 'base_model.encoder.layer.17.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.18.output.dense.weight', 'base_model.encoder.layer.1.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.1.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.13.output.LayerNorm.bias', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.4.attention.self.key.bias', 'base_model.encoder.layer.9.output.adapters.ts.adapter_up.weight', 'base_model.embeddings.word_embeddings.weight', 'base_model.encoder.layer.9.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.8.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.10.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.11.attention.output.LayerNorm.weight', 'base_model.encoder.layer.14.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.5.attention.output.LayerNorm.weight', 'base_model.encoder.layer.16.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.14.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.12.attention.self.key.weight', 'base_model.encoder.layer.13.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.23.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.6.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.5.output.LayerNorm.weight', 'base_model.encoder.layer.18.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.7.attention.self.query.bias', 'base_model.encoder.layer.20.output.dense.weight', 'base_model.encoder.layer.8.output.LayerNorm.weight', 'base_model.encoder.layer.13.attention.output.LayerNorm.weight', 'base_model.encoder.layer.4.intermediate.dense.bias', 'base_model.encoder.layer.4.attention.self.value.bias', 'base_model.encoder.layer.22.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.9.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.10.intermediate.dense.weight', 'base_model.encoder.layer.12.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.15.intermediate.dense.bias', 'base_model.encoder.layer.20.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.22.attention.output.dense.weight', 'base_model.encoder.layer.7.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.8.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.16.attention.output.LayerNorm.weight', 'base_model.encoder.layer.17.attention.self.key.weight', 'base_model.encoder.layer.2.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.6.attention.self.value.weight', 'base_model.encoder.layer.11.attention.self.value.bias', 'base_model.encoder.layer.4.attention.self.value.weight', 'base_model.encoder.layer.7.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.19.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.9.attention.self.key.weight', 'base_model.encoder.layer.19.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.14.intermediate.dense.weight', 'base_model.encoder.layer.14.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.19.attention.self.query.weight', 'base_model.encoder.layer.19.attention.output.dense.bias', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.18.output.adapters.tp.adapter_down.0.weight', 'qa_outputs.bias', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.5.attention.self.value.weight', 'base_model.encoder.layer.5.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.11.attention.output.LayerNorm.bias', 'base_model.encoder.layer.0.intermediate.dense.weight', 'base_model.encoder.layer.4.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.11.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.9.intermediate.dense.bias', 'base_model.encoder.layer.5.intermediate.dense.weight', 'base_model.encoder.layer.16.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.5.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.10.intermediate.dense.bias', 'base_model.encoder.layer.18.intermediate.dense.weight', 'base_model.encoder.layer.1.intermediate.dense.weight', 'base_model.encoder.layer.4.output.LayerNorm.bias', 'base_model.encoder.layer.1.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.14.attention.self.key.bias', 'base_model.encoder.layer.13.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.17.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.16.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.20.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.14.attention.self.key.weight', 'base_model.encoder.layer.10.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.2.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.4.attention.output.LayerNorm.weight', 'base_model.encoder.layer.11.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.15.attention.self.query.weight', 'base_model.encoder.layer.22.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.9.attention.self.query.weight', 'base_model.encoder.layer.15.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.21.attention.self.query.bias', 'base_model.encoder.layer.0.attention.output.dense.weight', 'base_model.encoder.layer.3.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.5.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.16.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.20.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.13.attention.self.value.weight', 'base_model.encoder.layer.10.attention.output.dense.bias', 'base_model.encoder.layer.20.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.12.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.11.intermediate.dense.weight', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.17.output.LayerNorm.bias', 'base_model.encoder.layer.15.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.14.output.LayerNorm.weight', 'base_model.encoder.layer.2.intermediate.dense.bias', 'base_model.encoder.layer.13.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.15.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.19.intermediate.dense.bias', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.11.attention.self.key.weight', 'base_model.encoder.layer.15.attention.output.dense.bias', 'base_model.encoder.layer.7.intermediate.dense.bias', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.3.attention.output.dense.bias', 'base_model.encoder.layer.19.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.20.attention.self.query.weight', 'base_model.encoder.layer.11.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.15.attention.output.LayerNorm.bias', 'base_model.encoder.layer.9.attention.self.key.bias', 'base_model.encoder.layer.21.attention.output.dense.weight', 'base_model.encoder.layer.23.intermediate.dense.bias', 'base_model.encoder.layer.15.output.LayerNorm.weight', 'base_model.encoder.layer.9.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.12.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.23.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.0.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.3.output.LayerNorm.bias', 'base_model.encoder.layer.2.attention.self.value.bias', 'base_model.encoder.layer.3.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.8.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.7.output.dense.weight', 'base_model.encoder.layer.2.attention.self.value.weight', 'base_model.encoder.layer.11.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.16.intermediate.dense.weight', 'base_model.encoder.layer.23.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.16.attention.self.query.weight', 'base_model.encoder.layer.8.intermediate.dense.bias', 'base_model.encoder.layer.23.attention.output.dense.bias', 'base_model.encoder.layer.8.attention.self.value.bias', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.22.output.LayerNorm.weight', 'base_model.encoder.layer.23.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.22.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.14.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.10.attention.self.value.weight', 'base_model.encoder.layer.4.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.0.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.12.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.0.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.16.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.23.attention.self.key.weight', 'base_model.encoder.layer.0.attention.output.dense.bias', 'base_model.encoder.layer.22.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.3.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.13.attention.self.query.weight', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.2.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.9.output.LayerNorm.bias', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.13.attention.self.key.bias', 'base_model.encoder.layer.15.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.17.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.16.attention.self.value.weight', 'base_model.encoder.layer.20.attention.output.LayerNorm.weight', 'base_model.encoder.layer.22.intermediate.dense.weight', 'base_model.encoder.layer.12.attention.output.LayerNorm.bias', 'base_model.encoder.layer.23.output.dense.weight', 'base_model.encoder.layer.14.output.dense.bias', 'base_model.encoder.layer.8.attention.self.key.bias', 'base_model.encoder.layer.19.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.18.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.5.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.3.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.8.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.16.attention.self.value.bias', 'base_model.encoder.layer.17.attention.output.dense.bias', 'base_model.encoder.layer.11.attention.output.dense.bias', 'base_model.encoder.layer.8.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.22.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.5.attention.output.dense.bias', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.5.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.2.attention.self.key.weight', 'base_model.encoder.layer.9.output.dense.weight', 'base_model.encoder.layer.13.output.LayerNorm.weight', 'base_model.encoder.layer.17.attention.self.query.weight', 'base_model.encoder.layer.22.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.11.intermediate.dense.bias', 'base_model.encoder.layer.21.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.2.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.16.attention.output.dense.weight', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.1.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.19.output.dense.bias', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.19.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.5.attention.self.key.bias', 'base_model.encoder.layer.1.output.dense.bias', 'base_model.encoder.layer.16.attention.self.query.bias', 'base_model.encoder.layer.13.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.16.attention.self.key.weight', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.3.intermediate.dense.weight', 'base_model.encoder.layer.8.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.10.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.3.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.15.attention.self.key.weight', 'base_model.encoder.layer.3.attention.self.key.bias', 'base_model.encoder.layer.6.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.21.attention.self.value.bias', 'base_model.encoder.layer.23.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.3.attention.output.dense.weight', 'base_model.encoder.layer.10.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.6.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.23.attention.self.value.weight', 'base_model.encoder.layer.2.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.23.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.10.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.1.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.13.attention.self.key.weight', 'base_model.encoder.layer.23.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.14.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.11.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.20.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.22.attention.output.LayerNorm.bias', 'base_model.encoder.layer.21.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.23.output.LayerNorm.bias', 'base_model.encoder.layer.4.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.12.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.16.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.22.attention.self.key.bias', 'base_model.encoder.layer.12.output.dense.bias', 'base_model.encoder.layer.19.output.LayerNorm.weight', 'base_model.encoder.layer.4.output.dense.bias', 'base_model.encoder.layer.18.attention.self.key.bias', 'base_model.encoder.layer.5.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.9.output.dense.bias', 'base_model.encoder.layer.10.attention.self.key.bias', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.23.attention.output.LayerNorm.weight', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.2.output.LayerNorm.weight', 'base_model.encoder.layer.15.attention.self.value.weight', 'base_model.encoder.layer.5.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.6.attention.self.query.weight', 'base_model.encoder.layer.6.attention.output.LayerNorm.weight', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.11.attention.self.key.bias']
- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of XLMRobertaModel were not initialized from the model checkpoint at /cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//squad/xlm-KG_LR8e-6_EPOCH2.0_maxlen384_batchsize4_gradacc4 and are newly initialized: ['encoder.layer.11.attention.output.dense.weight', 'encoder.layer.5.attention.output.dense.weight', 'encoder.layer.12.output.dense.weight', 'encoder.layer.12.attention.output.LayerNorm.bias', 'pooler.dense.weight', 'encoder.layer.3.attention.self.key.bias', 'encoder.layer.7.attention.self.key.bias', 'encoder.layer.21.attention.self.value.weight', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.20.intermediate.dense.bias', 'encoder.layer.13.intermediate.dense.bias', 'encoder.layer.5.attention.self.query.weight', 'encoder.layer.18.output.dense.weight', 'encoder.layer.0.attention.self.query.weight', 'encoder.layer.17.output.dense.bias', 'encoder.layer.22.attention.self.value.bias', 'encoder.layer.21.output.LayerNorm.bias', 'encoder.layer.10.attention.self.query.weight', 'encoder.layer.13.attention.self.query.bias', 'encoder.layer.14.intermediate.dense.bias', 'encoder.layer.5.attention.self.value.weight', 'encoder.layer.5.attention.self.key.bias', 'encoder.layer.17.attention.output.dense.weight', 'encoder.layer.15.attention.self.value.weight', 'encoder.layer.16.intermediate.dense.bias', 'encoder.layer.14.intermediate.dense.weight', 'embeddings.word_embeddings.weight', 'encoder.layer.23.output.dense.bias', 'encoder.layer.11.attention.output.LayerNorm.weight', 'encoder.layer.23.output.dense.weight', 'encoder.layer.8.attention.self.key.bias', 'encoder.layer.17.intermediate.dense.weight', 'encoder.layer.23.attention.self.key.weight', 'encoder.layer.11.output.LayerNorm.weight', 'encoder.layer.19.attention.self.query.weight', 'encoder.layer.7.output.LayerNorm.bias', 'encoder.layer.9.attention.self.key.bias', 'encoder.layer.22.attention.output.LayerNorm.weight', 'encoder.layer.19.intermediate.dense.bias', 'encoder.layer.14.attention.self.query.weight', 'encoder.layer.19.attention.output.LayerNorm.bias', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.12.attention.self.value.weight', 'encoder.layer.8.attention.self.value.bias', 'encoder.layer.1.attention.output.dense.bias', 'encoder.layer.7.output.LayerNorm.weight', 'encoder.layer.15.attention.output.LayerNorm.bias', 'encoder.layer.23.attention.output.dense.bias', 'pooler.dense.bias', 'encoder.layer.3.attention.output.dense.bias', 'encoder.layer.23.attention.self.query.weight', 'encoder.layer.5.output.LayerNorm.bias', 'encoder.layer.21.attention.self.value.bias', 'encoder.layer.12.attention.output.dense.bias', 'encoder.layer.1.attention.output.LayerNorm.weight', 'encoder.layer.18.attention.self.key.bias', 'embeddings.LayerNorm.weight', 'encoder.layer.14.attention.self.value.bias', 'encoder.layer.23.intermediate.dense.weight', 'encoder.layer.15.intermediate.dense.bias', 'encoder.layer.0.attention.self.value.bias', 'encoder.layer.22.output.LayerNorm.weight', 'encoder.layer.1.attention.self.key.bias', 'encoder.layer.8.attention.output.dense.weight', 'encoder.layer.23.attention.output.LayerNorm.bias', 'encoder.layer.0.output.dense.weight', 'encoder.layer.11.attention.self.query.weight', 'encoder.layer.7.output.dense.bias', 'encoder.layer.2.attention.self.query.weight', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.14.attention.output.LayerNorm.bias', 'encoder.layer.9.attention.self.query.weight', 'encoder.layer.10.output.LayerNorm.bias', 'encoder.layer.13.attention.self.value.bias', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.5.attention.self.key.weight', 'encoder.layer.8.attention.self.value.weight', 'encoder.layer.12.attention.output.LayerNorm.weight', 'encoder.layer.10.attention.self.value.bias', 'encoder.layer.16.attention.self.key.weight', 'encoder.layer.13.attention.output.dense.bias', 'encoder.layer.22.attention.self.key.weight', 'encoder.layer.12.attention.output.dense.weight', 'encoder.layer.15.attention.self.query.bias', 'encoder.layer.12.attention.self.query.weight', 'encoder.layer.23.attention.self.query.bias', 'encoder.layer.20.attention.self.query.weight', 'encoder.layer.21.attention.self.key.weight', 'encoder.layer.6.attention.self.key.weight', 'encoder.layer.0.attention.self.value.weight', 'encoder.layer.10.output.LayerNorm.weight', 'encoder.layer.21.output.dense.bias', 'encoder.layer.7.attention.output.dense.weight', 'encoder.layer.9.attention.output.dense.bias', 'encoder.layer.18.attention.output.dense.bias', 'encoder.layer.11.attention.self.key.weight', 'encoder.layer.16.output.LayerNorm.weight', 'encoder.layer.21.intermediate.dense.weight', 'encoder.layer.21.attention.output.LayerNorm.weight', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.2.attention.self.value.bias', 'encoder.layer.2.attention.output.dense.weight', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.14.attention.self.key.bias', 'encoder.layer.13.attention.self.query.weight', 'encoder.layer.2.output.dense.weight', 'encoder.layer.3.attention.self.query.bias', 'encoder.layer.6.output.LayerNorm.bias', 'encoder.layer.22.attention.output.LayerNorm.bias', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.11.output.dense.bias', 'encoder.layer.23.attention.output.LayerNorm.weight', 'encoder.layer.10.attention.output.dense.weight', 'encoder.layer.20.attention.self.value.weight', 'encoder.layer.8.output.LayerNorm.weight', 'encoder.layer.8.output.dense.weight', 'encoder.layer.20.attention.self.key.weight', 'encoder.layer.23.attention.self.value.bias', 'encoder.layer.8.output.LayerNorm.bias', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.20.output.LayerNorm.bias', 'encoder.layer.11.attention.self.key.bias', 'encoder.layer.19.output.LayerNorm.weight', 'encoder.layer.2.attention.self.query.bias', 'encoder.layer.13.output.dense.weight', 'encoder.layer.14.attention.self.key.weight', 'encoder.layer.9.attention.output.dense.weight', 'encoder.layer.6.attention.self.key.bias', 'encoder.layer.16.attention.self.value.weight', 'encoder.layer.9.attention.output.LayerNorm.weight', 'encoder.layer.10.attention.output.LayerNorm.bias', 'encoder.layer.1.attention.self.query.weight', 'encoder.layer.17.output.LayerNorm.bias', 'encoder.layer.23.attention.self.key.bias', 'encoder.layer.10.attention.output.dense.bias', 'encoder.layer.23.attention.self.value.weight', 'encoder.layer.6.attention.output.dense.bias', 'encoder.layer.19.attention.self.value.weight', 'encoder.layer.0.attention.output.dense.weight', 'encoder.layer.1.attention.self.value.bias', 'encoder.layer.11.attention.output.dense.bias', 'encoder.layer.9.output.LayerNorm.bias', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.15.intermediate.dense.weight', 'encoder.layer.19.attention.output.dense.bias', 'encoder.layer.12.attention.self.key.bias', 'encoder.layer.12.output.LayerNorm.bias', 'encoder.layer.18.attention.output.LayerNorm.weight', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.13.output.dense.bias', 'encoder.layer.20.output.dense.weight', 'encoder.layer.11.attention.self.query.bias', 'encoder.layer.17.output.LayerNorm.weight', 'encoder.layer.16.output.dense.weight', 'encoder.layer.18.attention.output.dense.weight', 'encoder.layer.8.attention.output.LayerNorm.weight', 'encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.layer.15.attention.output.dense.weight', 'encoder.layer.20.attention.output.LayerNorm.weight', 'encoder.layer.11.output.LayerNorm.bias', 'encoder.layer.4.attention.output.dense.weight', 'encoder.layer.16.attention.output.LayerNorm.weight', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.5.output.dense.weight', 'encoder.layer.22.output.dense.bias', 'encoder.layer.22.intermediate.dense.bias', 'encoder.layer.20.attention.output.dense.weight', 'encoder.layer.20.attention.self.key.bias', 'encoder.layer.21.output.LayerNorm.weight', 'encoder.layer.4.attention.output.dense.bias', 'encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.layer.22.attention.output.dense.weight', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.8.attention.output.dense.bias', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.2.attention.self.key.bias', 'encoder.layer.6.attention.output.LayerNorm.weight', 'encoder.layer.9.attention.self.key.weight', 'encoder.layer.8.attention.self.query.weight', 'encoder.layer.16.attention.self.value.bias', 'encoder.layer.4.attention.self.value.weight', 'encoder.layer.9.attention.self.query.bias', 'encoder.layer.19.intermediate.dense.weight', 'encoder.layer.17.attention.output.dense.bias', 'encoder.layer.4.output.dense.bias', 'encoder.layer.18.output.dense.bias', 'encoder.layer.20.output.LayerNorm.weight', 'encoder.layer.21.intermediate.dense.bias', 'encoder.layer.5.attention.output.dense.bias', 'encoder.layer.18.output.LayerNorm.weight', 'encoder.layer.21.attention.self.query.bias', 'encoder.layer.15.output.dense.bias', 'encoder.layer.12.attention.self.value.bias', 'encoder.layer.16.attention.self.query.weight', 'encoder.layer.13.output.LayerNorm.weight', 'encoder.layer.1.attention.self.key.weight', 'encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.layer.2.output.dense.bias', 'encoder.layer.13.attention.output.LayerNorm.weight', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.10.attention.self.query.bias', 'encoder.layer.14.output.dense.bias', 'encoder.layer.17.attention.self.value.weight', 'encoder.layer.18.attention.self.value.bias', 'encoder.layer.18.intermediate.dense.bias', 'encoder.layer.19.attention.output.LayerNorm.weight', 'encoder.layer.23.output.LayerNorm.weight', 'encoder.layer.22.attention.self.value.weight', 'encoder.layer.6.attention.self.query.bias', 'encoder.layer.23.intermediate.dense.bias', 'encoder.layer.1.output.dense.weight', 'encoder.layer.22.attention.self.query.bias', 'encoder.layer.10.attention.self.key.bias', 'encoder.layer.6.attention.self.query.weight', 'encoder.layer.15.attention.self.value.bias', 'encoder.layer.3.attention.self.value.bias', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.19.attention.self.key.bias', 'encoder.layer.22.output.LayerNorm.bias', 'encoder.layer.18.intermediate.dense.weight', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.10.output.dense.bias', 'encoder.layer.3.output.dense.weight', 'encoder.layer.5.attention.output.LayerNorm.weight', 'embeddings.token_type_embeddings.weight', 'encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.layer.7.attention.output.LayerNorm.weight', 'encoder.layer.4.output.dense.weight', 'encoder.layer.5.attention.self.query.bias', 'encoder.layer.0.attention.self.key.bias', 'encoder.layer.21.attention.self.query.weight', 'encoder.layer.9.output.LayerNorm.weight', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.21.attention.output.dense.weight', 'encoder.layer.15.attention.output.dense.bias', 'encoder.layer.13.output.LayerNorm.bias', 'embeddings.LayerNorm.bias', 'encoder.layer.13.attention.self.key.weight', 'encoder.layer.9.attention.output.LayerNorm.bias', 'encoder.layer.18.attention.self.query.weight', 'encoder.layer.18.attention.self.key.weight', 'encoder.layer.17.attention.self.key.weight', 'encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.7.attention.self.query.bias', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.7.attention.output.LayerNorm.bias', 'encoder.layer.4.attention.output.LayerNorm.bias', 'encoder.layer.9.output.dense.weight', 'encoder.layer.3.attention.self.value.weight', 'encoder.layer.16.attention.output.LayerNorm.bias', 'encoder.layer.11.attention.self.value.bias', 'encoder.layer.21.attention.output.dense.bias', 'encoder.layer.12.intermediate.dense.bias', 'encoder.layer.17.attention.output.LayerNorm.bias', 'encoder.layer.19.attention.self.key.weight', 'encoder.layer.0.attention.output.LayerNorm.weight', 'encoder.layer.2.attention.output.dense.bias', 'encoder.layer.0.attention.output.dense.bias', 'encoder.layer.22.intermediate.dense.weight', 'encoder.layer.18.attention.self.value.weight', 'embeddings.position_embeddings.weight', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.11.attention.self.value.weight', 'encoder.layer.15.attention.self.key.weight', 'encoder.layer.7.output.dense.weight', 'encoder.layer.21.output.dense.weight', 'encoder.layer.22.attention.output.dense.bias', 'encoder.layer.20.attention.output.dense.bias', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.13.attention.output.dense.weight', 'encoder.layer.10.attention.output.LayerNorm.weight', 'encoder.layer.14.attention.output.dense.weight', 'encoder.layer.3.output.dense.bias', 'encoder.layer.4.attention.self.key.weight', 'encoder.layer.22.attention.self.query.weight', 'encoder.layer.1.attention.output.dense.weight', 'encoder.layer.13.attention.self.value.weight', 'encoder.layer.18.attention.self.query.bias', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.1.attention.self.value.weight', 'encoder.layer.11.output.dense.weight', 'encoder.layer.17.output.dense.weight', 'encoder.layer.15.output.LayerNorm.bias', 'encoder.layer.19.attention.self.value.bias', 'encoder.layer.23.output.LayerNorm.bias', 'encoder.layer.16.attention.output.dense.weight', 'encoder.layer.4.attention.self.query.weight', 'encoder.layer.12.attention.self.query.bias', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.5.attention.self.value.bias', 'encoder.layer.20.output.dense.bias', 'encoder.layer.8.output.dense.bias', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.17.attention.self.value.bias', 'encoder.layer.2.attention.self.value.weight', 'encoder.layer.20.attention.self.value.bias', 'encoder.layer.12.output.dense.bias', 'encoder.layer.14.output.dense.weight', 'encoder.layer.13.attention.self.key.bias', 'encoder.layer.12.output.LayerNorm.weight', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.22.output.dense.weight', 'encoder.layer.16.attention.output.dense.bias', 'encoder.layer.12.attention.self.key.weight', 'encoder.layer.7.attention.self.key.weight', 'encoder.layer.0.output.dense.bias', 'encoder.layer.6.attention.self.value.bias', 'encoder.layer.9.attention.self.value.weight', 'encoder.layer.20.intermediate.dense.weight', 'encoder.layer.16.intermediate.dense.weight', 'encoder.layer.8.attention.output.LayerNorm.bias', 'encoder.layer.15.attention.self.query.weight', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.16.attention.self.key.bias', 'encoder.layer.14.output.LayerNorm.weight', 'encoder.layer.21.attention.self.key.bias', 'encoder.layer.17.attention.self.query.weight', 'encoder.layer.17.attention.self.query.bias', 'encoder.layer.21.attention.output.LayerNorm.bias', 'encoder.layer.10.output.dense.weight', 'encoder.layer.15.output.dense.weight', 'encoder.layer.10.attention.self.key.weight', 'encoder.layer.19.output.LayerNorm.bias', 'encoder.layer.6.output.dense.weight', 'encoder.layer.7.attention.output.dense.bias', 'encoder.layer.7.attention.self.query.weight', 'encoder.layer.19.attention.self.query.bias', 'encoder.layer.14.output.LayerNorm.bias', 'encoder.layer.19.attention.output.dense.weight', 'encoder.layer.20.attention.self.query.bias', 'encoder.layer.18.attention.output.LayerNorm.bias', 'encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.layer.6.output.dense.bias', 'encoder.layer.13.intermediate.dense.weight', 'encoder.layer.3.attention.self.query.weight', 'encoder.layer.14.attention.self.query.bias', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.9.output.dense.bias', 'encoder.layer.16.output.dense.bias', 'encoder.layer.22.attention.self.key.bias', 'encoder.layer.16.attention.self.query.bias', 'encoder.layer.4.attention.self.key.bias', 'encoder.layer.9.attention.self.value.bias', 'encoder.layer.4.attention.output.LayerNorm.weight', 'encoder.layer.7.intermediate.dense.bias', 'encoder.layer.19.output.dense.bias', 'encoder.layer.10.intermediate.dense.weight', 'encoder.layer.14.attention.output.LayerNorm.weight', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.5.output.dense.bias', 'encoder.layer.7.attention.self.value.bias', 'encoder.layer.2.attention.self.key.weight', 'encoder.layer.18.output.LayerNorm.bias', 'encoder.layer.15.output.LayerNorm.weight', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.8.attention.self.key.weight', 'encoder.layer.10.attention.self.value.weight', 'encoder.layer.3.attention.self.key.weight', 'encoder.layer.1.output.dense.bias', 'encoder.layer.4.attention.self.value.bias', 'encoder.layer.15.attention.output.LayerNorm.weight', 'encoder.layer.16.output.LayerNorm.bias', 'encoder.layer.19.output.dense.weight', 'encoder.layer.17.attention.self.key.bias', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.14.attention.self.value.weight', 'encoder.layer.17.attention.output.LayerNorm.weight', 'encoder.layer.17.intermediate.dense.bias', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.4.attention.self.query.bias', 'encoder.layer.14.attention.output.dense.bias', 'encoder.layer.1.attention.self.query.bias', 'encoder.layer.0.attention.self.query.bias', 'encoder.layer.2.attention.output.LayerNorm.weight', 'encoder.layer.6.attention.output.LayerNorm.bias', 'encoder.layer.15.attention.self.key.bias', 'encoder.layer.6.attention.self.value.weight', 'encoder.layer.20.attention.output.LayerNorm.bias', 'encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.layer.7.attention.self.value.weight', 'encoder.layer.8.attention.self.query.bias', 'encoder.layer.12.intermediate.dense.weight', 'encoder.layer.0.attention.self.key.weight', 'encoder.layer.6.attention.output.dense.weight', 'encoder.layer.3.attention.output.dense.weight', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.13.attention.output.LayerNorm.bias', 'encoder.layer.23.attention.output.dense.weight', 'encoder.layer.2.attention.output.LayerNorm.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Overwriting existing adapter 'ep'.
Overwriting existing adapter 'tp'.
Overwriting existing adapter 'es'.
Overwriting existing adapter 'ts'.
Overwriting existing adapter fusion module 'ep,tp,es,ts'
05/09/2022 20:01:06 - INFO - __main__ -   lang2id = None
05/09/2022 20:01:11 - INFO - __main__ -   Training/evaluation parameters Namespace(adam_epsilon=1e-08, cache_dir='', config_name='', data_dir=None, device=device(type='cuda'), do_eval=True, do_lower_case=False, do_train=False, doc_stride=128, eval_all_checkpoints=False, eval_lang='tr', evaluate_during_training=False, fp16=False, fp16_opt_level='O1', gradient_accumulation_steps=1, learning_rate=5e-05, local_rank=-1, logging_steps=50, max_answer_length=30, max_grad_norm=1.0, max_query_length=64, max_seq_length=384, max_steps=-1, model_name='xlm-KG', model_name_or_path='/cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//squad/xlm-KG_LR8e-6_EPOCH2.0_maxlen384_batchsize4_gradacc4', model_type='xlm', modelkg_dir='/cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/adapter/xlmr_adapter', n_best_size=20, n_gpu=1, no_cuda=False, null_score_diff_threshold=0.0, num_train_epochs=3.0, output_dir='/cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//squad/xlm-KG_LR8e-6_EPOCH2.0_maxlen384_batchsize4_gradacc4/predictions/xquad/', overwrite_cache=False, overwrite_output_dir=False, per_gpu_eval_batch_size=8, per_gpu_train_batch_size=8, predict_file='/cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/download//xquad//xquad.tr.json', save_steps=50, seed=42, server_ip='', server_port='', threads=1, tokenizer_name='', train_file=None, train_lang='en', verbose_logging=False, version_2_with_negative=False, warmup_steps=0, weight_decay=0.0)
05/09/2022 20:01:11 - INFO - __main__ -   Loading checkpoint /cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//squad/xlm-KG_LR8e-6_EPOCH2.0_maxlen384_batchsize4_gradacc4 for evaluation
05/09/2022 20:01:11 - INFO - __main__ -   Evaluate the following checkpoints: ['/cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//squad/xlm-KG_LR8e-6_EPOCH2.0_maxlen384_batchsize4_gradacc4']
Some weights of the model checkpoint at /cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//squad/xlm-KG_LR8e-6_EPOCH2.0_maxlen384_batchsize4_gradacc4 were not used when initializing XLMRobertaModel: ['base_model.encoder.layer.1.output.LayerNorm.bias', 'base_model.encoder.layer.22.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.2.attention.self.key.bias', 'base_model.encoder.layer.6.attention.output.dense.bias', 'base_model.encoder.layer.1.attention.self.value.bias', 'base_model.encoder.layer.19.attention.output.LayerNorm.bias', 'base_model.encoder.layer.10.attention.output.dense.weight', 'base_model.encoder.layer.6.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.21.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.13.attention.self.value.bias', 'base_model.encoder.layer.21.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.17.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.9.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.18.attention.output.dense.bias', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.19.attention.self.query.bias', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.19.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.6.attention.self.key.weight', 'base_model.encoder.layer.1.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.3.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.17.attention.self.key.bias', 'base_model.encoder.layer.2.attention.self.query.weight', 'base_model.encoder.layer.0.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.17.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.18.attention.output.dense.weight', 'base_model.encoder.layer.15.attention.self.query.bias', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.15.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.22.attention.output.dense.bias', 'base_model.encoder.layer.6.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.13.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.13.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.15.intermediate.dense.weight', 'base_model.encoder.layer.3.attention.self.value.bias', 'base_model.encoder.layer.8.attention.output.LayerNorm.weight', 'base_model.encoder.layer.23.intermediate.dense.weight', 'base_model.encoder.layer.10.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.17.attention.output.LayerNorm.bias', 'base_model.encoder.layer.6.attention.self.value.bias', 'base_model.encoder.layer.21.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.19.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.21.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.6.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.4.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.0.attention.self.query.weight', 'base_model.encoder.layer.9.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.17.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.22.output.dense.bias', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.0.attention.self.key.bias', 'base_model.encoder.layer.12.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.9.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.13.intermediate.dense.bias', 'base_model.encoder.layer.13.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.3.output.LayerNorm.weight', 'base_model.encoder.layer.3.output.dense.weight', 'base_model.encoder.layer.5.attention.output.LayerNorm.bias', 'base_model.encoder.layer.9.attention.output.dense.weight', 'base_model.encoder.layer.10.output.adapters.ts.adapter_up.bias', 'base_model.embeddings.position_embeddings.weight', 'base_model.encoder.layer.7.attention.self.key.weight', 'base_model.encoder.layer.19.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.21.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.0.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.18.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.17.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.18.attention.self.query.bias', 'base_model.encoder.layer.20.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.6.attention.output.dense.weight', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.3.attention.self.value.weight', 'base_model.encoder.layer.8.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.1.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.2.output.LayerNorm.bias', 'base_model.encoder.layer.18.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.22.output.dense.weight', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.2.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.13.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.21.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.23.output.adapters.ep.adapter_up.bias', 'base_model.pooler.dense.weight', 'base_model.encoder.layer.18.attention.self.value.bias', 'base_model.encoder.layer.1.attention.output.LayerNorm.weight', 'base_model.encoder.layer.10.attention.self.query.weight', 'base_model.encoder.layer.14.attention.self.value.bias', 'base_model.encoder.layer.6.attention.self.query.bias', 'base_model.encoder.layer.12.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.17.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.5.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.17.attention.self.value.weight', 'base_model.encoder.layer.12.intermediate.dense.bias', 'base_model.encoder.layer.23.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.17.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.3.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.9.attention.output.LayerNorm.weight', 'base_model.encoder.layer.17.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.10.output.adapters.tp.adapter_down.0.bias', 'qa_outputs.weight', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.5.attention.self.key.weight', 'base_model.encoder.layer.23.output.dense.bias', 'base_model.embeddings.position_ids', 'base_model.encoder.layer.10.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.16.output.LayerNorm.bias', 'base_model.encoder.layer.21.attention.self.key.weight', 'base_model.encoder.layer.14.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.22.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.19.attention.self.key.weight', 'base_model.encoder.layer.18.attention.output.LayerNorm.bias', 'base_model.encoder.layer.19.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.5.output.dense.bias', 'base_model.encoder.layer.11.output.LayerNorm.weight', 'base_model.encoder.layer.11.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.20.intermediate.dense.bias', 'base_model.encoder.layer.18.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.22.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.20.attention.self.value.weight', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.19.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.17.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.5.attention.self.query.bias', 'base_model.encoder.layer.10.attention.self.query.bias', 'base_model.encoder.layer.5.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.22.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.0.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.9.attention.output.LayerNorm.bias', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.18.output.LayerNorm.weight', 'base_model.encoder.layer.0.attention.output.LayerNorm.weight', 'base_model.encoder.layer.14.attention.self.value.weight', 'base_model.encoder.layer.15.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.12.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.18.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.20.intermediate.dense.weight', 'base_model.encoder.layer.1.attention.self.query.weight', 'base_model.encoder.layer.15.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.1.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.17.attention.self.query.bias', 'base_model.encoder.layer.4.attention.self.query.bias', 'base_model.encoder.layer.15.attention.self.value.bias', 'base_model.encoder.layer.0.attention.self.key.weight', 'base_model.encoder.layer.10.attention.self.key.weight', 'base_model.encoder.layer.8.attention.output.dense.weight', 'base_model.encoder.layer.14.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.21.output.LayerNorm.bias', 'base_model.encoder.layer.0.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.8.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.22.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.3.attention.self.key.weight', 'base_model.encoder.layer.6.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.4.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.17.output.LayerNorm.weight', 'base_model.encoder.layer.3.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.14.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.20.attention.output.LayerNorm.bias', 'base_model.encoder.layer.15.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.2.output.adapters.es.adapter_down.0.weight', 'base_model.pooler.dense.bias', 'base_model.encoder.layer.0.attention.output.LayerNorm.bias', 'base_model.encoder.layer.9.attention.self.value.bias', 'base_model.encoder.layer.11.output.LayerNorm.bias', 'base_model.encoder.layer.1.attention.self.value.weight', 'base_model.encoder.layer.3.attention.self.query.weight', 'base_model.encoder.layer.5.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.22.attention.self.value.weight', 'base_model.encoder.layer.7.output.LayerNorm.weight', 'base_model.encoder.layer.12.output.LayerNorm.bias', 'base_model.encoder.layer.20.attention.output.dense.weight', 'base_model.encoder.layer.7.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.18.output.LayerNorm.bias', 'base_model.encoder.layer.9.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.21.attention.output.LayerNorm.weight', 'base_model.encoder.layer.7.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.2.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.11.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.15.attention.output.LayerNorm.weight', 'base_model.encoder.layer.16.attention.output.dense.bias', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.6.output.dense.bias', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.16.output.dense.weight', 'base_model.encoder.layer.20.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.21.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.13.attention.self.query.bias', 'base_model.encoder.layer.21.attention.self.query.weight', 'base_model.encoder.layer.5.attention.self.query.weight', 'base_model.encoder.layer.22.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.16.attention.output.LayerNorm.bias', 'base_model.encoder.layer.13.output.dense.bias', 'base_model.encoder.layer.0.intermediate.dense.bias', 'base_model.encoder.layer.19.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.0.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.7.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.13.output.dense.weight', 'base_model.encoder.layer.14.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.19.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.16.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.13.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.7.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.2.intermediate.dense.weight', 'base_model.encoder.layer.1.attention.self.key.bias', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.20.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.0.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.14.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.2.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.5.intermediate.dense.bias', 'base_model.encoder.layer.6.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.7.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.15.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.5.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.13.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.12.attention.output.LayerNorm.weight', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.14.attention.output.LayerNorm.bias', 'base_model.encoder.layer.13.intermediate.dense.weight', 'base_model.encoder.layer.18.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.23.attention.self.value.bias', 'base_model.encoder.layer.2.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.14.output.dense.weight', 'base_model.encoder.layer.6.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.19.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.23.attention.self.query.weight', 'base_model.encoder.layer.17.attention.self.value.bias', 'base_model.encoder.layer.16.intermediate.dense.bias', 'base_model.encoder.layer.17.attention.output.LayerNorm.weight', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.13.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.20.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.20.output.dense.bias', 'base_model.encoder.layer.11.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.23.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.1.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.0.output.dense.weight', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.3.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.1.output.LayerNorm.weight', 'base_model.encoder.layer.12.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.1.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.15.output.dense.weight', 'base_model.encoder.layer.12.intermediate.dense.weight', 'base_model.encoder.layer.15.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.20.attention.self.query.bias', 'base_model.encoder.layer.18.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.16.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.14.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.12.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.12.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.16.attention.self.key.bias', 'base_model.encoder.layer.7.attention.self.value.bias', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.19.attention.output.dense.weight', 'base_model.encoder.layer.14.attention.output.dense.weight', 'base_model.embeddings.LayerNorm.bias', 'base_model.encoder.layer.11.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.2.attention.output.dense.weight', 'base_model.encoder.layer.18.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.10.output.LayerNorm.weight', 'base_model.encoder.layer.21.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.22.attention.self.value.bias', 'base_model.encoder.layer.11.attention.self.value.weight', 'base_model.encoder.layer.10.attention.output.LayerNorm.weight', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.12.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.20.output.LayerNorm.weight', 'base_model.encoder.layer.7.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.0.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.4.attention.self.key.weight', 'base_model.encoder.layer.13.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.22.attention.output.LayerNorm.weight', 'base_model.encoder.layer.18.attention.self.key.weight', 'base_model.encoder.layer.7.attention.self.key.bias', 'base_model.encoder.layer.0.attention.self.query.bias', 'base_model.encoder.layer.2.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.19.attention.self.key.bias', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.19.output.LayerNorm.bias', 'base_model.encoder.layer.10.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.23.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.5.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.12.attention.self.query.weight', 'base_model.encoder.layer.16.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.7.attention.self.query.weight', 'base_model.encoder.layer.16.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.8.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.8.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.15.attention.self.key.bias', 'base_model.encoder.layer.4.attention.output.LayerNorm.bias', 'base_model.encoder.layer.6.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.13.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.18.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.20.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.12.output.LayerNorm.weight', 'base_model.encoder.layer.7.attention.output.dense.bias', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.21.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.0.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.7.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.21.intermediate.dense.weight', 'base_model.encoder.layer.14.output.LayerNorm.bias', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.18.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.18.attention.self.query.weight', 'base_model.encoder.layer.12.attention.self.query.bias', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.20.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.4.attention.output.dense.weight', 'base_model.encoder.layer.14.attention.self.query.weight', 'base_model.encoder.layer.3.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.9.attention.self.value.weight', 'base_model.encoder.layer.20.output.LayerNorm.bias', 'base_model.encoder.layer.7.intermediate.dense.weight', 'base_model.encoder.layer.9.intermediate.dense.weight', 'base_model.encoder.layer.9.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.20.output.adapters.ep.adapter_down.0.bias', 'base_model.embeddings.LayerNorm.weight', 'base_model.encoder.layer.11.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.17.output.dense.weight', 'base_model.encoder.layer.21.attention.self.value.weight', 'base_model.encoder.layer.4.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.4.output.LayerNorm.weight', 'base_model.encoder.layer.19.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.17.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.7.attention.self.value.weight', 'base_model.encoder.layer.1.attention.output.dense.weight', 'base_model.encoder.layer.11.output.dense.bias', 'base_model.encoder.layer.4.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.20.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.15.attention.output.dense.weight', 'base_model.encoder.layer.23.output.LayerNorm.weight', 'base_model.encoder.layer.16.output.LayerNorm.weight', 'base_model.encoder.layer.22.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.1.attention.self.key.weight', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.0.output.LayerNorm.bias', 'base_model.encoder.layer.22.attention.self.query.bias', 'base_model.encoder.layer.10.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.14.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.21.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.2.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.8.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.18.output.dense.bias', 'base_model.encoder.layer.18.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.20.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.6.attention.output.LayerNorm.bias', 'base_model.encoder.layer.9.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.19.intermediate.dense.weight', 'base_model.encoder.layer.8.attention.self.query.weight', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.3.output.dense.bias', 'base_model.encoder.layer.16.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.19.attention.self.value.weight', 'base_model.encoder.layer.16.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.12.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.8.attention.output.LayerNorm.bias', 'base_model.encoder.layer.0.output.dense.bias', 'base_model.encoder.layer.0.attention.self.value.weight', 'base_model.encoder.layer.8.output.dense.weight', 'base_model.encoder.layer.19.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.6.output.LayerNorm.bias', 'base_model.encoder.layer.6.output.LayerNorm.weight', 'base_model.encoder.layer.15.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.10.attention.self.value.bias', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.14.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.21.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.4.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.9.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.14.attention.output.LayerNorm.weight', 'base_model.encoder.layer.16.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.14.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.20.attention.self.key.bias', 'base_model.encoder.layer.17.attention.output.dense.weight', 'base_model.encoder.layer.11.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.20.attention.output.dense.bias', 'base_model.encoder.layer.17.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.23.attention.self.query.bias', 'base_model.encoder.layer.0.attention.self.value.bias', 'base_model.encoder.layer.0.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.3.attention.output.LayerNorm.weight', 'base_model.encoder.layer.11.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.12.attention.self.value.bias', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.2.output.dense.bias', 'base_model.encoder.layer.11.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.1.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.5.attention.output.dense.weight', 'base_model.encoder.layer.7.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.10.output.LayerNorm.bias', 'base_model.encoder.layer.10.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.2.attention.output.dense.bias', 'base_model.encoder.layer.5.output.LayerNorm.bias', 'base_model.encoder.layer.12.attention.self.key.bias', 'base_model.encoder.layer.5.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.2.attention.output.LayerNorm.weight', 'base_model.encoder.layer.5.output.dense.weight', 'base_model.encoder.layer.8.attention.self.value.weight', 'base_model.encoder.layer.12.attention.self.value.weight', 'base_model.encoder.layer.22.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.14.attention.output.dense.bias', 'base_model.encoder.layer.8.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.14.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.6.attention.self.key.bias', 'base_model.encoder.layer.7.output.LayerNorm.bias', 'base_model.encoder.layer.1.attention.output.dense.bias', 'base_model.encoder.layer.6.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.6.output.dense.weight', 'base_model.encoder.layer.7.attention.output.dense.weight', 'base_model.encoder.layer.10.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.10.attention.output.LayerNorm.bias', 'base_model.encoder.layer.21.attention.output.dense.bias', 'base_model.encoder.layer.4.intermediate.dense.weight', 'base_model.encoder.layer.16.output.dense.bias', 'base_model.encoder.layer.22.attention.self.query.weight', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.5.attention.self.value.bias', 'base_model.encoder.layer.11.attention.output.dense.weight', 'base_model.encoder.layer.4.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.23.attention.output.LayerNorm.bias', 'base_model.embeddings.token_type_embeddings.weight', 'base_model.encoder.layer.15.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.0.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.4.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.21.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.14.intermediate.dense.bias', 'base_model.encoder.layer.4.output.dense.weight', 'base_model.encoder.layer.3.intermediate.dense.bias', 'base_model.encoder.layer.21.attention.output.LayerNorm.bias', 'base_model.encoder.layer.10.output.dense.weight', 'base_model.encoder.layer.13.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.8.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.22.intermediate.dense.bias', 'base_model.encoder.layer.17.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.16.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.12.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.18.attention.self.value.weight', 'base_model.encoder.layer.22.attention.self.key.weight', 'base_model.encoder.layer.21.attention.self.key.bias', 'base_model.encoder.layer.9.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.10.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.2.attention.self.query.bias', 'base_model.encoder.layer.8.attention.self.query.bias', 'base_model.encoder.layer.2.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.8.output.dense.bias', 'base_model.encoder.layer.1.attention.output.LayerNorm.bias', 'base_model.encoder.layer.12.attention.output.dense.bias', 'base_model.encoder.layer.6.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.15.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.3.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.4.attention.self.query.weight', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.7.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.20.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.1.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.7.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.10.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.10.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.13.attention.output.LayerNorm.bias', 'base_model.encoder.layer.15.output.dense.bias', 'base_model.encoder.layer.17.output.dense.bias', 'base_model.encoder.layer.2.attention.output.LayerNorm.bias', 'base_model.encoder.layer.21.output.dense.weight', 'base_model.encoder.layer.6.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.8.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.3.attention.self.query.bias', 'base_model.encoder.layer.21.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.22.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.5.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.21.intermediate.dense.bias', 'base_model.encoder.layer.6.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.9.attention.output.dense.bias', 'base_model.encoder.layer.9.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.7.output.dense.bias', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.1.output.dense.weight', 'base_model.encoder.layer.3.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.5.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.9.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.1.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.9.attention.self.query.bias', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.8.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.0.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.3.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.13.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.17.intermediate.dense.bias', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.9.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.11.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.23.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.21.output.dense.bias', 'base_model.encoder.layer.16.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.1.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.13.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.23.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.4.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.8.attention.output.dense.bias', 'base_model.encoder.layer.23.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.6.intermediate.dense.weight', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.2.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.4.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.1.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.8.output.LayerNorm.bias', 'base_model.encoder.layer.2.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.22.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.20.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.0.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.3.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.7.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.15.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.7.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.20.attention.self.key.weight', 'base_model.encoder.layer.13.attention.output.dense.weight', 'base_model.encoder.layer.11.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.17.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.10.output.dense.bias', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.15.output.LayerNorm.bias', 'base_model.encoder.layer.17.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.22.output.LayerNorm.bias', 'base_model.encoder.layer.13.attention.output.dense.bias', 'base_model.encoder.layer.17.intermediate.dense.weight', 'base_model.encoder.layer.4.attention.output.dense.bias', 'base_model.encoder.layer.4.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.9.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.2.output.dense.weight', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.23.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.4.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.18.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.0.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.7.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.18.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.21.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.1.attention.self.query.bias', 'base_model.encoder.layer.1.intermediate.dense.bias', 'base_model.encoder.layer.12.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.14.attention.self.query.bias', 'base_model.encoder.layer.8.attention.self.key.weight', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.8.intermediate.dense.weight', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.7.attention.output.LayerNorm.weight', 'base_model.encoder.layer.2.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.23.attention.self.key.bias', 'base_model.encoder.layer.16.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.23.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.6.intermediate.dense.bias', 'base_model.encoder.layer.15.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.11.attention.self.query.bias', 'base_model.encoder.layer.7.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.5.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.11.attention.self.query.weight', 'base_model.encoder.layer.18.attention.output.LayerNorm.weight', 'base_model.encoder.layer.15.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.12.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.4.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.14.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.12.output.dense.weight', 'base_model.encoder.layer.8.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.7.attention.output.LayerNorm.bias', 'base_model.encoder.layer.3.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.12.attention.output.dense.weight', 'base_model.encoder.layer.19.output.dense.weight', 'base_model.encoder.layer.11.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.18.intermediate.dense.bias', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.21.output.LayerNorm.weight', 'base_model.encoder.layer.3.attention.output.LayerNorm.bias', 'base_model.encoder.layer.3.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.20.attention.self.value.bias', 'base_model.encoder.layer.6.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.11.output.dense.weight', 'base_model.encoder.layer.0.output.LayerNorm.weight', 'base_model.encoder.layer.23.attention.output.dense.weight', 'base_model.encoder.layer.1.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.6.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.9.output.LayerNorm.weight', 'base_model.encoder.layer.19.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.4.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.19.attention.output.LayerNorm.weight', 'base_model.encoder.layer.18.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.19.attention.self.value.bias', 'base_model.encoder.layer.17.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.18.output.dense.weight', 'base_model.encoder.layer.1.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.1.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.13.output.LayerNorm.bias', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.4.attention.self.key.bias', 'base_model.encoder.layer.9.output.adapters.ts.adapter_up.weight', 'base_model.embeddings.word_embeddings.weight', 'base_model.encoder.layer.9.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.8.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.10.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.11.attention.output.LayerNorm.weight', 'base_model.encoder.layer.14.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.5.attention.output.LayerNorm.weight', 'base_model.encoder.layer.16.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.14.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.12.attention.self.key.weight', 'base_model.encoder.layer.13.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.23.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.6.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.5.output.LayerNorm.weight', 'base_model.encoder.layer.18.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.7.attention.self.query.bias', 'base_model.encoder.layer.20.output.dense.weight', 'base_model.encoder.layer.8.output.LayerNorm.weight', 'base_model.encoder.layer.13.attention.output.LayerNorm.weight', 'base_model.encoder.layer.4.intermediate.dense.bias', 'base_model.encoder.layer.4.attention.self.value.bias', 'base_model.encoder.layer.22.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.9.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.10.intermediate.dense.weight', 'base_model.encoder.layer.12.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.15.intermediate.dense.bias', 'base_model.encoder.layer.20.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.22.attention.output.dense.weight', 'base_model.encoder.layer.7.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.8.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.16.attention.output.LayerNorm.weight', 'base_model.encoder.layer.17.attention.self.key.weight', 'base_model.encoder.layer.2.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.6.attention.self.value.weight', 'base_model.encoder.layer.11.attention.self.value.bias', 'base_model.encoder.layer.4.attention.self.value.weight', 'base_model.encoder.layer.7.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.19.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.9.attention.self.key.weight', 'base_model.encoder.layer.19.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.14.intermediate.dense.weight', 'base_model.encoder.layer.14.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.19.attention.self.query.weight', 'base_model.encoder.layer.19.attention.output.dense.bias', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.18.output.adapters.tp.adapter_down.0.weight', 'qa_outputs.bias', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.5.attention.self.value.weight', 'base_model.encoder.layer.5.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.11.attention.output.LayerNorm.bias', 'base_model.encoder.layer.0.intermediate.dense.weight', 'base_model.encoder.layer.4.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.11.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.9.intermediate.dense.bias', 'base_model.encoder.layer.5.intermediate.dense.weight', 'base_model.encoder.layer.16.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.5.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.10.intermediate.dense.bias', 'base_model.encoder.layer.18.intermediate.dense.weight', 'base_model.encoder.layer.1.intermediate.dense.weight', 'base_model.encoder.layer.4.output.LayerNorm.bias', 'base_model.encoder.layer.1.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.14.attention.self.key.bias', 'base_model.encoder.layer.13.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.17.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.16.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.20.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.14.attention.self.key.weight', 'base_model.encoder.layer.10.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.2.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.4.attention.output.LayerNorm.weight', 'base_model.encoder.layer.11.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.15.attention.self.query.weight', 'base_model.encoder.layer.22.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.9.attention.self.query.weight', 'base_model.encoder.layer.15.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.21.attention.self.query.bias', 'base_model.encoder.layer.0.attention.output.dense.weight', 'base_model.encoder.layer.3.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.5.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.16.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.20.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.13.attention.self.value.weight', 'base_model.encoder.layer.10.attention.output.dense.bias', 'base_model.encoder.layer.20.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.12.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.11.intermediate.dense.weight', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.17.output.LayerNorm.bias', 'base_model.encoder.layer.15.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.14.output.LayerNorm.weight', 'base_model.encoder.layer.2.intermediate.dense.bias', 'base_model.encoder.layer.13.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.15.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.19.intermediate.dense.bias', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.11.attention.self.key.weight', 'base_model.encoder.layer.15.attention.output.dense.bias', 'base_model.encoder.layer.7.intermediate.dense.bias', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.3.attention.output.dense.bias', 'base_model.encoder.layer.19.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.20.attention.self.query.weight', 'base_model.encoder.layer.11.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.15.attention.output.LayerNorm.bias', 'base_model.encoder.layer.9.attention.self.key.bias', 'base_model.encoder.layer.21.attention.output.dense.weight', 'base_model.encoder.layer.23.intermediate.dense.bias', 'base_model.encoder.layer.15.output.LayerNorm.weight', 'base_model.encoder.layer.9.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.12.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.23.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.0.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.3.output.LayerNorm.bias', 'base_model.encoder.layer.2.attention.self.value.bias', 'base_model.encoder.layer.3.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.8.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.7.output.dense.weight', 'base_model.encoder.layer.2.attention.self.value.weight', 'base_model.encoder.layer.11.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.16.intermediate.dense.weight', 'base_model.encoder.layer.23.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.16.attention.self.query.weight', 'base_model.encoder.layer.8.intermediate.dense.bias', 'base_model.encoder.layer.23.attention.output.dense.bias', 'base_model.encoder.layer.8.attention.self.value.bias', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.22.output.LayerNorm.weight', 'base_model.encoder.layer.23.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.22.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.14.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.10.attention.self.value.weight', 'base_model.encoder.layer.4.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.0.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.12.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.0.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.16.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.23.attention.self.key.weight', 'base_model.encoder.layer.0.attention.output.dense.bias', 'base_model.encoder.layer.22.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.3.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.13.attention.self.query.weight', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.2.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.9.output.LayerNorm.bias', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.13.attention.self.key.bias', 'base_model.encoder.layer.15.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.17.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.16.attention.self.value.weight', 'base_model.encoder.layer.20.attention.output.LayerNorm.weight', 'base_model.encoder.layer.22.intermediate.dense.weight', 'base_model.encoder.layer.12.attention.output.LayerNorm.bias', 'base_model.encoder.layer.23.output.dense.weight', 'base_model.encoder.layer.14.output.dense.bias', 'base_model.encoder.layer.8.attention.self.key.bias', 'base_model.encoder.layer.19.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.18.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.5.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.3.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.8.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.16.attention.self.value.bias', 'base_model.encoder.layer.17.attention.output.dense.bias', 'base_model.encoder.layer.11.attention.output.dense.bias', 'base_model.encoder.layer.8.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.22.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.5.attention.output.dense.bias', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.5.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.2.attention.self.key.weight', 'base_model.encoder.layer.9.output.dense.weight', 'base_model.encoder.layer.13.output.LayerNorm.weight', 'base_model.encoder.layer.17.attention.self.query.weight', 'base_model.encoder.layer.22.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.11.intermediate.dense.bias', 'base_model.encoder.layer.21.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.2.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.16.attention.output.dense.weight', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.1.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.19.output.dense.bias', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.19.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.5.attention.self.key.bias', 'base_model.encoder.layer.1.output.dense.bias', 'base_model.encoder.layer.16.attention.self.query.bias', 'base_model.encoder.layer.13.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.16.attention.self.key.weight', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.3.intermediate.dense.weight', 'base_model.encoder.layer.8.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.10.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.3.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.15.attention.self.key.weight', 'base_model.encoder.layer.3.attention.self.key.bias', 'base_model.encoder.layer.6.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.21.attention.self.value.bias', 'base_model.encoder.layer.23.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.3.attention.output.dense.weight', 'base_model.encoder.layer.10.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.6.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.23.attention.self.value.weight', 'base_model.encoder.layer.2.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.23.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.10.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.1.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.13.attention.self.key.weight', 'base_model.encoder.layer.23.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.14.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.11.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.20.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.22.attention.output.LayerNorm.bias', 'base_model.encoder.layer.21.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.23.output.LayerNorm.bias', 'base_model.encoder.layer.4.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.12.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.16.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.22.attention.self.key.bias', 'base_model.encoder.layer.12.output.dense.bias', 'base_model.encoder.layer.19.output.LayerNorm.weight', 'base_model.encoder.layer.4.output.dense.bias', 'base_model.encoder.layer.18.attention.self.key.bias', 'base_model.encoder.layer.5.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.9.output.dense.bias', 'base_model.encoder.layer.10.attention.self.key.bias', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.23.attention.output.LayerNorm.weight', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.2.output.LayerNorm.weight', 'base_model.encoder.layer.15.attention.self.value.weight', 'base_model.encoder.layer.5.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.6.attention.self.query.weight', 'base_model.encoder.layer.6.attention.output.LayerNorm.weight', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.11.attention.self.key.bias']
- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of XLMRobertaModel were not initialized from the model checkpoint at /cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//squad/xlm-KG_LR8e-6_EPOCH2.0_maxlen384_batchsize4_gradacc4 and are newly initialized: ['encoder.layer.11.attention.output.dense.weight', 'encoder.layer.5.attention.output.dense.weight', 'encoder.layer.12.output.dense.weight', 'encoder.layer.12.attention.output.LayerNorm.bias', 'pooler.dense.weight', 'encoder.layer.3.attention.self.key.bias', 'encoder.layer.7.attention.self.key.bias', 'encoder.layer.21.attention.self.value.weight', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.20.intermediate.dense.bias', 'encoder.layer.13.intermediate.dense.bias', 'encoder.layer.5.attention.self.query.weight', 'encoder.layer.18.output.dense.weight', 'encoder.layer.0.attention.self.query.weight', 'encoder.layer.17.output.dense.bias', 'encoder.layer.22.attention.self.value.bias', 'encoder.layer.21.output.LayerNorm.bias', 'encoder.layer.10.attention.self.query.weight', 'encoder.layer.13.attention.self.query.bias', 'encoder.layer.14.intermediate.dense.bias', 'encoder.layer.5.attention.self.value.weight', 'encoder.layer.5.attention.self.key.bias', 'encoder.layer.17.attention.output.dense.weight', 'encoder.layer.15.attention.self.value.weight', 'encoder.layer.16.intermediate.dense.bias', 'encoder.layer.14.intermediate.dense.weight', 'embeddings.word_embeddings.weight', 'encoder.layer.23.output.dense.bias', 'encoder.layer.11.attention.output.LayerNorm.weight', 'encoder.layer.23.output.dense.weight', 'encoder.layer.8.attention.self.key.bias', 'encoder.layer.17.intermediate.dense.weight', 'encoder.layer.23.attention.self.key.weight', 'encoder.layer.11.output.LayerNorm.weight', 'encoder.layer.19.attention.self.query.weight', 'encoder.layer.7.output.LayerNorm.bias', 'encoder.layer.9.attention.self.key.bias', 'encoder.layer.22.attention.output.LayerNorm.weight', 'encoder.layer.19.intermediate.dense.bias', 'encoder.layer.14.attention.self.query.weight', 'encoder.layer.19.attention.output.LayerNorm.bias', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.12.attention.self.value.weight', 'encoder.layer.8.attention.self.value.bias', 'encoder.layer.1.attention.output.dense.bias', 'encoder.layer.7.output.LayerNorm.weight', 'encoder.layer.15.attention.output.LayerNorm.bias', 'encoder.layer.23.attention.output.dense.bias', 'pooler.dense.bias', 'encoder.layer.3.attention.output.dense.bias', 'encoder.layer.23.attention.self.query.weight', 'encoder.layer.5.output.LayerNorm.bias', 'encoder.layer.21.attention.self.value.bias', 'encoder.layer.12.attention.output.dense.bias', 'encoder.layer.1.attention.output.LayerNorm.weight', 'encoder.layer.18.attention.self.key.bias', 'embeddings.LayerNorm.weight', 'encoder.layer.14.attention.self.value.bias', 'encoder.layer.23.intermediate.dense.weight', 'encoder.layer.15.intermediate.dense.bias', 'encoder.layer.0.attention.self.value.bias', 'encoder.layer.22.output.LayerNorm.weight', 'encoder.layer.1.attention.self.key.bias', 'encoder.layer.8.attention.output.dense.weight', 'encoder.layer.23.attention.output.LayerNorm.bias', 'encoder.layer.0.output.dense.weight', 'encoder.layer.11.attention.self.query.weight', 'encoder.layer.7.output.dense.bias', 'encoder.layer.2.attention.self.query.weight', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.14.attention.output.LayerNorm.bias', 'encoder.layer.9.attention.self.query.weight', 'encoder.layer.10.output.LayerNorm.bias', 'encoder.layer.13.attention.self.value.bias', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.5.attention.self.key.weight', 'encoder.layer.8.attention.self.value.weight', 'encoder.layer.12.attention.output.LayerNorm.weight', 'encoder.layer.10.attention.self.value.bias', 'encoder.layer.16.attention.self.key.weight', 'encoder.layer.13.attention.output.dense.bias', 'encoder.layer.22.attention.self.key.weight', 'encoder.layer.12.attention.output.dense.weight', 'encoder.layer.15.attention.self.query.bias', 'encoder.layer.12.attention.self.query.weight', 'encoder.layer.23.attention.self.query.bias', 'encoder.layer.20.attention.self.query.weight', 'encoder.layer.21.attention.self.key.weight', 'encoder.layer.6.attention.self.key.weight', 'encoder.layer.0.attention.self.value.weight', 'encoder.layer.10.output.LayerNorm.weight', 'encoder.layer.21.output.dense.bias', 'encoder.layer.7.attention.output.dense.weight', 'encoder.layer.9.attention.output.dense.bias', 'encoder.layer.18.attention.output.dense.bias', 'encoder.layer.11.attention.self.key.weight', 'encoder.layer.16.output.LayerNorm.weight', 'encoder.layer.21.intermediate.dense.weight', 'encoder.layer.21.attention.output.LayerNorm.weight', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.2.attention.self.value.bias', 'encoder.layer.2.attention.output.dense.weight', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.14.attention.self.key.bias', 'encoder.layer.13.attention.self.query.weight', 'encoder.layer.2.output.dense.weight', 'encoder.layer.3.attention.self.query.bias', 'encoder.layer.6.output.LayerNorm.bias', 'encoder.layer.22.attention.output.LayerNorm.bias', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.11.output.dense.bias', 'encoder.layer.23.attention.output.LayerNorm.weight', 'encoder.layer.10.attention.output.dense.weight', 'encoder.layer.20.attention.self.value.weight', 'encoder.layer.8.output.LayerNorm.weight', 'encoder.layer.8.output.dense.weight', 'encoder.layer.20.attention.self.key.weight', 'encoder.layer.23.attention.self.value.bias', 'encoder.layer.8.output.LayerNorm.bias', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.20.output.LayerNorm.bias', 'encoder.layer.11.attention.self.key.bias', 'encoder.layer.19.output.LayerNorm.weight', 'encoder.layer.2.attention.self.query.bias', 'encoder.layer.13.output.dense.weight', 'encoder.layer.14.attention.self.key.weight', 'encoder.layer.9.attention.output.dense.weight', 'encoder.layer.6.attention.self.key.bias', 'encoder.layer.16.attention.self.value.weight', 'encoder.layer.9.attention.output.LayerNorm.weight', 'encoder.layer.10.attention.output.LayerNorm.bias', 'encoder.layer.1.attention.self.query.weight', 'encoder.layer.17.output.LayerNorm.bias', 'encoder.layer.23.attention.self.key.bias', 'encoder.layer.10.attention.output.dense.bias', 'encoder.layer.23.attention.self.value.weight', 'encoder.layer.6.attention.output.dense.bias', 'encoder.layer.19.attention.self.value.weight', 'encoder.layer.0.attention.output.dense.weight', 'encoder.layer.1.attention.self.value.bias', 'encoder.layer.11.attention.output.dense.bias', 'encoder.layer.9.output.LayerNorm.bias', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.15.intermediate.dense.weight', 'encoder.layer.19.attention.output.dense.bias', 'encoder.layer.12.attention.self.key.bias', 'encoder.layer.12.output.LayerNorm.bias', 'encoder.layer.18.attention.output.LayerNorm.weight', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.13.output.dense.bias', 'encoder.layer.20.output.dense.weight', 'encoder.layer.11.attention.self.query.bias', 'encoder.layer.17.output.LayerNorm.weight', 'encoder.layer.16.output.dense.weight', 'encoder.layer.18.attention.output.dense.weight', 'encoder.layer.8.attention.output.LayerNorm.weight', 'encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.layer.15.attention.output.dense.weight', 'encoder.layer.20.attention.output.LayerNorm.weight', 'encoder.layer.11.output.LayerNorm.bias', 'encoder.layer.4.attention.output.dense.weight', 'encoder.layer.16.attention.output.LayerNorm.weight', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.5.output.dense.weight', 'encoder.layer.22.output.dense.bias', 'encoder.layer.22.intermediate.dense.bias', 'encoder.layer.20.attention.output.dense.weight', 'encoder.layer.20.attention.self.key.bias', 'encoder.layer.21.output.LayerNorm.weight', 'encoder.layer.4.attention.output.dense.bias', 'encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.layer.22.attention.output.dense.weight', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.8.attention.output.dense.bias', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.2.attention.self.key.bias', 'encoder.layer.6.attention.output.LayerNorm.weight', 'encoder.layer.9.attention.self.key.weight', 'encoder.layer.8.attention.self.query.weight', 'encoder.layer.16.attention.self.value.bias', 'encoder.layer.4.attention.self.value.weight', 'encoder.layer.9.attention.self.query.bias', 'encoder.layer.19.intermediate.dense.weight', 'encoder.layer.17.attention.output.dense.bias', 'encoder.layer.4.output.dense.bias', 'encoder.layer.18.output.dense.bias', 'encoder.layer.20.output.LayerNorm.weight', 'encoder.layer.21.intermediate.dense.bias', 'encoder.layer.5.attention.output.dense.bias', 'encoder.layer.18.output.LayerNorm.weight', 'encoder.layer.21.attention.self.query.bias', 'encoder.layer.15.output.dense.bias', 'encoder.layer.12.attention.self.value.bias', 'encoder.layer.16.attention.self.query.weight', 'encoder.layer.13.output.LayerNorm.weight', 'encoder.layer.1.attention.self.key.weight', 'encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.layer.2.output.dense.bias', 'encoder.layer.13.attention.output.LayerNorm.weight', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.10.attention.self.query.bias', 'encoder.layer.14.output.dense.bias', 'encoder.layer.17.attention.self.value.weight', 'encoder.layer.18.attention.self.value.bias', 'encoder.layer.18.intermediate.dense.bias', 'encoder.layer.19.attention.output.LayerNorm.weight', 'encoder.layer.23.output.LayerNorm.weight', 'encoder.layer.22.attention.self.value.weight', 'encoder.layer.6.attention.self.query.bias', 'encoder.layer.23.intermediate.dense.bias', 'encoder.layer.1.output.dense.weight', 'encoder.layer.22.attention.self.query.bias', 'encoder.layer.10.attention.self.key.bias', 'encoder.layer.6.attention.self.query.weight', 'encoder.layer.15.attention.self.value.bias', 'encoder.layer.3.attention.self.value.bias', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.19.attention.self.key.bias', 'encoder.layer.22.output.LayerNorm.bias', 'encoder.layer.18.intermediate.dense.weight', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.10.output.dense.bias', 'encoder.layer.3.output.dense.weight', 'encoder.layer.5.attention.output.LayerNorm.weight', 'embeddings.token_type_embeddings.weight', 'encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.layer.7.attention.output.LayerNorm.weight', 'encoder.layer.4.output.dense.weight', 'encoder.layer.5.attention.self.query.bias', 'encoder.layer.0.attention.self.key.bias', 'encoder.layer.21.attention.self.query.weight', 'encoder.layer.9.output.LayerNorm.weight', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.21.attention.output.dense.weight', 'encoder.layer.15.attention.output.dense.bias', 'encoder.layer.13.output.LayerNorm.bias', 'embeddings.LayerNorm.bias', 'encoder.layer.13.attention.self.key.weight', 'encoder.layer.9.attention.output.LayerNorm.bias', 'encoder.layer.18.attention.self.query.weight', 'encoder.layer.18.attention.self.key.weight', 'encoder.layer.17.attention.self.key.weight', 'encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.7.attention.self.query.bias', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.7.attention.output.LayerNorm.bias', 'encoder.layer.4.attention.output.LayerNorm.bias', 'encoder.layer.9.output.dense.weight', 'encoder.layer.3.attention.self.value.weight', 'encoder.layer.16.attention.output.LayerNorm.bias', 'encoder.layer.11.attention.self.value.bias', 'encoder.layer.21.attention.output.dense.bias', 'encoder.layer.12.intermediate.dense.bias', 'encoder.layer.17.attention.output.LayerNorm.bias', 'encoder.layer.19.attention.self.key.weight', 'encoder.layer.0.attention.output.LayerNorm.weight', 'encoder.layer.2.attention.output.dense.bias', 'encoder.layer.0.attention.output.dense.bias', 'encoder.layer.22.intermediate.dense.weight', 'encoder.layer.18.attention.self.value.weight', 'embeddings.position_embeddings.weight', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.11.attention.self.value.weight', 'encoder.layer.15.attention.self.key.weight', 'encoder.layer.7.output.dense.weight', 'encoder.layer.21.output.dense.weight', 'encoder.layer.22.attention.output.dense.bias', 'encoder.layer.20.attention.output.dense.bias', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.13.attention.output.dense.weight', 'encoder.layer.10.attention.output.LayerNorm.weight', 'encoder.layer.14.attention.output.dense.weight', 'encoder.layer.3.output.dense.bias', 'encoder.layer.4.attention.self.key.weight', 'encoder.layer.22.attention.self.query.weight', 'encoder.layer.1.attention.output.dense.weight', 'encoder.layer.13.attention.self.value.weight', 'encoder.layer.18.attention.self.query.bias', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.1.attention.self.value.weight', 'encoder.layer.11.output.dense.weight', 'encoder.layer.17.output.dense.weight', 'encoder.layer.15.output.LayerNorm.bias', 'encoder.layer.19.attention.self.value.bias', 'encoder.layer.23.output.LayerNorm.bias', 'encoder.layer.16.attention.output.dense.weight', 'encoder.layer.4.attention.self.query.weight', 'encoder.layer.12.attention.self.query.bias', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.5.attention.self.value.bias', 'encoder.layer.20.output.dense.bias', 'encoder.layer.8.output.dense.bias', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.17.attention.self.value.bias', 'encoder.layer.2.attention.self.value.weight', 'encoder.layer.20.attention.self.value.bias', 'encoder.layer.12.output.dense.bias', 'encoder.layer.14.output.dense.weight', 'encoder.layer.13.attention.self.key.bias', 'encoder.layer.12.output.LayerNorm.weight', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.22.output.dense.weight', 'encoder.layer.16.attention.output.dense.bias', 'encoder.layer.12.attention.self.key.weight', 'encoder.layer.7.attention.self.key.weight', 'encoder.layer.0.output.dense.bias', 'encoder.layer.6.attention.self.value.bias', 'encoder.layer.9.attention.self.value.weight', 'encoder.layer.20.intermediate.dense.weight', 'encoder.layer.16.intermediate.dense.weight', 'encoder.layer.8.attention.output.LayerNorm.bias', 'encoder.layer.15.attention.self.query.weight', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.16.attention.self.key.bias', 'encoder.layer.14.output.LayerNorm.weight', 'encoder.layer.21.attention.self.key.bias', 'encoder.layer.17.attention.self.query.weight', 'encoder.layer.17.attention.self.query.bias', 'encoder.layer.21.attention.output.LayerNorm.bias', 'encoder.layer.10.output.dense.weight', 'encoder.layer.15.output.dense.weight', 'encoder.layer.10.attention.self.key.weight', 'encoder.layer.19.output.LayerNorm.bias', 'encoder.layer.6.output.dense.weight', 'encoder.layer.7.attention.output.dense.bias', 'encoder.layer.7.attention.self.query.weight', 'encoder.layer.19.attention.self.query.bias', 'encoder.layer.14.output.LayerNorm.bias', 'encoder.layer.19.attention.output.dense.weight', 'encoder.layer.20.attention.self.query.bias', 'encoder.layer.18.attention.output.LayerNorm.bias', 'encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.layer.6.output.dense.bias', 'encoder.layer.13.intermediate.dense.weight', 'encoder.layer.3.attention.self.query.weight', 'encoder.layer.14.attention.self.query.bias', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.9.output.dense.bias', 'encoder.layer.16.output.dense.bias', 'encoder.layer.22.attention.self.key.bias', 'encoder.layer.16.attention.self.query.bias', 'encoder.layer.4.attention.self.key.bias', 'encoder.layer.9.attention.self.value.bias', 'encoder.layer.4.attention.output.LayerNorm.weight', 'encoder.layer.7.intermediate.dense.bias', 'encoder.layer.19.output.dense.bias', 'encoder.layer.10.intermediate.dense.weight', 'encoder.layer.14.attention.output.LayerNorm.weight', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.5.output.dense.bias', 'encoder.layer.7.attention.self.value.bias', 'encoder.layer.2.attention.self.key.weight', 'encoder.layer.18.output.LayerNorm.bias', 'encoder.layer.15.output.LayerNorm.weight', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.8.attention.self.key.weight', 'encoder.layer.10.attention.self.value.weight', 'encoder.layer.3.attention.self.key.weight', 'encoder.layer.1.output.dense.bias', 'encoder.layer.4.attention.self.value.bias', 'encoder.layer.15.attention.output.LayerNorm.weight', 'encoder.layer.16.output.LayerNorm.bias', 'encoder.layer.19.output.dense.weight', 'encoder.layer.17.attention.self.key.bias', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.14.attention.self.value.weight', 'encoder.layer.17.attention.output.LayerNorm.weight', 'encoder.layer.17.intermediate.dense.bias', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.4.attention.self.query.bias', 'encoder.layer.14.attention.output.dense.bias', 'encoder.layer.1.attention.self.query.bias', 'encoder.layer.0.attention.self.query.bias', 'encoder.layer.2.attention.output.LayerNorm.weight', 'encoder.layer.6.attention.output.LayerNorm.bias', 'encoder.layer.15.attention.self.key.bias', 'encoder.layer.6.attention.self.value.weight', 'encoder.layer.20.attention.output.LayerNorm.bias', 'encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.layer.7.attention.self.value.weight', 'encoder.layer.8.attention.self.query.bias', 'encoder.layer.12.intermediate.dense.weight', 'encoder.layer.0.attention.self.key.weight', 'encoder.layer.6.attention.output.dense.weight', 'encoder.layer.3.attention.output.dense.weight', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.13.attention.output.LayerNorm.bias', 'encoder.layer.23.attention.output.dense.weight', 'encoder.layer.2.attention.output.LayerNorm.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Overwriting existing adapter 'ep'.
Overwriting existing adapter 'tp'.
Overwriting existing adapter 'es'.
Overwriting existing adapter 'ts'.
Overwriting existing adapter fusion module 'ep,tp,es,ts'
05/09/2022 20:01:53 - INFO - __main__ -   Creating features from dataset file at .
/cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//squad/xlm-KG_LR8e-6_EPOCH2.0_maxlen384_batchsize4_gradacc4
XLMConfig {
  "architectures": [
    "XLMRobertaForMaskedLM"
  ],
  "asm": false,
  "attention_dropout": 0.1,
  "attention_probs_dropout_prob": 0.1,
  "bos_index": 0,
  "bos_token_id": 0,
  "causal": false,
  "dropout": 0.1,
  "emb_dim": 1024,
  "embed_init_std": 0.02209708691207961,
  "end_n_top": 5,
  "eos_index": 1,
  "eos_token_id": 2,
  "gelu_activation": true,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "init_std": 0.02,
  "initializer_range": 0.02,
  "intermediate_size": 4096,
  "is_encoder": true,
  "lang_id": 0,
  "layer_norm_eps": 1e-05,
  "mask_index": 5,
  "mask_token_id": 0,
  "max_position_embeddings": 514,
  "model_type": "xlm",
  "n_heads": 16,
  "n_langs": 1,
  "n_layers": 24,
  "output_past": true,
  "pad_index": 2,
  "pad_token_id": 1,
  "sinusoidal_embeddings": false,
  "start_n_top": 5,
  "summary_activation": null,
  "summary_first_dropout": 0.1,
  "summary_proj_to_labels": true,
  "summary_type": "first",
  "summary_use_proj": true,
  "transformers_version": "4.17.0",
  "type_vocab_size": 1,
  "unk_index": 3,
  "use_lang_emb": false,
  "vocab_size": 250002
}

  0%|          | 0/48 [00:00<?, ?it/s] 33%|███▎      | 16/48 [00:00<00:00, 127.17it/s] 60%|██████    | 29/48 [00:00<00:00, 109.18it/s] 85%|████████▌ | 41/48 [00:00<00:00, 111.06it/s]100%|██████████| 48/48 [00:00<00:00, 116.74it/s]
convert squad examples to features:   0%|          | 0/1190 [00:00<?, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.
convert squad examples to features:   0%|          | 1/1190 [00:00<02:50,  6.96it/s]convert squad examples to features:   5%|▌         | 65/1190 [00:00<00:05, 222.35it/s]convert squad examples to features:   8%|▊         | 97/1190 [00:00<00:04, 248.48it/s]convert squad examples to features:  14%|█▎        | 161/1190 [00:00<00:03, 286.63it/s]convert squad examples to features:  19%|█▉        | 225/1190 [00:00<00:03, 314.95it/s]convert squad examples to features:  22%|██▏       | 257/1190 [00:00<00:03, 295.86it/s]convert squad examples to features:  24%|██▍       | 289/1190 [00:01<00:03, 289.42it/s]convert squad examples to features:  27%|██▋       | 321/1190 [00:01<00:03, 278.48it/s]convert squad examples to features:  32%|███▏      | 385/1190 [00:01<00:04, 188.08it/s]convert squad examples to features:  35%|███▌      | 417/1190 [00:01<00:03, 201.37it/s]convert squad examples to features:  38%|███▊      | 449/1190 [00:01<00:03, 211.84it/s]convert squad examples to features:  40%|████      | 481/1190 [00:02<00:03, 224.04it/s]convert squad examples to features:  43%|████▎     | 513/1190 [00:02<00:02, 234.45it/s]convert squad examples to features:  46%|████▌     | 545/1190 [00:02<00:02, 223.98it/s]convert squad examples to features:  48%|████▊     | 577/1190 [00:02<00:02, 240.78it/s]convert squad examples to features:  51%|█████     | 609/1190 [00:02<00:02, 229.84it/s]convert squad examples to features:  54%|█████▍    | 641/1190 [00:02<00:02, 223.85it/s]convert squad examples to features:  57%|█████▋    | 673/1190 [00:02<00:02, 219.36it/s]convert squad examples to features:  59%|█████▉    | 705/1190 [00:03<00:02, 221.79it/s]convert squad examples to features:  62%|██████▏   | 737/1190 [00:03<00:01, 237.80it/s]convert squad examples to features:  67%|██████▋   | 801/1190 [00:03<00:01, 276.84it/s]convert squad examples to features:  70%|███████   | 833/1190 [00:03<00:01, 247.86it/s]convert squad examples to features:  73%|███████▎  | 865/1190 [00:03<00:01, 254.67it/s]convert squad examples to features:  75%|███████▌  | 897/1190 [00:03<00:01, 243.99it/s]convert squad examples to features:  78%|███████▊  | 929/1190 [00:03<00:01, 250.59it/s]convert squad examples to features:  81%|████████  | 961/1190 [00:04<00:00, 254.12it/s]convert squad examples to features:  83%|████████▎ | 993/1190 [00:04<00:00, 256.27it/s]convert squad examples to features:  86%|████████▌ | 1025/1190 [00:04<00:00, 270.66it/s]convert squad examples to features:  92%|█████████▏| 1089/1190 [00:04<00:00, 303.96it/s]convert squad examples to features:  94%|█████████▍| 1121/1190 [00:04<00:00, 298.77it/s]convert squad examples to features:  97%|█████████▋| 1153/1190 [00:04<00:00, 286.05it/s]convert squad examples to features: 100%|██████████| 1190/1190 [00:04<00:00, 256.03it/s]/cluster/project/sachan/yifan/softwares/anaconda/anaconda3/envs/xfactr/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2272: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

add example index and unique id:   0%|          | 0/1190 [00:00<?, ?it/s]add example index and unique id: 100%|██████████| 1190/1190 [00:00<00:00, 845826.43it/s]
05/09/2022 20:01:58 - INFO - __main__ -   Saving features into cached file ./cached_xquad.tr.json_xlm-KG_LR8e-6_EPOCH2.0_maxlen384_batchsize4_gradacc4_384_tr
05/09/2022 20:01:59 - INFO - __main__ -   ***** Running evaluation  *****
05/09/2022 20:01:59 - INFO - __main__ -     Num examples = 1274
05/09/2022 20:01:59 - INFO - __main__ -     Batch size = 8
Evaluating:   0%|          | 0/160 [00:00<?, ?it/s]Evaluating:   1%|          | 1/160 [00:00<02:14,  1.18it/s]Evaluating:   1%|▏         | 2/160 [00:01<01:28,  1.79it/s]Evaluating:   2%|▏         | 3/160 [00:01<01:12,  2.15it/s]Evaluating:   2%|▎         | 4/160 [00:01<01:05,  2.37it/s]Evaluating:   3%|▎         | 5/160 [00:02<01:01,  2.52it/s]Evaluating:   4%|▍         | 6/160 [00:02<00:58,  2.62it/s]Evaluating:   4%|▍         | 7/160 [00:02<00:57,  2.68it/s]Evaluating:   5%|▌         | 8/160 [00:03<00:55,  2.72it/s]Evaluating:   6%|▌         | 9/160 [00:03<00:55,  2.74it/s]Evaluating:   6%|▋         | 10/160 [00:04<00:54,  2.75it/s]Evaluating:   7%|▋         | 11/160 [00:04<00:53,  2.77it/s]Evaluating:   8%|▊         | 12/160 [00:04<00:53,  2.78it/s]Evaluating:   8%|▊         | 13/160 [00:05<00:52,  2.78it/s]Evaluating:   9%|▉         | 14/160 [00:05<00:52,  2.79it/s]Evaluating:   9%|▉         | 15/160 [00:05<00:51,  2.80it/s]Evaluating:  10%|█         | 16/160 [00:06<00:51,  2.79it/s]Evaluating:  11%|█         | 17/160 [00:06<00:51,  2.78it/s]Evaluating:  11%|█▏        | 18/160 [00:06<00:50,  2.79it/s]Evaluating:  12%|█▏        | 19/160 [00:07<00:50,  2.79it/s]Evaluating:  12%|█▎        | 20/160 [00:07<00:49,  2.80it/s]Evaluating:  13%|█▎        | 21/160 [00:07<00:49,  2.81it/s]Evaluating:  14%|█▍        | 22/160 [00:08<00:48,  2.82it/s]Evaluating:  14%|█▍        | 23/160 [00:08<00:48,  2.82it/s]Evaluating:  15%|█▌        | 24/160 [00:09<00:49,  2.77it/s]Evaluating:  16%|█▌        | 25/160 [00:09<00:48,  2.79it/s]Evaluating:  16%|█▋        | 26/160 [00:09<00:49,  2.71it/s]Evaluating:  17%|█▋        | 27/160 [00:10<00:48,  2.75it/s]Evaluating:  18%|█▊        | 28/160 [00:10<00:47,  2.76it/s]Evaluating:  18%|█▊        | 29/160 [00:10<00:48,  2.71it/s]Evaluating:  19%|█▉        | 30/160 [00:11<00:47,  2.72it/s]Evaluating:  19%|█▉        | 31/160 [00:11<00:47,  2.69it/s]Evaluating:  20%|██        | 32/160 [00:12<00:47,  2.69it/s]Evaluating:  21%|██        | 33/160 [00:12<00:46,  2.71it/s]Evaluating:  21%|██▏       | 34/160 [00:12<00:46,  2.72it/s]Evaluating:  22%|██▏       | 35/160 [00:13<00:45,  2.74it/s]Evaluating:  22%|██▎       | 36/160 [00:13<00:45,  2.75it/s]Evaluating:  23%|██▎       | 37/160 [00:13<00:44,  2.76it/s]Evaluating:  24%|██▍       | 38/160 [00:14<00:43,  2.77it/s]Evaluating:  24%|██▍       | 39/160 [00:14<00:43,  2.77it/s]Evaluating:  25%|██▌       | 40/160 [00:14<00:43,  2.76it/s]Evaluating:  26%|██▌       | 41/160 [00:15<00:43,  2.76it/s]Evaluating:  26%|██▋       | 42/160 [00:15<00:42,  2.77it/s]Evaluating:  27%|██▋       | 43/160 [00:15<00:42,  2.78it/s]Evaluating:  28%|██▊       | 44/160 [00:16<00:41,  2.78it/s]Evaluating:  28%|██▊       | 45/160 [00:16<00:41,  2.79it/s]Evaluating:  29%|██▉       | 46/160 [00:17<00:40,  2.79it/s]Evaluating:  29%|██▉       | 47/160 [00:17<00:40,  2.79it/s]Evaluating:  30%|███       | 48/160 [00:17<00:40,  2.80it/s]Evaluating:  31%|███       | 49/160 [00:18<00:39,  2.80it/s]Evaluating:  31%|███▏      | 50/160 [00:18<00:39,  2.80it/s]Evaluating:  32%|███▏      | 51/160 [00:18<00:39,  2.79it/s]Evaluating:  32%|███▎      | 52/160 [00:19<00:38,  2.78it/s]Evaluating:  33%|███▎      | 53/160 [00:19<00:38,  2.78it/s]Evaluating:  34%|███▍      | 54/160 [00:19<00:38,  2.75it/s]Evaluating:  34%|███▍      | 55/160 [00:20<00:38,  2.75it/s]Evaluating:  35%|███▌      | 56/160 [00:20<00:37,  2.76it/s]Evaluating:  36%|███▌      | 57/160 [00:21<00:37,  2.76it/s]Evaluating:  36%|███▋      | 58/160 [00:21<00:37,  2.75it/s]Evaluating:  37%|███▋      | 59/160 [00:21<00:36,  2.76it/s]Evaluating:  38%|███▊      | 60/160 [00:22<00:36,  2.77it/s]Evaluating:  38%|███▊      | 61/160 [00:22<00:35,  2.76it/s]Evaluating:  39%|███▉      | 62/160 [00:22<00:35,  2.76it/s]Evaluating:  39%|███▉      | 63/160 [00:23<00:35,  2.76it/s]Evaluating:  40%|████      | 64/160 [00:23<00:34,  2.76it/s]Evaluating:  41%|████      | 65/160 [00:23<00:34,  2.76it/s]Evaluating:  41%|████▏     | 66/160 [00:24<00:34,  2.76it/s]Evaluating:  42%|████▏     | 67/160 [00:24<00:33,  2.77it/s]Evaluating:  42%|████▎     | 68/160 [00:25<00:33,  2.77it/s]Evaluating:  43%|████▎     | 69/160 [00:25<00:32,  2.77it/s]Evaluating:  44%|████▍     | 70/160 [00:25<00:32,  2.77it/s]Evaluating:  44%|████▍     | 71/160 [00:26<00:32,  2.77it/s]Evaluating:  45%|████▌     | 72/160 [00:26<00:31,  2.78it/s]Evaluating:  46%|████▌     | 73/160 [00:26<00:31,  2.78it/s]Evaluating:  46%|████▋     | 74/160 [00:27<00:30,  2.78it/s]Evaluating:  47%|████▋     | 75/160 [00:27<00:30,  2.78it/s]Evaluating:  48%|████▊     | 76/160 [00:27<00:30,  2.78it/s]Evaluating:  48%|████▊     | 77/160 [00:28<00:29,  2.77it/s]Evaluating:  49%|████▉     | 78/160 [00:28<00:29,  2.78it/s]Evaluating:  49%|████▉     | 79/160 [00:28<00:29,  2.78it/s]Evaluating:  50%|█████     | 80/160 [00:29<00:28,  2.77it/s]Evaluating:  51%|█████     | 81/160 [00:29<00:28,  2.78it/s]Evaluating:  51%|█████▏    | 82/160 [00:30<00:28,  2.78it/s]Evaluating:  52%|█████▏    | 83/160 [00:30<00:27,  2.76it/s]Evaluating:  52%|█████▎    | 84/160 [00:30<00:27,  2.76it/s]Evaluating:  53%|█████▎    | 85/160 [00:31<00:27,  2.76it/s]Evaluating:  54%|█████▍    | 86/160 [00:31<00:26,  2.77it/s]Evaluating:  54%|█████▍    | 87/160 [00:31<00:26,  2.77it/s]Evaluating:  55%|█████▌    | 88/160 [00:32<00:25,  2.77it/s]Evaluating:  56%|█████▌    | 89/160 [00:32<00:25,  2.76it/s]Evaluating:  56%|█████▋    | 90/160 [00:32<00:25,  2.76it/s]Evaluating:  57%|█████▋    | 91/160 [00:33<00:24,  2.76it/s]Evaluating:  57%|█████▊    | 92/160 [00:33<00:24,  2.77it/s]Evaluating:  58%|█████▊    | 93/160 [00:34<00:24,  2.77it/s]Evaluating:  59%|█████▉    | 94/160 [00:34<00:23,  2.76it/s]Evaluating:  59%|█████▉    | 95/160 [00:34<00:23,  2.77it/s]Evaluating:  60%|██████    | 96/160 [00:35<00:23,  2.77it/s]Evaluating:  61%|██████    | 97/160 [00:35<00:22,  2.77it/s]Evaluating:  61%|██████▏   | 98/160 [00:35<00:22,  2.77it/s]Evaluating:  62%|██████▏   | 99/160 [00:36<00:22,  2.77it/s]Evaluating:  62%|██████▎   | 100/160 [00:36<00:21,  2.78it/s]Evaluating:  63%|██████▎   | 101/160 [00:36<00:21,  2.76it/s]Evaluating:  64%|██████▍   | 102/160 [00:37<00:21,  2.75it/s]Evaluating:  64%|██████▍   | 103/160 [00:37<00:20,  2.76it/s]Evaluating:  65%|██████▌   | 104/160 [00:38<00:20,  2.69it/s]Evaluating:  66%|██████▌   | 105/160 [00:38<00:20,  2.69it/s]Evaluating:  66%|██████▋   | 106/160 [00:38<00:19,  2.72it/s]Evaluating:  67%|██████▋   | 107/160 [00:39<00:19,  2.73it/s]Evaluating:  68%|██████▊   | 108/160 [00:39<00:18,  2.74it/s]Evaluating:  68%|██████▊   | 109/160 [00:39<00:18,  2.75it/s]Evaluating:  69%|██████▉   | 110/160 [00:40<00:18,  2.74it/s]Evaluating:  69%|██████▉   | 111/160 [00:40<00:17,  2.75it/s]Evaluating:  70%|███████   | 112/160 [00:40<00:17,  2.74it/s]Evaluating:  71%|███████   | 113/160 [00:41<00:17,  2.73it/s]Evaluating:  71%|███████▏  | 114/160 [00:41<00:16,  2.73it/s]Evaluating:  72%|███████▏  | 115/160 [00:42<00:16,  2.72it/s]Evaluating:  72%|███████▎  | 116/160 [00:42<00:16,  2.71it/s]Evaluating:  73%|███████▎  | 117/160 [00:42<00:15,  2.71it/s]Evaluating:  74%|███████▍  | 118/160 [00:43<00:15,  2.69it/s]Evaluating:  74%|███████▍  | 119/160 [00:43<00:15,  2.71it/s]Evaluating:  75%|███████▌  | 120/160 [00:43<00:14,  2.73it/s]Evaluating:  76%|███████▌  | 121/160 [00:44<00:14,  2.74it/s]Evaluating:  76%|███████▋  | 122/160 [00:44<00:13,  2.74it/s]Evaluating:  77%|███████▋  | 123/160 [00:45<00:13,  2.71it/s]Evaluating:  78%|███████▊  | 124/160 [00:45<00:13,  2.70it/s]Evaluating:  78%|███████▊  | 125/160 [00:45<00:12,  2.72it/s]Evaluating:  79%|███████▉  | 126/160 [00:46<00:12,  2.72it/s]Evaluating:  79%|███████▉  | 127/160 [00:46<00:12,  2.73it/s]Evaluating:  80%|████████  | 128/160 [00:46<00:11,  2.74it/s]Evaluating:  81%|████████  | 129/160 [00:47<00:11,  2.75it/s]Evaluating:  81%|████████▏ | 130/160 [00:47<00:10,  2.76it/s]Evaluating:  82%|████████▏ | 131/160 [00:47<00:10,  2.74it/s]Evaluating:  82%|████████▎ | 132/160 [00:48<00:10,  2.71it/s]Evaluating:  83%|████████▎ | 133/160 [00:48<00:09,  2.73it/s]Evaluating:  84%|████████▍ | 134/160 [00:49<00:09,  2.73it/s]Evaluating:  84%|████████▍ | 135/160 [00:49<00:09,  2.74it/s]Evaluating:  85%|████████▌ | 136/160 [00:49<00:08,  2.75it/s]Evaluating:  86%|████████▌ | 137/160 [00:50<00:08,  2.76it/s]Evaluating:  86%|████████▋ | 138/160 [00:50<00:08,  2.74it/s]Evaluating:  87%|████████▋ | 139/160 [00:50<00:07,  2.75it/s]Evaluating:  88%|████████▊ | 140/160 [00:51<00:07,  2.75it/s]Evaluating:  88%|████████▊ | 141/160 [00:51<00:06,  2.76it/s]Evaluating:  89%|████████▉ | 142/160 [00:51<00:06,  2.76it/s]Evaluating:  89%|████████▉ | 143/160 [00:52<00:06,  2.75it/s]Evaluating:  90%|█████████ | 144/160 [00:52<00:05,  2.75it/s]Evaluating:  91%|█████████ | 145/160 [00:53<00:05,  2.75it/s]Evaluating:  91%|█████████▏| 146/160 [00:53<00:05,  2.75it/s]Evaluating:  92%|█████████▏| 147/160 [00:53<00:04,  2.76it/s]Evaluating:  92%|█████████▎| 148/160 [00:54<00:04,  2.76it/s]Evaluating:  93%|█████████▎| 149/160 [00:54<00:03,  2.77it/s]Evaluating:  94%|█████████▍| 150/160 [00:54<00:03,  2.77it/s]Evaluating:  94%|█████████▍| 151/160 [00:55<00:03,  2.77it/s]Evaluating:  95%|█████████▌| 152/160 [00:55<00:02,  2.76it/s]Evaluating:  96%|█████████▌| 153/160 [00:55<00:02,  2.75it/s]Evaluating:  96%|█████████▋| 154/160 [00:56<00:02,  2.75it/s]Evaluating:  97%|█████████▋| 155/160 [00:56<00:01,  2.74it/s]Evaluating:  98%|█████████▊| 156/160 [00:57<00:01,  2.74it/s]Evaluating:  98%|█████████▊| 157/160 [00:57<00:01,  2.75it/s]Evaluating:  99%|█████████▉| 158/160 [00:57<00:00,  2.74it/s]Evaluating:  99%|█████████▉| 159/160 [00:58<00:00,  2.75it/s]Evaluating: 100%|██████████| 160/160 [00:58<00:00,  3.51it/s]Evaluating: 100%|██████████| 160/160 [00:58<00:00,  2.75it/s]
05/09/2022 20:02:58 - INFO - __main__ -     Evaluation done in total 58.202902 secs (0.045685 sec per example)
05/09/2022 20:03:01 - INFO - __main__ -   Results: {'exact': 58.90756302521008, 'f1': 74.86142620445315, 'total': 1190, 'HasAns_exact': 58.90756302521008, 'HasAns_f1': 74.86142620445315, 'HasAns_total': 1190, 'best_exact': 58.90756302521008, 'best_exact_thresh': 0.0, 'best_f1': 74.86142620445315, 'best_f1_thresh': 0.0}
  ar 
2022-05-09 20:03:08.082940: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0
05/09/2022 20:03:13 - WARNING - __main__ -   Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, 16-bits training: False
You are using a model of type xlm-roberta to instantiate a model of type xlm. This is not supported for all configurations of models and can yield errors.
Some weights of the model checkpoint at /cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//squad/xlm-KG_LR8e-6_EPOCH2.0_maxlen384_batchsize4_gradacc4 were not used when initializing XLMRobertaModel: ['base_model.encoder.layer.4.intermediate.dense.weight', 'base_model.encoder.layer.17.output.dense.weight', 'base_model.encoder.layer.10.output.dense.bias', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.12.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.22.attention.self.value.bias', 'base_model.encoder.layer.16.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.21.attention.output.LayerNorm.weight', 'base_model.encoder.layer.15.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.18.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.22.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.17.attention.output.dense.weight', 'base_model.encoder.layer.15.attention.self.query.bias', 'base_model.encoder.layer.14.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.6.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.13.attention.self.value.bias', 'base_model.encoder.layer.7.output.LayerNorm.weight', 'base_model.encoder.layer.11.output.dense.weight', 'base_model.encoder.layer.5.attention.output.LayerNorm.weight', 'base_model.encoder.layer.6.attention.self.key.bias', 'base_model.encoder.layer.15.intermediate.dense.bias', 'base_model.encoder.layer.22.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.1.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.8.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.12.attention.output.dense.bias', 'base_model.embeddings.LayerNorm.weight', 'base_model.encoder.layer.13.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.9.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.5.attention.self.query.bias', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.8.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.9.attention.output.LayerNorm.weight', 'base_model.encoder.layer.0.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.4.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.14.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.1.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.13.attention.self.key.bias', 'base_model.encoder.layer.18.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.14.output.dense.weight', 'base_model.encoder.layer.5.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.20.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.9.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.8.attention.output.dense.bias', 'base_model.encoder.layer.13.output.LayerNorm.weight', 'base_model.encoder.layer.19.intermediate.dense.weight', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.18.intermediate.dense.bias', 'base_model.encoder.layer.16.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.8.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.20.attention.self.key.bias', 'base_model.encoder.layer.0.output.dense.weight', 'base_model.encoder.layer.5.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.12.attention.self.query.weight', 'base_model.encoder.layer.15.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.15.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.16.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.7.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.20.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.2.attention.self.key.bias', 'base_model.encoder.layer.13.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.8.attention.self.query.bias', 'base_model.encoder.layer.1.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.19.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.15.attention.self.query.weight', 'base_model.encoder.layer.21.attention.self.key.weight', 'base_model.encoder.layer.14.attention.output.dense.weight', 'base_model.encoder.layer.23.attention.self.value.bias', 'base_model.encoder.layer.19.attention.output.LayerNorm.bias', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.2.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.11.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.9.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.19.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.5.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.12.attention.self.key.bias', 'base_model.encoder.layer.16.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.20.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.3.output.dense.bias', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.22.attention.self.query.weight', 'base_model.encoder.layer.8.output.LayerNorm.weight', 'base_model.encoder.layer.21.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.22.attention.self.key.bias', 'base_model.encoder.layer.3.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.pooler.dense.bias', 'base_model.encoder.layer.5.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.17.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.6.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.19.attention.self.query.weight', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.6.output.LayerNorm.weight', 'base_model.encoder.layer.16.output.dense.bias', 'base_model.encoder.layer.11.intermediate.dense.weight', 'base_model.encoder.layer.17.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.18.output.dense.weight', 'base_model.encoder.layer.12.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.23.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.4.attention.output.dense.bias', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.8.attention.self.value.bias', 'base_model.encoder.layer.6.attention.self.key.weight', 'base_model.encoder.layer.4.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.3.intermediate.dense.weight', 'base_model.encoder.layer.8.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.10.output.LayerNorm.bias', 'base_model.encoder.layer.20.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.4.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.16.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.20.output.dense.bias', 'base_model.encoder.layer.19.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.10.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.5.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.4.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.5.attention.output.LayerNorm.bias', 'base_model.encoder.layer.21.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.20.intermediate.dense.bias', 'base_model.encoder.layer.14.attention.output.dense.bias', 'base_model.encoder.layer.8.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.3.attention.output.dense.weight', 'base_model.encoder.layer.0.output.dense.bias', 'base_model.encoder.layer.1.attention.output.dense.weight', 'base_model.encoder.layer.2.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.7.output.LayerNorm.bias', 'base_model.encoder.layer.1.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.1.attention.output.LayerNorm.weight', 'base_model.encoder.layer.9.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.7.attention.self.query.weight', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.15.attention.output.LayerNorm.bias', 'base_model.encoder.layer.20.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.21.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.20.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.22.attention.output.dense.weight', 'base_model.encoder.layer.21.attention.self.value.bias', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.6.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.15.attention.self.key.bias', 'base_model.encoder.layer.21.attention.output.dense.bias', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.3.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.22.output.LayerNorm.weight', 'base_model.encoder.layer.12.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.10.attention.self.key.weight', 'base_model.encoder.layer.5.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.12.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.14.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.16.attention.self.query.weight', 'qa_outputs.weight', 'base_model.encoder.layer.4.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.17.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.14.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.21.output.LayerNorm.bias', 'base_model.encoder.layer.13.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.18.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.18.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.8.attention.output.LayerNorm.weight', 'base_model.encoder.layer.9.output.dense.bias', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.2.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.4.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.4.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.8.attention.self.key.weight', 'base_model.encoder.layer.11.attention.output.dense.weight', 'base_model.encoder.layer.16.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.8.attention.self.key.bias', 'base_model.encoder.layer.19.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.11.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.12.output.dense.bias', 'base_model.encoder.layer.6.output.LayerNorm.bias', 'base_model.encoder.layer.13.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.0.attention.self.value.weight', 'base_model.encoder.layer.1.output.LayerNorm.weight', 'base_model.encoder.layer.8.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.7.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.5.attention.self.query.weight', 'base_model.encoder.layer.21.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.0.attention.self.query.bias', 'base_model.encoder.layer.22.attention.output.LayerNorm.weight', 'base_model.encoder.layer.9.attention.self.key.bias', 'base_model.encoder.layer.8.intermediate.dense.bias', 'base_model.encoder.layer.11.attention.self.key.weight', 'base_model.encoder.layer.11.output.LayerNorm.bias', 'base_model.encoder.layer.3.attention.self.value.bias', 'base_model.encoder.layer.18.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.22.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.10.attention.self.key.bias', 'base_model.encoder.layer.2.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.0.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.2.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.6.output.dense.weight', 'base_model.encoder.layer.18.attention.self.query.weight', 'base_model.encoder.layer.1.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.3.output.dense.weight', 'base_model.encoder.layer.13.intermediate.dense.weight', 'base_model.encoder.layer.8.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.13.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.4.attention.self.key.weight', 'base_model.encoder.layer.12.attention.output.LayerNorm.bias', 'base_model.encoder.layer.5.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.8.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.19.attention.output.dense.bias', 'base_model.encoder.layer.1.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.19.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.11.attention.output.dense.bias', 'base_model.encoder.layer.8.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.7.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.5.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.17.attention.self.value.bias', 'base_model.encoder.layer.20.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.20.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.19.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.2.attention.output.LayerNorm.bias', 'base_model.encoder.layer.10.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.4.output.LayerNorm.weight', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'qa_outputs.bias', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.16.attention.output.dense.bias', 'base_model.encoder.layer.11.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.22.output.dense.bias', 'base_model.encoder.layer.4.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.1.output.dense.bias', 'base_model.encoder.layer.5.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.14.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.18.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.7.intermediate.dense.bias', 'base_model.encoder.layer.10.attention.output.LayerNorm.weight', 'base_model.encoder.layer.12.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.21.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.17.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.15.output.LayerNorm.bias', 'base_model.encoder.layer.16.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.2.output.LayerNorm.bias', 'base_model.encoder.layer.20.output.LayerNorm.bias', 'base_model.encoder.layer.19.attention.output.dense.weight', 'base_model.encoder.layer.22.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.0.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.22.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.14.attention.self.value.weight', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.21.attention.self.query.weight', 'base_model.encoder.layer.0.intermediate.dense.bias', 'base_model.encoder.layer.7.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.16.output.LayerNorm.bias', 'base_model.encoder.layer.17.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.13.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.5.attention.self.value.bias', 'base_model.encoder.layer.6.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.22.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.1.intermediate.dense.bias', 'base_model.encoder.layer.13.attention.output.LayerNorm.weight', 'base_model.encoder.layer.0.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.21.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.7.output.dense.bias', 'base_model.encoder.layer.0.attention.output.dense.weight', 'base_model.encoder.layer.7.attention.self.query.bias', 'base_model.encoder.layer.16.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.21.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.14.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.23.output.dense.weight', 'base_model.encoder.layer.10.output.dense.weight', 'base_model.encoder.layer.2.attention.self.query.weight', 'base_model.encoder.layer.14.intermediate.dense.bias', 'base_model.encoder.layer.0.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.11.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.17.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.5.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.19.attention.output.LayerNorm.weight', 'base_model.encoder.layer.6.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.22.attention.output.LayerNorm.bias', 'base_model.encoder.layer.3.output.LayerNorm.weight', 'base_model.encoder.layer.21.attention.self.value.weight', 'base_model.encoder.layer.4.output.LayerNorm.bias', 'base_model.encoder.layer.17.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.19.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.11.output.dense.bias', 'base_model.encoder.layer.7.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.7.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.18.intermediate.dense.weight', 'base_model.encoder.layer.0.output.LayerNorm.bias', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.18.output.LayerNorm.bias', 'base_model.encoder.layer.8.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.16.attention.output.LayerNorm.weight', 'base_model.encoder.layer.0.attention.self.key.weight', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.10.intermediate.dense.bias', 'base_model.encoder.layer.23.output.LayerNorm.bias', 'base_model.encoder.layer.0.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.9.attention.output.LayerNorm.bias', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.6.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.17.intermediate.dense.weight', 'base_model.encoder.layer.15.attention.output.dense.bias', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.2.attention.self.query.bias', 'base_model.encoder.layer.23.attention.output.LayerNorm.weight', 'base_model.encoder.layer.4.attention.self.value.bias', 'base_model.encoder.layer.0.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.14.output.LayerNorm.weight', 'base_model.encoder.layer.21.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.3.attention.self.value.weight', 'base_model.encoder.layer.0.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.11.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.1.attention.self.value.weight', 'base_model.encoder.layer.7.attention.self.value.bias', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.7.attention.self.value.weight', 'base_model.encoder.layer.17.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.21.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.3.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.20.attention.self.key.weight', 'base_model.encoder.layer.1.output.LayerNorm.bias', 'base_model.encoder.layer.21.output.dense.weight', 'base_model.encoder.layer.22.intermediate.dense.bias', 'base_model.encoder.layer.18.attention.self.key.weight', 'base_model.encoder.layer.7.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.7.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.11.attention.output.LayerNorm.bias', 'base_model.encoder.layer.23.attention.self.query.bias', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.10.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.17.attention.self.key.weight', 'base_model.encoder.layer.17.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.6.attention.output.dense.weight', 'base_model.encoder.layer.11.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.3.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.11.attention.self.key.bias', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.23.attention.self.key.bias', 'base_model.encoder.layer.6.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.9.intermediate.dense.bias', 'base_model.encoder.layer.16.attention.self.key.bias', 'base_model.embeddings.position_embeddings.weight', 'base_model.encoder.layer.2.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.17.output.LayerNorm.bias', 'base_model.encoder.layer.19.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.15.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.23.attention.self.query.weight', 'base_model.encoder.layer.6.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.21.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.21.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.0.attention.output.LayerNorm.bias', 'base_model.encoder.layer.7.output.dense.weight', 'base_model.encoder.layer.12.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.15.attention.self.value.weight', 'base_model.encoder.layer.17.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.23.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.3.attention.output.LayerNorm.bias', 'base_model.encoder.layer.18.attention.output.LayerNorm.bias', 'base_model.encoder.layer.3.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.6.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.2.output.dense.weight', 'base_model.encoder.layer.0.attention.output.LayerNorm.weight', 'base_model.encoder.layer.5.intermediate.dense.bias', 'base_model.encoder.layer.13.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.7.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.5.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.18.output.LayerNorm.weight', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.11.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.10.intermediate.dense.weight', 'base_model.encoder.layer.22.attention.self.key.weight', 'base_model.encoder.layer.5.attention.output.dense.weight', 'base_model.encoder.layer.3.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.13.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.3.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.7.output.adapters.ts.adapter_down.0.bias', 'base_model.embeddings.token_type_embeddings.weight', 'base_model.encoder.layer.7.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.11.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.1.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.21.intermediate.dense.bias', 'base_model.encoder.layer.23.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.14.intermediate.dense.weight', 'base_model.encoder.layer.8.output.LayerNorm.bias', 'base_model.encoder.layer.15.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.18.attention.output.LayerNorm.weight', 'base_model.encoder.layer.10.attention.output.LayerNorm.bias', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.10.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.1.attention.self.key.weight', 'base_model.encoder.layer.2.attention.output.LayerNorm.weight', 'base_model.encoder.layer.12.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.14.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.15.output.LayerNorm.weight', 'base_model.encoder.layer.23.intermediate.dense.bias', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.9.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.0.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.12.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.18.attention.self.query.bias', 'base_model.encoder.layer.7.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.7.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.8.attention.self.query.weight', 'base_model.encoder.layer.22.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.5.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.1.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.10.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.22.output.LayerNorm.bias', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.4.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.15.attention.self.value.bias', 'base_model.encoder.layer.2.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.23.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.23.attention.self.value.weight', 'base_model.encoder.layer.22.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.21.output.dense.bias', 'base_model.encoder.layer.23.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.11.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.15.attention.output.LayerNorm.weight', 'base_model.encoder.layer.19.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.1.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.5.output.dense.weight', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.10.attention.self.value.weight', 'base_model.encoder.layer.5.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.2.output.dense.bias', 'base_model.encoder.layer.9.attention.self.query.bias', 'base_model.encoder.layer.19.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.18.attention.self.value.weight', 'base_model.encoder.layer.7.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.18.output.dense.bias', 'base_model.encoder.layer.3.attention.self.query.bias', 'base_model.encoder.layer.10.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.15.attention.self.key.weight', 'base_model.encoder.layer.15.attention.output.dense.weight', 'base_model.encoder.layer.9.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.11.attention.self.value.bias', 'base_model.embeddings.LayerNorm.bias', 'base_model.encoder.layer.5.attention.output.dense.bias', 'base_model.encoder.layer.9.output.LayerNorm.bias', 'base_model.encoder.layer.19.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.23.attention.output.LayerNorm.bias', 'base_model.encoder.layer.1.intermediate.dense.weight', 'base_model.encoder.layer.0.attention.self.query.weight', 'base_model.encoder.layer.11.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.16.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.9.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.18.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.0.output.LayerNorm.weight', 'base_model.encoder.layer.10.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.21.attention.output.LayerNorm.bias', 'base_model.encoder.layer.0.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.18.attention.self.value.bias', 'base_model.encoder.layer.7.intermediate.dense.weight', 'base_model.encoder.layer.8.attention.output.dense.weight', 'base_model.encoder.layer.8.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.14.output.adapters.tp.adapter_up.bias', 'base_model.pooler.dense.weight', 'base_model.encoder.layer.3.intermediate.dense.bias', 'base_model.encoder.layer.13.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.12.output.LayerNorm.bias', 'base_model.encoder.layer.20.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.12.attention.self.query.bias', 'base_model.encoder.layer.6.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.22.attention.self.query.bias', 'base_model.encoder.layer.6.attention.self.value.weight', 'base_model.encoder.layer.14.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.1.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.5.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.22.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.18.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.12.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.17.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.17.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.11.attention.self.query.weight', 'base_model.encoder.layer.3.attention.self.query.weight', 'base_model.encoder.layer.5.attention.self.value.weight', 'base_model.encoder.layer.9.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.19.output.dense.bias', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.6.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.15.output.dense.bias', 'base_model.encoder.layer.2.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.20.attention.output.dense.bias', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.13.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.5.output.LayerNorm.bias', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.19.attention.self.value.bias', 'base_model.encoder.layer.23.attention.output.dense.weight', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.7.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.17.output.dense.bias', 'base_model.encoder.layer.10.attention.output.dense.weight', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.0.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.1.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.14.attention.output.LayerNorm.weight', 'base_model.encoder.layer.7.attention.output.dense.weight', 'base_model.encoder.layer.15.intermediate.dense.weight', 'base_model.encoder.layer.2.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.7.attention.output.LayerNorm.weight', 'base_model.encoder.layer.2.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.21.attention.self.query.bias', 'base_model.encoder.layer.10.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.6.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.14.attention.self.key.weight', 'base_model.encoder.layer.16.output.dense.weight', 'base_model.encoder.layer.1.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.2.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.8.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.16.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.10.attention.output.dense.bias', 'base_model.encoder.layer.12.attention.self.key.weight', 'base_model.encoder.layer.2.attention.output.dense.bias', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.15.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.10.attention.self.value.bias', 'base_model.encoder.layer.15.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.2.intermediate.dense.bias', 'base_model.encoder.layer.6.output.dense.bias', 'base_model.encoder.layer.9.attention.self.value.bias', 'base_model.encoder.layer.16.attention.output.dense.weight', 'base_model.encoder.layer.4.output.dense.weight', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.18.attention.output.dense.weight', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.12.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.13.intermediate.dense.bias', 'base_model.encoder.layer.19.attention.self.key.bias', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.8.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.15.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.0.attention.self.value.bias', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.20.attention.self.value.bias', 'base_model.encoder.layer.22.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.18.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.20.attention.self.value.weight', 'base_model.encoder.layer.8.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.19.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.18.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.10.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.20.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.9.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.14.attention.self.query.bias', 'base_model.encoder.layer.1.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.9.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.6.attention.output.LayerNorm.bias', 'base_model.encoder.layer.13.output.dense.bias', 'base_model.encoder.layer.3.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.3.attention.self.key.bias', 'base_model.encoder.layer.11.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.20.attention.output.dense.weight', 'base_model.encoder.layer.1.attention.self.query.weight', 'base_model.encoder.layer.4.attention.self.key.bias', 'base_model.encoder.layer.12.attention.output.LayerNorm.weight', 'base_model.encoder.layer.17.output.LayerNorm.weight', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.22.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.16.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.4.attention.output.LayerNorm.bias', 'base_model.encoder.layer.9.attention.self.value.weight', 'base_model.encoder.layer.20.output.dense.weight', 'base_model.encoder.layer.2.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.21.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.4.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.4.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.16.attention.self.query.bias', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.13.attention.output.LayerNorm.bias', 'base_model.encoder.layer.22.attention.self.value.weight', 'base_model.encoder.layer.5.attention.self.key.bias', 'base_model.encoder.layer.22.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.22.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.22.output.dense.weight', 'base_model.encoder.layer.17.attention.self.query.weight', 'base_model.encoder.layer.14.attention.self.query.weight', 'base_model.encoder.layer.18.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.14.output.LayerNorm.bias', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.3.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.21.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.9.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.12.attention.output.dense.weight', 'base_model.encoder.layer.18.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.2.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.10.attention.self.query.bias', 'base_model.encoder.layer.19.output.LayerNorm.bias', 'base_model.encoder.layer.6.attention.self.query.bias', 'base_model.encoder.layer.13.output.LayerNorm.bias', 'base_model.encoder.layer.14.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.19.attention.self.key.weight', 'base_model.encoder.layer.8.intermediate.dense.weight', 'base_model.encoder.layer.14.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.3.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.23.intermediate.dense.weight', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.11.attention.self.value.weight', 'base_model.encoder.layer.13.attention.self.value.weight', 'base_model.encoder.layer.15.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.15.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.22.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.22.attention.output.dense.bias', 'base_model.encoder.layer.12.intermediate.dense.bias', 'base_model.encoder.layer.21.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.20.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.14.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.3.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.20.attention.self.query.weight', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.5.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.8.attention.self.value.weight', 'base_model.encoder.layer.4.attention.output.dense.weight', 'base_model.encoder.layer.10.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.15.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.5.output.LayerNorm.weight', 'base_model.encoder.layer.6.intermediate.dense.weight', 'base_model.encoder.layer.4.attention.output.LayerNorm.weight', 'base_model.encoder.layer.16.intermediate.dense.weight', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.17.attention.output.LayerNorm.bias', 'base_model.encoder.layer.18.attention.output.dense.bias', 'base_model.encoder.layer.18.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.21.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.3.attention.output.dense.bias', 'base_model.encoder.layer.3.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.14.attention.self.value.bias', 'base_model.encoder.layer.6.attention.self.value.bias', 'base_model.encoder.layer.16.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.21.output.LayerNorm.weight', 'base_model.encoder.layer.16.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.2.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.13.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.0.intermediate.dense.weight', 'base_model.encoder.layer.11.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.1.attention.self.query.bias', 'base_model.encoder.layer.12.output.dense.weight', 'base_model.encoder.layer.10.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.12.intermediate.dense.weight', 'base_model.encoder.layer.16.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.17.attention.self.key.bias', 'base_model.encoder.layer.21.attention.self.key.bias', 'base_model.encoder.layer.14.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.8.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.16.attention.self.key.weight', 'base_model.encoder.layer.1.output.dense.weight', 'base_model.encoder.layer.2.attention.self.key.weight', 'base_model.encoder.layer.12.attention.self.value.bias', 'base_model.encoder.layer.12.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.9.output.dense.weight', 'base_model.encoder.layer.23.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.4.intermediate.dense.bias', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.7.attention.self.key.weight', 'base_model.encoder.layer.17.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.3.output.adapters.ts.adapter_up.weight', 'base_model.embeddings.position_ids', 'base_model.encoder.layer.3.attention.self.key.weight', 'base_model.encoder.layer.3.output.LayerNorm.bias', 'base_model.encoder.layer.22.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.2.attention.output.dense.weight', 'base_model.encoder.layer.9.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.6.intermediate.dense.bias', 'base_model.embeddings.word_embeddings.weight', 'base_model.encoder.layer.9.attention.output.dense.bias', 'base_model.encoder.layer.10.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.13.output.dense.weight', 'base_model.encoder.layer.20.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.0.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.22.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.11.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.17.intermediate.dense.bias', 'base_model.encoder.layer.18.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.0.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.5.attention.self.key.weight', 'base_model.encoder.layer.20.intermediate.dense.weight', 'base_model.encoder.layer.23.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.15.output.dense.weight', 'base_model.encoder.layer.14.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.7.attention.self.key.bias', 'base_model.encoder.layer.9.attention.output.dense.weight', 'base_model.encoder.layer.10.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.17.attention.self.query.bias', 'base_model.encoder.layer.6.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.4.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.21.attention.output.dense.weight', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.13.attention.self.key.weight', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.13.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.19.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.15.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.14.output.dense.bias', 'base_model.encoder.layer.2.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.10.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.19.attention.self.query.bias', 'base_model.encoder.layer.12.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.6.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.6.attention.self.query.weight', 'base_model.encoder.layer.18.attention.self.key.bias', 'base_model.encoder.layer.1.attention.self.value.bias', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.16.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.16.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.20.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.12.output.LayerNorm.weight', 'base_model.encoder.layer.20.attention.output.LayerNorm.bias', 'base_model.encoder.layer.23.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.11.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.12.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.0.attention.self.key.bias', 'base_model.encoder.layer.0.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.1.attention.self.key.bias', 'base_model.encoder.layer.2.intermediate.dense.weight', 'base_model.encoder.layer.13.attention.self.query.weight', 'base_model.encoder.layer.21.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.19.attention.self.value.weight', 'base_model.encoder.layer.15.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.4.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.7.attention.output.LayerNorm.bias', 'base_model.encoder.layer.9.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.4.attention.self.query.weight', 'base_model.encoder.layer.0.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.11.attention.self.query.bias', 'base_model.encoder.layer.17.attention.output.LayerNorm.weight', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.23.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.4.attention.self.value.weight', 'base_model.encoder.layer.6.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.23.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.5.intermediate.dense.weight', 'base_model.encoder.layer.23.output.dense.bias', 'base_model.encoder.layer.0.attention.output.dense.bias', 'base_model.encoder.layer.10.attention.self.query.weight', 'base_model.encoder.layer.23.attention.self.key.weight', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.18.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.8.output.dense.weight', 'base_model.encoder.layer.3.attention.output.LayerNorm.weight', 'base_model.encoder.layer.20.attention.self.query.bias', 'base_model.encoder.layer.11.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.11.attention.output.LayerNorm.weight', 'base_model.encoder.layer.16.output.LayerNorm.weight', 'base_model.encoder.layer.12.attention.self.value.weight', 'base_model.encoder.layer.16.intermediate.dense.bias', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.1.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.3.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.5.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.6.attention.output.dense.bias', 'base_model.encoder.layer.20.attention.output.LayerNorm.weight', 'base_model.encoder.layer.10.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.16.attention.self.value.weight', 'base_model.encoder.layer.17.attention.output.dense.bias', 'base_model.encoder.layer.23.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.9.attention.self.key.weight', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.23.output.LayerNorm.weight', 'base_model.encoder.layer.9.output.LayerNorm.weight', 'base_model.encoder.layer.23.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.19.output.LayerNorm.weight', 'base_model.encoder.layer.1.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.19.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.22.intermediate.dense.weight', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.7.attention.output.dense.bias', 'base_model.encoder.layer.11.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.4.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.15.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.1.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.17.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.9.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.3.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.20.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.18.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.15.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.17.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.20.output.LayerNorm.weight', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.12.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.8.output.dense.bias', 'base_model.encoder.layer.4.attention.self.query.bias', 'base_model.encoder.layer.2.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.2.attention.self.value.bias', 'base_model.encoder.layer.2.output.LayerNorm.weight', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.15.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.19.intermediate.dense.bias', 'base_model.encoder.layer.19.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.23.attention.output.dense.bias', 'base_model.encoder.layer.4.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.9.attention.self.query.weight', 'base_model.encoder.layer.13.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.13.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.5.output.dense.bias', 'base_model.encoder.layer.13.attention.output.dense.weight', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.20.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.17.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.0.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.11.output.LayerNorm.weight', 'base_model.encoder.layer.1.attention.output.dense.bias', 'base_model.encoder.layer.16.attention.output.LayerNorm.bias', 'base_model.encoder.layer.12.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.10.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.13.attention.self.query.bias', 'base_model.encoder.layer.23.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.14.attention.output.LayerNorm.bias', 'base_model.encoder.layer.23.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.4.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.14.attention.self.key.bias', 'base_model.encoder.layer.2.attention.self.value.weight', 'base_model.encoder.layer.23.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.8.attention.output.LayerNorm.bias', 'base_model.encoder.layer.13.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.3.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.8.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.7.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.11.intermediate.dense.bias', 'base_model.encoder.layer.6.attention.output.LayerNorm.weight', 'base_model.encoder.layer.23.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.17.attention.self.value.weight', 'base_model.encoder.layer.12.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.19.output.dense.weight', 'base_model.encoder.layer.4.output.dense.bias', 'base_model.encoder.layer.14.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.16.attention.self.value.bias', 'base_model.encoder.layer.9.intermediate.dense.weight', 'base_model.encoder.layer.9.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.1.attention.output.LayerNorm.bias', 'base_model.encoder.layer.13.attention.output.dense.bias', 'base_model.encoder.layer.6.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.10.output.LayerNorm.weight', 'base_model.encoder.layer.13.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.14.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.19.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.21.intermediate.dense.weight', 'base_model.encoder.layer.9.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.20.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.query.bias']
- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of XLMRobertaModel were not initialized from the model checkpoint at /cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//squad/xlm-KG_LR8e-6_EPOCH2.0_maxlen384_batchsize4_gradacc4 and are newly initialized: ['encoder.layer.8.attention.self.value.bias', 'encoder.layer.6.attention.self.value.weight', 'encoder.layer.2.output.dense.bias', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.19.attention.output.dense.weight', 'encoder.layer.2.attention.self.value.bias', 'encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.layer.0.attention.self.key.weight', 'encoder.layer.0.attention.self.query.weight', 'encoder.layer.6.attention.output.LayerNorm.weight', 'encoder.layer.10.attention.self.value.weight', 'encoder.layer.18.attention.output.dense.bias', 'encoder.layer.12.intermediate.dense.weight', 'encoder.layer.3.attention.self.query.bias', 'encoder.layer.11.attention.self.key.bias', 'encoder.layer.19.output.dense.bias', 'encoder.layer.19.output.LayerNorm.bias', 'encoder.layer.14.output.dense.bias', 'encoder.layer.23.attention.output.dense.bias', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.13.output.dense.weight', 'encoder.layer.1.attention.self.value.weight', 'encoder.layer.18.attention.self.value.bias', 'encoder.layer.4.output.dense.weight', 'encoder.layer.5.attention.output.dense.bias', 'encoder.layer.7.attention.self.key.weight', 'encoder.layer.5.attention.self.value.bias', 'encoder.layer.5.output.LayerNorm.bias', 'encoder.layer.17.attention.self.query.bias', 'encoder.layer.12.output.LayerNorm.bias', 'encoder.layer.21.attention.output.dense.weight', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.7.attention.output.dense.weight', 'encoder.layer.21.output.LayerNorm.bias', 'encoder.layer.2.attention.self.value.weight', 'encoder.layer.18.attention.output.LayerNorm.weight', 'encoder.layer.6.attention.output.LayerNorm.bias', 'encoder.layer.4.attention.self.value.weight', 'encoder.layer.9.attention.output.dense.bias', 'encoder.layer.23.output.LayerNorm.weight', 'encoder.layer.1.attention.self.query.weight', 'embeddings.position_embeddings.weight', 'encoder.layer.23.intermediate.dense.bias', 'encoder.layer.17.output.dense.weight', 'encoder.layer.15.attention.output.dense.bias', 'encoder.layer.17.attention.self.key.weight', 'encoder.layer.17.intermediate.dense.weight', 'encoder.layer.11.attention.self.key.weight', 'encoder.layer.21.attention.self.key.weight', 'encoder.layer.10.attention.output.LayerNorm.bias', 'encoder.layer.9.attention.self.query.bias', 'embeddings.token_type_embeddings.weight', 'encoder.layer.13.attention.self.value.weight', 'encoder.layer.15.output.dense.bias', 'encoder.layer.15.intermediate.dense.weight', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.8.attention.self.query.weight', 'encoder.layer.15.attention.self.query.bias', 'encoder.layer.20.attention.self.query.weight', 'encoder.layer.12.intermediate.dense.bias', 'encoder.layer.22.intermediate.dense.bias', 'encoder.layer.3.output.dense.weight', 'encoder.layer.7.attention.self.value.bias', 'encoder.layer.18.output.dense.weight', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.14.attention.self.query.bias', 'encoder.layer.10.intermediate.dense.weight', 'encoder.layer.18.attention.self.value.weight', 'encoder.layer.12.attention.output.LayerNorm.bias', 'encoder.layer.3.attention.self.value.bias', 'encoder.layer.16.output.dense.bias', 'encoder.layer.19.attention.output.LayerNorm.weight', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.19.attention.self.query.weight', 'encoder.layer.3.attention.self.key.weight', 'encoder.layer.16.intermediate.dense.weight', 'encoder.layer.23.output.dense.weight', 'encoder.layer.21.intermediate.dense.bias', 'encoder.layer.13.attention.output.LayerNorm.weight', 'encoder.layer.6.attention.self.query.weight', 'encoder.layer.16.attention.self.query.bias', 'encoder.layer.7.output.LayerNorm.bias', 'encoder.layer.23.attention.output.LayerNorm.weight', 'encoder.layer.21.intermediate.dense.weight', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.5.attention.output.dense.weight', 'encoder.layer.22.attention.self.key.weight', 'encoder.layer.20.attention.output.LayerNorm.bias', 'encoder.layer.16.attention.output.dense.bias', 'encoder.layer.20.attention.output.dense.weight', 'encoder.layer.16.output.LayerNorm.bias', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.4.attention.self.value.bias', 'encoder.layer.16.attention.self.value.weight', 'encoder.layer.8.attention.self.value.weight', 'encoder.layer.12.attention.output.dense.bias', 'encoder.layer.21.output.LayerNorm.weight', 'encoder.layer.19.intermediate.dense.weight', 'encoder.layer.8.output.dense.weight', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.22.intermediate.dense.weight', 'encoder.layer.0.output.dense.weight', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.12.attention.self.key.bias', 'encoder.layer.9.attention.self.key.bias', 'encoder.layer.17.attention.output.dense.bias', 'encoder.layer.4.attention.self.key.bias', 'encoder.layer.11.attention.self.value.weight', 'encoder.layer.7.output.dense.weight', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.17.attention.output.dense.weight', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.0.attention.self.value.weight', 'encoder.layer.6.attention.output.dense.bias', 'encoder.layer.9.attention.self.query.weight', 'encoder.layer.1.attention.self.value.bias', 'encoder.layer.7.attention.self.query.weight', 'encoder.layer.14.output.dense.weight', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.19.attention.self.key.bias', 'encoder.layer.19.attention.self.value.bias', 'encoder.layer.13.attention.self.query.bias', 'encoder.layer.18.output.dense.bias', 'encoder.layer.0.attention.output.LayerNorm.weight', 'encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.layer.9.output.LayerNorm.weight', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.0.attention.self.key.bias', 'encoder.layer.13.output.LayerNorm.weight', 'encoder.layer.0.output.dense.bias', 'encoder.layer.2.attention.self.key.weight', 'encoder.layer.13.attention.self.query.weight', 'encoder.layer.14.attention.self.value.bias', 'encoder.layer.0.attention.self.query.bias', 'encoder.layer.6.output.dense.weight', 'encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.17.attention.self.value.weight', 'encoder.layer.11.output.LayerNorm.bias', 'encoder.layer.9.attention.output.LayerNorm.bias', 'encoder.layer.17.output.LayerNorm.bias', 'encoder.layer.14.intermediate.dense.weight', 'encoder.layer.6.attention.self.query.bias', 'encoder.layer.12.attention.output.dense.weight', 'encoder.layer.18.output.LayerNorm.bias', 'encoder.layer.18.intermediate.dense.bias', 'encoder.layer.8.attention.output.LayerNorm.weight', 'encoder.layer.21.attention.output.LayerNorm.bias', 'encoder.layer.8.attention.self.query.bias', 'encoder.layer.16.output.dense.weight', 'encoder.layer.13.output.dense.bias', 'encoder.layer.7.attention.output.dense.bias', 'encoder.layer.10.output.LayerNorm.bias', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.2.attention.self.key.bias', 'encoder.layer.14.attention.output.dense.bias', 'encoder.layer.13.attention.output.dense.bias', 'encoder.layer.4.attention.self.query.weight', 'encoder.layer.8.output.LayerNorm.bias', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.layer.22.attention.self.query.weight', 'encoder.layer.23.intermediate.dense.weight', 'encoder.layer.7.attention.self.query.bias', 'encoder.layer.10.attention.output.dense.weight', 'encoder.layer.5.attention.output.LayerNorm.weight', 'encoder.layer.21.attention.output.LayerNorm.weight', 'encoder.layer.5.attention.self.key.weight', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.20.output.LayerNorm.bias', 'encoder.layer.2.attention.self.query.weight', 'encoder.layer.13.attention.self.key.weight', 'encoder.layer.10.attention.self.query.bias', 'encoder.layer.4.attention.output.LayerNorm.weight', 'encoder.layer.20.intermediate.dense.weight', 'encoder.layer.1.output.dense.weight', 'encoder.layer.1.attention.self.key.weight', 'encoder.layer.5.output.dense.weight', 'encoder.layer.20.output.dense.weight', 'encoder.layer.22.attention.self.value.weight', 'encoder.layer.17.attention.self.key.bias', 'encoder.layer.11.attention.output.dense.weight', 'encoder.layer.10.output.LayerNorm.weight', 'encoder.layer.20.attention.output.LayerNorm.weight', 'encoder.layer.23.output.LayerNorm.bias', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.21.attention.self.query.weight', 'encoder.layer.15.attention.output.dense.weight', 'encoder.layer.3.attention.self.key.bias', 'encoder.layer.12.output.dense.bias', 'encoder.layer.22.output.dense.weight', 'encoder.layer.14.attention.self.key.bias', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.8.attention.self.key.bias', 'encoder.layer.2.attention.output.LayerNorm.bias', 'encoder.layer.9.attention.output.dense.weight', 'encoder.layer.9.attention.self.value.weight', 'encoder.layer.15.attention.self.query.weight', 'encoder.layer.1.attention.output.LayerNorm.weight', 'encoder.layer.8.output.dense.bias', 'encoder.layer.12.attention.self.key.weight', 'encoder.layer.3.attention.output.dense.weight', 'encoder.layer.4.attention.self.key.weight', 'encoder.layer.4.attention.output.dense.bias', 'encoder.layer.10.attention.self.key.weight', 'encoder.layer.0.attention.self.value.bias', 'encoder.layer.11.attention.self.value.bias', 'encoder.layer.16.attention.self.value.bias', 'encoder.layer.6.attention.output.dense.weight', 'encoder.layer.20.attention.self.query.bias', 'encoder.layer.7.attention.self.key.bias', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.6.output.LayerNorm.bias', 'encoder.layer.9.attention.self.value.bias', 'encoder.layer.23.attention.self.value.weight', 'encoder.layer.10.output.dense.bias', 'encoder.layer.13.intermediate.dense.weight', 'encoder.layer.19.attention.output.dense.bias', 'encoder.layer.21.attention.self.value.weight', 'encoder.layer.5.attention.self.query.bias', 'encoder.layer.18.attention.self.query.weight', 'encoder.layer.4.attention.output.LayerNorm.bias', 'embeddings.LayerNorm.weight', 'encoder.layer.5.attention.self.value.weight', 'encoder.layer.18.attention.output.LayerNorm.bias', 'encoder.layer.9.attention.output.LayerNorm.weight', 'encoder.layer.16.attention.output.LayerNorm.weight', 'encoder.layer.10.attention.self.query.weight', 'encoder.layer.12.attention.output.LayerNorm.weight', 'encoder.layer.20.attention.self.key.weight', 'encoder.layer.20.attention.self.value.bias', 'encoder.layer.16.attention.self.query.weight', 'pooler.dense.weight', 'encoder.layer.10.output.dense.weight', 'encoder.layer.2.attention.self.query.bias', 'encoder.layer.19.intermediate.dense.bias', 'encoder.layer.20.attention.self.value.weight', 'encoder.layer.1.output.dense.bias', 'encoder.layer.23.attention.output.LayerNorm.bias', 'encoder.layer.13.attention.self.value.bias', 'encoder.layer.18.attention.self.key.weight', 'embeddings.word_embeddings.weight', 'encoder.layer.21.attention.output.dense.bias', 'encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.layer.12.output.dense.weight', 'encoder.layer.13.attention.output.LayerNorm.bias', 'encoder.layer.7.attention.output.LayerNorm.weight', 'encoder.layer.8.attention.output.dense.bias', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.11.output.dense.bias', 'encoder.layer.8.attention.output.LayerNorm.bias', 'encoder.layer.14.output.LayerNorm.weight', 'encoder.layer.11.attention.self.query.bias', 'encoder.layer.17.attention.output.LayerNorm.bias', 'encoder.layer.2.attention.output.dense.weight', 'encoder.layer.23.output.dense.bias', 'encoder.layer.13.output.LayerNorm.bias', 'encoder.layer.18.attention.output.dense.weight', 'encoder.layer.1.attention.self.key.bias', 'encoder.layer.14.attention.output.LayerNorm.weight', 'encoder.layer.15.attention.output.LayerNorm.bias', 'encoder.layer.6.attention.self.key.weight', 'encoder.layer.3.output.dense.bias', 'encoder.layer.3.attention.self.query.weight', 'encoder.layer.4.output.dense.bias', 'encoder.layer.0.intermediate.dense.bias', 'pooler.dense.bias', 'encoder.layer.14.attention.self.query.weight', 'encoder.layer.17.output.dense.bias', 'encoder.layer.1.attention.self.query.bias', 'encoder.layer.11.output.LayerNorm.weight', 'encoder.layer.19.attention.output.LayerNorm.bias', 'encoder.layer.4.attention.output.dense.weight', 'encoder.layer.23.attention.self.query.weight', 'encoder.layer.22.attention.output.LayerNorm.bias', 'encoder.layer.15.attention.self.key.bias', 'encoder.layer.22.attention.self.key.bias', 'encoder.layer.10.attention.self.key.bias', 'encoder.layer.14.attention.output.LayerNorm.bias', 'encoder.layer.8.attention.output.dense.weight', 'encoder.layer.21.output.dense.bias', 'encoder.layer.1.attention.output.dense.weight', 'encoder.layer.0.attention.output.dense.bias', 'encoder.layer.12.output.LayerNorm.weight', 'encoder.layer.15.output.LayerNorm.weight', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.11.attention.output.LayerNorm.weight', 'encoder.layer.23.attention.output.dense.weight', 'encoder.layer.22.attention.output.dense.bias', 'encoder.layer.5.attention.self.key.bias', 'encoder.layer.19.output.dense.weight', 'encoder.layer.21.attention.self.query.bias', 'encoder.layer.9.output.dense.bias', 'encoder.layer.0.attention.output.dense.weight', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.10.attention.self.value.bias', 'encoder.layer.2.output.dense.weight', 'encoder.layer.14.output.LayerNorm.bias', 'encoder.layer.22.output.LayerNorm.bias', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.layer.18.attention.self.key.bias', 'encoder.layer.22.output.LayerNorm.weight', 'encoder.layer.10.attention.output.dense.bias', 'encoder.layer.14.attention.self.key.weight', 'encoder.layer.4.attention.self.query.bias', 'encoder.layer.6.attention.self.key.bias', 'encoder.layer.23.attention.self.key.bias', 'encoder.layer.18.intermediate.dense.weight', 'encoder.layer.15.attention.output.LayerNorm.weight', 'encoder.layer.18.output.LayerNorm.weight', 'encoder.layer.11.attention.self.query.weight', 'encoder.layer.14.intermediate.dense.bias', 'encoder.layer.7.intermediate.dense.bias', 'encoder.layer.20.output.dense.bias', 'encoder.layer.22.attention.self.value.bias', 'encoder.layer.22.attention.output.dense.weight', 'encoder.layer.22.attention.output.LayerNorm.weight', 'encoder.layer.21.attention.self.value.bias', 'encoder.layer.15.output.LayerNorm.bias', 'encoder.layer.7.attention.self.value.weight', 'encoder.layer.11.attention.output.dense.bias', 'encoder.layer.17.output.LayerNorm.weight', 'encoder.layer.15.intermediate.dense.bias', 'encoder.layer.11.output.dense.weight', 'encoder.layer.1.attention.output.dense.bias', 'encoder.layer.23.attention.self.query.bias', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.16.attention.self.key.bias', 'encoder.layer.6.output.dense.bias', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.8.output.LayerNorm.weight', 'encoder.layer.16.intermediate.dense.bias', 'encoder.layer.7.attention.output.LayerNorm.bias', 'encoder.layer.22.attention.self.query.bias', 'encoder.layer.20.intermediate.dense.bias', 'encoder.layer.21.output.dense.weight', 'encoder.layer.2.attention.output.dense.bias', 'encoder.layer.22.output.dense.bias', 'encoder.layer.19.output.LayerNorm.weight', 'encoder.layer.19.attention.self.key.weight', 'encoder.layer.17.intermediate.dense.bias', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.23.attention.self.value.bias', 'encoder.layer.12.attention.self.value.weight', 'encoder.layer.20.output.LayerNorm.weight', 'encoder.layer.18.attention.self.query.bias', 'encoder.layer.13.intermediate.dense.bias', 'encoder.layer.19.attention.self.query.bias', 'encoder.layer.19.attention.self.value.weight', 'encoder.layer.16.attention.output.LayerNorm.bias', 'encoder.layer.12.attention.self.value.bias', 'encoder.layer.5.attention.self.query.weight', 'encoder.layer.20.attention.output.dense.bias', 'encoder.layer.23.attention.self.key.weight', 'encoder.layer.16.attention.self.key.weight', 'encoder.layer.20.attention.self.key.bias', 'encoder.layer.12.attention.self.query.bias', 'embeddings.LayerNorm.bias', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.15.attention.self.value.weight', 'encoder.layer.13.attention.output.dense.weight', 'encoder.layer.8.attention.self.key.weight', 'encoder.layer.9.attention.self.key.weight', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.14.attention.output.dense.weight', 'encoder.layer.15.attention.self.key.weight', 'encoder.layer.3.attention.output.dense.bias', 'encoder.layer.17.attention.self.value.bias', 'encoder.layer.15.output.dense.weight', 'encoder.layer.2.attention.output.LayerNorm.weight', 'encoder.layer.21.attention.self.key.bias', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.9.output.LayerNorm.bias', 'encoder.layer.17.attention.self.query.weight', 'encoder.layer.16.attention.output.dense.weight', 'encoder.layer.5.output.dense.bias', 'encoder.layer.13.attention.self.key.bias', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.16.output.LayerNorm.weight', 'encoder.layer.6.attention.self.value.bias', 'encoder.layer.12.attention.self.query.weight', 'encoder.layer.3.attention.self.value.weight', 'encoder.layer.9.output.dense.weight', 'encoder.layer.17.attention.output.LayerNorm.weight', 'encoder.layer.15.attention.self.value.bias', 'encoder.layer.7.output.dense.bias', 'encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.layer.7.output.LayerNorm.weight', 'encoder.layer.14.attention.self.value.weight', 'encoder.layer.10.attention.output.LayerNorm.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Overwriting existing adapter 'ep'.
Overwriting existing adapter 'tp'.
Overwriting existing adapter 'es'.
Overwriting existing adapter 'ts'.
Overwriting existing adapter fusion module 'ep,tp,es,ts'
05/09/2022 20:03:35 - INFO - __main__ -   lang2id = None
05/09/2022 20:03:39 - INFO - __main__ -   Training/evaluation parameters Namespace(adam_epsilon=1e-08, cache_dir='', config_name='', data_dir=None, device=device(type='cuda'), do_eval=True, do_lower_case=False, do_train=False, doc_stride=128, eval_all_checkpoints=False, eval_lang='ar', evaluate_during_training=False, fp16=False, fp16_opt_level='O1', gradient_accumulation_steps=1, learning_rate=5e-05, local_rank=-1, logging_steps=50, max_answer_length=30, max_grad_norm=1.0, max_query_length=64, max_seq_length=384, max_steps=-1, model_name='xlm-KG', model_name_or_path='/cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//squad/xlm-KG_LR8e-6_EPOCH2.0_maxlen384_batchsize4_gradacc4', model_type='xlm', modelkg_dir='/cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/adapter/xlmr_adapter', n_best_size=20, n_gpu=1, no_cuda=False, null_score_diff_threshold=0.0, num_train_epochs=3.0, output_dir='/cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//squad/xlm-KG_LR8e-6_EPOCH2.0_maxlen384_batchsize4_gradacc4/predictions/xquad/', overwrite_cache=False, overwrite_output_dir=False, per_gpu_eval_batch_size=8, per_gpu_train_batch_size=8, predict_file='/cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/download//xquad//xquad.ar.json', save_steps=50, seed=42, server_ip='', server_port='', threads=1, tokenizer_name='', train_file=None, train_lang='en', verbose_logging=False, version_2_with_negative=False, warmup_steps=0, weight_decay=0.0)
05/09/2022 20:03:39 - INFO - __main__ -   Loading checkpoint /cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//squad/xlm-KG_LR8e-6_EPOCH2.0_maxlen384_batchsize4_gradacc4 for evaluation
05/09/2022 20:03:39 - INFO - __main__ -   Evaluate the following checkpoints: ['/cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//squad/xlm-KG_LR8e-6_EPOCH2.0_maxlen384_batchsize4_gradacc4']
Some weights of the model checkpoint at /cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//squad/xlm-KG_LR8e-6_EPOCH2.0_maxlen384_batchsize4_gradacc4 were not used when initializing XLMRobertaModel: ['base_model.encoder.layer.4.intermediate.dense.weight', 'base_model.encoder.layer.17.output.dense.weight', 'base_model.encoder.layer.10.output.dense.bias', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.12.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.22.attention.self.value.bias', 'base_model.encoder.layer.16.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.21.attention.output.LayerNorm.weight', 'base_model.encoder.layer.15.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.18.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.22.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.17.attention.output.dense.weight', 'base_model.encoder.layer.15.attention.self.query.bias', 'base_model.encoder.layer.14.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.6.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.13.attention.self.value.bias', 'base_model.encoder.layer.7.output.LayerNorm.weight', 'base_model.encoder.layer.11.output.dense.weight', 'base_model.encoder.layer.5.attention.output.LayerNorm.weight', 'base_model.encoder.layer.6.attention.self.key.bias', 'base_model.encoder.layer.15.intermediate.dense.bias', 'base_model.encoder.layer.22.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.1.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.8.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.12.attention.output.dense.bias', 'base_model.embeddings.LayerNorm.weight', 'base_model.encoder.layer.13.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.9.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.5.attention.self.query.bias', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.8.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.9.attention.output.LayerNorm.weight', 'base_model.encoder.layer.0.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.4.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.14.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.1.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.13.attention.self.key.bias', 'base_model.encoder.layer.18.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.14.output.dense.weight', 'base_model.encoder.layer.5.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.20.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.9.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.8.attention.output.dense.bias', 'base_model.encoder.layer.13.output.LayerNorm.weight', 'base_model.encoder.layer.19.intermediate.dense.weight', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.18.intermediate.dense.bias', 'base_model.encoder.layer.16.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.8.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.20.attention.self.key.bias', 'base_model.encoder.layer.0.output.dense.weight', 'base_model.encoder.layer.5.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.12.attention.self.query.weight', 'base_model.encoder.layer.15.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.15.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.16.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.7.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.20.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.2.attention.self.key.bias', 'base_model.encoder.layer.13.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.8.attention.self.query.bias', 'base_model.encoder.layer.1.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.19.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.15.attention.self.query.weight', 'base_model.encoder.layer.21.attention.self.key.weight', 'base_model.encoder.layer.14.attention.output.dense.weight', 'base_model.encoder.layer.23.attention.self.value.bias', 'base_model.encoder.layer.19.attention.output.LayerNorm.bias', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.2.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.11.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.9.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.19.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.5.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.12.attention.self.key.bias', 'base_model.encoder.layer.16.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.20.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.3.output.dense.bias', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.22.attention.self.query.weight', 'base_model.encoder.layer.8.output.LayerNorm.weight', 'base_model.encoder.layer.21.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.22.attention.self.key.bias', 'base_model.encoder.layer.3.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.pooler.dense.bias', 'base_model.encoder.layer.5.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.17.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.6.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.19.attention.self.query.weight', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.6.output.LayerNorm.weight', 'base_model.encoder.layer.16.output.dense.bias', 'base_model.encoder.layer.11.intermediate.dense.weight', 'base_model.encoder.layer.17.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.18.output.dense.weight', 'base_model.encoder.layer.12.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.23.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.4.attention.output.dense.bias', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.8.attention.self.value.bias', 'base_model.encoder.layer.6.attention.self.key.weight', 'base_model.encoder.layer.4.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.3.intermediate.dense.weight', 'base_model.encoder.layer.8.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.10.output.LayerNorm.bias', 'base_model.encoder.layer.20.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.4.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.16.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.20.output.dense.bias', 'base_model.encoder.layer.19.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.10.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.5.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.4.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.5.attention.output.LayerNorm.bias', 'base_model.encoder.layer.21.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.20.intermediate.dense.bias', 'base_model.encoder.layer.14.attention.output.dense.bias', 'base_model.encoder.layer.8.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.3.attention.output.dense.weight', 'base_model.encoder.layer.0.output.dense.bias', 'base_model.encoder.layer.1.attention.output.dense.weight', 'base_model.encoder.layer.2.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.7.output.LayerNorm.bias', 'base_model.encoder.layer.1.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.1.attention.output.LayerNorm.weight', 'base_model.encoder.layer.9.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.7.attention.self.query.weight', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.15.attention.output.LayerNorm.bias', 'base_model.encoder.layer.20.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.21.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.20.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.22.attention.output.dense.weight', 'base_model.encoder.layer.21.attention.self.value.bias', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.6.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.15.attention.self.key.bias', 'base_model.encoder.layer.21.attention.output.dense.bias', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.3.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.22.output.LayerNorm.weight', 'base_model.encoder.layer.12.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.10.attention.self.key.weight', 'base_model.encoder.layer.5.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.12.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.14.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.16.attention.self.query.weight', 'qa_outputs.weight', 'base_model.encoder.layer.4.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.17.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.14.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.21.output.LayerNorm.bias', 'base_model.encoder.layer.13.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.18.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.18.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.8.attention.output.LayerNorm.weight', 'base_model.encoder.layer.9.output.dense.bias', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.2.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.4.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.4.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.8.attention.self.key.weight', 'base_model.encoder.layer.11.attention.output.dense.weight', 'base_model.encoder.layer.16.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.8.attention.self.key.bias', 'base_model.encoder.layer.19.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.11.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.12.output.dense.bias', 'base_model.encoder.layer.6.output.LayerNorm.bias', 'base_model.encoder.layer.13.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.0.attention.self.value.weight', 'base_model.encoder.layer.1.output.LayerNorm.weight', 'base_model.encoder.layer.8.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.7.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.5.attention.self.query.weight', 'base_model.encoder.layer.21.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.0.attention.self.query.bias', 'base_model.encoder.layer.22.attention.output.LayerNorm.weight', 'base_model.encoder.layer.9.attention.self.key.bias', 'base_model.encoder.layer.8.intermediate.dense.bias', 'base_model.encoder.layer.11.attention.self.key.weight', 'base_model.encoder.layer.11.output.LayerNorm.bias', 'base_model.encoder.layer.3.attention.self.value.bias', 'base_model.encoder.layer.18.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.22.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.10.attention.self.key.bias', 'base_model.encoder.layer.2.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.0.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.2.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.6.output.dense.weight', 'base_model.encoder.layer.18.attention.self.query.weight', 'base_model.encoder.layer.1.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.3.output.dense.weight', 'base_model.encoder.layer.13.intermediate.dense.weight', 'base_model.encoder.layer.8.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.13.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.4.attention.self.key.weight', 'base_model.encoder.layer.12.attention.output.LayerNorm.bias', 'base_model.encoder.layer.5.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.8.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.19.attention.output.dense.bias', 'base_model.encoder.layer.1.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.19.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.11.attention.output.dense.bias', 'base_model.encoder.layer.8.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.7.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.5.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.17.attention.self.value.bias', 'base_model.encoder.layer.20.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.20.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.19.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.2.attention.output.LayerNorm.bias', 'base_model.encoder.layer.10.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.4.output.LayerNorm.weight', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'qa_outputs.bias', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.16.attention.output.dense.bias', 'base_model.encoder.layer.11.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.22.output.dense.bias', 'base_model.encoder.layer.4.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.1.output.dense.bias', 'base_model.encoder.layer.5.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.14.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.18.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.7.intermediate.dense.bias', 'base_model.encoder.layer.10.attention.output.LayerNorm.weight', 'base_model.encoder.layer.12.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.21.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.17.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.15.output.LayerNorm.bias', 'base_model.encoder.layer.16.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.2.output.LayerNorm.bias', 'base_model.encoder.layer.20.output.LayerNorm.bias', 'base_model.encoder.layer.19.attention.output.dense.weight', 'base_model.encoder.layer.22.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.0.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.22.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.14.attention.self.value.weight', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.21.attention.self.query.weight', 'base_model.encoder.layer.0.intermediate.dense.bias', 'base_model.encoder.layer.7.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.16.output.LayerNorm.bias', 'base_model.encoder.layer.17.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.13.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.5.attention.self.value.bias', 'base_model.encoder.layer.6.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.22.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.1.intermediate.dense.bias', 'base_model.encoder.layer.13.attention.output.LayerNorm.weight', 'base_model.encoder.layer.0.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.21.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.7.output.dense.bias', 'base_model.encoder.layer.0.attention.output.dense.weight', 'base_model.encoder.layer.7.attention.self.query.bias', 'base_model.encoder.layer.16.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.21.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.14.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.23.output.dense.weight', 'base_model.encoder.layer.10.output.dense.weight', 'base_model.encoder.layer.2.attention.self.query.weight', 'base_model.encoder.layer.14.intermediate.dense.bias', 'base_model.encoder.layer.0.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.11.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.17.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.5.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.19.attention.output.LayerNorm.weight', 'base_model.encoder.layer.6.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.22.attention.output.LayerNorm.bias', 'base_model.encoder.layer.3.output.LayerNorm.weight', 'base_model.encoder.layer.21.attention.self.value.weight', 'base_model.encoder.layer.4.output.LayerNorm.bias', 'base_model.encoder.layer.17.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.19.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.11.output.dense.bias', 'base_model.encoder.layer.7.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.7.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.18.intermediate.dense.weight', 'base_model.encoder.layer.0.output.LayerNorm.bias', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.18.output.LayerNorm.bias', 'base_model.encoder.layer.8.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.16.attention.output.LayerNorm.weight', 'base_model.encoder.layer.0.attention.self.key.weight', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.10.intermediate.dense.bias', 'base_model.encoder.layer.23.output.LayerNorm.bias', 'base_model.encoder.layer.0.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.9.attention.output.LayerNorm.bias', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.6.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.17.intermediate.dense.weight', 'base_model.encoder.layer.15.attention.output.dense.bias', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.2.attention.self.query.bias', 'base_model.encoder.layer.23.attention.output.LayerNorm.weight', 'base_model.encoder.layer.4.attention.self.value.bias', 'base_model.encoder.layer.0.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.14.output.LayerNorm.weight', 'base_model.encoder.layer.21.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.3.attention.self.value.weight', 'base_model.encoder.layer.0.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.11.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.1.attention.self.value.weight', 'base_model.encoder.layer.7.attention.self.value.bias', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.7.attention.self.value.weight', 'base_model.encoder.layer.17.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.21.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.3.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.20.attention.self.key.weight', 'base_model.encoder.layer.1.output.LayerNorm.bias', 'base_model.encoder.layer.21.output.dense.weight', 'base_model.encoder.layer.22.intermediate.dense.bias', 'base_model.encoder.layer.18.attention.self.key.weight', 'base_model.encoder.layer.7.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.7.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.11.attention.output.LayerNorm.bias', 'base_model.encoder.layer.23.attention.self.query.bias', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.10.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.17.attention.self.key.weight', 'base_model.encoder.layer.17.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.6.attention.output.dense.weight', 'base_model.encoder.layer.11.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.3.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.11.attention.self.key.bias', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.23.attention.self.key.bias', 'base_model.encoder.layer.6.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.9.intermediate.dense.bias', 'base_model.encoder.layer.16.attention.self.key.bias', 'base_model.embeddings.position_embeddings.weight', 'base_model.encoder.layer.2.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.17.output.LayerNorm.bias', 'base_model.encoder.layer.19.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.15.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.23.attention.self.query.weight', 'base_model.encoder.layer.6.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.21.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.21.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.0.attention.output.LayerNorm.bias', 'base_model.encoder.layer.7.output.dense.weight', 'base_model.encoder.layer.12.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.15.attention.self.value.weight', 'base_model.encoder.layer.17.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.23.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.3.attention.output.LayerNorm.bias', 'base_model.encoder.layer.18.attention.output.LayerNorm.bias', 'base_model.encoder.layer.3.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.6.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.2.output.dense.weight', 'base_model.encoder.layer.0.attention.output.LayerNorm.weight', 'base_model.encoder.layer.5.intermediate.dense.bias', 'base_model.encoder.layer.13.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.7.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.5.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.18.output.LayerNorm.weight', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.11.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.10.intermediate.dense.weight', 'base_model.encoder.layer.22.attention.self.key.weight', 'base_model.encoder.layer.5.attention.output.dense.weight', 'base_model.encoder.layer.3.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.13.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.3.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.7.output.adapters.ts.adapter_down.0.bias', 'base_model.embeddings.token_type_embeddings.weight', 'base_model.encoder.layer.7.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.11.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.1.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.21.intermediate.dense.bias', 'base_model.encoder.layer.23.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.14.intermediate.dense.weight', 'base_model.encoder.layer.8.output.LayerNorm.bias', 'base_model.encoder.layer.15.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.18.attention.output.LayerNorm.weight', 'base_model.encoder.layer.10.attention.output.LayerNorm.bias', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.10.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.1.attention.self.key.weight', 'base_model.encoder.layer.2.attention.output.LayerNorm.weight', 'base_model.encoder.layer.12.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.14.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.15.output.LayerNorm.weight', 'base_model.encoder.layer.23.intermediate.dense.bias', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.9.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.0.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.12.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.18.attention.self.query.bias', 'base_model.encoder.layer.7.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.7.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.8.attention.self.query.weight', 'base_model.encoder.layer.22.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.5.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.1.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.10.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.22.output.LayerNorm.bias', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.4.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.15.attention.self.value.bias', 'base_model.encoder.layer.2.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.23.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.23.attention.self.value.weight', 'base_model.encoder.layer.22.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.21.output.dense.bias', 'base_model.encoder.layer.23.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.11.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.15.attention.output.LayerNorm.weight', 'base_model.encoder.layer.19.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.1.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.5.output.dense.weight', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.10.attention.self.value.weight', 'base_model.encoder.layer.5.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.2.output.dense.bias', 'base_model.encoder.layer.9.attention.self.query.bias', 'base_model.encoder.layer.19.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.18.attention.self.value.weight', 'base_model.encoder.layer.7.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.18.output.dense.bias', 'base_model.encoder.layer.3.attention.self.query.bias', 'base_model.encoder.layer.10.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.15.attention.self.key.weight', 'base_model.encoder.layer.15.attention.output.dense.weight', 'base_model.encoder.layer.9.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.11.attention.self.value.bias', 'base_model.embeddings.LayerNorm.bias', 'base_model.encoder.layer.5.attention.output.dense.bias', 'base_model.encoder.layer.9.output.LayerNorm.bias', 'base_model.encoder.layer.19.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.23.attention.output.LayerNorm.bias', 'base_model.encoder.layer.1.intermediate.dense.weight', 'base_model.encoder.layer.0.attention.self.query.weight', 'base_model.encoder.layer.11.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.16.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.9.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.18.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.0.output.LayerNorm.weight', 'base_model.encoder.layer.10.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.21.attention.output.LayerNorm.bias', 'base_model.encoder.layer.0.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.18.attention.self.value.bias', 'base_model.encoder.layer.7.intermediate.dense.weight', 'base_model.encoder.layer.8.attention.output.dense.weight', 'base_model.encoder.layer.8.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.14.output.adapters.tp.adapter_up.bias', 'base_model.pooler.dense.weight', 'base_model.encoder.layer.3.intermediate.dense.bias', 'base_model.encoder.layer.13.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.12.output.LayerNorm.bias', 'base_model.encoder.layer.20.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.12.attention.self.query.bias', 'base_model.encoder.layer.6.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.22.attention.self.query.bias', 'base_model.encoder.layer.6.attention.self.value.weight', 'base_model.encoder.layer.14.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.1.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.5.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.22.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.18.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.12.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.17.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.17.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.11.attention.self.query.weight', 'base_model.encoder.layer.3.attention.self.query.weight', 'base_model.encoder.layer.5.attention.self.value.weight', 'base_model.encoder.layer.9.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.19.output.dense.bias', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.6.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.15.output.dense.bias', 'base_model.encoder.layer.2.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.20.attention.output.dense.bias', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.13.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.5.output.LayerNorm.bias', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.19.attention.self.value.bias', 'base_model.encoder.layer.23.attention.output.dense.weight', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.7.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.17.output.dense.bias', 'base_model.encoder.layer.10.attention.output.dense.weight', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.0.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.1.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.14.attention.output.LayerNorm.weight', 'base_model.encoder.layer.7.attention.output.dense.weight', 'base_model.encoder.layer.15.intermediate.dense.weight', 'base_model.encoder.layer.2.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.7.attention.output.LayerNorm.weight', 'base_model.encoder.layer.2.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.21.attention.self.query.bias', 'base_model.encoder.layer.10.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.6.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.14.attention.self.key.weight', 'base_model.encoder.layer.16.output.dense.weight', 'base_model.encoder.layer.1.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.2.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.8.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.16.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.10.attention.output.dense.bias', 'base_model.encoder.layer.12.attention.self.key.weight', 'base_model.encoder.layer.2.attention.output.dense.bias', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.15.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.10.attention.self.value.bias', 'base_model.encoder.layer.15.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.2.intermediate.dense.bias', 'base_model.encoder.layer.6.output.dense.bias', 'base_model.encoder.layer.9.attention.self.value.bias', 'base_model.encoder.layer.16.attention.output.dense.weight', 'base_model.encoder.layer.4.output.dense.weight', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.18.attention.output.dense.weight', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.12.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.13.intermediate.dense.bias', 'base_model.encoder.layer.19.attention.self.key.bias', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.8.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.15.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.0.attention.self.value.bias', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.20.attention.self.value.bias', 'base_model.encoder.layer.22.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.18.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.20.attention.self.value.weight', 'base_model.encoder.layer.8.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.19.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.18.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.10.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.20.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.9.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.14.attention.self.query.bias', 'base_model.encoder.layer.1.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.9.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.6.attention.output.LayerNorm.bias', 'base_model.encoder.layer.13.output.dense.bias', 'base_model.encoder.layer.3.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.3.attention.self.key.bias', 'base_model.encoder.layer.11.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.20.attention.output.dense.weight', 'base_model.encoder.layer.1.attention.self.query.weight', 'base_model.encoder.layer.4.attention.self.key.bias', 'base_model.encoder.layer.12.attention.output.LayerNorm.weight', 'base_model.encoder.layer.17.output.LayerNorm.weight', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.22.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.16.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.4.attention.output.LayerNorm.bias', 'base_model.encoder.layer.9.attention.self.value.weight', 'base_model.encoder.layer.20.output.dense.weight', 'base_model.encoder.layer.2.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.21.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.4.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.4.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.16.attention.self.query.bias', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.13.attention.output.LayerNorm.bias', 'base_model.encoder.layer.22.attention.self.value.weight', 'base_model.encoder.layer.5.attention.self.key.bias', 'base_model.encoder.layer.22.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.22.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.22.output.dense.weight', 'base_model.encoder.layer.17.attention.self.query.weight', 'base_model.encoder.layer.14.attention.self.query.weight', 'base_model.encoder.layer.18.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.14.output.LayerNorm.bias', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.3.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.21.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.9.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.12.attention.output.dense.weight', 'base_model.encoder.layer.18.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.2.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.10.attention.self.query.bias', 'base_model.encoder.layer.19.output.LayerNorm.bias', 'base_model.encoder.layer.6.attention.self.query.bias', 'base_model.encoder.layer.13.output.LayerNorm.bias', 'base_model.encoder.layer.14.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.19.attention.self.key.weight', 'base_model.encoder.layer.8.intermediate.dense.weight', 'base_model.encoder.layer.14.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.3.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.23.intermediate.dense.weight', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.11.attention.self.value.weight', 'base_model.encoder.layer.13.attention.self.value.weight', 'base_model.encoder.layer.15.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.15.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.22.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.22.attention.output.dense.bias', 'base_model.encoder.layer.12.intermediate.dense.bias', 'base_model.encoder.layer.21.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.20.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.14.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.3.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.20.attention.self.query.weight', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.5.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.8.attention.self.value.weight', 'base_model.encoder.layer.4.attention.output.dense.weight', 'base_model.encoder.layer.10.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.15.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.5.output.LayerNorm.weight', 'base_model.encoder.layer.6.intermediate.dense.weight', 'base_model.encoder.layer.4.attention.output.LayerNorm.weight', 'base_model.encoder.layer.16.intermediate.dense.weight', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.17.attention.output.LayerNorm.bias', 'base_model.encoder.layer.18.attention.output.dense.bias', 'base_model.encoder.layer.18.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.21.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.3.attention.output.dense.bias', 'base_model.encoder.layer.3.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.14.attention.self.value.bias', 'base_model.encoder.layer.6.attention.self.value.bias', 'base_model.encoder.layer.16.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.21.output.LayerNorm.weight', 'base_model.encoder.layer.16.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.2.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.13.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.0.intermediate.dense.weight', 'base_model.encoder.layer.11.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.1.attention.self.query.bias', 'base_model.encoder.layer.12.output.dense.weight', 'base_model.encoder.layer.10.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.12.intermediate.dense.weight', 'base_model.encoder.layer.16.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.17.attention.self.key.bias', 'base_model.encoder.layer.21.attention.self.key.bias', 'base_model.encoder.layer.14.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.8.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.16.attention.self.key.weight', 'base_model.encoder.layer.1.output.dense.weight', 'base_model.encoder.layer.2.attention.self.key.weight', 'base_model.encoder.layer.12.attention.self.value.bias', 'base_model.encoder.layer.12.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.9.output.dense.weight', 'base_model.encoder.layer.23.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.4.intermediate.dense.bias', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.7.attention.self.key.weight', 'base_model.encoder.layer.17.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.3.output.adapters.ts.adapter_up.weight', 'base_model.embeddings.position_ids', 'base_model.encoder.layer.3.attention.self.key.weight', 'base_model.encoder.layer.3.output.LayerNorm.bias', 'base_model.encoder.layer.22.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.2.attention.output.dense.weight', 'base_model.encoder.layer.9.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.6.intermediate.dense.bias', 'base_model.embeddings.word_embeddings.weight', 'base_model.encoder.layer.9.attention.output.dense.bias', 'base_model.encoder.layer.10.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.13.output.dense.weight', 'base_model.encoder.layer.20.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.0.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.22.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.11.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.17.intermediate.dense.bias', 'base_model.encoder.layer.18.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.0.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.5.attention.self.key.weight', 'base_model.encoder.layer.20.intermediate.dense.weight', 'base_model.encoder.layer.23.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.15.output.dense.weight', 'base_model.encoder.layer.14.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.7.attention.self.key.bias', 'base_model.encoder.layer.9.attention.output.dense.weight', 'base_model.encoder.layer.10.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.17.attention.self.query.bias', 'base_model.encoder.layer.6.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.4.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.21.attention.output.dense.weight', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.13.attention.self.key.weight', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.13.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.19.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.15.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.14.output.dense.bias', 'base_model.encoder.layer.2.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.10.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.19.attention.self.query.bias', 'base_model.encoder.layer.12.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.6.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.6.attention.self.query.weight', 'base_model.encoder.layer.18.attention.self.key.bias', 'base_model.encoder.layer.1.attention.self.value.bias', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.16.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.16.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.20.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.12.output.LayerNorm.weight', 'base_model.encoder.layer.20.attention.output.LayerNorm.bias', 'base_model.encoder.layer.23.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.11.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.12.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.0.attention.self.key.bias', 'base_model.encoder.layer.0.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.1.attention.self.key.bias', 'base_model.encoder.layer.2.intermediate.dense.weight', 'base_model.encoder.layer.13.attention.self.query.weight', 'base_model.encoder.layer.21.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.19.attention.self.value.weight', 'base_model.encoder.layer.15.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.4.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.7.attention.output.LayerNorm.bias', 'base_model.encoder.layer.9.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.4.attention.self.query.weight', 'base_model.encoder.layer.0.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.11.attention.self.query.bias', 'base_model.encoder.layer.17.attention.output.LayerNorm.weight', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.23.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.4.attention.self.value.weight', 'base_model.encoder.layer.6.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.23.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.5.intermediate.dense.weight', 'base_model.encoder.layer.23.output.dense.bias', 'base_model.encoder.layer.0.attention.output.dense.bias', 'base_model.encoder.layer.10.attention.self.query.weight', 'base_model.encoder.layer.23.attention.self.key.weight', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.18.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.8.output.dense.weight', 'base_model.encoder.layer.3.attention.output.LayerNorm.weight', 'base_model.encoder.layer.20.attention.self.query.bias', 'base_model.encoder.layer.11.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.11.attention.output.LayerNorm.weight', 'base_model.encoder.layer.16.output.LayerNorm.weight', 'base_model.encoder.layer.12.attention.self.value.weight', 'base_model.encoder.layer.16.intermediate.dense.bias', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.1.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.3.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.5.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.6.attention.output.dense.bias', 'base_model.encoder.layer.20.attention.output.LayerNorm.weight', 'base_model.encoder.layer.10.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.16.attention.self.value.weight', 'base_model.encoder.layer.17.attention.output.dense.bias', 'base_model.encoder.layer.23.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.9.attention.self.key.weight', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.23.output.LayerNorm.weight', 'base_model.encoder.layer.9.output.LayerNorm.weight', 'base_model.encoder.layer.23.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.19.output.LayerNorm.weight', 'base_model.encoder.layer.1.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.19.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.22.intermediate.dense.weight', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.7.attention.output.dense.bias', 'base_model.encoder.layer.11.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.4.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.15.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.1.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.17.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.9.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.3.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.20.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.18.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.15.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.17.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.20.output.LayerNorm.weight', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.12.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.8.output.dense.bias', 'base_model.encoder.layer.4.attention.self.query.bias', 'base_model.encoder.layer.2.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.2.attention.self.value.bias', 'base_model.encoder.layer.2.output.LayerNorm.weight', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.15.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.19.intermediate.dense.bias', 'base_model.encoder.layer.19.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.23.attention.output.dense.bias', 'base_model.encoder.layer.4.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.9.attention.self.query.weight', 'base_model.encoder.layer.13.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.13.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.5.output.dense.bias', 'base_model.encoder.layer.13.attention.output.dense.weight', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.20.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.17.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.0.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.11.output.LayerNorm.weight', 'base_model.encoder.layer.1.attention.output.dense.bias', 'base_model.encoder.layer.16.attention.output.LayerNorm.bias', 'base_model.encoder.layer.12.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.10.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.13.attention.self.query.bias', 'base_model.encoder.layer.23.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.14.attention.output.LayerNorm.bias', 'base_model.encoder.layer.23.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.4.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.14.attention.self.key.bias', 'base_model.encoder.layer.2.attention.self.value.weight', 'base_model.encoder.layer.23.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.8.attention.output.LayerNorm.bias', 'base_model.encoder.layer.13.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.3.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.8.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.7.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.11.intermediate.dense.bias', 'base_model.encoder.layer.6.attention.output.LayerNorm.weight', 'base_model.encoder.layer.23.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.17.attention.self.value.weight', 'base_model.encoder.layer.12.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.19.output.dense.weight', 'base_model.encoder.layer.4.output.dense.bias', 'base_model.encoder.layer.14.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.16.attention.self.value.bias', 'base_model.encoder.layer.9.intermediate.dense.weight', 'base_model.encoder.layer.9.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.1.attention.output.LayerNorm.bias', 'base_model.encoder.layer.13.attention.output.dense.bias', 'base_model.encoder.layer.6.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.10.output.LayerNorm.weight', 'base_model.encoder.layer.13.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.14.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.19.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.21.intermediate.dense.weight', 'base_model.encoder.layer.9.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.20.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.query.bias']
- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of XLMRobertaModel were not initialized from the model checkpoint at /cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//squad/xlm-KG_LR8e-6_EPOCH2.0_maxlen384_batchsize4_gradacc4 and are newly initialized: ['encoder.layer.8.attention.self.value.bias', 'encoder.layer.6.attention.self.value.weight', 'encoder.layer.2.output.dense.bias', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.19.attention.output.dense.weight', 'encoder.layer.2.attention.self.value.bias', 'encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.layer.0.attention.self.key.weight', 'encoder.layer.0.attention.self.query.weight', 'encoder.layer.6.attention.output.LayerNorm.weight', 'encoder.layer.10.attention.self.value.weight', 'encoder.layer.18.attention.output.dense.bias', 'encoder.layer.12.intermediate.dense.weight', 'encoder.layer.3.attention.self.query.bias', 'encoder.layer.11.attention.self.key.bias', 'encoder.layer.19.output.dense.bias', 'encoder.layer.19.output.LayerNorm.bias', 'encoder.layer.14.output.dense.bias', 'encoder.layer.23.attention.output.dense.bias', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.13.output.dense.weight', 'encoder.layer.1.attention.self.value.weight', 'encoder.layer.18.attention.self.value.bias', 'encoder.layer.4.output.dense.weight', 'encoder.layer.5.attention.output.dense.bias', 'encoder.layer.7.attention.self.key.weight', 'encoder.layer.5.attention.self.value.bias', 'encoder.layer.5.output.LayerNorm.bias', 'encoder.layer.17.attention.self.query.bias', 'encoder.layer.12.output.LayerNorm.bias', 'encoder.layer.21.attention.output.dense.weight', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.7.attention.output.dense.weight', 'encoder.layer.21.output.LayerNorm.bias', 'encoder.layer.2.attention.self.value.weight', 'encoder.layer.18.attention.output.LayerNorm.weight', 'encoder.layer.6.attention.output.LayerNorm.bias', 'encoder.layer.4.attention.self.value.weight', 'encoder.layer.9.attention.output.dense.bias', 'encoder.layer.23.output.LayerNorm.weight', 'encoder.layer.1.attention.self.query.weight', 'embeddings.position_embeddings.weight', 'encoder.layer.23.intermediate.dense.bias', 'encoder.layer.17.output.dense.weight', 'encoder.layer.15.attention.output.dense.bias', 'encoder.layer.17.attention.self.key.weight', 'encoder.layer.17.intermediate.dense.weight', 'encoder.layer.11.attention.self.key.weight', 'encoder.layer.21.attention.self.key.weight', 'encoder.layer.10.attention.output.LayerNorm.bias', 'encoder.layer.9.attention.self.query.bias', 'embeddings.token_type_embeddings.weight', 'encoder.layer.13.attention.self.value.weight', 'encoder.layer.15.output.dense.bias', 'encoder.layer.15.intermediate.dense.weight', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.8.attention.self.query.weight', 'encoder.layer.15.attention.self.query.bias', 'encoder.layer.20.attention.self.query.weight', 'encoder.layer.12.intermediate.dense.bias', 'encoder.layer.22.intermediate.dense.bias', 'encoder.layer.3.output.dense.weight', 'encoder.layer.7.attention.self.value.bias', 'encoder.layer.18.output.dense.weight', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.14.attention.self.query.bias', 'encoder.layer.10.intermediate.dense.weight', 'encoder.layer.18.attention.self.value.weight', 'encoder.layer.12.attention.output.LayerNorm.bias', 'encoder.layer.3.attention.self.value.bias', 'encoder.layer.16.output.dense.bias', 'encoder.layer.19.attention.output.LayerNorm.weight', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.19.attention.self.query.weight', 'encoder.layer.3.attention.self.key.weight', 'encoder.layer.16.intermediate.dense.weight', 'encoder.layer.23.output.dense.weight', 'encoder.layer.21.intermediate.dense.bias', 'encoder.layer.13.attention.output.LayerNorm.weight', 'encoder.layer.6.attention.self.query.weight', 'encoder.layer.16.attention.self.query.bias', 'encoder.layer.7.output.LayerNorm.bias', 'encoder.layer.23.attention.output.LayerNorm.weight', 'encoder.layer.21.intermediate.dense.weight', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.5.attention.output.dense.weight', 'encoder.layer.22.attention.self.key.weight', 'encoder.layer.20.attention.output.LayerNorm.bias', 'encoder.layer.16.attention.output.dense.bias', 'encoder.layer.20.attention.output.dense.weight', 'encoder.layer.16.output.LayerNorm.bias', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.4.attention.self.value.bias', 'encoder.layer.16.attention.self.value.weight', 'encoder.layer.8.attention.self.value.weight', 'encoder.layer.12.attention.output.dense.bias', 'encoder.layer.21.output.LayerNorm.weight', 'encoder.layer.19.intermediate.dense.weight', 'encoder.layer.8.output.dense.weight', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.22.intermediate.dense.weight', 'encoder.layer.0.output.dense.weight', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.12.attention.self.key.bias', 'encoder.layer.9.attention.self.key.bias', 'encoder.layer.17.attention.output.dense.bias', 'encoder.layer.4.attention.self.key.bias', 'encoder.layer.11.attention.self.value.weight', 'encoder.layer.7.output.dense.weight', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.17.attention.output.dense.weight', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.0.attention.self.value.weight', 'encoder.layer.6.attention.output.dense.bias', 'encoder.layer.9.attention.self.query.weight', 'encoder.layer.1.attention.self.value.bias', 'encoder.layer.7.attention.self.query.weight', 'encoder.layer.14.output.dense.weight', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.19.attention.self.key.bias', 'encoder.layer.19.attention.self.value.bias', 'encoder.layer.13.attention.self.query.bias', 'encoder.layer.18.output.dense.bias', 'encoder.layer.0.attention.output.LayerNorm.weight', 'encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.layer.9.output.LayerNorm.weight', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.0.attention.self.key.bias', 'encoder.layer.13.output.LayerNorm.weight', 'encoder.layer.0.output.dense.bias', 'encoder.layer.2.attention.self.key.weight', 'encoder.layer.13.attention.self.query.weight', 'encoder.layer.14.attention.self.value.bias', 'encoder.layer.0.attention.self.query.bias', 'encoder.layer.6.output.dense.weight', 'encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.17.attention.self.value.weight', 'encoder.layer.11.output.LayerNorm.bias', 'encoder.layer.9.attention.output.LayerNorm.bias', 'encoder.layer.17.output.LayerNorm.bias', 'encoder.layer.14.intermediate.dense.weight', 'encoder.layer.6.attention.self.query.bias', 'encoder.layer.12.attention.output.dense.weight', 'encoder.layer.18.output.LayerNorm.bias', 'encoder.layer.18.intermediate.dense.bias', 'encoder.layer.8.attention.output.LayerNorm.weight', 'encoder.layer.21.attention.output.LayerNorm.bias', 'encoder.layer.8.attention.self.query.bias', 'encoder.layer.16.output.dense.weight', 'encoder.layer.13.output.dense.bias', 'encoder.layer.7.attention.output.dense.bias', 'encoder.layer.10.output.LayerNorm.bias', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.2.attention.self.key.bias', 'encoder.layer.14.attention.output.dense.bias', 'encoder.layer.13.attention.output.dense.bias', 'encoder.layer.4.attention.self.query.weight', 'encoder.layer.8.output.LayerNorm.bias', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.layer.22.attention.self.query.weight', 'encoder.layer.23.intermediate.dense.weight', 'encoder.layer.7.attention.self.query.bias', 'encoder.layer.10.attention.output.dense.weight', 'encoder.layer.5.attention.output.LayerNorm.weight', 'encoder.layer.21.attention.output.LayerNorm.weight', 'encoder.layer.5.attention.self.key.weight', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.20.output.LayerNorm.bias', 'encoder.layer.2.attention.self.query.weight', 'encoder.layer.13.attention.self.key.weight', 'encoder.layer.10.attention.self.query.bias', 'encoder.layer.4.attention.output.LayerNorm.weight', 'encoder.layer.20.intermediate.dense.weight', 'encoder.layer.1.output.dense.weight', 'encoder.layer.1.attention.self.key.weight', 'encoder.layer.5.output.dense.weight', 'encoder.layer.20.output.dense.weight', 'encoder.layer.22.attention.self.value.weight', 'encoder.layer.17.attention.self.key.bias', 'encoder.layer.11.attention.output.dense.weight', 'encoder.layer.10.output.LayerNorm.weight', 'encoder.layer.20.attention.output.LayerNorm.weight', 'encoder.layer.23.output.LayerNorm.bias', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.21.attention.self.query.weight', 'encoder.layer.15.attention.output.dense.weight', 'encoder.layer.3.attention.self.key.bias', 'encoder.layer.12.output.dense.bias', 'encoder.layer.22.output.dense.weight', 'encoder.layer.14.attention.self.key.bias', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.8.attention.self.key.bias', 'encoder.layer.2.attention.output.LayerNorm.bias', 'encoder.layer.9.attention.output.dense.weight', 'encoder.layer.9.attention.self.value.weight', 'encoder.layer.15.attention.self.query.weight', 'encoder.layer.1.attention.output.LayerNorm.weight', 'encoder.layer.8.output.dense.bias', 'encoder.layer.12.attention.self.key.weight', 'encoder.layer.3.attention.output.dense.weight', 'encoder.layer.4.attention.self.key.weight', 'encoder.layer.4.attention.output.dense.bias', 'encoder.layer.10.attention.self.key.weight', 'encoder.layer.0.attention.self.value.bias', 'encoder.layer.11.attention.self.value.bias', 'encoder.layer.16.attention.self.value.bias', 'encoder.layer.6.attention.output.dense.weight', 'encoder.layer.20.attention.self.query.bias', 'encoder.layer.7.attention.self.key.bias', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.6.output.LayerNorm.bias', 'encoder.layer.9.attention.self.value.bias', 'encoder.layer.23.attention.self.value.weight', 'encoder.layer.10.output.dense.bias', 'encoder.layer.13.intermediate.dense.weight', 'encoder.layer.19.attention.output.dense.bias', 'encoder.layer.21.attention.self.value.weight', 'encoder.layer.5.attention.self.query.bias', 'encoder.layer.18.attention.self.query.weight', 'encoder.layer.4.attention.output.LayerNorm.bias', 'embeddings.LayerNorm.weight', 'encoder.layer.5.attention.self.value.weight', 'encoder.layer.18.attention.output.LayerNorm.bias', 'encoder.layer.9.attention.output.LayerNorm.weight', 'encoder.layer.16.attention.output.LayerNorm.weight', 'encoder.layer.10.attention.self.query.weight', 'encoder.layer.12.attention.output.LayerNorm.weight', 'encoder.layer.20.attention.self.key.weight', 'encoder.layer.20.attention.self.value.bias', 'encoder.layer.16.attention.self.query.weight', 'pooler.dense.weight', 'encoder.layer.10.output.dense.weight', 'encoder.layer.2.attention.self.query.bias', 'encoder.layer.19.intermediate.dense.bias', 'encoder.layer.20.attention.self.value.weight', 'encoder.layer.1.output.dense.bias', 'encoder.layer.23.attention.output.LayerNorm.bias', 'encoder.layer.13.attention.self.value.bias', 'encoder.layer.18.attention.self.key.weight', 'embeddings.word_embeddings.weight', 'encoder.layer.21.attention.output.dense.bias', 'encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.layer.12.output.dense.weight', 'encoder.layer.13.attention.output.LayerNorm.bias', 'encoder.layer.7.attention.output.LayerNorm.weight', 'encoder.layer.8.attention.output.dense.bias', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.11.output.dense.bias', 'encoder.layer.8.attention.output.LayerNorm.bias', 'encoder.layer.14.output.LayerNorm.weight', 'encoder.layer.11.attention.self.query.bias', 'encoder.layer.17.attention.output.LayerNorm.bias', 'encoder.layer.2.attention.output.dense.weight', 'encoder.layer.23.output.dense.bias', 'encoder.layer.13.output.LayerNorm.bias', 'encoder.layer.18.attention.output.dense.weight', 'encoder.layer.1.attention.self.key.bias', 'encoder.layer.14.attention.output.LayerNorm.weight', 'encoder.layer.15.attention.output.LayerNorm.bias', 'encoder.layer.6.attention.self.key.weight', 'encoder.layer.3.output.dense.bias', 'encoder.layer.3.attention.self.query.weight', 'encoder.layer.4.output.dense.bias', 'encoder.layer.0.intermediate.dense.bias', 'pooler.dense.bias', 'encoder.layer.14.attention.self.query.weight', 'encoder.layer.17.output.dense.bias', 'encoder.layer.1.attention.self.query.bias', 'encoder.layer.11.output.LayerNorm.weight', 'encoder.layer.19.attention.output.LayerNorm.bias', 'encoder.layer.4.attention.output.dense.weight', 'encoder.layer.23.attention.self.query.weight', 'encoder.layer.22.attention.output.LayerNorm.bias', 'encoder.layer.15.attention.self.key.bias', 'encoder.layer.22.attention.self.key.bias', 'encoder.layer.10.attention.self.key.bias', 'encoder.layer.14.attention.output.LayerNorm.bias', 'encoder.layer.8.attention.output.dense.weight', 'encoder.layer.21.output.dense.bias', 'encoder.layer.1.attention.output.dense.weight', 'encoder.layer.0.attention.output.dense.bias', 'encoder.layer.12.output.LayerNorm.weight', 'encoder.layer.15.output.LayerNorm.weight', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.11.attention.output.LayerNorm.weight', 'encoder.layer.23.attention.output.dense.weight', 'encoder.layer.22.attention.output.dense.bias', 'encoder.layer.5.attention.self.key.bias', 'encoder.layer.19.output.dense.weight', 'encoder.layer.21.attention.self.query.bias', 'encoder.layer.9.output.dense.bias', 'encoder.layer.0.attention.output.dense.weight', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.10.attention.self.value.bias', 'encoder.layer.2.output.dense.weight', 'encoder.layer.14.output.LayerNorm.bias', 'encoder.layer.22.output.LayerNorm.bias', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.layer.18.attention.self.key.bias', 'encoder.layer.22.output.LayerNorm.weight', 'encoder.layer.10.attention.output.dense.bias', 'encoder.layer.14.attention.self.key.weight', 'encoder.layer.4.attention.self.query.bias', 'encoder.layer.6.attention.self.key.bias', 'encoder.layer.23.attention.self.key.bias', 'encoder.layer.18.intermediate.dense.weight', 'encoder.layer.15.attention.output.LayerNorm.weight', 'encoder.layer.18.output.LayerNorm.weight', 'encoder.layer.11.attention.self.query.weight', 'encoder.layer.14.intermediate.dense.bias', 'encoder.layer.7.intermediate.dense.bias', 'encoder.layer.20.output.dense.bias', 'encoder.layer.22.attention.self.value.bias', 'encoder.layer.22.attention.output.dense.weight', 'encoder.layer.22.attention.output.LayerNorm.weight', 'encoder.layer.21.attention.self.value.bias', 'encoder.layer.15.output.LayerNorm.bias', 'encoder.layer.7.attention.self.value.weight', 'encoder.layer.11.attention.output.dense.bias', 'encoder.layer.17.output.LayerNorm.weight', 'encoder.layer.15.intermediate.dense.bias', 'encoder.layer.11.output.dense.weight', 'encoder.layer.1.attention.output.dense.bias', 'encoder.layer.23.attention.self.query.bias', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.16.attention.self.key.bias', 'encoder.layer.6.output.dense.bias', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.8.output.LayerNorm.weight', 'encoder.layer.16.intermediate.dense.bias', 'encoder.layer.7.attention.output.LayerNorm.bias', 'encoder.layer.22.attention.self.query.bias', 'encoder.layer.20.intermediate.dense.bias', 'encoder.layer.21.output.dense.weight', 'encoder.layer.2.attention.output.dense.bias', 'encoder.layer.22.output.dense.bias', 'encoder.layer.19.output.LayerNorm.weight', 'encoder.layer.19.attention.self.key.weight', 'encoder.layer.17.intermediate.dense.bias', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.23.attention.self.value.bias', 'encoder.layer.12.attention.self.value.weight', 'encoder.layer.20.output.LayerNorm.weight', 'encoder.layer.18.attention.self.query.bias', 'encoder.layer.13.intermediate.dense.bias', 'encoder.layer.19.attention.self.query.bias', 'encoder.layer.19.attention.self.value.weight', 'encoder.layer.16.attention.output.LayerNorm.bias', 'encoder.layer.12.attention.self.value.bias', 'encoder.layer.5.attention.self.query.weight', 'encoder.layer.20.attention.output.dense.bias', 'encoder.layer.23.attention.self.key.weight', 'encoder.layer.16.attention.self.key.weight', 'encoder.layer.20.attention.self.key.bias', 'encoder.layer.12.attention.self.query.bias', 'embeddings.LayerNorm.bias', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.15.attention.self.value.weight', 'encoder.layer.13.attention.output.dense.weight', 'encoder.layer.8.attention.self.key.weight', 'encoder.layer.9.attention.self.key.weight', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.14.attention.output.dense.weight', 'encoder.layer.15.attention.self.key.weight', 'encoder.layer.3.attention.output.dense.bias', 'encoder.layer.17.attention.self.value.bias', 'encoder.layer.15.output.dense.weight', 'encoder.layer.2.attention.output.LayerNorm.weight', 'encoder.layer.21.attention.self.key.bias', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.9.output.LayerNorm.bias', 'encoder.layer.17.attention.self.query.weight', 'encoder.layer.16.attention.output.dense.weight', 'encoder.layer.5.output.dense.bias', 'encoder.layer.13.attention.self.key.bias', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.16.output.LayerNorm.weight', 'encoder.layer.6.attention.self.value.bias', 'encoder.layer.12.attention.self.query.weight', 'encoder.layer.3.attention.self.value.weight', 'encoder.layer.9.output.dense.weight', 'encoder.layer.17.attention.output.LayerNorm.weight', 'encoder.layer.15.attention.self.value.bias', 'encoder.layer.7.output.dense.bias', 'encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.layer.7.output.LayerNorm.weight', 'encoder.layer.14.attention.self.value.weight', 'encoder.layer.10.attention.output.LayerNorm.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Overwriting existing adapter 'ep'.
Overwriting existing adapter 'tp'.
Overwriting existing adapter 'es'.
Overwriting existing adapter 'ts'.
Overwriting existing adapter fusion module 'ep,tp,es,ts'
05/09/2022 20:04:21 - INFO - __main__ -   Creating features from dataset file at .
/cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//squad/xlm-KG_LR8e-6_EPOCH2.0_maxlen384_batchsize4_gradacc4
XLMConfig {
  "architectures": [
    "XLMRobertaForMaskedLM"
  ],
  "asm": false,
  "attention_dropout": 0.1,
  "attention_probs_dropout_prob": 0.1,
  "bos_index": 0,
  "bos_token_id": 0,
  "causal": false,
  "dropout": 0.1,
  "emb_dim": 1024,
  "embed_init_std": 0.02209708691207961,
  "end_n_top": 5,
  "eos_index": 1,
  "eos_token_id": 2,
  "gelu_activation": true,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "init_std": 0.02,
  "initializer_range": 0.02,
  "intermediate_size": 4096,
  "is_encoder": true,
  "lang_id": 0,
  "layer_norm_eps": 1e-05,
  "mask_index": 5,
  "mask_token_id": 0,
  "max_position_embeddings": 514,
  "model_type": "xlm",
  "n_heads": 16,
  "n_langs": 1,
  "n_layers": 24,
  "output_past": true,
  "pad_index": 2,
  "pad_token_id": 1,
  "sinusoidal_embeddings": false,
  "start_n_top": 5,
  "summary_activation": null,
  "summary_first_dropout": 0.1,
  "summary_proj_to_labels": true,
  "summary_type": "first",
  "summary_use_proj": true,
  "transformers_version": "4.17.0",
  "type_vocab_size": 1,
  "unk_index": 3,
  "use_lang_emb": false,
  "vocab_size": 250002
}

  0%|          | 0/48 [00:00<?, ?it/s] 31%|███▏      | 15/48 [00:00<00:00, 141.37it/s] 62%|██████▎   | 30/48 [00:00<00:00, 108.68it/s] 94%|█████████▍| 45/48 [00:00<00:00, 121.05it/s]100%|██████████| 48/48 [00:00<00:00, 123.19it/s]
convert squad examples to features:   0%|          | 0/1190 [00:00<?, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.
convert squad examples to features:   0%|          | 1/1190 [00:00<04:13,  4.69it/s]convert squad examples to features:   5%|▌         | 65/1190 [00:00<00:06, 173.63it/s]convert squad examples to features:   8%|▊         | 97/1190 [00:00<00:05, 214.04it/s]convert squad examples to features:  14%|█▎        | 161/1190 [00:00<00:03, 287.58it/s]convert squad examples to features:  19%|█▉        | 225/1190 [00:00<00:03, 294.85it/s]convert squad examples to features:  22%|██▏       | 257/1190 [00:01<00:03, 280.16it/s]convert squad examples to features:  24%|██▍       | 289/1190 [00:01<00:03, 264.02it/s]convert squad examples to features:  27%|██▋       | 321/1190 [00:01<00:03, 263.97it/s]convert squad examples to features:  32%|███▏      | 385/1190 [00:01<00:05, 159.67it/s]convert squad examples to features:  35%|███▌      | 417/1190 [00:02<00:04, 176.66it/s]convert squad examples to features:  38%|███▊      | 449/1190 [00:02<00:03, 187.97it/s]convert squad examples to features:  40%|████      | 481/1190 [00:02<00:03, 200.91it/s]convert squad examples to features:  43%|████▎     | 513/1190 [00:02<00:03, 207.23it/s]convert squad examples to features:  46%|████▌     | 545/1190 [00:02<00:03, 206.97it/s]convert squad examples to features:  48%|████▊     | 577/1190 [00:02<00:02, 217.33it/s]convert squad examples to features:  51%|█████     | 609/1190 [00:02<00:02, 212.87it/s]convert squad examples to features:  54%|█████▍    | 641/1190 [00:03<00:02, 217.28it/s]convert squad examples to features:  57%|█████▋    | 673/1190 [00:03<00:02, 216.75it/s]convert squad examples to features:  59%|█████▉    | 705/1190 [00:03<00:02, 230.71it/s]convert squad examples to features:  65%|██████▍   | 769/1190 [00:03<00:01, 265.30it/s]convert squad examples to features:  67%|██████▋   | 801/1190 [00:03<00:01, 274.41it/s]convert squad examples to features:  70%|███████   | 833/1190 [00:03<00:01, 250.73it/s]convert squad examples to features:  73%|███████▎  | 865/1190 [00:03<00:01, 255.45it/s]convert squad examples to features:  75%|███████▌  | 897/1190 [00:04<00:01, 245.76it/s]convert squad examples to features:  78%|███████▊  | 929/1190 [00:04<00:01, 246.03it/s]convert squad examples to features:  81%|████████  | 961/1190 [00:04<00:00, 246.78it/s]convert squad examples to features:  83%|████████▎ | 993/1190 [00:04<00:00, 262.50it/s]convert squad examples to features:  89%|████████▉ | 1057/1190 [00:04<00:00, 299.27it/s]convert squad examples to features:  92%|█████████▏| 1089/1190 [00:04<00:00, 295.81it/s]convert squad examples to features:  94%|█████████▍| 1121/1190 [00:04<00:00, 280.64it/s]convert squad examples to features:  97%|█████████▋| 1153/1190 [00:04<00:00, 274.34it/s]convert squad examples to features: 100%|██████████| 1190/1190 [00:04<00:00, 241.54it/s]/cluster/project/sachan/yifan/softwares/anaconda/anaconda3/envs/xfactr/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2272: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

add example index and unique id:   0%|          | 0/1190 [00:00<?, ?it/s]add example index and unique id: 100%|██████████| 1190/1190 [00:00<00:00, 806596.92it/s]
05/09/2022 20:04:27 - INFO - __main__ -   Saving features into cached file ./cached_xquad.ar.json_xlm-KG_LR8e-6_EPOCH2.0_maxlen384_batchsize4_gradacc4_384_ar
05/09/2022 20:04:28 - INFO - __main__ -   ***** Running evaluation  *****
05/09/2022 20:04:28 - INFO - __main__ -     Num examples = 1318
05/09/2022 20:04:28 - INFO - __main__ -     Batch size = 8
Evaluating:   0%|          | 0/165 [00:00<?, ?it/s]Evaluating:   1%|          | 1/165 [00:00<02:16,  1.20it/s]Evaluating:   1%|          | 2/165 [00:01<01:29,  1.81it/s]Evaluating:   2%|▏         | 3/165 [00:01<01:15,  2.16it/s]Evaluating:   2%|▏         | 4/165 [00:01<01:08,  2.36it/s]Evaluating:   3%|▎         | 5/165 [00:02<01:03,  2.51it/s]Evaluating:   4%|▎         | 6/165 [00:02<01:01,  2.60it/s]Evaluating:   4%|▍         | 7/165 [00:02<00:59,  2.66it/s]Evaluating:   5%|▍         | 8/165 [00:03<00:57,  2.71it/s]Evaluating:   5%|▌         | 9/165 [00:03<00:56,  2.74it/s]Evaluating:   6%|▌         | 10/165 [00:04<00:56,  2.74it/s]Evaluating:   7%|▋         | 11/165 [00:04<00:56,  2.75it/s]Evaluating:   7%|▋         | 12/165 [00:04<00:55,  2.76it/s]Evaluating:   8%|▊         | 13/165 [00:05<00:54,  2.77it/s]Evaluating:   8%|▊         | 14/165 [00:05<00:54,  2.78it/s]Evaluating:   9%|▉         | 15/165 [00:05<00:54,  2.78it/s]Evaluating:  10%|▉         | 16/165 [00:06<00:53,  2.79it/s]Evaluating:  10%|█         | 17/165 [00:06<00:52,  2.80it/s]Evaluating:  11%|█         | 18/165 [00:06<00:52,  2.79it/s]Evaluating:  12%|█▏        | 19/165 [00:07<00:52,  2.80it/s]Evaluating:  12%|█▏        | 20/165 [00:07<00:51,  2.80it/s]Evaluating:  13%|█▎        | 21/165 [00:07<00:51,  2.80it/s]Evaluating:  13%|█▎        | 22/165 [00:08<00:51,  2.79it/s]Evaluating:  14%|█▍        | 23/165 [00:08<00:50,  2.79it/s]Evaluating:  15%|█▍        | 24/165 [00:09<00:50,  2.80it/s]Evaluating:  15%|█▌        | 25/165 [00:09<00:50,  2.75it/s]Evaluating:  16%|█▌        | 26/165 [00:09<00:50,  2.76it/s]Evaluating:  16%|█▋        | 27/165 [00:10<00:50,  2.76it/s]Evaluating:  17%|█▋        | 28/165 [00:10<00:49,  2.77it/s]Evaluating:  18%|█▊        | 29/165 [00:10<00:48,  2.78it/s]Evaluating:  18%|█▊        | 30/165 [00:11<00:48,  2.79it/s]Evaluating:  19%|█▉        | 31/165 [00:11<00:48,  2.79it/s]Evaluating:  19%|█▉        | 32/165 [00:11<00:47,  2.79it/s]Evaluating:  20%|██        | 33/165 [00:12<00:47,  2.79it/s]Evaluating:  21%|██        | 34/165 [00:12<00:46,  2.79it/s]Evaluating:  21%|██        | 35/165 [00:13<00:46,  2.78it/s]Evaluating:  22%|██▏       | 36/165 [00:13<00:46,  2.76it/s]Evaluating:  22%|██▏       | 37/165 [00:13<00:46,  2.77it/s]Evaluating:  23%|██▎       | 38/165 [00:14<00:45,  2.77it/s]Evaluating:  24%|██▎       | 39/165 [00:14<00:45,  2.76it/s]Evaluating:  24%|██▍       | 40/165 [00:14<00:45,  2.74it/s]Evaluating:  25%|██▍       | 41/165 [00:15<00:44,  2.76it/s]Evaluating:  25%|██▌       | 42/165 [00:15<00:44,  2.77it/s]Evaluating:  26%|██▌       | 43/165 [00:15<00:44,  2.73it/s]Evaluating:  27%|██▋       | 44/165 [00:16<00:44,  2.75it/s]Evaluating:  27%|██▋       | 45/165 [00:16<00:43,  2.76it/s]Evaluating:  28%|██▊       | 46/165 [00:17<00:43,  2.76it/s]Evaluating:  28%|██▊       | 47/165 [00:17<00:42,  2.78it/s]Evaluating:  29%|██▉       | 48/165 [00:17<00:41,  2.79it/s]Evaluating:  30%|██▉       | 49/165 [00:18<00:41,  2.79it/s]Evaluating:  30%|███       | 50/165 [00:18<00:41,  2.79it/s]Evaluating:  31%|███       | 51/165 [00:18<00:40,  2.79it/s]Evaluating:  32%|███▏      | 52/165 [00:19<00:40,  2.78it/s]Evaluating:  32%|███▏      | 53/165 [00:19<00:40,  2.78it/s]Evaluating:  33%|███▎      | 54/165 [00:19<00:40,  2.76it/s]Evaluating:  33%|███▎      | 55/165 [00:20<00:39,  2.76it/s]Evaluating:  34%|███▍      | 56/165 [00:20<00:39,  2.76it/s]Evaluating:  35%|███▍      | 57/165 [00:20<00:39,  2.76it/s]Evaluating:  35%|███▌      | 58/165 [00:21<00:38,  2.76it/s]Evaluating:  36%|███▌      | 59/165 [00:21<00:38,  2.76it/s]Evaluating:  36%|███▋      | 60/165 [00:22<00:38,  2.76it/s]Evaluating:  37%|███▋      | 61/165 [00:22<00:38,  2.73it/s]Evaluating:  38%|███▊      | 62/165 [00:22<00:37,  2.74it/s]Evaluating:  38%|███▊      | 63/165 [00:23<00:37,  2.74it/s]Evaluating:  39%|███▉      | 64/165 [00:23<00:36,  2.75it/s]Evaluating:  39%|███▉      | 65/165 [00:23<00:36,  2.75it/s]Evaluating:  40%|████      | 66/165 [00:24<00:35,  2.76it/s]Evaluating:  41%|████      | 67/165 [00:24<00:35,  2.76it/s]Evaluating:  41%|████      | 68/165 [00:24<00:35,  2.76it/s]Evaluating:  42%|████▏     | 69/165 [00:25<00:34,  2.76it/s]Evaluating:  42%|████▏     | 70/165 [00:25<00:34,  2.77it/s]Evaluating:  43%|████▎     | 71/165 [00:26<00:33,  2.77it/s]Evaluating:  44%|████▎     | 72/165 [00:26<00:33,  2.75it/s]Evaluating:  44%|████▍     | 73/165 [00:26<00:33,  2.76it/s]Evaluating:  45%|████▍     | 74/165 [00:27<00:32,  2.77it/s]Evaluating:  45%|████▌     | 75/165 [00:27<00:32,  2.73it/s]Evaluating:  46%|████▌     | 76/165 [00:27<00:32,  2.75it/s]Evaluating:  47%|████▋     | 77/165 [00:28<00:32,  2.75it/s]Evaluating:  47%|████▋     | 78/165 [00:28<00:31,  2.75it/s]Evaluating:  48%|████▊     | 79/165 [00:28<00:31,  2.75it/s]Evaluating:  48%|████▊     | 80/165 [00:29<00:30,  2.75it/s]Evaluating:  49%|████▉     | 81/165 [00:29<00:30,  2.75it/s]Evaluating:  50%|████▉     | 82/165 [00:30<00:30,  2.76it/s]Evaluating:  50%|█████     | 83/165 [00:30<00:29,  2.76it/s]Evaluating:  51%|█████     | 84/165 [00:30<00:29,  2.75it/s]Evaluating:  52%|█████▏    | 85/165 [00:31<00:29,  2.75it/s]Evaluating:  52%|█████▏    | 86/165 [00:31<00:28,  2.75it/s]Evaluating:  53%|█████▎    | 87/165 [00:31<00:28,  2.75it/s]Evaluating:  53%|█████▎    | 88/165 [00:32<00:28,  2.74it/s]Evaluating:  54%|█████▍    | 89/165 [00:32<00:27,  2.75it/s]Evaluating:  55%|█████▍    | 90/165 [00:32<00:27,  2.75it/s]Evaluating:  55%|█████▌    | 91/165 [00:33<00:26,  2.74it/s]Evaluating:  56%|█████▌    | 92/165 [00:33<00:26,  2.74it/s]Evaluating:  56%|█████▋    | 93/165 [00:34<00:26,  2.74it/s]Evaluating:  57%|█████▋    | 94/165 [00:34<00:25,  2.74it/s]Evaluating:  58%|█████▊    | 95/165 [00:34<00:25,  2.74it/s]Evaluating:  58%|█████▊    | 96/165 [00:35<00:25,  2.75it/s]Evaluating:  59%|█████▉    | 97/165 [00:35<00:24,  2.75it/s]Evaluating:  59%|█████▉    | 98/165 [00:35<00:24,  2.74it/s]Evaluating:  60%|██████    | 99/165 [00:36<00:24,  2.74it/s]Evaluating:  61%|██████    | 100/165 [00:36<00:23,  2.75it/s]Evaluating:  61%|██████    | 101/165 [00:36<00:23,  2.75it/s]Evaluating:  62%|██████▏   | 102/165 [00:37<00:22,  2.75it/s]Evaluating:  62%|██████▏   | 103/165 [00:37<00:22,  2.76it/s]Evaluating:  63%|██████▎   | 104/165 [00:38<00:22,  2.76it/s]Evaluating:  64%|██████▎   | 105/165 [00:38<00:21,  2.75it/s]Evaluating:  64%|██████▍   | 106/165 [00:38<00:21,  2.75it/s]Evaluating:  65%|██████▍   | 107/165 [00:39<00:21,  2.72it/s]Evaluating:  65%|██████▌   | 108/165 [00:39<00:20,  2.73it/s]Evaluating:  66%|██████▌   | 109/165 [00:39<00:20,  2.74it/s]Evaluating:  67%|██████▋   | 110/165 [00:40<00:20,  2.74it/s]Evaluating:  67%|██████▋   | 111/165 [00:40<00:19,  2.74it/s]Evaluating:  68%|██████▊   | 112/165 [00:40<00:19,  2.75it/s]Evaluating:  68%|██████▊   | 113/165 [00:41<00:18,  2.76it/s]Evaluating:  69%|██████▉   | 114/165 [00:41<00:18,  2.76it/s]Evaluating:  70%|██████▉   | 115/165 [00:42<00:18,  2.76it/s]Evaluating:  70%|███████   | 116/165 [00:42<00:17,  2.76it/s]Evaluating:  71%|███████   | 117/165 [00:42<00:17,  2.76it/s]Evaluating:  72%|███████▏  | 118/165 [00:43<00:17,  2.76it/s]Evaluating:  72%|███████▏  | 119/165 [00:43<00:16,  2.76it/s]Evaluating:  73%|███████▎  | 120/165 [00:43<00:16,  2.76it/s]Evaluating:  73%|███████▎  | 121/165 [00:44<00:16,  2.75it/s]Evaluating:  74%|███████▍  | 122/165 [00:44<00:15,  2.76it/s]Evaluating:  75%|███████▍  | 123/165 [00:44<00:15,  2.76it/s]Evaluating:  75%|███████▌  | 124/165 [00:45<00:15,  2.73it/s]Evaluating:  76%|███████▌  | 125/165 [00:45<00:15,  2.65it/s]Evaluating:  76%|███████▋  | 126/165 [00:46<00:14,  2.68it/s]Evaluating:  77%|███████▋  | 127/165 [00:46<00:14,  2.70it/s]Evaluating:  78%|███████▊  | 128/165 [00:46<00:13,  2.72it/s]Evaluating:  78%|███████▊  | 129/165 [00:47<00:13,  2.73it/s]Evaluating:  79%|███████▉  | 130/165 [00:47<00:12,  2.72it/s]Evaluating:  79%|███████▉  | 131/165 [00:47<00:12,  2.73it/s]Evaluating:  80%|████████  | 132/165 [00:48<00:12,  2.73it/s]Evaluating:  81%|████████  | 133/165 [00:48<00:11,  2.74it/s]Evaluating:  81%|████████  | 134/165 [00:49<00:11,  2.75it/s]Evaluating:  82%|████████▏ | 135/165 [00:49<00:10,  2.76it/s]Evaluating:  82%|████████▏ | 136/165 [00:49<00:10,  2.75it/s]Evaluating:  83%|████████▎ | 137/165 [00:50<00:10,  2.72it/s]Evaluating:  84%|████████▎ | 138/165 [00:50<00:09,  2.73it/s]Evaluating:  84%|████████▍ | 139/165 [00:50<00:09,  2.74it/s]Evaluating:  85%|████████▍ | 140/165 [00:51<00:09,  2.74it/s]Evaluating:  85%|████████▌ | 141/165 [00:51<00:08,  2.73it/s]Evaluating:  86%|████████▌ | 142/165 [00:51<00:08,  2.74it/s]Evaluating:  87%|████████▋ | 143/165 [00:52<00:07,  2.75it/s]Evaluating:  87%|████████▋ | 144/165 [00:52<00:07,  2.76it/s]Evaluating:  88%|████████▊ | 145/165 [00:53<00:07,  2.76it/s]Evaluating:  88%|████████▊ | 146/165 [00:53<00:06,  2.77it/s]Evaluating:  89%|████████▉ | 147/165 [00:53<00:06,  2.77it/s]Evaluating:  90%|████████▉ | 148/165 [00:54<00:06,  2.76it/s]Evaluating:  90%|█████████ | 149/165 [00:54<00:05,  2.77it/s]Evaluating:  91%|█████████ | 150/165 [00:54<00:05,  2.77it/s]Evaluating:  92%|█████████▏| 151/165 [00:55<00:05,  2.77it/s]Evaluating:  92%|█████████▏| 152/165 [00:55<00:04,  2.72it/s]Evaluating:  93%|█████████▎| 153/165 [00:55<00:04,  2.73it/s]Evaluating:  93%|█████████▎| 154/165 [00:56<00:04,  2.74it/s]Evaluating:  94%|█████████▍| 155/165 [00:56<00:03,  2.72it/s]Evaluating:  95%|█████████▍| 156/165 [00:57<00:03,  2.67it/s]Evaluating:  95%|█████████▌| 157/165 [00:57<00:03,  2.65it/s]Evaluating:  96%|█████████▌| 158/165 [00:57<00:02,  2.69it/s]Evaluating:  96%|█████████▋| 159/165 [00:58<00:02,  2.71it/s]Evaluating:  97%|█████████▋| 160/165 [00:58<00:01,  2.72it/s]Evaluating:  98%|█████████▊| 161/165 [00:58<00:01,  2.73it/s]Evaluating:  98%|█████████▊| 162/165 [00:59<00:01,  2.74it/s]Evaluating:  99%|█████████▉| 163/165 [00:59<00:00,  2.73it/s]Evaluating:  99%|█████████▉| 164/165 [01:00<00:00,  2.74it/s]Evaluating: 100%|██████████| 165/165 [01:00<00:00,  2.98it/s]Evaluating: 100%|██████████| 165/165 [01:00<00:00,  2.74it/s]
05/09/2022 20:05:28 - INFO - __main__ -     Evaluation done in total 60.272403 secs (0.045730 sec per example)
05/09/2022 20:05:32 - INFO - __main__ -   Results: {'exact': 58.23529411764706, 'f1': 76.21482586200361, 'total': 1190, 'HasAns_exact': 58.23529411764706, 'HasAns_f1': 76.21482586200361, 'HasAns_total': 1190, 'best_exact': 58.23529411764706, 'best_exact_thresh': 0.0, 'best_f1': 76.21482586200361, 'best_f1_thresh': 0.0}
  vi 
2022-05-09 20:05:38.519944: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0
05/09/2022 20:05:45 - WARNING - __main__ -   Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, 16-bits training: False
You are using a model of type xlm-roberta to instantiate a model of type xlm. This is not supported for all configurations of models and can yield errors.
Some weights of the model checkpoint at /cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//squad/xlm-KG_LR8e-6_EPOCH2.0_maxlen384_batchsize4_gradacc4 were not used when initializing XLMRobertaModel: ['base_model.encoder.layer.15.attention.output.LayerNorm.bias', 'base_model.encoder.layer.5.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.0.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.12.attention.output.dense.bias', 'base_model.encoder.layer.5.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.8.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.21.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.6.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.12.output.LayerNorm.bias', 'base_model.encoder.layer.12.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.16.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.2.attention.self.value.weight', 'base_model.encoder.layer.12.intermediate.dense.bias', 'base_model.encoder.layer.4.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.15.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.21.intermediate.dense.bias', 'base_model.encoder.layer.8.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.3.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.10.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.12.output.LayerNorm.weight', 'base_model.encoder.layer.13.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.15.attention.output.dense.bias', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.19.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.22.attention.output.dense.weight', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.10.attention.self.value.bias', 'base_model.encoder.layer.2.output.LayerNorm.weight', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.17.attention.self.key.weight', 'base_model.encoder.layer.20.attention.self.value.weight', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.9.attention.self.query.weight', 'base_model.encoder.layer.10.attention.self.query.bias', 'base_model.encoder.layer.11.attention.self.query.bias', 'base_model.encoder.layer.8.output.LayerNorm.weight', 'base_model.encoder.layer.16.output.LayerNorm.bias', 'base_model.encoder.layer.18.attention.self.query.bias', 'base_model.encoder.layer.23.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.8.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.21.output.dense.bias', 'base_model.encoder.layer.15.attention.self.query.weight', 'base_model.encoder.layer.23.attention.output.dense.bias', 'base_model.encoder.layer.9.attention.self.value.weight', 'base_model.encoder.layer.17.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.1.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.9.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.12.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.4.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.18.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.18.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.19.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.16.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.7.output.LayerNorm.bias', 'base_model.encoder.layer.4.attention.output.LayerNorm.bias', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.9.output.dense.weight', 'base_model.encoder.layer.23.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.5.attention.self.value.weight', 'base_model.encoder.layer.15.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.20.attention.self.value.bias', 'base_model.encoder.layer.23.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.14.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.5.attention.self.value.bias', 'base_model.encoder.layer.20.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.8.attention.self.query.bias', 'base_model.encoder.layer.11.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.3.attention.self.value.weight', 'base_model.encoder.layer.2.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.3.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.17.output.dense.weight', 'base_model.encoder.layer.19.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.13.attention.output.dense.weight', 'base_model.encoder.layer.2.attention.output.dense.weight', 'base_model.encoder.layer.12.output.dense.bias', 'base_model.encoder.layer.14.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.6.attention.output.dense.bias', 'base_model.encoder.layer.9.attention.self.query.bias', 'base_model.pooler.dense.bias', 'base_model.encoder.layer.0.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.17.attention.output.LayerNorm.bias', 'base_model.encoder.layer.5.output.dense.bias', 'base_model.encoder.layer.18.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.13.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.16.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.9.output.dense.bias', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.4.attention.self.value.weight', 'base_model.encoder.layer.15.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.19.attention.output.LayerNorm.bias', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.14.output.dense.bias', 'base_model.encoder.layer.5.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.6.output.dense.weight', 'base_model.encoder.layer.19.output.LayerNorm.bias', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.22.output.dense.bias', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.18.intermediate.dense.weight', 'base_model.encoder.layer.17.attention.output.LayerNorm.weight', 'base_model.encoder.layer.17.intermediate.dense.weight', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.19.attention.self.key.weight', 'base_model.encoder.layer.3.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.23.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.18.output.dense.bias', 'base_model.encoder.layer.6.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.11.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.23.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.19.output.LayerNorm.weight', 'base_model.encoder.layer.12.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.1.output.dense.weight', 'base_model.encoder.layer.17.output.dense.bias', 'base_model.encoder.layer.5.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.8.attention.output.dense.weight', 'base_model.encoder.layer.18.attention.output.dense.weight', 'base_model.encoder.layer.5.attention.output.LayerNorm.bias', 'base_model.encoder.layer.20.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.21.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.13.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.3.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.13.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.12.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.23.attention.self.key.bias', 'base_model.encoder.layer.11.intermediate.dense.weight', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.8.output.dense.bias', 'base_model.encoder.layer.13.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.0.attention.self.query.weight', 'base_model.encoder.layer.13.output.LayerNorm.bias', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.9.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.1.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.10.attention.self.key.weight', 'base_model.encoder.layer.7.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.16.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.12.attention.output.dense.weight', 'base_model.encoder.layer.8.attention.output.LayerNorm.bias', 'base_model.encoder.layer.13.attention.output.dense.bias', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.13.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.12.attention.output.LayerNorm.weight', 'base_model.encoder.layer.15.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.22.intermediate.dense.weight', 'base_model.encoder.layer.18.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.23.attention.output.LayerNorm.bias', 'base_model.encoder.layer.22.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.4.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.20.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.2.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.15.output.dense.weight', 'base_model.encoder.layer.15.output.LayerNorm.bias', 'base_model.encoder.layer.3.attention.output.dense.weight', 'base_model.encoder.layer.21.attention.output.dense.bias', 'base_model.encoder.layer.6.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.9.output.LayerNorm.bias', 'base_model.encoder.layer.6.intermediate.dense.weight', 'base_model.encoder.layer.14.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.0.output.dense.weight', 'base_model.encoder.layer.2.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.9.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.14.output.LayerNorm.weight', 'base_model.encoder.layer.23.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.22.intermediate.dense.bias', 'base_model.encoder.layer.0.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.14.output.dense.weight', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.7.attention.output.LayerNorm.weight', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.3.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.4.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.10.attention.output.dense.bias', 'base_model.encoder.layer.11.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.17.output.LayerNorm.bias', 'base_model.encoder.layer.6.attention.self.value.bias', 'base_model.encoder.layer.13.attention.self.key.bias', 'base_model.encoder.layer.18.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.embeddings.LayerNorm.weight', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.21.attention.self.value.bias', 'base_model.encoder.layer.20.attention.output.dense.weight', 'base_model.encoder.layer.22.attention.self.key.weight', 'base_model.encoder.layer.6.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.6.attention.output.dense.weight', 'base_model.encoder.layer.6.attention.output.LayerNorm.weight', 'base_model.encoder.layer.7.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.6.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.4.attention.self.key.weight', 'base_model.encoder.layer.12.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.13.attention.output.LayerNorm.bias', 'base_model.encoder.layer.14.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.0.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.2.attention.output.LayerNorm.weight', 'base_model.encoder.layer.9.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.22.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.14.attention.self.key.weight', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.0.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.6.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.0.attention.output.LayerNorm.weight', 'base_model.encoder.layer.21.attention.self.key.weight', 'base_model.encoder.layer.5.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.5.intermediate.dense.weight', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.7.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.1.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.15.attention.self.key.weight', 'base_model.encoder.layer.16.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.11.intermediate.dense.bias', 'base_model.encoder.layer.6.attention.self.value.weight', 'base_model.encoder.layer.13.attention.self.value.weight', 'base_model.encoder.layer.2.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.15.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.20.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.17.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.0.intermediate.dense.weight', 'base_model.encoder.layer.20.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.17.output.LayerNorm.weight', 'base_model.encoder.layer.1.output.LayerNorm.weight', 'base_model.encoder.layer.7.attention.output.dense.weight', 'base_model.encoder.layer.17.attention.self.query.weight', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.12.attention.self.query.bias', 'base_model.encoder.layer.9.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.13.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.9.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.18.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.3.attention.self.key.weight', 'base_model.encoder.layer.8.intermediate.dense.weight', 'base_model.encoder.layer.14.intermediate.dense.weight', 'base_model.encoder.layer.9.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.8.output.adapters.es.adapter_up.bias', 'qa_outputs.bias', 'base_model.encoder.layer.11.output.dense.bias', 'base_model.encoder.layer.4.output.dense.weight', 'base_model.encoder.layer.9.attention.output.LayerNorm.bias', 'base_model.encoder.layer.21.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.13.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.15.intermediate.dense.bias', 'base_model.encoder.layer.3.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.16.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.1.attention.self.value.bias', 'base_model.encoder.layer.20.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.5.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.10.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.6.attention.self.query.weight', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.17.attention.self.value.bias', 'base_model.encoder.layer.15.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.16.attention.self.query.weight', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.18.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.3.output.LayerNorm.weight', 'base_model.encoder.layer.4.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.9.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.5.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.10.attention.self.key.bias', 'base_model.encoder.layer.18.attention.self.key.weight', 'base_model.encoder.layer.23.intermediate.dense.weight', 'base_model.encoder.layer.16.attention.self.value.weight', 'base_model.encoder.layer.18.output.dense.weight', 'base_model.encoder.layer.15.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.22.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.1.attention.output.LayerNorm.bias', 'base_model.encoder.layer.22.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.0.attention.output.dense.weight', 'base_model.encoder.layer.21.output.LayerNorm.weight', 'base_model.encoder.layer.2.attention.self.value.bias', 'base_model.encoder.layer.11.attention.self.key.weight', 'base_model.encoder.layer.7.attention.self.query.bias', 'base_model.encoder.layer.6.output.LayerNorm.bias', 'base_model.encoder.layer.23.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.6.attention.self.query.bias', 'base_model.encoder.layer.18.attention.self.key.bias', 'base_model.encoder.layer.9.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.9.attention.output.LayerNorm.weight', 'base_model.encoder.layer.7.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.20.output.LayerNorm.weight', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.14.attention.self.value.weight', 'base_model.encoder.layer.7.output.LayerNorm.weight', 'base_model.encoder.layer.9.output.LayerNorm.weight', 'base_model.encoder.layer.1.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.0.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.20.intermediate.dense.weight', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.21.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.15.attention.self.value.weight', 'base_model.encoder.layer.11.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.1.output.LayerNorm.bias', 'base_model.encoder.layer.19.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.20.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.21.attention.output.dense.weight', 'base_model.encoder.layer.15.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.6.attention.output.LayerNorm.bias', 'base_model.encoder.layer.6.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.16.intermediate.dense.bias', 'base_model.encoder.layer.14.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.5.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.20.output.dense.weight', 'base_model.encoder.layer.20.attention.self.query.weight', 'base_model.encoder.layer.20.attention.output.LayerNorm.weight', 'base_model.encoder.layer.21.attention.self.query.weight', 'base_model.encoder.layer.10.attention.output.LayerNorm.bias', 'base_model.embeddings.position_embeddings.weight', 'base_model.encoder.layer.14.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.2.output.dense.weight', 'base_model.encoder.layer.20.attention.self.key.weight', 'base_model.encoder.layer.22.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.19.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.7.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.9.attention.self.value.bias', 'base_model.encoder.layer.9.intermediate.dense.weight', 'base_model.encoder.layer.13.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.10.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.22.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.9.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.13.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.13.attention.self.query.weight', 'base_model.encoder.layer.6.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.8.attention.self.query.weight', 'base_model.encoder.layer.17.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.17.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.22.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.11.output.LayerNorm.weight', 'base_model.encoder.layer.12.attention.self.value.weight', 'base_model.encoder.layer.13.attention.self.query.bias', 'base_model.encoder.layer.23.attention.self.query.bias', 'base_model.encoder.layer.9.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.0.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.15.output.LayerNorm.weight', 'base_model.encoder.layer.16.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.5.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.9.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.5.intermediate.dense.bias', 'base_model.encoder.layer.21.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.8.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.21.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.21.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.18.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.15.attention.self.query.bias', 'base_model.encoder.layer.16.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.14.output.LayerNorm.bias', 'base_model.encoder.layer.11.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.12.attention.self.key.weight', 'base_model.encoder.layer.7.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.7.output.dense.bias', 'base_model.encoder.layer.10.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.2.attention.self.query.bias', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.8.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.22.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.16.output.dense.bias', 'base_model.encoder.layer.8.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.21.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.4.attention.self.query.weight', 'base_model.encoder.layer.5.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.1.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.13.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.6.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.18.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.1.attention.self.query.bias', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.5.attention.self.key.bias', 'base_model.encoder.layer.10.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.4.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.15.attention.output.LayerNorm.weight', 'base_model.encoder.layer.9.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.2.intermediate.dense.weight', 'base_model.encoder.layer.1.attention.output.dense.bias', 'base_model.encoder.layer.0.output.dense.bias', 'base_model.encoder.layer.12.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.11.output.LayerNorm.bias', 'base_model.encoder.layer.17.intermediate.dense.bias', 'base_model.encoder.layer.13.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.21.attention.self.value.weight', 'base_model.encoder.layer.14.attention.self.query.bias', 'base_model.encoder.layer.13.attention.self.value.bias', 'base_model.encoder.layer.17.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.4.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.6.output.dense.bias', 'base_model.encoder.layer.22.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.10.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.17.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.12.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.11.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.4.intermediate.dense.bias', 'base_model.encoder.layer.7.attention.self.query.weight', 'base_model.encoder.layer.7.attention.output.LayerNorm.bias', 'base_model.encoder.layer.21.output.dense.weight', 'base_model.encoder.layer.2.attention.output.dense.bias', 'base_model.encoder.layer.0.attention.self.query.bias', 'base_model.encoder.layer.17.attention.self.query.bias', 'base_model.encoder.layer.18.attention.self.value.bias', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.10.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.5.attention.self.query.bias', 'base_model.encoder.layer.10.intermediate.dense.weight', 'base_model.encoder.layer.2.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.8.attention.self.key.bias', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.18.attention.self.query.weight', 'base_model.encoder.layer.22.output.LayerNorm.weight', 'base_model.encoder.layer.10.output.LayerNorm.bias', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.23.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.0.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.11.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.16.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.3.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.15.intermediate.dense.weight', 'base_model.encoder.layer.18.intermediate.dense.bias', 'base_model.encoder.layer.10.attention.self.query.weight', 'base_model.encoder.layer.16.attention.output.LayerNorm.weight', 'base_model.encoder.layer.4.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.3.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.13.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.2.output.LayerNorm.bias', 'base_model.encoder.layer.6.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.1.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.4.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.13.output.LayerNorm.weight', 'base_model.encoder.layer.4.attention.self.query.bias', 'base_model.encoder.layer.10.output.dense.bias', 'base_model.encoder.layer.14.attention.output.dense.weight', 'base_model.encoder.layer.13.attention.output.LayerNorm.weight', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.1.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.9.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.8.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.22.attention.self.value.weight', 'base_model.encoder.layer.4.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.5.output.LayerNorm.weight', 'base_model.encoder.layer.18.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.12.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.19.attention.self.query.weight', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.12.attention.output.LayerNorm.bias', 'base_model.encoder.layer.19.attention.self.value.weight', 'base_model.encoder.layer.15.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.18.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.2.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.11.attention.output.dense.weight', 'base_model.encoder.layer.14.attention.self.key.bias', 'base_model.encoder.layer.22.attention.self.query.bias', 'base_model.encoder.layer.1.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.19.output.dense.bias', 'base_model.encoder.layer.12.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.9.attention.self.key.bias', 'base_model.encoder.layer.13.intermediate.dense.weight', 'base_model.encoder.layer.8.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.23.attention.output.dense.weight', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.7.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.15.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.5.output.dense.weight', 'base_model.encoder.layer.22.output.dense.weight', 'base_model.encoder.layer.23.output.dense.weight', 'base_model.encoder.layer.16.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.9.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.6.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.7.attention.self.value.bias', 'base_model.encoder.layer.1.attention.self.key.bias', 'base_model.encoder.layer.21.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.8.output.LayerNorm.bias', 'base_model.encoder.layer.11.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.17.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.8.output.dense.weight', 'base_model.encoder.layer.20.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.9.attention.self.key.weight', 'base_model.encoder.layer.1.intermediate.dense.weight', 'base_model.encoder.layer.3.attention.self.query.bias', 'base_model.encoder.layer.9.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.10.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.20.attention.output.LayerNorm.bias', 'base_model.encoder.layer.20.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.18.attention.self.value.weight', 'base_model.encoder.layer.6.intermediate.dense.bias', 'base_model.encoder.layer.13.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.15.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.7.intermediate.dense.weight', 'base_model.encoder.layer.10.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.4.output.LayerNorm.bias', 'base_model.encoder.layer.11.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.2.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.21.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.17.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.3.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.22.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.23.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.17.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.22.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.20.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.7.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.3.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.7.attention.output.dense.bias', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.0.attention.self.key.bias', 'base_model.encoder.layer.14.attention.output.dense.bias', 'base_model.encoder.layer.14.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.20.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.8.attention.self.value.weight', 'base_model.encoder.layer.20.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.23.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.21.output.LayerNorm.bias', 'base_model.encoder.layer.21.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.1.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.8.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.16.attention.output.dense.bias', 'base_model.encoder.layer.16.attention.self.value.bias', 'base_model.encoder.layer.19.attention.self.value.bias', 'base_model.encoder.layer.7.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.4.attention.self.key.bias', 'base_model.encoder.layer.23.attention.self.value.bias', 'base_model.encoder.layer.5.attention.self.query.weight', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.4.output.dense.bias', 'base_model.encoder.layer.1.intermediate.dense.bias', 'base_model.encoder.layer.22.attention.output.dense.bias', 'base_model.encoder.layer.3.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.18.attention.output.LayerNorm.weight', 'base_model.encoder.layer.3.intermediate.dense.weight', 'base_model.encoder.layer.15.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.11.attention.self.query.weight', 'base_model.encoder.layer.4.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.7.attention.self.value.weight', 'base_model.encoder.layer.14.intermediate.dense.bias', 'base_model.encoder.layer.3.output.LayerNorm.bias', 'base_model.encoder.layer.0.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.13.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.16.output.LayerNorm.weight', 'base_model.encoder.layer.21.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.1.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.5.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.8.attention.self.key.weight', 'base_model.encoder.layer.19.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.11.output.dense.weight', 'base_model.encoder.layer.0.output.LayerNorm.bias', 'base_model.encoder.layer.15.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.11.attention.self.value.weight', 'base_model.encoder.layer.16.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.18.output.LayerNorm.weight', 'base_model.encoder.layer.19.intermediate.dense.weight', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.pooler.dense.weight', 'base_model.encoder.layer.10.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.3.attention.output.dense.bias', 'base_model.encoder.layer.6.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.14.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.8.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.16.attention.self.key.bias', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.23.attention.self.value.weight', 'base_model.encoder.layer.3.attention.self.query.weight', 'base_model.encoder.layer.18.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.21.attention.self.query.bias', 'base_model.encoder.layer.1.attention.self.key.weight', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.10.output.dense.weight', 'base_model.encoder.layer.0.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.19.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.15.attention.self.value.bias', 'base_model.encoder.layer.14.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.10.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.7.attention.self.key.weight', 'base_model.encoder.layer.3.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.3.output.adapters.es.adapter_down.0.weight', 'base_model.embeddings.position_ids', 'base_model.encoder.layer.20.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.2.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.17.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.18.attention.output.LayerNorm.bias', 'base_model.encoder.layer.16.attention.self.query.bias', 'base_model.encoder.layer.1.attention.output.dense.weight', 'base_model.encoder.layer.19.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.16.attention.output.LayerNorm.bias', 'base_model.encoder.layer.14.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.23.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.12.output.dense.weight', 'base_model.encoder.layer.13.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.19.attention.output.LayerNorm.weight', 'base_model.encoder.layer.19.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.1.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.2.attention.self.key.weight', 'base_model.encoder.layer.3.attention.self.value.bias', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.22.attention.self.query.weight', 'base_model.encoder.layer.6.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.23.output.LayerNorm.bias', 'base_model.encoder.layer.5.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.7.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.4.attention.output.dense.bias', 'base_model.encoder.layer.18.output.LayerNorm.bias', 'base_model.encoder.layer.23.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.5.output.LayerNorm.bias', 'base_model.encoder.layer.11.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.0.attention.output.LayerNorm.bias', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.21.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.21.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.2.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.7.intermediate.dense.bias', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.10.attention.self.value.weight', 'base_model.encoder.layer.14.attention.output.LayerNorm.bias', 'base_model.encoder.layer.10.attention.output.dense.weight', 'base_model.encoder.layer.17.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.10.attention.output.LayerNorm.weight', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.2.intermediate.dense.bias', 'base_model.encoder.layer.16.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.16.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.4.attention.output.LayerNorm.weight', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.10.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.11.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.19.attention.self.query.bias', 'base_model.encoder.layer.12.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.10.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.18.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.23.attention.output.LayerNorm.weight', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.22.attention.self.key.bias', 'base_model.encoder.layer.19.attention.output.dense.weight', 'base_model.encoder.layer.19.attention.self.key.bias', 'base_model.encoder.layer.13.intermediate.dense.bias', 'base_model.encoder.layer.11.attention.self.key.bias', 'base_model.encoder.layer.10.intermediate.dense.bias', 'base_model.encoder.layer.15.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.4.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.23.attention.self.query.weight', 'base_model.encoder.layer.11.output.adapters.ep.adapter_up.bias', 'base_model.embeddings.token_type_embeddings.weight', 'base_model.encoder.layer.7.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.12.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.20.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.20.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.7.output.dense.weight', 'base_model.encoder.layer.14.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.8.attention.output.dense.bias', 'base_model.encoder.layer.17.attention.self.key.bias', 'base_model.encoder.layer.16.output.dense.weight', 'base_model.encoder.layer.5.attention.output.dense.weight', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.20.attention.self.query.bias', 'base_model.encoder.layer.1.output.dense.bias', 'base_model.encoder.layer.3.output.dense.bias', 'base_model.encoder.layer.10.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.11.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.9.attention.output.dense.bias', 'base_model.encoder.layer.12.intermediate.dense.weight', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.22.output.LayerNorm.bias', 'base_model.encoder.layer.18.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.15.attention.output.dense.weight', 'base_model.encoder.layer.23.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.14.attention.self.query.weight', 'base_model.encoder.layer.7.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.14.attention.self.value.bias', 'base_model.encoder.layer.16.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.8.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.4.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.19.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.3.attention.output.LayerNorm.weight', 'base_model.encoder.layer.3.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.14.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.5.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.18.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.12.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.16.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.5.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.2.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.0.attention.self.value.bias', 'base_model.encoder.layer.7.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.19.attention.output.dense.bias', 'base_model.encoder.layer.16.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.15.attention.self.key.bias', 'base_model.encoder.layer.9.intermediate.dense.bias', 'base_model.encoder.layer.5.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.6.output.LayerNorm.weight', 'base_model.encoder.layer.12.attention.self.query.weight', 'base_model.encoder.layer.0.intermediate.dense.bias', 'base_model.encoder.layer.19.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.5.attention.output.dense.bias', 'base_model.encoder.layer.8.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.23.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.2.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.2.output.dense.bias', 'base_model.encoder.layer.4.attention.self.value.bias', 'base_model.encoder.layer.11.attention.output.LayerNorm.bias', 'base_model.encoder.layer.13.output.dense.bias', 'base_model.encoder.layer.0.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.4.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.4.output.LayerNorm.weight', 'base_model.encoder.layer.7.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.14.attention.output.LayerNorm.weight', 'base_model.encoder.layer.12.attention.self.value.bias', 'base_model.encoder.layer.14.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.22.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.23.attention.self.key.weight', 'base_model.encoder.layer.2.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.0.output.LayerNorm.weight', 'base_model.encoder.layer.15.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.11.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.0.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.16.intermediate.dense.weight', 'base_model.encoder.layer.17.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.17.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.0.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.0.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.20.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.6.attention.self.key.weight', 'base_model.encoder.layer.22.attention.output.LayerNorm.bias', 'base_model.encoder.layer.0.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.15.output.dense.bias', 'base_model.encoder.layer.1.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.21.attention.output.LayerNorm.bias', 'base_model.encoder.layer.21.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.3.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.2.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.6.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.20.attention.self.key.bias', 'base_model.encoder.layer.2.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.7.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.3.output.dense.weight', 'base_model.encoder.layer.17.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.21.attention.output.LayerNorm.weight', 'base_model.encoder.layer.2.attention.self.key.bias', 'base_model.encoder.layer.2.attention.output.LayerNorm.bias', 'base_model.encoder.layer.23.output.LayerNorm.weight', 'base_model.encoder.layer.11.attention.output.dense.bias', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.1.attention.self.value.weight', 'base_model.encoder.layer.19.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.5.attention.output.LayerNorm.weight', 'base_model.encoder.layer.13.output.dense.weight', 'base_model.encoder.layer.1.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.8.intermediate.dense.bias', 'base_model.encoder.layer.17.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.17.attention.self.value.weight', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.10.output.LayerNorm.weight', 'base_model.encoder.layer.10.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.11.attention.output.LayerNorm.weight', 'base_model.encoder.layer.21.attention.self.key.bias', 'base_model.encoder.layer.9.attention.output.dense.weight', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.19.output.adapters.ts.adapter_up.bias', 'base_model.embeddings.word_embeddings.weight', 'base_model.encoder.layer.11.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.8.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.22.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.16.attention.output.dense.weight', 'base_model.encoder.layer.2.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.6.attention.self.key.bias', 'base_model.encoder.layer.1.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.12.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'qa_outputs.weight', 'base_model.encoder.layer.5.attention.self.key.weight', 'base_model.encoder.layer.18.attention.output.dense.bias', 'base_model.encoder.layer.12.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.10.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.11.attention.self.value.bias', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.17.attention.output.dense.bias', 'base_model.encoder.layer.20.output.LayerNorm.bias', 'base_model.encoder.layer.3.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.0.attention.self.key.weight', 'base_model.encoder.layer.19.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.6.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.19.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.7.attention.self.key.bias', 'base_model.encoder.layer.15.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.19.intermediate.dense.bias', 'base_model.encoder.layer.22.attention.self.value.bias', 'base_model.encoder.layer.23.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.0.attention.self.value.weight', 'base_model.encoder.layer.11.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.14.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.18.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.4.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.4.attention.output.dense.weight', 'base_model.encoder.layer.8.attention.self.value.bias', 'base_model.encoder.layer.1.attention.output.LayerNorm.weight', 'base_model.encoder.layer.3.attention.self.key.bias', 'base_model.encoder.layer.8.attention.output.LayerNorm.weight', 'base_model.encoder.layer.21.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.20.attention.output.dense.bias', 'base_model.encoder.layer.19.output.dense.weight', 'base_model.encoder.layer.23.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.4.intermediate.dense.weight', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.21.intermediate.dense.weight', 'base_model.encoder.layer.22.attention.output.LayerNorm.weight', 'base_model.encoder.layer.1.attention.self.query.weight', 'base_model.encoder.layer.3.intermediate.dense.bias', 'base_model.encoder.layer.23.intermediate.dense.bias', 'base_model.encoder.layer.12.attention.self.key.bias', 'base_model.encoder.layer.22.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.1.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.7.output.adapters.ep.adapter_up.weight', 'base_model.embeddings.LayerNorm.bias', 'base_model.encoder.layer.6.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.14.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.8.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.22.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.0.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.22.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.20.intermediate.dense.bias', 'base_model.encoder.layer.20.output.dense.bias', 'base_model.encoder.layer.2.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.14.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.3.attention.output.LayerNorm.bias', 'base_model.encoder.layer.12.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.1.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.5.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.2.attention.self.query.weight', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.12.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.13.attention.self.key.weight', 'base_model.encoder.layer.19.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.23.output.dense.bias', 'base_model.encoder.layer.17.attention.output.dense.weight', 'base_model.encoder.layer.16.attention.self.key.weight', 'base_model.encoder.layer.8.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.17.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.4.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.0.attention.output.dense.bias']
- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of XLMRobertaModel were not initialized from the model checkpoint at /cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//squad/xlm-KG_LR8e-6_EPOCH2.0_maxlen384_batchsize4_gradacc4 and are newly initialized: ['encoder.layer.21.attention.self.key.weight', 'encoder.layer.19.output.dense.bias', 'encoder.layer.9.attention.self.key.weight', 'encoder.layer.18.attention.output.dense.weight', 'encoder.layer.20.output.LayerNorm.bias', 'encoder.layer.8.attention.self.value.bias', 'encoder.layer.17.intermediate.dense.bias', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.23.attention.self.query.bias', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.16.attention.self.query.bias', 'encoder.layer.17.output.LayerNorm.weight', 'encoder.layer.3.attention.output.dense.bias', 'encoder.layer.17.output.LayerNorm.bias', 'encoder.layer.4.attention.output.dense.weight', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.5.attention.self.value.weight', 'encoder.layer.14.attention.self.query.weight', 'encoder.layer.22.output.dense.bias', 'encoder.layer.5.output.dense.bias', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.1.attention.self.key.weight', 'encoder.layer.14.attention.output.LayerNorm.bias', 'encoder.layer.13.intermediate.dense.weight', 'encoder.layer.0.attention.self.key.weight', 'encoder.layer.2.attention.output.dense.weight', 'encoder.layer.12.output.dense.bias', 'encoder.layer.5.attention.output.dense.weight', 'encoder.layer.17.attention.self.value.bias', 'encoder.layer.22.attention.self.query.bias', 'encoder.layer.11.output.dense.bias', 'encoder.layer.6.attention.output.dense.weight', 'encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.layer.14.output.LayerNorm.weight', 'encoder.layer.4.output.dense.weight', 'encoder.layer.21.attention.self.value.weight', 'encoder.layer.18.output.LayerNorm.bias', 'encoder.layer.7.attention.output.LayerNorm.bias', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.16.attention.self.value.bias', 'encoder.layer.8.attention.self.value.weight', 'encoder.layer.22.attention.output.dense.weight', 'encoder.layer.9.attention.output.dense.bias', 'encoder.layer.11.attention.output.dense.weight', 'encoder.layer.8.attention.output.LayerNorm.weight', 'encoder.layer.8.output.dense.bias', 'encoder.layer.18.attention.self.query.bias', 'encoder.layer.23.output.LayerNorm.bias', 'encoder.layer.7.attention.self.value.bias', 'encoder.layer.18.intermediate.dense.bias', 'encoder.layer.15.intermediate.dense.bias', 'encoder.layer.16.attention.self.value.weight', 'encoder.layer.16.attention.self.key.bias', 'encoder.layer.22.attention.self.key.weight', 'encoder.layer.1.attention.self.query.bias', 'encoder.layer.14.attention.self.value.bias', 'encoder.layer.21.output.LayerNorm.weight', 'encoder.layer.12.attention.self.query.bias', 'encoder.layer.0.attention.output.LayerNorm.weight', 'encoder.layer.1.output.dense.weight', 'encoder.layer.20.attention.output.LayerNorm.weight', 'encoder.layer.10.attention.self.value.weight', 'encoder.layer.0.attention.self.key.bias', 'encoder.layer.6.attention.self.value.weight', 'encoder.layer.20.attention.self.key.weight', 'encoder.layer.11.output.LayerNorm.bias', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.18.attention.self.value.weight', 'encoder.layer.4.attention.self.query.weight', 'encoder.layer.6.output.LayerNorm.bias', 'encoder.layer.17.attention.output.LayerNorm.weight', 'encoder.layer.2.attention.self.value.weight', 'encoder.layer.6.attention.self.key.bias', 'encoder.layer.18.attention.output.LayerNorm.weight', 'encoder.layer.13.attention.self.query.weight', 'embeddings.word_embeddings.weight', 'encoder.layer.3.output.dense.bias', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.18.attention.output.dense.bias', 'encoder.layer.20.output.dense.weight', 'encoder.layer.17.attention.self.key.weight', 'encoder.layer.7.intermediate.dense.bias', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.18.output.dense.weight', 'encoder.layer.6.attention.output.dense.bias', 'encoder.layer.10.output.LayerNorm.weight', 'encoder.layer.15.output.dense.weight', 'encoder.layer.19.attention.self.key.weight', 'encoder.layer.22.attention.output.LayerNorm.weight', 'encoder.layer.17.attention.self.query.bias', 'encoder.layer.14.attention.output.dense.weight', 'encoder.layer.3.attention.self.query.bias', 'encoder.layer.12.attention.self.key.bias', 'encoder.layer.5.output.LayerNorm.bias', 'encoder.layer.10.attention.self.query.bias', 'encoder.layer.22.attention.self.query.weight', 'encoder.layer.5.attention.output.LayerNorm.weight', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.15.output.LayerNorm.bias', 'encoder.layer.21.attention.self.value.bias', 'encoder.layer.21.attention.output.LayerNorm.bias', 'encoder.layer.20.output.dense.bias', 'encoder.layer.9.attention.self.query.bias', 'encoder.layer.19.attention.output.LayerNorm.weight', 'encoder.layer.20.attention.output.dense.bias', 'encoder.layer.9.attention.self.value.bias', 'encoder.layer.19.intermediate.dense.bias', 'encoder.layer.20.output.LayerNorm.weight', 'encoder.layer.23.attention.self.query.weight', 'embeddings.position_embeddings.weight', 'encoder.layer.11.attention.self.value.bias', 'encoder.layer.14.output.dense.bias', 'encoder.layer.14.intermediate.dense.weight', 'encoder.layer.13.attention.output.dense.weight', 'encoder.layer.20.attention.self.value.bias', 'encoder.layer.12.output.LayerNorm.weight', 'encoder.layer.13.output.dense.bias', 'encoder.layer.14.attention.self.value.weight', 'encoder.layer.21.attention.self.key.bias', 'encoder.layer.21.attention.self.query.bias', 'encoder.layer.14.attention.output.LayerNorm.weight', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.10.output.LayerNorm.bias', 'encoder.layer.18.attention.self.key.weight', 'encoder.layer.15.attention.output.dense.weight', 'encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.layer.15.attention.self.value.weight', 'encoder.layer.17.attention.self.query.weight', 'embeddings.token_type_embeddings.weight', 'encoder.layer.10.attention.output.LayerNorm.weight', 'encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.18.attention.self.value.bias', 'encoder.layer.12.attention.output.dense.weight', 'encoder.layer.18.attention.self.query.weight', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.17.intermediate.dense.weight', 'encoder.layer.7.attention.self.query.bias', 'encoder.layer.12.output.LayerNorm.bias', 'encoder.layer.14.attention.self.query.bias', 'encoder.layer.14.attention.self.key.bias', 'encoder.layer.9.attention.output.LayerNorm.bias', 'encoder.layer.8.attention.self.key.bias', 'encoder.layer.8.output.LayerNorm.bias', 'encoder.layer.7.attention.output.LayerNorm.weight', 'encoder.layer.3.attention.self.key.weight', 'encoder.layer.14.output.dense.weight', 'encoder.layer.1.attention.output.dense.bias', 'encoder.layer.18.output.dense.bias', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.16.output.LayerNorm.weight', 'encoder.layer.0.output.dense.weight', 'encoder.layer.5.attention.output.dense.bias', 'encoder.layer.4.attention.output.dense.bias', 'encoder.layer.1.attention.self.query.weight', 'encoder.layer.19.output.LayerNorm.bias', 'encoder.layer.23.attention.output.dense.weight', 'encoder.layer.16.output.dense.weight', 'embeddings.LayerNorm.bias', 'encoder.layer.13.attention.output.LayerNorm.weight', 'encoder.layer.15.attention.self.key.weight', 'encoder.layer.12.attention.output.LayerNorm.bias', 'encoder.layer.18.output.LayerNorm.weight', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.15.attention.output.LayerNorm.weight', 'encoder.layer.11.attention.self.key.weight', 'encoder.layer.5.attention.self.key.weight', 'encoder.layer.17.output.dense.bias', 'encoder.layer.19.output.dense.weight', 'encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.0.attention.self.query.weight', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.2.attention.output.dense.bias', 'encoder.layer.15.attention.self.query.bias', 'encoder.layer.15.intermediate.dense.weight', 'encoder.layer.10.output.dense.weight', 'encoder.layer.23.attention.output.LayerNorm.weight', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.16.attention.self.key.weight', 'encoder.layer.20.attention.self.query.weight', 'encoder.layer.3.attention.self.key.bias', 'encoder.layer.8.output.dense.weight', 'encoder.layer.20.intermediate.dense.weight', 'encoder.layer.21.attention.output.dense.bias', 'encoder.layer.10.attention.output.dense.weight', 'encoder.layer.21.intermediate.dense.weight', 'encoder.layer.12.attention.self.query.weight', 'encoder.layer.13.output.LayerNorm.weight', 'encoder.layer.22.attention.self.value.weight', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.18.attention.output.LayerNorm.bias', 'encoder.layer.12.attention.output.LayerNorm.weight', 'encoder.layer.17.output.dense.weight', 'encoder.layer.23.attention.self.key.bias', 'encoder.layer.3.attention.output.dense.weight', 'encoder.layer.9.attention.self.key.bias', 'encoder.layer.6.attention.output.LayerNorm.bias', 'encoder.layer.21.output.LayerNorm.bias', 'encoder.layer.0.attention.output.dense.bias', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.20.attention.self.query.bias', 'encoder.layer.22.output.LayerNorm.bias', 'encoder.layer.2.output.dense.weight', 'encoder.layer.15.attention.output.LayerNorm.bias', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.5.output.dense.weight', 'encoder.layer.11.attention.self.query.weight', 'encoder.layer.21.output.dense.bias', 'encoder.layer.9.output.dense.weight', 'encoder.layer.12.output.dense.weight', 'encoder.layer.9.attention.self.query.weight', 'encoder.layer.6.output.dense.weight', 'encoder.layer.2.output.dense.bias', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.16.intermediate.dense.weight', 'encoder.layer.15.attention.self.query.weight', 'encoder.layer.2.attention.self.value.bias', 'encoder.layer.4.output.dense.bias', 'encoder.layer.23.output.dense.weight', 'encoder.layer.1.attention.self.key.bias', 'encoder.layer.4.attention.self.value.weight', 'encoder.layer.9.attention.self.value.weight', 'encoder.layer.11.output.LayerNorm.weight', 'encoder.layer.6.attention.self.value.bias', 'encoder.layer.11.attention.output.LayerNorm.weight', 'encoder.layer.16.attention.output.LayerNorm.bias', 'encoder.layer.17.attention.self.key.bias', 'encoder.layer.15.attention.output.dense.bias', 'encoder.layer.7.attention.output.dense.weight', 'encoder.layer.1.output.dense.bias', 'encoder.layer.12.intermediate.dense.bias', 'encoder.layer.19.attention.self.query.weight', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.19.attention.output.dense.weight', 'encoder.layer.20.attention.self.value.weight', 'encoder.layer.22.output.LayerNorm.weight', 'encoder.layer.10.attention.self.value.bias', 'encoder.layer.19.output.LayerNorm.weight', 'encoder.layer.4.attention.self.query.bias', 'encoder.layer.9.attention.output.dense.weight', 'encoder.layer.22.attention.self.key.bias', 'encoder.layer.7.output.dense.bias', 'encoder.layer.13.attention.self.value.bias', 'encoder.layer.3.attention.self.value.weight', 'encoder.layer.1.attention.self.value.bias', 'encoder.layer.13.attention.self.key.weight', 'encoder.layer.16.attention.output.LayerNorm.weight', 'encoder.layer.13.attention.output.dense.bias', 'encoder.layer.12.attention.self.key.weight', 'encoder.layer.0.attention.output.dense.weight', 'encoder.layer.12.attention.self.value.weight', 'encoder.layer.9.output.dense.bias', 'encoder.layer.5.attention.self.query.weight', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.22.attention.output.dense.bias', 'encoder.layer.15.attention.self.value.bias', 'encoder.layer.2.attention.self.query.bias', 'encoder.layer.2.attention.self.key.weight', 'encoder.layer.7.attention.self.key.bias', 'encoder.layer.17.attention.output.dense.bias', 'encoder.layer.20.intermediate.dense.bias', 'encoder.layer.3.output.LayerNorm.weight', 'embeddings.LayerNorm.weight', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.2.attention.output.LayerNorm.bias', 'encoder.layer.10.intermediate.dense.weight', 'encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.layer.23.attention.self.value.weight', 'encoder.layer.13.attention.self.value.weight', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.7.output.LayerNorm.bias', 'encoder.layer.16.output.LayerNorm.bias', 'encoder.layer.3.output.dense.weight', 'encoder.layer.9.output.LayerNorm.weight', 'encoder.layer.10.attention.output.LayerNorm.bias', 'pooler.dense.weight', 'encoder.layer.16.output.dense.bias', 'encoder.layer.8.attention.self.query.weight', 'encoder.layer.13.intermediate.dense.bias', 'encoder.layer.19.intermediate.dense.weight', 'encoder.layer.20.attention.output.dense.weight', 'encoder.layer.4.attention.self.value.bias', 'encoder.layer.11.attention.self.value.weight', 'encoder.layer.22.attention.output.LayerNorm.bias', 'encoder.layer.23.intermediate.dense.bias', 'encoder.layer.14.intermediate.dense.bias', 'encoder.layer.8.attention.output.dense.weight', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.6.attention.self.query.weight', 'encoder.layer.7.output.dense.weight', 'encoder.layer.8.output.LayerNorm.weight', 'pooler.dense.bias', 'encoder.layer.3.attention.self.query.weight', 'encoder.layer.13.attention.self.key.bias', 'encoder.layer.13.output.LayerNorm.bias', 'encoder.layer.16.attention.output.dense.weight', 'encoder.layer.10.attention.self.query.weight', 'encoder.layer.19.attention.self.value.bias', 'encoder.layer.14.attention.self.key.weight', 'encoder.layer.3.attention.self.value.bias', 'encoder.layer.7.attention.self.query.weight', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.0.attention.self.value.weight', 'encoder.layer.18.attention.self.key.bias', 'encoder.layer.23.intermediate.dense.weight', 'encoder.layer.0.attention.self.value.bias', 'encoder.layer.12.attention.self.value.bias', 'encoder.layer.17.attention.output.LayerNorm.bias', 'encoder.layer.14.attention.output.dense.bias', 'encoder.layer.9.output.LayerNorm.bias', 'encoder.layer.1.attention.output.LayerNorm.weight', 'encoder.layer.15.output.LayerNorm.weight', 'encoder.layer.23.attention.self.key.weight', 'encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.layer.2.attention.self.query.weight', 'encoder.layer.10.attention.output.dense.bias', 'encoder.layer.16.attention.output.dense.bias', 'encoder.layer.8.attention.self.key.weight', 'encoder.layer.19.attention.output.dense.bias', 'encoder.layer.7.attention.self.key.weight', 'encoder.layer.21.attention.output.LayerNorm.weight', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.6.output.dense.bias', 'encoder.layer.11.attention.self.key.bias', 'encoder.layer.15.output.dense.bias', 'encoder.layer.19.attention.self.query.bias', 'encoder.layer.2.attention.output.LayerNorm.weight', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.10.output.dense.bias', 'encoder.layer.21.attention.output.dense.weight', 'encoder.layer.21.output.dense.weight', 'encoder.layer.5.attention.self.query.bias', 'encoder.layer.22.intermediate.dense.weight', 'encoder.layer.21.intermediate.dense.bias', 'encoder.layer.13.attention.output.LayerNorm.bias', 'encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.layer.6.attention.self.query.bias', 'encoder.layer.6.attention.output.LayerNorm.weight', 'encoder.layer.19.attention.self.key.bias', 'encoder.layer.23.output.LayerNorm.weight', 'encoder.layer.20.attention.self.key.bias', 'encoder.layer.21.attention.self.query.weight', 'encoder.layer.23.output.dense.bias', 'encoder.layer.8.attention.output.dense.bias', 'encoder.layer.23.attention.self.value.bias', 'encoder.layer.22.attention.self.value.bias', 'encoder.layer.0.output.dense.bias', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.22.intermediate.dense.bias', 'encoder.layer.20.attention.output.LayerNorm.bias', 'encoder.layer.23.attention.output.LayerNorm.bias', 'encoder.layer.19.attention.output.LayerNorm.bias', 'encoder.layer.8.attention.self.query.bias', 'encoder.layer.7.output.LayerNorm.weight', 'encoder.layer.2.attention.self.key.bias', 'encoder.layer.19.attention.self.value.weight', 'encoder.layer.12.intermediate.dense.weight', 'encoder.layer.11.attention.self.query.bias', 'encoder.layer.5.attention.self.key.bias', 'encoder.layer.14.output.LayerNorm.bias', 'encoder.layer.7.attention.output.dense.bias', 'encoder.layer.17.attention.output.dense.weight', 'encoder.layer.5.attention.self.value.bias', 'encoder.layer.16.intermediate.dense.bias', 'encoder.layer.10.attention.self.key.weight', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.7.attention.self.value.weight', 'encoder.layer.1.attention.self.value.weight', 'encoder.layer.11.attention.output.dense.bias', 'encoder.layer.4.attention.self.key.weight', 'encoder.layer.17.attention.self.value.weight', 'encoder.layer.22.output.dense.weight', 'encoder.layer.13.attention.self.query.bias', 'encoder.layer.4.attention.output.LayerNorm.weight', 'encoder.layer.11.output.dense.weight', 'encoder.layer.9.attention.output.LayerNorm.weight', 'encoder.layer.4.attention.self.key.bias', 'encoder.layer.23.attention.output.dense.bias', 'encoder.layer.18.intermediate.dense.weight', 'encoder.layer.0.attention.self.query.bias', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.12.attention.output.dense.bias', 'encoder.layer.1.attention.output.dense.weight', 'encoder.layer.13.output.dense.weight', 'encoder.layer.10.attention.self.key.bias', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.16.attention.self.query.weight', 'encoder.layer.15.attention.self.key.bias', 'encoder.layer.8.attention.output.LayerNorm.bias', 'encoder.layer.6.attention.self.key.weight', 'encoder.layer.4.attention.output.LayerNorm.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Overwriting existing adapter 'ep'.
Overwriting existing adapter 'tp'.
Overwriting existing adapter 'es'.
Overwriting existing adapter 'ts'.
Overwriting existing adapter fusion module 'ep,tp,es,ts'
05/09/2022 20:06:18 - INFO - __main__ -   lang2id = None
05/09/2022 20:06:22 - INFO - __main__ -   Training/evaluation parameters Namespace(adam_epsilon=1e-08, cache_dir='', config_name='', data_dir=None, device=device(type='cuda'), do_eval=True, do_lower_case=False, do_train=False, doc_stride=128, eval_all_checkpoints=False, eval_lang='vi', evaluate_during_training=False, fp16=False, fp16_opt_level='O1', gradient_accumulation_steps=1, learning_rate=5e-05, local_rank=-1, logging_steps=50, max_answer_length=30, max_grad_norm=1.0, max_query_length=64, max_seq_length=384, max_steps=-1, model_name='xlm-KG', model_name_or_path='/cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//squad/xlm-KG_LR8e-6_EPOCH2.0_maxlen384_batchsize4_gradacc4', model_type='xlm', modelkg_dir='/cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/adapter/xlmr_adapter', n_best_size=20, n_gpu=1, no_cuda=False, null_score_diff_threshold=0.0, num_train_epochs=3.0, output_dir='/cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//squad/xlm-KG_LR8e-6_EPOCH2.0_maxlen384_batchsize4_gradacc4/predictions/xquad/', overwrite_cache=False, overwrite_output_dir=False, per_gpu_eval_batch_size=8, per_gpu_train_batch_size=8, predict_file='/cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/download//xquad//xquad.vi.json', save_steps=50, seed=42, server_ip='', server_port='', threads=1, tokenizer_name='', train_file=None, train_lang='en', verbose_logging=False, version_2_with_negative=False, warmup_steps=0, weight_decay=0.0)
05/09/2022 20:06:22 - INFO - __main__ -   Loading checkpoint /cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//squad/xlm-KG_LR8e-6_EPOCH2.0_maxlen384_batchsize4_gradacc4 for evaluation
05/09/2022 20:06:22 - INFO - __main__ -   Evaluate the following checkpoints: ['/cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//squad/xlm-KG_LR8e-6_EPOCH2.0_maxlen384_batchsize4_gradacc4']
Some weights of the model checkpoint at /cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//squad/xlm-KG_LR8e-6_EPOCH2.0_maxlen384_batchsize4_gradacc4 were not used when initializing XLMRobertaModel: ['base_model.encoder.layer.15.attention.output.LayerNorm.bias', 'base_model.encoder.layer.5.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.0.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.12.attention.output.dense.bias', 'base_model.encoder.layer.5.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.8.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.21.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.6.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.12.output.LayerNorm.bias', 'base_model.encoder.layer.12.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.16.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.2.attention.self.value.weight', 'base_model.encoder.layer.12.intermediate.dense.bias', 'base_model.encoder.layer.4.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.15.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.21.intermediate.dense.bias', 'base_model.encoder.layer.8.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.3.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.10.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.12.output.LayerNorm.weight', 'base_model.encoder.layer.13.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.15.attention.output.dense.bias', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.19.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.22.attention.output.dense.weight', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.10.attention.self.value.bias', 'base_model.encoder.layer.2.output.LayerNorm.weight', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.17.attention.self.key.weight', 'base_model.encoder.layer.20.attention.self.value.weight', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.9.attention.self.query.weight', 'base_model.encoder.layer.10.attention.self.query.bias', 'base_model.encoder.layer.11.attention.self.query.bias', 'base_model.encoder.layer.8.output.LayerNorm.weight', 'base_model.encoder.layer.16.output.LayerNorm.bias', 'base_model.encoder.layer.18.attention.self.query.bias', 'base_model.encoder.layer.23.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.8.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.21.output.dense.bias', 'base_model.encoder.layer.15.attention.self.query.weight', 'base_model.encoder.layer.23.attention.output.dense.bias', 'base_model.encoder.layer.9.attention.self.value.weight', 'base_model.encoder.layer.17.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.1.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.9.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.12.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.4.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.18.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.18.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.19.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.16.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.7.output.LayerNorm.bias', 'base_model.encoder.layer.4.attention.output.LayerNorm.bias', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.9.output.dense.weight', 'base_model.encoder.layer.23.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.5.attention.self.value.weight', 'base_model.encoder.layer.15.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.20.attention.self.value.bias', 'base_model.encoder.layer.23.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.14.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.5.attention.self.value.bias', 'base_model.encoder.layer.20.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.8.attention.self.query.bias', 'base_model.encoder.layer.11.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.3.attention.self.value.weight', 'base_model.encoder.layer.2.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.3.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.17.output.dense.weight', 'base_model.encoder.layer.19.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.13.attention.output.dense.weight', 'base_model.encoder.layer.2.attention.output.dense.weight', 'base_model.encoder.layer.12.output.dense.bias', 'base_model.encoder.layer.14.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.6.attention.output.dense.bias', 'base_model.encoder.layer.9.attention.self.query.bias', 'base_model.pooler.dense.bias', 'base_model.encoder.layer.0.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.17.attention.output.LayerNorm.bias', 'base_model.encoder.layer.5.output.dense.bias', 'base_model.encoder.layer.18.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.13.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.16.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.9.output.dense.bias', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.4.attention.self.value.weight', 'base_model.encoder.layer.15.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.19.attention.output.LayerNorm.bias', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.14.output.dense.bias', 'base_model.encoder.layer.5.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.6.output.dense.weight', 'base_model.encoder.layer.19.output.LayerNorm.bias', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.22.output.dense.bias', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.18.intermediate.dense.weight', 'base_model.encoder.layer.17.attention.output.LayerNorm.weight', 'base_model.encoder.layer.17.intermediate.dense.weight', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.19.attention.self.key.weight', 'base_model.encoder.layer.3.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.23.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.18.output.dense.bias', 'base_model.encoder.layer.6.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.11.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.23.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.19.output.LayerNorm.weight', 'base_model.encoder.layer.12.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.1.output.dense.weight', 'base_model.encoder.layer.17.output.dense.bias', 'base_model.encoder.layer.5.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.8.attention.output.dense.weight', 'base_model.encoder.layer.18.attention.output.dense.weight', 'base_model.encoder.layer.5.attention.output.LayerNorm.bias', 'base_model.encoder.layer.20.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.21.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.13.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.3.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.13.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.12.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.23.attention.self.key.bias', 'base_model.encoder.layer.11.intermediate.dense.weight', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.8.output.dense.bias', 'base_model.encoder.layer.13.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.0.attention.self.query.weight', 'base_model.encoder.layer.13.output.LayerNorm.bias', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.9.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.1.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.10.attention.self.key.weight', 'base_model.encoder.layer.7.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.16.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.12.attention.output.dense.weight', 'base_model.encoder.layer.8.attention.output.LayerNorm.bias', 'base_model.encoder.layer.13.attention.output.dense.bias', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.13.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.12.attention.output.LayerNorm.weight', 'base_model.encoder.layer.15.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.22.intermediate.dense.weight', 'base_model.encoder.layer.18.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.23.attention.output.LayerNorm.bias', 'base_model.encoder.layer.22.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.4.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.20.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.2.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.15.output.dense.weight', 'base_model.encoder.layer.15.output.LayerNorm.bias', 'base_model.encoder.layer.3.attention.output.dense.weight', 'base_model.encoder.layer.21.attention.output.dense.bias', 'base_model.encoder.layer.6.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.9.output.LayerNorm.bias', 'base_model.encoder.layer.6.intermediate.dense.weight', 'base_model.encoder.layer.14.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.0.output.dense.weight', 'base_model.encoder.layer.2.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.9.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.14.output.LayerNorm.weight', 'base_model.encoder.layer.23.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.22.intermediate.dense.bias', 'base_model.encoder.layer.0.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.14.output.dense.weight', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.7.attention.output.LayerNorm.weight', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.3.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.4.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.10.attention.output.dense.bias', 'base_model.encoder.layer.11.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.17.output.LayerNorm.bias', 'base_model.encoder.layer.6.attention.self.value.bias', 'base_model.encoder.layer.13.attention.self.key.bias', 'base_model.encoder.layer.18.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.embeddings.LayerNorm.weight', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.21.attention.self.value.bias', 'base_model.encoder.layer.20.attention.output.dense.weight', 'base_model.encoder.layer.22.attention.self.key.weight', 'base_model.encoder.layer.6.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.6.attention.output.dense.weight', 'base_model.encoder.layer.6.attention.output.LayerNorm.weight', 'base_model.encoder.layer.7.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.6.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.4.attention.self.key.weight', 'base_model.encoder.layer.12.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.13.attention.output.LayerNorm.bias', 'base_model.encoder.layer.14.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.0.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.2.attention.output.LayerNorm.weight', 'base_model.encoder.layer.9.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.22.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.14.attention.self.key.weight', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.0.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.6.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.0.attention.output.LayerNorm.weight', 'base_model.encoder.layer.21.attention.self.key.weight', 'base_model.encoder.layer.5.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.5.intermediate.dense.weight', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.7.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.1.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.15.attention.self.key.weight', 'base_model.encoder.layer.16.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.11.intermediate.dense.bias', 'base_model.encoder.layer.6.attention.self.value.weight', 'base_model.encoder.layer.13.attention.self.value.weight', 'base_model.encoder.layer.2.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.15.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.20.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.17.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.0.intermediate.dense.weight', 'base_model.encoder.layer.20.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.17.output.LayerNorm.weight', 'base_model.encoder.layer.1.output.LayerNorm.weight', 'base_model.encoder.layer.7.attention.output.dense.weight', 'base_model.encoder.layer.17.attention.self.query.weight', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.12.attention.self.query.bias', 'base_model.encoder.layer.9.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.13.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.9.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.18.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.3.attention.self.key.weight', 'base_model.encoder.layer.8.intermediate.dense.weight', 'base_model.encoder.layer.14.intermediate.dense.weight', 'base_model.encoder.layer.9.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.8.output.adapters.es.adapter_up.bias', 'qa_outputs.bias', 'base_model.encoder.layer.11.output.dense.bias', 'base_model.encoder.layer.4.output.dense.weight', 'base_model.encoder.layer.9.attention.output.LayerNorm.bias', 'base_model.encoder.layer.21.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.13.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.15.intermediate.dense.bias', 'base_model.encoder.layer.3.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.16.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.1.attention.self.value.bias', 'base_model.encoder.layer.20.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.5.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.10.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.6.attention.self.query.weight', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.17.attention.self.value.bias', 'base_model.encoder.layer.15.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.16.attention.self.query.weight', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.18.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.3.output.LayerNorm.weight', 'base_model.encoder.layer.4.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.9.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.5.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.10.attention.self.key.bias', 'base_model.encoder.layer.18.attention.self.key.weight', 'base_model.encoder.layer.23.intermediate.dense.weight', 'base_model.encoder.layer.16.attention.self.value.weight', 'base_model.encoder.layer.18.output.dense.weight', 'base_model.encoder.layer.15.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.22.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.1.attention.output.LayerNorm.bias', 'base_model.encoder.layer.22.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.0.attention.output.dense.weight', 'base_model.encoder.layer.21.output.LayerNorm.weight', 'base_model.encoder.layer.2.attention.self.value.bias', 'base_model.encoder.layer.11.attention.self.key.weight', 'base_model.encoder.layer.7.attention.self.query.bias', 'base_model.encoder.layer.6.output.LayerNorm.bias', 'base_model.encoder.layer.23.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.6.attention.self.query.bias', 'base_model.encoder.layer.18.attention.self.key.bias', 'base_model.encoder.layer.9.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.9.attention.output.LayerNorm.weight', 'base_model.encoder.layer.7.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.20.output.LayerNorm.weight', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.14.attention.self.value.weight', 'base_model.encoder.layer.7.output.LayerNorm.weight', 'base_model.encoder.layer.9.output.LayerNorm.weight', 'base_model.encoder.layer.1.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.0.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.20.intermediate.dense.weight', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.21.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.15.attention.self.value.weight', 'base_model.encoder.layer.11.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.1.output.LayerNorm.bias', 'base_model.encoder.layer.19.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.20.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.21.attention.output.dense.weight', 'base_model.encoder.layer.15.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.6.attention.output.LayerNorm.bias', 'base_model.encoder.layer.6.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.16.intermediate.dense.bias', 'base_model.encoder.layer.14.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.5.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.20.output.dense.weight', 'base_model.encoder.layer.20.attention.self.query.weight', 'base_model.encoder.layer.20.attention.output.LayerNorm.weight', 'base_model.encoder.layer.21.attention.self.query.weight', 'base_model.encoder.layer.10.attention.output.LayerNorm.bias', 'base_model.embeddings.position_embeddings.weight', 'base_model.encoder.layer.14.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.2.output.dense.weight', 'base_model.encoder.layer.20.attention.self.key.weight', 'base_model.encoder.layer.22.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.19.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.7.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.9.attention.self.value.bias', 'base_model.encoder.layer.9.intermediate.dense.weight', 'base_model.encoder.layer.13.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.10.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.22.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.9.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.13.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.13.attention.self.query.weight', 'base_model.encoder.layer.6.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.8.attention.self.query.weight', 'base_model.encoder.layer.17.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.17.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.22.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.11.output.LayerNorm.weight', 'base_model.encoder.layer.12.attention.self.value.weight', 'base_model.encoder.layer.13.attention.self.query.bias', 'base_model.encoder.layer.23.attention.self.query.bias', 'base_model.encoder.layer.9.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.0.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.15.output.LayerNorm.weight', 'base_model.encoder.layer.16.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.5.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.9.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.5.intermediate.dense.bias', 'base_model.encoder.layer.21.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.8.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.21.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.21.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.18.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.15.attention.self.query.bias', 'base_model.encoder.layer.16.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.14.output.LayerNorm.bias', 'base_model.encoder.layer.11.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.12.attention.self.key.weight', 'base_model.encoder.layer.7.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.7.output.dense.bias', 'base_model.encoder.layer.10.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.2.attention.self.query.bias', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.8.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.22.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.16.output.dense.bias', 'base_model.encoder.layer.8.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.21.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.4.attention.self.query.weight', 'base_model.encoder.layer.5.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.1.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.13.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.6.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.18.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.1.attention.self.query.bias', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.5.attention.self.key.bias', 'base_model.encoder.layer.10.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.4.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.15.attention.output.LayerNorm.weight', 'base_model.encoder.layer.9.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.2.intermediate.dense.weight', 'base_model.encoder.layer.1.attention.output.dense.bias', 'base_model.encoder.layer.0.output.dense.bias', 'base_model.encoder.layer.12.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.11.output.LayerNorm.bias', 'base_model.encoder.layer.17.intermediate.dense.bias', 'base_model.encoder.layer.13.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.21.attention.self.value.weight', 'base_model.encoder.layer.14.attention.self.query.bias', 'base_model.encoder.layer.13.attention.self.value.bias', 'base_model.encoder.layer.17.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.4.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.6.output.dense.bias', 'base_model.encoder.layer.22.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.10.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.17.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.12.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.11.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.4.intermediate.dense.bias', 'base_model.encoder.layer.7.attention.self.query.weight', 'base_model.encoder.layer.7.attention.output.LayerNorm.bias', 'base_model.encoder.layer.21.output.dense.weight', 'base_model.encoder.layer.2.attention.output.dense.bias', 'base_model.encoder.layer.0.attention.self.query.bias', 'base_model.encoder.layer.17.attention.self.query.bias', 'base_model.encoder.layer.18.attention.self.value.bias', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.10.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.5.attention.self.query.bias', 'base_model.encoder.layer.10.intermediate.dense.weight', 'base_model.encoder.layer.2.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.8.attention.self.key.bias', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.18.attention.self.query.weight', 'base_model.encoder.layer.22.output.LayerNorm.weight', 'base_model.encoder.layer.10.output.LayerNorm.bias', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.23.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.0.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.11.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.16.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.3.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.15.intermediate.dense.weight', 'base_model.encoder.layer.18.intermediate.dense.bias', 'base_model.encoder.layer.10.attention.self.query.weight', 'base_model.encoder.layer.16.attention.output.LayerNorm.weight', 'base_model.encoder.layer.4.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.3.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.13.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.2.output.LayerNorm.bias', 'base_model.encoder.layer.6.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.1.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.4.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.13.output.LayerNorm.weight', 'base_model.encoder.layer.4.attention.self.query.bias', 'base_model.encoder.layer.10.output.dense.bias', 'base_model.encoder.layer.14.attention.output.dense.weight', 'base_model.encoder.layer.13.attention.output.LayerNorm.weight', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.1.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.9.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.8.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.22.attention.self.value.weight', 'base_model.encoder.layer.4.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.5.output.LayerNorm.weight', 'base_model.encoder.layer.18.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.12.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.19.attention.self.query.weight', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.12.attention.output.LayerNorm.bias', 'base_model.encoder.layer.19.attention.self.value.weight', 'base_model.encoder.layer.15.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.18.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.2.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.11.attention.output.dense.weight', 'base_model.encoder.layer.14.attention.self.key.bias', 'base_model.encoder.layer.22.attention.self.query.bias', 'base_model.encoder.layer.1.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.19.output.dense.bias', 'base_model.encoder.layer.12.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.9.attention.self.key.bias', 'base_model.encoder.layer.13.intermediate.dense.weight', 'base_model.encoder.layer.8.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.23.attention.output.dense.weight', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.7.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.15.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.5.output.dense.weight', 'base_model.encoder.layer.22.output.dense.weight', 'base_model.encoder.layer.23.output.dense.weight', 'base_model.encoder.layer.16.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.9.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.6.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.7.attention.self.value.bias', 'base_model.encoder.layer.1.attention.self.key.bias', 'base_model.encoder.layer.21.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.8.output.LayerNorm.bias', 'base_model.encoder.layer.11.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.17.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.8.output.dense.weight', 'base_model.encoder.layer.20.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.9.attention.self.key.weight', 'base_model.encoder.layer.1.intermediate.dense.weight', 'base_model.encoder.layer.3.attention.self.query.bias', 'base_model.encoder.layer.9.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.10.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.20.attention.output.LayerNorm.bias', 'base_model.encoder.layer.20.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.18.attention.self.value.weight', 'base_model.encoder.layer.6.intermediate.dense.bias', 'base_model.encoder.layer.13.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.15.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.7.intermediate.dense.weight', 'base_model.encoder.layer.10.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.4.output.LayerNorm.bias', 'base_model.encoder.layer.11.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.2.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.21.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.17.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.3.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.22.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.23.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.17.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.22.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.20.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.7.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.3.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.7.attention.output.dense.bias', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.0.attention.self.key.bias', 'base_model.encoder.layer.14.attention.output.dense.bias', 'base_model.encoder.layer.14.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.20.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.8.attention.self.value.weight', 'base_model.encoder.layer.20.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.23.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.21.output.LayerNorm.bias', 'base_model.encoder.layer.21.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.1.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.8.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.16.attention.output.dense.bias', 'base_model.encoder.layer.16.attention.self.value.bias', 'base_model.encoder.layer.19.attention.self.value.bias', 'base_model.encoder.layer.7.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.4.attention.self.key.bias', 'base_model.encoder.layer.23.attention.self.value.bias', 'base_model.encoder.layer.5.attention.self.query.weight', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.4.output.dense.bias', 'base_model.encoder.layer.1.intermediate.dense.bias', 'base_model.encoder.layer.22.attention.output.dense.bias', 'base_model.encoder.layer.3.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.18.attention.output.LayerNorm.weight', 'base_model.encoder.layer.3.intermediate.dense.weight', 'base_model.encoder.layer.15.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.11.attention.self.query.weight', 'base_model.encoder.layer.4.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.7.attention.self.value.weight', 'base_model.encoder.layer.14.intermediate.dense.bias', 'base_model.encoder.layer.3.output.LayerNorm.bias', 'base_model.encoder.layer.0.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.13.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.16.output.LayerNorm.weight', 'base_model.encoder.layer.21.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.1.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.5.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.8.attention.self.key.weight', 'base_model.encoder.layer.19.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.11.output.dense.weight', 'base_model.encoder.layer.0.output.LayerNorm.bias', 'base_model.encoder.layer.15.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.11.attention.self.value.weight', 'base_model.encoder.layer.16.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.18.output.LayerNorm.weight', 'base_model.encoder.layer.19.intermediate.dense.weight', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.pooler.dense.weight', 'base_model.encoder.layer.10.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.3.attention.output.dense.bias', 'base_model.encoder.layer.6.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.14.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.8.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.16.attention.self.key.bias', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.23.attention.self.value.weight', 'base_model.encoder.layer.3.attention.self.query.weight', 'base_model.encoder.layer.18.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.21.attention.self.query.bias', 'base_model.encoder.layer.1.attention.self.key.weight', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.10.output.dense.weight', 'base_model.encoder.layer.0.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.19.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.15.attention.self.value.bias', 'base_model.encoder.layer.14.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.10.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.7.attention.self.key.weight', 'base_model.encoder.layer.3.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.3.output.adapters.es.adapter_down.0.weight', 'base_model.embeddings.position_ids', 'base_model.encoder.layer.20.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.2.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.17.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.18.attention.output.LayerNorm.bias', 'base_model.encoder.layer.16.attention.self.query.bias', 'base_model.encoder.layer.1.attention.output.dense.weight', 'base_model.encoder.layer.19.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.16.attention.output.LayerNorm.bias', 'base_model.encoder.layer.14.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.23.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.12.output.dense.weight', 'base_model.encoder.layer.13.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.19.attention.output.LayerNorm.weight', 'base_model.encoder.layer.19.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.1.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.2.attention.self.key.weight', 'base_model.encoder.layer.3.attention.self.value.bias', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.22.attention.self.query.weight', 'base_model.encoder.layer.6.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.23.output.LayerNorm.bias', 'base_model.encoder.layer.5.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.7.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.4.attention.output.dense.bias', 'base_model.encoder.layer.18.output.LayerNorm.bias', 'base_model.encoder.layer.23.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.5.output.LayerNorm.bias', 'base_model.encoder.layer.11.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.0.attention.output.LayerNorm.bias', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.21.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.21.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.2.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.7.intermediate.dense.bias', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.10.attention.self.value.weight', 'base_model.encoder.layer.14.attention.output.LayerNorm.bias', 'base_model.encoder.layer.10.attention.output.dense.weight', 'base_model.encoder.layer.17.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.10.attention.output.LayerNorm.weight', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.2.intermediate.dense.bias', 'base_model.encoder.layer.16.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.16.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.4.attention.output.LayerNorm.weight', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.10.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.11.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.19.attention.self.query.bias', 'base_model.encoder.layer.12.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.10.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.18.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.23.attention.output.LayerNorm.weight', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.22.attention.self.key.bias', 'base_model.encoder.layer.19.attention.output.dense.weight', 'base_model.encoder.layer.19.attention.self.key.bias', 'base_model.encoder.layer.13.intermediate.dense.bias', 'base_model.encoder.layer.11.attention.self.key.bias', 'base_model.encoder.layer.10.intermediate.dense.bias', 'base_model.encoder.layer.15.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.4.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.23.attention.self.query.weight', 'base_model.encoder.layer.11.output.adapters.ep.adapter_up.bias', 'base_model.embeddings.token_type_embeddings.weight', 'base_model.encoder.layer.7.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.12.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.20.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.20.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.7.output.dense.weight', 'base_model.encoder.layer.14.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.8.attention.output.dense.bias', 'base_model.encoder.layer.17.attention.self.key.bias', 'base_model.encoder.layer.16.output.dense.weight', 'base_model.encoder.layer.5.attention.output.dense.weight', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.20.attention.self.query.bias', 'base_model.encoder.layer.1.output.dense.bias', 'base_model.encoder.layer.3.output.dense.bias', 'base_model.encoder.layer.10.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.11.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.9.attention.output.dense.bias', 'base_model.encoder.layer.12.intermediate.dense.weight', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.22.output.LayerNorm.bias', 'base_model.encoder.layer.18.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.15.attention.output.dense.weight', 'base_model.encoder.layer.23.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.14.attention.self.query.weight', 'base_model.encoder.layer.7.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.14.attention.self.value.bias', 'base_model.encoder.layer.16.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.8.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.4.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.19.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.3.attention.output.LayerNorm.weight', 'base_model.encoder.layer.3.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.14.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.5.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.18.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.12.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.16.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.5.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.2.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.0.attention.self.value.bias', 'base_model.encoder.layer.7.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.19.attention.output.dense.bias', 'base_model.encoder.layer.16.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.15.attention.self.key.bias', 'base_model.encoder.layer.9.intermediate.dense.bias', 'base_model.encoder.layer.5.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.6.output.LayerNorm.weight', 'base_model.encoder.layer.12.attention.self.query.weight', 'base_model.encoder.layer.0.intermediate.dense.bias', 'base_model.encoder.layer.19.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.5.attention.output.dense.bias', 'base_model.encoder.layer.8.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.23.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.2.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.2.output.dense.bias', 'base_model.encoder.layer.4.attention.self.value.bias', 'base_model.encoder.layer.11.attention.output.LayerNorm.bias', 'base_model.encoder.layer.13.output.dense.bias', 'base_model.encoder.layer.0.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.4.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.4.output.LayerNorm.weight', 'base_model.encoder.layer.7.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.14.attention.output.LayerNorm.weight', 'base_model.encoder.layer.12.attention.self.value.bias', 'base_model.encoder.layer.14.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.22.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.23.attention.self.key.weight', 'base_model.encoder.layer.2.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.0.output.LayerNorm.weight', 'base_model.encoder.layer.15.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.11.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.0.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.16.intermediate.dense.weight', 'base_model.encoder.layer.17.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.17.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.0.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.0.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.20.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.6.attention.self.key.weight', 'base_model.encoder.layer.22.attention.output.LayerNorm.bias', 'base_model.encoder.layer.0.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.15.output.dense.bias', 'base_model.encoder.layer.1.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.21.attention.output.LayerNorm.bias', 'base_model.encoder.layer.21.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.3.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.2.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.6.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.20.attention.self.key.bias', 'base_model.encoder.layer.2.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.7.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.3.output.dense.weight', 'base_model.encoder.layer.17.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.21.attention.output.LayerNorm.weight', 'base_model.encoder.layer.2.attention.self.key.bias', 'base_model.encoder.layer.2.attention.output.LayerNorm.bias', 'base_model.encoder.layer.23.output.LayerNorm.weight', 'base_model.encoder.layer.11.attention.output.dense.bias', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.1.attention.self.value.weight', 'base_model.encoder.layer.19.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.5.attention.output.LayerNorm.weight', 'base_model.encoder.layer.13.output.dense.weight', 'base_model.encoder.layer.1.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.8.intermediate.dense.bias', 'base_model.encoder.layer.17.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.17.attention.self.value.weight', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.10.output.LayerNorm.weight', 'base_model.encoder.layer.10.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.11.attention.output.LayerNorm.weight', 'base_model.encoder.layer.21.attention.self.key.bias', 'base_model.encoder.layer.9.attention.output.dense.weight', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.19.output.adapters.ts.adapter_up.bias', 'base_model.embeddings.word_embeddings.weight', 'base_model.encoder.layer.11.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.8.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.22.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.16.attention.output.dense.weight', 'base_model.encoder.layer.2.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.6.attention.self.key.bias', 'base_model.encoder.layer.1.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.12.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'qa_outputs.weight', 'base_model.encoder.layer.5.attention.self.key.weight', 'base_model.encoder.layer.18.attention.output.dense.bias', 'base_model.encoder.layer.12.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.10.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.11.attention.self.value.bias', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.17.attention.output.dense.bias', 'base_model.encoder.layer.20.output.LayerNorm.bias', 'base_model.encoder.layer.3.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.0.attention.self.key.weight', 'base_model.encoder.layer.19.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.6.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.19.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.7.attention.self.key.bias', 'base_model.encoder.layer.15.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.19.intermediate.dense.bias', 'base_model.encoder.layer.22.attention.self.value.bias', 'base_model.encoder.layer.23.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.0.attention.self.value.weight', 'base_model.encoder.layer.11.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.14.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.18.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.4.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.4.attention.output.dense.weight', 'base_model.encoder.layer.8.attention.self.value.bias', 'base_model.encoder.layer.1.attention.output.LayerNorm.weight', 'base_model.encoder.layer.3.attention.self.key.bias', 'base_model.encoder.layer.8.attention.output.LayerNorm.weight', 'base_model.encoder.layer.21.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.20.attention.output.dense.bias', 'base_model.encoder.layer.19.output.dense.weight', 'base_model.encoder.layer.23.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.4.intermediate.dense.weight', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.21.intermediate.dense.weight', 'base_model.encoder.layer.22.attention.output.LayerNorm.weight', 'base_model.encoder.layer.1.attention.self.query.weight', 'base_model.encoder.layer.3.intermediate.dense.bias', 'base_model.encoder.layer.23.intermediate.dense.bias', 'base_model.encoder.layer.12.attention.self.key.bias', 'base_model.encoder.layer.22.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.1.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.7.output.adapters.ep.adapter_up.weight', 'base_model.embeddings.LayerNorm.bias', 'base_model.encoder.layer.6.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.14.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.8.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.22.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.0.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.22.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.20.intermediate.dense.bias', 'base_model.encoder.layer.20.output.dense.bias', 'base_model.encoder.layer.2.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.14.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.3.attention.output.LayerNorm.bias', 'base_model.encoder.layer.12.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.1.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.5.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.2.attention.self.query.weight', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.12.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.13.attention.self.key.weight', 'base_model.encoder.layer.19.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.23.output.dense.bias', 'base_model.encoder.layer.17.attention.output.dense.weight', 'base_model.encoder.layer.16.attention.self.key.weight', 'base_model.encoder.layer.8.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.17.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.4.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.0.attention.output.dense.bias']
- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of XLMRobertaModel were not initialized from the model checkpoint at /cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//squad/xlm-KG_LR8e-6_EPOCH2.0_maxlen384_batchsize4_gradacc4 and are newly initialized: ['encoder.layer.21.attention.self.key.weight', 'encoder.layer.19.output.dense.bias', 'encoder.layer.9.attention.self.key.weight', 'encoder.layer.18.attention.output.dense.weight', 'encoder.layer.20.output.LayerNorm.bias', 'encoder.layer.8.attention.self.value.bias', 'encoder.layer.17.intermediate.dense.bias', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.23.attention.self.query.bias', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.16.attention.self.query.bias', 'encoder.layer.17.output.LayerNorm.weight', 'encoder.layer.3.attention.output.dense.bias', 'encoder.layer.17.output.LayerNorm.bias', 'encoder.layer.4.attention.output.dense.weight', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.5.attention.self.value.weight', 'encoder.layer.14.attention.self.query.weight', 'encoder.layer.22.output.dense.bias', 'encoder.layer.5.output.dense.bias', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.1.attention.self.key.weight', 'encoder.layer.14.attention.output.LayerNorm.bias', 'encoder.layer.13.intermediate.dense.weight', 'encoder.layer.0.attention.self.key.weight', 'encoder.layer.2.attention.output.dense.weight', 'encoder.layer.12.output.dense.bias', 'encoder.layer.5.attention.output.dense.weight', 'encoder.layer.17.attention.self.value.bias', 'encoder.layer.22.attention.self.query.bias', 'encoder.layer.11.output.dense.bias', 'encoder.layer.6.attention.output.dense.weight', 'encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.layer.14.output.LayerNorm.weight', 'encoder.layer.4.output.dense.weight', 'encoder.layer.21.attention.self.value.weight', 'encoder.layer.18.output.LayerNorm.bias', 'encoder.layer.7.attention.output.LayerNorm.bias', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.16.attention.self.value.bias', 'encoder.layer.8.attention.self.value.weight', 'encoder.layer.22.attention.output.dense.weight', 'encoder.layer.9.attention.output.dense.bias', 'encoder.layer.11.attention.output.dense.weight', 'encoder.layer.8.attention.output.LayerNorm.weight', 'encoder.layer.8.output.dense.bias', 'encoder.layer.18.attention.self.query.bias', 'encoder.layer.23.output.LayerNorm.bias', 'encoder.layer.7.attention.self.value.bias', 'encoder.layer.18.intermediate.dense.bias', 'encoder.layer.15.intermediate.dense.bias', 'encoder.layer.16.attention.self.value.weight', 'encoder.layer.16.attention.self.key.bias', 'encoder.layer.22.attention.self.key.weight', 'encoder.layer.1.attention.self.query.bias', 'encoder.layer.14.attention.self.value.bias', 'encoder.layer.21.output.LayerNorm.weight', 'encoder.layer.12.attention.self.query.bias', 'encoder.layer.0.attention.output.LayerNorm.weight', 'encoder.layer.1.output.dense.weight', 'encoder.layer.20.attention.output.LayerNorm.weight', 'encoder.layer.10.attention.self.value.weight', 'encoder.layer.0.attention.self.key.bias', 'encoder.layer.6.attention.self.value.weight', 'encoder.layer.20.attention.self.key.weight', 'encoder.layer.11.output.LayerNorm.bias', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.18.attention.self.value.weight', 'encoder.layer.4.attention.self.query.weight', 'encoder.layer.6.output.LayerNorm.bias', 'encoder.layer.17.attention.output.LayerNorm.weight', 'encoder.layer.2.attention.self.value.weight', 'encoder.layer.6.attention.self.key.bias', 'encoder.layer.18.attention.output.LayerNorm.weight', 'encoder.layer.13.attention.self.query.weight', 'embeddings.word_embeddings.weight', 'encoder.layer.3.output.dense.bias', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.18.attention.output.dense.bias', 'encoder.layer.20.output.dense.weight', 'encoder.layer.17.attention.self.key.weight', 'encoder.layer.7.intermediate.dense.bias', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.18.output.dense.weight', 'encoder.layer.6.attention.output.dense.bias', 'encoder.layer.10.output.LayerNorm.weight', 'encoder.layer.15.output.dense.weight', 'encoder.layer.19.attention.self.key.weight', 'encoder.layer.22.attention.output.LayerNorm.weight', 'encoder.layer.17.attention.self.query.bias', 'encoder.layer.14.attention.output.dense.weight', 'encoder.layer.3.attention.self.query.bias', 'encoder.layer.12.attention.self.key.bias', 'encoder.layer.5.output.LayerNorm.bias', 'encoder.layer.10.attention.self.query.bias', 'encoder.layer.22.attention.self.query.weight', 'encoder.layer.5.attention.output.LayerNorm.weight', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.15.output.LayerNorm.bias', 'encoder.layer.21.attention.self.value.bias', 'encoder.layer.21.attention.output.LayerNorm.bias', 'encoder.layer.20.output.dense.bias', 'encoder.layer.9.attention.self.query.bias', 'encoder.layer.19.attention.output.LayerNorm.weight', 'encoder.layer.20.attention.output.dense.bias', 'encoder.layer.9.attention.self.value.bias', 'encoder.layer.19.intermediate.dense.bias', 'encoder.layer.20.output.LayerNorm.weight', 'encoder.layer.23.attention.self.query.weight', 'embeddings.position_embeddings.weight', 'encoder.layer.11.attention.self.value.bias', 'encoder.layer.14.output.dense.bias', 'encoder.layer.14.intermediate.dense.weight', 'encoder.layer.13.attention.output.dense.weight', 'encoder.layer.20.attention.self.value.bias', 'encoder.layer.12.output.LayerNorm.weight', 'encoder.layer.13.output.dense.bias', 'encoder.layer.14.attention.self.value.weight', 'encoder.layer.21.attention.self.key.bias', 'encoder.layer.21.attention.self.query.bias', 'encoder.layer.14.attention.output.LayerNorm.weight', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.10.output.LayerNorm.bias', 'encoder.layer.18.attention.self.key.weight', 'encoder.layer.15.attention.output.dense.weight', 'encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.layer.15.attention.self.value.weight', 'encoder.layer.17.attention.self.query.weight', 'embeddings.token_type_embeddings.weight', 'encoder.layer.10.attention.output.LayerNorm.weight', 'encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.18.attention.self.value.bias', 'encoder.layer.12.attention.output.dense.weight', 'encoder.layer.18.attention.self.query.weight', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.17.intermediate.dense.weight', 'encoder.layer.7.attention.self.query.bias', 'encoder.layer.12.output.LayerNorm.bias', 'encoder.layer.14.attention.self.query.bias', 'encoder.layer.14.attention.self.key.bias', 'encoder.layer.9.attention.output.LayerNorm.bias', 'encoder.layer.8.attention.self.key.bias', 'encoder.layer.8.output.LayerNorm.bias', 'encoder.layer.7.attention.output.LayerNorm.weight', 'encoder.layer.3.attention.self.key.weight', 'encoder.layer.14.output.dense.weight', 'encoder.layer.1.attention.output.dense.bias', 'encoder.layer.18.output.dense.bias', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.16.output.LayerNorm.weight', 'encoder.layer.0.output.dense.weight', 'encoder.layer.5.attention.output.dense.bias', 'encoder.layer.4.attention.output.dense.bias', 'encoder.layer.1.attention.self.query.weight', 'encoder.layer.19.output.LayerNorm.bias', 'encoder.layer.23.attention.output.dense.weight', 'encoder.layer.16.output.dense.weight', 'embeddings.LayerNorm.bias', 'encoder.layer.13.attention.output.LayerNorm.weight', 'encoder.layer.15.attention.self.key.weight', 'encoder.layer.12.attention.output.LayerNorm.bias', 'encoder.layer.18.output.LayerNorm.weight', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.15.attention.output.LayerNorm.weight', 'encoder.layer.11.attention.self.key.weight', 'encoder.layer.5.attention.self.key.weight', 'encoder.layer.17.output.dense.bias', 'encoder.layer.19.output.dense.weight', 'encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.0.attention.self.query.weight', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.2.attention.output.dense.bias', 'encoder.layer.15.attention.self.query.bias', 'encoder.layer.15.intermediate.dense.weight', 'encoder.layer.10.output.dense.weight', 'encoder.layer.23.attention.output.LayerNorm.weight', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.16.attention.self.key.weight', 'encoder.layer.20.attention.self.query.weight', 'encoder.layer.3.attention.self.key.bias', 'encoder.layer.8.output.dense.weight', 'encoder.layer.20.intermediate.dense.weight', 'encoder.layer.21.attention.output.dense.bias', 'encoder.layer.10.attention.output.dense.weight', 'encoder.layer.21.intermediate.dense.weight', 'encoder.layer.12.attention.self.query.weight', 'encoder.layer.13.output.LayerNorm.weight', 'encoder.layer.22.attention.self.value.weight', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.18.attention.output.LayerNorm.bias', 'encoder.layer.12.attention.output.LayerNorm.weight', 'encoder.layer.17.output.dense.weight', 'encoder.layer.23.attention.self.key.bias', 'encoder.layer.3.attention.output.dense.weight', 'encoder.layer.9.attention.self.key.bias', 'encoder.layer.6.attention.output.LayerNorm.bias', 'encoder.layer.21.output.LayerNorm.bias', 'encoder.layer.0.attention.output.dense.bias', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.20.attention.self.query.bias', 'encoder.layer.22.output.LayerNorm.bias', 'encoder.layer.2.output.dense.weight', 'encoder.layer.15.attention.output.LayerNorm.bias', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.5.output.dense.weight', 'encoder.layer.11.attention.self.query.weight', 'encoder.layer.21.output.dense.bias', 'encoder.layer.9.output.dense.weight', 'encoder.layer.12.output.dense.weight', 'encoder.layer.9.attention.self.query.weight', 'encoder.layer.6.output.dense.weight', 'encoder.layer.2.output.dense.bias', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.16.intermediate.dense.weight', 'encoder.layer.15.attention.self.query.weight', 'encoder.layer.2.attention.self.value.bias', 'encoder.layer.4.output.dense.bias', 'encoder.layer.23.output.dense.weight', 'encoder.layer.1.attention.self.key.bias', 'encoder.layer.4.attention.self.value.weight', 'encoder.layer.9.attention.self.value.weight', 'encoder.layer.11.output.LayerNorm.weight', 'encoder.layer.6.attention.self.value.bias', 'encoder.layer.11.attention.output.LayerNorm.weight', 'encoder.layer.16.attention.output.LayerNorm.bias', 'encoder.layer.17.attention.self.key.bias', 'encoder.layer.15.attention.output.dense.bias', 'encoder.layer.7.attention.output.dense.weight', 'encoder.layer.1.output.dense.bias', 'encoder.layer.12.intermediate.dense.bias', 'encoder.layer.19.attention.self.query.weight', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.19.attention.output.dense.weight', 'encoder.layer.20.attention.self.value.weight', 'encoder.layer.22.output.LayerNorm.weight', 'encoder.layer.10.attention.self.value.bias', 'encoder.layer.19.output.LayerNorm.weight', 'encoder.layer.4.attention.self.query.bias', 'encoder.layer.9.attention.output.dense.weight', 'encoder.layer.22.attention.self.key.bias', 'encoder.layer.7.output.dense.bias', 'encoder.layer.13.attention.self.value.bias', 'encoder.layer.3.attention.self.value.weight', 'encoder.layer.1.attention.self.value.bias', 'encoder.layer.13.attention.self.key.weight', 'encoder.layer.16.attention.output.LayerNorm.weight', 'encoder.layer.13.attention.output.dense.bias', 'encoder.layer.12.attention.self.key.weight', 'encoder.layer.0.attention.output.dense.weight', 'encoder.layer.12.attention.self.value.weight', 'encoder.layer.9.output.dense.bias', 'encoder.layer.5.attention.self.query.weight', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.22.attention.output.dense.bias', 'encoder.layer.15.attention.self.value.bias', 'encoder.layer.2.attention.self.query.bias', 'encoder.layer.2.attention.self.key.weight', 'encoder.layer.7.attention.self.key.bias', 'encoder.layer.17.attention.output.dense.bias', 'encoder.layer.20.intermediate.dense.bias', 'encoder.layer.3.output.LayerNorm.weight', 'embeddings.LayerNorm.weight', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.2.attention.output.LayerNorm.bias', 'encoder.layer.10.intermediate.dense.weight', 'encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.layer.23.attention.self.value.weight', 'encoder.layer.13.attention.self.value.weight', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.7.output.LayerNorm.bias', 'encoder.layer.16.output.LayerNorm.bias', 'encoder.layer.3.output.dense.weight', 'encoder.layer.9.output.LayerNorm.weight', 'encoder.layer.10.attention.output.LayerNorm.bias', 'pooler.dense.weight', 'encoder.layer.16.output.dense.bias', 'encoder.layer.8.attention.self.query.weight', 'encoder.layer.13.intermediate.dense.bias', 'encoder.layer.19.intermediate.dense.weight', 'encoder.layer.20.attention.output.dense.weight', 'encoder.layer.4.attention.self.value.bias', 'encoder.layer.11.attention.self.value.weight', 'encoder.layer.22.attention.output.LayerNorm.bias', 'encoder.layer.23.intermediate.dense.bias', 'encoder.layer.14.intermediate.dense.bias', 'encoder.layer.8.attention.output.dense.weight', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.6.attention.self.query.weight', 'encoder.layer.7.output.dense.weight', 'encoder.layer.8.output.LayerNorm.weight', 'pooler.dense.bias', 'encoder.layer.3.attention.self.query.weight', 'encoder.layer.13.attention.self.key.bias', 'encoder.layer.13.output.LayerNorm.bias', 'encoder.layer.16.attention.output.dense.weight', 'encoder.layer.10.attention.self.query.weight', 'encoder.layer.19.attention.self.value.bias', 'encoder.layer.14.attention.self.key.weight', 'encoder.layer.3.attention.self.value.bias', 'encoder.layer.7.attention.self.query.weight', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.0.attention.self.value.weight', 'encoder.layer.18.attention.self.key.bias', 'encoder.layer.23.intermediate.dense.weight', 'encoder.layer.0.attention.self.value.bias', 'encoder.layer.12.attention.self.value.bias', 'encoder.layer.17.attention.output.LayerNorm.bias', 'encoder.layer.14.attention.output.dense.bias', 'encoder.layer.9.output.LayerNorm.bias', 'encoder.layer.1.attention.output.LayerNorm.weight', 'encoder.layer.15.output.LayerNorm.weight', 'encoder.layer.23.attention.self.key.weight', 'encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.layer.2.attention.self.query.weight', 'encoder.layer.10.attention.output.dense.bias', 'encoder.layer.16.attention.output.dense.bias', 'encoder.layer.8.attention.self.key.weight', 'encoder.layer.19.attention.output.dense.bias', 'encoder.layer.7.attention.self.key.weight', 'encoder.layer.21.attention.output.LayerNorm.weight', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.6.output.dense.bias', 'encoder.layer.11.attention.self.key.bias', 'encoder.layer.15.output.dense.bias', 'encoder.layer.19.attention.self.query.bias', 'encoder.layer.2.attention.output.LayerNorm.weight', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.10.output.dense.bias', 'encoder.layer.21.attention.output.dense.weight', 'encoder.layer.21.output.dense.weight', 'encoder.layer.5.attention.self.query.bias', 'encoder.layer.22.intermediate.dense.weight', 'encoder.layer.21.intermediate.dense.bias', 'encoder.layer.13.attention.output.LayerNorm.bias', 'encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.layer.6.attention.self.query.bias', 'encoder.layer.6.attention.output.LayerNorm.weight', 'encoder.layer.19.attention.self.key.bias', 'encoder.layer.23.output.LayerNorm.weight', 'encoder.layer.20.attention.self.key.bias', 'encoder.layer.21.attention.self.query.weight', 'encoder.layer.23.output.dense.bias', 'encoder.layer.8.attention.output.dense.bias', 'encoder.layer.23.attention.self.value.bias', 'encoder.layer.22.attention.self.value.bias', 'encoder.layer.0.output.dense.bias', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.22.intermediate.dense.bias', 'encoder.layer.20.attention.output.LayerNorm.bias', 'encoder.layer.23.attention.output.LayerNorm.bias', 'encoder.layer.19.attention.output.LayerNorm.bias', 'encoder.layer.8.attention.self.query.bias', 'encoder.layer.7.output.LayerNorm.weight', 'encoder.layer.2.attention.self.key.bias', 'encoder.layer.19.attention.self.value.weight', 'encoder.layer.12.intermediate.dense.weight', 'encoder.layer.11.attention.self.query.bias', 'encoder.layer.5.attention.self.key.bias', 'encoder.layer.14.output.LayerNorm.bias', 'encoder.layer.7.attention.output.dense.bias', 'encoder.layer.17.attention.output.dense.weight', 'encoder.layer.5.attention.self.value.bias', 'encoder.layer.16.intermediate.dense.bias', 'encoder.layer.10.attention.self.key.weight', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.7.attention.self.value.weight', 'encoder.layer.1.attention.self.value.weight', 'encoder.layer.11.attention.output.dense.bias', 'encoder.layer.4.attention.self.key.weight', 'encoder.layer.17.attention.self.value.weight', 'encoder.layer.22.output.dense.weight', 'encoder.layer.13.attention.self.query.bias', 'encoder.layer.4.attention.output.LayerNorm.weight', 'encoder.layer.11.output.dense.weight', 'encoder.layer.9.attention.output.LayerNorm.weight', 'encoder.layer.4.attention.self.key.bias', 'encoder.layer.23.attention.output.dense.bias', 'encoder.layer.18.intermediate.dense.weight', 'encoder.layer.0.attention.self.query.bias', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.12.attention.output.dense.bias', 'encoder.layer.1.attention.output.dense.weight', 'encoder.layer.13.output.dense.weight', 'encoder.layer.10.attention.self.key.bias', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.16.attention.self.query.weight', 'encoder.layer.15.attention.self.key.bias', 'encoder.layer.8.attention.output.LayerNorm.bias', 'encoder.layer.6.attention.self.key.weight', 'encoder.layer.4.attention.output.LayerNorm.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Overwriting existing adapter 'ep'.
Overwriting existing adapter 'tp'.
Overwriting existing adapter 'es'.
Overwriting existing adapter 'ts'.
Overwriting existing adapter fusion module 'ep,tp,es,ts'
05/09/2022 20:07:20 - INFO - __main__ -   Creating features from dataset file at .
/cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//squad/xlm-KG_LR8e-6_EPOCH2.0_maxlen384_batchsize4_gradacc4
XLMConfig {
  "architectures": [
    "XLMRobertaForMaskedLM"
  ],
  "asm": false,
  "attention_dropout": 0.1,
  "attention_probs_dropout_prob": 0.1,
  "bos_index": 0,
  "bos_token_id": 0,
  "causal": false,
  "dropout": 0.1,
  "emb_dim": 1024,
  "embed_init_std": 0.02209708691207961,
  "end_n_top": 5,
  "eos_index": 1,
  "eos_token_id": 2,
  "gelu_activation": true,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "init_std": 0.02,
  "initializer_range": 0.02,
  "intermediate_size": 4096,
  "is_encoder": true,
  "lang_id": 0,
  "layer_norm_eps": 1e-05,
  "mask_index": 5,
  "mask_token_id": 0,
  "max_position_embeddings": 514,
  "model_type": "xlm",
  "n_heads": 16,
  "n_langs": 1,
  "n_layers": 24,
  "output_past": true,
  "pad_index": 2,
  "pad_token_id": 1,
  "sinusoidal_embeddings": false,
  "start_n_top": 5,
  "summary_activation": null,
  "summary_first_dropout": 0.1,
  "summary_proj_to_labels": true,
  "summary_type": "first",
  "summary_use_proj": true,
  "transformers_version": "4.17.0",
  "type_vocab_size": 1,
  "unk_index": 3,
  "use_lang_emb": false,
  "vocab_size": 250002
}

  0%|          | 0/48 [00:00<?, ?it/s] 31%|███▏      | 15/48 [00:00<00:00, 135.23it/s] 60%|██████    | 29/48 [00:00<00:00, 103.33it/s] 92%|█████████▏| 44/48 [00:00<00:00, 119.84it/s]100%|██████████| 48/48 [00:00<00:00, 120.41it/s]
convert squad examples to features:   0%|          | 0/1190 [00:00<?, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.
convert squad examples to features:   0%|          | 1/1190 [00:00<04:36,  4.30it/s]convert squad examples to features:   5%|▌         | 65/1190 [00:00<00:07, 151.10it/s]convert squad examples to features:   8%|▊         | 97/1190 [00:00<00:05, 182.84it/s]convert squad examples to features:  11%|█         | 129/1190 [00:00<00:05, 202.18it/s]convert squad examples to features:  14%|█▎        | 161/1190 [00:00<00:04, 224.93it/s]convert squad examples to features:  16%|█▌        | 193/1190 [00:00<00:04, 239.41it/s]convert squad examples to features:  19%|█▉        | 225/1190 [00:01<00:04, 234.99it/s]convert squad examples to features:  22%|██▏       | 257/1190 [00:01<00:04, 232.44it/s]convert squad examples to features:  24%|██▍       | 289/1190 [00:01<00:04, 221.49it/s]convert squad examples to features:  27%|██▋       | 321/1190 [00:01<00:03, 219.20it/s]convert squad examples to features:  30%|██▉       | 353/1190 [00:01<00:03, 232.58it/s]convert squad examples to features:  32%|███▏      | 385/1190 [00:02<00:07, 111.07it/s]convert squad examples to features:  35%|███▌      | 417/1190 [00:02<00:06, 122.41it/s]convert squad examples to features:  38%|███▊      | 449/1190 [00:02<00:05, 127.50it/s]convert squad examples to features:  40%|████      | 481/1190 [00:02<00:05, 136.90it/s]convert squad examples to features:  43%|████▎     | 513/1190 [00:03<00:04, 142.91it/s]convert squad examples to features:  46%|████▌     | 545/1190 [00:03<00:04, 156.62it/s]convert squad examples to features:  48%|████▊     | 577/1190 [00:03<00:03, 163.05it/s]convert squad examples to features:  51%|█████     | 609/1190 [00:03<00:03, 162.63it/s]convert squad examples to features:  54%|█████▍    | 641/1190 [00:03<00:03, 157.53it/s]convert squad examples to features:  57%|█████▋    | 673/1190 [00:04<00:03, 154.34it/s]convert squad examples to features:  59%|█████▉    | 705/1190 [00:04<00:02, 162.37it/s]convert squad examples to features:  62%|██████▏   | 737/1190 [00:04<00:02, 165.03it/s]convert squad examples to features:  65%|██████▍   | 769/1190 [00:04<00:02, 175.78it/s]convert squad examples to features:  67%|██████▋   | 801/1190 [00:04<00:02, 193.83it/s]convert squad examples to features:  70%|███████   | 833/1190 [00:05<00:02, 163.41it/s]convert squad examples to features:  73%|███████▎  | 865/1190 [00:05<00:01, 178.28it/s]convert squad examples to features:  75%|███████▌  | 897/1190 [00:05<00:01, 173.84it/s]convert squad examples to features:  78%|███████▊  | 929/1190 [00:05<00:01, 171.37it/s]convert squad examples to features:  81%|████████  | 961/1190 [00:05<00:01, 183.94it/s]convert squad examples to features:  83%|████████▎ | 993/1190 [00:05<00:01, 191.08it/s]convert squad examples to features:  86%|████████▌ | 1025/1190 [00:05<00:00, 203.64it/s]convert squad examples to features:  89%|████████▉ | 1057/1190 [00:06<00:00, 218.21it/s]convert squad examples to features:  92%|█████████▏| 1089/1190 [00:06<00:00, 212.22it/s]convert squad examples to features:  94%|█████████▍| 1121/1190 [00:06<00:00, 205.14it/s]convert squad examples to features:  97%|█████████▋| 1153/1190 [00:06<00:00, 183.98it/s]convert squad examples to features: 100%|██████████| 1190/1190 [00:06<00:00, 178.45it/s]/cluster/project/sachan/yifan/softwares/anaconda/anaconda3/envs/xfactr/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2272: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

add example index and unique id:   0%|          | 0/1190 [00:00<?, ?it/s]add example index and unique id: 100%|██████████| 1190/1190 [00:00<00:00, 879045.75it/s]
05/09/2022 20:07:27 - INFO - __main__ -   Saving features into cached file ./cached_xquad.vi.json_xlm-KG_LR8e-6_EPOCH2.0_maxlen384_batchsize4_gradacc4_384_vi
05/09/2022 20:07:29 - INFO - __main__ -   ***** Running evaluation  *****
05/09/2022 20:07:29 - INFO - __main__ -     Num examples = 1314
05/09/2022 20:07:29 - INFO - __main__ -     Batch size = 8
Evaluating:   0%|          | 0/165 [00:00<?, ?it/s]Evaluating:   1%|          | 1/165 [00:00<02:20,  1.17it/s]Evaluating:   1%|          | 2/165 [00:01<01:32,  1.76it/s]Evaluating:   2%|▏         | 3/165 [00:01<01:16,  2.11it/s]Evaluating:   2%|▏         | 4/165 [00:01<01:08,  2.34it/s]Evaluating:   3%|▎         | 5/165 [00:02<01:04,  2.49it/s]Evaluating:   4%|▎         | 6/165 [00:02<01:01,  2.58it/s]Evaluating:   4%|▍         | 7/165 [00:03<00:59,  2.65it/s]Evaluating:   5%|▍         | 8/165 [00:03<00:58,  2.71it/s]Evaluating:   5%|▌         | 9/165 [00:03<00:56,  2.74it/s]Evaluating:   6%|▌         | 10/165 [00:04<00:56,  2.75it/s]Evaluating:   7%|▋         | 11/165 [00:04<00:56,  2.75it/s]Evaluating:   7%|▋         | 12/165 [00:04<00:55,  2.76it/s]Evaluating:   8%|▊         | 13/165 [00:05<00:54,  2.77it/s]Evaluating:   8%|▊         | 14/165 [00:05<00:54,  2.77it/s]Evaluating:   9%|▉         | 15/165 [00:05<00:54,  2.78it/s]Evaluating:  10%|▉         | 16/165 [00:06<00:53,  2.78it/s]Evaluating:  10%|█         | 17/165 [00:06<00:52,  2.79it/s]Evaluating:  11%|█         | 18/165 [00:06<00:52,  2.79it/s]Evaluating:  12%|█▏        | 19/165 [00:07<00:52,  2.80it/s]Evaluating:  12%|█▏        | 20/165 [00:07<00:52,  2.75it/s]Evaluating:  13%|█▎        | 21/165 [00:08<00:52,  2.73it/s]Evaluating:  13%|█▎        | 22/165 [00:08<00:51,  2.75it/s]Evaluating:  14%|█▍        | 23/165 [00:08<00:51,  2.77it/s]Evaluating:  15%|█▍        | 24/165 [00:09<00:50,  2.79it/s]Evaluating:  15%|█▌        | 25/165 [00:09<00:51,  2.74it/s]Evaluating:  16%|█▌        | 26/165 [00:09<00:50,  2.76it/s]Evaluating:  16%|█▋        | 27/165 [00:10<00:49,  2.77it/s]Evaluating:  17%|█▋        | 28/165 [00:10<00:49,  2.79it/s]Evaluating:  18%|█▊        | 29/165 [00:10<00:48,  2.80it/s]Evaluating:  18%|█▊        | 30/165 [00:11<00:49,  2.74it/s]Evaluating:  19%|█▉        | 31/165 [00:11<00:48,  2.74it/s]Evaluating:  19%|█▉        | 32/165 [00:12<00:48,  2.72it/s]Evaluating:  20%|██        | 33/165 [00:12<00:48,  2.73it/s]Evaluating:  21%|██        | 34/165 [00:12<00:47,  2.76it/s]Evaluating:  21%|██        | 35/165 [00:13<00:46,  2.78it/s]Evaluating:  22%|██▏       | 36/165 [00:13<00:46,  2.78it/s]Evaluating:  22%|██▏       | 37/165 [00:13<00:46,  2.78it/s]Evaluating:  23%|██▎       | 38/165 [00:14<00:45,  2.78it/s]Evaluating:  24%|██▎       | 39/165 [00:14<00:45,  2.78it/s]Evaluating:  24%|██▍       | 40/165 [00:14<00:45,  2.77it/s]Evaluating:  25%|██▍       | 41/165 [00:15<00:44,  2.77it/s]Evaluating:  25%|██▌       | 42/165 [00:15<00:44,  2.75it/s]Evaluating:  26%|██▌       | 43/165 [00:16<00:44,  2.74it/s]Evaluating:  27%|██▋       | 44/165 [00:16<00:43,  2.75it/s]Evaluating:  27%|██▋       | 45/165 [00:16<00:43,  2.76it/s]Evaluating:  28%|██▊       | 46/165 [00:17<00:42,  2.77it/s]Evaluating:  28%|██▊       | 47/165 [00:17<00:42,  2.75it/s]Evaluating:  29%|██▉       | 48/165 [00:17<00:42,  2.76it/s]Evaluating:  30%|██▉       | 49/165 [00:18<00:42,  2.73it/s]Evaluating:  30%|███       | 50/165 [00:18<00:42,  2.69it/s]Evaluating:  31%|███       | 51/165 [00:18<00:41,  2.71it/s]Evaluating:  32%|███▏      | 52/165 [00:19<00:41,  2.71it/s]Evaluating:  32%|███▏      | 53/165 [00:19<00:41,  2.72it/s]Evaluating:  33%|███▎      | 54/165 [00:20<00:41,  2.70it/s]Evaluating:  33%|███▎      | 55/165 [00:20<00:40,  2.71it/s]Evaluating:  34%|███▍      | 56/165 [00:20<00:39,  2.73it/s]Evaluating:  35%|███▍      | 57/165 [00:21<00:39,  2.74it/s]Evaluating:  35%|███▌      | 58/165 [00:21<00:38,  2.75it/s]Evaluating:  36%|███▌      | 59/165 [00:21<00:38,  2.74it/s]Evaluating:  36%|███▋      | 60/165 [00:22<00:38,  2.75it/s]Evaluating:  37%|███▋      | 61/165 [00:22<00:37,  2.75it/s]Evaluating:  38%|███▊      | 62/165 [00:22<00:37,  2.75it/s]Evaluating:  38%|███▊      | 63/165 [00:23<00:36,  2.76it/s]Evaluating:  39%|███▉      | 64/165 [00:23<00:36,  2.77it/s]Evaluating:  39%|███▉      | 65/165 [00:24<00:36,  2.76it/s]Evaluating:  40%|████      | 66/165 [00:24<00:35,  2.76it/s]Evaluating:  41%|████      | 67/165 [00:24<00:35,  2.77it/s]Evaluating:  41%|████      | 68/165 [00:25<00:35,  2.76it/s]Evaluating:  42%|████▏     | 69/165 [00:25<00:34,  2.76it/s]Evaluating:  42%|████▏     | 70/165 [00:25<00:34,  2.76it/s]Evaluating:  43%|████▎     | 71/165 [00:26<00:33,  2.77it/s]Evaluating:  44%|████▎     | 72/165 [00:26<00:33,  2.77it/s]Evaluating:  44%|████▍     | 73/165 [00:26<00:33,  2.78it/s]Evaluating:  45%|████▍     | 74/165 [00:27<00:32,  2.78it/s]Evaluating:  45%|████▌     | 75/165 [00:27<00:32,  2.78it/s]Evaluating:  46%|████▌     | 76/165 [00:28<00:32,  2.78it/s]Evaluating:  47%|████▋     | 77/165 [00:28<00:31,  2.78it/s]Evaluating:  47%|████▋     | 78/165 [00:28<00:31,  2.78it/s]Evaluating:  48%|████▊     | 79/165 [00:29<00:31,  2.76it/s]Evaluating:  48%|████▊     | 80/165 [00:29<00:30,  2.76it/s]Evaluating:  49%|████▉     | 81/165 [00:29<00:30,  2.75it/s]Evaluating:  50%|████▉     | 82/165 [00:30<00:30,  2.75it/s]Evaluating:  50%|█████     | 83/165 [00:30<00:29,  2.76it/s]Evaluating:  51%|█████     | 84/165 [00:30<00:29,  2.76it/s]Evaluating:  52%|█████▏    | 85/165 [00:31<00:29,  2.75it/s]Evaluating:  52%|█████▏    | 86/165 [00:31<00:28,  2.76it/s]Evaluating:  53%|█████▎    | 87/165 [00:31<00:28,  2.76it/s]Evaluating:  53%|█████▎    | 88/165 [00:32<00:27,  2.76it/s]Evaluating:  54%|█████▍    | 89/165 [00:32<00:27,  2.76it/s]Evaluating:  55%|█████▍    | 90/165 [00:33<00:27,  2.75it/s]Evaluating:  55%|█████▌    | 91/165 [00:33<00:26,  2.75it/s]Evaluating:  56%|█████▌    | 92/165 [00:33<00:26,  2.74it/s]Evaluating:  56%|█████▋    | 93/165 [00:34<00:26,  2.74it/s]Evaluating:  57%|█████▋    | 94/165 [00:34<00:25,  2.74it/s]Evaluating:  58%|█████▊    | 95/165 [00:34<00:25,  2.73it/s]Evaluating:  58%|█████▊    | 96/165 [00:35<00:25,  2.73it/s]Evaluating:  59%|█████▉    | 97/165 [00:35<00:24,  2.73it/s]Evaluating:  59%|█████▉    | 98/165 [00:36<00:24,  2.74it/s]Evaluating:  60%|██████    | 99/165 [00:36<00:24,  2.74it/s]Evaluating:  61%|██████    | 100/165 [00:36<00:23,  2.75it/s]Evaluating:  61%|██████    | 101/165 [00:37<00:23,  2.74it/s]Evaluating:  62%|██████▏   | 102/165 [00:37<00:22,  2.75it/s]Evaluating:  62%|██████▏   | 103/165 [00:37<00:22,  2.75it/s]Evaluating:  63%|██████▎   | 104/165 [00:38<00:22,  2.76it/s]Evaluating:  64%|██████▎   | 105/165 [00:38<00:21,  2.75it/s]Evaluating:  64%|██████▍   | 106/165 [00:38<00:21,  2.75it/s]Evaluating:  65%|██████▍   | 107/165 [00:39<00:21,  2.75it/s]Evaluating:  65%|██████▌   | 108/165 [00:39<00:20,  2.76it/s]Evaluating:  66%|██████▌   | 109/165 [00:39<00:20,  2.77it/s]Evaluating:  67%|██████▋   | 110/165 [00:40<00:19,  2.76it/s]Evaluating:  67%|██████▋   | 111/165 [00:40<00:19,  2.76it/s]Evaluating:  68%|██████▊   | 112/165 [00:41<00:19,  2.77it/s]Evaluating:  68%|██████▊   | 113/165 [00:41<00:18,  2.75it/s]Evaluating:  69%|██████▉   | 114/165 [00:41<00:18,  2.76it/s]Evaluating:  70%|██████▉   | 115/165 [00:42<00:18,  2.76it/s]Evaluating:  70%|███████   | 116/165 [00:42<00:17,  2.77it/s]Evaluating:  71%|███████   | 117/165 [00:42<00:17,  2.77it/s]Evaluating:  72%|███████▏  | 118/165 [00:43<00:16,  2.77it/s]Evaluating:  72%|███████▏  | 119/165 [00:43<00:16,  2.75it/s]Evaluating:  73%|███████▎  | 120/165 [00:43<00:16,  2.74it/s]Evaluating:  73%|███████▎  | 121/165 [00:44<00:16,  2.74it/s]Evaluating:  74%|███████▍  | 122/165 [00:44<00:15,  2.75it/s]Evaluating:  75%|███████▍  | 123/165 [00:45<00:15,  2.75it/s]Evaluating:  75%|███████▌  | 124/165 [00:45<00:15,  2.72it/s]Evaluating:  76%|███████▌  | 125/165 [00:45<00:14,  2.71it/s]Evaluating:  76%|███████▋  | 126/165 [00:46<00:14,  2.72it/s]Evaluating:  77%|███████▋  | 127/165 [00:46<00:13,  2.74it/s]Evaluating:  78%|███████▊  | 128/165 [00:46<00:13,  2.75it/s]Evaluating:  78%|███████▊  | 129/165 [00:47<00:13,  2.75it/s]Evaluating:  79%|███████▉  | 130/165 [00:47<00:12,  2.74it/s]Evaluating:  79%|███████▉  | 131/165 [00:48<00:12,  2.75it/s]Evaluating:  80%|████████  | 132/165 [00:48<00:12,  2.72it/s]Evaluating:  81%|████████  | 133/165 [00:48<00:11,  2.67it/s]Evaluating:  81%|████████  | 134/165 [00:49<00:11,  2.71it/s]Evaluating:  82%|████████▏ | 135/165 [00:49<00:10,  2.73it/s]Evaluating:  82%|████████▏ | 136/165 [00:49<00:10,  2.75it/s]Evaluating:  83%|████████▎ | 137/165 [00:50<00:10,  2.76it/s]Evaluating:  84%|████████▎ | 138/165 [00:50<00:09,  2.77it/s]Evaluating:  84%|████████▍ | 139/165 [00:50<00:09,  2.76it/s]Evaluating:  85%|████████▍ | 140/165 [00:51<00:09,  2.77it/s]Evaluating:  85%|████████▌ | 141/165 [00:51<00:08,  2.77it/s]Evaluating:  86%|████████▌ | 142/165 [00:52<00:08,  2.77it/s]Evaluating:  87%|████████▋ | 143/165 [00:52<00:07,  2.77it/s]Evaluating:  87%|████████▋ | 144/165 [00:52<00:07,  2.77it/s]Evaluating:  88%|████████▊ | 145/165 [00:53<00:07,  2.68it/s]Evaluating:  88%|████████▊ | 146/165 [00:53<00:07,  2.67it/s]Evaluating:  89%|████████▉ | 147/165 [00:53<00:06,  2.70it/s]Evaluating:  90%|████████▉ | 148/165 [00:54<00:06,  2.72it/s]Evaluating:  90%|█████████ | 149/165 [00:54<00:05,  2.74it/s]Evaluating:  91%|█████████ | 150/165 [00:54<00:05,  2.75it/s]Evaluating:  92%|█████████▏| 151/165 [00:55<00:05,  2.76it/s]Evaluating:  92%|█████████▏| 152/165 [00:55<00:04,  2.73it/s]Evaluating:  93%|█████████▎| 153/165 [00:56<00:04,  2.69it/s]Evaluating:  93%|█████████▎| 154/165 [00:56<00:04,  2.71it/s]Evaluating:  94%|█████████▍| 155/165 [00:56<00:03,  2.70it/s]Evaluating:  95%|█████████▍| 156/165 [00:57<00:03,  2.71it/s]Evaluating:  95%|█████████▌| 157/165 [00:57<00:02,  2.73it/s]Evaluating:  96%|█████████▌| 158/165 [00:57<00:02,  2.73it/s]Evaluating:  96%|█████████▋| 159/165 [00:58<00:02,  2.73it/s]Evaluating:  97%|█████████▋| 160/165 [00:58<00:01,  2.71it/s]Evaluating:  98%|█████████▊| 161/165 [00:59<00:01,  2.71it/s]Evaluating:  98%|█████████▊| 162/165 [00:59<00:01,  2.72it/s]Evaluating:  99%|█████████▉| 163/165 [00:59<00:00,  2.73it/s]Evaluating:  99%|█████████▉| 164/165 [01:00<00:00,  2.74it/s]Evaluating: 100%|██████████| 165/165 [01:00<00:00,  3.49it/s]Evaluating: 100%|██████████| 165/165 [01:00<00:00,  2.74it/s]
05/09/2022 20:08:29 - INFO - __main__ -     Evaluation done in total 60.204936 secs (0.045818 sec per example)
05/09/2022 20:08:33 - INFO - __main__ -   Results: {'exact': 60.588235294117645, 'f1': 80.02115256793604, 'total': 1190, 'HasAns_exact': 60.588235294117645, 'HasAns_f1': 80.02115256793604, 'HasAns_total': 1190, 'best_exact': 60.588235294117645, 'best_exact_thresh': 0.0, 'best_f1': 80.02115256793604, 'best_f1_thresh': 0.0}
  th 
2022-05-09 20:08:37.690664: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0
05/09/2022 20:08:40 - WARNING - __main__ -   Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, 16-bits training: False
You are using a model of type xlm-roberta to instantiate a model of type xlm. This is not supported for all configurations of models and can yield errors.
Some weights of the model checkpoint at /cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//squad/xlm-KG_LR8e-6_EPOCH2.0_maxlen384_batchsize4_gradacc4 were not used when initializing XLMRobertaModel: ['base_model.encoder.layer.0.attention.self.key.bias', 'base_model.encoder.layer.1.attention.self.value.weight', 'base_model.encoder.layer.14.intermediate.dense.bias', 'base_model.encoder.layer.3.attention.self.value.bias', 'base_model.encoder.layer.12.attention.self.query.weight', 'base_model.encoder.layer.2.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.21.output.LayerNorm.weight', 'base_model.encoder.layer.21.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.20.output.dense.bias', 'base_model.encoder.layer.2.attention.output.dense.bias', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.1.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.18.output.LayerNorm.bias', 'base_model.encoder.layer.21.attention.self.query.weight', 'base_model.encoder.layer.14.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.3.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.15.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.8.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.21.intermediate.dense.weight', 'base_model.encoder.layer.22.output.LayerNorm.bias', 'base_model.encoder.layer.14.output.dense.weight', 'base_model.encoder.layer.8.attention.self.value.weight', 'base_model.encoder.layer.15.attention.output.LayerNorm.weight', 'base_model.encoder.layer.15.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.21.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.6.attention.output.LayerNorm.weight', 'base_model.encoder.layer.7.output.dense.bias', 'base_model.encoder.layer.0.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.4.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.2.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.11.attention.self.key.bias', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.1.attention.output.dense.bias', 'base_model.encoder.layer.14.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.0.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.22.output.dense.bias', 'base_model.encoder.layer.9.output.LayerNorm.weight', 'base_model.encoder.layer.3.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.1.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.6.output.dense.bias', 'base_model.encoder.layer.10.attention.output.LayerNorm.weight', 'base_model.encoder.layer.18.output.dense.weight', 'base_model.encoder.layer.14.output.LayerNorm.bias', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.2.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.4.intermediate.dense.weight', 'base_model.encoder.layer.20.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.7.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.2.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.7.attention.self.key.bias', 'base_model.encoder.layer.0.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.15.attention.output.dense.weight', 'base_model.encoder.layer.16.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.5.attention.self.key.bias', 'base_model.encoder.layer.11.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.2.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.0.attention.output.dense.bias', 'base_model.encoder.layer.15.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.22.attention.self.key.bias', 'base_model.encoder.layer.14.attention.self.key.bias', 'base_model.encoder.layer.13.output.LayerNorm.weight', 'base_model.encoder.layer.15.output.LayerNorm.bias', 'base_model.encoder.layer.4.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.17.output.dense.bias', 'base_model.encoder.layer.2.attention.self.query.bias', 'base_model.encoder.layer.16.attention.output.LayerNorm.bias', 'base_model.encoder.layer.17.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.17.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.5.attention.self.value.bias', 'base_model.encoder.layer.21.attention.self.value.weight', 'base_model.encoder.layer.20.output.dense.weight', 'base_model.encoder.layer.21.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.14.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.23.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.17.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.21.attention.output.dense.weight', 'base_model.encoder.layer.22.attention.output.LayerNorm.weight', 'base_model.encoder.layer.9.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.21.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.7.intermediate.dense.bias', 'base_model.encoder.layer.18.attention.output.LayerNorm.bias', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.19.attention.output.LayerNorm.weight', 'base_model.encoder.layer.4.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.17.output.dense.weight', 'base_model.encoder.layer.10.attention.self.query.weight', 'base_model.encoder.layer.6.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.1.intermediate.dense.weight', 'base_model.encoder.layer.7.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.8.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.12.attention.self.key.weight', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.17.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.5.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.6.attention.self.value.weight', 'base_model.encoder.layer.0.attention.self.value.weight', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.19.attention.self.query.weight', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.12.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.3.output.LayerNorm.weight', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.19.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.19.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.11.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.14.attention.self.query.bias', 'base_model.encoder.layer.15.attention.output.dense.bias', 'qa_outputs.weight', 'base_model.encoder.layer.3.intermediate.dense.weight', 'base_model.encoder.layer.2.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.5.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.21.output.dense.bias', 'base_model.encoder.layer.5.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.4.attention.self.value.bias', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.2.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.5.attention.output.LayerNorm.weight', 'base_model.encoder.layer.23.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.1.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.19.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.2.output.dense.bias', 'base_model.encoder.layer.1.attention.output.LayerNorm.bias', 'base_model.encoder.layer.19.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.19.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.2.attention.output.LayerNorm.bias', 'base_model.encoder.layer.9.attention.self.query.bias', 'base_model.encoder.layer.0.attention.output.LayerNorm.bias', 'base_model.encoder.layer.22.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.22.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.10.attention.self.value.bias', 'base_model.encoder.layer.12.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.20.attention.self.value.bias', 'base_model.encoder.layer.7.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.5.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.12.attention.output.dense.weight', 'base_model.encoder.layer.16.attention.output.LayerNorm.weight', 'base_model.encoder.layer.9.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.5.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.3.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.2.intermediate.dense.weight', 'base_model.encoder.layer.8.attention.self.value.bias', 'base_model.encoder.layer.17.attention.self.key.weight', 'base_model.encoder.layer.17.attention.self.value.bias', 'base_model.encoder.layer.23.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.7.intermediate.dense.weight', 'base_model.encoder.layer.22.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.14.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.9.intermediate.dense.bias', 'base_model.encoder.layer.18.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.14.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.22.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.16.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.7.output.LayerNorm.weight', 'base_model.encoder.layer.4.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.5.attention.self.query.bias', 'base_model.encoder.layer.8.output.dense.bias', 'base_model.encoder.layer.18.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.2.output.LayerNorm.weight', 'base_model.encoder.layer.8.attention.output.LayerNorm.bias', 'base_model.encoder.layer.23.attention.output.dense.bias', 'base_model.encoder.layer.23.intermediate.dense.bias', 'base_model.encoder.layer.8.output.adapters.es.adapter_down.0.weight', 'base_model.pooler.dense.weight', 'base_model.encoder.layer.10.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.5.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.6.attention.output.dense.bias', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.0.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.23.output.dense.bias', 'base_model.encoder.layer.15.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.19.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.1.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.20.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.4.attention.output.dense.bias', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.16.attention.self.query.weight', 'base_model.embeddings.position_embeddings.weight', 'base_model.encoder.layer.14.attention.self.value.bias', 'base_model.encoder.layer.20.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.7.attention.output.dense.weight', 'base_model.encoder.layer.23.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.15.output.dense.bias', 'base_model.encoder.layer.3.attention.self.value.weight', 'base_model.encoder.layer.23.attention.self.value.bias', 'base_model.encoder.layer.17.attention.self.query.weight', 'base_model.encoder.layer.0.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.1.output.dense.bias', 'base_model.encoder.layer.4.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.23.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.19.attention.self.value.weight', 'base_model.encoder.layer.3.output.LayerNorm.bias', 'base_model.encoder.layer.10.attention.output.dense.bias', 'base_model.encoder.layer.20.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.10.output.LayerNorm.weight', 'base_model.encoder.layer.3.output.adapters.es.adapter_down.0.bias', 'base_model.embeddings.LayerNorm.weight', 'base_model.encoder.layer.0.attention.self.value.bias', 'base_model.encoder.layer.6.intermediate.dense.weight', 'base_model.encoder.layer.14.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.21.attention.self.value.bias', 'base_model.encoder.layer.7.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.11.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.10.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.21.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.2.output.LayerNorm.bias', 'base_model.encoder.layer.5.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.8.attention.self.query.bias', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.13.attention.self.key.bias', 'base_model.encoder.layer.19.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.1.output.LayerNorm.weight', 'base_model.encoder.layer.0.output.LayerNorm.bias', 'base_model.encoder.layer.1.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.14.intermediate.dense.weight', 'base_model.encoder.layer.9.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.1.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.3.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.4.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.2.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.16.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.4.attention.output.dense.weight', 'base_model.encoder.layer.15.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.23.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.5.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.4.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.16.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.17.attention.output.dense.bias', 'base_model.encoder.layer.21.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.17.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.17.attention.self.query.bias', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.20.intermediate.dense.weight', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.10.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.13.output.dense.bias', 'base_model.encoder.layer.12.attention.output.LayerNorm.bias', 'base_model.encoder.layer.9.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.13.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.23.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.3.output.dense.weight', 'base_model.encoder.layer.9.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.16.intermediate.dense.weight', 'base_model.encoder.layer.12.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.12.attention.self.value.weight', 'base_model.encoder.layer.3.attention.output.dense.bias', 'base_model.encoder.layer.7.attention.self.query.bias', 'base_model.encoder.layer.4.output.dense.bias', 'base_model.encoder.layer.1.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.1.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.20.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.5.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.19.attention.self.key.bias', 'base_model.encoder.layer.4.attention.self.value.weight', 'base_model.encoder.layer.15.attention.self.value.bias', 'base_model.encoder.layer.3.output.dense.bias', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.12.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.15.attention.self.query.weight', 'base_model.encoder.layer.21.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.1.attention.self.key.weight', 'base_model.encoder.layer.4.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.6.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.20.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.9.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.20.intermediate.dense.bias', 'base_model.encoder.layer.8.attention.output.dense.bias', 'base_model.encoder.layer.4.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.5.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.12.output.LayerNorm.weight', 'base_model.encoder.layer.19.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.1.attention.self.query.bias', 'base_model.encoder.layer.22.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.0.attention.output.dense.weight', 'base_model.encoder.layer.5.output.dense.bias', 'base_model.encoder.layer.19.attention.output.dense.weight', 'base_model.encoder.layer.7.attention.output.LayerNorm.bias', 'base_model.encoder.layer.10.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.11.intermediate.dense.bias', 'base_model.encoder.layer.10.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.11.output.LayerNorm.weight', 'base_model.encoder.layer.6.output.dense.weight', 'base_model.encoder.layer.0.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.6.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.23.output.LayerNorm.bias', 'base_model.encoder.layer.21.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.17.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.0.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.11.attention.self.key.weight', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.21.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.10.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.19.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.12.output.dense.weight', 'base_model.encoder.layer.15.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.21.output.LayerNorm.bias', 'base_model.encoder.layer.22.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.3.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.11.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.2.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.16.output.dense.bias', 'base_model.encoder.layer.11.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.16.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.16.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.8.attention.output.LayerNorm.weight', 'base_model.encoder.layer.10.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.2.attention.self.key.bias', 'base_model.encoder.layer.19.attention.self.value.bias', 'base_model.encoder.layer.1.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.6.intermediate.dense.bias', 'base_model.encoder.layer.15.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.21.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.10.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.7.attention.output.dense.bias', 'base_model.encoder.layer.20.attention.output.dense.bias', 'base_model.encoder.layer.8.attention.self.key.weight', 'base_model.encoder.layer.17.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.6.attention.output.LayerNorm.bias', 'base_model.encoder.layer.7.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.4.attention.self.query.weight', 'base_model.encoder.layer.1.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.10.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.14.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.2.attention.output.LayerNorm.weight', 'base_model.encoder.layer.13.attention.output.dense.bias', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.3.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.7.attention.output.LayerNorm.weight', 'base_model.encoder.layer.14.attention.output.LayerNorm.bias', 'base_model.encoder.layer.19.attention.self.key.weight', 'base_model.encoder.layer.0.attention.output.LayerNorm.weight', 'base_model.encoder.layer.18.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.10.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.20.output.LayerNorm.bias', 'base_model.encoder.layer.21.attention.self.key.weight', 'base_model.encoder.layer.21.attention.self.key.bias', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.14.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.2.attention.output.dense.weight', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.11.attention.output.dense.weight', 'base_model.encoder.layer.19.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.0.attention.self.query.weight', 'base_model.encoder.layer.4.attention.self.key.weight', 'base_model.encoder.layer.4.attention.self.key.bias', 'base_model.encoder.layer.12.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.14.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.4.attention.output.LayerNorm.weight', 'base_model.encoder.layer.17.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.11.attention.self.value.weight', 'base_model.encoder.layer.11.attention.output.dense.bias', 'base_model.encoder.layer.21.attention.output.LayerNorm.bias', 'base_model.encoder.layer.14.output.LayerNorm.weight', 'base_model.encoder.layer.13.attention.self.value.bias', 'base_model.encoder.layer.1.output.dense.weight', 'base_model.encoder.layer.22.output.dense.weight', 'base_model.encoder.layer.14.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.6.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.23.attention.output.LayerNorm.weight', 'base_model.encoder.layer.8.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.7.attention.self.value.bias', 'base_model.encoder.layer.21.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.0.intermediate.dense.bias', 'base_model.encoder.layer.15.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.2.attention.self.value.bias', 'base_model.encoder.layer.23.output.LayerNorm.weight', 'base_model.encoder.layer.20.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.7.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.18.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.13.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.17.attention.output.LayerNorm.bias', 'base_model.encoder.layer.4.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.18.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.21.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.20.attention.output.dense.weight', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.1.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.11.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.13.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.20.attention.self.key.bias', 'base_model.encoder.layer.10.output.LayerNorm.bias', 'base_model.encoder.layer.13.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.5.attention.self.key.weight', 'base_model.encoder.layer.19.output.LayerNorm.weight', 'base_model.encoder.layer.0.output.dense.bias', 'base_model.encoder.layer.19.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.8.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.8.output.dense.weight', 'base_model.encoder.layer.18.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.10.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.11.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.14.attention.self.key.weight', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.1.attention.self.query.weight', 'base_model.encoder.layer.1.attention.self.value.bias', 'base_model.encoder.layer.6.attention.self.key.weight', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.18.intermediate.dense.weight', 'base_model.encoder.layer.4.attention.self.query.bias', 'base_model.encoder.layer.23.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.10.output.dense.weight', 'base_model.encoder.layer.20.output.LayerNorm.weight', 'base_model.encoder.layer.16.output.LayerNorm.weight', 'base_model.encoder.layer.14.attention.output.dense.bias', 'base_model.encoder.layer.20.attention.self.key.weight', 'base_model.encoder.layer.16.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.1.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.17.intermediate.dense.bias', 'base_model.encoder.layer.3.attention.output.dense.weight', 'base_model.encoder.layer.2.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.18.attention.self.query.bias', 'base_model.encoder.layer.20.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.14.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.12.attention.self.query.bias', 'base_model.encoder.layer.20.attention.output.LayerNorm.weight', 'base_model.encoder.layer.22.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.14.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.3.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.6.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.11.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.20.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.16.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.15.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.17.attention.output.LayerNorm.weight', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.13.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.14.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.4.output.dense.weight', 'base_model.encoder.layer.22.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.5.attention.output.dense.bias', 'base_model.encoder.layer.15.attention.output.LayerNorm.bias', 'base_model.encoder.layer.11.attention.self.query.bias', 'base_model.encoder.layer.23.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.19.attention.output.LayerNorm.bias', 'base_model.encoder.layer.13.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.16.attention.self.query.bias', 'base_model.encoder.layer.14.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.21.intermediate.dense.bias', 'base_model.encoder.layer.15.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.1.output.LayerNorm.bias', 'base_model.encoder.layer.0.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.17.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.3.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.6.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.12.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.3.attention.output.LayerNorm.weight', 'base_model.encoder.layer.8.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.15.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.6.output.LayerNorm.weight', 'base_model.encoder.layer.13.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.18.intermediate.dense.bias', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.15.output.dense.weight', 'base_model.encoder.layer.19.attention.output.dense.bias', 'base_model.encoder.layer.11.output.dense.weight', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.11.attention.self.value.bias', 'base_model.encoder.layer.5.attention.output.dense.weight', 'base_model.encoder.layer.13.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.18.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.20.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.2.output.dense.weight', 'base_model.encoder.layer.0.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.13.output.dense.weight', 'base_model.encoder.layer.16.attention.output.dense.bias', 'base_model.encoder.layer.21.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.9.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.11.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.8.attention.output.dense.weight', 'base_model.encoder.layer.15.output.LayerNorm.weight', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.8.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.4.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.4.intermediate.dense.bias', 'base_model.encoder.layer.14.output.dense.bias', 'base_model.encoder.layer.18.attention.output.dense.weight', 'base_model.encoder.layer.1.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.15.attention.self.query.bias', 'base_model.encoder.layer.23.intermediate.dense.weight', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.9.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.0.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.16.attention.self.value.weight', 'base_model.encoder.layer.23.attention.self.query.weight', 'base_model.encoder.layer.10.attention.self.key.weight', 'base_model.encoder.layer.6.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.16.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.2.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.20.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.0.output.dense.weight', 'base_model.encoder.layer.21.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.22.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.5.output.LayerNorm.weight', 'base_model.encoder.layer.19.output.adapters.ts.adapter_up.weight', 'base_model.pooler.dense.bias', 'base_model.encoder.layer.13.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.11.output.LayerNorm.bias', 'base_model.encoder.layer.19.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.10.intermediate.dense.weight', 'base_model.encoder.layer.10.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.4.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.13.attention.self.query.bias', 'base_model.encoder.layer.16.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.11.attention.output.LayerNorm.weight', 'base_model.encoder.layer.3.attention.self.query.weight', 'base_model.encoder.layer.22.attention.output.dense.bias', 'base_model.encoder.layer.11.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.5.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.15.intermediate.dense.bias', 'base_model.encoder.layer.3.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.9.attention.self.query.weight', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.8.intermediate.dense.bias', 'base_model.encoder.layer.1.attention.self.key.bias', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.12.attention.output.dense.bias', 'base_model.encoder.layer.21.attention.output.dense.bias', 'base_model.encoder.layer.2.attention.self.query.weight', 'base_model.encoder.layer.9.attention.self.value.weight', 'base_model.encoder.layer.3.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.3.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.21.attention.output.LayerNorm.weight', 'base_model.encoder.layer.7.attention.self.value.weight', 'base_model.encoder.layer.8.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.5.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.9.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.22.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.4.attention.output.LayerNorm.bias', 'base_model.encoder.layer.16.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.18.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.11.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.11.attention.self.query.weight', 'base_model.encoder.layer.22.attention.output.dense.weight', 'base_model.encoder.layer.6.attention.self.query.bias', 'base_model.encoder.layer.22.intermediate.dense.weight', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.12.intermediate.dense.bias', 'base_model.encoder.layer.0.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.14.attention.self.value.weight', 'base_model.encoder.layer.22.attention.output.LayerNorm.bias', 'base_model.encoder.layer.12.intermediate.dense.weight', 'base_model.encoder.layer.4.output.LayerNorm.weight', 'base_model.encoder.layer.20.output.adapters.es.adapter_up.weight', 'base_model.embeddings.LayerNorm.bias', 'base_model.encoder.layer.1.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.19.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.17.output.LayerNorm.bias', 'base_model.encoder.layer.12.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.14.attention.output.dense.weight', 'base_model.encoder.layer.3.attention.self.query.bias', 'base_model.encoder.layer.9.attention.self.value.bias', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.23.attention.self.key.bias', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.23.attention.output.dense.weight', 'base_model.encoder.layer.12.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.23.attention.self.key.weight', 'base_model.encoder.layer.18.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.12.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.12.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.19.output.dense.weight', 'base_model.encoder.layer.23.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.9.attention.output.LayerNorm.bias', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.17.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.7.attention.self.key.weight', 'base_model.encoder.layer.8.attention.self.query.weight', 'base_model.encoder.layer.13.attention.self.query.weight', 'base_model.encoder.layer.13.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.19.intermediate.dense.bias', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.2.attention.self.value.weight', 'base_model.encoder.layer.8.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.2.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.16.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.17.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.16.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.11.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.9.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.18.attention.output.LayerNorm.weight', 'base_model.encoder.layer.0.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.5.output.dense.weight', 'base_model.encoder.layer.23.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.0.attention.self.key.weight', 'base_model.encoder.layer.3.attention.self.key.weight', 'base_model.encoder.layer.5.attention.self.query.weight', 'base_model.encoder.layer.20.attention.self.value.weight', 'base_model.encoder.layer.8.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.3.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.1.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.20.attention.self.query.weight', 'base_model.encoder.layer.18.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.21.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.2.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.11.attention.output.LayerNorm.bias', 'base_model.encoder.layer.19.output.dense.bias', 'base_model.encoder.layer.9.attention.output.dense.weight', 'base_model.encoder.layer.18.attention.output.dense.bias', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.19.attention.self.query.bias', 'base_model.encoder.layer.11.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.7.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.9.output.dense.weight', 'base_model.encoder.layer.9.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.16.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.23.output.dense.weight', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.6.attention.self.query.weight', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.7.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.14.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.10.attention.self.value.weight', 'base_model.encoder.layer.3.attention.self.key.bias', 'base_model.encoder.layer.8.output.LayerNorm.bias', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.0.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.8.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.9.output.dense.bias', 'base_model.encoder.layer.13.intermediate.dense.bias', 'base_model.encoder.layer.13.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.22.attention.self.key.weight', 'base_model.encoder.layer.22.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.4.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.18.attention.self.value.bias', 'base_model.encoder.layer.1.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.3.intermediate.dense.bias', 'base_model.encoder.layer.15.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.16.output.dense.weight', 'base_model.encoder.layer.17.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.15.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.14.attention.self.query.weight', 'base_model.encoder.layer.16.output.LayerNorm.bias', 'base_model.encoder.layer.23.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.8.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.21.attention.self.query.bias', 'base_model.encoder.layer.2.intermediate.dense.bias', 'base_model.encoder.layer.13.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.17.attention.self.key.bias', 'base_model.encoder.layer.5.attention.output.LayerNorm.bias', 'base_model.encoder.layer.12.output.LayerNorm.bias', 'base_model.encoder.layer.18.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.16.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.7.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.2.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.6.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.9.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.13.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.22.attention.self.query.bias', 'base_model.encoder.layer.22.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.16.attention.self.key.bias', 'base_model.encoder.layer.6.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.9.intermediate.dense.weight', 'base_model.embeddings.token_type_embeddings.weight', 'base_model.encoder.layer.19.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.8.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.7.attention.self.query.weight', 'base_model.encoder.layer.10.intermediate.dense.bias', 'base_model.encoder.layer.10.attention.self.key.bias', 'base_model.encoder.layer.9.attention.output.LayerNorm.weight', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.6.output.LayerNorm.bias', 'base_model.encoder.layer.22.output.LayerNorm.weight', 'base_model.encoder.layer.10.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.23.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.16.attention.self.value.bias', 'base_model.encoder.layer.18.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.17.intermediate.dense.weight', 'base_model.encoder.layer.23.attention.output.LayerNorm.bias', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.16.attention.output.dense.weight', 'base_model.encoder.layer.11.output.dense.bias', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.18.attention.self.key.bias', 'base_model.encoder.layer.19.intermediate.dense.weight', 'base_model.encoder.layer.23.attention.self.value.weight', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.8.attention.self.key.bias', 'base_model.encoder.layer.5.intermediate.dense.weight', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.0.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.5.intermediate.dense.bias', 'base_model.encoder.layer.8.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.15.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.22.attention.self.value.bias', 'base_model.embeddings.word_embeddings.weight', 'base_model.encoder.layer.3.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.12.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.18.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.18.attention.self.query.weight', 'base_model.encoder.layer.15.attention.self.value.weight', 'base_model.encoder.layer.6.attention.self.value.bias', 'base_model.encoder.layer.14.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.1.attention.output.dense.weight', 'base_model.encoder.layer.5.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.12.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.12.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.1.attention.output.LayerNorm.weight', 'base_model.encoder.layer.12.attention.self.value.bias', 'base_model.encoder.layer.16.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.5.output.LayerNorm.bias', 'base_model.encoder.layer.7.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.6.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.19.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.15.intermediate.dense.weight', 'base_model.encoder.layer.17.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.16.attention.self.key.weight', 'base_model.encoder.layer.19.output.LayerNorm.bias', 'base_model.encoder.layer.12.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.20.attention.self.query.bias', 'base_model.encoder.layer.18.attention.self.key.weight', 'base_model.encoder.layer.7.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.18.output.LayerNorm.weight', 'base_model.encoder.layer.13.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.9.output.LayerNorm.bias', 'base_model.encoder.layer.10.attention.output.dense.weight', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.5.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.9.attention.self.key.weight', 'base_model.encoder.layer.11.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.2.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.17.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.20.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.13.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.22.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.4.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.10.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.16.intermediate.dense.bias', 'base_model.encoder.layer.20.attention.output.LayerNorm.bias', 'base_model.encoder.layer.14.attention.output.LayerNorm.weight', 'base_model.encoder.layer.11.intermediate.dense.weight', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.22.intermediate.dense.bias', 'base_model.encoder.layer.8.intermediate.dense.weight', 'base_model.encoder.layer.2.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.5.attention.self.value.weight', 'qa_outputs.bias', 'base_model.encoder.layer.2.attention.self.key.weight', 'base_model.encoder.layer.7.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.8.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.6.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.18.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.15.attention.self.key.weight', 'base_model.encoder.layer.6.attention.self.key.bias', 'base_model.encoder.layer.20.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.7.output.LayerNorm.bias', 'base_model.encoder.layer.13.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.15.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.12.attention.output.LayerNorm.weight', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.17.attention.self.value.weight', 'base_model.encoder.layer.22.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.3.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.6.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.9.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.13.attention.output.LayerNorm.bias', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.6.attention.output.dense.weight', 'base_model.encoder.layer.22.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.8.output.LayerNorm.weight', 'base_model.encoder.layer.9.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.10.attention.self.query.bias', 'base_model.encoder.layer.18.output.dense.bias', 'base_model.encoder.layer.18.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.21.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.9.attention.self.key.bias', 'base_model.encoder.layer.12.attention.self.key.bias', 'base_model.encoder.layer.20.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.9.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.3.attention.output.LayerNorm.bias', 'base_model.encoder.layer.6.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.22.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.18.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.4.output.LayerNorm.bias', 'base_model.encoder.layer.10.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.13.attention.self.key.weight', 'base_model.encoder.layer.7.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.18.attention.self.value.weight', 'base_model.encoder.layer.10.output.dense.bias', 'base_model.encoder.layer.9.attention.output.dense.bias', 'base_model.encoder.layer.12.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.13.attention.output.dense.weight', 'base_model.encoder.layer.15.attention.self.key.bias', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.1.intermediate.dense.bias', 'base_model.encoder.layer.11.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.4.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.4.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.7.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.10.attention.output.LayerNorm.bias', 'base_model.encoder.layer.23.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.0.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.9.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.6.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.8.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.13.intermediate.dense.weight', 'base_model.encoder.layer.12.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.23.output.adapters.ts.adapter_down.0.bias', 'base_model.embeddings.position_ids', 'base_model.encoder.layer.0.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.15.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.17.attention.output.dense.weight', 'base_model.encoder.layer.0.intermediate.dense.weight', 'base_model.encoder.layer.5.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.11.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.23.attention.self.query.bias', 'base_model.encoder.layer.0.output.LayerNorm.weight', 'base_model.encoder.layer.7.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.23.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.22.attention.self.query.weight', 'base_model.encoder.layer.17.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.7.output.dense.weight', 'base_model.encoder.layer.13.attention.output.LayerNorm.weight', 'base_model.encoder.layer.13.attention.self.value.weight', 'base_model.encoder.layer.0.attention.self.query.bias', 'base_model.encoder.layer.13.output.LayerNorm.bias', 'base_model.encoder.layer.21.output.dense.weight', 'base_model.encoder.layer.12.output.dense.bias', 'base_model.encoder.layer.17.output.LayerNorm.weight', 'base_model.encoder.layer.6.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.22.attention.self.value.weight', 'base_model.encoder.layer.17.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.10.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.3.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.7.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.6.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.20.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.5.output.adapters.tp.adapter_down.0.bias']
- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of XLMRobertaModel were not initialized from the model checkpoint at /cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//squad/xlm-KG_LR8e-6_EPOCH2.0_maxlen384_batchsize4_gradacc4 and are newly initialized: ['encoder.layer.0.attention.self.value.weight', 'encoder.layer.11.output.dense.weight', 'encoder.layer.2.output.dense.bias', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.4.attention.self.value.weight', 'encoder.layer.5.attention.output.LayerNorm.weight', 'encoder.layer.6.attention.self.value.weight', 'encoder.layer.17.output.LayerNorm.bias', 'encoder.layer.18.attention.self.query.weight', 'encoder.layer.14.intermediate.dense.bias', 'encoder.layer.5.attention.self.key.bias', 'encoder.layer.7.output.dense.bias', 'encoder.layer.7.output.LayerNorm.weight', 'encoder.layer.14.attention.output.LayerNorm.weight', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.4.output.dense.bias', 'encoder.layer.16.attention.output.LayerNorm.weight', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.9.output.LayerNorm.bias', 'encoder.layer.7.attention.output.dense.bias', 'encoder.layer.1.attention.self.query.weight', 'encoder.layer.13.attention.self.key.bias', 'encoder.layer.1.attention.output.dense.weight', 'encoder.layer.22.attention.self.query.weight', 'encoder.layer.19.attention.output.LayerNorm.bias', 'encoder.layer.11.attention.self.key.weight', 'encoder.layer.2.attention.self.key.bias', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.13.attention.self.key.weight', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.22.attention.self.key.weight', 'encoder.layer.9.attention.self.key.bias', 'encoder.layer.6.attention.output.LayerNorm.weight', 'encoder.layer.13.output.LayerNorm.bias', 'encoder.layer.10.attention.output.LayerNorm.bias', 'encoder.layer.11.attention.self.query.bias', 'encoder.layer.7.attention.self.value.weight', 'encoder.layer.18.intermediate.dense.weight', 'encoder.layer.21.output.LayerNorm.bias', 'encoder.layer.8.attention.output.dense.bias', 'encoder.layer.17.attention.output.dense.weight', 'encoder.layer.2.attention.self.query.weight', 'encoder.layer.1.attention.output.dense.bias', 'encoder.layer.20.attention.output.LayerNorm.weight', 'encoder.layer.10.output.LayerNorm.bias', 'encoder.layer.13.intermediate.dense.bias', 'encoder.layer.11.output.LayerNorm.bias', 'encoder.layer.23.attention.self.key.bias', 'encoder.layer.10.intermediate.dense.weight', 'encoder.layer.6.attention.self.query.weight', 'encoder.layer.5.attention.output.dense.weight', 'encoder.layer.1.output.dense.weight', 'encoder.layer.12.attention.self.value.bias', 'encoder.layer.17.output.dense.weight', 'encoder.layer.23.attention.self.query.bias', 'encoder.layer.7.attention.output.LayerNorm.bias', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.layer.7.attention.output.LayerNorm.weight', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.22.intermediate.dense.bias', 'encoder.layer.9.attention.output.dense.bias', 'encoder.layer.21.attention.self.value.bias', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.11.attention.self.value.weight', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.11.attention.self.query.weight', 'encoder.layer.16.attention.self.value.bias', 'encoder.layer.10.output.LayerNorm.weight', 'encoder.layer.10.attention.self.query.bias', 'encoder.layer.12.intermediate.dense.weight', 'encoder.layer.21.attention.self.query.weight', 'encoder.layer.14.output.dense.weight', 'encoder.layer.7.output.LayerNorm.bias', 'encoder.layer.3.attention.output.dense.weight', 'encoder.layer.14.attention.self.key.weight', 'encoder.layer.10.output.dense.weight', 'encoder.layer.9.output.LayerNorm.weight', 'encoder.layer.9.attention.output.LayerNorm.weight', 'encoder.layer.5.output.dense.weight', 'embeddings.position_embeddings.weight', 'encoder.layer.12.attention.output.LayerNorm.bias', 'encoder.layer.23.intermediate.dense.bias', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.4.attention.self.query.weight', 'encoder.layer.16.output.LayerNorm.weight', 'encoder.layer.22.attention.self.query.bias', 'pooler.dense.weight', 'encoder.layer.1.attention.self.value.bias', 'encoder.layer.23.attention.self.value.weight', 'encoder.layer.14.attention.self.value.weight', 'encoder.layer.12.output.dense.bias', 'encoder.layer.14.attention.self.value.bias', 'encoder.layer.5.output.LayerNorm.bias', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.22.attention.self.value.bias', 'encoder.layer.7.attention.self.key.weight', 'encoder.layer.13.attention.output.dense.weight', 'encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.layer.13.attention.self.value.weight', 'encoder.layer.4.attention.output.LayerNorm.weight', 'encoder.layer.21.attention.self.value.weight', 'encoder.layer.17.attention.self.key.bias', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.10.attention.self.key.bias', 'encoder.layer.11.output.LayerNorm.weight', 'encoder.layer.15.attention.self.key.bias', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.7.attention.output.dense.weight', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.3.output.dense.bias', 'embeddings.word_embeddings.weight', 'encoder.layer.9.output.dense.bias', 'encoder.layer.6.attention.output.dense.weight', 'encoder.layer.15.attention.self.value.weight', 'encoder.layer.14.attention.output.LayerNorm.bias', 'encoder.layer.0.attention.output.dense.weight', 'embeddings.token_type_embeddings.weight', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.18.output.dense.weight', 'encoder.layer.20.attention.output.dense.bias', 'encoder.layer.8.attention.self.key.bias', 'encoder.layer.23.attention.self.query.weight', 'encoder.layer.18.output.LayerNorm.bias', 'encoder.layer.7.attention.self.value.bias', 'encoder.layer.12.output.LayerNorm.bias', 'encoder.layer.15.attention.output.dense.bias', 'encoder.layer.0.attention.self.value.bias', 'encoder.layer.18.attention.self.query.bias', 'encoder.layer.12.attention.self.query.weight', 'encoder.layer.16.attention.self.key.weight', 'encoder.layer.7.attention.self.key.bias', 'embeddings.LayerNorm.bias', 'encoder.layer.16.attention.self.value.weight', 'encoder.layer.13.attention.output.dense.bias', 'encoder.layer.15.attention.self.query.bias', 'encoder.layer.19.attention.output.dense.bias', 'encoder.layer.1.attention.self.value.weight', 'encoder.layer.4.attention.output.dense.weight', 'encoder.layer.10.attention.output.LayerNorm.weight', 'encoder.layer.19.attention.self.key.bias', 'encoder.layer.21.intermediate.dense.weight', 'encoder.layer.3.attention.self.query.bias', 'encoder.layer.6.output.dense.weight', 'encoder.layer.5.attention.self.value.weight', 'encoder.layer.0.attention.self.query.bias', 'encoder.layer.12.attention.self.key.weight', 'encoder.layer.19.attention.output.dense.weight', 'encoder.layer.8.attention.output.LayerNorm.bias', 'encoder.layer.14.attention.self.query.bias', 'encoder.layer.23.output.LayerNorm.weight', 'encoder.layer.0.attention.output.LayerNorm.weight', 'encoder.layer.3.attention.self.query.weight', 'encoder.layer.8.attention.output.dense.weight', 'encoder.layer.1.attention.output.LayerNorm.weight', 'encoder.layer.7.attention.self.query.weight', 'encoder.layer.23.attention.output.dense.bias', 'encoder.layer.10.attention.self.key.weight', 'encoder.layer.16.attention.output.LayerNorm.bias', 'encoder.layer.8.output.LayerNorm.bias', 'encoder.layer.17.attention.self.value.bias', 'encoder.layer.3.attention.self.key.weight', 'encoder.layer.4.attention.output.dense.bias', 'encoder.layer.19.intermediate.dense.bias', 'encoder.layer.4.attention.self.key.bias', 'encoder.layer.13.attention.output.LayerNorm.bias', 'encoder.layer.14.attention.output.dense.bias', 'encoder.layer.21.attention.output.dense.weight', 'encoder.layer.15.attention.self.query.weight', 'encoder.layer.17.attention.self.key.weight', 'encoder.layer.18.attention.output.dense.weight', 'encoder.layer.14.attention.self.query.weight', 'encoder.layer.6.attention.self.key.weight', 'encoder.layer.23.output.LayerNorm.bias', 'encoder.layer.3.attention.output.dense.bias', 'encoder.layer.12.attention.self.value.weight', 'encoder.layer.17.attention.self.value.weight', 'encoder.layer.3.attention.self.value.weight', 'encoder.layer.15.output.LayerNorm.weight', 'encoder.layer.15.attention.output.LayerNorm.bias', 'encoder.layer.3.attention.self.value.bias', 'encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.layer.7.intermediate.dense.bias', 'encoder.layer.2.attention.output.LayerNorm.bias', 'encoder.layer.9.attention.self.query.weight', 'encoder.layer.10.attention.self.query.weight', 'encoder.layer.15.attention.self.value.bias', 'encoder.layer.21.attention.output.LayerNorm.bias', 'encoder.layer.6.output.dense.bias', 'encoder.layer.16.output.LayerNorm.bias', 'encoder.layer.22.attention.self.key.bias', 'encoder.layer.13.output.LayerNorm.weight', 'encoder.layer.4.output.dense.weight', 'encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.layer.6.attention.self.query.bias', 'encoder.layer.9.attention.self.value.weight', 'encoder.layer.18.attention.self.key.weight', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.2.attention.self.query.bias', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.0.attention.self.query.weight', 'encoder.layer.9.attention.output.LayerNorm.bias', 'encoder.layer.17.attention.self.query.bias', 'encoder.layer.9.attention.self.key.weight', 'encoder.layer.17.attention.output.LayerNorm.bias', 'encoder.layer.5.attention.self.query.weight', 'encoder.layer.13.output.dense.bias', 'encoder.layer.19.output.dense.bias', 'encoder.layer.19.attention.self.query.bias', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.1.attention.self.key.weight', 'encoder.layer.18.attention.self.value.bias', 'encoder.layer.20.intermediate.dense.bias', 'encoder.layer.10.attention.self.value.weight', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.10.attention.output.dense.weight', 'encoder.layer.18.attention.output.LayerNorm.bias', 'encoder.layer.8.output.LayerNorm.weight', 'encoder.layer.12.intermediate.dense.bias', 'encoder.layer.14.output.LayerNorm.bias', 'encoder.layer.2.attention.output.LayerNorm.weight', 'encoder.layer.23.attention.output.LayerNorm.weight', 'encoder.layer.12.attention.self.key.bias', 'encoder.layer.23.attention.output.dense.weight', 'encoder.layer.16.attention.self.query.weight', 'encoder.layer.3.output.dense.weight', 'encoder.layer.21.attention.self.key.bias', 'encoder.layer.19.attention.output.LayerNorm.weight', 'encoder.layer.2.attention.self.key.weight', 'encoder.layer.10.output.dense.bias', 'encoder.layer.15.output.dense.bias', 'encoder.layer.8.attention.self.query.weight', 'encoder.layer.11.attention.output.dense.weight', 'encoder.layer.13.attention.self.value.bias', 'encoder.layer.5.attention.self.value.bias', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.15.attention.output.LayerNorm.weight', 'encoder.layer.13.output.dense.weight', 'encoder.layer.19.attention.self.value.bias', 'encoder.layer.8.attention.self.value.weight', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.1.attention.self.query.bias', 'encoder.layer.0.attention.output.dense.bias', 'encoder.layer.2.attention.output.dense.bias', 'encoder.layer.14.attention.output.dense.weight', 'encoder.layer.16.attention.self.query.bias', 'encoder.layer.12.attention.self.query.bias', 'encoder.layer.13.intermediate.dense.weight', 'encoder.layer.5.attention.output.dense.bias', 'encoder.layer.15.intermediate.dense.bias', 'encoder.layer.14.attention.self.key.bias', 'encoder.layer.16.output.dense.bias', 'encoder.layer.23.attention.self.value.bias', 'encoder.layer.0.output.dense.weight', 'encoder.layer.15.output.dense.weight', 'encoder.layer.5.attention.self.query.bias', 'encoder.layer.7.output.dense.weight', 'encoder.layer.13.attention.self.query.weight', 'encoder.layer.20.output.LayerNorm.bias', 'encoder.layer.8.attention.self.value.bias', 'encoder.layer.8.attention.output.LayerNorm.weight', 'encoder.layer.18.output.LayerNorm.weight', 'encoder.layer.2.output.dense.weight', 'encoder.layer.9.output.dense.weight', 'encoder.layer.15.output.LayerNorm.bias', 'encoder.layer.14.intermediate.dense.weight', 'encoder.layer.2.attention.output.dense.weight', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.22.attention.output.LayerNorm.weight', 'encoder.layer.16.intermediate.dense.bias', 'encoder.layer.8.output.dense.bias', 'encoder.layer.23.attention.output.LayerNorm.bias', 'encoder.layer.20.attention.self.key.weight', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.11.attention.self.value.bias', 'encoder.layer.22.output.LayerNorm.bias', 'encoder.layer.11.attention.output.dense.bias', 'encoder.layer.22.intermediate.dense.weight', 'encoder.layer.6.attention.output.LayerNorm.bias', 'encoder.layer.18.attention.output.dense.bias', 'encoder.layer.21.output.dense.bias', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.21.attention.self.query.bias', 'encoder.layer.12.output.LayerNorm.weight', 'encoder.layer.20.attention.output.dense.weight', 'encoder.layer.22.attention.output.dense.weight', 'encoder.layer.4.attention.output.LayerNorm.bias', 'encoder.layer.1.attention.self.key.bias', 'encoder.layer.15.intermediate.dense.weight', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.18.attention.output.LayerNorm.weight', 'encoder.layer.17.output.dense.bias', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.20.attention.self.query.bias', 'encoder.layer.22.attention.self.value.weight', 'encoder.layer.23.output.dense.bias', 'encoder.layer.20.attention.self.value.bias', 'pooler.dense.bias', 'encoder.layer.11.attention.output.LayerNorm.weight', 'encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.layer.18.attention.self.key.bias', 'encoder.layer.14.output.dense.bias', 'encoder.layer.21.attention.self.key.weight', 'encoder.layer.23.intermediate.dense.weight', 'encoder.layer.9.attention.output.dense.weight', 'encoder.layer.3.attention.self.key.bias', 'embeddings.LayerNorm.weight', 'encoder.layer.16.attention.output.dense.weight', 'encoder.layer.6.attention.output.dense.bias', 'encoder.layer.9.attention.self.query.bias', 'encoder.layer.17.output.LayerNorm.weight', 'encoder.layer.16.intermediate.dense.weight', 'encoder.layer.8.attention.self.query.bias', 'encoder.layer.17.attention.output.LayerNorm.weight', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.10.attention.self.value.bias', 'encoder.layer.22.output.dense.weight', 'encoder.layer.0.attention.self.key.bias', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.20.attention.output.LayerNorm.bias', 'encoder.layer.17.intermediate.dense.bias', 'encoder.layer.23.attention.self.key.weight', 'encoder.layer.14.output.LayerNorm.weight', 'encoder.layer.12.attention.output.dense.weight', 'encoder.layer.6.attention.self.value.bias', 'encoder.layer.20.attention.self.value.weight', 'encoder.layer.22.output.LayerNorm.weight', 'encoder.layer.4.attention.self.value.bias', 'encoder.layer.17.attention.output.dense.bias', 'encoder.layer.19.attention.self.key.weight', 'encoder.layer.6.output.LayerNorm.bias', 'encoder.layer.20.output.LayerNorm.weight', 'encoder.layer.1.output.dense.bias', 'encoder.layer.21.attention.output.LayerNorm.weight', 'encoder.layer.5.output.dense.bias', 'encoder.layer.6.attention.self.key.bias', 'encoder.layer.8.attention.self.key.weight', 'encoder.layer.22.output.dense.bias', 'encoder.layer.17.attention.self.query.weight', 'encoder.layer.2.attention.self.value.weight', 'encoder.layer.16.attention.output.dense.bias', 'encoder.layer.12.attention.output.dense.bias', 'encoder.layer.20.attention.self.query.weight', 'encoder.layer.21.output.LayerNorm.weight', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.19.intermediate.dense.weight', 'encoder.layer.13.attention.output.LayerNorm.weight', 'encoder.layer.11.attention.self.key.bias', 'encoder.layer.19.attention.self.query.weight', 'encoder.layer.12.attention.output.LayerNorm.weight', 'encoder.layer.19.output.LayerNorm.weight', 'encoder.layer.12.output.dense.weight', 'encoder.layer.18.output.dense.bias', 'encoder.layer.21.attention.output.dense.bias', 'encoder.layer.20.attention.self.key.bias', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.17.intermediate.dense.weight', 'encoder.layer.9.attention.self.value.bias', 'encoder.layer.7.attention.self.query.bias', 'encoder.layer.16.output.dense.weight', 'encoder.layer.20.output.dense.bias', 'encoder.layer.19.attention.self.value.weight', 'encoder.layer.13.attention.self.query.bias', 'encoder.layer.16.attention.self.key.bias', 'encoder.layer.11.output.dense.bias', 'encoder.layer.20.intermediate.dense.weight', 'encoder.layer.2.attention.self.value.bias', 'encoder.layer.15.attention.self.key.weight', 'encoder.layer.4.attention.self.key.weight', 'encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.layer.19.output.LayerNorm.bias', 'encoder.layer.5.attention.self.key.weight', 'encoder.layer.20.output.dense.weight', 'encoder.layer.18.intermediate.dense.bias', 'encoder.layer.19.output.dense.weight', 'encoder.layer.18.attention.self.value.weight', 'encoder.layer.0.output.dense.bias', 'encoder.layer.22.attention.output.dense.bias', 'encoder.layer.21.intermediate.dense.bias', 'encoder.layer.10.attention.output.dense.bias', 'encoder.layer.0.attention.self.key.weight', 'encoder.layer.15.attention.output.dense.weight', 'encoder.layer.22.attention.output.LayerNorm.bias', 'encoder.layer.23.output.dense.weight', 'encoder.layer.4.attention.self.query.bias', 'encoder.layer.21.output.dense.weight', 'encoder.layer.8.output.dense.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Overwriting existing adapter 'ep'.
Overwriting existing adapter 'tp'.
Overwriting existing adapter 'es'.
Overwriting existing adapter 'ts'.
Overwriting existing adapter fusion module 'ep,tp,es,ts'
05/09/2022 20:09:17 - INFO - __main__ -   lang2id = None
05/09/2022 20:09:21 - INFO - __main__ -   Training/evaluation parameters Namespace(adam_epsilon=1e-08, cache_dir='', config_name='', data_dir=None, device=device(type='cuda'), do_eval=True, do_lower_case=False, do_train=False, doc_stride=128, eval_all_checkpoints=False, eval_lang='th', evaluate_during_training=False, fp16=False, fp16_opt_level='O1', gradient_accumulation_steps=1, learning_rate=5e-05, local_rank=-1, logging_steps=50, max_answer_length=30, max_grad_norm=1.0, max_query_length=64, max_seq_length=384, max_steps=-1, model_name='xlm-KG', model_name_or_path='/cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//squad/xlm-KG_LR8e-6_EPOCH2.0_maxlen384_batchsize4_gradacc4', model_type='xlm', modelkg_dir='/cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/adapter/xlmr_adapter', n_best_size=20, n_gpu=1, no_cuda=False, null_score_diff_threshold=0.0, num_train_epochs=3.0, output_dir='/cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//squad/xlm-KG_LR8e-6_EPOCH2.0_maxlen384_batchsize4_gradacc4/predictions/xquad/', overwrite_cache=False, overwrite_output_dir=False, per_gpu_eval_batch_size=8, per_gpu_train_batch_size=8, predict_file='/cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/download//xquad//xquad.th.json', save_steps=50, seed=42, server_ip='', server_port='', threads=1, tokenizer_name='', train_file=None, train_lang='en', verbose_logging=False, version_2_with_negative=False, warmup_steps=0, weight_decay=0.0)
05/09/2022 20:09:21 - INFO - __main__ -   Loading checkpoint /cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//squad/xlm-KG_LR8e-6_EPOCH2.0_maxlen384_batchsize4_gradacc4 for evaluation
05/09/2022 20:09:21 - INFO - __main__ -   Evaluate the following checkpoints: ['/cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//squad/xlm-KG_LR8e-6_EPOCH2.0_maxlen384_batchsize4_gradacc4']
Some weights of the model checkpoint at /cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//squad/xlm-KG_LR8e-6_EPOCH2.0_maxlen384_batchsize4_gradacc4 were not used when initializing XLMRobertaModel: ['base_model.encoder.layer.0.attention.self.key.bias', 'base_model.encoder.layer.1.attention.self.value.weight', 'base_model.encoder.layer.14.intermediate.dense.bias', 'base_model.encoder.layer.3.attention.self.value.bias', 'base_model.encoder.layer.12.attention.self.query.weight', 'base_model.encoder.layer.2.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.21.output.LayerNorm.weight', 'base_model.encoder.layer.21.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.20.output.dense.bias', 'base_model.encoder.layer.2.attention.output.dense.bias', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.1.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.18.output.LayerNorm.bias', 'base_model.encoder.layer.21.attention.self.query.weight', 'base_model.encoder.layer.14.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.3.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.15.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.8.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.21.intermediate.dense.weight', 'base_model.encoder.layer.22.output.LayerNorm.bias', 'base_model.encoder.layer.14.output.dense.weight', 'base_model.encoder.layer.8.attention.self.value.weight', 'base_model.encoder.layer.15.attention.output.LayerNorm.weight', 'base_model.encoder.layer.15.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.21.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.6.attention.output.LayerNorm.weight', 'base_model.encoder.layer.7.output.dense.bias', 'base_model.encoder.layer.0.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.4.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.2.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.11.attention.self.key.bias', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.1.attention.output.dense.bias', 'base_model.encoder.layer.14.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.0.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.22.output.dense.bias', 'base_model.encoder.layer.9.output.LayerNorm.weight', 'base_model.encoder.layer.3.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.1.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.6.output.dense.bias', 'base_model.encoder.layer.10.attention.output.LayerNorm.weight', 'base_model.encoder.layer.18.output.dense.weight', 'base_model.encoder.layer.14.output.LayerNorm.bias', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.2.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.4.intermediate.dense.weight', 'base_model.encoder.layer.20.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.7.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.2.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.7.attention.self.key.bias', 'base_model.encoder.layer.0.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.15.attention.output.dense.weight', 'base_model.encoder.layer.16.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.5.attention.self.key.bias', 'base_model.encoder.layer.11.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.2.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.0.attention.output.dense.bias', 'base_model.encoder.layer.15.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.22.attention.self.key.bias', 'base_model.encoder.layer.14.attention.self.key.bias', 'base_model.encoder.layer.13.output.LayerNorm.weight', 'base_model.encoder.layer.15.output.LayerNorm.bias', 'base_model.encoder.layer.4.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.17.output.dense.bias', 'base_model.encoder.layer.2.attention.self.query.bias', 'base_model.encoder.layer.16.attention.output.LayerNorm.bias', 'base_model.encoder.layer.17.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.17.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.5.attention.self.value.bias', 'base_model.encoder.layer.21.attention.self.value.weight', 'base_model.encoder.layer.20.output.dense.weight', 'base_model.encoder.layer.21.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.14.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.23.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.17.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.21.attention.output.dense.weight', 'base_model.encoder.layer.22.attention.output.LayerNorm.weight', 'base_model.encoder.layer.9.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.21.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.7.intermediate.dense.bias', 'base_model.encoder.layer.18.attention.output.LayerNorm.bias', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.19.attention.output.LayerNorm.weight', 'base_model.encoder.layer.4.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.17.output.dense.weight', 'base_model.encoder.layer.10.attention.self.query.weight', 'base_model.encoder.layer.6.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.1.intermediate.dense.weight', 'base_model.encoder.layer.7.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.8.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.12.attention.self.key.weight', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.17.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.5.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.6.attention.self.value.weight', 'base_model.encoder.layer.0.attention.self.value.weight', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.19.attention.self.query.weight', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.12.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.3.output.LayerNorm.weight', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.19.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.19.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.11.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.14.attention.self.query.bias', 'base_model.encoder.layer.15.attention.output.dense.bias', 'qa_outputs.weight', 'base_model.encoder.layer.3.intermediate.dense.weight', 'base_model.encoder.layer.2.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.5.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.21.output.dense.bias', 'base_model.encoder.layer.5.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.4.attention.self.value.bias', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.2.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.5.attention.output.LayerNorm.weight', 'base_model.encoder.layer.23.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.1.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.19.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.2.output.dense.bias', 'base_model.encoder.layer.1.attention.output.LayerNorm.bias', 'base_model.encoder.layer.19.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.19.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.2.attention.output.LayerNorm.bias', 'base_model.encoder.layer.9.attention.self.query.bias', 'base_model.encoder.layer.0.attention.output.LayerNorm.bias', 'base_model.encoder.layer.22.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.22.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.10.attention.self.value.bias', 'base_model.encoder.layer.12.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.20.attention.self.value.bias', 'base_model.encoder.layer.7.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.5.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.12.attention.output.dense.weight', 'base_model.encoder.layer.16.attention.output.LayerNorm.weight', 'base_model.encoder.layer.9.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.5.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.3.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.2.intermediate.dense.weight', 'base_model.encoder.layer.8.attention.self.value.bias', 'base_model.encoder.layer.17.attention.self.key.weight', 'base_model.encoder.layer.17.attention.self.value.bias', 'base_model.encoder.layer.23.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.7.intermediate.dense.weight', 'base_model.encoder.layer.22.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.14.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.9.intermediate.dense.bias', 'base_model.encoder.layer.18.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.14.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.22.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.16.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.7.output.LayerNorm.weight', 'base_model.encoder.layer.4.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.5.attention.self.query.bias', 'base_model.encoder.layer.8.output.dense.bias', 'base_model.encoder.layer.18.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.2.output.LayerNorm.weight', 'base_model.encoder.layer.8.attention.output.LayerNorm.bias', 'base_model.encoder.layer.23.attention.output.dense.bias', 'base_model.encoder.layer.23.intermediate.dense.bias', 'base_model.encoder.layer.8.output.adapters.es.adapter_down.0.weight', 'base_model.pooler.dense.weight', 'base_model.encoder.layer.10.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.5.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.6.attention.output.dense.bias', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.0.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.23.output.dense.bias', 'base_model.encoder.layer.15.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.19.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.1.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.20.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.4.attention.output.dense.bias', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.16.attention.self.query.weight', 'base_model.embeddings.position_embeddings.weight', 'base_model.encoder.layer.14.attention.self.value.bias', 'base_model.encoder.layer.20.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.7.attention.output.dense.weight', 'base_model.encoder.layer.23.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.15.output.dense.bias', 'base_model.encoder.layer.3.attention.self.value.weight', 'base_model.encoder.layer.23.attention.self.value.bias', 'base_model.encoder.layer.17.attention.self.query.weight', 'base_model.encoder.layer.0.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.1.output.dense.bias', 'base_model.encoder.layer.4.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.23.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.19.attention.self.value.weight', 'base_model.encoder.layer.3.output.LayerNorm.bias', 'base_model.encoder.layer.10.attention.output.dense.bias', 'base_model.encoder.layer.20.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.10.output.LayerNorm.weight', 'base_model.encoder.layer.3.output.adapters.es.adapter_down.0.bias', 'base_model.embeddings.LayerNorm.weight', 'base_model.encoder.layer.0.attention.self.value.bias', 'base_model.encoder.layer.6.intermediate.dense.weight', 'base_model.encoder.layer.14.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.21.attention.self.value.bias', 'base_model.encoder.layer.7.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.11.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.10.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.21.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.2.output.LayerNorm.bias', 'base_model.encoder.layer.5.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.8.attention.self.query.bias', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.13.attention.self.key.bias', 'base_model.encoder.layer.19.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.1.output.LayerNorm.weight', 'base_model.encoder.layer.0.output.LayerNorm.bias', 'base_model.encoder.layer.1.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.14.intermediate.dense.weight', 'base_model.encoder.layer.9.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.1.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.3.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.4.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.2.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.16.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.4.attention.output.dense.weight', 'base_model.encoder.layer.15.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.23.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.5.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.4.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.16.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.17.attention.output.dense.bias', 'base_model.encoder.layer.21.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.17.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.17.attention.self.query.bias', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.20.intermediate.dense.weight', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.10.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.13.output.dense.bias', 'base_model.encoder.layer.12.attention.output.LayerNorm.bias', 'base_model.encoder.layer.9.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.13.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.23.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.3.output.dense.weight', 'base_model.encoder.layer.9.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.16.intermediate.dense.weight', 'base_model.encoder.layer.12.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.12.attention.self.value.weight', 'base_model.encoder.layer.3.attention.output.dense.bias', 'base_model.encoder.layer.7.attention.self.query.bias', 'base_model.encoder.layer.4.output.dense.bias', 'base_model.encoder.layer.1.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.1.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.20.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.5.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.19.attention.self.key.bias', 'base_model.encoder.layer.4.attention.self.value.weight', 'base_model.encoder.layer.15.attention.self.value.bias', 'base_model.encoder.layer.3.output.dense.bias', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.12.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.15.attention.self.query.weight', 'base_model.encoder.layer.21.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.1.attention.self.key.weight', 'base_model.encoder.layer.4.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.6.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.20.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.9.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.20.intermediate.dense.bias', 'base_model.encoder.layer.8.attention.output.dense.bias', 'base_model.encoder.layer.4.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.5.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.12.output.LayerNorm.weight', 'base_model.encoder.layer.19.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.1.attention.self.query.bias', 'base_model.encoder.layer.22.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.0.attention.output.dense.weight', 'base_model.encoder.layer.5.output.dense.bias', 'base_model.encoder.layer.19.attention.output.dense.weight', 'base_model.encoder.layer.7.attention.output.LayerNorm.bias', 'base_model.encoder.layer.10.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.11.intermediate.dense.bias', 'base_model.encoder.layer.10.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.11.output.LayerNorm.weight', 'base_model.encoder.layer.6.output.dense.weight', 'base_model.encoder.layer.0.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.6.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.23.output.LayerNorm.bias', 'base_model.encoder.layer.21.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.17.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.0.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.11.attention.self.key.weight', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.21.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.10.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.19.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.12.output.dense.weight', 'base_model.encoder.layer.15.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.21.output.LayerNorm.bias', 'base_model.encoder.layer.22.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.3.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.11.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.2.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.16.output.dense.bias', 'base_model.encoder.layer.11.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.16.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.16.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.8.attention.output.LayerNorm.weight', 'base_model.encoder.layer.10.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.2.attention.self.key.bias', 'base_model.encoder.layer.19.attention.self.value.bias', 'base_model.encoder.layer.1.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.6.intermediate.dense.bias', 'base_model.encoder.layer.15.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.21.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.10.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.7.attention.output.dense.bias', 'base_model.encoder.layer.20.attention.output.dense.bias', 'base_model.encoder.layer.8.attention.self.key.weight', 'base_model.encoder.layer.17.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.6.attention.output.LayerNorm.bias', 'base_model.encoder.layer.7.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.4.attention.self.query.weight', 'base_model.encoder.layer.1.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.10.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.14.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.2.attention.output.LayerNorm.weight', 'base_model.encoder.layer.13.attention.output.dense.bias', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.3.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.7.attention.output.LayerNorm.weight', 'base_model.encoder.layer.14.attention.output.LayerNorm.bias', 'base_model.encoder.layer.19.attention.self.key.weight', 'base_model.encoder.layer.0.attention.output.LayerNorm.weight', 'base_model.encoder.layer.18.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.10.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.20.output.LayerNorm.bias', 'base_model.encoder.layer.21.attention.self.key.weight', 'base_model.encoder.layer.21.attention.self.key.bias', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.14.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.2.attention.output.dense.weight', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.11.attention.output.dense.weight', 'base_model.encoder.layer.19.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.0.attention.self.query.weight', 'base_model.encoder.layer.4.attention.self.key.weight', 'base_model.encoder.layer.4.attention.self.key.bias', 'base_model.encoder.layer.12.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.14.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.4.attention.output.LayerNorm.weight', 'base_model.encoder.layer.17.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.11.attention.self.value.weight', 'base_model.encoder.layer.11.attention.output.dense.bias', 'base_model.encoder.layer.21.attention.output.LayerNorm.bias', 'base_model.encoder.layer.14.output.LayerNorm.weight', 'base_model.encoder.layer.13.attention.self.value.bias', 'base_model.encoder.layer.1.output.dense.weight', 'base_model.encoder.layer.22.output.dense.weight', 'base_model.encoder.layer.14.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.6.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.23.attention.output.LayerNorm.weight', 'base_model.encoder.layer.8.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.7.attention.self.value.bias', 'base_model.encoder.layer.21.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.0.intermediate.dense.bias', 'base_model.encoder.layer.15.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.2.attention.self.value.bias', 'base_model.encoder.layer.23.output.LayerNorm.weight', 'base_model.encoder.layer.20.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.7.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.18.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.13.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.17.attention.output.LayerNorm.bias', 'base_model.encoder.layer.4.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.18.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.21.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.20.attention.output.dense.weight', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.1.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.11.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.13.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.20.attention.self.key.bias', 'base_model.encoder.layer.10.output.LayerNorm.bias', 'base_model.encoder.layer.13.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.5.attention.self.key.weight', 'base_model.encoder.layer.19.output.LayerNorm.weight', 'base_model.encoder.layer.0.output.dense.bias', 'base_model.encoder.layer.19.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.8.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.8.output.dense.weight', 'base_model.encoder.layer.18.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.10.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.11.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.14.attention.self.key.weight', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.1.attention.self.query.weight', 'base_model.encoder.layer.1.attention.self.value.bias', 'base_model.encoder.layer.6.attention.self.key.weight', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.18.intermediate.dense.weight', 'base_model.encoder.layer.4.attention.self.query.bias', 'base_model.encoder.layer.23.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.10.output.dense.weight', 'base_model.encoder.layer.20.output.LayerNorm.weight', 'base_model.encoder.layer.16.output.LayerNorm.weight', 'base_model.encoder.layer.14.attention.output.dense.bias', 'base_model.encoder.layer.20.attention.self.key.weight', 'base_model.encoder.layer.16.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.1.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.17.intermediate.dense.bias', 'base_model.encoder.layer.3.attention.output.dense.weight', 'base_model.encoder.layer.2.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.18.attention.self.query.bias', 'base_model.encoder.layer.20.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.14.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.12.attention.self.query.bias', 'base_model.encoder.layer.20.attention.output.LayerNorm.weight', 'base_model.encoder.layer.22.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.14.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.3.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.6.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.11.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.20.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.16.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.15.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.17.attention.output.LayerNorm.weight', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.13.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.14.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.4.output.dense.weight', 'base_model.encoder.layer.22.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.5.attention.output.dense.bias', 'base_model.encoder.layer.15.attention.output.LayerNorm.bias', 'base_model.encoder.layer.11.attention.self.query.bias', 'base_model.encoder.layer.23.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.19.attention.output.LayerNorm.bias', 'base_model.encoder.layer.13.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.16.attention.self.query.bias', 'base_model.encoder.layer.14.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.21.intermediate.dense.bias', 'base_model.encoder.layer.15.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.1.output.LayerNorm.bias', 'base_model.encoder.layer.0.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.17.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.3.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.6.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.12.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.3.attention.output.LayerNorm.weight', 'base_model.encoder.layer.8.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.15.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.6.output.LayerNorm.weight', 'base_model.encoder.layer.13.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.18.intermediate.dense.bias', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.15.output.dense.weight', 'base_model.encoder.layer.19.attention.output.dense.bias', 'base_model.encoder.layer.11.output.dense.weight', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.11.attention.self.value.bias', 'base_model.encoder.layer.5.attention.output.dense.weight', 'base_model.encoder.layer.13.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.18.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.20.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.2.output.dense.weight', 'base_model.encoder.layer.0.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.13.output.dense.weight', 'base_model.encoder.layer.16.attention.output.dense.bias', 'base_model.encoder.layer.21.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.9.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.11.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.8.attention.output.dense.weight', 'base_model.encoder.layer.15.output.LayerNorm.weight', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.8.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.4.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.4.intermediate.dense.bias', 'base_model.encoder.layer.14.output.dense.bias', 'base_model.encoder.layer.18.attention.output.dense.weight', 'base_model.encoder.layer.1.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.15.attention.self.query.bias', 'base_model.encoder.layer.23.intermediate.dense.weight', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.9.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.0.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.16.attention.self.value.weight', 'base_model.encoder.layer.23.attention.self.query.weight', 'base_model.encoder.layer.10.attention.self.key.weight', 'base_model.encoder.layer.6.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.16.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.2.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.20.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.0.output.dense.weight', 'base_model.encoder.layer.21.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.22.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.5.output.LayerNorm.weight', 'base_model.encoder.layer.19.output.adapters.ts.adapter_up.weight', 'base_model.pooler.dense.bias', 'base_model.encoder.layer.13.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.11.output.LayerNorm.bias', 'base_model.encoder.layer.19.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.10.intermediate.dense.weight', 'base_model.encoder.layer.10.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.4.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.13.attention.self.query.bias', 'base_model.encoder.layer.16.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.11.attention.output.LayerNorm.weight', 'base_model.encoder.layer.3.attention.self.query.weight', 'base_model.encoder.layer.22.attention.output.dense.bias', 'base_model.encoder.layer.11.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.5.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.15.intermediate.dense.bias', 'base_model.encoder.layer.3.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.9.attention.self.query.weight', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.8.intermediate.dense.bias', 'base_model.encoder.layer.1.attention.self.key.bias', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.12.attention.output.dense.bias', 'base_model.encoder.layer.21.attention.output.dense.bias', 'base_model.encoder.layer.2.attention.self.query.weight', 'base_model.encoder.layer.9.attention.self.value.weight', 'base_model.encoder.layer.3.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.3.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.21.attention.output.LayerNorm.weight', 'base_model.encoder.layer.7.attention.self.value.weight', 'base_model.encoder.layer.8.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.5.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.9.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.22.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.4.attention.output.LayerNorm.bias', 'base_model.encoder.layer.16.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.18.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.11.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.11.attention.self.query.weight', 'base_model.encoder.layer.22.attention.output.dense.weight', 'base_model.encoder.layer.6.attention.self.query.bias', 'base_model.encoder.layer.22.intermediate.dense.weight', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.12.intermediate.dense.bias', 'base_model.encoder.layer.0.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.14.attention.self.value.weight', 'base_model.encoder.layer.22.attention.output.LayerNorm.bias', 'base_model.encoder.layer.12.intermediate.dense.weight', 'base_model.encoder.layer.4.output.LayerNorm.weight', 'base_model.encoder.layer.20.output.adapters.es.adapter_up.weight', 'base_model.embeddings.LayerNorm.bias', 'base_model.encoder.layer.1.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.19.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.17.output.LayerNorm.bias', 'base_model.encoder.layer.12.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.14.attention.output.dense.weight', 'base_model.encoder.layer.3.attention.self.query.bias', 'base_model.encoder.layer.9.attention.self.value.bias', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.23.attention.self.key.bias', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.23.attention.output.dense.weight', 'base_model.encoder.layer.12.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.23.attention.self.key.weight', 'base_model.encoder.layer.18.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.12.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.12.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.19.output.dense.weight', 'base_model.encoder.layer.23.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.9.attention.output.LayerNorm.bias', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.17.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.7.attention.self.key.weight', 'base_model.encoder.layer.8.attention.self.query.weight', 'base_model.encoder.layer.13.attention.self.query.weight', 'base_model.encoder.layer.13.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.19.intermediate.dense.bias', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.2.attention.self.value.weight', 'base_model.encoder.layer.8.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.2.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.16.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.17.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.16.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.11.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.9.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.18.attention.output.LayerNorm.weight', 'base_model.encoder.layer.0.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.5.output.dense.weight', 'base_model.encoder.layer.23.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.0.attention.self.key.weight', 'base_model.encoder.layer.3.attention.self.key.weight', 'base_model.encoder.layer.5.attention.self.query.weight', 'base_model.encoder.layer.20.attention.self.value.weight', 'base_model.encoder.layer.8.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.3.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.1.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.20.attention.self.query.weight', 'base_model.encoder.layer.18.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.21.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.2.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.11.attention.output.LayerNorm.bias', 'base_model.encoder.layer.19.output.dense.bias', 'base_model.encoder.layer.9.attention.output.dense.weight', 'base_model.encoder.layer.18.attention.output.dense.bias', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.19.attention.self.query.bias', 'base_model.encoder.layer.11.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.7.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.9.output.dense.weight', 'base_model.encoder.layer.9.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.16.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.23.output.dense.weight', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.6.attention.self.query.weight', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.7.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.14.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.10.attention.self.value.weight', 'base_model.encoder.layer.3.attention.self.key.bias', 'base_model.encoder.layer.8.output.LayerNorm.bias', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.0.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.8.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.9.output.dense.bias', 'base_model.encoder.layer.13.intermediate.dense.bias', 'base_model.encoder.layer.13.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.22.attention.self.key.weight', 'base_model.encoder.layer.22.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.4.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.18.attention.self.value.bias', 'base_model.encoder.layer.1.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.3.intermediate.dense.bias', 'base_model.encoder.layer.15.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.16.output.dense.weight', 'base_model.encoder.layer.17.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.15.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.14.attention.self.query.weight', 'base_model.encoder.layer.16.output.LayerNorm.bias', 'base_model.encoder.layer.23.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.8.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.21.attention.self.query.bias', 'base_model.encoder.layer.2.intermediate.dense.bias', 'base_model.encoder.layer.13.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.17.attention.self.key.bias', 'base_model.encoder.layer.5.attention.output.LayerNorm.bias', 'base_model.encoder.layer.12.output.LayerNorm.bias', 'base_model.encoder.layer.18.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.16.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.7.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.2.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.6.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.9.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.13.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.22.attention.self.query.bias', 'base_model.encoder.layer.22.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.16.attention.self.key.bias', 'base_model.encoder.layer.6.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.9.intermediate.dense.weight', 'base_model.embeddings.token_type_embeddings.weight', 'base_model.encoder.layer.19.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.8.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.7.attention.self.query.weight', 'base_model.encoder.layer.10.intermediate.dense.bias', 'base_model.encoder.layer.10.attention.self.key.bias', 'base_model.encoder.layer.9.attention.output.LayerNorm.weight', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.6.output.LayerNorm.bias', 'base_model.encoder.layer.22.output.LayerNorm.weight', 'base_model.encoder.layer.10.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.23.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.16.attention.self.value.bias', 'base_model.encoder.layer.18.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.17.intermediate.dense.weight', 'base_model.encoder.layer.23.attention.output.LayerNorm.bias', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.16.attention.output.dense.weight', 'base_model.encoder.layer.11.output.dense.bias', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.18.attention.self.key.bias', 'base_model.encoder.layer.19.intermediate.dense.weight', 'base_model.encoder.layer.23.attention.self.value.weight', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.8.attention.self.key.bias', 'base_model.encoder.layer.5.intermediate.dense.weight', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.0.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.5.intermediate.dense.bias', 'base_model.encoder.layer.8.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.15.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.22.attention.self.value.bias', 'base_model.embeddings.word_embeddings.weight', 'base_model.encoder.layer.3.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.12.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.18.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.18.attention.self.query.weight', 'base_model.encoder.layer.15.attention.self.value.weight', 'base_model.encoder.layer.6.attention.self.value.bias', 'base_model.encoder.layer.14.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.1.attention.output.dense.weight', 'base_model.encoder.layer.5.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.12.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.12.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.1.attention.output.LayerNorm.weight', 'base_model.encoder.layer.12.attention.self.value.bias', 'base_model.encoder.layer.16.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.5.output.LayerNorm.bias', 'base_model.encoder.layer.7.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.6.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.19.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.15.intermediate.dense.weight', 'base_model.encoder.layer.17.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.16.attention.self.key.weight', 'base_model.encoder.layer.19.output.LayerNorm.bias', 'base_model.encoder.layer.12.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.20.attention.self.query.bias', 'base_model.encoder.layer.18.attention.self.key.weight', 'base_model.encoder.layer.7.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.18.output.LayerNorm.weight', 'base_model.encoder.layer.13.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.9.output.LayerNorm.bias', 'base_model.encoder.layer.10.attention.output.dense.weight', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.5.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.9.attention.self.key.weight', 'base_model.encoder.layer.11.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.2.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.17.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.20.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.13.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.22.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.4.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.10.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.16.intermediate.dense.bias', 'base_model.encoder.layer.20.attention.output.LayerNorm.bias', 'base_model.encoder.layer.14.attention.output.LayerNorm.weight', 'base_model.encoder.layer.11.intermediate.dense.weight', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.22.intermediate.dense.bias', 'base_model.encoder.layer.8.intermediate.dense.weight', 'base_model.encoder.layer.2.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.5.attention.self.value.weight', 'qa_outputs.bias', 'base_model.encoder.layer.2.attention.self.key.weight', 'base_model.encoder.layer.7.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.8.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.6.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.18.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.15.attention.self.key.weight', 'base_model.encoder.layer.6.attention.self.key.bias', 'base_model.encoder.layer.20.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.7.output.LayerNorm.bias', 'base_model.encoder.layer.13.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.15.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.12.attention.output.LayerNorm.weight', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.17.attention.self.value.weight', 'base_model.encoder.layer.22.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.3.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.6.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.9.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.13.attention.output.LayerNorm.bias', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.6.attention.output.dense.weight', 'base_model.encoder.layer.22.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.8.output.LayerNorm.weight', 'base_model.encoder.layer.9.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.10.attention.self.query.bias', 'base_model.encoder.layer.18.output.dense.bias', 'base_model.encoder.layer.18.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.21.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.9.attention.self.key.bias', 'base_model.encoder.layer.12.attention.self.key.bias', 'base_model.encoder.layer.20.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.9.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.3.attention.output.LayerNorm.bias', 'base_model.encoder.layer.6.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.22.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.18.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.4.output.LayerNorm.bias', 'base_model.encoder.layer.10.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.13.attention.self.key.weight', 'base_model.encoder.layer.7.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.18.attention.self.value.weight', 'base_model.encoder.layer.10.output.dense.bias', 'base_model.encoder.layer.9.attention.output.dense.bias', 'base_model.encoder.layer.12.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.13.attention.output.dense.weight', 'base_model.encoder.layer.15.attention.self.key.bias', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.1.intermediate.dense.bias', 'base_model.encoder.layer.11.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.4.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.4.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.7.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.10.attention.output.LayerNorm.bias', 'base_model.encoder.layer.23.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.0.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.9.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.6.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.8.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.13.intermediate.dense.weight', 'base_model.encoder.layer.12.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.23.output.adapters.ts.adapter_down.0.bias', 'base_model.embeddings.position_ids', 'base_model.encoder.layer.0.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.15.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.17.attention.output.dense.weight', 'base_model.encoder.layer.0.intermediate.dense.weight', 'base_model.encoder.layer.5.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.11.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.23.attention.self.query.bias', 'base_model.encoder.layer.0.output.LayerNorm.weight', 'base_model.encoder.layer.7.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.23.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.22.attention.self.query.weight', 'base_model.encoder.layer.17.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.7.output.dense.weight', 'base_model.encoder.layer.13.attention.output.LayerNorm.weight', 'base_model.encoder.layer.13.attention.self.value.weight', 'base_model.encoder.layer.0.attention.self.query.bias', 'base_model.encoder.layer.13.output.LayerNorm.bias', 'base_model.encoder.layer.21.output.dense.weight', 'base_model.encoder.layer.12.output.dense.bias', 'base_model.encoder.layer.17.output.LayerNorm.weight', 'base_model.encoder.layer.6.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.22.attention.self.value.weight', 'base_model.encoder.layer.17.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.10.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.3.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.7.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.6.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.20.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.5.output.adapters.tp.adapter_down.0.bias']
- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of XLMRobertaModel were not initialized from the model checkpoint at /cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//squad/xlm-KG_LR8e-6_EPOCH2.0_maxlen384_batchsize4_gradacc4 and are newly initialized: ['encoder.layer.0.attention.self.value.weight', 'encoder.layer.11.output.dense.weight', 'encoder.layer.2.output.dense.bias', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.4.attention.self.value.weight', 'encoder.layer.5.attention.output.LayerNorm.weight', 'encoder.layer.6.attention.self.value.weight', 'encoder.layer.17.output.LayerNorm.bias', 'encoder.layer.18.attention.self.query.weight', 'encoder.layer.14.intermediate.dense.bias', 'encoder.layer.5.attention.self.key.bias', 'encoder.layer.7.output.dense.bias', 'encoder.layer.7.output.LayerNorm.weight', 'encoder.layer.14.attention.output.LayerNorm.weight', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.4.output.dense.bias', 'encoder.layer.16.attention.output.LayerNorm.weight', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.9.output.LayerNorm.bias', 'encoder.layer.7.attention.output.dense.bias', 'encoder.layer.1.attention.self.query.weight', 'encoder.layer.13.attention.self.key.bias', 'encoder.layer.1.attention.output.dense.weight', 'encoder.layer.22.attention.self.query.weight', 'encoder.layer.19.attention.output.LayerNorm.bias', 'encoder.layer.11.attention.self.key.weight', 'encoder.layer.2.attention.self.key.bias', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.13.attention.self.key.weight', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.22.attention.self.key.weight', 'encoder.layer.9.attention.self.key.bias', 'encoder.layer.6.attention.output.LayerNorm.weight', 'encoder.layer.13.output.LayerNorm.bias', 'encoder.layer.10.attention.output.LayerNorm.bias', 'encoder.layer.11.attention.self.query.bias', 'encoder.layer.7.attention.self.value.weight', 'encoder.layer.18.intermediate.dense.weight', 'encoder.layer.21.output.LayerNorm.bias', 'encoder.layer.8.attention.output.dense.bias', 'encoder.layer.17.attention.output.dense.weight', 'encoder.layer.2.attention.self.query.weight', 'encoder.layer.1.attention.output.dense.bias', 'encoder.layer.20.attention.output.LayerNorm.weight', 'encoder.layer.10.output.LayerNorm.bias', 'encoder.layer.13.intermediate.dense.bias', 'encoder.layer.11.output.LayerNorm.bias', 'encoder.layer.23.attention.self.key.bias', 'encoder.layer.10.intermediate.dense.weight', 'encoder.layer.6.attention.self.query.weight', 'encoder.layer.5.attention.output.dense.weight', 'encoder.layer.1.output.dense.weight', 'encoder.layer.12.attention.self.value.bias', 'encoder.layer.17.output.dense.weight', 'encoder.layer.23.attention.self.query.bias', 'encoder.layer.7.attention.output.LayerNorm.bias', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.layer.7.attention.output.LayerNorm.weight', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.22.intermediate.dense.bias', 'encoder.layer.9.attention.output.dense.bias', 'encoder.layer.21.attention.self.value.bias', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.11.attention.self.value.weight', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.11.attention.self.query.weight', 'encoder.layer.16.attention.self.value.bias', 'encoder.layer.10.output.LayerNorm.weight', 'encoder.layer.10.attention.self.query.bias', 'encoder.layer.12.intermediate.dense.weight', 'encoder.layer.21.attention.self.query.weight', 'encoder.layer.14.output.dense.weight', 'encoder.layer.7.output.LayerNorm.bias', 'encoder.layer.3.attention.output.dense.weight', 'encoder.layer.14.attention.self.key.weight', 'encoder.layer.10.output.dense.weight', 'encoder.layer.9.output.LayerNorm.weight', 'encoder.layer.9.attention.output.LayerNorm.weight', 'encoder.layer.5.output.dense.weight', 'embeddings.position_embeddings.weight', 'encoder.layer.12.attention.output.LayerNorm.bias', 'encoder.layer.23.intermediate.dense.bias', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.4.attention.self.query.weight', 'encoder.layer.16.output.LayerNorm.weight', 'encoder.layer.22.attention.self.query.bias', 'pooler.dense.weight', 'encoder.layer.1.attention.self.value.bias', 'encoder.layer.23.attention.self.value.weight', 'encoder.layer.14.attention.self.value.weight', 'encoder.layer.12.output.dense.bias', 'encoder.layer.14.attention.self.value.bias', 'encoder.layer.5.output.LayerNorm.bias', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.22.attention.self.value.bias', 'encoder.layer.7.attention.self.key.weight', 'encoder.layer.13.attention.output.dense.weight', 'encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.layer.13.attention.self.value.weight', 'encoder.layer.4.attention.output.LayerNorm.weight', 'encoder.layer.21.attention.self.value.weight', 'encoder.layer.17.attention.self.key.bias', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.10.attention.self.key.bias', 'encoder.layer.11.output.LayerNorm.weight', 'encoder.layer.15.attention.self.key.bias', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.7.attention.output.dense.weight', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.3.output.dense.bias', 'embeddings.word_embeddings.weight', 'encoder.layer.9.output.dense.bias', 'encoder.layer.6.attention.output.dense.weight', 'encoder.layer.15.attention.self.value.weight', 'encoder.layer.14.attention.output.LayerNorm.bias', 'encoder.layer.0.attention.output.dense.weight', 'embeddings.token_type_embeddings.weight', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.18.output.dense.weight', 'encoder.layer.20.attention.output.dense.bias', 'encoder.layer.8.attention.self.key.bias', 'encoder.layer.23.attention.self.query.weight', 'encoder.layer.18.output.LayerNorm.bias', 'encoder.layer.7.attention.self.value.bias', 'encoder.layer.12.output.LayerNorm.bias', 'encoder.layer.15.attention.output.dense.bias', 'encoder.layer.0.attention.self.value.bias', 'encoder.layer.18.attention.self.query.bias', 'encoder.layer.12.attention.self.query.weight', 'encoder.layer.16.attention.self.key.weight', 'encoder.layer.7.attention.self.key.bias', 'embeddings.LayerNorm.bias', 'encoder.layer.16.attention.self.value.weight', 'encoder.layer.13.attention.output.dense.bias', 'encoder.layer.15.attention.self.query.bias', 'encoder.layer.19.attention.output.dense.bias', 'encoder.layer.1.attention.self.value.weight', 'encoder.layer.4.attention.output.dense.weight', 'encoder.layer.10.attention.output.LayerNorm.weight', 'encoder.layer.19.attention.self.key.bias', 'encoder.layer.21.intermediate.dense.weight', 'encoder.layer.3.attention.self.query.bias', 'encoder.layer.6.output.dense.weight', 'encoder.layer.5.attention.self.value.weight', 'encoder.layer.0.attention.self.query.bias', 'encoder.layer.12.attention.self.key.weight', 'encoder.layer.19.attention.output.dense.weight', 'encoder.layer.8.attention.output.LayerNorm.bias', 'encoder.layer.14.attention.self.query.bias', 'encoder.layer.23.output.LayerNorm.weight', 'encoder.layer.0.attention.output.LayerNorm.weight', 'encoder.layer.3.attention.self.query.weight', 'encoder.layer.8.attention.output.dense.weight', 'encoder.layer.1.attention.output.LayerNorm.weight', 'encoder.layer.7.attention.self.query.weight', 'encoder.layer.23.attention.output.dense.bias', 'encoder.layer.10.attention.self.key.weight', 'encoder.layer.16.attention.output.LayerNorm.bias', 'encoder.layer.8.output.LayerNorm.bias', 'encoder.layer.17.attention.self.value.bias', 'encoder.layer.3.attention.self.key.weight', 'encoder.layer.4.attention.output.dense.bias', 'encoder.layer.19.intermediate.dense.bias', 'encoder.layer.4.attention.self.key.bias', 'encoder.layer.13.attention.output.LayerNorm.bias', 'encoder.layer.14.attention.output.dense.bias', 'encoder.layer.21.attention.output.dense.weight', 'encoder.layer.15.attention.self.query.weight', 'encoder.layer.17.attention.self.key.weight', 'encoder.layer.18.attention.output.dense.weight', 'encoder.layer.14.attention.self.query.weight', 'encoder.layer.6.attention.self.key.weight', 'encoder.layer.23.output.LayerNorm.bias', 'encoder.layer.3.attention.output.dense.bias', 'encoder.layer.12.attention.self.value.weight', 'encoder.layer.17.attention.self.value.weight', 'encoder.layer.3.attention.self.value.weight', 'encoder.layer.15.output.LayerNorm.weight', 'encoder.layer.15.attention.output.LayerNorm.bias', 'encoder.layer.3.attention.self.value.bias', 'encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.layer.7.intermediate.dense.bias', 'encoder.layer.2.attention.output.LayerNorm.bias', 'encoder.layer.9.attention.self.query.weight', 'encoder.layer.10.attention.self.query.weight', 'encoder.layer.15.attention.self.value.bias', 'encoder.layer.21.attention.output.LayerNorm.bias', 'encoder.layer.6.output.dense.bias', 'encoder.layer.16.output.LayerNorm.bias', 'encoder.layer.22.attention.self.key.bias', 'encoder.layer.13.output.LayerNorm.weight', 'encoder.layer.4.output.dense.weight', 'encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.layer.6.attention.self.query.bias', 'encoder.layer.9.attention.self.value.weight', 'encoder.layer.18.attention.self.key.weight', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.2.attention.self.query.bias', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.0.attention.self.query.weight', 'encoder.layer.9.attention.output.LayerNorm.bias', 'encoder.layer.17.attention.self.query.bias', 'encoder.layer.9.attention.self.key.weight', 'encoder.layer.17.attention.output.LayerNorm.bias', 'encoder.layer.5.attention.self.query.weight', 'encoder.layer.13.output.dense.bias', 'encoder.layer.19.output.dense.bias', 'encoder.layer.19.attention.self.query.bias', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.1.attention.self.key.weight', 'encoder.layer.18.attention.self.value.bias', 'encoder.layer.20.intermediate.dense.bias', 'encoder.layer.10.attention.self.value.weight', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.10.attention.output.dense.weight', 'encoder.layer.18.attention.output.LayerNorm.bias', 'encoder.layer.8.output.LayerNorm.weight', 'encoder.layer.12.intermediate.dense.bias', 'encoder.layer.14.output.LayerNorm.bias', 'encoder.layer.2.attention.output.LayerNorm.weight', 'encoder.layer.23.attention.output.LayerNorm.weight', 'encoder.layer.12.attention.self.key.bias', 'encoder.layer.23.attention.output.dense.weight', 'encoder.layer.16.attention.self.query.weight', 'encoder.layer.3.output.dense.weight', 'encoder.layer.21.attention.self.key.bias', 'encoder.layer.19.attention.output.LayerNorm.weight', 'encoder.layer.2.attention.self.key.weight', 'encoder.layer.10.output.dense.bias', 'encoder.layer.15.output.dense.bias', 'encoder.layer.8.attention.self.query.weight', 'encoder.layer.11.attention.output.dense.weight', 'encoder.layer.13.attention.self.value.bias', 'encoder.layer.5.attention.self.value.bias', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.15.attention.output.LayerNorm.weight', 'encoder.layer.13.output.dense.weight', 'encoder.layer.19.attention.self.value.bias', 'encoder.layer.8.attention.self.value.weight', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.1.attention.self.query.bias', 'encoder.layer.0.attention.output.dense.bias', 'encoder.layer.2.attention.output.dense.bias', 'encoder.layer.14.attention.output.dense.weight', 'encoder.layer.16.attention.self.query.bias', 'encoder.layer.12.attention.self.query.bias', 'encoder.layer.13.intermediate.dense.weight', 'encoder.layer.5.attention.output.dense.bias', 'encoder.layer.15.intermediate.dense.bias', 'encoder.layer.14.attention.self.key.bias', 'encoder.layer.16.output.dense.bias', 'encoder.layer.23.attention.self.value.bias', 'encoder.layer.0.output.dense.weight', 'encoder.layer.15.output.dense.weight', 'encoder.layer.5.attention.self.query.bias', 'encoder.layer.7.output.dense.weight', 'encoder.layer.13.attention.self.query.weight', 'encoder.layer.20.output.LayerNorm.bias', 'encoder.layer.8.attention.self.value.bias', 'encoder.layer.8.attention.output.LayerNorm.weight', 'encoder.layer.18.output.LayerNorm.weight', 'encoder.layer.2.output.dense.weight', 'encoder.layer.9.output.dense.weight', 'encoder.layer.15.output.LayerNorm.bias', 'encoder.layer.14.intermediate.dense.weight', 'encoder.layer.2.attention.output.dense.weight', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.22.attention.output.LayerNorm.weight', 'encoder.layer.16.intermediate.dense.bias', 'encoder.layer.8.output.dense.bias', 'encoder.layer.23.attention.output.LayerNorm.bias', 'encoder.layer.20.attention.self.key.weight', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.11.attention.self.value.bias', 'encoder.layer.22.output.LayerNorm.bias', 'encoder.layer.11.attention.output.dense.bias', 'encoder.layer.22.intermediate.dense.weight', 'encoder.layer.6.attention.output.LayerNorm.bias', 'encoder.layer.18.attention.output.dense.bias', 'encoder.layer.21.output.dense.bias', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.21.attention.self.query.bias', 'encoder.layer.12.output.LayerNorm.weight', 'encoder.layer.20.attention.output.dense.weight', 'encoder.layer.22.attention.output.dense.weight', 'encoder.layer.4.attention.output.LayerNorm.bias', 'encoder.layer.1.attention.self.key.bias', 'encoder.layer.15.intermediate.dense.weight', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.18.attention.output.LayerNorm.weight', 'encoder.layer.17.output.dense.bias', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.20.attention.self.query.bias', 'encoder.layer.22.attention.self.value.weight', 'encoder.layer.23.output.dense.bias', 'encoder.layer.20.attention.self.value.bias', 'pooler.dense.bias', 'encoder.layer.11.attention.output.LayerNorm.weight', 'encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.layer.18.attention.self.key.bias', 'encoder.layer.14.output.dense.bias', 'encoder.layer.21.attention.self.key.weight', 'encoder.layer.23.intermediate.dense.weight', 'encoder.layer.9.attention.output.dense.weight', 'encoder.layer.3.attention.self.key.bias', 'embeddings.LayerNorm.weight', 'encoder.layer.16.attention.output.dense.weight', 'encoder.layer.6.attention.output.dense.bias', 'encoder.layer.9.attention.self.query.bias', 'encoder.layer.17.output.LayerNorm.weight', 'encoder.layer.16.intermediate.dense.weight', 'encoder.layer.8.attention.self.query.bias', 'encoder.layer.17.attention.output.LayerNorm.weight', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.10.attention.self.value.bias', 'encoder.layer.22.output.dense.weight', 'encoder.layer.0.attention.self.key.bias', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.20.attention.output.LayerNorm.bias', 'encoder.layer.17.intermediate.dense.bias', 'encoder.layer.23.attention.self.key.weight', 'encoder.layer.14.output.LayerNorm.weight', 'encoder.layer.12.attention.output.dense.weight', 'encoder.layer.6.attention.self.value.bias', 'encoder.layer.20.attention.self.value.weight', 'encoder.layer.22.output.LayerNorm.weight', 'encoder.layer.4.attention.self.value.bias', 'encoder.layer.17.attention.output.dense.bias', 'encoder.layer.19.attention.self.key.weight', 'encoder.layer.6.output.LayerNorm.bias', 'encoder.layer.20.output.LayerNorm.weight', 'encoder.layer.1.output.dense.bias', 'encoder.layer.21.attention.output.LayerNorm.weight', 'encoder.layer.5.output.dense.bias', 'encoder.layer.6.attention.self.key.bias', 'encoder.layer.8.attention.self.key.weight', 'encoder.layer.22.output.dense.bias', 'encoder.layer.17.attention.self.query.weight', 'encoder.layer.2.attention.self.value.weight', 'encoder.layer.16.attention.output.dense.bias', 'encoder.layer.12.attention.output.dense.bias', 'encoder.layer.20.attention.self.query.weight', 'encoder.layer.21.output.LayerNorm.weight', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.19.intermediate.dense.weight', 'encoder.layer.13.attention.output.LayerNorm.weight', 'encoder.layer.11.attention.self.key.bias', 'encoder.layer.19.attention.self.query.weight', 'encoder.layer.12.attention.output.LayerNorm.weight', 'encoder.layer.19.output.LayerNorm.weight', 'encoder.layer.12.output.dense.weight', 'encoder.layer.18.output.dense.bias', 'encoder.layer.21.attention.output.dense.bias', 'encoder.layer.20.attention.self.key.bias', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.17.intermediate.dense.weight', 'encoder.layer.9.attention.self.value.bias', 'encoder.layer.7.attention.self.query.bias', 'encoder.layer.16.output.dense.weight', 'encoder.layer.20.output.dense.bias', 'encoder.layer.19.attention.self.value.weight', 'encoder.layer.13.attention.self.query.bias', 'encoder.layer.16.attention.self.key.bias', 'encoder.layer.11.output.dense.bias', 'encoder.layer.20.intermediate.dense.weight', 'encoder.layer.2.attention.self.value.bias', 'encoder.layer.15.attention.self.key.weight', 'encoder.layer.4.attention.self.key.weight', 'encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.layer.19.output.LayerNorm.bias', 'encoder.layer.5.attention.self.key.weight', 'encoder.layer.20.output.dense.weight', 'encoder.layer.18.intermediate.dense.bias', 'encoder.layer.19.output.dense.weight', 'encoder.layer.18.attention.self.value.weight', 'encoder.layer.0.output.dense.bias', 'encoder.layer.22.attention.output.dense.bias', 'encoder.layer.21.intermediate.dense.bias', 'encoder.layer.10.attention.output.dense.bias', 'encoder.layer.0.attention.self.key.weight', 'encoder.layer.15.attention.output.dense.weight', 'encoder.layer.22.attention.output.LayerNorm.bias', 'encoder.layer.23.output.dense.weight', 'encoder.layer.4.attention.self.query.bias', 'encoder.layer.21.output.dense.weight', 'encoder.layer.8.output.dense.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Overwriting existing adapter 'ep'.
Overwriting existing adapter 'tp'.
Overwriting existing adapter 'es'.
Overwriting existing adapter 'ts'.
Overwriting existing adapter fusion module 'ep,tp,es,ts'
05/09/2022 20:10:19 - INFO - __main__ -   Creating features from dataset file at .
/cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//squad/xlm-KG_LR8e-6_EPOCH2.0_maxlen384_batchsize4_gradacc4
XLMConfig {
  "architectures": [
    "XLMRobertaForMaskedLM"
  ],
  "asm": false,
  "attention_dropout": 0.1,
  "attention_probs_dropout_prob": 0.1,
  "bos_index": 0,
  "bos_token_id": 0,
  "causal": false,
  "dropout": 0.1,
  "emb_dim": 1024,
  "embed_init_std": 0.02209708691207961,
  "end_n_top": 5,
  "eos_index": 1,
  "eos_token_id": 2,
  "gelu_activation": true,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "init_std": 0.02,
  "initializer_range": 0.02,
  "intermediate_size": 4096,
  "is_encoder": true,
  "lang_id": 0,
  "layer_norm_eps": 1e-05,
  "mask_index": 5,
  "mask_token_id": 0,
  "max_position_embeddings": 514,
  "model_type": "xlm",
  "n_heads": 16,
  "n_langs": 1,
  "n_layers": 24,
  "output_past": true,
  "pad_index": 2,
  "pad_token_id": 1,
  "sinusoidal_embeddings": false,
  "start_n_top": 5,
  "summary_activation": null,
  "summary_first_dropout": 0.1,
  "summary_proj_to_labels": true,
  "summary_type": "first",
  "summary_use_proj": true,
  "transformers_version": "4.17.0",
  "type_vocab_size": 1,
  "unk_index": 3,
  "use_lang_emb": false,
  "vocab_size": 250002
}

  0%|          | 0/48 [00:00<?, ?it/s] 23%|██▎       | 11/48 [00:00<00:00, 102.81it/s] 46%|████▌     | 22/48 [00:00<00:00, 95.30it/s]  69%|██████▉   | 33/48 [00:00<00:00, 100.27it/s] 92%|█████████▏| 44/48 [00:00<00:00, 103.23it/s]100%|██████████| 48/48 [00:00<00:00, 101.37it/s]
convert squad examples to features:   0%|          | 0/1190 [00:00<?, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.
convert squad examples to features:   0%|          | 1/1190 [00:00<03:57,  5.01it/s]convert squad examples to features:   5%|▌         | 65/1190 [00:00<00:06, 184.96it/s]convert squad examples to features:  11%|█         | 129/1190 [00:00<00:03, 268.76it/s]convert squad examples to features:  16%|█▌        | 193/1190 [00:00<00:02, 341.92it/s]convert squad examples to features:  22%|██▏       | 257/1190 [00:00<00:02, 331.99it/s]convert squad examples to features:  27%|██▋       | 321/1190 [00:01<00:02, 351.35it/s]convert squad examples to features:  32%|███▏      | 385/1190 [00:01<00:03, 243.69it/s]convert squad examples to features:  35%|███▌      | 417/1190 [00:01<00:03, 255.03it/s]convert squad examples to features:  40%|████      | 481/1190 [00:01<00:02, 286.03it/s]convert squad examples to features:  43%|████▎     | 514/1190 [00:01<00:02, 287.27it/s]convert squad examples to features:  46%|████▌     | 546/1190 [00:01<00:02, 283.41it/s]convert squad examples to features:  51%|█████     | 609/1190 [00:02<00:01, 295.24it/s]convert squad examples to features:  57%|█████▋    | 673/1190 [00:02<00:01, 295.89it/s]convert squad examples to features:  62%|██████▏   | 737/1190 [00:02<00:01, 318.00it/s]convert squad examples to features:  67%|██████▋   | 801/1190 [00:02<00:01, 332.28it/s]convert squad examples to features:  70%|███████   | 835/1190 [00:02<00:01, 311.20it/s]convert squad examples to features:  75%|███████▌  | 897/1190 [00:03<00:00, 309.12it/s]convert squad examples to features:  81%|████████  | 961/1190 [00:03<00:00, 310.85it/s]convert squad examples to features:  86%|████████▌ | 1025/1190 [00:03<00:00, 331.83it/s]convert squad examples to features:  92%|█████████▏| 1089/1190 [00:03<00:00, 341.37it/s]convert squad examples to features:  94%|█████████▍| 1124/1190 [00:03<00:00, 338.33it/s]convert squad examples to features:  97%|█████████▋| 1158/1190 [00:03<00:00, 331.46it/s]convert squad examples to features: 100%|██████████| 1190/1190 [00:03<00:00, 307.74it/s]/cluster/project/sachan/yifan/softwares/anaconda/anaconda3/envs/xfactr/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2272: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

add example index and unique id:   0%|          | 0/1190 [00:00<?, ?it/s]add example index and unique id: 100%|██████████| 1190/1190 [00:00<00:00, 535653.76it/s]
05/09/2022 20:10:24 - INFO - __main__ -   Saving features into cached file ./cached_xquad.th.json_xlm-KG_LR8e-6_EPOCH2.0_maxlen384_batchsize4_gradacc4_384_th
05/09/2022 20:10:25 - INFO - __main__ -   ***** Running evaluation  *****
05/09/2022 20:10:25 - INFO - __main__ -     Num examples = 1314
05/09/2022 20:10:25 - INFO - __main__ -     Batch size = 8
Evaluating:   0%|          | 0/165 [00:00<?, ?it/s]Evaluating:   1%|          | 1/165 [00:00<02:23,  1.14it/s]Evaluating:   1%|          | 2/165 [00:01<01:33,  1.75it/s]Evaluating:   2%|▏         | 3/165 [00:01<01:16,  2.10it/s]Evaluating:   2%|▏         | 4/165 [00:01<01:09,  2.32it/s]Evaluating:   3%|▎         | 5/165 [00:02<01:05,  2.45it/s]Evaluating:   4%|▎         | 6/165 [00:02<01:02,  2.56it/s]Evaluating:   4%|▍         | 7/165 [00:03<00:59,  2.64it/s]Evaluating:   5%|▍         | 8/165 [00:03<00:58,  2.68it/s]Evaluating:   5%|▌         | 9/165 [00:03<00:57,  2.72it/s]Evaluating:   6%|▌         | 10/165 [00:04<00:56,  2.72it/s]Evaluating:   7%|▋         | 11/165 [00:04<00:56,  2.73it/s]Evaluating:   7%|▋         | 12/165 [00:04<00:55,  2.74it/s]Evaluating:   8%|▊         | 13/165 [00:05<00:55,  2.75it/s]Evaluating:   8%|▊         | 14/165 [00:05<00:54,  2.76it/s]Evaluating:   9%|▉         | 15/165 [00:05<00:54,  2.76it/s]Evaluating:  10%|▉         | 16/165 [00:06<00:53,  2.77it/s]Evaluating:  10%|█         | 17/165 [00:06<00:53,  2.78it/s]Evaluating:  11%|█         | 18/165 [00:07<00:52,  2.78it/s]Evaluating:  12%|█▏        | 19/165 [00:07<00:52,  2.79it/s]Evaluating:  12%|█▏        | 20/165 [00:07<00:51,  2.79it/s]Evaluating:  13%|█▎        | 21/165 [00:08<00:51,  2.79it/s]Evaluating:  13%|█▎        | 22/165 [00:08<00:51,  2.80it/s]Evaluating:  14%|█▍        | 23/165 [00:08<00:50,  2.80it/s]Evaluating:  15%|█▍        | 24/165 [00:09<00:51,  2.75it/s]Evaluating:  15%|█▌        | 25/165 [00:09<00:50,  2.75it/s]Evaluating:  16%|█▌        | 26/165 [00:09<00:50,  2.75it/s]Evaluating:  16%|█▋        | 27/165 [00:10<00:49,  2.77it/s]Evaluating:  17%|█▋        | 28/165 [00:10<00:49,  2.77it/s]Evaluating:  18%|█▊        | 29/165 [00:10<00:48,  2.78it/s]Evaluating:  18%|█▊        | 30/165 [00:11<00:48,  2.79it/s]Evaluating:  19%|█▉        | 31/165 [00:11<00:47,  2.79it/s]Evaluating:  19%|█▉        | 32/165 [00:12<00:48,  2.77it/s]Evaluating:  20%|██        | 33/165 [00:12<00:47,  2.77it/s]Evaluating:  21%|██        | 34/165 [00:12<00:47,  2.77it/s]Evaluating:  21%|██        | 35/165 [00:13<00:46,  2.78it/s]Evaluating:  22%|██▏       | 36/165 [00:13<00:46,  2.78it/s]Evaluating:  22%|██▏       | 37/165 [00:13<00:46,  2.78it/s]Evaluating:  23%|██▎       | 38/165 [00:14<00:45,  2.77it/s]Evaluating:  24%|██▎       | 39/165 [00:14<00:45,  2.77it/s]Evaluating:  24%|██▍       | 40/165 [00:14<00:44,  2.78it/s]Evaluating:  25%|██▍       | 41/165 [00:15<00:45,  2.75it/s]Evaluating:  25%|██▌       | 42/165 [00:15<00:44,  2.77it/s]Evaluating:  26%|██▌       | 43/165 [00:16<00:44,  2.76it/s]Evaluating:  27%|██▋       | 44/165 [00:16<00:43,  2.77it/s]Evaluating:  27%|██▋       | 45/165 [00:16<00:43,  2.78it/s]Evaluating:  28%|██▊       | 46/165 [00:17<00:42,  2.78it/s]Evaluating:  28%|██▊       | 47/165 [00:17<00:42,  2.79it/s]Evaluating:  29%|██▉       | 48/165 [00:17<00:42,  2.78it/s]Evaluating:  30%|██▉       | 49/165 [00:18<00:41,  2.78it/s]Evaluating:  30%|███       | 50/165 [00:18<00:41,  2.78it/s]Evaluating:  31%|███       | 51/165 [00:18<00:40,  2.79it/s]Evaluating:  32%|███▏      | 52/165 [00:19<00:40,  2.76it/s]Evaluating:  32%|███▏      | 53/165 [00:19<00:40,  2.76it/s]Evaluating:  33%|███▎      | 54/165 [00:19<00:40,  2.76it/s]Evaluating:  33%|███▎      | 55/165 [00:20<00:39,  2.76it/s]Evaluating:  34%|███▍      | 56/165 [00:20<00:39,  2.75it/s]Evaluating:  35%|███▍      | 57/165 [00:21<00:39,  2.72it/s]Evaluating:  35%|███▌      | 58/165 [00:21<00:39,  2.72it/s]Evaluating:  36%|███▌      | 59/165 [00:21<00:38,  2.74it/s]Evaluating:  36%|███▋      | 60/165 [00:22<00:38,  2.74it/s]Evaluating:  37%|███▋      | 61/165 [00:22<00:37,  2.74it/s]Evaluating:  38%|███▊      | 62/165 [00:22<00:38,  2.69it/s]Evaluating:  38%|███▊      | 63/165 [00:23<00:37,  2.71it/s]Evaluating:  39%|███▉      | 64/165 [00:23<00:36,  2.73it/s]Evaluating:  39%|███▉      | 65/165 [00:24<00:37,  2.66it/s]Evaluating:  40%|████      | 66/165 [00:24<00:36,  2.68it/s]Evaluating:  41%|████      | 67/165 [00:24<00:36,  2.71it/s]Evaluating:  41%|████      | 68/165 [00:25<00:35,  2.72it/s]Evaluating:  42%|████▏     | 69/165 [00:25<00:35,  2.74it/s]Evaluating:  42%|████▏     | 70/165 [00:25<00:34,  2.75it/s]Evaluating:  43%|████▎     | 71/165 [00:26<00:34,  2.76it/s]Evaluating:  44%|████▎     | 72/165 [00:26<00:33,  2.77it/s]Evaluating:  44%|████▍     | 73/165 [00:26<00:33,  2.78it/s]Evaluating:  45%|████▍     | 74/165 [00:27<00:32,  2.78it/s]Evaluating:  45%|████▌     | 75/165 [00:27<00:32,  2.78it/s]Evaluating:  46%|████▌     | 76/165 [00:28<00:32,  2.78it/s]Evaluating:  47%|████▋     | 77/165 [00:28<00:31,  2.77it/s]Evaluating:  47%|████▋     | 78/165 [00:28<00:31,  2.76it/s]Evaluating:  48%|████▊     | 79/165 [00:29<00:31,  2.77it/s]Evaluating:  48%|████▊     | 80/165 [00:29<00:30,  2.77it/s]Evaluating:  49%|████▉     | 81/165 [00:29<00:30,  2.78it/s]Evaluating:  50%|████▉     | 82/165 [00:30<00:29,  2.77it/s]Evaluating:  50%|█████     | 83/165 [00:30<00:29,  2.77it/s]Evaluating:  51%|█████     | 84/165 [00:30<00:29,  2.77it/s]Evaluating:  52%|█████▏    | 85/165 [00:31<00:28,  2.77it/s]Evaluating:  52%|█████▏    | 86/165 [00:31<00:28,  2.76it/s]Evaluating:  53%|█████▎    | 87/165 [00:31<00:28,  2.75it/s]Evaluating:  53%|█████▎    | 88/165 [00:32<00:27,  2.76it/s]Evaluating:  54%|█████▍    | 89/165 [00:32<00:27,  2.75it/s]Evaluating:  55%|█████▍    | 90/165 [00:33<00:27,  2.74it/s]Evaluating:  55%|█████▌    | 91/165 [00:33<00:26,  2.74it/s]Evaluating:  56%|█████▌    | 92/165 [00:33<00:26,  2.75it/s]Evaluating:  56%|█████▋    | 93/165 [00:34<00:26,  2.75it/s]Evaluating:  57%|█████▋    | 94/165 [00:34<00:25,  2.75it/s]Evaluating:  58%|█████▊    | 95/165 [00:34<00:25,  2.75it/s]Evaluating:  58%|█████▊    | 96/165 [00:35<00:25,  2.75it/s]Evaluating:  59%|█████▉    | 97/165 [00:35<00:24,  2.75it/s]Evaluating:  59%|█████▉    | 98/165 [00:35<00:24,  2.75it/s]Evaluating:  60%|██████    | 99/165 [00:36<00:23,  2.76it/s]Evaluating:  61%|██████    | 100/165 [00:36<00:23,  2.76it/s]Evaluating:  61%|██████    | 101/165 [00:37<00:23,  2.75it/s]Evaluating:  62%|██████▏   | 102/165 [00:37<00:22,  2.75it/s]Evaluating:  62%|██████▏   | 103/165 [00:37<00:22,  2.76it/s]Evaluating:  63%|██████▎   | 104/165 [00:38<00:22,  2.75it/s]Evaluating:  64%|██████▎   | 105/165 [00:38<00:21,  2.74it/s]Evaluating:  64%|██████▍   | 106/165 [00:38<00:21,  2.75it/s]Evaluating:  65%|██████▍   | 107/165 [00:39<00:21,  2.75it/s]Evaluating:  65%|██████▌   | 108/165 [00:39<00:20,  2.74it/s]Evaluating:  66%|██████▌   | 109/165 [00:40<00:20,  2.74it/s]Evaluating:  67%|██████▋   | 110/165 [00:40<00:20,  2.75it/s]Evaluating:  67%|██████▋   | 111/165 [00:40<00:19,  2.75it/s]Evaluating:  68%|██████▊   | 112/165 [00:41<00:19,  2.76it/s]Evaluating:  68%|██████▊   | 113/165 [00:41<00:18,  2.75it/s]Evaluating:  69%|██████▉   | 114/165 [00:41<00:18,  2.73it/s]Evaluating:  70%|██████▉   | 115/165 [00:42<00:18,  2.73it/s]Evaluating:  70%|███████   | 116/165 [00:42<00:17,  2.72it/s]Evaluating:  71%|███████   | 117/165 [00:42<00:17,  2.73it/s]Evaluating:  72%|███████▏  | 118/165 [00:43<00:17,  2.74it/s]Evaluating:  72%|███████▏  | 119/165 [00:43<00:16,  2.74it/s]Evaluating:  73%|███████▎  | 120/165 [00:44<00:16,  2.71it/s]Evaluating:  73%|███████▎  | 121/165 [00:44<00:16,  2.73it/s]Evaluating:  74%|███████▍  | 122/165 [00:44<00:15,  2.74it/s]Evaluating:  75%|███████▍  | 123/165 [00:45<00:15,  2.75it/s]Evaluating:  75%|███████▌  | 124/165 [00:45<00:14,  2.76it/s]Evaluating:  76%|███████▌  | 125/165 [00:45<00:14,  2.75it/s]Evaluating:  76%|███████▋  | 126/165 [00:46<00:14,  2.75it/s]Evaluating:  77%|███████▋  | 127/165 [00:46<00:13,  2.75it/s]Evaluating:  78%|███████▊  | 128/165 [00:46<00:13,  2.75it/s]Evaluating:  78%|███████▊  | 129/165 [00:47<00:13,  2.76it/s]Evaluating:  79%|███████▉  | 130/165 [00:47<00:12,  2.75it/s]Evaluating:  79%|███████▉  | 131/165 [00:48<00:12,  2.75it/s]Evaluating:  80%|████████  | 132/165 [00:48<00:12,  2.73it/s]Evaluating:  81%|████████  | 133/165 [00:48<00:11,  2.73it/s]Evaluating:  81%|████████  | 134/165 [00:49<00:11,  2.75it/s]Evaluating:  82%|████████▏ | 135/165 [00:49<00:11,  2.71it/s]Evaluating:  82%|████████▏ | 136/165 [00:49<00:10,  2.73it/s]Evaluating:  83%|████████▎ | 137/165 [00:50<00:10,  2.74it/s]Evaluating:  84%|████████▎ | 138/165 [00:50<00:09,  2.74it/s]Evaluating:  84%|████████▍ | 139/165 [00:50<00:09,  2.75it/s]Evaluating:  85%|████████▍ | 140/165 [00:51<00:09,  2.76it/s]Evaluating:  85%|████████▌ | 141/165 [00:51<00:08,  2.75it/s]Evaluating:  86%|████████▌ | 142/165 [00:52<00:08,  2.76it/s]Evaluating:  87%|████████▋ | 143/165 [00:52<00:07,  2.76it/s]Evaluating:  87%|████████▋ | 144/165 [00:52<00:07,  2.73it/s]Evaluating:  88%|████████▊ | 145/165 [00:53<00:07,  2.73it/s]Evaluating:  88%|████████▊ | 146/165 [00:53<00:06,  2.72it/s]Evaluating:  89%|████████▉ | 147/165 [00:53<00:06,  2.74it/s]Evaluating:  90%|████████▉ | 148/165 [00:54<00:06,  2.74it/s]Evaluating:  90%|█████████ | 149/165 [00:54<00:05,  2.76it/s]Evaluating:  91%|█████████ | 150/165 [00:54<00:05,  2.74it/s]Evaluating:  92%|█████████▏| 151/165 [00:55<00:05,  2.75it/s]Evaluating:  92%|█████████▏| 152/165 [00:55<00:04,  2.73it/s]Evaluating:  93%|█████████▎| 153/165 [00:56<00:04,  2.73it/s]Evaluating:  93%|█████████▎| 154/165 [00:56<00:04,  2.75it/s]Evaluating:  94%|█████████▍| 155/165 [00:56<00:03,  2.75it/s]Evaluating:  95%|█████████▍| 156/165 [00:57<00:03,  2.75it/s]Evaluating:  95%|█████████▌| 157/165 [00:57<00:02,  2.75it/s]Evaluating:  96%|█████████▌| 158/165 [00:57<00:02,  2.75it/s]Evaluating:  96%|█████████▋| 159/165 [00:58<00:02,  2.75it/s]Evaluating:  97%|█████████▋| 160/165 [00:58<00:01,  2.75it/s]Evaluating:  98%|█████████▊| 161/165 [00:58<00:01,  2.74it/s]Evaluating:  98%|█████████▊| 162/165 [00:59<00:01,  2.70it/s]Evaluating:  99%|█████████▉| 163/165 [00:59<00:00,  2.71it/s]Evaluating:  99%|█████████▉| 164/165 [01:00<00:00,  2.73it/s]Evaluating: 100%|██████████| 165/165 [01:00<00:00,  3.49it/s]Evaluating: 100%|██████████| 165/165 [01:00<00:00,  2.74it/s]
05/09/2022 20:11:25 - INFO - __main__ -     Evaluation done in total 60.176545 secs (0.045796 sec per example)
05/09/2022 20:11:31 - INFO - __main__ -   Results: {'exact': 61.1764705882353, 'f1': 73.30711029351001, 'total': 1190, 'HasAns_exact': 61.1764705882353, 'HasAns_f1': 73.30711029351001, 'HasAns_total': 1190, 'best_exact': 61.1764705882353, 'best_exact_thresh': 0.0, 'best_f1': 73.30711029351001, 'best_f1_thresh': 0.0}
  zh 
2022-05-09 20:11:38.041693: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0
05/09/2022 20:11:43 - WARNING - __main__ -   Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, 16-bits training: False
You are using a model of type xlm-roberta to instantiate a model of type xlm. This is not supported for all configurations of models and can yield errors.
Some weights of the model checkpoint at /cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//squad/xlm-KG_LR8e-6_EPOCH2.0_maxlen384_batchsize4_gradacc4 were not used when initializing XLMRobertaModel: ['base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.13.attention.output.dense.weight', 'base_model.encoder.layer.12.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.20.attention.self.value.bias', 'base_model.encoder.layer.10.attention.output.LayerNorm.weight', 'base_model.encoder.layer.3.attention.output.dense.bias', 'base_model.encoder.layer.16.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.11.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.0.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.10.attention.self.key.weight', 'base_model.encoder.layer.6.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.17.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.9.attention.self.query.weight', 'base_model.encoder.layer.11.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.12.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.3.intermediate.dense.bias', 'base_model.encoder.layer.6.attention.output.dense.weight', 'base_model.encoder.layer.2.output.dense.bias', 'base_model.encoder.layer.12.attention.self.key.weight', 'base_model.encoder.layer.7.intermediate.dense.bias', 'base_model.encoder.layer.17.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.18.attention.self.value.bias', 'base_model.encoder.layer.21.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.4.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.7.intermediate.dense.weight', 'base_model.encoder.layer.2.output.dense.weight', 'base_model.encoder.layer.7.output.dense.bias', 'base_model.encoder.layer.10.output.dense.weight', 'base_model.encoder.layer.23.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.19.attention.self.query.weight', 'base_model.encoder.layer.5.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.20.attention.self.key.weight', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.6.attention.self.query.bias', 'base_model.encoder.layer.14.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.13.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.7.attention.self.query.weight', 'base_model.encoder.layer.11.attention.output.dense.weight', 'base_model.encoder.layer.9.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.14.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.18.attention.self.query.bias', 'base_model.encoder.layer.18.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.20.intermediate.dense.weight', 'base_model.encoder.layer.16.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.14.output.dense.bias', 'base_model.encoder.layer.4.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.17.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.8.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.11.intermediate.dense.weight', 'base_model.encoder.layer.5.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.8.attention.output.dense.bias', 'base_model.encoder.layer.8.attention.self.key.weight', 'base_model.encoder.layer.13.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.6.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.22.attention.output.dense.weight', 'base_model.encoder.layer.1.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.12.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.21.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.3.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.10.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.17.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.20.output.LayerNorm.weight', 'base_model.encoder.layer.10.attention.self.value.weight', 'base_model.encoder.layer.14.attention.self.key.weight', 'base_model.encoder.layer.23.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.20.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.0.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.3.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.22.attention.self.value.bias', 'base_model.encoder.layer.12.intermediate.dense.bias', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.10.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.12.attention.output.LayerNorm.weight', 'base_model.encoder.layer.4.output.dense.weight', 'base_model.encoder.layer.19.intermediate.dense.weight', 'base_model.encoder.layer.16.output.adapters.ep.adapter_up.bias', 'base_model.embeddings.LayerNorm.bias', 'base_model.encoder.layer.3.output.LayerNorm.weight', 'base_model.encoder.layer.18.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.6.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.10.attention.self.query.weight', 'base_model.encoder.layer.5.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.10.intermediate.dense.bias', 'base_model.encoder.layer.16.attention.output.dense.weight', 'base_model.encoder.layer.3.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.5.attention.output.LayerNorm.bias', 'base_model.encoder.layer.15.attention.self.key.weight', 'base_model.encoder.layer.0.attention.self.key.weight', 'base_model.encoder.layer.7.attention.output.dense.weight', 'base_model.encoder.layer.9.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.18.attention.self.key.weight', 'base_model.encoder.layer.21.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.14.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.11.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.0.output.LayerNorm.weight', 'base_model.encoder.layer.10.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.8.attention.self.query.weight', 'base_model.encoder.layer.13.attention.self.query.weight', 'base_model.encoder.layer.15.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.4.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.1.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.23.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.1.attention.output.LayerNorm.weight', 'base_model.encoder.layer.6.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.18.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.22.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.2.attention.self.query.bias', 'base_model.encoder.layer.7.output.LayerNorm.bias', 'base_model.encoder.layer.6.attention.output.dense.bias', 'base_model.encoder.layer.18.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.16.attention.self.key.weight', 'base_model.encoder.layer.21.output.dense.weight', 'base_model.encoder.layer.8.intermediate.dense.bias', 'base_model.encoder.layer.5.intermediate.dense.weight', 'base_model.encoder.layer.22.attention.self.value.weight', 'base_model.encoder.layer.17.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.15.output.LayerNorm.weight', 'base_model.encoder.layer.21.attention.self.value.weight', 'base_model.encoder.layer.21.intermediate.dense.weight', 'base_model.encoder.layer.17.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.10.attention.self.key.bias', 'base_model.encoder.layer.9.attention.output.dense.bias', 'base_model.encoder.layer.22.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.4.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.22.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.6.attention.output.LayerNorm.weight', 'base_model.encoder.layer.8.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.13.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.18.attention.self.value.weight', 'base_model.encoder.layer.13.attention.output.LayerNorm.weight', 'base_model.encoder.layer.4.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.11.attention.self.key.weight', 'base_model.encoder.layer.21.attention.output.LayerNorm.weight', 'base_model.encoder.layer.6.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.3.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.16.output.LayerNorm.weight', 'base_model.encoder.layer.1.attention.output.dense.weight', 'base_model.encoder.layer.1.output.dense.weight', 'base_model.encoder.layer.11.attention.self.query.bias', 'base_model.encoder.layer.3.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.7.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.19.attention.self.key.weight', 'base_model.encoder.layer.21.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.5.output.dense.weight', 'base_model.encoder.layer.22.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.9.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.15.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.17.attention.output.dense.weight', 'base_model.encoder.layer.15.output.dense.weight', 'base_model.encoder.layer.23.attention.output.LayerNorm.weight', 'base_model.encoder.layer.23.attention.self.key.weight', 'base_model.encoder.layer.23.attention.output.LayerNorm.bias', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.7.output.LayerNorm.weight', 'base_model.encoder.layer.9.attention.output.LayerNorm.bias', 'base_model.encoder.layer.8.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.20.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.12.output.LayerNorm.bias', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.9.intermediate.dense.weight', 'base_model.encoder.layer.10.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.3.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.14.attention.self.query.weight', 'base_model.encoder.layer.20.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.16.output.dense.weight', 'base_model.encoder.layer.22.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.21.output.dense.bias', 'base_model.encoder.layer.21.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.18.attention.output.LayerNorm.bias', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.17.output.dense.weight', 'base_model.encoder.layer.12.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.15.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.2.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.10.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.22.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.3.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.14.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.0.intermediate.dense.weight', 'base_model.encoder.layer.19.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.17.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.16.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.13.intermediate.dense.weight', 'base_model.encoder.layer.12.attention.output.dense.weight', 'base_model.encoder.layer.0.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.13.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.21.attention.output.dense.bias', 'base_model.encoder.layer.17.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.20.attention.output.dense.bias', 'base_model.encoder.layer.19.output.LayerNorm.weight', 'base_model.encoder.layer.11.output.LayerNorm.weight', 'base_model.encoder.layer.1.attention.self.value.weight', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.8.output.LayerNorm.bias', 'base_model.encoder.layer.0.attention.self.key.bias', 'base_model.encoder.layer.14.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.13.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.15.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.14.attention.output.dense.weight', 'base_model.encoder.layer.16.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.13.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.20.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.6.output.dense.weight', 'base_model.encoder.layer.5.attention.self.value.bias', 'base_model.encoder.layer.21.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.18.output.LayerNorm.bias', 'base_model.encoder.layer.14.attention.self.value.bias', 'base_model.encoder.layer.18.attention.output.dense.weight', 'base_model.encoder.layer.9.output.LayerNorm.bias', 'base_model.encoder.layer.2.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.10.output.dense.bias', 'base_model.encoder.layer.11.output.dense.bias', 'base_model.encoder.layer.11.attention.self.value.bias', 'base_model.encoder.layer.18.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.13.intermediate.dense.bias', 'base_model.encoder.layer.16.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.19.attention.self.query.bias', 'base_model.encoder.layer.11.intermediate.dense.bias', 'base_model.encoder.layer.11.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.3.attention.output.LayerNorm.weight', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.12.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.2.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.19.output.LayerNorm.bias', 'base_model.encoder.layer.15.attention.self.value.bias', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.21.attention.self.key.bias', 'base_model.encoder.layer.7.attention.self.key.bias', 'base_model.encoder.layer.17.output.dense.bias', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.0.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.12.attention.self.query.bias', 'base_model.encoder.layer.1.output.LayerNorm.weight', 'base_model.encoder.layer.19.attention.output.LayerNorm.weight', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.4.attention.self.key.weight', 'base_model.encoder.layer.18.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.22.intermediate.dense.weight', 'base_model.encoder.layer.11.attention.output.LayerNorm.weight', 'base_model.encoder.layer.17.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.22.output.dense.weight', 'base_model.encoder.layer.22.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.6.attention.self.key.bias', 'base_model.encoder.layer.0.output.dense.bias', 'base_model.encoder.layer.12.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.6.attention.self.value.bias', 'base_model.encoder.layer.1.intermediate.dense.bias', 'base_model.encoder.layer.19.intermediate.dense.bias', 'base_model.encoder.layer.22.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.7.attention.output.LayerNorm.weight', 'base_model.encoder.layer.12.output.dense.bias', 'base_model.encoder.layer.0.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.12.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.9.intermediate.dense.bias', 'base_model.encoder.layer.19.attention.self.key.bias', 'base_model.encoder.layer.14.attention.output.dense.bias', 'base_model.encoder.layer.3.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.8.output.dense.weight', 'base_model.encoder.layer.19.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.21.attention.self.query.bias', 'base_model.encoder.layer.9.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.14.intermediate.dense.bias', 'base_model.encoder.layer.5.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.8.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.22.attention.self.key.bias', 'base_model.encoder.layer.21.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.3.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.10.output.LayerNorm.bias', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.15.attention.self.value.weight', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.18.intermediate.dense.weight', 'base_model.encoder.layer.16.attention.output.LayerNorm.bias', 'base_model.encoder.layer.2.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.6.output.dense.bias', 'base_model.encoder.layer.1.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.17.intermediate.dense.weight', 'base_model.encoder.layer.4.attention.self.value.weight', 'base_model.encoder.layer.9.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.22.attention.self.key.weight', 'base_model.encoder.layer.2.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.6.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.8.attention.output.LayerNorm.bias', 'base_model.encoder.layer.12.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.20.attention.output.dense.weight', 'base_model.encoder.layer.1.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.17.attention.self.key.bias', 'base_model.encoder.layer.6.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.15.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.23.attention.self.value.weight', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.8.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.8.output.LayerNorm.weight', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.9.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.17.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.18.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.4.output.LayerNorm.weight', 'base_model.encoder.layer.2.attention.self.query.weight', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.11.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.7.attention.self.value.weight', 'base_model.encoder.layer.15.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.20.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.11.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.4.intermediate.dense.weight', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.20.output.dense.bias', 'base_model.encoder.layer.9.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.1.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.1.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.11.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.13.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.14.attention.self.query.bias', 'base_model.embeddings.position_ids', 'base_model.encoder.layer.5.output.LayerNorm.bias', 'base_model.encoder.layer.20.output.dense.weight', 'base_model.encoder.layer.19.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.8.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.10.attention.self.value.bias', 'base_model.encoder.layer.16.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.21.attention.output.LayerNorm.bias', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.2.attention.output.LayerNorm.weight', 'base_model.encoder.layer.21.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.5.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.1.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.11.attention.self.key.bias', 'base_model.encoder.layer.9.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.19.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.14.intermediate.dense.weight', 'base_model.encoder.layer.20.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.18.attention.self.query.weight', 'base_model.encoder.layer.7.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.11.attention.self.query.weight', 'base_model.encoder.layer.12.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.21.attention.output.dense.weight', 'base_model.encoder.layer.15.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.23.output.dense.weight', 'base_model.encoder.layer.21.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.2.intermediate.dense.bias', 'qa_outputs.weight', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.20.attention.self.query.weight', 'base_model.encoder.layer.13.output.LayerNorm.bias', 'base_model.encoder.layer.5.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.13.attention.self.value.weight', 'base_model.encoder.layer.6.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.8.attention.self.value.weight', 'base_model.encoder.layer.13.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.1.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.22.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.5.intermediate.dense.bias', 'base_model.encoder.layer.4.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.12.attention.self.value.weight', 'base_model.encoder.layer.22.attention.self.query.bias', 'base_model.encoder.layer.8.attention.output.LayerNorm.weight', 'base_model.encoder.layer.4.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.13.attention.self.key.weight', 'base_model.encoder.layer.2.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.16.attention.self.value.weight', 'base_model.encoder.layer.17.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.6.attention.self.key.weight', 'base_model.encoder.layer.16.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.23.attention.output.dense.weight', 'base_model.encoder.layer.16.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.13.attention.self.value.bias', 'qa_outputs.bias', 'base_model.encoder.layer.1.attention.self.key.bias', 'base_model.encoder.layer.15.attention.self.query.weight', 'base_model.encoder.layer.11.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.5.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.2.attention.self.value.bias', 'base_model.encoder.layer.4.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.8.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.3.attention.self.key.weight', 'base_model.encoder.layer.6.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.12.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.4.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.12.attention.self.value.bias', 'base_model.encoder.layer.22.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.2.attention.output.dense.weight', 'base_model.encoder.layer.5.attention.self.key.bias', 'base_model.encoder.layer.9.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.7.output.dense.weight', 'base_model.encoder.layer.9.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.14.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.2.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.15.intermediate.dense.bias', 'base_model.encoder.layer.14.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.4.attention.output.dense.bias', 'base_model.encoder.layer.11.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.21.intermediate.dense.bias', 'base_model.encoder.layer.10.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.15.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.19.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.14.attention.self.value.weight', 'base_model.encoder.layer.23.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.13.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.5.attention.output.dense.weight', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.6.output.LayerNorm.bias', 'base_model.encoder.layer.6.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.11.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.16.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.20.attention.output.LayerNorm.weight', 'base_model.encoder.layer.21.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.22.output.LayerNorm.weight', 'base_model.encoder.layer.14.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.20.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.7.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.4.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.17.output.LayerNorm.weight', 'base_model.encoder.layer.3.output.dense.weight', 'base_model.encoder.layer.14.attention.output.LayerNorm.bias', 'base_model.encoder.layer.17.attention.self.query.bias', 'base_model.encoder.layer.5.attention.output.dense.bias', 'base_model.encoder.layer.8.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.9.attention.self.key.weight', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.pooler.dense.weight', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.7.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.16.intermediate.dense.weight', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.8.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.4.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.12.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.4.attention.self.key.bias', 'base_model.encoder.layer.1.output.dense.bias', 'base_model.encoder.layer.3.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.5.attention.output.LayerNorm.weight', 'base_model.encoder.layer.19.attention.output.dense.weight', 'base_model.encoder.layer.15.output.LayerNorm.bias', 'base_model.embeddings.word_embeddings.weight', 'base_model.encoder.layer.2.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.2.attention.self.key.bias', 'base_model.encoder.layer.3.output.dense.bias', 'base_model.encoder.layer.4.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.6.intermediate.dense.bias', 'base_model.encoder.layer.7.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.9.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.5.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.0.attention.self.query.weight', 'base_model.encoder.layer.7.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.8.output.dense.bias', 'base_model.encoder.layer.3.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.12.attention.output.LayerNorm.bias', 'base_model.encoder.layer.20.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.15.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.11.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.1.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.22.output.dense.bias', 'base_model.encoder.layer.21.attention.self.value.bias', 'base_model.encoder.layer.0.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.3.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.12.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.18.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.20.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.23.output.LayerNorm.weight', 'base_model.encoder.layer.10.intermediate.dense.weight', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.9.attention.output.dense.weight', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.3.attention.self.query.weight', 'base_model.encoder.layer.9.attention.self.key.bias', 'base_model.encoder.layer.10.attention.output.LayerNorm.bias', 'base_model.encoder.layer.1.intermediate.dense.weight', 'base_model.encoder.layer.6.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.19.output.dense.bias', 'base_model.encoder.layer.15.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.3.attention.self.value.bias', 'base_model.encoder.layer.16.attention.self.key.bias', 'base_model.encoder.layer.0.output.LayerNorm.bias', 'base_model.encoder.layer.12.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.15.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.17.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.16.attention.self.value.bias', 'base_model.encoder.layer.23.attention.self.value.bias', 'base_model.encoder.layer.21.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.10.attention.output.dense.weight', 'base_model.encoder.layer.0.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.1.attention.self.value.bias', 'base_model.encoder.layer.7.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.16.attention.output.dense.bias', 'base_model.encoder.layer.9.attention.output.LayerNorm.weight', 'base_model.encoder.layer.12.output.dense.weight', 'base_model.encoder.layer.18.attention.output.LayerNorm.weight', 'base_model.encoder.layer.10.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.12.attention.output.dense.bias', 'base_model.encoder.layer.16.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.21.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.14.attention.self.key.bias', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.12.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.17.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.9.output.LayerNorm.weight', 'base_model.encoder.layer.18.attention.output.dense.bias', 'base_model.encoder.layer.14.attention.output.LayerNorm.weight', 'base_model.encoder.layer.8.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.0.attention.self.value.weight', 'base_model.encoder.layer.17.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.13.attention.output.dense.bias', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.20.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.21.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.4.attention.output.LayerNorm.weight', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.16.attention.self.query.bias', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.4.attention.self.query.bias', 'base_model.encoder.layer.14.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.2.attention.output.dense.bias', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.18.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.3.attention.self.query.bias', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.9.attention.self.value.weight', 'base_model.encoder.layer.19.attention.output.dense.bias', 'base_model.encoder.layer.0.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.3.output.adapters.ep.adapter_down.0.bias', 'base_model.embeddings.token_type_embeddings.weight', 'base_model.encoder.layer.2.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.10.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.6.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.13.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.15.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.0.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.3.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.15.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.16.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.23.attention.output.dense.bias', 'base_model.encoder.layer.4.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.22.output.LayerNorm.bias', 'base_model.encoder.layer.3.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.13.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.5.attention.self.value.weight', 'base_model.encoder.layer.15.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.16.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.23.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.19.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.23.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.23.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.1.attention.output.dense.bias', 'base_model.encoder.layer.20.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.4.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.22.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.11.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.6.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.14.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.14.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.7.attention.output.dense.bias', 'base_model.encoder.layer.19.output.dense.weight', 'base_model.encoder.layer.13.attention.self.key.bias', 'base_model.encoder.layer.22.attention.self.query.weight', 'base_model.encoder.layer.6.attention.output.LayerNorm.bias', 'base_model.encoder.layer.21.attention.self.key.weight', 'base_model.encoder.layer.2.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.18.intermediate.dense.bias', 'base_model.encoder.layer.23.attention.self.key.bias', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.1.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.6.output.LayerNorm.weight', 'base_model.encoder.layer.5.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.22.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.7.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.16.intermediate.dense.bias', 'base_model.encoder.layer.19.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.13.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.18.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.8.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.17.attention.self.query.weight', 'base_model.encoder.layer.13.output.dense.bias', 'base_model.encoder.layer.19.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.16.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.5.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.0.output.dense.weight', 'base_model.encoder.layer.23.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.1.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.11.attention.output.dense.bias', 'base_model.encoder.layer.12.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.20.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.9.attention.self.query.bias', 'base_model.encoder.layer.8.attention.self.value.bias', 'base_model.encoder.layer.6.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.23.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.10.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.1.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.9.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.16.attention.output.LayerNorm.weight', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.10.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.21.output.LayerNorm.bias', 'base_model.encoder.layer.22.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.4.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.9.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.9.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.17.intermediate.dense.bias', 'base_model.encoder.layer.4.attention.output.LayerNorm.bias', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.23.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.22.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.19.attention.self.value.bias', 'base_model.encoder.layer.21.attention.self.query.weight', 'base_model.encoder.layer.7.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.14.output.dense.weight', 'base_model.encoder.layer.11.output.LayerNorm.bias', 'base_model.encoder.layer.4.attention.self.query.weight', 'base_model.encoder.layer.21.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.2.intermediate.dense.weight', 'base_model.encoder.layer.2.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.9.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.2.attention.self.value.weight', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.23.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.18.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.1.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.5.attention.self.query.bias', 'base_model.encoder.layer.15.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.7.attention.self.key.weight', 'base_model.encoder.layer.2.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.21.output.LayerNorm.weight', 'base_model.encoder.layer.4.intermediate.dense.bias', 'base_model.encoder.layer.2.attention.output.LayerNorm.bias', 'base_model.encoder.layer.2.attention.self.key.weight', 'base_model.encoder.layer.13.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.21.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.7.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.5.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.6.attention.self.value.weight', 'base_model.encoder.layer.0.attention.self.query.bias', 'base_model.encoder.layer.15.attention.self.key.bias', 'base_model.encoder.layer.23.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.14.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.10.attention.output.dense.bias', 'base_model.encoder.layer.10.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.18.output.LayerNorm.weight', 'base_model.encoder.layer.7.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.0.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.5.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.10.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.18.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.23.intermediate.dense.weight', 'base_model.encoder.layer.23.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.5.attention.self.query.weight', 'base_model.encoder.layer.17.attention.output.LayerNorm.bias', 'base_model.encoder.layer.14.output.LayerNorm.bias', 'base_model.encoder.layer.16.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.12.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.5.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.11.attention.output.LayerNorm.bias', 'base_model.encoder.layer.7.output.adapters.es.adapter_down.0.weight', 'base_model.pooler.dense.bias', 'base_model.encoder.layer.15.output.dense.bias', 'base_model.encoder.layer.18.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.16.attention.self.query.weight', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.0.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.0.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.7.attention.self.value.bias', 'base_model.encoder.layer.2.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.8.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.0.attention.output.LayerNorm.weight', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.0.attention.output.dense.bias', 'base_model.encoder.layer.2.output.LayerNorm.bias', 'base_model.encoder.layer.4.output.LayerNorm.bias', 'base_model.encoder.layer.19.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.20.attention.self.value.weight', 'base_model.encoder.layer.20.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.1.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.20.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.11.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.7.attention.output.LayerNorm.bias', 'base_model.encoder.layer.8.intermediate.dense.weight', 'base_model.encoder.layer.9.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.14.output.adapters.es.adapter_up.weight', 'base_model.embeddings.LayerNorm.weight', 'base_model.encoder.layer.2.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.19.attention.output.LayerNorm.bias', 'base_model.encoder.layer.9.output.dense.weight', 'base_model.encoder.layer.0.intermediate.dense.bias', 'base_model.encoder.layer.4.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.5.output.dense.bias', 'base_model.encoder.layer.20.attention.output.LayerNorm.bias', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.6.attention.self.query.weight', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.13.output.dense.weight', 'base_model.encoder.layer.8.attention.output.dense.weight', 'base_model.encoder.layer.9.output.dense.bias', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.11.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.16.output.dense.bias', 'base_model.encoder.layer.18.attention.self.key.bias', 'base_model.encoder.layer.23.attention.self.query.weight', 'base_model.encoder.layer.8.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.3.attention.self.value.weight', 'base_model.encoder.layer.3.attention.output.LayerNorm.bias', 'base_model.encoder.layer.13.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.3.output.LayerNorm.bias', 'base_model.encoder.layer.14.output.LayerNorm.weight', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.17.attention.output.dense.bias', 'base_model.encoder.layer.18.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.19.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.7.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.22.intermediate.dense.bias', 'base_model.encoder.layer.3.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.10.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.20.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.14.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.12.intermediate.dense.weight', 'base_model.encoder.layer.13.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.11.output.dense.weight', 'base_model.encoder.layer.17.attention.output.LayerNorm.weight', 'base_model.encoder.layer.18.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.4.attention.self.value.bias', 'base_model.encoder.layer.12.attention.self.key.bias', 'base_model.encoder.layer.8.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.7.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.15.attention.output.dense.weight', 'base_model.encoder.layer.23.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.20.output.LayerNorm.bias', 'base_model.encoder.layer.12.attention.self.query.weight', 'base_model.encoder.layer.5.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.22.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.13.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.15.attention.output.LayerNorm.weight', 'base_model.encoder.layer.17.attention.self.value.bias', 'base_model.encoder.layer.22.attention.output.dense.bias', 'base_model.encoder.layer.2.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.18.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.19.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.2.output.LayerNorm.weight', 'base_model.encoder.layer.8.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.11.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.21.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.1.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.6.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.0.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.16.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.20.attention.self.key.bias', 'base_model.encoder.layer.11.attention.self.value.weight', 'base_model.encoder.layer.0.attention.output.LayerNorm.bias', 'base_model.encoder.layer.14.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.7.attention.self.query.bias', 'base_model.encoder.layer.5.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.10.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.13.attention.self.query.bias', 'base_model.encoder.layer.19.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.15.intermediate.dense.weight', 'base_model.encoder.layer.4.output.dense.bias', 'base_model.encoder.layer.5.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.12.output.LayerNorm.weight', 'base_model.encoder.layer.19.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.19.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.20.intermediate.dense.bias', 'base_model.embeddings.position_embeddings.weight', 'base_model.encoder.layer.15.attention.output.dense.bias', 'base_model.encoder.layer.23.attention.self.query.bias', 'base_model.encoder.layer.16.output.LayerNorm.bias', 'base_model.encoder.layer.20.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.1.output.LayerNorm.bias', 'base_model.encoder.layer.5.output.LayerNorm.weight', 'base_model.encoder.layer.0.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.3.intermediate.dense.weight', 'base_model.encoder.layer.6.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.18.output.dense.weight', 'base_model.encoder.layer.17.attention.self.value.weight', 'base_model.encoder.layer.10.output.LayerNorm.weight', 'base_model.encoder.layer.1.attention.self.key.weight', 'base_model.encoder.layer.1.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.5.attention.self.key.weight', 'base_model.encoder.layer.9.attention.self.value.bias', 'base_model.encoder.layer.10.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.17.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.23.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.0.attention.self.value.bias', 'base_model.encoder.layer.7.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.13.output.LayerNorm.weight', 'base_model.encoder.layer.23.intermediate.dense.bias', 'base_model.encoder.layer.6.intermediate.dense.weight', 'base_model.encoder.layer.1.attention.self.query.bias', 'base_model.encoder.layer.18.output.dense.bias', 'base_model.encoder.layer.0.attention.output.dense.weight', 'base_model.encoder.layer.0.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.8.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.15.attention.self.query.bias', 'base_model.encoder.layer.15.attention.output.LayerNorm.bias', 'base_model.encoder.layer.22.attention.output.LayerNorm.weight', 'base_model.encoder.layer.17.output.LayerNorm.bias', 'base_model.encoder.layer.23.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.3.attention.self.key.bias', 'base_model.encoder.layer.19.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.11.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.17.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.22.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.1.attention.output.LayerNorm.bias', 'base_model.encoder.layer.2.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.3.attention.output.dense.weight', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.0.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.22.attention.output.LayerNorm.bias', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.10.attention.self.query.bias', 'base_model.encoder.layer.14.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.19.attention.self.value.weight', 'base_model.encoder.layer.19.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.4.attention.output.dense.weight', 'base_model.encoder.layer.8.attention.self.query.bias', 'base_model.encoder.layer.10.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.17.attention.self.key.weight', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.7.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.13.attention.output.LayerNorm.bias', 'base_model.encoder.layer.23.output.LayerNorm.bias', 'base_model.encoder.layer.15.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.1.attention.self.query.weight', 'base_model.encoder.layer.20.attention.self.query.bias', 'base_model.encoder.layer.8.attention.self.key.bias', 'base_model.encoder.layer.23.output.dense.bias']
- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of XLMRobertaModel were not initialized from the model checkpoint at /cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//squad/xlm-KG_LR8e-6_EPOCH2.0_maxlen384_batchsize4_gradacc4 and are newly initialized: ['encoder.layer.15.attention.output.LayerNorm.bias', 'encoder.layer.2.attention.output.LayerNorm.weight', 'encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.layer.9.attention.self.value.weight', 'encoder.layer.5.output.dense.bias', 'encoder.layer.10.output.LayerNorm.bias', 'encoder.layer.13.output.LayerNorm.weight', 'pooler.dense.bias', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.1.attention.output.dense.bias', 'encoder.layer.20.attention.output.LayerNorm.weight', 'encoder.layer.16.attention.self.key.weight', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.15.intermediate.dense.weight', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.20.attention.output.LayerNorm.bias', 'encoder.layer.8.output.dense.bias', 'encoder.layer.0.attention.output.dense.bias', 'encoder.layer.12.attention.self.value.weight', 'encoder.layer.18.attention.self.value.bias', 'encoder.layer.23.attention.self.key.weight', 'encoder.layer.16.attention.output.LayerNorm.bias', 'encoder.layer.12.attention.output.LayerNorm.weight', 'encoder.layer.20.attention.self.key.weight', 'encoder.layer.14.attention.self.query.bias', 'encoder.layer.6.attention.output.LayerNorm.weight', 'encoder.layer.14.output.dense.bias', 'encoder.layer.0.attention.self.key.weight', 'encoder.layer.4.attention.output.dense.bias', 'encoder.layer.2.attention.self.key.bias', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.11.attention.self.key.weight', 'encoder.layer.15.attention.output.LayerNorm.weight', 'encoder.layer.17.attention.output.dense.bias', 'encoder.layer.22.attention.self.key.weight', 'encoder.layer.3.attention.self.query.bias', 'encoder.layer.7.attention.self.key.bias', 'encoder.layer.21.attention.self.key.weight', 'encoder.layer.0.attention.self.query.weight', 'encoder.layer.1.attention.self.value.weight', 'encoder.layer.23.attention.output.dense.bias', 'encoder.layer.5.attention.self.value.bias', 'encoder.layer.16.attention.self.query.weight', 'encoder.layer.19.attention.self.value.bias', 'encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.11.attention.self.query.weight', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.14.intermediate.dense.weight', 'encoder.layer.14.output.LayerNorm.weight', 'encoder.layer.21.attention.output.LayerNorm.bias', 'encoder.layer.22.attention.self.query.weight', 'encoder.layer.18.attention.self.key.bias', 'encoder.layer.14.attention.self.key.bias', 'encoder.layer.22.attention.output.dense.bias', 'encoder.layer.5.attention.output.dense.bias', 'encoder.layer.18.output.LayerNorm.weight', 'pooler.dense.weight', 'encoder.layer.10.attention.self.value.bias', 'encoder.layer.15.intermediate.dense.bias', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.4.attention.self.query.bias', 'encoder.layer.20.intermediate.dense.weight', 'encoder.layer.2.attention.self.value.bias', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.11.attention.self.value.weight', 'encoder.layer.16.attention.output.LayerNorm.weight', 'encoder.layer.2.attention.self.value.weight', 'encoder.layer.8.output.LayerNorm.weight', 'encoder.layer.13.output.LayerNorm.bias', 'encoder.layer.14.attention.output.LayerNorm.bias', 'encoder.layer.13.attention.output.dense.weight', 'encoder.layer.8.attention.self.query.weight', 'encoder.layer.23.attention.self.query.weight', 'encoder.layer.19.attention.self.key.weight', 'encoder.layer.8.attention.output.LayerNorm.bias', 'encoder.layer.15.output.LayerNorm.weight', 'encoder.layer.20.attention.self.key.bias', 'encoder.layer.12.attention.output.LayerNorm.bias', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.18.attention.output.dense.weight', 'encoder.layer.2.attention.self.query.bias', 'encoder.layer.10.output.LayerNorm.weight', 'encoder.layer.22.attention.self.query.bias', 'encoder.layer.20.intermediate.dense.bias', 'encoder.layer.14.attention.output.dense.weight', 'encoder.layer.23.output.dense.bias', 'encoder.layer.12.output.LayerNorm.weight', 'encoder.layer.19.attention.self.value.weight', 'encoder.layer.19.output.dense.bias', 'encoder.layer.15.attention.output.dense.bias', 'encoder.layer.17.attention.self.query.bias', 'encoder.layer.23.output.LayerNorm.weight', 'encoder.layer.0.output.dense.weight', 'encoder.layer.11.attention.self.value.bias', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.14.attention.output.LayerNorm.weight', 'encoder.layer.16.attention.output.dense.bias', 'encoder.layer.10.attention.self.key.bias', 'encoder.layer.22.output.LayerNorm.weight', 'encoder.layer.21.attention.self.query.bias', 'encoder.layer.8.attention.self.query.bias', 'encoder.layer.4.output.dense.weight', 'encoder.layer.22.intermediate.dense.weight', 'encoder.layer.21.output.LayerNorm.bias', 'encoder.layer.21.output.dense.weight', 'encoder.layer.20.attention.self.query.bias', 'encoder.layer.9.output.dense.weight', 'encoder.layer.21.attention.self.value.weight', 'encoder.layer.20.output.LayerNorm.bias', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.12.attention.self.query.bias', 'encoder.layer.18.attention.output.LayerNorm.bias', 'encoder.layer.0.attention.self.query.bias', 'encoder.layer.16.intermediate.dense.weight', 'encoder.layer.4.attention.self.value.bias', 'encoder.layer.17.intermediate.dense.weight', 'encoder.layer.8.attention.self.key.bias', 'encoder.layer.20.attention.self.query.weight', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.18.attention.output.LayerNorm.weight', 'encoder.layer.4.attention.output.dense.weight', 'encoder.layer.12.attention.output.dense.weight', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.17.attention.self.query.weight', 'encoder.layer.8.attention.output.dense.weight', 'embeddings.LayerNorm.weight', 'encoder.layer.7.attention.self.value.bias', 'encoder.layer.1.attention.self.key.bias', 'encoder.layer.9.attention.self.query.weight', 'encoder.layer.13.attention.output.LayerNorm.bias', 'encoder.layer.11.output.LayerNorm.bias', 'encoder.layer.17.output.dense.bias', 'encoder.layer.16.attention.self.value.weight', 'encoder.layer.21.intermediate.dense.weight', 'encoder.layer.15.output.dense.weight', 'encoder.layer.10.attention.output.dense.bias', 'encoder.layer.12.output.LayerNorm.bias', 'encoder.layer.19.intermediate.dense.bias', 'encoder.layer.1.attention.output.LayerNorm.weight', 'encoder.layer.12.attention.self.value.bias', 'encoder.layer.9.attention.output.LayerNorm.weight', 'encoder.layer.14.intermediate.dense.bias', 'encoder.layer.23.output.LayerNorm.bias', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.3.attention.output.LayerNorm.weight', 'embeddings.word_embeddings.weight', 'encoder.layer.7.output.dense.weight', 'encoder.layer.13.attention.self.query.weight', 'encoder.layer.18.attention.self.query.weight', 'embeddings.token_type_embeddings.weight', 'encoder.layer.22.intermediate.dense.bias', 'encoder.layer.10.attention.output.dense.weight', 'encoder.layer.17.attention.output.dense.weight', 'encoder.layer.3.output.dense.weight', 'encoder.layer.18.attention.self.value.weight', 'encoder.layer.1.attention.self.query.bias', 'encoder.layer.8.attention.output.LayerNorm.weight', 'encoder.layer.1.output.dense.weight', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.23.attention.output.dense.weight', 'encoder.layer.13.attention.output.LayerNorm.weight', 'encoder.layer.7.output.dense.bias', 'encoder.layer.7.attention.output.dense.bias', 'encoder.layer.20.attention.output.dense.weight', 'encoder.layer.6.output.dense.bias', 'encoder.layer.12.intermediate.dense.weight', 'encoder.layer.16.output.LayerNorm.bias', 'encoder.layer.9.attention.output.dense.weight', 'encoder.layer.8.attention.self.key.weight', 'encoder.layer.8.output.LayerNorm.bias', 'encoder.layer.10.output.dense.weight', 'encoder.layer.18.attention.self.query.bias', 'encoder.layer.22.output.LayerNorm.bias', 'encoder.layer.22.attention.output.LayerNorm.bias', 'encoder.layer.8.output.dense.weight', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.19.output.LayerNorm.weight', 'encoder.layer.22.attention.self.key.bias', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.5.attention.self.key.bias', 'encoder.layer.16.intermediate.dense.bias', 'encoder.layer.4.attention.self.key.bias', 'encoder.layer.5.output.LayerNorm.bias', 'encoder.layer.18.attention.output.dense.bias', 'encoder.layer.6.attention.output.LayerNorm.bias', 'encoder.layer.13.attention.output.dense.bias', 'encoder.layer.13.attention.self.value.weight', 'encoder.layer.12.attention.self.query.weight', 'encoder.layer.10.attention.self.value.weight', 'encoder.layer.13.intermediate.dense.weight', 'encoder.layer.13.output.dense.bias', 'encoder.layer.8.attention.self.value.bias', 'encoder.layer.5.attention.self.key.weight', 'encoder.layer.7.attention.output.dense.weight', 'encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.layer.14.attention.self.key.weight', 'encoder.layer.19.intermediate.dense.weight', 'embeddings.LayerNorm.bias', 'encoder.layer.9.attention.output.LayerNorm.bias', 'encoder.layer.8.attention.self.value.weight', 'encoder.layer.17.attention.self.key.bias', 'encoder.layer.17.attention.output.LayerNorm.weight', 'encoder.layer.22.output.dense.weight', 'encoder.layer.11.attention.output.dense.bias', 'encoder.layer.18.intermediate.dense.bias', 'encoder.layer.23.output.dense.weight', 'encoder.layer.6.attention.self.value.weight', 'encoder.layer.1.attention.self.query.weight', 'encoder.layer.9.attention.self.query.bias', 'encoder.layer.6.attention.self.value.bias', 'encoder.layer.14.attention.self.value.weight', 'encoder.layer.17.attention.self.value.weight', 'encoder.layer.3.attention.self.query.weight', 'encoder.layer.4.output.dense.bias', 'encoder.layer.11.output.dense.bias', 'encoder.layer.6.attention.self.query.weight', 'encoder.layer.14.output.LayerNorm.bias', 'encoder.layer.2.attention.output.LayerNorm.bias', 'encoder.layer.2.attention.self.key.weight', 'encoder.layer.2.output.dense.bias', 'encoder.layer.16.output.dense.bias', 'encoder.layer.5.attention.self.query.bias', 'encoder.layer.3.attention.output.dense.bias', 'embeddings.position_embeddings.weight', 'encoder.layer.22.attention.output.LayerNorm.weight', 'encoder.layer.14.attention.self.value.bias', 'encoder.layer.7.attention.self.value.weight', 'encoder.layer.4.attention.output.LayerNorm.bias', 'encoder.layer.6.attention.self.query.bias', 'encoder.layer.20.attention.self.value.weight', 'encoder.layer.5.attention.output.LayerNorm.weight', 'encoder.layer.10.attention.self.query.bias', 'encoder.layer.11.attention.output.dense.weight', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.22.attention.self.value.bias', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.16.output.LayerNorm.weight', 'encoder.layer.11.attention.output.LayerNorm.weight', 'encoder.layer.19.attention.self.key.bias', 'encoder.layer.7.attention.self.key.weight', 'encoder.layer.8.attention.output.dense.bias', 'encoder.layer.10.output.dense.bias', 'encoder.layer.21.attention.output.dense.bias', 'encoder.layer.14.attention.output.dense.bias', 'encoder.layer.11.attention.self.query.bias', 'encoder.layer.12.attention.self.key.bias', 'encoder.layer.18.output.dense.bias', 'encoder.layer.19.output.dense.weight', 'encoder.layer.4.attention.output.LayerNorm.weight', 'encoder.layer.15.output.dense.bias', 'encoder.layer.23.attention.output.LayerNorm.weight', 'encoder.layer.13.attention.self.query.bias', 'encoder.layer.12.output.dense.bias', 'encoder.layer.18.intermediate.dense.weight', 'encoder.layer.12.output.dense.weight', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.5.attention.self.value.weight', 'encoder.layer.2.attention.output.dense.bias', 'encoder.layer.13.attention.self.key.bias', 'encoder.layer.15.attention.self.key.bias', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.10.attention.self.query.weight', 'encoder.layer.20.output.dense.bias', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.20.attention.output.dense.bias', 'encoder.layer.9.attention.self.key.weight', 'encoder.layer.6.attention.output.dense.bias', 'encoder.layer.0.attention.self.value.bias', 'encoder.layer.5.attention.output.dense.weight', 'encoder.layer.21.intermediate.dense.bias', 'encoder.layer.0.attention.self.value.weight', 'encoder.layer.0.output.dense.bias', 'encoder.layer.6.attention.output.dense.weight', 'encoder.layer.1.output.dense.bias', 'encoder.layer.0.attention.self.key.bias', 'encoder.layer.18.attention.self.key.weight', 'encoder.layer.16.output.dense.weight', 'encoder.layer.2.attention.self.query.weight', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.2.output.dense.weight', 'encoder.layer.19.output.LayerNorm.bias', 'encoder.layer.23.intermediate.dense.bias', 'encoder.layer.17.output.dense.weight', 'encoder.layer.12.attention.output.dense.bias', 'encoder.layer.6.attention.self.key.weight', 'encoder.layer.14.output.dense.weight', 'encoder.layer.15.attention.self.query.bias', 'encoder.layer.17.attention.self.key.weight', 'encoder.layer.1.attention.self.value.bias', 'encoder.layer.7.output.LayerNorm.weight', 'encoder.layer.13.attention.self.key.weight', 'encoder.layer.17.output.LayerNorm.weight', 'encoder.layer.19.attention.self.query.bias', 'encoder.layer.3.attention.self.key.weight', 'encoder.layer.4.attention.self.query.weight', 'encoder.layer.0.attention.output.dense.weight', 'encoder.layer.1.attention.output.dense.weight', 'encoder.layer.3.attention.output.dense.weight', 'encoder.layer.6.attention.self.key.bias', 'encoder.layer.22.attention.self.value.weight', 'encoder.layer.9.attention.self.value.bias', 'encoder.layer.10.attention.output.LayerNorm.weight', 'encoder.layer.23.attention.self.query.bias', 'encoder.layer.7.output.LayerNorm.bias', 'encoder.layer.9.output.LayerNorm.bias', 'encoder.layer.9.output.LayerNorm.weight', 'encoder.layer.4.attention.self.key.weight', 'encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.layer.9.attention.output.dense.bias', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.20.output.dense.weight', 'encoder.layer.15.attention.output.dense.weight', 'encoder.layer.21.attention.output.dense.weight', 'encoder.layer.6.output.LayerNorm.bias', 'encoder.layer.11.output.LayerNorm.weight', 'encoder.layer.11.attention.self.key.bias', 'encoder.layer.3.attention.self.value.bias', 'encoder.layer.15.attention.self.query.weight', 'encoder.layer.22.attention.output.dense.weight', 'encoder.layer.15.attention.self.value.bias', 'encoder.layer.19.attention.output.dense.bias', 'encoder.layer.20.output.LayerNorm.weight', 'encoder.layer.23.attention.self.value.weight', 'encoder.layer.19.attention.self.query.weight', 'encoder.layer.2.attention.output.dense.weight', 'encoder.layer.17.attention.output.LayerNorm.bias', 'encoder.layer.6.output.dense.weight', 'encoder.layer.17.attention.self.value.bias', 'encoder.layer.12.intermediate.dense.bias', 'encoder.layer.11.output.dense.weight', 'encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.layer.21.output.dense.bias', 'encoder.layer.15.output.LayerNorm.bias', 'encoder.layer.22.output.dense.bias', 'encoder.layer.9.output.dense.bias', 'encoder.layer.20.attention.self.value.bias', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.3.output.dense.bias', 'encoder.layer.7.attention.output.LayerNorm.bias', 'encoder.layer.19.attention.output.LayerNorm.weight', 'encoder.layer.5.attention.self.query.weight', 'encoder.layer.0.attention.output.LayerNorm.weight', 'encoder.layer.17.output.LayerNorm.bias', 'encoder.layer.17.intermediate.dense.bias', 'encoder.layer.10.attention.output.LayerNorm.bias', 'encoder.layer.13.intermediate.dense.bias', 'encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.layer.13.attention.self.value.bias', 'encoder.layer.21.attention.self.value.bias', 'encoder.layer.12.attention.self.key.weight', 'encoder.layer.4.attention.self.value.weight', 'encoder.layer.13.output.dense.weight', 'encoder.layer.23.intermediate.dense.weight', 'encoder.layer.3.attention.self.value.weight', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.21.output.LayerNorm.weight', 'encoder.layer.23.attention.self.value.bias', 'encoder.layer.18.output.dense.weight', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.23.attention.self.key.bias', 'encoder.layer.7.attention.output.LayerNorm.weight', 'encoder.layer.16.attention.self.value.bias', 'encoder.layer.21.attention.self.query.weight', 'encoder.layer.10.intermediate.dense.weight', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.19.attention.output.LayerNorm.bias', 'encoder.layer.10.attention.self.key.weight', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.9.attention.self.key.bias', 'encoder.layer.7.attention.self.query.weight', 'encoder.layer.7.attention.self.query.bias', 'encoder.layer.23.attention.output.LayerNorm.bias', 'encoder.layer.21.attention.output.LayerNorm.weight', 'encoder.layer.21.attention.self.key.bias', 'encoder.layer.14.attention.self.query.weight', 'encoder.layer.19.attention.output.dense.weight', 'encoder.layer.16.attention.output.dense.weight', 'encoder.layer.15.attention.self.key.weight', 'encoder.layer.15.attention.self.value.weight', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.16.attention.self.query.bias', 'encoder.layer.3.attention.self.key.bias', 'encoder.layer.7.intermediate.dense.bias', 'encoder.layer.18.output.LayerNorm.bias', 'encoder.layer.1.attention.self.key.weight', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.16.attention.self.key.bias', 'encoder.layer.5.output.dense.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Overwriting existing adapter 'ep'.
Overwriting existing adapter 'tp'.
Overwriting existing adapter 'es'.
Overwriting existing adapter 'ts'.
Overwriting existing adapter fusion module 'ep,tp,es,ts'
05/09/2022 20:12:21 - INFO - __main__ -   lang2id = None
05/09/2022 20:12:25 - INFO - __main__ -   Training/evaluation parameters Namespace(adam_epsilon=1e-08, cache_dir='', config_name='', data_dir=None, device=device(type='cuda'), do_eval=True, do_lower_case=False, do_train=False, doc_stride=128, eval_all_checkpoints=False, eval_lang='zh', evaluate_during_training=False, fp16=False, fp16_opt_level='O1', gradient_accumulation_steps=1, learning_rate=5e-05, local_rank=-1, logging_steps=50, max_answer_length=30, max_grad_norm=1.0, max_query_length=64, max_seq_length=384, max_steps=-1, model_name='xlm-KG', model_name_or_path='/cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//squad/xlm-KG_LR8e-6_EPOCH2.0_maxlen384_batchsize4_gradacc4', model_type='xlm', modelkg_dir='/cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/adapter/xlmr_adapter', n_best_size=20, n_gpu=1, no_cuda=False, null_score_diff_threshold=0.0, num_train_epochs=3.0, output_dir='/cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//squad/xlm-KG_LR8e-6_EPOCH2.0_maxlen384_batchsize4_gradacc4/predictions/xquad/', overwrite_cache=False, overwrite_output_dir=False, per_gpu_eval_batch_size=8, per_gpu_train_batch_size=8, predict_file='/cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/download//xquad//xquad.zh.json', save_steps=50, seed=42, server_ip='', server_port='', threads=1, tokenizer_name='', train_file=None, train_lang='en', verbose_logging=False, version_2_with_negative=False, warmup_steps=0, weight_decay=0.0)
05/09/2022 20:12:25 - INFO - __main__ -   Loading checkpoint /cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//squad/xlm-KG_LR8e-6_EPOCH2.0_maxlen384_batchsize4_gradacc4 for evaluation
05/09/2022 20:12:25 - INFO - __main__ -   Evaluate the following checkpoints: ['/cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//squad/xlm-KG_LR8e-6_EPOCH2.0_maxlen384_batchsize4_gradacc4']
Some weights of the model checkpoint at /cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//squad/xlm-KG_LR8e-6_EPOCH2.0_maxlen384_batchsize4_gradacc4 were not used when initializing XLMRobertaModel: ['base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.13.attention.output.dense.weight', 'base_model.encoder.layer.12.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.20.attention.self.value.bias', 'base_model.encoder.layer.10.attention.output.LayerNorm.weight', 'base_model.encoder.layer.3.attention.output.dense.bias', 'base_model.encoder.layer.16.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.11.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.0.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.10.attention.self.key.weight', 'base_model.encoder.layer.6.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.17.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.9.attention.self.query.weight', 'base_model.encoder.layer.11.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.12.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.3.intermediate.dense.bias', 'base_model.encoder.layer.6.attention.output.dense.weight', 'base_model.encoder.layer.2.output.dense.bias', 'base_model.encoder.layer.12.attention.self.key.weight', 'base_model.encoder.layer.7.intermediate.dense.bias', 'base_model.encoder.layer.17.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.18.attention.self.value.bias', 'base_model.encoder.layer.21.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.4.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.7.intermediate.dense.weight', 'base_model.encoder.layer.2.output.dense.weight', 'base_model.encoder.layer.7.output.dense.bias', 'base_model.encoder.layer.10.output.dense.weight', 'base_model.encoder.layer.23.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.19.attention.self.query.weight', 'base_model.encoder.layer.5.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.20.attention.self.key.weight', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.6.attention.self.query.bias', 'base_model.encoder.layer.14.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.13.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.7.attention.self.query.weight', 'base_model.encoder.layer.11.attention.output.dense.weight', 'base_model.encoder.layer.9.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.14.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.18.attention.self.query.bias', 'base_model.encoder.layer.18.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.20.intermediate.dense.weight', 'base_model.encoder.layer.16.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.14.output.dense.bias', 'base_model.encoder.layer.4.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.17.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.8.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.11.intermediate.dense.weight', 'base_model.encoder.layer.5.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.8.attention.output.dense.bias', 'base_model.encoder.layer.8.attention.self.key.weight', 'base_model.encoder.layer.13.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.6.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.22.attention.output.dense.weight', 'base_model.encoder.layer.1.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.12.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.21.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.3.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.10.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.17.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.20.output.LayerNorm.weight', 'base_model.encoder.layer.10.attention.self.value.weight', 'base_model.encoder.layer.14.attention.self.key.weight', 'base_model.encoder.layer.23.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.20.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.0.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.3.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.22.attention.self.value.bias', 'base_model.encoder.layer.12.intermediate.dense.bias', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.10.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.12.attention.output.LayerNorm.weight', 'base_model.encoder.layer.4.output.dense.weight', 'base_model.encoder.layer.19.intermediate.dense.weight', 'base_model.encoder.layer.16.output.adapters.ep.adapter_up.bias', 'base_model.embeddings.LayerNorm.bias', 'base_model.encoder.layer.3.output.LayerNorm.weight', 'base_model.encoder.layer.18.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.6.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.10.attention.self.query.weight', 'base_model.encoder.layer.5.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.10.intermediate.dense.bias', 'base_model.encoder.layer.16.attention.output.dense.weight', 'base_model.encoder.layer.3.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.5.attention.output.LayerNorm.bias', 'base_model.encoder.layer.15.attention.self.key.weight', 'base_model.encoder.layer.0.attention.self.key.weight', 'base_model.encoder.layer.7.attention.output.dense.weight', 'base_model.encoder.layer.9.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.18.attention.self.key.weight', 'base_model.encoder.layer.21.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.14.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.11.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.0.output.LayerNorm.weight', 'base_model.encoder.layer.10.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.8.attention.self.query.weight', 'base_model.encoder.layer.13.attention.self.query.weight', 'base_model.encoder.layer.15.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.4.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.1.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.23.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.1.attention.output.LayerNorm.weight', 'base_model.encoder.layer.6.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.18.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.22.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.2.attention.self.query.bias', 'base_model.encoder.layer.7.output.LayerNorm.bias', 'base_model.encoder.layer.6.attention.output.dense.bias', 'base_model.encoder.layer.18.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.16.attention.self.key.weight', 'base_model.encoder.layer.21.output.dense.weight', 'base_model.encoder.layer.8.intermediate.dense.bias', 'base_model.encoder.layer.5.intermediate.dense.weight', 'base_model.encoder.layer.22.attention.self.value.weight', 'base_model.encoder.layer.17.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.15.output.LayerNorm.weight', 'base_model.encoder.layer.21.attention.self.value.weight', 'base_model.encoder.layer.21.intermediate.dense.weight', 'base_model.encoder.layer.17.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.10.attention.self.key.bias', 'base_model.encoder.layer.9.attention.output.dense.bias', 'base_model.encoder.layer.22.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.4.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.22.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.6.attention.output.LayerNorm.weight', 'base_model.encoder.layer.8.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.13.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.18.attention.self.value.weight', 'base_model.encoder.layer.13.attention.output.LayerNorm.weight', 'base_model.encoder.layer.4.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.11.attention.self.key.weight', 'base_model.encoder.layer.21.attention.output.LayerNorm.weight', 'base_model.encoder.layer.6.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.3.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.16.output.LayerNorm.weight', 'base_model.encoder.layer.1.attention.output.dense.weight', 'base_model.encoder.layer.1.output.dense.weight', 'base_model.encoder.layer.11.attention.self.query.bias', 'base_model.encoder.layer.3.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.7.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.19.attention.self.key.weight', 'base_model.encoder.layer.21.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.5.output.dense.weight', 'base_model.encoder.layer.22.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.9.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.15.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.17.attention.output.dense.weight', 'base_model.encoder.layer.15.output.dense.weight', 'base_model.encoder.layer.23.attention.output.LayerNorm.weight', 'base_model.encoder.layer.23.attention.self.key.weight', 'base_model.encoder.layer.23.attention.output.LayerNorm.bias', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.7.output.LayerNorm.weight', 'base_model.encoder.layer.9.attention.output.LayerNorm.bias', 'base_model.encoder.layer.8.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.20.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.12.output.LayerNorm.bias', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.9.intermediate.dense.weight', 'base_model.encoder.layer.10.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.3.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.14.attention.self.query.weight', 'base_model.encoder.layer.20.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.16.output.dense.weight', 'base_model.encoder.layer.22.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.21.output.dense.bias', 'base_model.encoder.layer.21.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.18.attention.output.LayerNorm.bias', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.17.output.dense.weight', 'base_model.encoder.layer.12.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.15.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.2.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.10.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.22.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.3.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.14.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.0.intermediate.dense.weight', 'base_model.encoder.layer.19.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.17.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.16.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.13.intermediate.dense.weight', 'base_model.encoder.layer.12.attention.output.dense.weight', 'base_model.encoder.layer.0.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.13.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.21.attention.output.dense.bias', 'base_model.encoder.layer.17.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.20.attention.output.dense.bias', 'base_model.encoder.layer.19.output.LayerNorm.weight', 'base_model.encoder.layer.11.output.LayerNorm.weight', 'base_model.encoder.layer.1.attention.self.value.weight', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.8.output.LayerNorm.bias', 'base_model.encoder.layer.0.attention.self.key.bias', 'base_model.encoder.layer.14.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.13.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.15.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.14.attention.output.dense.weight', 'base_model.encoder.layer.16.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.13.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.20.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.6.output.dense.weight', 'base_model.encoder.layer.5.attention.self.value.bias', 'base_model.encoder.layer.21.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.18.output.LayerNorm.bias', 'base_model.encoder.layer.14.attention.self.value.bias', 'base_model.encoder.layer.18.attention.output.dense.weight', 'base_model.encoder.layer.9.output.LayerNorm.bias', 'base_model.encoder.layer.2.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.10.output.dense.bias', 'base_model.encoder.layer.11.output.dense.bias', 'base_model.encoder.layer.11.attention.self.value.bias', 'base_model.encoder.layer.18.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.13.intermediate.dense.bias', 'base_model.encoder.layer.16.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.19.attention.self.query.bias', 'base_model.encoder.layer.11.intermediate.dense.bias', 'base_model.encoder.layer.11.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.3.attention.output.LayerNorm.weight', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.12.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.2.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.19.output.LayerNorm.bias', 'base_model.encoder.layer.15.attention.self.value.bias', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.21.attention.self.key.bias', 'base_model.encoder.layer.7.attention.self.key.bias', 'base_model.encoder.layer.17.output.dense.bias', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.0.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.12.attention.self.query.bias', 'base_model.encoder.layer.1.output.LayerNorm.weight', 'base_model.encoder.layer.19.attention.output.LayerNorm.weight', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.4.attention.self.key.weight', 'base_model.encoder.layer.18.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.22.intermediate.dense.weight', 'base_model.encoder.layer.11.attention.output.LayerNorm.weight', 'base_model.encoder.layer.17.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.22.output.dense.weight', 'base_model.encoder.layer.22.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.6.attention.self.key.bias', 'base_model.encoder.layer.0.output.dense.bias', 'base_model.encoder.layer.12.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.6.attention.self.value.bias', 'base_model.encoder.layer.1.intermediate.dense.bias', 'base_model.encoder.layer.19.intermediate.dense.bias', 'base_model.encoder.layer.22.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.7.attention.output.LayerNorm.weight', 'base_model.encoder.layer.12.output.dense.bias', 'base_model.encoder.layer.0.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.12.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.9.intermediate.dense.bias', 'base_model.encoder.layer.19.attention.self.key.bias', 'base_model.encoder.layer.14.attention.output.dense.bias', 'base_model.encoder.layer.3.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.8.output.dense.weight', 'base_model.encoder.layer.19.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.21.attention.self.query.bias', 'base_model.encoder.layer.9.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.14.intermediate.dense.bias', 'base_model.encoder.layer.5.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.8.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.22.attention.self.key.bias', 'base_model.encoder.layer.21.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.3.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.10.output.LayerNorm.bias', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.15.attention.self.value.weight', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.18.intermediate.dense.weight', 'base_model.encoder.layer.16.attention.output.LayerNorm.bias', 'base_model.encoder.layer.2.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.6.output.dense.bias', 'base_model.encoder.layer.1.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.17.intermediate.dense.weight', 'base_model.encoder.layer.4.attention.self.value.weight', 'base_model.encoder.layer.9.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.22.attention.self.key.weight', 'base_model.encoder.layer.2.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.6.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.8.attention.output.LayerNorm.bias', 'base_model.encoder.layer.12.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.20.attention.output.dense.weight', 'base_model.encoder.layer.1.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.17.attention.self.key.bias', 'base_model.encoder.layer.6.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.15.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.23.attention.self.value.weight', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.8.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.8.output.LayerNorm.weight', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.9.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.17.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.18.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.4.output.LayerNorm.weight', 'base_model.encoder.layer.2.attention.self.query.weight', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.11.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.7.attention.self.value.weight', 'base_model.encoder.layer.15.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.20.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.11.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.4.intermediate.dense.weight', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.20.output.dense.bias', 'base_model.encoder.layer.9.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.1.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.1.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.11.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.13.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.14.attention.self.query.bias', 'base_model.embeddings.position_ids', 'base_model.encoder.layer.5.output.LayerNorm.bias', 'base_model.encoder.layer.20.output.dense.weight', 'base_model.encoder.layer.19.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.8.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.10.attention.self.value.bias', 'base_model.encoder.layer.16.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.21.attention.output.LayerNorm.bias', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.2.attention.output.LayerNorm.weight', 'base_model.encoder.layer.21.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.5.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.1.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.11.attention.self.key.bias', 'base_model.encoder.layer.9.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.19.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.14.intermediate.dense.weight', 'base_model.encoder.layer.20.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.18.attention.self.query.weight', 'base_model.encoder.layer.7.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.11.attention.self.query.weight', 'base_model.encoder.layer.12.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.21.attention.output.dense.weight', 'base_model.encoder.layer.15.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.23.output.dense.weight', 'base_model.encoder.layer.21.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.2.intermediate.dense.bias', 'qa_outputs.weight', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.20.attention.self.query.weight', 'base_model.encoder.layer.13.output.LayerNorm.bias', 'base_model.encoder.layer.5.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.13.attention.self.value.weight', 'base_model.encoder.layer.6.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.8.attention.self.value.weight', 'base_model.encoder.layer.13.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.1.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.22.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.5.intermediate.dense.bias', 'base_model.encoder.layer.4.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.12.attention.self.value.weight', 'base_model.encoder.layer.22.attention.self.query.bias', 'base_model.encoder.layer.8.attention.output.LayerNorm.weight', 'base_model.encoder.layer.4.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.13.attention.self.key.weight', 'base_model.encoder.layer.2.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.16.attention.self.value.weight', 'base_model.encoder.layer.17.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.6.attention.self.key.weight', 'base_model.encoder.layer.16.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.23.attention.output.dense.weight', 'base_model.encoder.layer.16.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.13.attention.self.value.bias', 'qa_outputs.bias', 'base_model.encoder.layer.1.attention.self.key.bias', 'base_model.encoder.layer.15.attention.self.query.weight', 'base_model.encoder.layer.11.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.5.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.2.attention.self.value.bias', 'base_model.encoder.layer.4.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.8.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.3.attention.self.key.weight', 'base_model.encoder.layer.6.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.12.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.4.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.12.attention.self.value.bias', 'base_model.encoder.layer.22.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.2.attention.output.dense.weight', 'base_model.encoder.layer.5.attention.self.key.bias', 'base_model.encoder.layer.9.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.7.output.dense.weight', 'base_model.encoder.layer.9.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.14.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.2.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.15.intermediate.dense.bias', 'base_model.encoder.layer.14.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.4.attention.output.dense.bias', 'base_model.encoder.layer.11.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.21.intermediate.dense.bias', 'base_model.encoder.layer.10.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.15.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.19.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.14.attention.self.value.weight', 'base_model.encoder.layer.23.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.13.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.5.attention.output.dense.weight', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.6.output.LayerNorm.bias', 'base_model.encoder.layer.6.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.11.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.16.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.20.attention.output.LayerNorm.weight', 'base_model.encoder.layer.21.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.22.output.LayerNorm.weight', 'base_model.encoder.layer.14.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.20.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.7.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.4.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.17.output.LayerNorm.weight', 'base_model.encoder.layer.3.output.dense.weight', 'base_model.encoder.layer.14.attention.output.LayerNorm.bias', 'base_model.encoder.layer.17.attention.self.query.bias', 'base_model.encoder.layer.5.attention.output.dense.bias', 'base_model.encoder.layer.8.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.9.attention.self.key.weight', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.pooler.dense.weight', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.7.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.16.intermediate.dense.weight', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.8.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.4.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.12.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.4.attention.self.key.bias', 'base_model.encoder.layer.1.output.dense.bias', 'base_model.encoder.layer.3.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.5.attention.output.LayerNorm.weight', 'base_model.encoder.layer.19.attention.output.dense.weight', 'base_model.encoder.layer.15.output.LayerNorm.bias', 'base_model.embeddings.word_embeddings.weight', 'base_model.encoder.layer.2.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.2.attention.self.key.bias', 'base_model.encoder.layer.3.output.dense.bias', 'base_model.encoder.layer.4.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.6.intermediate.dense.bias', 'base_model.encoder.layer.7.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.9.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.5.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.0.attention.self.query.weight', 'base_model.encoder.layer.7.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.8.output.dense.bias', 'base_model.encoder.layer.3.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.12.attention.output.LayerNorm.bias', 'base_model.encoder.layer.20.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.15.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.11.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.1.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.22.output.dense.bias', 'base_model.encoder.layer.21.attention.self.value.bias', 'base_model.encoder.layer.0.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.3.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.12.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.18.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.20.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.23.output.LayerNorm.weight', 'base_model.encoder.layer.10.intermediate.dense.weight', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.9.attention.output.dense.weight', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.3.attention.self.query.weight', 'base_model.encoder.layer.9.attention.self.key.bias', 'base_model.encoder.layer.10.attention.output.LayerNorm.bias', 'base_model.encoder.layer.1.intermediate.dense.weight', 'base_model.encoder.layer.6.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.19.output.dense.bias', 'base_model.encoder.layer.15.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.3.attention.self.value.bias', 'base_model.encoder.layer.16.attention.self.key.bias', 'base_model.encoder.layer.0.output.LayerNorm.bias', 'base_model.encoder.layer.12.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.15.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.17.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.16.attention.self.value.bias', 'base_model.encoder.layer.23.attention.self.value.bias', 'base_model.encoder.layer.21.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.10.attention.output.dense.weight', 'base_model.encoder.layer.0.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.1.attention.self.value.bias', 'base_model.encoder.layer.7.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.16.attention.output.dense.bias', 'base_model.encoder.layer.9.attention.output.LayerNorm.weight', 'base_model.encoder.layer.12.output.dense.weight', 'base_model.encoder.layer.18.attention.output.LayerNorm.weight', 'base_model.encoder.layer.10.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.12.attention.output.dense.bias', 'base_model.encoder.layer.16.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.21.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.14.attention.self.key.bias', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.12.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.17.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.9.output.LayerNorm.weight', 'base_model.encoder.layer.18.attention.output.dense.bias', 'base_model.encoder.layer.14.attention.output.LayerNorm.weight', 'base_model.encoder.layer.8.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.0.attention.self.value.weight', 'base_model.encoder.layer.17.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.13.attention.output.dense.bias', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.20.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.21.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.4.attention.output.LayerNorm.weight', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.16.attention.self.query.bias', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.4.attention.self.query.bias', 'base_model.encoder.layer.14.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.2.attention.output.dense.bias', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.18.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.3.attention.self.query.bias', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.9.attention.self.value.weight', 'base_model.encoder.layer.19.attention.output.dense.bias', 'base_model.encoder.layer.0.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.3.output.adapters.ep.adapter_down.0.bias', 'base_model.embeddings.token_type_embeddings.weight', 'base_model.encoder.layer.2.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.10.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.6.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.13.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.15.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.0.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.3.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.15.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.16.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.23.attention.output.dense.bias', 'base_model.encoder.layer.4.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.22.output.LayerNorm.bias', 'base_model.encoder.layer.3.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.13.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.5.attention.self.value.weight', 'base_model.encoder.layer.15.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.16.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.23.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.19.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.23.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.23.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.1.attention.output.dense.bias', 'base_model.encoder.layer.20.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.4.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.22.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.11.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.6.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.14.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.14.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.7.attention.output.dense.bias', 'base_model.encoder.layer.19.output.dense.weight', 'base_model.encoder.layer.13.attention.self.key.bias', 'base_model.encoder.layer.22.attention.self.query.weight', 'base_model.encoder.layer.6.attention.output.LayerNorm.bias', 'base_model.encoder.layer.21.attention.self.key.weight', 'base_model.encoder.layer.2.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.18.intermediate.dense.bias', 'base_model.encoder.layer.23.attention.self.key.bias', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.1.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.6.output.LayerNorm.weight', 'base_model.encoder.layer.5.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.22.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.7.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.16.intermediate.dense.bias', 'base_model.encoder.layer.19.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.13.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.18.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.8.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.17.attention.self.query.weight', 'base_model.encoder.layer.13.output.dense.bias', 'base_model.encoder.layer.19.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.16.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.5.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.0.output.dense.weight', 'base_model.encoder.layer.23.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.1.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.11.attention.output.dense.bias', 'base_model.encoder.layer.12.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.20.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.9.attention.self.query.bias', 'base_model.encoder.layer.8.attention.self.value.bias', 'base_model.encoder.layer.6.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.23.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.10.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.1.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.9.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.16.attention.output.LayerNorm.weight', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.10.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.21.output.LayerNorm.bias', 'base_model.encoder.layer.22.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.4.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.9.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.9.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.17.intermediate.dense.bias', 'base_model.encoder.layer.4.attention.output.LayerNorm.bias', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.23.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.22.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.19.attention.self.value.bias', 'base_model.encoder.layer.21.attention.self.query.weight', 'base_model.encoder.layer.7.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.14.output.dense.weight', 'base_model.encoder.layer.11.output.LayerNorm.bias', 'base_model.encoder.layer.4.attention.self.query.weight', 'base_model.encoder.layer.21.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.2.intermediate.dense.weight', 'base_model.encoder.layer.2.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.9.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.2.attention.self.value.weight', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.23.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.18.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.1.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.5.attention.self.query.bias', 'base_model.encoder.layer.15.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.7.attention.self.key.weight', 'base_model.encoder.layer.2.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.21.output.LayerNorm.weight', 'base_model.encoder.layer.4.intermediate.dense.bias', 'base_model.encoder.layer.2.attention.output.LayerNorm.bias', 'base_model.encoder.layer.2.attention.self.key.weight', 'base_model.encoder.layer.13.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.21.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.7.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.5.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.6.attention.self.value.weight', 'base_model.encoder.layer.0.attention.self.query.bias', 'base_model.encoder.layer.15.attention.self.key.bias', 'base_model.encoder.layer.23.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.14.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.10.attention.output.dense.bias', 'base_model.encoder.layer.10.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.18.output.LayerNorm.weight', 'base_model.encoder.layer.7.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.0.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.5.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.10.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.18.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.23.intermediate.dense.weight', 'base_model.encoder.layer.23.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.5.attention.self.query.weight', 'base_model.encoder.layer.17.attention.output.LayerNorm.bias', 'base_model.encoder.layer.14.output.LayerNorm.bias', 'base_model.encoder.layer.16.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.12.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.5.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.11.attention.output.LayerNorm.bias', 'base_model.encoder.layer.7.output.adapters.es.adapter_down.0.weight', 'base_model.pooler.dense.bias', 'base_model.encoder.layer.15.output.dense.bias', 'base_model.encoder.layer.18.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.16.attention.self.query.weight', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.0.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.0.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.7.attention.self.value.bias', 'base_model.encoder.layer.2.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.8.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.0.attention.output.LayerNorm.weight', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.0.attention.output.dense.bias', 'base_model.encoder.layer.2.output.LayerNorm.bias', 'base_model.encoder.layer.4.output.LayerNorm.bias', 'base_model.encoder.layer.19.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.20.attention.self.value.weight', 'base_model.encoder.layer.20.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.1.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.20.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.11.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.7.attention.output.LayerNorm.bias', 'base_model.encoder.layer.8.intermediate.dense.weight', 'base_model.encoder.layer.9.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.14.output.adapters.es.adapter_up.weight', 'base_model.embeddings.LayerNorm.weight', 'base_model.encoder.layer.2.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.19.attention.output.LayerNorm.bias', 'base_model.encoder.layer.9.output.dense.weight', 'base_model.encoder.layer.0.intermediate.dense.bias', 'base_model.encoder.layer.4.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.5.output.dense.bias', 'base_model.encoder.layer.20.attention.output.LayerNorm.bias', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.6.attention.self.query.weight', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.13.output.dense.weight', 'base_model.encoder.layer.8.attention.output.dense.weight', 'base_model.encoder.layer.9.output.dense.bias', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.11.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.16.output.dense.bias', 'base_model.encoder.layer.18.attention.self.key.bias', 'base_model.encoder.layer.23.attention.self.query.weight', 'base_model.encoder.layer.8.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.3.attention.self.value.weight', 'base_model.encoder.layer.3.attention.output.LayerNorm.bias', 'base_model.encoder.layer.13.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.3.output.LayerNorm.bias', 'base_model.encoder.layer.14.output.LayerNorm.weight', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.17.attention.output.dense.bias', 'base_model.encoder.layer.18.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.19.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.7.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.22.intermediate.dense.bias', 'base_model.encoder.layer.3.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.10.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.20.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.14.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.12.intermediate.dense.weight', 'base_model.encoder.layer.13.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.11.output.dense.weight', 'base_model.encoder.layer.17.attention.output.LayerNorm.weight', 'base_model.encoder.layer.18.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.4.attention.self.value.bias', 'base_model.encoder.layer.12.attention.self.key.bias', 'base_model.encoder.layer.8.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.7.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.15.attention.output.dense.weight', 'base_model.encoder.layer.23.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.20.output.LayerNorm.bias', 'base_model.encoder.layer.12.attention.self.query.weight', 'base_model.encoder.layer.5.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.22.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.13.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.15.attention.output.LayerNorm.weight', 'base_model.encoder.layer.17.attention.self.value.bias', 'base_model.encoder.layer.22.attention.output.dense.bias', 'base_model.encoder.layer.2.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.18.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.19.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.2.output.LayerNorm.weight', 'base_model.encoder.layer.8.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.11.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.21.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.1.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.6.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.0.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.16.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.20.attention.self.key.bias', 'base_model.encoder.layer.11.attention.self.value.weight', 'base_model.encoder.layer.0.attention.output.LayerNorm.bias', 'base_model.encoder.layer.14.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.7.attention.self.query.bias', 'base_model.encoder.layer.5.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.10.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.13.attention.self.query.bias', 'base_model.encoder.layer.19.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.15.intermediate.dense.weight', 'base_model.encoder.layer.4.output.dense.bias', 'base_model.encoder.layer.5.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.12.output.LayerNorm.weight', 'base_model.encoder.layer.19.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.19.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.20.intermediate.dense.bias', 'base_model.embeddings.position_embeddings.weight', 'base_model.encoder.layer.15.attention.output.dense.bias', 'base_model.encoder.layer.23.attention.self.query.bias', 'base_model.encoder.layer.16.output.LayerNorm.bias', 'base_model.encoder.layer.20.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.1.output.LayerNorm.bias', 'base_model.encoder.layer.5.output.LayerNorm.weight', 'base_model.encoder.layer.0.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.3.intermediate.dense.weight', 'base_model.encoder.layer.6.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.18.output.dense.weight', 'base_model.encoder.layer.17.attention.self.value.weight', 'base_model.encoder.layer.10.output.LayerNorm.weight', 'base_model.encoder.layer.1.attention.self.key.weight', 'base_model.encoder.layer.1.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.5.attention.self.key.weight', 'base_model.encoder.layer.9.attention.self.value.bias', 'base_model.encoder.layer.10.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.17.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.23.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.0.attention.self.value.bias', 'base_model.encoder.layer.7.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.13.output.LayerNorm.weight', 'base_model.encoder.layer.23.intermediate.dense.bias', 'base_model.encoder.layer.6.intermediate.dense.weight', 'base_model.encoder.layer.1.attention.self.query.bias', 'base_model.encoder.layer.18.output.dense.bias', 'base_model.encoder.layer.0.attention.output.dense.weight', 'base_model.encoder.layer.0.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.8.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.15.attention.self.query.bias', 'base_model.encoder.layer.15.attention.output.LayerNorm.bias', 'base_model.encoder.layer.22.attention.output.LayerNorm.weight', 'base_model.encoder.layer.17.output.LayerNorm.bias', 'base_model.encoder.layer.23.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.3.attention.self.key.bias', 'base_model.encoder.layer.19.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.11.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.17.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.22.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.1.attention.output.LayerNorm.bias', 'base_model.encoder.layer.2.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.3.attention.output.dense.weight', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.0.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.22.attention.output.LayerNorm.bias', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.10.attention.self.query.bias', 'base_model.encoder.layer.14.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.19.attention.self.value.weight', 'base_model.encoder.layer.19.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.4.attention.output.dense.weight', 'base_model.encoder.layer.8.attention.self.query.bias', 'base_model.encoder.layer.10.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.17.attention.self.key.weight', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.7.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.13.attention.output.LayerNorm.bias', 'base_model.encoder.layer.23.output.LayerNorm.bias', 'base_model.encoder.layer.15.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.1.attention.self.query.weight', 'base_model.encoder.layer.20.attention.self.query.bias', 'base_model.encoder.layer.8.attention.self.key.bias', 'base_model.encoder.layer.23.output.dense.bias']
- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of XLMRobertaModel were not initialized from the model checkpoint at /cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//squad/xlm-KG_LR8e-6_EPOCH2.0_maxlen384_batchsize4_gradacc4 and are newly initialized: ['encoder.layer.15.attention.output.LayerNorm.bias', 'encoder.layer.2.attention.output.LayerNorm.weight', 'encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.layer.9.attention.self.value.weight', 'encoder.layer.5.output.dense.bias', 'encoder.layer.10.output.LayerNorm.bias', 'encoder.layer.13.output.LayerNorm.weight', 'pooler.dense.bias', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.1.attention.output.dense.bias', 'encoder.layer.20.attention.output.LayerNorm.weight', 'encoder.layer.16.attention.self.key.weight', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.15.intermediate.dense.weight', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.20.attention.output.LayerNorm.bias', 'encoder.layer.8.output.dense.bias', 'encoder.layer.0.attention.output.dense.bias', 'encoder.layer.12.attention.self.value.weight', 'encoder.layer.18.attention.self.value.bias', 'encoder.layer.23.attention.self.key.weight', 'encoder.layer.16.attention.output.LayerNorm.bias', 'encoder.layer.12.attention.output.LayerNorm.weight', 'encoder.layer.20.attention.self.key.weight', 'encoder.layer.14.attention.self.query.bias', 'encoder.layer.6.attention.output.LayerNorm.weight', 'encoder.layer.14.output.dense.bias', 'encoder.layer.0.attention.self.key.weight', 'encoder.layer.4.attention.output.dense.bias', 'encoder.layer.2.attention.self.key.bias', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.11.attention.self.key.weight', 'encoder.layer.15.attention.output.LayerNorm.weight', 'encoder.layer.17.attention.output.dense.bias', 'encoder.layer.22.attention.self.key.weight', 'encoder.layer.3.attention.self.query.bias', 'encoder.layer.7.attention.self.key.bias', 'encoder.layer.21.attention.self.key.weight', 'encoder.layer.0.attention.self.query.weight', 'encoder.layer.1.attention.self.value.weight', 'encoder.layer.23.attention.output.dense.bias', 'encoder.layer.5.attention.self.value.bias', 'encoder.layer.16.attention.self.query.weight', 'encoder.layer.19.attention.self.value.bias', 'encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.11.attention.self.query.weight', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.14.intermediate.dense.weight', 'encoder.layer.14.output.LayerNorm.weight', 'encoder.layer.21.attention.output.LayerNorm.bias', 'encoder.layer.22.attention.self.query.weight', 'encoder.layer.18.attention.self.key.bias', 'encoder.layer.14.attention.self.key.bias', 'encoder.layer.22.attention.output.dense.bias', 'encoder.layer.5.attention.output.dense.bias', 'encoder.layer.18.output.LayerNorm.weight', 'pooler.dense.weight', 'encoder.layer.10.attention.self.value.bias', 'encoder.layer.15.intermediate.dense.bias', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.4.attention.self.query.bias', 'encoder.layer.20.intermediate.dense.weight', 'encoder.layer.2.attention.self.value.bias', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.11.attention.self.value.weight', 'encoder.layer.16.attention.output.LayerNorm.weight', 'encoder.layer.2.attention.self.value.weight', 'encoder.layer.8.output.LayerNorm.weight', 'encoder.layer.13.output.LayerNorm.bias', 'encoder.layer.14.attention.output.LayerNorm.bias', 'encoder.layer.13.attention.output.dense.weight', 'encoder.layer.8.attention.self.query.weight', 'encoder.layer.23.attention.self.query.weight', 'encoder.layer.19.attention.self.key.weight', 'encoder.layer.8.attention.output.LayerNorm.bias', 'encoder.layer.15.output.LayerNorm.weight', 'encoder.layer.20.attention.self.key.bias', 'encoder.layer.12.attention.output.LayerNorm.bias', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.18.attention.output.dense.weight', 'encoder.layer.2.attention.self.query.bias', 'encoder.layer.10.output.LayerNorm.weight', 'encoder.layer.22.attention.self.query.bias', 'encoder.layer.20.intermediate.dense.bias', 'encoder.layer.14.attention.output.dense.weight', 'encoder.layer.23.output.dense.bias', 'encoder.layer.12.output.LayerNorm.weight', 'encoder.layer.19.attention.self.value.weight', 'encoder.layer.19.output.dense.bias', 'encoder.layer.15.attention.output.dense.bias', 'encoder.layer.17.attention.self.query.bias', 'encoder.layer.23.output.LayerNorm.weight', 'encoder.layer.0.output.dense.weight', 'encoder.layer.11.attention.self.value.bias', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.14.attention.output.LayerNorm.weight', 'encoder.layer.16.attention.output.dense.bias', 'encoder.layer.10.attention.self.key.bias', 'encoder.layer.22.output.LayerNorm.weight', 'encoder.layer.21.attention.self.query.bias', 'encoder.layer.8.attention.self.query.bias', 'encoder.layer.4.output.dense.weight', 'encoder.layer.22.intermediate.dense.weight', 'encoder.layer.21.output.LayerNorm.bias', 'encoder.layer.21.output.dense.weight', 'encoder.layer.20.attention.self.query.bias', 'encoder.layer.9.output.dense.weight', 'encoder.layer.21.attention.self.value.weight', 'encoder.layer.20.output.LayerNorm.bias', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.12.attention.self.query.bias', 'encoder.layer.18.attention.output.LayerNorm.bias', 'encoder.layer.0.attention.self.query.bias', 'encoder.layer.16.intermediate.dense.weight', 'encoder.layer.4.attention.self.value.bias', 'encoder.layer.17.intermediate.dense.weight', 'encoder.layer.8.attention.self.key.bias', 'encoder.layer.20.attention.self.query.weight', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.18.attention.output.LayerNorm.weight', 'encoder.layer.4.attention.output.dense.weight', 'encoder.layer.12.attention.output.dense.weight', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.17.attention.self.query.weight', 'encoder.layer.8.attention.output.dense.weight', 'embeddings.LayerNorm.weight', 'encoder.layer.7.attention.self.value.bias', 'encoder.layer.1.attention.self.key.bias', 'encoder.layer.9.attention.self.query.weight', 'encoder.layer.13.attention.output.LayerNorm.bias', 'encoder.layer.11.output.LayerNorm.bias', 'encoder.layer.17.output.dense.bias', 'encoder.layer.16.attention.self.value.weight', 'encoder.layer.21.intermediate.dense.weight', 'encoder.layer.15.output.dense.weight', 'encoder.layer.10.attention.output.dense.bias', 'encoder.layer.12.output.LayerNorm.bias', 'encoder.layer.19.intermediate.dense.bias', 'encoder.layer.1.attention.output.LayerNorm.weight', 'encoder.layer.12.attention.self.value.bias', 'encoder.layer.9.attention.output.LayerNorm.weight', 'encoder.layer.14.intermediate.dense.bias', 'encoder.layer.23.output.LayerNorm.bias', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.3.attention.output.LayerNorm.weight', 'embeddings.word_embeddings.weight', 'encoder.layer.7.output.dense.weight', 'encoder.layer.13.attention.self.query.weight', 'encoder.layer.18.attention.self.query.weight', 'embeddings.token_type_embeddings.weight', 'encoder.layer.22.intermediate.dense.bias', 'encoder.layer.10.attention.output.dense.weight', 'encoder.layer.17.attention.output.dense.weight', 'encoder.layer.3.output.dense.weight', 'encoder.layer.18.attention.self.value.weight', 'encoder.layer.1.attention.self.query.bias', 'encoder.layer.8.attention.output.LayerNorm.weight', 'encoder.layer.1.output.dense.weight', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.23.attention.output.dense.weight', 'encoder.layer.13.attention.output.LayerNorm.weight', 'encoder.layer.7.output.dense.bias', 'encoder.layer.7.attention.output.dense.bias', 'encoder.layer.20.attention.output.dense.weight', 'encoder.layer.6.output.dense.bias', 'encoder.layer.12.intermediate.dense.weight', 'encoder.layer.16.output.LayerNorm.bias', 'encoder.layer.9.attention.output.dense.weight', 'encoder.layer.8.attention.self.key.weight', 'encoder.layer.8.output.LayerNorm.bias', 'encoder.layer.10.output.dense.weight', 'encoder.layer.18.attention.self.query.bias', 'encoder.layer.22.output.LayerNorm.bias', 'encoder.layer.22.attention.output.LayerNorm.bias', 'encoder.layer.8.output.dense.weight', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.19.output.LayerNorm.weight', 'encoder.layer.22.attention.self.key.bias', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.5.attention.self.key.bias', 'encoder.layer.16.intermediate.dense.bias', 'encoder.layer.4.attention.self.key.bias', 'encoder.layer.5.output.LayerNorm.bias', 'encoder.layer.18.attention.output.dense.bias', 'encoder.layer.6.attention.output.LayerNorm.bias', 'encoder.layer.13.attention.output.dense.bias', 'encoder.layer.13.attention.self.value.weight', 'encoder.layer.12.attention.self.query.weight', 'encoder.layer.10.attention.self.value.weight', 'encoder.layer.13.intermediate.dense.weight', 'encoder.layer.13.output.dense.bias', 'encoder.layer.8.attention.self.value.bias', 'encoder.layer.5.attention.self.key.weight', 'encoder.layer.7.attention.output.dense.weight', 'encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.layer.14.attention.self.key.weight', 'encoder.layer.19.intermediate.dense.weight', 'embeddings.LayerNorm.bias', 'encoder.layer.9.attention.output.LayerNorm.bias', 'encoder.layer.8.attention.self.value.weight', 'encoder.layer.17.attention.self.key.bias', 'encoder.layer.17.attention.output.LayerNorm.weight', 'encoder.layer.22.output.dense.weight', 'encoder.layer.11.attention.output.dense.bias', 'encoder.layer.18.intermediate.dense.bias', 'encoder.layer.23.output.dense.weight', 'encoder.layer.6.attention.self.value.weight', 'encoder.layer.1.attention.self.query.weight', 'encoder.layer.9.attention.self.query.bias', 'encoder.layer.6.attention.self.value.bias', 'encoder.layer.14.attention.self.value.weight', 'encoder.layer.17.attention.self.value.weight', 'encoder.layer.3.attention.self.query.weight', 'encoder.layer.4.output.dense.bias', 'encoder.layer.11.output.dense.bias', 'encoder.layer.6.attention.self.query.weight', 'encoder.layer.14.output.LayerNorm.bias', 'encoder.layer.2.attention.output.LayerNorm.bias', 'encoder.layer.2.attention.self.key.weight', 'encoder.layer.2.output.dense.bias', 'encoder.layer.16.output.dense.bias', 'encoder.layer.5.attention.self.query.bias', 'encoder.layer.3.attention.output.dense.bias', 'embeddings.position_embeddings.weight', 'encoder.layer.22.attention.output.LayerNorm.weight', 'encoder.layer.14.attention.self.value.bias', 'encoder.layer.7.attention.self.value.weight', 'encoder.layer.4.attention.output.LayerNorm.bias', 'encoder.layer.6.attention.self.query.bias', 'encoder.layer.20.attention.self.value.weight', 'encoder.layer.5.attention.output.LayerNorm.weight', 'encoder.layer.10.attention.self.query.bias', 'encoder.layer.11.attention.output.dense.weight', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.22.attention.self.value.bias', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.16.output.LayerNorm.weight', 'encoder.layer.11.attention.output.LayerNorm.weight', 'encoder.layer.19.attention.self.key.bias', 'encoder.layer.7.attention.self.key.weight', 'encoder.layer.8.attention.output.dense.bias', 'encoder.layer.10.output.dense.bias', 'encoder.layer.21.attention.output.dense.bias', 'encoder.layer.14.attention.output.dense.bias', 'encoder.layer.11.attention.self.query.bias', 'encoder.layer.12.attention.self.key.bias', 'encoder.layer.18.output.dense.bias', 'encoder.layer.19.output.dense.weight', 'encoder.layer.4.attention.output.LayerNorm.weight', 'encoder.layer.15.output.dense.bias', 'encoder.layer.23.attention.output.LayerNorm.weight', 'encoder.layer.13.attention.self.query.bias', 'encoder.layer.12.output.dense.bias', 'encoder.layer.18.intermediate.dense.weight', 'encoder.layer.12.output.dense.weight', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.5.attention.self.value.weight', 'encoder.layer.2.attention.output.dense.bias', 'encoder.layer.13.attention.self.key.bias', 'encoder.layer.15.attention.self.key.bias', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.10.attention.self.query.weight', 'encoder.layer.20.output.dense.bias', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.20.attention.output.dense.bias', 'encoder.layer.9.attention.self.key.weight', 'encoder.layer.6.attention.output.dense.bias', 'encoder.layer.0.attention.self.value.bias', 'encoder.layer.5.attention.output.dense.weight', 'encoder.layer.21.intermediate.dense.bias', 'encoder.layer.0.attention.self.value.weight', 'encoder.layer.0.output.dense.bias', 'encoder.layer.6.attention.output.dense.weight', 'encoder.layer.1.output.dense.bias', 'encoder.layer.0.attention.self.key.bias', 'encoder.layer.18.attention.self.key.weight', 'encoder.layer.16.output.dense.weight', 'encoder.layer.2.attention.self.query.weight', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.2.output.dense.weight', 'encoder.layer.19.output.LayerNorm.bias', 'encoder.layer.23.intermediate.dense.bias', 'encoder.layer.17.output.dense.weight', 'encoder.layer.12.attention.output.dense.bias', 'encoder.layer.6.attention.self.key.weight', 'encoder.layer.14.output.dense.weight', 'encoder.layer.15.attention.self.query.bias', 'encoder.layer.17.attention.self.key.weight', 'encoder.layer.1.attention.self.value.bias', 'encoder.layer.7.output.LayerNorm.weight', 'encoder.layer.13.attention.self.key.weight', 'encoder.layer.17.output.LayerNorm.weight', 'encoder.layer.19.attention.self.query.bias', 'encoder.layer.3.attention.self.key.weight', 'encoder.layer.4.attention.self.query.weight', 'encoder.layer.0.attention.output.dense.weight', 'encoder.layer.1.attention.output.dense.weight', 'encoder.layer.3.attention.output.dense.weight', 'encoder.layer.6.attention.self.key.bias', 'encoder.layer.22.attention.self.value.weight', 'encoder.layer.9.attention.self.value.bias', 'encoder.layer.10.attention.output.LayerNorm.weight', 'encoder.layer.23.attention.self.query.bias', 'encoder.layer.7.output.LayerNorm.bias', 'encoder.layer.9.output.LayerNorm.bias', 'encoder.layer.9.output.LayerNorm.weight', 'encoder.layer.4.attention.self.key.weight', 'encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.layer.9.attention.output.dense.bias', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.20.output.dense.weight', 'encoder.layer.15.attention.output.dense.weight', 'encoder.layer.21.attention.output.dense.weight', 'encoder.layer.6.output.LayerNorm.bias', 'encoder.layer.11.output.LayerNorm.weight', 'encoder.layer.11.attention.self.key.bias', 'encoder.layer.3.attention.self.value.bias', 'encoder.layer.15.attention.self.query.weight', 'encoder.layer.22.attention.output.dense.weight', 'encoder.layer.15.attention.self.value.bias', 'encoder.layer.19.attention.output.dense.bias', 'encoder.layer.20.output.LayerNorm.weight', 'encoder.layer.23.attention.self.value.weight', 'encoder.layer.19.attention.self.query.weight', 'encoder.layer.2.attention.output.dense.weight', 'encoder.layer.17.attention.output.LayerNorm.bias', 'encoder.layer.6.output.dense.weight', 'encoder.layer.17.attention.self.value.bias', 'encoder.layer.12.intermediate.dense.bias', 'encoder.layer.11.output.dense.weight', 'encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.layer.21.output.dense.bias', 'encoder.layer.15.output.LayerNorm.bias', 'encoder.layer.22.output.dense.bias', 'encoder.layer.9.output.dense.bias', 'encoder.layer.20.attention.self.value.bias', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.3.output.dense.bias', 'encoder.layer.7.attention.output.LayerNorm.bias', 'encoder.layer.19.attention.output.LayerNorm.weight', 'encoder.layer.5.attention.self.query.weight', 'encoder.layer.0.attention.output.LayerNorm.weight', 'encoder.layer.17.output.LayerNorm.bias', 'encoder.layer.17.intermediate.dense.bias', 'encoder.layer.10.attention.output.LayerNorm.bias', 'encoder.layer.13.intermediate.dense.bias', 'encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.layer.13.attention.self.value.bias', 'encoder.layer.21.attention.self.value.bias', 'encoder.layer.12.attention.self.key.weight', 'encoder.layer.4.attention.self.value.weight', 'encoder.layer.13.output.dense.weight', 'encoder.layer.23.intermediate.dense.weight', 'encoder.layer.3.attention.self.value.weight', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.21.output.LayerNorm.weight', 'encoder.layer.23.attention.self.value.bias', 'encoder.layer.18.output.dense.weight', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.23.attention.self.key.bias', 'encoder.layer.7.attention.output.LayerNorm.weight', 'encoder.layer.16.attention.self.value.bias', 'encoder.layer.21.attention.self.query.weight', 'encoder.layer.10.intermediate.dense.weight', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.19.attention.output.LayerNorm.bias', 'encoder.layer.10.attention.self.key.weight', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.9.attention.self.key.bias', 'encoder.layer.7.attention.self.query.weight', 'encoder.layer.7.attention.self.query.bias', 'encoder.layer.23.attention.output.LayerNorm.bias', 'encoder.layer.21.attention.output.LayerNorm.weight', 'encoder.layer.21.attention.self.key.bias', 'encoder.layer.14.attention.self.query.weight', 'encoder.layer.19.attention.output.dense.weight', 'encoder.layer.16.attention.output.dense.weight', 'encoder.layer.15.attention.self.key.weight', 'encoder.layer.15.attention.self.value.weight', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.16.attention.self.query.bias', 'encoder.layer.3.attention.self.key.bias', 'encoder.layer.7.intermediate.dense.bias', 'encoder.layer.18.output.LayerNorm.bias', 'encoder.layer.1.attention.self.key.weight', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.16.attention.self.key.bias', 'encoder.layer.5.output.dense.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Overwriting existing adapter 'ep'.
Overwriting existing adapter 'tp'.
Overwriting existing adapter 'es'.
Overwriting existing adapter 'ts'.
Overwriting existing adapter fusion module 'ep,tp,es,ts'
05/09/2022 20:13:30 - INFO - __main__ -   Creating features from dataset file at .
/cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//squad/xlm-KG_LR8e-6_EPOCH2.0_maxlen384_batchsize4_gradacc4
XLMConfig {
  "architectures": [
    "XLMRobertaForMaskedLM"
  ],
  "asm": false,
  "attention_dropout": 0.1,
  "attention_probs_dropout_prob": 0.1,
  "bos_index": 0,
  "bos_token_id": 0,
  "causal": false,
  "dropout": 0.1,
  "emb_dim": 1024,
  "embed_init_std": 0.02209708691207961,
  "end_n_top": 5,
  "eos_index": 1,
  "eos_token_id": 2,
  "gelu_activation": true,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "init_std": 0.02,
  "initializer_range": 0.02,
  "intermediate_size": 4096,
  "is_encoder": true,
  "lang_id": 0,
  "layer_norm_eps": 1e-05,
  "mask_index": 5,
  "mask_token_id": 0,
  "max_position_embeddings": 514,
  "model_type": "xlm",
  "n_heads": 16,
  "n_langs": 1,
  "n_layers": 24,
  "output_past": true,
  "pad_index": 2,
  "pad_token_id": 1,
  "sinusoidal_embeddings": false,
  "start_n_top": 5,
  "summary_activation": null,
  "summary_first_dropout": 0.1,
  "summary_proj_to_labels": true,
  "summary_type": "first",
  "summary_use_proj": true,
  "transformers_version": "4.17.0",
  "type_vocab_size": 1,
  "unk_index": 3,
  "use_lang_emb": false,
  "vocab_size": 250002
}

  0%|          | 0/48 [00:00<?, ?it/s] 60%|██████    | 29/48 [00:00<00:00, 283.77it/s]100%|██████████| 48/48 [00:00<00:00, 291.30it/s]
convert squad examples to features:   0%|          | 0/1190 [00:00<?, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.
convert squad examples to features:   3%|▎         | 33/1190 [00:00<00:03, 296.37it/s]convert squad examples to features:   8%|▊         | 97/1190 [00:00<00:02, 376.82it/s]convert squad examples to features:  14%|█▎        | 161/1190 [00:00<00:02, 476.90it/s]convert squad examples to features:  19%|█▉        | 225/1190 [00:00<00:01, 528.71it/s]convert squad examples to features:  24%|██▍       | 289/1190 [00:00<00:01, 537.20it/s]convert squad examples to features:  30%|██▉       | 353/1190 [00:00<00:01, 529.78it/s]convert squad examples to features:  34%|███▍      | 407/1190 [00:00<00:02, 388.58it/s]convert squad examples to features:  38%|███▊      | 451/1190 [00:01<00:01, 371.80it/s]convert squad examples to features:  43%|████▎     | 513/1190 [00:01<00:01, 408.62it/s]convert squad examples to features:  48%|████▊     | 577/1190 [00:01<00:01, 440.28it/s]convert squad examples to features:  54%|█████▍    | 641/1190 [00:01<00:01, 460.59it/s]convert squad examples to features:  59%|█████▉    | 705/1190 [00:01<00:01, 440.16it/s]convert squad examples to features:  65%|██████▍   | 769/1190 [00:01<00:00, 481.53it/s]convert squad examples to features:  70%|███████   | 833/1190 [00:01<00:00, 453.62it/s]convert squad examples to features:  75%|███████▌  | 897/1190 [00:01<00:00, 479.83it/s]convert squad examples to features:  81%|████████  | 961/1190 [00:02<00:00, 484.14it/s]convert squad examples to features:  86%|████████▌ | 1025/1190 [00:02<00:00, 518.87it/s]convert squad examples to features:  94%|█████████▍| 1121/1190 [00:02<00:00, 562.08it/s]convert squad examples to features: 100%|██████████| 1190/1190 [00:02<00:00, 489.91it/s]/cluster/project/sachan/yifan/softwares/anaconda/anaconda3/envs/xfactr/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2272: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

add example index and unique id:   0%|          | 0/1190 [00:00<?, ?it/s]add example index and unique id: 100%|██████████| 1190/1190 [00:00<00:00, 604556.90it/s]
05/09/2022 20:13:33 - INFO - __main__ -   Saving features into cached file ./cached_xquad.zh.json_xlm-KG_LR8e-6_EPOCH2.0_maxlen384_batchsize4_gradacc4_384_zh
05/09/2022 20:13:34 - INFO - __main__ -   ***** Running evaluation  *****
05/09/2022 20:13:34 - INFO - __main__ -     Num examples = 1246
05/09/2022 20:13:34 - INFO - __main__ -     Batch size = 8
Evaluating:   0%|          | 0/156 [00:00<?, ?it/s]Evaluating:   1%|          | 1/156 [00:00<02:02,  1.26it/s]Evaluating:   1%|▏         | 2/156 [00:01<01:22,  1.87it/s]Evaluating:   2%|▏         | 3/156 [00:01<01:09,  2.21it/s]Evaluating:   3%|▎         | 4/156 [00:01<01:03,  2.41it/s]Evaluating:   3%|▎         | 5/156 [00:02<00:59,  2.54it/s]Evaluating:   4%|▍         | 6/156 [00:02<00:57,  2.59it/s]Evaluating:   4%|▍         | 7/156 [00:02<00:56,  2.66it/s]Evaluating:   5%|▌         | 8/156 [00:03<00:54,  2.70it/s]Evaluating:   6%|▌         | 9/156 [00:03<00:55,  2.64it/s]Evaluating:   6%|▋         | 10/156 [00:04<00:54,  2.67it/s]Evaluating:   7%|▋         | 11/156 [00:04<00:53,  2.70it/s]Evaluating:   8%|▊         | 12/156 [00:04<00:52,  2.73it/s]Evaluating:   8%|▊         | 13/156 [00:05<00:51,  2.75it/s]Evaluating:   9%|▉         | 14/156 [00:05<00:51,  2.77it/s]Evaluating:  10%|▉         | 15/156 [00:05<00:50,  2.78it/s]Evaluating:  10%|█         | 16/156 [00:06<00:50,  2.78it/s]Evaluating:  11%|█         | 17/156 [00:06<00:50,  2.74it/s]Evaluating:  12%|█▏        | 18/156 [00:06<00:49,  2.76it/s]Evaluating:  12%|█▏        | 19/156 [00:07<00:49,  2.77it/s]Evaluating:  13%|█▎        | 20/156 [00:07<00:49,  2.76it/s]Evaluating:  13%|█▎        | 21/156 [00:08<00:48,  2.78it/s]Evaluating:  14%|█▍        | 22/156 [00:08<00:47,  2.80it/s]Evaluating:  15%|█▍        | 23/156 [00:08<00:47,  2.80it/s]Evaluating:  15%|█▌        | 24/156 [00:09<00:47,  2.80it/s]Evaluating:  16%|█▌        | 25/156 [00:09<00:46,  2.81it/s]Evaluating:  17%|█▋        | 26/156 [00:09<00:46,  2.80it/s]Evaluating:  17%|█▋        | 27/156 [00:10<00:47,  2.72it/s]Evaluating:  18%|█▊        | 28/156 [00:10<00:46,  2.75it/s]Evaluating:  19%|█▊        | 29/156 [00:10<00:45,  2.77it/s]Evaluating:  19%|█▉        | 30/156 [00:11<00:45,  2.78it/s]Evaluating:  20%|█▉        | 31/156 [00:11<00:45,  2.77it/s]Evaluating:  21%|██        | 32/156 [00:11<00:44,  2.78it/s]Evaluating:  21%|██        | 33/156 [00:12<00:44,  2.79it/s]Evaluating:  22%|██▏       | 34/156 [00:12<00:43,  2.80it/s]Evaluating:  22%|██▏       | 35/156 [00:13<00:43,  2.80it/s]Evaluating:  23%|██▎       | 36/156 [00:13<00:42,  2.79it/s]Evaluating:  24%|██▎       | 37/156 [00:13<00:42,  2.79it/s]Evaluating:  24%|██▍       | 38/156 [00:14<00:42,  2.79it/s]Evaluating:  25%|██▌       | 39/156 [00:14<00:42,  2.74it/s]Evaluating:  26%|██▌       | 40/156 [00:14<00:42,  2.76it/s]Evaluating:  26%|██▋       | 41/156 [00:15<00:41,  2.77it/s]Evaluating:  27%|██▋       | 42/156 [00:15<00:41,  2.78it/s]Evaluating:  28%|██▊       | 43/156 [00:15<00:40,  2.78it/s]Evaluating:  28%|██▊       | 44/156 [00:16<00:40,  2.78it/s]Evaluating:  29%|██▉       | 45/156 [00:16<00:39,  2.79it/s]Evaluating:  29%|██▉       | 46/156 [00:16<00:39,  2.80it/s]Evaluating:  30%|███       | 47/156 [00:17<00:39,  2.79it/s]Evaluating:  31%|███       | 48/156 [00:17<00:38,  2.79it/s]Evaluating:  31%|███▏      | 49/156 [00:18<00:38,  2.79it/s]Evaluating:  32%|███▏      | 50/156 [00:18<00:38,  2.78it/s]Evaluating:  33%|███▎      | 51/156 [00:18<00:37,  2.77it/s]Evaluating:  33%|███▎      | 52/156 [00:19<00:37,  2.75it/s]Evaluating:  34%|███▍      | 53/156 [00:19<00:37,  2.75it/s]Evaluating:  35%|███▍      | 54/156 [00:19<00:37,  2.74it/s]Evaluating:  35%|███▌      | 55/156 [00:20<00:36,  2.74it/s]Evaluating:  36%|███▌      | 56/156 [00:20<00:36,  2.75it/s]Evaluating:  37%|███▋      | 57/156 [00:20<00:35,  2.76it/s]Evaluating:  37%|███▋      | 58/156 [00:21<00:35,  2.75it/s]Evaluating:  38%|███▊      | 59/156 [00:21<00:35,  2.75it/s]Evaluating:  38%|███▊      | 60/156 [00:22<00:34,  2.77it/s]Evaluating:  39%|███▉      | 61/156 [00:22<00:34,  2.77it/s]Evaluating:  40%|███▉      | 62/156 [00:22<00:33,  2.77it/s]Evaluating:  40%|████      | 63/156 [00:23<00:33,  2.76it/s]Evaluating:  41%|████      | 64/156 [00:23<00:33,  2.75it/s]Evaluating:  42%|████▏     | 65/156 [00:23<00:33,  2.75it/s]Evaluating:  42%|████▏     | 66/156 [00:24<00:32,  2.75it/s]Evaluating:  43%|████▎     | 67/156 [00:24<00:32,  2.76it/s]Evaluating:  44%|████▎     | 68/156 [00:24<00:31,  2.77it/s]Evaluating:  44%|████▍     | 69/156 [00:25<00:31,  2.77it/s]Evaluating:  45%|████▍     | 70/156 [00:25<00:31,  2.77it/s]Evaluating:  46%|████▌     | 71/156 [00:26<00:30,  2.76it/s]Evaluating:  46%|████▌     | 72/156 [00:26<00:30,  2.77it/s]Evaluating:  47%|████▋     | 73/156 [00:26<00:30,  2.76it/s]Evaluating:  47%|████▋     | 74/156 [00:27<00:29,  2.77it/s]Evaluating:  48%|████▊     | 75/156 [00:27<00:29,  2.76it/s]Evaluating:  49%|████▊     | 76/156 [00:27<00:28,  2.76it/s]Evaluating:  49%|████▉     | 77/156 [00:28<00:28,  2.77it/s]Evaluating:  50%|█████     | 78/156 [00:28<00:28,  2.77it/s]Evaluating:  51%|█████     | 79/156 [00:28<00:27,  2.78it/s]Evaluating:  51%|█████▏    | 80/156 [00:29<00:27,  2.78it/s]Evaluating:  52%|█████▏    | 81/156 [00:29<00:27,  2.78it/s]Evaluating:  53%|█████▎    | 82/156 [00:30<00:26,  2.78it/s]Evaluating:  53%|█████▎    | 83/156 [00:30<00:26,  2.78it/s]Evaluating:  54%|█████▍    | 84/156 [00:30<00:26,  2.77it/s]Evaluating:  54%|█████▍    | 85/156 [00:31<00:25,  2.77it/s]Evaluating:  55%|█████▌    | 86/156 [00:31<00:25,  2.77it/s]Evaluating:  56%|█████▌    | 87/156 [00:31<00:24,  2.77it/s]Evaluating:  56%|█████▋    | 88/156 [00:32<00:24,  2.77it/s]Evaluating:  57%|█████▋    | 89/156 [00:32<00:24,  2.77it/s]Evaluating:  58%|█████▊    | 90/156 [00:32<00:23,  2.77it/s]Evaluating:  58%|█████▊    | 91/156 [00:33<00:23,  2.77it/s]Evaluating:  59%|█████▉    | 92/156 [00:33<00:23,  2.69it/s]Evaluating:  60%|█████▉    | 93/156 [00:34<00:23,  2.69it/s]Evaluating:  60%|██████    | 94/156 [00:34<00:22,  2.72it/s]Evaluating:  61%|██████    | 95/156 [00:34<00:22,  2.73it/s]Evaluating:  62%|██████▏   | 96/156 [00:35<00:21,  2.75it/s]Evaluating:  62%|██████▏   | 97/156 [00:35<00:21,  2.76it/s]Evaluating:  63%|██████▎   | 98/156 [00:35<00:21,  2.76it/s]Evaluating:  63%|██████▎   | 99/156 [00:36<00:20,  2.77it/s]Evaluating:  64%|██████▍   | 100/156 [00:36<00:20,  2.76it/s]Evaluating:  65%|██████▍   | 101/156 [00:36<00:19,  2.76it/s]Evaluating:  65%|██████▌   | 102/156 [00:37<00:19,  2.76it/s]Evaluating:  66%|██████▌   | 103/156 [00:37<00:19,  2.77it/s]Evaluating:  67%|██████▋   | 104/156 [00:38<00:18,  2.77it/s]Evaluating:  67%|██████▋   | 105/156 [00:38<00:18,  2.76it/s]Evaluating:  68%|██████▊   | 106/156 [00:38<00:18,  2.77it/s]Evaluating:  69%|██████▊   | 107/156 [00:39<00:17,  2.76it/s]Evaluating:  69%|██████▉   | 108/156 [00:39<00:17,  2.77it/s]Evaluating:  70%|██████▉   | 109/156 [00:39<00:16,  2.77it/s]Evaluating:  71%|███████   | 110/156 [00:40<00:16,  2.77it/s]Evaluating:  71%|███████   | 111/156 [00:40<00:16,  2.77it/s]Evaluating:  72%|███████▏  | 112/156 [00:40<00:15,  2.76it/s]Evaluating:  72%|███████▏  | 113/156 [00:41<00:15,  2.77it/s]Evaluating:  73%|███████▎  | 114/156 [00:41<00:15,  2.77it/s]Evaluating:  74%|███████▎  | 115/156 [00:41<00:14,  2.78it/s]Evaluating:  74%|███████▍  | 116/156 [00:42<00:14,  2.78it/s]Evaluating:  75%|███████▌  | 117/156 [00:42<00:14,  2.78it/s]Evaluating:  76%|███████▌  | 118/156 [00:43<00:13,  2.78it/s]Evaluating:  76%|███████▋  | 119/156 [00:43<00:13,  2.77it/s]Evaluating:  77%|███████▋  | 120/156 [00:43<00:13,  2.76it/s]Evaluating:  78%|███████▊  | 121/156 [00:44<00:12,  2.76it/s]Evaluating:  78%|███████▊  | 122/156 [00:44<00:12,  2.77it/s]Evaluating:  79%|███████▉  | 123/156 [00:44<00:12,  2.75it/s]Evaluating:  79%|███████▉  | 124/156 [00:45<00:11,  2.74it/s]Evaluating:  80%|████████  | 125/156 [00:45<00:11,  2.65it/s]Evaluating:  81%|████████  | 126/156 [00:46<00:11,  2.69it/s]Evaluating:  81%|████████▏ | 127/156 [00:46<00:10,  2.72it/s]Evaluating:  82%|████████▏ | 128/156 [00:46<00:10,  2.74it/s]Evaluating:  83%|████████▎ | 129/156 [00:47<00:09,  2.75it/s]Evaluating:  83%|████████▎ | 130/156 [00:47<00:09,  2.73it/s]Evaluating:  84%|████████▍ | 131/156 [00:47<00:09,  2.71it/s]Evaluating:  85%|████████▍ | 132/156 [00:48<00:08,  2.73it/s]Evaluating:  85%|████████▌ | 133/156 [00:48<00:08,  2.74it/s]Evaluating:  86%|████████▌ | 134/156 [00:48<00:08,  2.73it/s]Evaluating:  87%|████████▋ | 135/156 [00:49<00:07,  2.75it/s]Evaluating:  87%|████████▋ | 136/156 [00:49<00:07,  2.76it/s]Evaluating:  88%|████████▊ | 137/156 [00:50<00:06,  2.76it/s]Evaluating:  88%|████████▊ | 138/156 [00:50<00:06,  2.77it/s]Evaluating:  89%|████████▉ | 139/156 [00:50<00:06,  2.78it/s]Evaluating:  90%|████████▉ | 140/156 [00:51<00:05,  2.77it/s]Evaluating:  90%|█████████ | 141/156 [00:51<00:05,  2.78it/s]Evaluating:  91%|█████████ | 142/156 [00:51<00:05,  2.78it/s]Evaluating:  92%|█████████▏| 143/156 [00:52<00:04,  2.78it/s]Evaluating:  92%|█████████▏| 144/156 [00:52<00:04,  2.77it/s]Evaluating:  93%|█████████▎| 145/156 [00:52<00:04,  2.73it/s]Evaluating:  94%|█████████▎| 146/156 [00:53<00:03,  2.74it/s]Evaluating:  94%|█████████▍| 147/156 [00:53<00:03,  2.74it/s]Evaluating:  95%|█████████▍| 148/156 [00:53<00:02,  2.74it/s]Evaluating:  96%|█████████▌| 149/156 [00:54<00:02,  2.70it/s]Evaluating:  96%|█████████▌| 150/156 [00:54<00:02,  2.70it/s]Evaluating:  97%|█████████▋| 151/156 [00:55<00:01,  2.70it/s]Evaluating:  97%|█████████▋| 152/156 [00:55<00:01,  2.72it/s]Evaluating:  98%|█████████▊| 153/156 [00:55<00:01,  2.72it/s]Evaluating:  99%|█████████▊| 154/156 [00:56<00:00,  2.72it/s]Evaluating:  99%|█████████▉| 155/156 [00:56<00:00,  2.74it/s]Evaluating: 100%|██████████| 156/156 [00:56<00:00,  2.99it/s]Evaluating: 100%|██████████| 156/156 [00:56<00:00,  2.74it/s]
05/09/2022 20:14:31 - INFO - __main__ -     Evaluation done in total 56.838248 secs (0.045617 sec per example)
05/09/2022 20:14:54 - INFO - __main__ -   Results: {'exact': 46.72268907563025, 'f1': 55.99635192072162, 'total': 1190, 'HasAns_exact': 46.72268907563025, 'HasAns_f1': 55.99635192072162, 'HasAns_total': 1190, 'best_exact': 46.72268907563025, 'best_exact_thresh': 0.0, 'best_f1': 55.99635192072162, 'best_f1_thresh': 0.0}
  hi 
2022-05-09 20:14:57.238334: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0
05/09/2022 20:14:59 - WARNING - __main__ -   Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, 16-bits training: False
You are using a model of type xlm-roberta to instantiate a model of type xlm. This is not supported for all configurations of models and can yield errors.
Some weights of the model checkpoint at /cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//squad/xlm-KG_LR8e-6_EPOCH2.0_maxlen384_batchsize4_gradacc4 were not used when initializing XLMRobertaModel: ['base_model.encoder.layer.20.attention.self.query.weight', 'base_model.encoder.layer.3.attention.self.value.bias', 'base_model.pooler.dense.weight', 'base_model.encoder.layer.4.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.7.attention.self.query.weight', 'base_model.encoder.layer.19.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.12.attention.output.dense.bias', 'base_model.encoder.layer.11.attention.output.LayerNorm.weight', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.8.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.5.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.9.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.18.output.dense.bias', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.19.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.11.attention.self.key.bias', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.1.output.dense.weight', 'base_model.encoder.layer.6.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.6.intermediate.dense.bias', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.6.output.LayerNorm.weight', 'base_model.encoder.layer.18.attention.output.dense.weight', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.21.output.LayerNorm.bias', 'base_model.encoder.layer.10.attention.output.LayerNorm.weight', 'base_model.encoder.layer.13.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.5.attention.self.value.bias', 'base_model.encoder.layer.6.attention.self.query.weight', 'base_model.encoder.layer.17.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.13.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.4.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.2.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.7.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.2.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.9.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.10.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.4.attention.self.key.weight', 'base_model.encoder.layer.11.intermediate.dense.bias', 'base_model.encoder.layer.18.attention.output.LayerNorm.weight', 'base_model.encoder.layer.15.output.LayerNorm.bias', 'base_model.encoder.layer.21.output.dense.bias', 'base_model.encoder.layer.22.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.15.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.22.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.0.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.23.output.LayerNorm.bias', 'base_model.encoder.layer.8.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.8.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.11.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.5.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.16.output.LayerNorm.bias', 'base_model.encoder.layer.22.attention.self.key.bias', 'base_model.encoder.layer.23.attention.output.LayerNorm.weight', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.9.attention.self.query.weight', 'base_model.encoder.layer.20.output.LayerNorm.weight', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.20.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.15.attention.output.dense.weight', 'base_model.encoder.layer.15.attention.output.LayerNorm.bias', 'base_model.encoder.layer.15.output.LayerNorm.weight', 'base_model.encoder.layer.16.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.14.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.5.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.22.attention.output.dense.bias', 'base_model.encoder.layer.23.attention.output.dense.bias', 'base_model.encoder.layer.0.output.dense.bias', 'base_model.encoder.layer.17.attention.self.key.weight', 'base_model.encoder.layer.9.attention.self.value.weight', 'base_model.encoder.layer.13.attention.self.query.weight', 'base_model.encoder.layer.18.attention.output.dense.bias', 'base_model.encoder.layer.19.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.16.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.5.attention.self.key.weight', 'base_model.encoder.layer.0.attention.self.key.weight', 'base_model.encoder.layer.4.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.11.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.18.output.dense.weight', 'base_model.encoder.layer.12.attention.output.LayerNorm.bias', 'base_model.encoder.layer.0.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.16.output.adapters.ts.adapter_up.bias', 'base_model.pooler.dense.bias', 'base_model.encoder.layer.19.attention.output.LayerNorm.bias', 'base_model.encoder.layer.6.attention.output.LayerNorm.weight', 'base_model.encoder.layer.2.attention.output.dense.bias', 'base_model.encoder.layer.16.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.21.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.22.output.LayerNorm.weight', 'base_model.encoder.layer.19.output.dense.weight', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.6.attention.self.query.bias', 'base_model.encoder.layer.20.output.adapters.es.adapter_down.0.weight', 'qa_outputs.bias', 'base_model.encoder.layer.7.output.LayerNorm.weight', 'base_model.encoder.layer.8.output.LayerNorm.weight', 'base_model.encoder.layer.14.intermediate.dense.bias', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.6.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.10.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.13.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.14.output.LayerNorm.weight', 'base_model.encoder.layer.10.attention.self.value.weight', 'base_model.encoder.layer.3.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.13.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.14.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.15.output.dense.bias', 'base_model.encoder.layer.2.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.14.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.12.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.21.attention.output.dense.weight', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.7.attention.output.dense.weight', 'base_model.encoder.layer.8.attention.self.key.weight', 'base_model.encoder.layer.17.output.LayerNorm.weight', 'base_model.encoder.layer.20.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.1.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.0.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.14.attention.output.dense.bias', 'base_model.encoder.layer.5.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.4.attention.self.query.bias', 'base_model.encoder.layer.20.attention.self.value.weight', 'base_model.encoder.layer.3.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.5.attention.self.query.weight', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.12.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.11.attention.self.query.weight', 'base_model.encoder.layer.11.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.15.output.dense.weight', 'base_model.encoder.layer.17.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.4.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.9.attention.self.query.bias', 'base_model.encoder.layer.12.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.19.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.22.intermediate.dense.weight', 'base_model.encoder.layer.2.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.11.output.LayerNorm.bias', 'base_model.encoder.layer.14.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.12.attention.self.value.bias', 'base_model.encoder.layer.18.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.7.intermediate.dense.bias', 'base_model.encoder.layer.18.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.23.intermediate.dense.weight', 'base_model.encoder.layer.22.output.dense.bias', 'base_model.encoder.layer.9.attention.output.dense.bias', 'base_model.encoder.layer.15.attention.self.key.bias', 'base_model.encoder.layer.22.attention.self.value.bias', 'base_model.embeddings.LayerNorm.weight', 'base_model.encoder.layer.2.attention.output.dense.weight', 'base_model.encoder.layer.12.attention.self.key.weight', 'base_model.encoder.layer.21.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.7.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.9.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.18.attention.self.query.bias', 'base_model.encoder.layer.10.intermediate.dense.bias', 'base_model.encoder.layer.13.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.14.output.dense.bias', 'base_model.encoder.layer.15.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.10.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.1.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.10.attention.output.LayerNorm.bias', 'base_model.embeddings.position_embeddings.weight', 'base_model.encoder.layer.1.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.5.output.LayerNorm.weight', 'base_model.encoder.layer.10.output.LayerNorm.weight', 'base_model.encoder.layer.0.attention.output.LayerNorm.bias', 'base_model.encoder.layer.4.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.7.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.7.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.22.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.21.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.23.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.12.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.16.attention.self.value.weight', 'base_model.encoder.layer.4.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.1.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.21.attention.output.LayerNorm.weight', 'base_model.encoder.layer.3.attention.output.dense.bias', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.21.attention.self.value.bias', 'base_model.encoder.layer.19.attention.self.query.bias', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.18.attention.self.value.bias', 'base_model.encoder.layer.4.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.5.attention.self.value.weight', 'base_model.encoder.layer.9.attention.output.LayerNorm.bias', 'base_model.encoder.layer.5.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.16.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.7.attention.self.value.weight', 'base_model.encoder.layer.19.intermediate.dense.bias', 'base_model.encoder.layer.5.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.16.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.22.attention.output.LayerNorm.bias', 'base_model.encoder.layer.23.attention.self.value.weight', 'base_model.encoder.layer.9.output.dense.weight', 'base_model.encoder.layer.16.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.15.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.23.attention.self.value.bias', 'base_model.encoder.layer.4.output.LayerNorm.weight', 'base_model.encoder.layer.9.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.11.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.3.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.0.intermediate.dense.weight', 'base_model.encoder.layer.5.attention.self.key.bias', 'base_model.encoder.layer.22.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.13.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.20.attention.output.LayerNorm.weight', 'base_model.encoder.layer.0.attention.self.query.weight', 'base_model.encoder.layer.2.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.13.output.dense.bias', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.11.output.LayerNorm.weight', 'base_model.encoder.layer.0.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.7.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.12.attention.output.LayerNorm.weight', 'base_model.encoder.layer.18.intermediate.dense.weight', 'base_model.encoder.layer.17.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.9.output.LayerNorm.bias', 'base_model.encoder.layer.6.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.18.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.9.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.11.attention.self.key.weight', 'base_model.encoder.layer.12.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.18.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.17.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.11.intermediate.dense.weight', 'base_model.encoder.layer.20.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.23.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.4.attention.self.key.bias', 'base_model.encoder.layer.8.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.16.intermediate.dense.weight', 'base_model.encoder.layer.1.attention.output.dense.bias', 'base_model.encoder.layer.7.output.dense.weight', 'base_model.encoder.layer.6.output.LayerNorm.bias', 'base_model.encoder.layer.22.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.18.attention.self.value.weight', 'base_model.encoder.layer.9.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.11.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.1.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.5.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.13.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.16.attention.self.query.weight', 'base_model.encoder.layer.3.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.1.attention.self.value.weight', 'base_model.encoder.layer.23.attention.output.dense.weight', 'base_model.encoder.layer.6.intermediate.dense.weight', 'base_model.encoder.layer.2.intermediate.dense.bias', 'base_model.encoder.layer.12.attention.self.query.weight', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.15.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.18.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.20.intermediate.dense.bias', 'base_model.encoder.layer.15.attention.output.LayerNorm.weight', 'base_model.encoder.layer.7.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.18.attention.output.LayerNorm.bias', 'base_model.encoder.layer.14.attention.self.query.bias', 'base_model.encoder.layer.17.attention.output.LayerNorm.bias', 'base_model.encoder.layer.19.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.22.attention.output.LayerNorm.weight', 'base_model.encoder.layer.23.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.20.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.3.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.9.intermediate.dense.bias', 'base_model.encoder.layer.11.attention.self.value.bias', 'base_model.encoder.layer.12.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.21.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.6.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.23.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.5.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.2.output.dense.weight', 'base_model.encoder.layer.18.intermediate.dense.bias', 'base_model.encoder.layer.2.output.LayerNorm.bias', 'base_model.encoder.layer.1.intermediate.dense.weight', 'base_model.encoder.layer.23.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.8.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.16.attention.self.key.weight', 'base_model.encoder.layer.22.intermediate.dense.bias', 'base_model.encoder.layer.1.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.8.output.LayerNorm.bias', 'base_model.encoder.layer.21.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.4.output.dense.weight', 'base_model.encoder.layer.1.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.16.attention.output.LayerNorm.weight', 'base_model.encoder.layer.9.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.6.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.14.attention.self.key.bias', 'base_model.encoder.layer.18.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.22.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.10.attention.output.dense.weight', 'base_model.encoder.layer.21.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.8.attention.self.query.bias', 'base_model.encoder.layer.7.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.3.intermediate.dense.weight', 'base_model.encoder.layer.5.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.14.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.19.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.12.intermediate.dense.weight', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.2.attention.self.query.bias', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.8.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.12.output.dense.bias', 'base_model.encoder.layer.13.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.6.attention.output.dense.weight', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.19.attention.self.key.bias', 'base_model.encoder.layer.8.attention.self.query.weight', 'base_model.encoder.layer.1.attention.self.value.bias', 'base_model.encoder.layer.6.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.7.attention.self.query.bias', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.19.attention.output.dense.weight', 'base_model.encoder.layer.17.attention.self.query.weight', 'base_model.encoder.layer.5.output.LayerNorm.bias', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.23.attention.self.query.weight', 'base_model.encoder.layer.21.attention.output.dense.bias', 'base_model.encoder.layer.10.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.23.intermediate.dense.bias', 'base_model.encoder.layer.20.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.2.attention.self.key.bias', 'base_model.encoder.layer.9.attention.self.key.bias', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.21.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.21.output.dense.weight', 'base_model.encoder.layer.20.output.LayerNorm.bias', 'base_model.encoder.layer.6.attention.self.value.weight', 'base_model.encoder.layer.5.output.dense.weight', 'base_model.encoder.layer.17.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.3.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.6.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.17.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.16.intermediate.dense.bias', 'base_model.encoder.layer.14.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.20.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.0.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.17.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.16.output.dense.bias', 'base_model.encoder.layer.7.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.19.output.LayerNorm.weight', 'base_model.encoder.layer.15.attention.self.value.weight', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.11.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.5.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.6.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.8.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.21.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.8.attention.self.value.bias', 'base_model.embeddings.token_type_embeddings.weight', 'base_model.encoder.layer.10.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.11.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.19.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.23.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.2.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.5.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.6.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.9.attention.self.key.weight', 'base_model.encoder.layer.2.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.8.output.dense.weight', 'base_model.encoder.layer.13.attention.output.LayerNorm.weight', 'base_model.encoder.layer.10.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.6.output.dense.bias', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.4.intermediate.dense.bias', 'base_model.encoder.layer.10.output.dense.bias', 'base_model.encoder.layer.12.output.LayerNorm.bias', 'base_model.encoder.layer.7.attention.self.value.bias', 'base_model.encoder.layer.1.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.1.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.20.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.13.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.23.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.3.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.4.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.15.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.19.attention.self.value.bias', 'base_model.encoder.layer.4.output.dense.bias', 'base_model.encoder.layer.1.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.21.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.16.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.17.attention.self.query.bias', 'base_model.encoder.layer.14.output.dense.weight', 'base_model.encoder.layer.3.output.dense.bias', 'base_model.encoder.layer.13.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.3.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.10.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.21.intermediate.dense.bias', 'base_model.encoder.layer.3.attention.output.LayerNorm.weight', 'base_model.encoder.layer.21.attention.self.key.bias', 'base_model.encoder.layer.4.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.21.attention.output.LayerNorm.bias', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.16.attention.output.LayerNorm.bias', 'base_model.encoder.layer.2.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.23.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.14.output.LayerNorm.bias', 'base_model.encoder.layer.2.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.17.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.4.attention.output.LayerNorm.weight', 'base_model.encoder.layer.8.attention.self.key.bias', 'base_model.encoder.layer.19.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.18.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.2.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.12.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.14.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.19.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.19.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.18.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.1.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.1.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.9.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.10.attention.self.key.bias', 'base_model.encoder.layer.12.output.LayerNorm.weight', 'base_model.encoder.layer.0.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.0.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.13.attention.self.key.bias', 'base_model.encoder.layer.18.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.10.output.dense.weight', 'base_model.encoder.layer.20.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.14.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.13.intermediate.dense.weight', 'base_model.encoder.layer.16.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.17.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.22.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.0.attention.self.query.bias', 'base_model.encoder.layer.17.attention.self.value.bias', 'base_model.encoder.layer.18.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.21.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.0.attention.self.value.weight', 'base_model.encoder.layer.1.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.19.attention.output.LayerNorm.weight', 'base_model.encoder.layer.4.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.11.attention.output.LayerNorm.bias', 'base_model.encoder.layer.15.attention.self.query.bias', 'base_model.encoder.layer.1.attention.output.LayerNorm.weight', 'base_model.encoder.layer.19.output.LayerNorm.bias', 'base_model.encoder.layer.9.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.20.attention.output.dense.weight', 'base_model.encoder.layer.7.output.LayerNorm.bias', 'base_model.encoder.layer.3.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.6.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.0.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.8.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.13.output.dense.weight', 'base_model.encoder.layer.12.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.19.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.7.attention.self.key.bias', 'base_model.encoder.layer.13.attention.output.dense.bias', 'base_model.encoder.layer.14.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.21.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.23.attention.output.LayerNorm.bias', 'base_model.encoder.layer.8.attention.output.dense.bias', 'base_model.encoder.layer.13.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.18.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.15.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.22.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.5.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.20.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.6.attention.self.value.bias', 'base_model.embeddings.position_ids', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.20.attention.output.dense.bias', 'base_model.encoder.layer.15.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.0.attention.self.key.bias', 'base_model.encoder.layer.17.intermediate.dense.weight', 'base_model.encoder.layer.11.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.1.attention.self.key.bias', 'base_model.encoder.layer.4.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.13.output.LayerNorm.weight', 'base_model.encoder.layer.23.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.16.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.13.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.17.attention.output.dense.bias', 'base_model.encoder.layer.0.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.14.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.2.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.4.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.3.attention.self.query.bias', 'base_model.encoder.layer.12.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.15.intermediate.dense.bias', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.15.intermediate.dense.weight', 'base_model.encoder.layer.16.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.4.output.LayerNorm.bias', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.5.attention.output.dense.bias', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.12.attention.self.value.weight', 'base_model.encoder.layer.12.output.dense.weight', 'base_model.encoder.layer.13.attention.self.value.weight', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.12.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.7.attention.output.LayerNorm.bias', 'base_model.encoder.layer.10.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.14.attention.self.value.bias', 'base_model.encoder.layer.18.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.2.attention.self.value.bias', 'base_model.encoder.layer.15.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.22.attention.output.dense.weight', 'base_model.encoder.layer.0.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.0.output.LayerNorm.bias', 'base_model.encoder.layer.5.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.22.attention.self.value.weight', 'base_model.encoder.layer.2.intermediate.dense.weight', 'base_model.encoder.layer.14.attention.self.value.weight', 'base_model.encoder.layer.1.attention.self.query.weight', 'base_model.encoder.layer.2.attention.self.value.weight', 'base_model.encoder.layer.3.attention.self.key.bias', 'base_model.encoder.layer.0.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.6.attention.output.LayerNorm.bias', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.21.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.3.output.dense.weight', 'base_model.encoder.layer.8.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.20.attention.self.value.bias', 'base_model.encoder.layer.11.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.10.attention.self.query.bias', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.8.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.10.output.LayerNorm.bias', 'base_model.encoder.layer.12.intermediate.dense.bias', 'base_model.encoder.layer.8.attention.output.LayerNorm.weight', 'base_model.encoder.layer.2.attention.self.query.weight', 'base_model.encoder.layer.16.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.14.attention.self.key.weight', 'base_model.encoder.layer.9.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.22.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.11.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.16.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.1.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.10.attention.self.key.weight', 'base_model.encoder.layer.12.attention.self.key.bias', 'base_model.encoder.layer.3.intermediate.dense.bias', 'base_model.encoder.layer.20.output.dense.bias', 'base_model.encoder.layer.23.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.7.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.20.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.20.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.19.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.23.attention.self.query.bias', 'base_model.encoder.layer.20.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.8.output.dense.bias', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.11.attention.self.value.weight', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.17.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.13.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.0.attention.self.value.bias', 'base_model.encoder.layer.4.intermediate.dense.weight', 'base_model.encoder.layer.5.intermediate.dense.bias', 'base_model.encoder.layer.9.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.16.attention.self.key.bias', 'base_model.encoder.layer.21.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.11.attention.self.query.bias', 'base_model.encoder.layer.17.output.dense.bias', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.1.attention.self.query.bias', 'base_model.encoder.layer.9.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.22.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.6.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.9.attention.output.LayerNorm.weight', 'base_model.encoder.layer.10.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.19.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.12.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.13.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.15.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.18.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.4.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.18.attention.self.query.weight', 'base_model.encoder.layer.6.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.2.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.20.attention.self.key.bias', 'base_model.encoder.layer.1.attention.self.key.weight', 'base_model.encoder.layer.9.intermediate.dense.weight', 'base_model.encoder.layer.6.attention.self.key.weight', 'base_model.encoder.layer.6.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.16.attention.output.dense.weight', 'base_model.encoder.layer.11.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.7.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.15.attention.self.value.bias', 'base_model.encoder.layer.17.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.3.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.7.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.7.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.17.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.10.intermediate.dense.weight', 'base_model.encoder.layer.3.output.LayerNorm.weight', 'base_model.encoder.layer.14.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.19.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.7.attention.output.LayerNorm.weight', 'base_model.encoder.layer.14.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.3.attention.output.dense.weight', 'base_model.encoder.layer.5.attention.output.LayerNorm.weight', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.10.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.6.attention.self.key.bias', 'base_model.encoder.layer.13.attention.output.LayerNorm.bias', 'base_model.encoder.layer.18.output.LayerNorm.bias', 'base_model.encoder.layer.4.attention.output.dense.bias', 'base_model.encoder.layer.3.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.21.attention.self.value.weight', 'base_model.encoder.layer.3.attention.self.value.weight', 'base_model.encoder.layer.19.attention.self.query.weight', 'base_model.encoder.layer.7.attention.output.dense.bias', 'base_model.encoder.layer.1.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.12.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.11.attention.output.dense.weight', 'base_model.encoder.layer.22.attention.self.query.weight', 'base_model.encoder.layer.13.intermediate.dense.bias', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.23.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.6.output.dense.weight', 'base_model.encoder.layer.23.output.dense.bias', 'base_model.encoder.layer.1.intermediate.dense.bias', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.18.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.17.output.dense.weight', 'base_model.encoder.layer.17.attention.output.LayerNorm.weight', 'base_model.encoder.layer.22.attention.self.query.bias', 'base_model.encoder.layer.14.attention.output.LayerNorm.bias', 'base_model.encoder.layer.14.attention.self.query.weight', 'base_model.encoder.layer.11.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.22.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.3.attention.output.LayerNorm.bias', 'base_model.encoder.layer.15.attention.self.key.weight', 'base_model.encoder.layer.20.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.0.output.LayerNorm.weight', 'base_model.encoder.layer.21.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.0.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.1.output.LayerNorm.weight', 'base_model.encoder.layer.15.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.21.attention.self.query.weight', 'base_model.encoder.layer.4.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.14.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.2.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.10.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.3.attention.self.key.weight', 'base_model.encoder.layer.5.attention.output.LayerNorm.bias', 'base_model.encoder.layer.7.attention.self.key.weight', 'base_model.encoder.layer.12.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.20.attention.self.key.weight', 'base_model.encoder.layer.6.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.22.attention.self.key.weight', 'base_model.encoder.layer.5.intermediate.dense.weight', 'base_model.encoder.layer.16.attention.self.value.bias', 'base_model.encoder.layer.0.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.14.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.2.attention.output.LayerNorm.bias', 'base_model.encoder.layer.20.attention.output.LayerNorm.bias', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.0.intermediate.dense.bias', 'base_model.encoder.layer.0.attention.output.dense.bias', 'base_model.encoder.layer.23.attention.self.key.bias', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.0.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.11.output.dense.weight', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.11.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.8.intermediate.dense.bias', 'base_model.encoder.layer.12.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.20.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.5.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.9.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.8.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.6.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.7.intermediate.dense.weight', 'base_model.encoder.layer.9.output.dense.bias', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.16.attention.output.dense.bias', 'base_model.encoder.layer.2.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.14.attention.output.dense.weight', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.5.attention.self.query.bias', 'base_model.encoder.layer.8.attention.output.LayerNorm.bias', 'base_model.encoder.layer.19.attention.output.dense.bias', 'base_model.encoder.layer.4.attention.self.query.weight', 'base_model.encoder.layer.11.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.4.attention.output.LayerNorm.bias', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.14.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.15.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.13.attention.output.dense.weight', 'base_model.encoder.layer.16.output.LayerNorm.weight', 'base_model.encoder.layer.3.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.16.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.1.output.LayerNorm.bias', 'base_model.encoder.layer.2.output.LayerNorm.weight', 'base_model.encoder.layer.13.output.LayerNorm.bias', 'base_model.encoder.layer.5.attention.output.dense.weight', 'base_model.encoder.layer.3.attention.self.query.weight', 'base_model.encoder.layer.11.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.17.attention.self.value.weight', 'base_model.encoder.layer.18.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.1.attention.output.dense.weight', 'base_model.encoder.layer.22.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.0.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.12.attention.output.dense.weight', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.12.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.11.output.dense.bias', 'base_model.encoder.layer.15.attention.self.query.weight', 'base_model.encoder.layer.0.attention.output.dense.weight', 'base_model.encoder.layer.14.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.16.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.23.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.13.attention.self.key.weight', 'qa_outputs.weight', 'base_model.encoder.layer.2.output.dense.bias', 'base_model.encoder.layer.2.attention.output.LayerNorm.weight', 'base_model.encoder.layer.18.attention.self.key.bias', 'base_model.encoder.layer.9.output.LayerNorm.weight', 'base_model.encoder.layer.20.output.dense.weight', 'base_model.encoder.layer.22.output.dense.weight', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.21.intermediate.dense.weight', 'base_model.encoder.layer.17.attention.self.key.bias', 'base_model.encoder.layer.4.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.10.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.22.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.8.attention.self.value.weight', 'base_model.encoder.layer.1.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.16.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.2.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.7.output.dense.bias', 'base_model.encoder.layer.8.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.10.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.16.attention.self.query.bias', 'base_model.encoder.layer.21.output.LayerNorm.weight', 'base_model.encoder.layer.23.output.LayerNorm.weight', 'base_model.encoder.layer.4.attention.self.value.bias', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.embeddings.LayerNorm.bias', 'base_model.encoder.layer.10.attention.self.query.weight', 'base_model.encoder.layer.17.attention.output.dense.weight', 'base_model.encoder.layer.2.attention.self.key.weight', 'base_model.encoder.layer.11.attention.output.dense.bias', 'base_model.encoder.layer.13.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.8.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.22.output.LayerNorm.bias', 'base_model.encoder.layer.6.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.9.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.4.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.15.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.23.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.21.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.9.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.3.output.LayerNorm.bias', 'base_model.encoder.layer.9.attention.output.dense.weight', 'base_model.encoder.layer.15.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.19.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.22.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.3.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.19.output.dense.bias', 'base_model.encoder.layer.7.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.13.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.7.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.18.output.LayerNorm.weight', 'base_model.encoder.layer.5.output.dense.bias', 'base_model.encoder.layer.23.output.dense.weight', 'base_model.encoder.layer.13.attention.self.query.bias', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.5.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.14.attention.output.LayerNorm.weight', 'base_model.encoder.layer.17.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.5.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.19.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.12.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.10.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.17.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.8.intermediate.dense.weight', 'base_model.encoder.layer.8.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.23.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.15.attention.output.dense.bias', 'base_model.encoder.layer.16.output.dense.weight', 'base_model.encoder.layer.15.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.21.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.17.output.LayerNorm.bias', 'base_model.encoder.layer.14.intermediate.dense.weight', 'base_model.encoder.layer.19.attention.self.value.weight', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.18.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.20.output.adapters.ts.adapter_down.0.bias', 'base_model.embeddings.word_embeddings.weight', 'base_model.encoder.layer.0.output.dense.weight', 'base_model.encoder.layer.4.attention.output.dense.weight', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.8.attention.output.dense.weight', 'base_model.encoder.layer.3.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.13.attention.self.value.bias', 'base_model.encoder.layer.20.attention.self.query.bias', 'base_model.encoder.layer.18.attention.self.key.weight', 'base_model.encoder.layer.19.attention.self.key.weight', 'base_model.encoder.layer.17.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.23.attention.self.key.weight', 'base_model.encoder.layer.21.attention.self.key.weight', 'base_model.encoder.layer.17.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.0.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.6.attention.output.dense.bias', 'base_model.encoder.layer.10.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.7.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.22.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.2.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.7.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.23.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.8.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.4.attention.self.value.weight', 'base_model.encoder.layer.21.attention.self.query.bias', 'base_model.encoder.layer.22.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.20.intermediate.dense.weight', 'base_model.encoder.layer.10.attention.self.value.bias', 'base_model.encoder.layer.1.output.dense.bias', 'base_model.encoder.layer.11.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.17.intermediate.dense.bias', 'base_model.encoder.layer.1.attention.output.LayerNorm.bias', 'base_model.encoder.layer.15.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.0.attention.output.LayerNorm.weight', 'base_model.encoder.layer.3.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.8.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.9.attention.self.value.bias', 'base_model.encoder.layer.10.attention.output.dense.bias', 'base_model.encoder.layer.12.attention.self.query.bias', 'base_model.encoder.layer.10.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.15.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.19.intermediate.dense.weight', 'base_model.encoder.layer.23.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.9.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.3.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.value.weight']
- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of XLMRobertaModel were not initialized from the model checkpoint at /cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//squad/xlm-KG_LR8e-6_EPOCH2.0_maxlen384_batchsize4_gradacc4 and are newly initialized: ['encoder.layer.3.attention.self.value.weight', 'encoder.layer.11.attention.self.query.weight', 'encoder.layer.6.output.dense.bias', 'encoder.layer.23.output.dense.weight', 'encoder.layer.12.attention.output.dense.bias', 'encoder.layer.7.attention.output.LayerNorm.weight', 'encoder.layer.13.attention.output.dense.weight', 'encoder.layer.7.attention.self.key.weight', 'encoder.layer.14.attention.output.dense.weight', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.5.attention.self.value.weight', 'encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.10.output.LayerNorm.weight', 'encoder.layer.17.output.dense.bias', 'encoder.layer.7.output.dense.weight', 'encoder.layer.22.output.LayerNorm.bias', 'pooler.dense.bias', 'encoder.layer.12.attention.output.dense.weight', 'encoder.layer.20.output.LayerNorm.weight', 'encoder.layer.23.attention.self.key.bias', 'encoder.layer.21.attention.output.LayerNorm.weight', 'encoder.layer.19.output.dense.weight', 'encoder.layer.2.attention.output.LayerNorm.weight', 'encoder.layer.17.attention.self.value.bias', 'encoder.layer.0.attention.self.query.bias', 'encoder.layer.19.intermediate.dense.weight', 'encoder.layer.8.attention.self.value.weight', 'encoder.layer.11.output.LayerNorm.weight', 'encoder.layer.19.attention.output.dense.bias', 'encoder.layer.12.attention.self.key.bias', 'encoder.layer.6.output.LayerNorm.bias', 'encoder.layer.10.attention.self.key.bias', 'encoder.layer.5.attention.output.dense.bias', 'encoder.layer.16.attention.self.query.bias', 'encoder.layer.6.output.dense.weight', 'encoder.layer.0.attention.self.key.weight', 'encoder.layer.7.attention.output.dense.weight', 'encoder.layer.19.output.LayerNorm.weight', 'encoder.layer.13.attention.self.value.weight', 'encoder.layer.18.attention.self.value.weight', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.5.attention.self.key.weight', 'encoder.layer.18.attention.self.key.bias', 'encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.layer.1.output.dense.weight', 'encoder.layer.16.attention.output.dense.weight', 'encoder.layer.2.attention.output.dense.weight', 'encoder.layer.6.attention.output.dense.bias', 'encoder.layer.22.attention.output.LayerNorm.weight', 'encoder.layer.11.attention.output.dense.bias', 'encoder.layer.13.attention.output.LayerNorm.weight', 'encoder.layer.15.output.LayerNorm.bias', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.21.attention.self.query.weight', 'pooler.dense.weight', 'encoder.layer.20.attention.self.query.bias', 'encoder.layer.1.attention.self.value.bias', 'encoder.layer.13.output.dense.bias', 'encoder.layer.23.attention.self.value.bias', 'encoder.layer.7.attention.self.query.bias', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.6.attention.self.key.bias', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.4.attention.self.key.weight', 'encoder.layer.20.output.dense.weight', 'encoder.layer.3.attention.self.key.bias', 'encoder.layer.10.attention.self.value.weight', 'encoder.layer.17.attention.self.query.bias', 'encoder.layer.19.attention.self.key.bias', 'encoder.layer.19.output.LayerNorm.bias', 'encoder.layer.10.output.dense.bias', 'encoder.layer.13.attention.self.query.weight', 'encoder.layer.18.output.dense.bias', 'encoder.layer.9.attention.output.dense.bias', 'encoder.layer.13.intermediate.dense.bias', 'encoder.layer.16.output.dense.weight', 'encoder.layer.3.attention.self.key.weight', 'encoder.layer.4.attention.output.dense.weight', 'encoder.layer.15.attention.output.LayerNorm.weight', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.20.attention.output.dense.bias', 'encoder.layer.23.attention.self.query.weight', 'encoder.layer.0.attention.output.LayerNorm.weight', 'encoder.layer.12.attention.self.value.bias', 'encoder.layer.18.attention.self.query.weight', 'encoder.layer.9.attention.self.value.weight', 'encoder.layer.23.attention.output.LayerNorm.weight', 'encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.layer.17.attention.output.dense.weight', 'encoder.layer.23.intermediate.dense.weight', 'encoder.layer.5.output.LayerNorm.bias', 'encoder.layer.17.attention.self.value.weight', 'encoder.layer.3.attention.self.query.bias', 'encoder.layer.18.attention.self.key.weight', 'encoder.layer.16.attention.self.value.bias', 'encoder.layer.13.output.LayerNorm.bias', 'encoder.layer.20.attention.self.key.weight', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.7.attention.output.LayerNorm.bias', 'encoder.layer.2.attention.self.key.bias', 'encoder.layer.6.attention.output.LayerNorm.bias', 'encoder.layer.18.attention.output.dense.bias', 'encoder.layer.21.output.dense.bias', 'encoder.layer.18.intermediate.dense.weight', 'encoder.layer.0.output.dense.bias', 'encoder.layer.14.attention.self.value.bias', 'encoder.layer.22.output.LayerNorm.weight', 'encoder.layer.18.attention.output.LayerNorm.bias', 'encoder.layer.10.attention.self.key.weight', 'encoder.layer.4.attention.output.LayerNorm.weight', 'encoder.layer.8.attention.self.query.weight', 'encoder.layer.16.intermediate.dense.bias', 'encoder.layer.4.attention.output.LayerNorm.bias', 'encoder.layer.8.attention.output.dense.weight', 'encoder.layer.19.attention.output.LayerNorm.weight', 'encoder.layer.3.attention.self.query.weight', 'encoder.layer.13.intermediate.dense.weight', 'encoder.layer.13.attention.output.LayerNorm.bias', 'encoder.layer.8.attention.output.LayerNorm.bias', 'encoder.layer.12.output.LayerNorm.weight', 'encoder.layer.14.attention.self.query.bias', 'encoder.layer.15.attention.output.LayerNorm.bias', 'encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.layer.19.attention.output.LayerNorm.bias', 'encoder.layer.3.attention.output.dense.weight', 'encoder.layer.15.output.dense.weight', 'encoder.layer.0.attention.self.key.bias', 'encoder.layer.18.attention.output.LayerNorm.weight', 'encoder.layer.1.attention.output.dense.weight', 'encoder.layer.0.attention.self.value.weight', 'encoder.layer.0.attention.output.dense.bias', 'encoder.layer.17.intermediate.dense.weight', 'encoder.layer.5.output.dense.weight', 'encoder.layer.18.output.LayerNorm.bias', 'encoder.layer.5.attention.output.dense.weight', 'encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.layer.22.attention.self.value.weight', 'encoder.layer.1.attention.self.key.bias', 'encoder.layer.11.attention.output.LayerNorm.weight', 'encoder.layer.6.attention.self.key.weight', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.8.output.dense.weight', 'encoder.layer.11.attention.self.value.weight', 'encoder.layer.7.intermediate.dense.bias', 'encoder.layer.19.attention.self.value.bias', 'encoder.layer.4.attention.self.query.weight', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.1.attention.self.query.weight', 'encoder.layer.17.output.LayerNorm.bias', 'encoder.layer.15.attention.self.key.bias', 'encoder.layer.5.attention.self.query.bias', 'encoder.layer.20.attention.self.value.bias', 'encoder.layer.21.attention.self.value.weight', 'encoder.layer.13.output.LayerNorm.weight', 'encoder.layer.21.attention.self.query.bias', 'encoder.layer.18.attention.output.dense.weight', 'encoder.layer.1.output.dense.bias', 'encoder.layer.17.attention.output.LayerNorm.weight', 'encoder.layer.20.attention.self.key.bias', 'encoder.layer.14.output.dense.weight', 'encoder.layer.13.attention.self.key.weight', 'encoder.layer.2.output.dense.bias', 'encoder.layer.10.intermediate.dense.weight', 'encoder.layer.9.attention.output.LayerNorm.weight', 'encoder.layer.12.output.LayerNorm.bias', 'encoder.layer.14.intermediate.dense.weight', 'encoder.layer.23.output.LayerNorm.bias', 'encoder.layer.12.output.dense.weight', 'encoder.layer.23.attention.self.query.bias', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.16.attention.self.query.weight', 'encoder.layer.17.output.dense.weight', 'encoder.layer.4.output.dense.bias', 'encoder.layer.17.attention.output.dense.bias', 'embeddings.position_embeddings.weight', 'encoder.layer.1.attention.self.query.bias', 'encoder.layer.12.attention.self.query.bias', 'encoder.layer.2.attention.self.value.bias', 'encoder.layer.2.attention.self.query.weight', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.12.attention.output.LayerNorm.bias', 'encoder.layer.17.attention.self.key.bias', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.8.output.LayerNorm.bias', 'encoder.layer.23.output.LayerNorm.weight', 'encoder.layer.9.output.dense.weight', 'encoder.layer.15.attention.output.dense.weight', 'encoder.layer.14.intermediate.dense.bias', 'encoder.layer.10.attention.output.LayerNorm.bias', 'encoder.layer.6.attention.self.query.weight', 'encoder.layer.14.attention.output.dense.bias', 'encoder.layer.9.output.LayerNorm.weight', 'encoder.layer.19.attention.self.query.weight', 'encoder.layer.17.output.LayerNorm.weight', 'encoder.layer.8.attention.output.dense.bias', 'encoder.layer.20.attention.output.dense.weight', 'encoder.layer.11.attention.self.query.bias', 'encoder.layer.18.output.dense.weight', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.19.output.dense.bias', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.14.attention.self.key.weight', 'encoder.layer.6.attention.output.LayerNorm.weight', 'encoder.layer.6.attention.self.value.weight', 'encoder.layer.18.output.LayerNorm.weight', 'encoder.layer.1.attention.self.key.weight', 'encoder.layer.22.attention.self.key.bias', 'encoder.layer.9.attention.output.LayerNorm.bias', 'encoder.layer.10.attention.self.value.bias', 'encoder.layer.3.output.dense.weight', 'encoder.layer.18.attention.self.value.bias', 'encoder.layer.7.attention.self.value.bias', 'encoder.layer.21.attention.output.dense.bias', 'encoder.layer.5.attention.self.query.weight', 'encoder.layer.2.output.LayerNorm.weight', 'embeddings.LayerNorm.weight', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.22.output.dense.bias', 'encoder.layer.4.output.dense.weight', 'encoder.layer.6.attention.self.query.bias', 'encoder.layer.14.attention.self.value.weight', 'encoder.layer.21.intermediate.dense.weight', 'encoder.layer.2.attention.output.dense.bias', 'encoder.layer.14.attention.self.key.bias', 'encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.15.attention.output.dense.bias', 'encoder.layer.16.intermediate.dense.weight', 'encoder.layer.12.attention.self.query.weight', 'encoder.layer.7.output.LayerNorm.bias', 'encoder.layer.22.attention.self.key.weight', 'embeddings.word_embeddings.weight', 'encoder.layer.7.attention.output.dense.bias', 'encoder.layer.8.attention.output.LayerNorm.weight', 'encoder.layer.21.output.LayerNorm.bias', 'encoder.layer.0.attention.self.value.bias', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.11.attention.self.value.bias', 'encoder.layer.14.output.LayerNorm.bias', 'encoder.layer.1.attention.output.LayerNorm.weight', 'encoder.layer.8.attention.self.value.bias', 'embeddings.LayerNorm.bias', 'encoder.layer.21.attention.output.dense.weight', 'encoder.layer.0.attention.self.query.weight', 'encoder.layer.11.output.dense.bias', 'encoder.layer.22.attention.self.value.bias', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.16.attention.output.dense.bias', 'encoder.layer.3.attention.self.value.bias', 'encoder.layer.10.output.dense.weight', 'encoder.layer.18.attention.self.query.bias', 'encoder.layer.9.attention.self.query.weight', 'encoder.layer.22.attention.output.dense.weight', 'encoder.layer.7.output.LayerNorm.weight', 'encoder.layer.16.attention.self.key.weight', 'encoder.layer.21.attention.self.key.weight', 'encoder.layer.23.output.dense.bias', 'encoder.layer.16.attention.self.key.bias', 'encoder.layer.3.attention.output.dense.bias', 'encoder.layer.11.attention.self.key.bias', 'encoder.layer.12.attention.self.value.weight', 'encoder.layer.11.attention.output.dense.weight', 'encoder.layer.15.attention.self.query.weight', 'encoder.layer.20.attention.output.LayerNorm.bias', 'encoder.layer.5.attention.output.LayerNorm.weight', 'encoder.layer.10.output.LayerNorm.bias', 'encoder.layer.4.attention.self.value.weight', 'encoder.layer.9.output.dense.bias', 'encoder.layer.15.intermediate.dense.weight', 'encoder.layer.23.attention.output.dense.weight', 'encoder.layer.23.intermediate.dense.bias', 'encoder.layer.9.output.LayerNorm.bias', 'encoder.layer.20.intermediate.dense.weight', 'encoder.layer.22.output.dense.weight', 'encoder.layer.22.attention.self.query.weight', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.15.output.LayerNorm.weight', 'encoder.layer.14.output.dense.bias', 'encoder.layer.21.intermediate.dense.bias', 'encoder.layer.20.attention.self.query.weight', 'encoder.layer.14.attention.self.query.weight', 'encoder.layer.17.intermediate.dense.bias', 'encoder.layer.15.attention.self.key.weight', 'encoder.layer.6.attention.output.dense.weight', 'encoder.layer.0.output.dense.weight', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.17.attention.self.query.weight', 'encoder.layer.7.attention.self.query.weight', 'encoder.layer.19.intermediate.dense.bias', 'encoder.layer.5.attention.self.key.bias', 'encoder.layer.4.attention.self.key.bias', 'encoder.layer.12.output.dense.bias', 'encoder.layer.2.attention.self.key.weight', 'encoder.layer.21.attention.self.key.bias', 'encoder.layer.5.output.dense.bias', 'encoder.layer.19.attention.self.value.weight', 'encoder.layer.9.attention.output.dense.weight', 'encoder.layer.11.output.LayerNorm.bias', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.15.attention.self.value.weight', 'encoder.layer.1.attention.self.value.weight', 'encoder.layer.12.intermediate.dense.bias', 'encoder.layer.16.output.LayerNorm.weight', 'encoder.layer.2.attention.output.LayerNorm.bias', 'encoder.layer.22.intermediate.dense.weight', 'encoder.layer.19.attention.output.dense.weight', 'encoder.layer.11.attention.self.key.weight', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.15.attention.self.query.bias', 'encoder.layer.16.attention.output.LayerNorm.bias', 'encoder.layer.17.attention.self.key.weight', 'encoder.layer.4.attention.self.value.bias', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.7.attention.self.key.bias', 'encoder.layer.0.attention.output.dense.weight', 'embeddings.token_type_embeddings.weight', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.23.attention.output.LayerNorm.bias', 'encoder.layer.8.attention.self.query.bias', 'encoder.layer.7.attention.self.value.weight', 'encoder.layer.22.attention.output.LayerNorm.bias', 'encoder.layer.10.attention.self.query.weight', 'encoder.layer.20.output.dense.bias', 'encoder.layer.10.attention.self.query.bias', 'encoder.layer.23.attention.output.dense.bias', 'encoder.layer.2.output.dense.weight', 'encoder.layer.22.attention.output.dense.bias', 'encoder.layer.2.attention.self.query.bias', 'encoder.layer.12.attention.output.LayerNorm.weight', 'encoder.layer.9.attention.self.value.bias', 'encoder.layer.8.output.dense.bias', 'encoder.layer.13.attention.self.query.bias', 'encoder.layer.15.attention.self.value.bias', 'encoder.layer.4.attention.output.dense.bias', 'encoder.layer.20.attention.self.value.weight', 'encoder.layer.10.attention.output.LayerNorm.weight', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.16.output.LayerNorm.bias', 'encoder.layer.8.attention.self.key.weight', 'encoder.layer.14.attention.output.LayerNorm.weight', 'encoder.layer.14.output.LayerNorm.weight', 'encoder.layer.10.attention.output.dense.bias', 'encoder.layer.18.intermediate.dense.bias', 'encoder.layer.20.attention.output.LayerNorm.weight', 'encoder.layer.8.output.LayerNorm.weight', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.8.attention.self.key.bias', 'encoder.layer.23.attention.self.value.weight', 'encoder.layer.21.attention.self.value.bias', 'encoder.layer.3.output.dense.bias', 'encoder.layer.9.attention.self.key.bias', 'encoder.layer.22.intermediate.dense.bias', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.13.attention.output.dense.bias', 'encoder.layer.19.attention.self.key.weight', 'encoder.layer.15.output.dense.bias', 'encoder.layer.16.output.dense.bias', 'encoder.layer.17.attention.output.LayerNorm.bias', 'encoder.layer.13.attention.self.key.bias', 'encoder.layer.20.output.LayerNorm.bias', 'encoder.layer.9.attention.self.query.bias', 'encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.layer.23.attention.self.key.weight', 'encoder.layer.12.attention.self.key.weight', 'encoder.layer.10.attention.output.dense.weight', 'encoder.layer.13.attention.self.value.bias', 'encoder.layer.15.intermediate.dense.bias', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.9.attention.self.key.weight', 'encoder.layer.5.attention.self.value.bias', 'encoder.layer.7.output.dense.bias', 'encoder.layer.13.output.dense.weight', 'encoder.layer.16.attention.self.value.weight', 'encoder.layer.6.attention.self.value.bias', 'encoder.layer.22.attention.self.query.bias', 'encoder.layer.2.attention.self.value.weight', 'encoder.layer.4.attention.self.query.bias', 'encoder.layer.16.attention.output.LayerNorm.weight', 'encoder.layer.12.intermediate.dense.weight', 'encoder.layer.20.intermediate.dense.bias', 'encoder.layer.14.attention.output.LayerNorm.bias', 'encoder.layer.1.attention.output.dense.bias', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.21.output.dense.weight', 'encoder.layer.19.attention.self.query.bias', 'encoder.layer.11.output.dense.weight', 'encoder.layer.21.output.LayerNorm.weight', 'encoder.layer.21.attention.output.LayerNorm.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Overwriting existing adapter 'ep'.
Overwriting existing adapter 'tp'.
Overwriting existing adapter 'es'.
Overwriting existing adapter 'ts'.
Overwriting existing adapter fusion module 'ep,tp,es,ts'
05/09/2022 20:15:27 - INFO - __main__ -   lang2id = None
05/09/2022 20:15:31 - INFO - __main__ -   Training/evaluation parameters Namespace(adam_epsilon=1e-08, cache_dir='', config_name='', data_dir=None, device=device(type='cuda'), do_eval=True, do_lower_case=False, do_train=False, doc_stride=128, eval_all_checkpoints=False, eval_lang='hi', evaluate_during_training=False, fp16=False, fp16_opt_level='O1', gradient_accumulation_steps=1, learning_rate=5e-05, local_rank=-1, logging_steps=50, max_answer_length=30, max_grad_norm=1.0, max_query_length=64, max_seq_length=384, max_steps=-1, model_name='xlm-KG', model_name_or_path='/cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//squad/xlm-KG_LR8e-6_EPOCH2.0_maxlen384_batchsize4_gradacc4', model_type='xlm', modelkg_dir='/cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/adapter/xlmr_adapter', n_best_size=20, n_gpu=1, no_cuda=False, null_score_diff_threshold=0.0, num_train_epochs=3.0, output_dir='/cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//squad/xlm-KG_LR8e-6_EPOCH2.0_maxlen384_batchsize4_gradacc4/predictions/xquad/', overwrite_cache=False, overwrite_output_dir=False, per_gpu_eval_batch_size=8, per_gpu_train_batch_size=8, predict_file='/cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/download//xquad//xquad.hi.json', save_steps=50, seed=42, server_ip='', server_port='', threads=1, tokenizer_name='', train_file=None, train_lang='en', verbose_logging=False, version_2_with_negative=False, warmup_steps=0, weight_decay=0.0)
05/09/2022 20:15:31 - INFO - __main__ -   Loading checkpoint /cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//squad/xlm-KG_LR8e-6_EPOCH2.0_maxlen384_batchsize4_gradacc4 for evaluation
05/09/2022 20:15:31 - INFO - __main__ -   Evaluate the following checkpoints: ['/cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//squad/xlm-KG_LR8e-6_EPOCH2.0_maxlen384_batchsize4_gradacc4']
Some weights of the model checkpoint at /cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//squad/xlm-KG_LR8e-6_EPOCH2.0_maxlen384_batchsize4_gradacc4 were not used when initializing XLMRobertaModel: ['base_model.encoder.layer.20.attention.self.query.weight', 'base_model.encoder.layer.3.attention.self.value.bias', 'base_model.pooler.dense.weight', 'base_model.encoder.layer.4.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.7.attention.self.query.weight', 'base_model.encoder.layer.19.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.12.attention.output.dense.bias', 'base_model.encoder.layer.11.attention.output.LayerNorm.weight', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.8.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.5.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.9.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.18.output.dense.bias', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.19.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.11.attention.self.key.bias', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.1.output.dense.weight', 'base_model.encoder.layer.6.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.6.intermediate.dense.bias', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.6.output.LayerNorm.weight', 'base_model.encoder.layer.18.attention.output.dense.weight', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.21.output.LayerNorm.bias', 'base_model.encoder.layer.10.attention.output.LayerNorm.weight', 'base_model.encoder.layer.13.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.5.attention.self.value.bias', 'base_model.encoder.layer.6.attention.self.query.weight', 'base_model.encoder.layer.17.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.13.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.4.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.2.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.7.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.2.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.9.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.10.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.4.attention.self.key.weight', 'base_model.encoder.layer.11.intermediate.dense.bias', 'base_model.encoder.layer.18.attention.output.LayerNorm.weight', 'base_model.encoder.layer.15.output.LayerNorm.bias', 'base_model.encoder.layer.21.output.dense.bias', 'base_model.encoder.layer.22.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.15.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.22.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.0.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.23.output.LayerNorm.bias', 'base_model.encoder.layer.8.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.8.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.11.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.5.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.16.output.LayerNorm.bias', 'base_model.encoder.layer.22.attention.self.key.bias', 'base_model.encoder.layer.23.attention.output.LayerNorm.weight', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.9.attention.self.query.weight', 'base_model.encoder.layer.20.output.LayerNorm.weight', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.20.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.15.attention.output.dense.weight', 'base_model.encoder.layer.15.attention.output.LayerNorm.bias', 'base_model.encoder.layer.15.output.LayerNorm.weight', 'base_model.encoder.layer.16.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.14.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.5.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.22.attention.output.dense.bias', 'base_model.encoder.layer.23.attention.output.dense.bias', 'base_model.encoder.layer.0.output.dense.bias', 'base_model.encoder.layer.17.attention.self.key.weight', 'base_model.encoder.layer.9.attention.self.value.weight', 'base_model.encoder.layer.13.attention.self.query.weight', 'base_model.encoder.layer.18.attention.output.dense.bias', 'base_model.encoder.layer.19.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.16.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.5.attention.self.key.weight', 'base_model.encoder.layer.0.attention.self.key.weight', 'base_model.encoder.layer.4.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.11.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.18.output.dense.weight', 'base_model.encoder.layer.12.attention.output.LayerNorm.bias', 'base_model.encoder.layer.0.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.16.output.adapters.ts.adapter_up.bias', 'base_model.pooler.dense.bias', 'base_model.encoder.layer.19.attention.output.LayerNorm.bias', 'base_model.encoder.layer.6.attention.output.LayerNorm.weight', 'base_model.encoder.layer.2.attention.output.dense.bias', 'base_model.encoder.layer.16.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.21.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.22.output.LayerNorm.weight', 'base_model.encoder.layer.19.output.dense.weight', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.6.attention.self.query.bias', 'base_model.encoder.layer.20.output.adapters.es.adapter_down.0.weight', 'qa_outputs.bias', 'base_model.encoder.layer.7.output.LayerNorm.weight', 'base_model.encoder.layer.8.output.LayerNorm.weight', 'base_model.encoder.layer.14.intermediate.dense.bias', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.6.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.10.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.13.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.14.output.LayerNorm.weight', 'base_model.encoder.layer.10.attention.self.value.weight', 'base_model.encoder.layer.3.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.13.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.14.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.15.output.dense.bias', 'base_model.encoder.layer.2.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.14.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.12.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.21.attention.output.dense.weight', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.7.attention.output.dense.weight', 'base_model.encoder.layer.8.attention.self.key.weight', 'base_model.encoder.layer.17.output.LayerNorm.weight', 'base_model.encoder.layer.20.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.1.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.0.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.14.attention.output.dense.bias', 'base_model.encoder.layer.5.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.4.attention.self.query.bias', 'base_model.encoder.layer.20.attention.self.value.weight', 'base_model.encoder.layer.3.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.5.attention.self.query.weight', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.12.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.11.attention.self.query.weight', 'base_model.encoder.layer.11.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.15.output.dense.weight', 'base_model.encoder.layer.17.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.4.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.9.attention.self.query.bias', 'base_model.encoder.layer.12.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.19.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.22.intermediate.dense.weight', 'base_model.encoder.layer.2.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.11.output.LayerNorm.bias', 'base_model.encoder.layer.14.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.12.attention.self.value.bias', 'base_model.encoder.layer.18.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.7.intermediate.dense.bias', 'base_model.encoder.layer.18.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.23.intermediate.dense.weight', 'base_model.encoder.layer.22.output.dense.bias', 'base_model.encoder.layer.9.attention.output.dense.bias', 'base_model.encoder.layer.15.attention.self.key.bias', 'base_model.encoder.layer.22.attention.self.value.bias', 'base_model.embeddings.LayerNorm.weight', 'base_model.encoder.layer.2.attention.output.dense.weight', 'base_model.encoder.layer.12.attention.self.key.weight', 'base_model.encoder.layer.21.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.7.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.9.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.18.attention.self.query.bias', 'base_model.encoder.layer.10.intermediate.dense.bias', 'base_model.encoder.layer.13.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.14.output.dense.bias', 'base_model.encoder.layer.15.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.10.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.1.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.10.attention.output.LayerNorm.bias', 'base_model.embeddings.position_embeddings.weight', 'base_model.encoder.layer.1.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.5.output.LayerNorm.weight', 'base_model.encoder.layer.10.output.LayerNorm.weight', 'base_model.encoder.layer.0.attention.output.LayerNorm.bias', 'base_model.encoder.layer.4.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.7.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.7.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.22.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.21.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.23.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.12.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.16.attention.self.value.weight', 'base_model.encoder.layer.4.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.1.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.21.attention.output.LayerNorm.weight', 'base_model.encoder.layer.3.attention.output.dense.bias', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.21.attention.self.value.bias', 'base_model.encoder.layer.19.attention.self.query.bias', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.18.attention.self.value.bias', 'base_model.encoder.layer.4.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.5.attention.self.value.weight', 'base_model.encoder.layer.9.attention.output.LayerNorm.bias', 'base_model.encoder.layer.5.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.16.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.7.attention.self.value.weight', 'base_model.encoder.layer.19.intermediate.dense.bias', 'base_model.encoder.layer.5.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.16.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.22.attention.output.LayerNorm.bias', 'base_model.encoder.layer.23.attention.self.value.weight', 'base_model.encoder.layer.9.output.dense.weight', 'base_model.encoder.layer.16.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.15.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.23.attention.self.value.bias', 'base_model.encoder.layer.4.output.LayerNorm.weight', 'base_model.encoder.layer.9.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.11.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.3.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.0.intermediate.dense.weight', 'base_model.encoder.layer.5.attention.self.key.bias', 'base_model.encoder.layer.22.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.13.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.20.attention.output.LayerNorm.weight', 'base_model.encoder.layer.0.attention.self.query.weight', 'base_model.encoder.layer.2.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.13.output.dense.bias', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.11.output.LayerNorm.weight', 'base_model.encoder.layer.0.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.7.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.12.attention.output.LayerNorm.weight', 'base_model.encoder.layer.18.intermediate.dense.weight', 'base_model.encoder.layer.17.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.9.output.LayerNorm.bias', 'base_model.encoder.layer.6.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.18.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.9.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.11.attention.self.key.weight', 'base_model.encoder.layer.12.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.18.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.17.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.11.intermediate.dense.weight', 'base_model.encoder.layer.20.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.23.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.4.attention.self.key.bias', 'base_model.encoder.layer.8.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.16.intermediate.dense.weight', 'base_model.encoder.layer.1.attention.output.dense.bias', 'base_model.encoder.layer.7.output.dense.weight', 'base_model.encoder.layer.6.output.LayerNorm.bias', 'base_model.encoder.layer.22.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.18.attention.self.value.weight', 'base_model.encoder.layer.9.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.11.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.1.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.5.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.13.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.16.attention.self.query.weight', 'base_model.encoder.layer.3.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.1.attention.self.value.weight', 'base_model.encoder.layer.23.attention.output.dense.weight', 'base_model.encoder.layer.6.intermediate.dense.weight', 'base_model.encoder.layer.2.intermediate.dense.bias', 'base_model.encoder.layer.12.attention.self.query.weight', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.15.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.18.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.20.intermediate.dense.bias', 'base_model.encoder.layer.15.attention.output.LayerNorm.weight', 'base_model.encoder.layer.7.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.18.attention.output.LayerNorm.bias', 'base_model.encoder.layer.14.attention.self.query.bias', 'base_model.encoder.layer.17.attention.output.LayerNorm.bias', 'base_model.encoder.layer.19.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.22.attention.output.LayerNorm.weight', 'base_model.encoder.layer.23.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.20.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.3.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.9.intermediate.dense.bias', 'base_model.encoder.layer.11.attention.self.value.bias', 'base_model.encoder.layer.12.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.21.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.6.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.23.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.5.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.2.output.dense.weight', 'base_model.encoder.layer.18.intermediate.dense.bias', 'base_model.encoder.layer.2.output.LayerNorm.bias', 'base_model.encoder.layer.1.intermediate.dense.weight', 'base_model.encoder.layer.23.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.8.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.16.attention.self.key.weight', 'base_model.encoder.layer.22.intermediate.dense.bias', 'base_model.encoder.layer.1.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.8.output.LayerNorm.bias', 'base_model.encoder.layer.21.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.4.output.dense.weight', 'base_model.encoder.layer.1.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.16.attention.output.LayerNorm.weight', 'base_model.encoder.layer.9.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.6.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.14.attention.self.key.bias', 'base_model.encoder.layer.18.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.22.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.10.attention.output.dense.weight', 'base_model.encoder.layer.21.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.8.attention.self.query.bias', 'base_model.encoder.layer.7.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.3.intermediate.dense.weight', 'base_model.encoder.layer.5.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.14.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.19.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.12.intermediate.dense.weight', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.2.attention.self.query.bias', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.8.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.12.output.dense.bias', 'base_model.encoder.layer.13.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.6.attention.output.dense.weight', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.19.attention.self.key.bias', 'base_model.encoder.layer.8.attention.self.query.weight', 'base_model.encoder.layer.1.attention.self.value.bias', 'base_model.encoder.layer.6.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.7.attention.self.query.bias', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.19.attention.output.dense.weight', 'base_model.encoder.layer.17.attention.self.query.weight', 'base_model.encoder.layer.5.output.LayerNorm.bias', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.23.attention.self.query.weight', 'base_model.encoder.layer.21.attention.output.dense.bias', 'base_model.encoder.layer.10.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.23.intermediate.dense.bias', 'base_model.encoder.layer.20.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.2.attention.self.key.bias', 'base_model.encoder.layer.9.attention.self.key.bias', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.21.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.21.output.dense.weight', 'base_model.encoder.layer.20.output.LayerNorm.bias', 'base_model.encoder.layer.6.attention.self.value.weight', 'base_model.encoder.layer.5.output.dense.weight', 'base_model.encoder.layer.17.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.3.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.6.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.17.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.16.intermediate.dense.bias', 'base_model.encoder.layer.14.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.20.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.0.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.17.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.16.output.dense.bias', 'base_model.encoder.layer.7.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.19.output.LayerNorm.weight', 'base_model.encoder.layer.15.attention.self.value.weight', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.11.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.5.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.6.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.8.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.21.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.8.attention.self.value.bias', 'base_model.embeddings.token_type_embeddings.weight', 'base_model.encoder.layer.10.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.11.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.19.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.23.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.2.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.5.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.6.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.9.attention.self.key.weight', 'base_model.encoder.layer.2.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.8.output.dense.weight', 'base_model.encoder.layer.13.attention.output.LayerNorm.weight', 'base_model.encoder.layer.10.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.6.output.dense.bias', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.4.intermediate.dense.bias', 'base_model.encoder.layer.10.output.dense.bias', 'base_model.encoder.layer.12.output.LayerNorm.bias', 'base_model.encoder.layer.7.attention.self.value.bias', 'base_model.encoder.layer.1.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.1.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.20.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.13.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.23.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.3.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.4.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.15.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.19.attention.self.value.bias', 'base_model.encoder.layer.4.output.dense.bias', 'base_model.encoder.layer.1.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.21.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.16.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.17.attention.self.query.bias', 'base_model.encoder.layer.14.output.dense.weight', 'base_model.encoder.layer.3.output.dense.bias', 'base_model.encoder.layer.13.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.3.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.10.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.21.intermediate.dense.bias', 'base_model.encoder.layer.3.attention.output.LayerNorm.weight', 'base_model.encoder.layer.21.attention.self.key.bias', 'base_model.encoder.layer.4.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.21.attention.output.LayerNorm.bias', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.16.attention.output.LayerNorm.bias', 'base_model.encoder.layer.2.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.23.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.14.output.LayerNorm.bias', 'base_model.encoder.layer.2.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.17.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.4.attention.output.LayerNorm.weight', 'base_model.encoder.layer.8.attention.self.key.bias', 'base_model.encoder.layer.19.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.18.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.2.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.12.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.14.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.19.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.19.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.18.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.1.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.1.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.9.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.10.attention.self.key.bias', 'base_model.encoder.layer.12.output.LayerNorm.weight', 'base_model.encoder.layer.0.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.0.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.13.attention.self.key.bias', 'base_model.encoder.layer.18.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.10.output.dense.weight', 'base_model.encoder.layer.20.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.14.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.13.intermediate.dense.weight', 'base_model.encoder.layer.16.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.17.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.22.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.0.attention.self.query.bias', 'base_model.encoder.layer.17.attention.self.value.bias', 'base_model.encoder.layer.18.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.21.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.0.attention.self.value.weight', 'base_model.encoder.layer.1.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.19.attention.output.LayerNorm.weight', 'base_model.encoder.layer.4.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.11.attention.output.LayerNorm.bias', 'base_model.encoder.layer.15.attention.self.query.bias', 'base_model.encoder.layer.1.attention.output.LayerNorm.weight', 'base_model.encoder.layer.19.output.LayerNorm.bias', 'base_model.encoder.layer.9.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.20.attention.output.dense.weight', 'base_model.encoder.layer.7.output.LayerNorm.bias', 'base_model.encoder.layer.3.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.6.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.0.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.8.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.13.output.dense.weight', 'base_model.encoder.layer.12.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.19.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.7.attention.self.key.bias', 'base_model.encoder.layer.13.attention.output.dense.bias', 'base_model.encoder.layer.14.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.21.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.23.attention.output.LayerNorm.bias', 'base_model.encoder.layer.8.attention.output.dense.bias', 'base_model.encoder.layer.13.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.18.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.15.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.22.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.5.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.20.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.6.attention.self.value.bias', 'base_model.embeddings.position_ids', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.20.attention.output.dense.bias', 'base_model.encoder.layer.15.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.0.attention.self.key.bias', 'base_model.encoder.layer.17.intermediate.dense.weight', 'base_model.encoder.layer.11.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.1.attention.self.key.bias', 'base_model.encoder.layer.4.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.13.output.LayerNorm.weight', 'base_model.encoder.layer.23.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.16.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.13.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.17.attention.output.dense.bias', 'base_model.encoder.layer.0.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.14.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.2.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.4.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.3.attention.self.query.bias', 'base_model.encoder.layer.12.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.15.intermediate.dense.bias', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.15.intermediate.dense.weight', 'base_model.encoder.layer.16.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.4.output.LayerNorm.bias', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.5.attention.output.dense.bias', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.12.attention.self.value.weight', 'base_model.encoder.layer.12.output.dense.weight', 'base_model.encoder.layer.13.attention.self.value.weight', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.12.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.7.attention.output.LayerNorm.bias', 'base_model.encoder.layer.10.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.14.attention.self.value.bias', 'base_model.encoder.layer.18.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.2.attention.self.value.bias', 'base_model.encoder.layer.15.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.22.attention.output.dense.weight', 'base_model.encoder.layer.0.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.0.output.LayerNorm.bias', 'base_model.encoder.layer.5.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.22.attention.self.value.weight', 'base_model.encoder.layer.2.intermediate.dense.weight', 'base_model.encoder.layer.14.attention.self.value.weight', 'base_model.encoder.layer.1.attention.self.query.weight', 'base_model.encoder.layer.2.attention.self.value.weight', 'base_model.encoder.layer.3.attention.self.key.bias', 'base_model.encoder.layer.0.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.6.attention.output.LayerNorm.bias', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.21.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.3.output.dense.weight', 'base_model.encoder.layer.8.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.20.attention.self.value.bias', 'base_model.encoder.layer.11.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.10.attention.self.query.bias', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.8.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.10.output.LayerNorm.bias', 'base_model.encoder.layer.12.intermediate.dense.bias', 'base_model.encoder.layer.8.attention.output.LayerNorm.weight', 'base_model.encoder.layer.2.attention.self.query.weight', 'base_model.encoder.layer.16.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.14.attention.self.key.weight', 'base_model.encoder.layer.9.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.22.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.11.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.16.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.1.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.10.attention.self.key.weight', 'base_model.encoder.layer.12.attention.self.key.bias', 'base_model.encoder.layer.3.intermediate.dense.bias', 'base_model.encoder.layer.20.output.dense.bias', 'base_model.encoder.layer.23.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.7.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.20.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.20.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.19.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.23.attention.self.query.bias', 'base_model.encoder.layer.20.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.8.output.dense.bias', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.11.attention.self.value.weight', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.17.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.13.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.0.attention.self.value.bias', 'base_model.encoder.layer.4.intermediate.dense.weight', 'base_model.encoder.layer.5.intermediate.dense.bias', 'base_model.encoder.layer.9.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.16.attention.self.key.bias', 'base_model.encoder.layer.21.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.11.attention.self.query.bias', 'base_model.encoder.layer.17.output.dense.bias', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.1.attention.self.query.bias', 'base_model.encoder.layer.9.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.22.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.6.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.9.attention.output.LayerNorm.weight', 'base_model.encoder.layer.10.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.19.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.12.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.13.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.15.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.18.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.4.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.18.attention.self.query.weight', 'base_model.encoder.layer.6.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.2.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.20.attention.self.key.bias', 'base_model.encoder.layer.1.attention.self.key.weight', 'base_model.encoder.layer.9.intermediate.dense.weight', 'base_model.encoder.layer.6.attention.self.key.weight', 'base_model.encoder.layer.6.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.16.attention.output.dense.weight', 'base_model.encoder.layer.11.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.7.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.15.attention.self.value.bias', 'base_model.encoder.layer.17.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.3.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.7.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.7.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.17.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.10.intermediate.dense.weight', 'base_model.encoder.layer.3.output.LayerNorm.weight', 'base_model.encoder.layer.14.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.19.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.7.attention.output.LayerNorm.weight', 'base_model.encoder.layer.14.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.3.attention.output.dense.weight', 'base_model.encoder.layer.5.attention.output.LayerNorm.weight', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.10.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.6.attention.self.key.bias', 'base_model.encoder.layer.13.attention.output.LayerNorm.bias', 'base_model.encoder.layer.18.output.LayerNorm.bias', 'base_model.encoder.layer.4.attention.output.dense.bias', 'base_model.encoder.layer.3.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.21.attention.self.value.weight', 'base_model.encoder.layer.3.attention.self.value.weight', 'base_model.encoder.layer.19.attention.self.query.weight', 'base_model.encoder.layer.7.attention.output.dense.bias', 'base_model.encoder.layer.1.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.12.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.11.attention.output.dense.weight', 'base_model.encoder.layer.22.attention.self.query.weight', 'base_model.encoder.layer.13.intermediate.dense.bias', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.23.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.6.output.dense.weight', 'base_model.encoder.layer.23.output.dense.bias', 'base_model.encoder.layer.1.intermediate.dense.bias', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.18.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.17.output.dense.weight', 'base_model.encoder.layer.17.attention.output.LayerNorm.weight', 'base_model.encoder.layer.22.attention.self.query.bias', 'base_model.encoder.layer.14.attention.output.LayerNorm.bias', 'base_model.encoder.layer.14.attention.self.query.weight', 'base_model.encoder.layer.11.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.22.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.3.attention.output.LayerNorm.bias', 'base_model.encoder.layer.15.attention.self.key.weight', 'base_model.encoder.layer.20.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.0.output.LayerNorm.weight', 'base_model.encoder.layer.21.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.0.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.1.output.LayerNorm.weight', 'base_model.encoder.layer.15.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.21.attention.self.query.weight', 'base_model.encoder.layer.4.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.14.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.2.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.10.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.3.attention.self.key.weight', 'base_model.encoder.layer.5.attention.output.LayerNorm.bias', 'base_model.encoder.layer.7.attention.self.key.weight', 'base_model.encoder.layer.12.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.20.attention.self.key.weight', 'base_model.encoder.layer.6.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.22.attention.self.key.weight', 'base_model.encoder.layer.5.intermediate.dense.weight', 'base_model.encoder.layer.16.attention.self.value.bias', 'base_model.encoder.layer.0.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.14.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.2.attention.output.LayerNorm.bias', 'base_model.encoder.layer.20.attention.output.LayerNorm.bias', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.0.intermediate.dense.bias', 'base_model.encoder.layer.0.attention.output.dense.bias', 'base_model.encoder.layer.23.attention.self.key.bias', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.0.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.11.output.dense.weight', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.11.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.8.intermediate.dense.bias', 'base_model.encoder.layer.12.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.20.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.5.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.9.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.8.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.6.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.7.intermediate.dense.weight', 'base_model.encoder.layer.9.output.dense.bias', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.16.attention.output.dense.bias', 'base_model.encoder.layer.2.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.14.attention.output.dense.weight', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.5.attention.self.query.bias', 'base_model.encoder.layer.8.attention.output.LayerNorm.bias', 'base_model.encoder.layer.19.attention.output.dense.bias', 'base_model.encoder.layer.4.attention.self.query.weight', 'base_model.encoder.layer.11.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.4.attention.output.LayerNorm.bias', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.14.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.15.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.13.attention.output.dense.weight', 'base_model.encoder.layer.16.output.LayerNorm.weight', 'base_model.encoder.layer.3.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.16.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.1.output.LayerNorm.bias', 'base_model.encoder.layer.2.output.LayerNorm.weight', 'base_model.encoder.layer.13.output.LayerNorm.bias', 'base_model.encoder.layer.5.attention.output.dense.weight', 'base_model.encoder.layer.3.attention.self.query.weight', 'base_model.encoder.layer.11.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.17.attention.self.value.weight', 'base_model.encoder.layer.18.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.1.attention.output.dense.weight', 'base_model.encoder.layer.22.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.0.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.12.attention.output.dense.weight', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.12.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.11.output.dense.bias', 'base_model.encoder.layer.15.attention.self.query.weight', 'base_model.encoder.layer.0.attention.output.dense.weight', 'base_model.encoder.layer.14.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.16.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.23.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.13.attention.self.key.weight', 'qa_outputs.weight', 'base_model.encoder.layer.2.output.dense.bias', 'base_model.encoder.layer.2.attention.output.LayerNorm.weight', 'base_model.encoder.layer.18.attention.self.key.bias', 'base_model.encoder.layer.9.output.LayerNorm.weight', 'base_model.encoder.layer.20.output.dense.weight', 'base_model.encoder.layer.22.output.dense.weight', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.21.intermediate.dense.weight', 'base_model.encoder.layer.17.attention.self.key.bias', 'base_model.encoder.layer.4.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.10.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.22.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.8.attention.self.value.weight', 'base_model.encoder.layer.1.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.16.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.2.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.7.output.dense.bias', 'base_model.encoder.layer.8.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.10.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.16.attention.self.query.bias', 'base_model.encoder.layer.21.output.LayerNorm.weight', 'base_model.encoder.layer.23.output.LayerNorm.weight', 'base_model.encoder.layer.4.attention.self.value.bias', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.embeddings.LayerNorm.bias', 'base_model.encoder.layer.10.attention.self.query.weight', 'base_model.encoder.layer.17.attention.output.dense.weight', 'base_model.encoder.layer.2.attention.self.key.weight', 'base_model.encoder.layer.11.attention.output.dense.bias', 'base_model.encoder.layer.13.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.8.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.22.output.LayerNorm.bias', 'base_model.encoder.layer.6.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.9.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.4.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.15.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.23.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.21.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.9.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.3.output.LayerNorm.bias', 'base_model.encoder.layer.9.attention.output.dense.weight', 'base_model.encoder.layer.15.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.19.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.22.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.3.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.19.output.dense.bias', 'base_model.encoder.layer.7.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.13.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.7.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.18.output.LayerNorm.weight', 'base_model.encoder.layer.5.output.dense.bias', 'base_model.encoder.layer.23.output.dense.weight', 'base_model.encoder.layer.13.attention.self.query.bias', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.5.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.14.attention.output.LayerNorm.weight', 'base_model.encoder.layer.17.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.5.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.19.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.12.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.10.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.17.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.8.intermediate.dense.weight', 'base_model.encoder.layer.8.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.23.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.15.attention.output.dense.bias', 'base_model.encoder.layer.16.output.dense.weight', 'base_model.encoder.layer.15.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.21.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.17.output.LayerNorm.bias', 'base_model.encoder.layer.14.intermediate.dense.weight', 'base_model.encoder.layer.19.attention.self.value.weight', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.18.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.20.output.adapters.ts.adapter_down.0.bias', 'base_model.embeddings.word_embeddings.weight', 'base_model.encoder.layer.0.output.dense.weight', 'base_model.encoder.layer.4.attention.output.dense.weight', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.8.attention.output.dense.weight', 'base_model.encoder.layer.3.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.13.attention.self.value.bias', 'base_model.encoder.layer.20.attention.self.query.bias', 'base_model.encoder.layer.18.attention.self.key.weight', 'base_model.encoder.layer.19.attention.self.key.weight', 'base_model.encoder.layer.17.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.23.attention.self.key.weight', 'base_model.encoder.layer.21.attention.self.key.weight', 'base_model.encoder.layer.17.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.0.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.6.attention.output.dense.bias', 'base_model.encoder.layer.10.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.7.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.22.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.2.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.7.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.23.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.8.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.4.attention.self.value.weight', 'base_model.encoder.layer.21.attention.self.query.bias', 'base_model.encoder.layer.22.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.20.intermediate.dense.weight', 'base_model.encoder.layer.10.attention.self.value.bias', 'base_model.encoder.layer.1.output.dense.bias', 'base_model.encoder.layer.11.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.17.intermediate.dense.bias', 'base_model.encoder.layer.1.attention.output.LayerNorm.bias', 'base_model.encoder.layer.15.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.0.attention.output.LayerNorm.weight', 'base_model.encoder.layer.3.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.8.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.9.attention.self.value.bias', 'base_model.encoder.layer.10.attention.output.dense.bias', 'base_model.encoder.layer.12.attention.self.query.bias', 'base_model.encoder.layer.10.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.15.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.19.intermediate.dense.weight', 'base_model.encoder.layer.23.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.9.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.3.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.value.weight']
- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of XLMRobertaModel were not initialized from the model checkpoint at /cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//squad/xlm-KG_LR8e-6_EPOCH2.0_maxlen384_batchsize4_gradacc4 and are newly initialized: ['encoder.layer.3.attention.self.value.weight', 'encoder.layer.11.attention.self.query.weight', 'encoder.layer.6.output.dense.bias', 'encoder.layer.23.output.dense.weight', 'encoder.layer.12.attention.output.dense.bias', 'encoder.layer.7.attention.output.LayerNorm.weight', 'encoder.layer.13.attention.output.dense.weight', 'encoder.layer.7.attention.self.key.weight', 'encoder.layer.14.attention.output.dense.weight', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.5.attention.self.value.weight', 'encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.10.output.LayerNorm.weight', 'encoder.layer.17.output.dense.bias', 'encoder.layer.7.output.dense.weight', 'encoder.layer.22.output.LayerNorm.bias', 'pooler.dense.bias', 'encoder.layer.12.attention.output.dense.weight', 'encoder.layer.20.output.LayerNorm.weight', 'encoder.layer.23.attention.self.key.bias', 'encoder.layer.21.attention.output.LayerNorm.weight', 'encoder.layer.19.output.dense.weight', 'encoder.layer.2.attention.output.LayerNorm.weight', 'encoder.layer.17.attention.self.value.bias', 'encoder.layer.0.attention.self.query.bias', 'encoder.layer.19.intermediate.dense.weight', 'encoder.layer.8.attention.self.value.weight', 'encoder.layer.11.output.LayerNorm.weight', 'encoder.layer.19.attention.output.dense.bias', 'encoder.layer.12.attention.self.key.bias', 'encoder.layer.6.output.LayerNorm.bias', 'encoder.layer.10.attention.self.key.bias', 'encoder.layer.5.attention.output.dense.bias', 'encoder.layer.16.attention.self.query.bias', 'encoder.layer.6.output.dense.weight', 'encoder.layer.0.attention.self.key.weight', 'encoder.layer.7.attention.output.dense.weight', 'encoder.layer.19.output.LayerNorm.weight', 'encoder.layer.13.attention.self.value.weight', 'encoder.layer.18.attention.self.value.weight', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.5.attention.self.key.weight', 'encoder.layer.18.attention.self.key.bias', 'encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.layer.1.output.dense.weight', 'encoder.layer.16.attention.output.dense.weight', 'encoder.layer.2.attention.output.dense.weight', 'encoder.layer.6.attention.output.dense.bias', 'encoder.layer.22.attention.output.LayerNorm.weight', 'encoder.layer.11.attention.output.dense.bias', 'encoder.layer.13.attention.output.LayerNorm.weight', 'encoder.layer.15.output.LayerNorm.bias', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.21.attention.self.query.weight', 'pooler.dense.weight', 'encoder.layer.20.attention.self.query.bias', 'encoder.layer.1.attention.self.value.bias', 'encoder.layer.13.output.dense.bias', 'encoder.layer.23.attention.self.value.bias', 'encoder.layer.7.attention.self.query.bias', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.6.attention.self.key.bias', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.4.attention.self.key.weight', 'encoder.layer.20.output.dense.weight', 'encoder.layer.3.attention.self.key.bias', 'encoder.layer.10.attention.self.value.weight', 'encoder.layer.17.attention.self.query.bias', 'encoder.layer.19.attention.self.key.bias', 'encoder.layer.19.output.LayerNorm.bias', 'encoder.layer.10.output.dense.bias', 'encoder.layer.13.attention.self.query.weight', 'encoder.layer.18.output.dense.bias', 'encoder.layer.9.attention.output.dense.bias', 'encoder.layer.13.intermediate.dense.bias', 'encoder.layer.16.output.dense.weight', 'encoder.layer.3.attention.self.key.weight', 'encoder.layer.4.attention.output.dense.weight', 'encoder.layer.15.attention.output.LayerNorm.weight', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.20.attention.output.dense.bias', 'encoder.layer.23.attention.self.query.weight', 'encoder.layer.0.attention.output.LayerNorm.weight', 'encoder.layer.12.attention.self.value.bias', 'encoder.layer.18.attention.self.query.weight', 'encoder.layer.9.attention.self.value.weight', 'encoder.layer.23.attention.output.LayerNorm.weight', 'encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.layer.17.attention.output.dense.weight', 'encoder.layer.23.intermediate.dense.weight', 'encoder.layer.5.output.LayerNorm.bias', 'encoder.layer.17.attention.self.value.weight', 'encoder.layer.3.attention.self.query.bias', 'encoder.layer.18.attention.self.key.weight', 'encoder.layer.16.attention.self.value.bias', 'encoder.layer.13.output.LayerNorm.bias', 'encoder.layer.20.attention.self.key.weight', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.7.attention.output.LayerNorm.bias', 'encoder.layer.2.attention.self.key.bias', 'encoder.layer.6.attention.output.LayerNorm.bias', 'encoder.layer.18.attention.output.dense.bias', 'encoder.layer.21.output.dense.bias', 'encoder.layer.18.intermediate.dense.weight', 'encoder.layer.0.output.dense.bias', 'encoder.layer.14.attention.self.value.bias', 'encoder.layer.22.output.LayerNorm.weight', 'encoder.layer.18.attention.output.LayerNorm.bias', 'encoder.layer.10.attention.self.key.weight', 'encoder.layer.4.attention.output.LayerNorm.weight', 'encoder.layer.8.attention.self.query.weight', 'encoder.layer.16.intermediate.dense.bias', 'encoder.layer.4.attention.output.LayerNorm.bias', 'encoder.layer.8.attention.output.dense.weight', 'encoder.layer.19.attention.output.LayerNorm.weight', 'encoder.layer.3.attention.self.query.weight', 'encoder.layer.13.intermediate.dense.weight', 'encoder.layer.13.attention.output.LayerNorm.bias', 'encoder.layer.8.attention.output.LayerNorm.bias', 'encoder.layer.12.output.LayerNorm.weight', 'encoder.layer.14.attention.self.query.bias', 'encoder.layer.15.attention.output.LayerNorm.bias', 'encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.layer.19.attention.output.LayerNorm.bias', 'encoder.layer.3.attention.output.dense.weight', 'encoder.layer.15.output.dense.weight', 'encoder.layer.0.attention.self.key.bias', 'encoder.layer.18.attention.output.LayerNorm.weight', 'encoder.layer.1.attention.output.dense.weight', 'encoder.layer.0.attention.self.value.weight', 'encoder.layer.0.attention.output.dense.bias', 'encoder.layer.17.intermediate.dense.weight', 'encoder.layer.5.output.dense.weight', 'encoder.layer.18.output.LayerNorm.bias', 'encoder.layer.5.attention.output.dense.weight', 'encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.layer.22.attention.self.value.weight', 'encoder.layer.1.attention.self.key.bias', 'encoder.layer.11.attention.output.LayerNorm.weight', 'encoder.layer.6.attention.self.key.weight', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.8.output.dense.weight', 'encoder.layer.11.attention.self.value.weight', 'encoder.layer.7.intermediate.dense.bias', 'encoder.layer.19.attention.self.value.bias', 'encoder.layer.4.attention.self.query.weight', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.1.attention.self.query.weight', 'encoder.layer.17.output.LayerNorm.bias', 'encoder.layer.15.attention.self.key.bias', 'encoder.layer.5.attention.self.query.bias', 'encoder.layer.20.attention.self.value.bias', 'encoder.layer.21.attention.self.value.weight', 'encoder.layer.13.output.LayerNorm.weight', 'encoder.layer.21.attention.self.query.bias', 'encoder.layer.18.attention.output.dense.weight', 'encoder.layer.1.output.dense.bias', 'encoder.layer.17.attention.output.LayerNorm.weight', 'encoder.layer.20.attention.self.key.bias', 'encoder.layer.14.output.dense.weight', 'encoder.layer.13.attention.self.key.weight', 'encoder.layer.2.output.dense.bias', 'encoder.layer.10.intermediate.dense.weight', 'encoder.layer.9.attention.output.LayerNorm.weight', 'encoder.layer.12.output.LayerNorm.bias', 'encoder.layer.14.intermediate.dense.weight', 'encoder.layer.23.output.LayerNorm.bias', 'encoder.layer.12.output.dense.weight', 'encoder.layer.23.attention.self.query.bias', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.16.attention.self.query.weight', 'encoder.layer.17.output.dense.weight', 'encoder.layer.4.output.dense.bias', 'encoder.layer.17.attention.output.dense.bias', 'embeddings.position_embeddings.weight', 'encoder.layer.1.attention.self.query.bias', 'encoder.layer.12.attention.self.query.bias', 'encoder.layer.2.attention.self.value.bias', 'encoder.layer.2.attention.self.query.weight', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.12.attention.output.LayerNorm.bias', 'encoder.layer.17.attention.self.key.bias', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.8.output.LayerNorm.bias', 'encoder.layer.23.output.LayerNorm.weight', 'encoder.layer.9.output.dense.weight', 'encoder.layer.15.attention.output.dense.weight', 'encoder.layer.14.intermediate.dense.bias', 'encoder.layer.10.attention.output.LayerNorm.bias', 'encoder.layer.6.attention.self.query.weight', 'encoder.layer.14.attention.output.dense.bias', 'encoder.layer.9.output.LayerNorm.weight', 'encoder.layer.19.attention.self.query.weight', 'encoder.layer.17.output.LayerNorm.weight', 'encoder.layer.8.attention.output.dense.bias', 'encoder.layer.20.attention.output.dense.weight', 'encoder.layer.11.attention.self.query.bias', 'encoder.layer.18.output.dense.weight', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.19.output.dense.bias', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.14.attention.self.key.weight', 'encoder.layer.6.attention.output.LayerNorm.weight', 'encoder.layer.6.attention.self.value.weight', 'encoder.layer.18.output.LayerNorm.weight', 'encoder.layer.1.attention.self.key.weight', 'encoder.layer.22.attention.self.key.bias', 'encoder.layer.9.attention.output.LayerNorm.bias', 'encoder.layer.10.attention.self.value.bias', 'encoder.layer.3.output.dense.weight', 'encoder.layer.18.attention.self.value.bias', 'encoder.layer.7.attention.self.value.bias', 'encoder.layer.21.attention.output.dense.bias', 'encoder.layer.5.attention.self.query.weight', 'encoder.layer.2.output.LayerNorm.weight', 'embeddings.LayerNorm.weight', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.22.output.dense.bias', 'encoder.layer.4.output.dense.weight', 'encoder.layer.6.attention.self.query.bias', 'encoder.layer.14.attention.self.value.weight', 'encoder.layer.21.intermediate.dense.weight', 'encoder.layer.2.attention.output.dense.bias', 'encoder.layer.14.attention.self.key.bias', 'encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.15.attention.output.dense.bias', 'encoder.layer.16.intermediate.dense.weight', 'encoder.layer.12.attention.self.query.weight', 'encoder.layer.7.output.LayerNorm.bias', 'encoder.layer.22.attention.self.key.weight', 'embeddings.word_embeddings.weight', 'encoder.layer.7.attention.output.dense.bias', 'encoder.layer.8.attention.output.LayerNorm.weight', 'encoder.layer.21.output.LayerNorm.bias', 'encoder.layer.0.attention.self.value.bias', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.11.attention.self.value.bias', 'encoder.layer.14.output.LayerNorm.bias', 'encoder.layer.1.attention.output.LayerNorm.weight', 'encoder.layer.8.attention.self.value.bias', 'embeddings.LayerNorm.bias', 'encoder.layer.21.attention.output.dense.weight', 'encoder.layer.0.attention.self.query.weight', 'encoder.layer.11.output.dense.bias', 'encoder.layer.22.attention.self.value.bias', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.16.attention.output.dense.bias', 'encoder.layer.3.attention.self.value.bias', 'encoder.layer.10.output.dense.weight', 'encoder.layer.18.attention.self.query.bias', 'encoder.layer.9.attention.self.query.weight', 'encoder.layer.22.attention.output.dense.weight', 'encoder.layer.7.output.LayerNorm.weight', 'encoder.layer.16.attention.self.key.weight', 'encoder.layer.21.attention.self.key.weight', 'encoder.layer.23.output.dense.bias', 'encoder.layer.16.attention.self.key.bias', 'encoder.layer.3.attention.output.dense.bias', 'encoder.layer.11.attention.self.key.bias', 'encoder.layer.12.attention.self.value.weight', 'encoder.layer.11.attention.output.dense.weight', 'encoder.layer.15.attention.self.query.weight', 'encoder.layer.20.attention.output.LayerNorm.bias', 'encoder.layer.5.attention.output.LayerNorm.weight', 'encoder.layer.10.output.LayerNorm.bias', 'encoder.layer.4.attention.self.value.weight', 'encoder.layer.9.output.dense.bias', 'encoder.layer.15.intermediate.dense.weight', 'encoder.layer.23.attention.output.dense.weight', 'encoder.layer.23.intermediate.dense.bias', 'encoder.layer.9.output.LayerNorm.bias', 'encoder.layer.20.intermediate.dense.weight', 'encoder.layer.22.output.dense.weight', 'encoder.layer.22.attention.self.query.weight', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.15.output.LayerNorm.weight', 'encoder.layer.14.output.dense.bias', 'encoder.layer.21.intermediate.dense.bias', 'encoder.layer.20.attention.self.query.weight', 'encoder.layer.14.attention.self.query.weight', 'encoder.layer.17.intermediate.dense.bias', 'encoder.layer.15.attention.self.key.weight', 'encoder.layer.6.attention.output.dense.weight', 'encoder.layer.0.output.dense.weight', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.17.attention.self.query.weight', 'encoder.layer.7.attention.self.query.weight', 'encoder.layer.19.intermediate.dense.bias', 'encoder.layer.5.attention.self.key.bias', 'encoder.layer.4.attention.self.key.bias', 'encoder.layer.12.output.dense.bias', 'encoder.layer.2.attention.self.key.weight', 'encoder.layer.21.attention.self.key.bias', 'encoder.layer.5.output.dense.bias', 'encoder.layer.19.attention.self.value.weight', 'encoder.layer.9.attention.output.dense.weight', 'encoder.layer.11.output.LayerNorm.bias', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.15.attention.self.value.weight', 'encoder.layer.1.attention.self.value.weight', 'encoder.layer.12.intermediate.dense.bias', 'encoder.layer.16.output.LayerNorm.weight', 'encoder.layer.2.attention.output.LayerNorm.bias', 'encoder.layer.22.intermediate.dense.weight', 'encoder.layer.19.attention.output.dense.weight', 'encoder.layer.11.attention.self.key.weight', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.15.attention.self.query.bias', 'encoder.layer.16.attention.output.LayerNorm.bias', 'encoder.layer.17.attention.self.key.weight', 'encoder.layer.4.attention.self.value.bias', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.7.attention.self.key.bias', 'encoder.layer.0.attention.output.dense.weight', 'embeddings.token_type_embeddings.weight', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.23.attention.output.LayerNorm.bias', 'encoder.layer.8.attention.self.query.bias', 'encoder.layer.7.attention.self.value.weight', 'encoder.layer.22.attention.output.LayerNorm.bias', 'encoder.layer.10.attention.self.query.weight', 'encoder.layer.20.output.dense.bias', 'encoder.layer.10.attention.self.query.bias', 'encoder.layer.23.attention.output.dense.bias', 'encoder.layer.2.output.dense.weight', 'encoder.layer.22.attention.output.dense.bias', 'encoder.layer.2.attention.self.query.bias', 'encoder.layer.12.attention.output.LayerNorm.weight', 'encoder.layer.9.attention.self.value.bias', 'encoder.layer.8.output.dense.bias', 'encoder.layer.13.attention.self.query.bias', 'encoder.layer.15.attention.self.value.bias', 'encoder.layer.4.attention.output.dense.bias', 'encoder.layer.20.attention.self.value.weight', 'encoder.layer.10.attention.output.LayerNorm.weight', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.16.output.LayerNorm.bias', 'encoder.layer.8.attention.self.key.weight', 'encoder.layer.14.attention.output.LayerNorm.weight', 'encoder.layer.14.output.LayerNorm.weight', 'encoder.layer.10.attention.output.dense.bias', 'encoder.layer.18.intermediate.dense.bias', 'encoder.layer.20.attention.output.LayerNorm.weight', 'encoder.layer.8.output.LayerNorm.weight', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.8.attention.self.key.bias', 'encoder.layer.23.attention.self.value.weight', 'encoder.layer.21.attention.self.value.bias', 'encoder.layer.3.output.dense.bias', 'encoder.layer.9.attention.self.key.bias', 'encoder.layer.22.intermediate.dense.bias', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.13.attention.output.dense.bias', 'encoder.layer.19.attention.self.key.weight', 'encoder.layer.15.output.dense.bias', 'encoder.layer.16.output.dense.bias', 'encoder.layer.17.attention.output.LayerNorm.bias', 'encoder.layer.13.attention.self.key.bias', 'encoder.layer.20.output.LayerNorm.bias', 'encoder.layer.9.attention.self.query.bias', 'encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.layer.23.attention.self.key.weight', 'encoder.layer.12.attention.self.key.weight', 'encoder.layer.10.attention.output.dense.weight', 'encoder.layer.13.attention.self.value.bias', 'encoder.layer.15.intermediate.dense.bias', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.9.attention.self.key.weight', 'encoder.layer.5.attention.self.value.bias', 'encoder.layer.7.output.dense.bias', 'encoder.layer.13.output.dense.weight', 'encoder.layer.16.attention.self.value.weight', 'encoder.layer.6.attention.self.value.bias', 'encoder.layer.22.attention.self.query.bias', 'encoder.layer.2.attention.self.value.weight', 'encoder.layer.4.attention.self.query.bias', 'encoder.layer.16.attention.output.LayerNorm.weight', 'encoder.layer.12.intermediate.dense.weight', 'encoder.layer.20.intermediate.dense.bias', 'encoder.layer.14.attention.output.LayerNorm.bias', 'encoder.layer.1.attention.output.dense.bias', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.21.output.dense.weight', 'encoder.layer.19.attention.self.query.bias', 'encoder.layer.11.output.dense.weight', 'encoder.layer.21.output.LayerNorm.weight', 'encoder.layer.21.attention.output.LayerNorm.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Overwriting existing adapter 'ep'.
Overwriting existing adapter 'tp'.
Overwriting existing adapter 'es'.
Overwriting existing adapter 'ts'.
Overwriting existing adapter fusion module 'ep,tp,es,ts'
05/09/2022 20:16:24 - INFO - __main__ -   Creating features from dataset file at .
/cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//squad/xlm-KG_LR8e-6_EPOCH2.0_maxlen384_batchsize4_gradacc4
XLMConfig {
  "architectures": [
    "XLMRobertaForMaskedLM"
  ],
  "asm": false,
  "attention_dropout": 0.1,
  "attention_probs_dropout_prob": 0.1,
  "bos_index": 0,
  "bos_token_id": 0,
  "causal": false,
  "dropout": 0.1,
  "emb_dim": 1024,
  "embed_init_std": 0.02209708691207961,
  "end_n_top": 5,
  "eos_index": 1,
  "eos_token_id": 2,
  "gelu_activation": true,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "init_std": 0.02,
  "initializer_range": 0.02,
  "intermediate_size": 4096,
  "is_encoder": true,
  "lang_id": 0,
  "layer_norm_eps": 1e-05,
  "mask_index": 5,
  "mask_token_id": 0,
  "max_position_embeddings": 514,
  "model_type": "xlm",
  "n_heads": 16,
  "n_langs": 1,
  "n_layers": 24,
  "output_past": true,
  "pad_index": 2,
  "pad_token_id": 1,
  "sinusoidal_embeddings": false,
  "start_n_top": 5,
  "summary_activation": null,
  "summary_first_dropout": 0.1,
  "summary_proj_to_labels": true,
  "summary_type": "first",
  "summary_use_proj": true,
  "transformers_version": "4.17.0",
  "type_vocab_size": 1,
  "unk_index": 3,
  "use_lang_emb": false,
  "vocab_size": 250002
}

  0%|          | 0/48 [00:00<?, ?it/s] 31%|███▏      | 15/48 [00:00<00:00, 148.10it/s] 62%|██████▎   | 30/48 [00:00<00:00, 104.14it/s] 92%|█████████▏| 44/48 [00:00<00:00, 115.71it/s]100%|██████████| 48/48 [00:00<00:00, 117.97it/s]
convert squad examples to features:   0%|          | 0/1190 [00:00<?, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.
convert squad examples to features:   0%|          | 1/1190 [00:00<03:40,  5.40it/s]convert squad examples to features:   5%|▌         | 65/1190 [00:00<00:06, 174.68it/s]convert squad examples to features:   8%|▊         | 97/1190 [00:00<00:05, 194.76it/s]convert squad examples to features:  11%|█         | 129/1190 [00:00<00:04, 219.96it/s]convert squad examples to features:  14%|█▎        | 161/1190 [00:00<00:04, 240.18it/s]convert squad examples to features:  16%|█▌        | 193/1190 [00:00<00:03, 252.77it/s]convert squad examples to features:  19%|█▉        | 225/1190 [00:01<00:03, 242.39it/s]convert squad examples to features:  22%|██▏       | 257/1190 [00:01<00:04, 208.03it/s]convert squad examples to features:  24%|██▍       | 289/1190 [00:01<00:04, 197.91it/s]convert squad examples to features:  27%|██▋       | 321/1190 [00:01<00:04, 198.90it/s]convert squad examples to features:  30%|██▉       | 353/1190 [00:01<00:03, 209.52it/s]convert squad examples to features:  32%|███▏      | 385/1190 [00:02<00:07, 113.91it/s]convert squad examples to features:  35%|███▌      | 417/1190 [00:02<00:05, 129.29it/s]convert squad examples to features:  38%|███▊      | 449/1190 [00:02<00:05, 137.54it/s]convert squad examples to features:  40%|████      | 481/1190 [00:02<00:04, 146.36it/s]convert squad examples to features:  43%|████▎     | 513/1190 [00:02<00:04, 164.81it/s]convert squad examples to features:  46%|████▌     | 545/1190 [00:03<00:03, 161.94it/s]convert squad examples to features:  48%|████▊     | 577/1190 [00:03<00:03, 170.94it/s]convert squad examples to features:  51%|█████     | 609/1190 [00:03<00:03, 173.43it/s]convert squad examples to features:  54%|█████▍    | 641/1190 [00:03<00:03, 177.21it/s]convert squad examples to features:  57%|█████▋    | 673/1190 [00:03<00:03, 155.08it/s]convert squad examples to features:  59%|█████▉    | 705/1190 [00:04<00:03, 154.38it/s]convert squad examples to features:  62%|██████▏   | 737/1190 [00:04<00:02, 167.58it/s]convert squad examples to features:  65%|██████▍   | 769/1190 [00:04<00:02, 189.30it/s]convert squad examples to features:  67%|██████▋   | 801/1190 [00:04<00:02, 186.46it/s]convert squad examples to features:  70%|███████   | 833/1190 [00:04<00:01, 180.91it/s]convert squad examples to features:  73%|███████▎  | 865/1190 [00:04<00:01, 182.19it/s]convert squad examples to features:  75%|███████▌  | 897/1190 [00:05<00:01, 179.75it/s]convert squad examples to features:  78%|███████▊  | 929/1190 [00:05<00:01, 180.89it/s]convert squad examples to features:  81%|████████  | 961/1190 [00:05<00:01, 191.56it/s]convert squad examples to features:  83%|████████▎ | 993/1190 [00:05<00:01, 194.00it/s]convert squad examples to features:  86%|████████▌ | 1025/1190 [00:05<00:00, 212.96it/s]convert squad examples to features:  89%|████████▉ | 1057/1190 [00:05<00:00, 213.94it/s]convert squad examples to features:  92%|█████████▏| 1089/1190 [00:06<00:00, 215.52it/s]convert squad examples to features:  94%|█████████▍| 1121/1190 [00:06<00:00, 209.87it/s]convert squad examples to features:  97%|█████████▋| 1153/1190 [00:06<00:00, 193.77it/s]convert squad examples to features: 100%|██████████| 1190/1190 [00:06<00:00, 185.04it/s]
add example index and unique id:   0%|          | 0/1190 [00:00<?, ?it/s]add example index and unique id: 100%|██████████| 1190/1190 [00:00<00:00, 636879.13it/s]
05/09/2022 20:16:31 - INFO - __main__ -   Saving features into cached file ./cached_xquad.hi.json_xlm-KG_LR8e-6_EPOCH2.0_maxlen384_batchsize4_gradacc4_384_hi
05/09/2022 20:16:33 - INFO - __main__ -   ***** Running evaluation  *****
05/09/2022 20:16:33 - INFO - __main__ -     Num examples = 1382
05/09/2022 20:16:33 - INFO - __main__ -     Batch size = 8
Evaluating:   0%|          | 0/173 [00:00<?, ?it/s]Evaluating:   1%|          | 1/173 [00:00<02:32,  1.12it/s]Evaluating:   1%|          | 2/173 [00:01<01:39,  1.72it/s]Evaluating:   2%|▏         | 3/173 [00:01<01:21,  2.08it/s]Evaluating:   2%|▏         | 4/173 [00:01<01:13,  2.31it/s]Evaluating:   3%|▎         | 5/173 [00:02<01:08,  2.46it/s]Evaluating:   3%|▎         | 6/173 [00:02<01:05,  2.56it/s]Evaluating:   4%|▍         | 7/173 [00:03<01:02,  2.64it/s]Evaluating:   5%|▍         | 8/173 [00:03<01:01,  2.70it/s]Evaluating:   5%|▌         | 9/173 [00:03<01:00,  2.73it/s]Evaluating:   6%|▌         | 10/173 [00:04<00:59,  2.75it/s]Evaluating:   6%|▋         | 11/173 [00:04<01:00,  2.69it/s]Evaluating:   7%|▋         | 12/173 [00:04<00:59,  2.72it/s]Evaluating:   8%|▊         | 13/173 [00:05<00:58,  2.74it/s]Evaluating:   8%|▊         | 14/173 [00:05<00:57,  2.75it/s]Evaluating:   9%|▊         | 15/173 [00:05<00:57,  2.75it/s]Evaluating:   9%|▉         | 16/173 [00:06<00:56,  2.76it/s]Evaluating:  10%|▉         | 17/173 [00:06<00:56,  2.76it/s]Evaluating:  10%|█         | 18/173 [00:07<00:56,  2.76it/s]Evaluating:  11%|█         | 19/173 [00:07<00:55,  2.77it/s]Evaluating:  12%|█▏        | 20/173 [00:07<00:55,  2.77it/s]Evaluating:  12%|█▏        | 21/173 [00:08<00:55,  2.76it/s]Evaluating:  13%|█▎        | 22/173 [00:08<00:54,  2.78it/s]Evaluating:  13%|█▎        | 23/173 [00:08<00:53,  2.78it/s]Evaluating:  14%|█▍        | 24/173 [00:09<00:53,  2.79it/s]Evaluating:  14%|█▍        | 25/173 [00:09<00:52,  2.79it/s]Evaluating:  15%|█▌        | 26/173 [00:09<00:52,  2.79it/s]Evaluating:  16%|█▌        | 27/173 [00:10<00:52,  2.78it/s]Evaluating:  16%|█▌        | 28/173 [00:10<00:53,  2.71it/s]Evaluating:  17%|█▋        | 29/173 [00:11<00:53,  2.69it/s]Evaluating:  17%|█▋        | 30/173 [00:11<00:52,  2.71it/s]Evaluating:  18%|█▊        | 31/173 [00:11<00:51,  2.74it/s]Evaluating:  18%|█▊        | 32/173 [00:12<00:51,  2.75it/s]Evaluating:  19%|█▉        | 33/173 [00:12<00:50,  2.77it/s]Evaluating:  20%|█▉        | 34/173 [00:12<00:50,  2.76it/s]Evaluating:  20%|██        | 35/173 [00:13<00:49,  2.77it/s]Evaluating:  21%|██        | 36/173 [00:13<00:49,  2.78it/s]Evaluating:  21%|██▏       | 37/173 [00:13<00:48,  2.78it/s]Evaluating:  22%|██▏       | 38/173 [00:14<00:48,  2.78it/s]Evaluating:  23%|██▎       | 39/173 [00:14<00:48,  2.77it/s]Evaluating:  23%|██▎       | 40/173 [00:14<00:47,  2.78it/s]Evaluating:  24%|██▎       | 41/173 [00:15<00:47,  2.78it/s]Evaluating:  24%|██▍       | 42/173 [00:15<00:47,  2.76it/s]Evaluating:  25%|██▍       | 43/173 [00:16<00:47,  2.76it/s]Evaluating:  25%|██▌       | 44/173 [00:16<00:47,  2.74it/s]Evaluating:  26%|██▌       | 45/173 [00:16<00:46,  2.74it/s]Evaluating:  27%|██▋       | 46/173 [00:17<00:46,  2.75it/s]Evaluating:  27%|██▋       | 47/173 [00:17<00:45,  2.75it/s]Evaluating:  28%|██▊       | 48/173 [00:17<00:45,  2.73it/s]Evaluating:  28%|██▊       | 49/173 [00:18<00:45,  2.72it/s]Evaluating:  29%|██▉       | 50/173 [00:18<00:45,  2.71it/s]Evaluating:  29%|██▉       | 51/173 [00:19<00:44,  2.72it/s]Evaluating:  30%|███       | 52/173 [00:19<00:44,  2.74it/s]Evaluating:  31%|███       | 53/173 [00:19<00:43,  2.75it/s]Evaluating:  31%|███       | 54/173 [00:20<00:43,  2.74it/s]Evaluating:  32%|███▏      | 55/173 [00:20<00:42,  2.75it/s]Evaluating:  32%|███▏      | 56/173 [00:20<00:42,  2.74it/s]Evaluating:  33%|███▎      | 57/173 [00:21<00:42,  2.72it/s]Evaluating:  34%|███▎      | 58/173 [00:21<00:42,  2.73it/s]Evaluating:  34%|███▍      | 59/173 [00:21<00:42,  2.70it/s]Evaluating:  35%|███▍      | 60/173 [00:22<00:41,  2.71it/s]Evaluating:  35%|███▌      | 61/173 [00:22<00:41,  2.71it/s]Evaluating:  36%|███▌      | 62/173 [00:23<00:40,  2.72it/s]Evaluating:  36%|███▋      | 63/173 [00:23<00:40,  2.72it/s]Evaluating:  37%|███▋      | 64/173 [00:23<00:40,  2.72it/s]Evaluating:  38%|███▊      | 65/173 [00:24<00:39,  2.73it/s]Evaluating:  38%|███▊      | 66/173 [00:24<00:38,  2.75it/s]Evaluating:  39%|███▊      | 67/173 [00:24<00:38,  2.74it/s]Evaluating:  39%|███▉      | 68/173 [00:25<00:38,  2.74it/s]Evaluating:  40%|███▉      | 69/173 [00:25<00:37,  2.74it/s]Evaluating:  40%|████      | 70/173 [00:25<00:37,  2.75it/s]Evaluating:  41%|████      | 71/173 [00:26<00:37,  2.74it/s]Evaluating:  42%|████▏     | 72/173 [00:26<00:36,  2.74it/s]Evaluating:  42%|████▏     | 73/173 [00:27<00:36,  2.73it/s]Evaluating:  43%|████▎     | 74/173 [00:27<00:36,  2.72it/s]Evaluating:  43%|████▎     | 75/173 [00:27<00:35,  2.73it/s]Evaluating:  44%|████▍     | 76/173 [00:28<00:35,  2.73it/s]Evaluating:  45%|████▍     | 77/173 [00:28<00:35,  2.73it/s]Evaluating:  45%|████▌     | 78/173 [00:28<00:34,  2.74it/s]Evaluating:  46%|████▌     | 79/173 [00:29<00:34,  2.73it/s]Evaluating:  46%|████▌     | 80/173 [00:29<00:33,  2.74it/s]Evaluating:  47%|████▋     | 81/173 [00:29<00:33,  2.75it/s]Evaluating:  47%|████▋     | 82/173 [00:30<00:33,  2.74it/s]Evaluating:  48%|████▊     | 83/173 [00:30<00:32,  2.74it/s]Evaluating:  49%|████▊     | 84/173 [00:31<00:32,  2.73it/s]Evaluating:  49%|████▉     | 85/173 [00:31<00:32,  2.72it/s]Evaluating:  50%|████▉     | 86/173 [00:31<00:32,  2.72it/s]Evaluating:  50%|█████     | 87/173 [00:32<00:31,  2.73it/s]Evaluating:  51%|█████     | 88/173 [00:32<00:31,  2.73it/s]Evaluating:  51%|█████▏    | 89/173 [00:32<00:30,  2.74it/s]Evaluating:  52%|█████▏    | 90/173 [00:33<00:30,  2.74it/s]Evaluating:  53%|█████▎    | 91/173 [00:33<00:30,  2.73it/s]Evaluating:  53%|█████▎    | 92/173 [00:34<00:29,  2.74it/s]Evaluating:  54%|█████▍    | 93/173 [00:34<00:29,  2.74it/s]Evaluating:  54%|█████▍    | 94/173 [00:34<00:28,  2.74it/s]Evaluating:  55%|█████▍    | 95/173 [00:35<00:28,  2.74it/s]Evaluating:  55%|█████▌    | 96/173 [00:35<00:28,  2.73it/s]Evaluating:  56%|█████▌    | 97/173 [00:35<00:27,  2.73it/s]Evaluating:  57%|█████▋    | 98/173 [00:36<00:27,  2.74it/s]Evaluating:  57%|█████▋    | 99/173 [00:36<00:27,  2.74it/s]Evaluating:  58%|█████▊    | 100/173 [00:36<00:26,  2.74it/s]Evaluating:  58%|█████▊    | 101/173 [00:37<00:26,  2.74it/s]Evaluating:  59%|█████▉    | 102/173 [00:37<00:26,  2.73it/s]Evaluating:  60%|█████▉    | 103/173 [00:38<00:25,  2.73it/s]Evaluating:  60%|██████    | 104/173 [00:38<00:25,  2.73it/s]Evaluating:  61%|██████    | 105/173 [00:38<00:24,  2.74it/s]Evaluating:  61%|██████▏   | 106/173 [00:39<00:24,  2.74it/s]Evaluating:  62%|██████▏   | 107/173 [00:39<00:24,  2.73it/s]Evaluating:  62%|██████▏   | 108/173 [00:39<00:23,  2.74it/s]Evaluating:  63%|██████▎   | 109/173 [00:40<00:23,  2.74it/s]Evaluating:  64%|██████▎   | 110/173 [00:40<00:22,  2.74it/s]Evaluating:  64%|██████▍   | 111/173 [00:40<00:22,  2.75it/s]Evaluating:  65%|██████▍   | 112/173 [00:41<00:22,  2.75it/s]Evaluating:  65%|██████▌   | 113/173 [00:41<00:21,  2.75it/s]Evaluating:  66%|██████▌   | 114/173 [00:42<00:21,  2.76it/s]Evaluating:  66%|██████▋   | 115/173 [00:42<00:21,  2.76it/s]Evaluating:  67%|██████▋   | 116/173 [00:42<00:20,  2.76it/s]Evaluating:  68%|██████▊   | 117/173 [00:43<00:20,  2.71it/s]Evaluating:  68%|██████▊   | 118/173 [00:43<00:20,  2.73it/s]Evaluating:  69%|██████▉   | 119/173 [00:43<00:19,  2.74it/s]Evaluating:  69%|██████▉   | 120/173 [00:44<00:19,  2.75it/s]Evaluating:  70%|██████▉   | 121/173 [00:44<00:18,  2.75it/s]Evaluating:  71%|███████   | 122/173 [00:44<00:18,  2.76it/s]Evaluating:  71%|███████   | 123/173 [00:45<00:18,  2.75it/s]Evaluating:  72%|███████▏  | 124/173 [00:45<00:17,  2.75it/s]Evaluating:  72%|███████▏  | 125/173 [00:46<00:17,  2.74it/s]Evaluating:  73%|███████▎  | 126/173 [00:46<00:17,  2.73it/s]Evaluating:  73%|███████▎  | 127/173 [00:46<00:16,  2.72it/s]Evaluating:  74%|███████▍  | 128/173 [00:47<00:16,  2.73it/s]Evaluating:  75%|███████▍  | 129/173 [00:47<00:16,  2.73it/s]Evaluating:  75%|███████▌  | 130/173 [00:47<00:15,  2.69it/s]Evaluating:  76%|███████▌  | 131/173 [00:48<00:15,  2.71it/s]Evaluating:  76%|███████▋  | 132/173 [00:48<00:15,  2.69it/s]Evaluating:  77%|███████▋  | 133/173 [00:49<00:14,  2.71it/s]Evaluating:  77%|███████▋  | 134/173 [00:49<00:14,  2.72it/s]Evaluating:  78%|███████▊  | 135/173 [00:49<00:13,  2.72it/s]Evaluating:  79%|███████▊  | 136/173 [00:50<00:13,  2.73it/s]Evaluating:  79%|███████▉  | 137/173 [00:50<00:13,  2.73it/s]Evaluating:  80%|███████▉  | 138/173 [00:50<00:12,  2.72it/s]Evaluating:  80%|████████  | 139/173 [00:51<00:12,  2.72it/s]Evaluating:  81%|████████  | 140/173 [00:51<00:12,  2.68it/s]Evaluating:  82%|████████▏ | 141/173 [00:51<00:11,  2.71it/s]Evaluating:  82%|████████▏ | 142/173 [00:52<00:11,  2.73it/s]Evaluating:  83%|████████▎ | 143/173 [00:52<00:10,  2.74it/s]Evaluating:  83%|████████▎ | 144/173 [00:53<00:10,  2.75it/s]Evaluating:  84%|████████▍ | 145/173 [00:53<00:10,  2.76it/s]Evaluating:  84%|████████▍ | 146/173 [00:53<00:09,  2.76it/s]Evaluating:  85%|████████▍ | 147/173 [00:54<00:09,  2.76it/s]Evaluating:  86%|████████▌ | 148/173 [00:54<00:09,  2.76it/s]Evaluating:  86%|████████▌ | 149/173 [00:54<00:08,  2.76it/s]Evaluating:  87%|████████▋ | 150/173 [00:55<00:08,  2.76it/s]Evaluating:  87%|████████▋ | 151/173 [00:55<00:07,  2.76it/s]Evaluating:  88%|████████▊ | 152/173 [00:55<00:07,  2.76it/s]Evaluating:  88%|████████▊ | 153/173 [00:56<00:07,  2.76it/s]Evaluating:  89%|████████▉ | 154/173 [00:56<00:06,  2.77it/s]Evaluating:  90%|████████▉ | 155/173 [00:57<00:06,  2.77it/s]Evaluating:  90%|█████████ | 156/173 [00:57<00:06,  2.77it/s]Evaluating:  91%|█████████ | 157/173 [00:57<00:05,  2.77it/s]Evaluating:  91%|█████████▏| 158/173 [00:58<00:05,  2.74it/s]Evaluating:  92%|█████████▏| 159/173 [00:58<00:05,  2.75it/s]Evaluating:  92%|█████████▏| 160/173 [00:58<00:04,  2.76it/s]Evaluating:  93%|█████████▎| 161/173 [00:59<00:04,  2.76it/s]Evaluating:  94%|█████████▎| 162/173 [00:59<00:03,  2.77it/s]Evaluating:  94%|█████████▍| 163/173 [00:59<00:03,  2.75it/s]Evaluating:  95%|█████████▍| 164/173 [01:00<00:03,  2.76it/s]Evaluating:  95%|█████████▌| 165/173 [01:00<00:02,  2.73it/s]Evaluating:  96%|█████████▌| 166/173 [01:01<00:02,  2.74it/s]Evaluating:  97%|█████████▋| 167/173 [01:01<00:02,  2.72it/s]Evaluating:  97%|█████████▋| 168/173 [01:01<00:01,  2.72it/s]Evaluating:  98%|█████████▊| 169/173 [01:02<00:01,  2.73it/s]Evaluating:  98%|█████████▊| 170/173 [01:02<00:01,  2.73it/s]Evaluating:  99%|█████████▉| 171/173 [01:02<00:00,  2.73it/s]Evaluating:  99%|█████████▉| 172/173 [01:03<00:00,  2.74it/s]Evaluating: 100%|██████████| 173/173 [01:03<00:00,  2.99it/s]Evaluating: 100%|██████████| 173/173 [01:03<00:00,  2.73it/s]
05/09/2022 20:17:36 - INFO - __main__ -     Evaluation done in total 63.483848 secs (0.045936 sec per example)
05/09/2022 20:17:40 - INFO - __main__ -   Results: {'exact': 59.32773109243698, 'f1': 75.63817673701293, 'total': 1190, 'HasAns_exact': 59.32773109243698, 'HasAns_f1': 75.63817673701293, 'HasAns_total': 1190, 'best_exact': 59.32773109243698, 'best_exact_thresh': 0.0, 'best_f1': 75.63817673701293, 'best_f1_thresh': 0.0}
