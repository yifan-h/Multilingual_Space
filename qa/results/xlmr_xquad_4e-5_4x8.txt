Fine-tuning /cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/xlm-roberta-large on xquad using GPU 5
Load data from /cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/download/, and save models to /cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter/
************************
/cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/xlm-roberta-large
************************

Predictions on xquad
  en 
2022-05-09 19:49:06.830445: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0
05/09/2022 19:49:10 - WARNING - __main__ -   Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, 16-bits training: False
You are using a model of type xlm-roberta to instantiate a model of type xlm. This is not supported for all configurations of models and can yield errors.
Some weights of the model checkpoint at /cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//squad/xlm-KG_LR4e-5_EPOCH2.0_maxlen384_batchsize4_gradacc8 were not used when initializing XLMRobertaModel: ['base_model.encoder.layer.9.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.15.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.13.output.LayerNorm.bias', 'base_model.encoder.layer.21.attention.self.value.weight', 'base_model.encoder.layer.18.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.0.attention.output.dense.weight', 'base_model.encoder.layer.16.attention.self.key.bias', 'base_model.encoder.layer.13.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.8.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.14.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.22.attention.self.key.weight', 'base_model.encoder.layer.5.output.adapters.ts.adapter_up.weight', 'base_model.embeddings.LayerNorm.weight', 'base_model.encoder.layer.7.attention.output.dense.weight', 'base_model.encoder.layer.9.attention.self.query.bias', 'base_model.encoder.layer.22.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.11.output.LayerNorm.weight', 'base_model.encoder.layer.21.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.9.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.21.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.22.attention.output.LayerNorm.weight', 'base_model.encoder.layer.19.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.20.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.13.intermediate.dense.bias', 'base_model.encoder.layer.2.attention.output.dense.bias', 'base_model.encoder.layer.1.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.4.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.18.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.12.attention.self.value.bias', 'base_model.encoder.layer.23.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.5.output.LayerNorm.bias', 'base_model.encoder.layer.6.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.19.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.16.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.11.attention.self.value.bias', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.16.attention.output.LayerNorm.weight', 'base_model.encoder.layer.2.output.dense.weight', 'base_model.encoder.layer.15.intermediate.dense.weight', 'base_model.encoder.layer.10.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.6.attention.output.dense.bias', 'base_model.encoder.layer.1.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.16.intermediate.dense.bias', 'base_model.encoder.layer.22.attention.self.value.weight', 'base_model.encoder.layer.18.output.dense.bias', 'base_model.encoder.layer.22.attention.output.dense.bias', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.6.attention.self.value.bias', 'base_model.encoder.layer.4.output.LayerNorm.weight', 'base_model.encoder.layer.2.attention.self.query.bias', 'base_model.encoder.layer.2.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.2.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.12.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.8.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.8.attention.output.dense.weight', 'base_model.encoder.layer.19.attention.output.dense.weight', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.18.intermediate.dense.weight', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.6.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.9.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.10.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.20.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.1.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.1.attention.self.value.bias', 'base_model.encoder.layer.5.intermediate.dense.bias', 'base_model.encoder.layer.9.output.LayerNorm.weight', 'base_model.encoder.layer.17.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.3.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.11.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.16.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.18.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.6.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.20.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.17.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.4.attention.self.key.weight', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.21.attention.output.dense.bias', 'base_model.encoder.layer.17.output.LayerNorm.bias', 'base_model.encoder.layer.18.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.22.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.18.attention.self.value.bias', 'base_model.encoder.layer.17.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.8.attention.self.key.bias', 'base_model.encoder.layer.5.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.13.output.LayerNorm.weight', 'base_model.encoder.layer.16.output.dense.bias', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.23.attention.self.query.bias', 'base_model.encoder.layer.5.attention.output.LayerNorm.weight', 'base_model.encoder.layer.13.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.23.attention.self.value.bias', 'base_model.encoder.layer.22.intermediate.dense.weight', 'base_model.encoder.layer.19.attention.self.key.bias', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.10.attention.self.key.bias', 'base_model.encoder.layer.9.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.11.attention.output.LayerNorm.bias', 'base_model.encoder.layer.21.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.2.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.22.attention.output.LayerNorm.bias', 'base_model.encoder.layer.10.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.20.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.8.attention.self.query.bias', 'base_model.encoder.layer.0.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.19.attention.self.query.weight', 'base_model.encoder.layer.12.attention.self.query.weight', 'base_model.encoder.layer.13.attention.output.LayerNorm.bias', 'base_model.encoder.layer.15.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.4.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.22.output.dense.weight', 'base_model.encoder.layer.21.attention.output.dense.weight', 'base_model.encoder.layer.10.attention.self.value.bias', 'base_model.encoder.layer.3.attention.output.LayerNorm.bias', 'base_model.encoder.layer.23.output.dense.bias', 'base_model.encoder.layer.14.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.2.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.4.output.dense.bias', 'base_model.encoder.layer.8.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.16.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.18.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.0.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.20.attention.self.value.weight', 'base_model.encoder.layer.12.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.23.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.20.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.12.output.LayerNorm.weight', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.20.attention.output.dense.bias', 'base_model.encoder.layer.22.output.LayerNorm.bias', 'base_model.encoder.layer.3.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.4.attention.self.query.bias', 'base_model.encoder.layer.9.output.LayerNorm.bias', 'base_model.encoder.layer.2.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.4.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.0.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.3.attention.self.query.bias', 'base_model.encoder.layer.15.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.18.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.9.attention.self.query.weight', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.21.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.1.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.21.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.2.intermediate.dense.bias', 'base_model.encoder.layer.11.attention.self.query.weight', 'base_model.encoder.layer.20.attention.self.key.bias', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.4.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.5.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.11.intermediate.dense.bias', 'base_model.encoder.layer.6.attention.output.LayerNorm.bias', 'base_model.encoder.layer.7.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.2.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.5.attention.output.dense.bias', 'base_model.encoder.layer.23.attention.output.LayerNorm.weight', 'base_model.encoder.layer.7.attention.output.dense.bias', 'base_model.encoder.layer.11.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.9.attention.output.dense.weight', 'base_model.encoder.layer.18.attention.self.key.weight', 'base_model.encoder.layer.6.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.4.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.23.intermediate.dense.bias', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.20.attention.self.query.weight', 'base_model.encoder.layer.18.attention.self.value.weight', 'base_model.encoder.layer.11.attention.self.key.bias', 'base_model.encoder.layer.13.attention.self.query.weight', 'base_model.encoder.layer.14.attention.self.query.weight', 'base_model.encoder.layer.15.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.13.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.7.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.20.output.dense.bias', 'base_model.encoder.layer.22.output.adapters.es.adapter_down.0.weight', 'base_model.embeddings.word_embeddings.weight', 'base_model.encoder.layer.11.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.19.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.13.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.9.output.dense.weight', 'base_model.encoder.layer.20.output.LayerNorm.bias', 'base_model.encoder.layer.4.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.0.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.1.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.7.attention.self.query.weight', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.3.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.11.output.dense.weight', 'base_model.encoder.layer.10.attention.self.value.weight', 'base_model.encoder.layer.22.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.6.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.11.attention.output.dense.weight', 'base_model.encoder.layer.5.attention.self.value.bias', 'base_model.encoder.layer.19.output.LayerNorm.weight', 'base_model.encoder.layer.10.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.19.attention.output.LayerNorm.bias', 'base_model.encoder.layer.5.attention.self.value.weight', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.21.output.adapters.ep.adapter_down.0.weight', 'base_model.embeddings.LayerNorm.bias', 'base_model.encoder.layer.5.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.3.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.18.output.LayerNorm.bias', 'base_model.encoder.layer.10.attention.self.query.bias', 'base_model.encoder.layer.20.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.23.output.LayerNorm.weight', 'base_model.encoder.layer.19.output.dense.weight', 'base_model.encoder.layer.17.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.7.intermediate.dense.weight', 'base_model.encoder.layer.11.intermediate.dense.weight', 'base_model.encoder.layer.7.attention.self.key.weight', 'base_model.encoder.layer.20.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.15.attention.output.dense.weight', 'base_model.encoder.layer.15.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.11.attention.self.query.bias', 'base_model.encoder.layer.4.attention.self.key.bias', 'base_model.encoder.layer.16.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.13.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.11.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.8.attention.self.value.bias', 'base_model.encoder.layer.2.attention.self.value.weight', 'base_model.encoder.layer.13.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.5.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.15.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.22.output.LayerNorm.weight', 'base_model.encoder.layer.3.attention.self.value.bias', 'base_model.encoder.layer.6.attention.self.key.bias', 'base_model.encoder.layer.3.attention.output.LayerNorm.weight', 'base_model.encoder.layer.16.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.18.attention.self.query.bias', 'base_model.encoder.layer.2.output.LayerNorm.weight', 'base_model.encoder.layer.16.intermediate.dense.weight', 'base_model.encoder.layer.2.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.9.attention.self.value.bias', 'base_model.encoder.layer.4.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.14.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.7.attention.output.LayerNorm.bias', 'base_model.encoder.layer.8.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.21.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.16.attention.self.value.bias', 'base_model.encoder.layer.15.output.dense.weight', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.14.attention.output.dense.bias', 'base_model.encoder.layer.10.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.23.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.15.attention.self.query.weight', 'base_model.encoder.layer.22.attention.self.query.bias', 'base_model.encoder.layer.10.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.13.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.2.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.7.attention.self.key.bias', 'base_model.encoder.layer.13.output.dense.weight', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.17.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.17.attention.self.value.weight', 'base_model.encoder.layer.0.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.13.attention.self.key.bias', 'base_model.encoder.layer.14.attention.output.LayerNorm.bias', 'base_model.encoder.layer.18.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.22.attention.self.key.bias', 'base_model.encoder.layer.14.attention.output.dense.weight', 'base_model.encoder.layer.18.attention.self.query.weight', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.20.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.0.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.23.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.10.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.12.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.19.intermediate.dense.weight', 'base_model.encoder.layer.19.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.3.attention.output.dense.weight', 'base_model.encoder.layer.17.attention.self.query.weight', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.18.attention.output.dense.weight', 'base_model.encoder.layer.11.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.15.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.10.attention.output.LayerNorm.weight', 'base_model.encoder.layer.12.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.7.attention.self.value.bias', 'base_model.encoder.layer.20.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.11.attention.output.LayerNorm.weight', 'base_model.encoder.layer.0.output.LayerNorm.bias', 'base_model.encoder.layer.10.output.LayerNorm.weight', 'base_model.encoder.layer.5.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.8.intermediate.dense.bias', 'base_model.encoder.layer.11.attention.output.dense.bias', 'base_model.encoder.layer.11.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.4.attention.output.dense.weight', 'base_model.encoder.layer.6.attention.self.key.weight', 'base_model.encoder.layer.9.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.1.attention.output.dense.bias', 'base_model.encoder.layer.0.attention.output.LayerNorm.bias', 'base_model.encoder.layer.14.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.6.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.12.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.7.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.2.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.6.output.dense.bias', 'base_model.encoder.layer.5.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.21.attention.output.LayerNorm.weight', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.0.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.6.attention.self.query.weight', 'base_model.encoder.layer.19.attention.self.value.bias', 'base_model.encoder.layer.0.attention.self.value.weight', 'base_model.encoder.layer.6.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.4.intermediate.dense.bias', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.5.attention.output.dense.weight', 'base_model.encoder.layer.10.attention.output.dense.weight', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.7.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.2.attention.output.LayerNorm.weight', 'base_model.encoder.layer.5.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.0.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.10.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.7.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.13.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.19.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.20.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.21.attention.self.query.weight', 'base_model.encoder.layer.4.attention.self.value.bias', 'base_model.encoder.layer.18.attention.output.LayerNorm.bias', 'base_model.encoder.layer.4.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.15.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.9.intermediate.dense.weight', 'base_model.encoder.layer.12.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.2.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.21.attention.self.query.bias', 'base_model.encoder.layer.23.output.adapters.ep.adapter_down.0.weight', 'base_model.embeddings.token_type_embeddings.weight', 'base_model.encoder.layer.7.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.4.intermediate.dense.weight', 'base_model.encoder.layer.3.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.5.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.3.attention.self.query.weight', 'base_model.encoder.layer.10.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.11.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.18.output.dense.weight', 'base_model.encoder.layer.6.output.LayerNorm.bias', 'base_model.encoder.layer.19.output.LayerNorm.bias', 'base_model.encoder.layer.12.attention.self.query.bias', 'base_model.encoder.layer.13.attention.self.value.bias', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.3.intermediate.dense.weight', 'base_model.encoder.layer.1.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.8.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.0.attention.output.dense.bias', 'base_model.encoder.layer.22.attention.self.query.weight', 'base_model.encoder.layer.20.intermediate.dense.weight', 'base_model.encoder.layer.15.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.2.attention.self.key.weight', 'base_model.encoder.layer.22.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.12.output.dense.bias', 'base_model.encoder.layer.5.intermediate.dense.weight', 'base_model.encoder.layer.23.attention.self.query.weight', 'base_model.encoder.layer.7.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.0.attention.self.key.weight', 'base_model.encoder.layer.18.attention.output.LayerNorm.weight', 'base_model.encoder.layer.1.attention.self.query.bias', 'base_model.encoder.layer.14.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.19.attention.self.value.weight', 'base_model.encoder.layer.21.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.15.attention.output.dense.bias', 'base_model.encoder.layer.12.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.21.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.22.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.6.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.16.attention.self.value.weight', 'base_model.encoder.layer.4.output.LayerNorm.bias', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.6.attention.output.LayerNorm.weight', 'base_model.encoder.layer.2.output.LayerNorm.bias', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.17.attention.output.dense.weight', 'base_model.encoder.layer.15.attention.output.LayerNorm.bias', 'base_model.encoder.layer.19.output.dense.bias', 'base_model.encoder.layer.0.output.LayerNorm.weight', 'base_model.encoder.layer.11.attention.self.key.weight', 'base_model.encoder.layer.20.attention.self.value.bias', 'base_model.encoder.layer.0.attention.self.query.bias', 'base_model.encoder.layer.23.attention.self.value.weight', 'base_model.encoder.layer.1.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.5.output.dense.bias', 'base_model.encoder.layer.19.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.8.intermediate.dense.weight', 'base_model.encoder.layer.1.output.LayerNorm.weight', 'base_model.encoder.layer.9.attention.self.value.weight', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.13.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.18.attention.output.dense.bias', 'base_model.encoder.layer.3.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.9.attention.output.dense.bias', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.2.output.dense.bias', 'base_model.encoder.layer.17.attention.self.key.bias', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.7.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.19.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.3.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.10.output.dense.weight', 'base_model.encoder.layer.4.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.5.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.12.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.5.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.6.intermediate.dense.weight', 'base_model.encoder.layer.1.output.LayerNorm.bias', 'base_model.encoder.layer.17.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.14.attention.self.key.weight', 'base_model.encoder.layer.0.intermediate.dense.weight', 'base_model.encoder.layer.15.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.15.intermediate.dense.bias', 'base_model.encoder.layer.17.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.6.attention.self.query.bias', 'base_model.encoder.layer.3.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.3.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.17.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.8.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.16.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.9.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.1.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.12.attention.output.dense.weight', 'base_model.encoder.layer.19.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.23.attention.output.dense.weight', 'base_model.encoder.layer.4.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.18.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.20.attention.output.dense.weight', 'base_model.encoder.layer.21.attention.self.key.weight', 'base_model.encoder.layer.13.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.22.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.3.attention.self.key.weight', 'base_model.encoder.layer.6.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.20.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.20.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.11.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.14.output.dense.bias', 'base_model.encoder.layer.4.attention.self.query.weight', 'base_model.encoder.layer.15.output.dense.bias', 'base_model.encoder.layer.16.output.dense.weight', 'base_model.encoder.layer.12.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.19.intermediate.dense.bias', 'base_model.encoder.layer.7.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.11.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.5.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.10.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.12.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.14.intermediate.dense.weight', 'base_model.encoder.layer.9.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.1.attention.self.query.weight', 'base_model.encoder.layer.22.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.23.attention.output.LayerNorm.bias', 'base_model.encoder.layer.4.attention.self.value.weight', 'base_model.encoder.layer.15.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.12.attention.output.LayerNorm.bias', 'base_model.encoder.layer.16.attention.self.query.weight', 'base_model.encoder.layer.15.attention.self.key.bias', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.22.attention.output.dense.weight', 'base_model.encoder.layer.18.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.12.attention.self.key.bias', 'base_model.encoder.layer.17.output.dense.bias', 'base_model.encoder.layer.2.intermediate.dense.weight', 'base_model.encoder.layer.12.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.10.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.20.output.adapters.ts.adapter_down.0.weight', 'base_model.pooler.dense.weight', 'base_model.encoder.layer.6.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.9.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.17.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.17.attention.output.dense.bias', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.1.intermediate.dense.weight', 'base_model.encoder.layer.15.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.16.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.14.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.14.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.1.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.18.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.21.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.17.attention.self.value.bias', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.14.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.1.attention.self.value.weight', 'base_model.encoder.layer.3.attention.self.value.weight', 'base_model.encoder.layer.17.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.3.attention.self.key.bias', 'base_model.encoder.layer.9.output.dense.bias', 'base_model.encoder.layer.14.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.19.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.1.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.20.attention.self.query.bias', 'base_model.encoder.layer.11.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.18.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.15.attention.self.query.bias', 'base_model.encoder.layer.14.output.LayerNorm.bias', 'base_model.encoder.layer.0.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.1.attention.self.key.bias', 'base_model.encoder.layer.0.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.6.attention.output.dense.weight', 'base_model.encoder.layer.6.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.9.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.15.attention.self.value.weight', 'base_model.encoder.layer.22.output.adapters.ep.adapter_down.0.weight', 'base_model.pooler.dense.bias', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.10.attention.output.LayerNorm.bias', 'base_model.encoder.layer.0.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.13.attention.self.key.weight', 'base_model.encoder.layer.21.intermediate.dense.bias', 'base_model.embeddings.position_ids', 'base_model.encoder.layer.7.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.13.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.15.output.LayerNorm.weight', 'base_model.encoder.layer.19.attention.output.LayerNorm.weight', 'base_model.encoder.layer.5.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.8.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.8.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.11.output.adapters.tp.adapter_up.bias', 'base_model.embeddings.position_embeddings.weight', 'base_model.encoder.layer.12.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.17.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.1.output.dense.bias', 'base_model.encoder.layer.20.output.dense.weight', 'base_model.encoder.layer.4.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.21.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.1.output.dense.weight', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.0.output.dense.weight', 'base_model.encoder.layer.9.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.10.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.3.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.13.attention.output.dense.bias', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.1.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.11.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.10.output.LayerNorm.bias', 'base_model.encoder.layer.1.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.9.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.3.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.8.attention.self.query.weight', 'base_model.encoder.layer.12.output.dense.weight', 'base_model.encoder.layer.21.output.dense.bias', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.10.attention.self.query.weight', 'base_model.encoder.layer.13.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.21.output.dense.weight', 'base_model.encoder.layer.17.attention.self.query.bias', 'base_model.encoder.layer.0.attention.self.key.bias', 'base_model.encoder.layer.3.output.LayerNorm.bias', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.6.intermediate.dense.bias', 'base_model.encoder.layer.7.attention.self.query.bias', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.7.output.dense.bias', 'base_model.encoder.layer.9.attention.output.LayerNorm.bias', 'base_model.encoder.layer.11.output.LayerNorm.bias', 'base_model.encoder.layer.11.attention.self.value.weight', 'base_model.encoder.layer.14.attention.output.LayerNorm.weight', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.17.attention.self.key.weight', 'base_model.encoder.layer.22.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.5.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.16.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.16.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.16.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.4.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.14.attention.self.value.weight', 'base_model.encoder.layer.20.output.LayerNorm.weight', 'base_model.encoder.layer.19.attention.output.dense.bias', 'base_model.encoder.layer.1.attention.output.LayerNorm.weight', 'base_model.encoder.layer.14.intermediate.dense.bias', 'base_model.encoder.layer.3.output.dense.bias', 'base_model.encoder.layer.4.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.21.attention.self.value.bias', 'base_model.encoder.layer.16.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.3.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.19.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.1.attention.output.dense.weight', 'base_model.encoder.layer.14.attention.self.query.bias', 'base_model.encoder.layer.7.attention.self.value.weight', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.3.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.7.output.dense.weight', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.8.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.19.attention.self.query.bias', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.15.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.8.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.23.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.12.output.LayerNorm.bias', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.22.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.23.attention.self.key.bias', 'base_model.encoder.layer.21.attention.self.key.bias', 'base_model.encoder.layer.12.attention.output.dense.bias', 'base_model.encoder.layer.6.output.LayerNorm.weight', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.1.intermediate.dense.bias', 'base_model.encoder.layer.13.intermediate.dense.weight', 'base_model.encoder.layer.15.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.6.attention.self.value.weight', 'base_model.encoder.layer.16.attention.output.LayerNorm.bias', 'base_model.encoder.layer.17.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.22.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.23.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.12.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.17.attention.output.LayerNorm.weight', 'base_model.encoder.layer.8.output.LayerNorm.bias', 'base_model.encoder.layer.5.attention.self.query.weight', 'base_model.encoder.layer.22.intermediate.dense.bias', 'base_model.encoder.layer.7.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.2.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.19.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.6.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.23.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.23.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.21.attention.output.LayerNorm.bias', 'base_model.encoder.layer.1.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.6.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.20.intermediate.dense.bias', 'base_model.encoder.layer.8.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.20.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.23.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.2.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.7.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.7.intermediate.dense.bias', 'base_model.encoder.layer.21.intermediate.dense.weight', 'base_model.encoder.layer.20.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.9.attention.self.key.weight', 'base_model.encoder.layer.23.output.LayerNorm.bias', 'base_model.encoder.layer.8.attention.self.value.weight', 'base_model.encoder.layer.23.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.17.intermediate.dense.weight', 'base_model.encoder.layer.7.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.3.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.1.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.9.attention.self.key.bias', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.8.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.12.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.23.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.5.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.8.output.dense.bias', 'base_model.encoder.layer.14.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.14.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.23.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.17.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.16.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.10.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.16.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.18.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.3.output.dense.weight', 'base_model.encoder.layer.20.attention.output.LayerNorm.weight', 'base_model.encoder.layer.16.attention.output.dense.bias', 'base_model.encoder.layer.21.output.LayerNorm.bias', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.17.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.14.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.8.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.0.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.7.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.9.attention.output.LayerNorm.weight', 'base_model.encoder.layer.1.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.12.attention.self.value.weight', 'base_model.encoder.layer.21.output.LayerNorm.weight', 'base_model.encoder.layer.21.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.0.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.18.intermediate.dense.bias', 'base_model.encoder.layer.11.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.22.output.dense.bias', 'base_model.encoder.layer.17.attention.output.LayerNorm.bias', 'base_model.encoder.layer.4.attention.output.LayerNorm.bias', 'base_model.encoder.layer.9.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.2.attention.output.LayerNorm.bias', 'base_model.encoder.layer.4.attention.output.dense.bias', 'base_model.encoder.layer.2.output.adapters.es.adapter_down.0.weight', 'qa_outputs.weight', 'base_model.encoder.layer.19.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.3.intermediate.dense.bias', 'base_model.encoder.layer.21.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.1.attention.self.key.weight', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.0.intermediate.dense.bias', 'base_model.encoder.layer.20.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.3.output.LayerNorm.weight', 'base_model.encoder.layer.9.output.adapters.es.adapter_up.weight', 'qa_outputs.bias', 'base_model.encoder.layer.14.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.0.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.4.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.13.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.16.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.9.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.8.output.dense.weight', 'base_model.encoder.layer.7.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.10.attention.self.key.weight', 'base_model.encoder.layer.10.attention.output.dense.bias', 'base_model.encoder.layer.2.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.10.intermediate.dense.weight', 'base_model.encoder.layer.16.attention.self.key.weight', 'base_model.encoder.layer.0.attention.output.LayerNorm.weight', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.14.attention.self.value.bias', 'base_model.encoder.layer.2.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.15.output.LayerNorm.bias', 'base_model.encoder.layer.13.attention.output.dense.weight', 'base_model.encoder.layer.0.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.6.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.8.attention.self.key.weight', 'base_model.encoder.layer.5.attention.self.key.weight', 'base_model.encoder.layer.9.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.15.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.3.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.19.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.16.attention.output.dense.weight', 'base_model.encoder.layer.7.output.LayerNorm.bias', 'base_model.encoder.layer.1.attention.output.LayerNorm.bias', 'base_model.encoder.layer.12.attention.output.LayerNorm.weight', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.3.attention.output.dense.bias', 'base_model.encoder.layer.19.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.21.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.5.attention.output.LayerNorm.bias', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.9.intermediate.dense.bias', 'base_model.encoder.layer.18.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.10.intermediate.dense.bias', 'base_model.encoder.layer.13.attention.self.value.weight', 'base_model.encoder.layer.10.output.dense.bias', 'base_model.encoder.layer.5.attention.self.query.bias', 'base_model.encoder.layer.19.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.10.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.12.intermediate.dense.weight', 'base_model.encoder.layer.23.attention.self.key.weight', 'base_model.encoder.layer.15.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.5.output.dense.weight', 'base_model.encoder.layer.12.intermediate.dense.bias', 'base_model.encoder.layer.2.attention.self.value.bias', 'base_model.encoder.layer.17.output.LayerNorm.weight', 'base_model.encoder.layer.21.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.4.attention.output.LayerNorm.weight', 'base_model.encoder.layer.5.output.LayerNorm.weight', 'base_model.encoder.layer.2.attention.self.query.weight', 'base_model.encoder.layer.2.attention.output.dense.weight', 'base_model.encoder.layer.6.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.12.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.17.output.dense.weight', 'base_model.encoder.layer.22.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.18.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.11.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.13.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.2.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.10.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.8.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.10.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.4.output.dense.weight', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.6.output.dense.weight', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.18.output.LayerNorm.weight', 'base_model.encoder.layer.9.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.13.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.22.attention.self.value.bias', 'base_model.encoder.layer.20.attention.output.LayerNorm.bias', 'base_model.encoder.layer.22.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.14.attention.self.key.bias', 'base_model.encoder.layer.23.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.8.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.11.output.dense.bias', 'base_model.encoder.layer.16.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.18.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.14.output.LayerNorm.weight', 'base_model.encoder.layer.4.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.16.output.LayerNorm.weight', 'base_model.encoder.layer.19.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.8.output.LayerNorm.weight', 'base_model.encoder.layer.15.attention.output.LayerNorm.weight', 'base_model.encoder.layer.20.attention.self.key.weight', 'base_model.encoder.layer.8.attention.output.LayerNorm.bias', 'base_model.encoder.layer.0.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.5.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.15.attention.self.value.bias', 'base_model.encoder.layer.22.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.14.output.dense.weight', 'base_model.encoder.layer.14.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.15.attention.self.key.weight', 'base_model.encoder.layer.14.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.17.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.18.attention.self.key.bias', 'base_model.encoder.layer.23.attention.output.dense.bias', 'base_model.encoder.layer.4.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.23.output.dense.weight', 'base_model.encoder.layer.13.attention.output.LayerNorm.weight', 'base_model.encoder.layer.12.attention.self.key.weight', 'base_model.encoder.layer.23.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.8.attention.output.dense.bias', 'base_model.encoder.layer.7.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.17.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.2.attention.self.key.bias', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.16.attention.self.query.bias', 'base_model.encoder.layer.12.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.7.attention.output.LayerNorm.weight', 'base_model.encoder.layer.11.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.5.attention.self.key.bias', 'base_model.encoder.layer.13.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.14.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.23.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.1.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.22.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.0.attention.self.value.bias', 'base_model.encoder.layer.0.output.dense.bias', 'base_model.encoder.layer.13.attention.self.query.bias', 'base_model.encoder.layer.18.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.3.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.6.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.19.attention.self.key.weight', 'base_model.encoder.layer.11.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.0.attention.self.query.weight', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.7.output.LayerNorm.weight', 'base_model.encoder.layer.16.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.21.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.16.output.LayerNorm.bias', 'base_model.encoder.layer.8.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.17.intermediate.dense.bias', 'base_model.encoder.layer.23.intermediate.dense.weight', 'base_model.encoder.layer.8.attention.output.LayerNorm.weight', 'base_model.encoder.layer.13.output.dense.bias']
- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of XLMRobertaModel were not initialized from the model checkpoint at /cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//squad/xlm-KG_LR4e-5_EPOCH2.0_maxlen384_batchsize4_gradacc8 and are newly initialized: ['encoder.layer.14.attention.self.query.bias', 'encoder.layer.4.attention.self.query.bias', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.20.attention.self.key.weight', 'encoder.layer.8.attention.self.query.bias', 'encoder.layer.23.attention.output.dense.weight', 'encoder.layer.0.attention.output.dense.bias', 'encoder.layer.11.attention.self.value.bias', 'encoder.layer.20.intermediate.dense.weight', 'encoder.layer.23.attention.self.key.bias', 'encoder.layer.3.attention.self.value.weight', 'encoder.layer.16.attention.self.key.bias', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.8.attention.self.key.weight', 'encoder.layer.5.output.dense.weight', 'encoder.layer.22.attention.self.value.weight', 'encoder.layer.18.attention.output.dense.weight', 'encoder.layer.23.attention.self.key.weight', 'encoder.layer.17.attention.self.query.bias', 'encoder.layer.18.attention.output.LayerNorm.bias', 'encoder.layer.4.attention.self.query.weight', 'encoder.layer.4.output.dense.bias', 'encoder.layer.8.attention.self.value.bias', 'encoder.layer.0.attention.self.value.weight', 'encoder.layer.17.output.dense.weight', 'encoder.layer.19.attention.output.LayerNorm.bias', 'encoder.layer.19.attention.self.key.weight', 'encoder.layer.3.output.dense.weight', 'encoder.layer.15.attention.output.dense.bias', 'encoder.layer.8.attention.self.query.weight', 'encoder.layer.8.output.dense.weight', 'encoder.layer.15.attention.self.query.weight', 'encoder.layer.13.attention.self.key.weight', 'encoder.layer.17.attention.self.key.weight', 'encoder.layer.19.attention.output.LayerNorm.weight', 'encoder.layer.21.output.LayerNorm.bias', 'encoder.layer.9.attention.output.dense.weight', 'encoder.layer.23.output.dense.bias', 'encoder.layer.19.attention.output.dense.bias', 'encoder.layer.14.output.dense.bias', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.5.attention.output.dense.weight', 'encoder.layer.7.attention.output.LayerNorm.bias', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.16.intermediate.dense.bias', 'encoder.layer.5.attention.self.value.bias', 'encoder.layer.6.attention.output.dense.weight', 'encoder.layer.12.attention.self.value.weight', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.18.attention.self.query.bias', 'encoder.layer.23.attention.self.value.bias', 'encoder.layer.11.output.LayerNorm.weight', 'encoder.layer.21.attention.self.query.weight', 'encoder.layer.12.attention.self.query.weight', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.11.attention.self.value.weight', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.17.attention.self.value.bias', 'encoder.layer.9.attention.self.value.bias', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.7.attention.self.value.weight', 'encoder.layer.8.output.LayerNorm.weight', 'encoder.layer.7.attention.self.query.bias', 'encoder.layer.3.attention.self.key.bias', 'encoder.layer.3.output.dense.bias', 'encoder.layer.15.output.LayerNorm.bias', 'encoder.layer.19.output.LayerNorm.bias', 'encoder.layer.19.attention.self.query.bias', 'encoder.layer.7.output.LayerNorm.weight', 'encoder.layer.20.attention.output.dense.weight', 'encoder.layer.18.output.LayerNorm.weight', 'encoder.layer.20.attention.self.key.bias', 'encoder.layer.14.attention.self.value.weight', 'encoder.layer.6.attention.output.dense.bias', 'encoder.layer.21.attention.output.LayerNorm.weight', 'encoder.layer.1.attention.self.query.weight', 'encoder.layer.13.attention.output.dense.weight', 'encoder.layer.10.output.dense.weight', 'encoder.layer.2.attention.self.value.weight', 'encoder.layer.8.attention.self.key.bias', 'encoder.layer.1.attention.self.value.weight', 'embeddings.LayerNorm.weight', 'encoder.layer.2.attention.self.query.weight', 'encoder.layer.11.attention.output.LayerNorm.weight', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.18.intermediate.dense.bias', 'encoder.layer.22.output.dense.bias', 'encoder.layer.20.output.dense.weight', 'encoder.layer.10.attention.self.key.bias', 'encoder.layer.1.attention.output.dense.weight', 'encoder.layer.1.attention.self.query.bias', 'encoder.layer.15.attention.self.query.bias', 'encoder.layer.5.attention.output.LayerNorm.weight', 'encoder.layer.0.attention.self.query.weight', 'encoder.layer.22.attention.self.value.bias', 'encoder.layer.15.output.dense.bias', 'encoder.layer.7.attention.output.dense.bias', 'encoder.layer.7.attention.self.key.weight', 'encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.layer.14.output.LayerNorm.bias', 'encoder.layer.22.output.dense.weight', 'encoder.layer.13.attention.self.query.weight', 'encoder.layer.2.output.dense.bias', 'encoder.layer.22.output.LayerNorm.weight', 'encoder.layer.5.output.LayerNorm.bias', 'encoder.layer.2.attention.output.dense.bias', 'encoder.layer.15.output.LayerNorm.weight', 'encoder.layer.19.attention.self.value.bias', 'encoder.layer.18.output.LayerNorm.bias', 'encoder.layer.12.attention.self.value.bias', 'encoder.layer.9.output.dense.bias', 'encoder.layer.12.attention.self.query.bias', 'encoder.layer.9.attention.self.key.bias', 'encoder.layer.10.attention.output.LayerNorm.bias', 'encoder.layer.11.attention.output.dense.weight', 'encoder.layer.13.attention.self.value.bias', 'encoder.layer.15.attention.self.key.bias', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.15.attention.self.value.weight', 'encoder.layer.23.output.LayerNorm.bias', 'encoder.layer.5.attention.self.query.weight', 'encoder.layer.18.attention.self.key.bias', 'encoder.layer.16.intermediate.dense.weight', 'encoder.layer.21.output.dense.bias', 'encoder.layer.19.attention.self.key.bias', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.4.attention.output.dense.weight', 'encoder.layer.2.attention.self.key.bias', 'encoder.layer.2.attention.output.LayerNorm.weight', 'encoder.layer.20.attention.self.value.bias', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.16.output.LayerNorm.weight', 'encoder.layer.16.output.dense.weight', 'encoder.layer.6.attention.self.query.weight', 'encoder.layer.15.attention.self.key.weight', 'encoder.layer.23.intermediate.dense.weight', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.10.attention.self.query.bias', 'encoder.layer.1.output.dense.bias', 'encoder.layer.19.attention.self.query.weight', 'encoder.layer.12.intermediate.dense.weight', 'encoder.layer.12.attention.self.key.weight', 'encoder.layer.23.attention.self.query.weight', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.15.attention.output.dense.weight', 'encoder.layer.6.attention.self.key.weight', 'encoder.layer.8.attention.output.dense.weight', 'encoder.layer.5.output.dense.bias', 'encoder.layer.3.attention.self.query.bias', 'encoder.layer.5.attention.self.key.bias', 'encoder.layer.10.attention.output.dense.weight', 'encoder.layer.14.attention.output.LayerNorm.weight', 'embeddings.LayerNorm.bias', 'encoder.layer.11.attention.self.key.weight', 'encoder.layer.13.attention.self.key.bias', 'encoder.layer.6.output.dense.weight', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.1.attention.output.dense.bias', 'encoder.layer.21.attention.output.dense.bias', 'encoder.layer.23.attention.self.query.bias', 'encoder.layer.3.attention.output.dense.weight', 'encoder.layer.8.attention.output.LayerNorm.bias', 'encoder.layer.9.attention.self.key.weight', 'encoder.layer.4.attention.self.key.bias', 'encoder.layer.12.output.dense.bias', 'encoder.layer.23.output.dense.weight', 'encoder.layer.22.attention.self.key.weight', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.0.attention.self.query.bias', 'encoder.layer.21.attention.self.value.bias', 'encoder.layer.8.output.dense.bias', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.10.intermediate.dense.weight', 'encoder.layer.22.intermediate.dense.weight', 'encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.layer.10.output.LayerNorm.weight', 'encoder.layer.13.attention.self.query.bias', 'encoder.layer.9.output.LayerNorm.weight', 'encoder.layer.2.attention.self.value.bias', 'encoder.layer.17.intermediate.dense.weight', 'encoder.layer.2.attention.output.LayerNorm.bias', 'encoder.layer.16.attention.self.value.weight', 'encoder.layer.20.attention.self.query.bias', 'encoder.layer.16.attention.self.query.bias', 'encoder.layer.12.output.LayerNorm.bias', 'encoder.layer.23.attention.output.dense.bias', 'encoder.layer.16.attention.output.dense.bias', 'encoder.layer.22.attention.output.LayerNorm.weight', 'encoder.layer.2.attention.self.key.weight', 'encoder.layer.22.attention.self.key.bias', 'encoder.layer.20.attention.output.dense.bias', 'encoder.layer.4.attention.self.key.weight', 'encoder.layer.22.attention.output.dense.bias', 'encoder.layer.14.intermediate.dense.weight', 'encoder.layer.17.intermediate.dense.bias', 'encoder.layer.6.attention.output.LayerNorm.weight', 'encoder.layer.8.output.LayerNorm.bias', 'encoder.layer.21.intermediate.dense.weight', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.4.output.dense.weight', 'encoder.layer.19.attention.self.value.weight', 'encoder.layer.16.attention.self.value.bias', 'encoder.layer.17.attention.self.key.bias', 'encoder.layer.18.attention.self.query.weight', 'encoder.layer.3.attention.output.dense.bias', 'encoder.layer.6.attention.self.key.bias', 'encoder.layer.23.attention.output.LayerNorm.weight', 'encoder.layer.4.attention.output.dense.bias', 'encoder.layer.5.attention.self.key.weight', 'encoder.layer.13.attention.output.LayerNorm.weight', 'encoder.layer.15.output.dense.weight', 'encoder.layer.23.output.LayerNorm.weight', 'encoder.layer.4.attention.self.value.bias', 'encoder.layer.17.attention.self.query.weight', 'encoder.layer.11.output.dense.bias', 'encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.18.output.dense.weight', 'encoder.layer.13.intermediate.dense.bias', 'encoder.layer.12.attention.output.dense.weight', 'encoder.layer.19.attention.output.dense.weight', 'encoder.layer.21.attention.self.value.weight', 'encoder.layer.6.attention.self.query.bias', 'encoder.layer.1.attention.self.key.bias', 'encoder.layer.7.attention.output.dense.weight', 'encoder.layer.0.attention.self.value.bias', 'encoder.layer.7.attention.self.key.bias', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.7.output.dense.weight', 'encoder.layer.0.output.dense.weight', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.12.output.dense.weight', 'encoder.layer.19.intermediate.dense.bias', 'encoder.layer.1.attention.output.LayerNorm.weight', 'encoder.layer.11.output.dense.weight', 'encoder.layer.16.output.LayerNorm.bias', 'encoder.layer.0.attention.output.dense.weight', 'encoder.layer.22.output.LayerNorm.bias', 'encoder.layer.19.output.dense.weight', 'encoder.layer.12.attention.output.LayerNorm.weight', 'encoder.layer.18.attention.self.key.weight', 'encoder.layer.10.attention.self.value.weight', 'encoder.layer.0.attention.self.key.bias', 'encoder.layer.16.attention.self.key.weight', 'encoder.layer.10.attention.output.LayerNorm.weight', 'encoder.layer.23.intermediate.dense.bias', 'encoder.layer.10.attention.output.dense.bias', 'encoder.layer.10.output.dense.bias', 'encoder.layer.21.attention.self.key.weight', 'encoder.layer.14.attention.output.dense.weight', 'encoder.layer.2.attention.self.query.bias', 'embeddings.word_embeddings.weight', 'encoder.layer.13.intermediate.dense.weight', 'encoder.layer.22.attention.self.query.bias', 'encoder.layer.9.attention.output.LayerNorm.bias', 'encoder.layer.18.output.dense.bias', 'encoder.layer.5.attention.output.dense.bias', 'encoder.layer.1.attention.self.key.weight', 'encoder.layer.4.attention.output.LayerNorm.weight', 'encoder.layer.5.attention.self.value.weight', 'encoder.layer.22.attention.self.query.weight', 'encoder.layer.7.attention.self.query.weight', 'encoder.layer.9.output.LayerNorm.bias', 'encoder.layer.8.attention.output.LayerNorm.weight', 'encoder.layer.18.intermediate.dense.weight', 'encoder.layer.18.attention.output.dense.bias', 'encoder.layer.3.attention.self.value.bias', 'encoder.layer.13.attention.output.LayerNorm.bias', 'encoder.layer.14.attention.self.value.bias', 'encoder.layer.15.intermediate.dense.bias', 'encoder.layer.12.attention.output.dense.bias', 'encoder.layer.20.intermediate.dense.bias', 'encoder.layer.9.attention.self.query.bias', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.19.intermediate.dense.weight', 'encoder.layer.7.attention.output.LayerNorm.weight', 'encoder.layer.13.output.LayerNorm.bias', 'encoder.layer.14.intermediate.dense.bias', 'encoder.layer.15.intermediate.dense.weight', 'encoder.layer.7.intermediate.dense.bias', 'encoder.layer.21.attention.output.LayerNorm.bias', 'encoder.layer.17.attention.output.LayerNorm.bias', 'encoder.layer.21.output.dense.weight', 'encoder.layer.15.attention.output.LayerNorm.bias', 'encoder.layer.10.output.LayerNorm.bias', 'encoder.layer.16.attention.output.dense.weight', 'encoder.layer.8.attention.output.dense.bias', 'encoder.layer.17.output.LayerNorm.weight', 'encoder.layer.18.attention.output.LayerNorm.weight', 'encoder.layer.11.attention.self.query.weight', 'encoder.layer.11.attention.output.dense.bias', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.10.attention.self.key.weight', 'encoder.layer.12.output.LayerNorm.weight', 'encoder.layer.14.attention.self.query.weight', 'encoder.layer.18.attention.self.value.weight', 'embeddings.position_embeddings.weight', 'encoder.layer.12.attention.output.LayerNorm.bias', 'encoder.layer.6.attention.self.value.weight', 'encoder.layer.21.attention.self.query.bias', 'encoder.layer.15.attention.self.value.bias', 'encoder.layer.1.attention.self.value.bias', 'encoder.layer.17.attention.self.value.weight', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.14.attention.output.LayerNorm.bias', 'encoder.layer.18.attention.self.value.bias', 'encoder.layer.1.output.dense.weight', 'encoder.layer.10.attention.self.value.bias', 'encoder.layer.3.attention.self.query.weight', 'encoder.layer.16.attention.output.LayerNorm.bias', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.20.output.dense.bias', 'encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.layer.7.attention.self.value.bias', 'encoder.layer.7.output.LayerNorm.bias', 'encoder.layer.13.attention.self.value.weight', 'encoder.layer.17.output.dense.bias', 'encoder.layer.13.output.LayerNorm.weight', 'encoder.layer.21.intermediate.dense.bias', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.21.attention.self.key.bias', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.16.output.dense.bias', 'encoder.layer.11.output.LayerNorm.bias', 'encoder.layer.19.output.LayerNorm.weight', 'encoder.layer.13.output.dense.weight', 'encoder.layer.16.attention.self.query.weight', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.9.attention.output.dense.bias', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.20.attention.self.query.weight', 'encoder.layer.6.attention.self.value.bias', 'encoder.layer.17.output.LayerNorm.bias', 'encoder.layer.5.attention.self.query.bias', 'encoder.layer.12.intermediate.dense.bias', 'encoder.layer.10.attention.self.query.weight', 'encoder.layer.2.output.dense.weight', 'encoder.layer.17.attention.output.dense.weight', 'encoder.layer.14.output.LayerNorm.weight', 'encoder.layer.13.output.dense.bias', 'encoder.layer.19.output.dense.bias', 'encoder.layer.3.attention.self.key.weight', 'encoder.layer.22.attention.output.LayerNorm.bias', 'encoder.layer.22.attention.output.dense.weight', 'encoder.layer.15.attention.output.LayerNorm.weight', 'encoder.layer.20.attention.output.LayerNorm.bias', 'encoder.layer.9.attention.self.value.weight', 'encoder.layer.14.attention.self.key.weight', 'encoder.layer.23.attention.output.LayerNorm.bias', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.9.attention.output.LayerNorm.weight', 'encoder.layer.17.attention.output.LayerNorm.weight', 'encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.layer.20.output.LayerNorm.weight', 'encoder.layer.16.attention.output.LayerNorm.weight', 'encoder.layer.6.output.LayerNorm.bias', 'encoder.layer.4.attention.self.value.weight', 'encoder.layer.9.output.dense.weight', 'encoder.layer.11.attention.self.key.bias', 'encoder.layer.17.attention.output.dense.bias', 'encoder.layer.23.attention.self.value.weight', 'encoder.layer.6.output.dense.bias', 'encoder.layer.22.intermediate.dense.bias', 'encoder.layer.12.attention.self.key.bias', 'encoder.layer.13.attention.output.dense.bias', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.11.attention.self.query.bias', 'encoder.layer.21.attention.output.dense.weight', 'encoder.layer.20.attention.self.value.weight', 'encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.layer.20.attention.output.LayerNorm.weight', 'encoder.layer.0.attention.output.LayerNorm.weight', 'encoder.layer.4.attention.output.LayerNorm.bias', 'encoder.layer.14.output.dense.weight', 'encoder.layer.21.output.LayerNorm.weight', 'encoder.layer.7.output.dense.bias', 'encoder.layer.14.attention.output.dense.bias', 'encoder.layer.9.attention.self.query.weight', 'encoder.layer.2.attention.output.dense.weight', 'encoder.layer.8.attention.self.value.weight', 'encoder.layer.6.attention.output.LayerNorm.bias', 'encoder.layer.20.output.LayerNorm.bias', 'embeddings.token_type_embeddings.weight', 'encoder.layer.1.output.LayerNorm.bias', 'pooler.dense.bias', 'pooler.dense.weight', 'encoder.layer.0.attention.self.key.weight', 'encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.layer.14.attention.self.key.bias', 'encoder.layer.0.output.dense.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Overwriting existing adapter 'ep'.
Overwriting existing adapter 'tp'.
Overwriting existing adapter 'es'.
Overwriting existing adapter 'ts'.
Overwriting existing adapter fusion module 'ep,tp,es,ts'
05/09/2022 19:49:36 - INFO - __main__ -   lang2id = None
05/09/2022 19:49:40 - INFO - __main__ -   Training/evaluation parameters Namespace(adam_epsilon=1e-08, cache_dir='', config_name='', data_dir=None, device=device(type='cuda'), do_eval=True, do_lower_case=False, do_train=False, doc_stride=128, eval_all_checkpoints=False, eval_lang='en', evaluate_during_training=False, fp16=False, fp16_opt_level='O1', gradient_accumulation_steps=1, learning_rate=5e-05, local_rank=-1, logging_steps=50, max_answer_length=30, max_grad_norm=1.0, max_query_length=64, max_seq_length=384, max_steps=-1, model_name='xlm-KG', model_name_or_path='/cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//squad/xlm-KG_LR4e-5_EPOCH2.0_maxlen384_batchsize4_gradacc8', model_type='xlm', modelkg_dir='/cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/adapter/xlmr_adapter', n_best_size=20, n_gpu=1, no_cuda=False, null_score_diff_threshold=0.0, num_train_epochs=3.0, output_dir='/cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//squad/xlm-KG_LR4e-5_EPOCH2.0_maxlen384_batchsize4_gradacc8/predictions/xquad/', overwrite_cache=False, overwrite_output_dir=False, per_gpu_eval_batch_size=8, per_gpu_train_batch_size=8, predict_file='/cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/download//xquad//xquad.en.json', save_steps=50, seed=42, server_ip='', server_port='', threads=1, tokenizer_name='', train_file=None, train_lang='en', verbose_logging=False, version_2_with_negative=False, warmup_steps=0, weight_decay=0.0)
05/09/2022 19:49:40 - INFO - __main__ -   Loading checkpoint /cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//squad/xlm-KG_LR4e-5_EPOCH2.0_maxlen384_batchsize4_gradacc8 for evaluation
05/09/2022 19:49:40 - INFO - __main__ -   Evaluate the following checkpoints: ['/cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//squad/xlm-KG_LR4e-5_EPOCH2.0_maxlen384_batchsize4_gradacc8']
Some weights of the model checkpoint at /cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//squad/xlm-KG_LR4e-5_EPOCH2.0_maxlen384_batchsize4_gradacc8 were not used when initializing XLMRobertaModel: ['base_model.encoder.layer.9.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.15.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.13.output.LayerNorm.bias', 'base_model.encoder.layer.21.attention.self.value.weight', 'base_model.encoder.layer.18.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.0.attention.output.dense.weight', 'base_model.encoder.layer.16.attention.self.key.bias', 'base_model.encoder.layer.13.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.8.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.14.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.22.attention.self.key.weight', 'base_model.encoder.layer.5.output.adapters.ts.adapter_up.weight', 'base_model.embeddings.LayerNorm.weight', 'base_model.encoder.layer.7.attention.output.dense.weight', 'base_model.encoder.layer.9.attention.self.query.bias', 'base_model.encoder.layer.22.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.11.output.LayerNorm.weight', 'base_model.encoder.layer.21.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.9.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.21.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.22.attention.output.LayerNorm.weight', 'base_model.encoder.layer.19.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.20.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.13.intermediate.dense.bias', 'base_model.encoder.layer.2.attention.output.dense.bias', 'base_model.encoder.layer.1.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.4.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.18.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.12.attention.self.value.bias', 'base_model.encoder.layer.23.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.5.output.LayerNorm.bias', 'base_model.encoder.layer.6.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.19.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.16.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.11.attention.self.value.bias', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.16.attention.output.LayerNorm.weight', 'base_model.encoder.layer.2.output.dense.weight', 'base_model.encoder.layer.15.intermediate.dense.weight', 'base_model.encoder.layer.10.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.6.attention.output.dense.bias', 'base_model.encoder.layer.1.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.16.intermediate.dense.bias', 'base_model.encoder.layer.22.attention.self.value.weight', 'base_model.encoder.layer.18.output.dense.bias', 'base_model.encoder.layer.22.attention.output.dense.bias', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.6.attention.self.value.bias', 'base_model.encoder.layer.4.output.LayerNorm.weight', 'base_model.encoder.layer.2.attention.self.query.bias', 'base_model.encoder.layer.2.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.2.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.12.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.8.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.8.attention.output.dense.weight', 'base_model.encoder.layer.19.attention.output.dense.weight', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.18.intermediate.dense.weight', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.6.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.9.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.10.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.20.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.1.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.1.attention.self.value.bias', 'base_model.encoder.layer.5.intermediate.dense.bias', 'base_model.encoder.layer.9.output.LayerNorm.weight', 'base_model.encoder.layer.17.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.3.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.11.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.16.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.18.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.6.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.20.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.17.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.4.attention.self.key.weight', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.21.attention.output.dense.bias', 'base_model.encoder.layer.17.output.LayerNorm.bias', 'base_model.encoder.layer.18.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.22.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.18.attention.self.value.bias', 'base_model.encoder.layer.17.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.8.attention.self.key.bias', 'base_model.encoder.layer.5.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.13.output.LayerNorm.weight', 'base_model.encoder.layer.16.output.dense.bias', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.23.attention.self.query.bias', 'base_model.encoder.layer.5.attention.output.LayerNorm.weight', 'base_model.encoder.layer.13.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.23.attention.self.value.bias', 'base_model.encoder.layer.22.intermediate.dense.weight', 'base_model.encoder.layer.19.attention.self.key.bias', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.10.attention.self.key.bias', 'base_model.encoder.layer.9.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.11.attention.output.LayerNorm.bias', 'base_model.encoder.layer.21.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.2.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.22.attention.output.LayerNorm.bias', 'base_model.encoder.layer.10.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.20.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.8.attention.self.query.bias', 'base_model.encoder.layer.0.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.19.attention.self.query.weight', 'base_model.encoder.layer.12.attention.self.query.weight', 'base_model.encoder.layer.13.attention.output.LayerNorm.bias', 'base_model.encoder.layer.15.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.4.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.22.output.dense.weight', 'base_model.encoder.layer.21.attention.output.dense.weight', 'base_model.encoder.layer.10.attention.self.value.bias', 'base_model.encoder.layer.3.attention.output.LayerNorm.bias', 'base_model.encoder.layer.23.output.dense.bias', 'base_model.encoder.layer.14.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.2.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.4.output.dense.bias', 'base_model.encoder.layer.8.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.16.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.18.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.0.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.20.attention.self.value.weight', 'base_model.encoder.layer.12.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.23.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.20.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.12.output.LayerNorm.weight', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.20.attention.output.dense.bias', 'base_model.encoder.layer.22.output.LayerNorm.bias', 'base_model.encoder.layer.3.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.4.attention.self.query.bias', 'base_model.encoder.layer.9.output.LayerNorm.bias', 'base_model.encoder.layer.2.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.4.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.0.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.3.attention.self.query.bias', 'base_model.encoder.layer.15.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.18.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.9.attention.self.query.weight', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.21.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.1.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.21.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.2.intermediate.dense.bias', 'base_model.encoder.layer.11.attention.self.query.weight', 'base_model.encoder.layer.20.attention.self.key.bias', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.4.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.5.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.11.intermediate.dense.bias', 'base_model.encoder.layer.6.attention.output.LayerNorm.bias', 'base_model.encoder.layer.7.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.2.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.5.attention.output.dense.bias', 'base_model.encoder.layer.23.attention.output.LayerNorm.weight', 'base_model.encoder.layer.7.attention.output.dense.bias', 'base_model.encoder.layer.11.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.9.attention.output.dense.weight', 'base_model.encoder.layer.18.attention.self.key.weight', 'base_model.encoder.layer.6.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.4.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.23.intermediate.dense.bias', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.20.attention.self.query.weight', 'base_model.encoder.layer.18.attention.self.value.weight', 'base_model.encoder.layer.11.attention.self.key.bias', 'base_model.encoder.layer.13.attention.self.query.weight', 'base_model.encoder.layer.14.attention.self.query.weight', 'base_model.encoder.layer.15.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.13.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.7.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.20.output.dense.bias', 'base_model.encoder.layer.22.output.adapters.es.adapter_down.0.weight', 'base_model.embeddings.word_embeddings.weight', 'base_model.encoder.layer.11.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.19.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.13.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.9.output.dense.weight', 'base_model.encoder.layer.20.output.LayerNorm.bias', 'base_model.encoder.layer.4.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.0.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.1.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.7.attention.self.query.weight', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.3.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.11.output.dense.weight', 'base_model.encoder.layer.10.attention.self.value.weight', 'base_model.encoder.layer.22.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.6.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.11.attention.output.dense.weight', 'base_model.encoder.layer.5.attention.self.value.bias', 'base_model.encoder.layer.19.output.LayerNorm.weight', 'base_model.encoder.layer.10.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.19.attention.output.LayerNorm.bias', 'base_model.encoder.layer.5.attention.self.value.weight', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.21.output.adapters.ep.adapter_down.0.weight', 'base_model.embeddings.LayerNorm.bias', 'base_model.encoder.layer.5.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.3.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.18.output.LayerNorm.bias', 'base_model.encoder.layer.10.attention.self.query.bias', 'base_model.encoder.layer.20.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.23.output.LayerNorm.weight', 'base_model.encoder.layer.19.output.dense.weight', 'base_model.encoder.layer.17.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.7.intermediate.dense.weight', 'base_model.encoder.layer.11.intermediate.dense.weight', 'base_model.encoder.layer.7.attention.self.key.weight', 'base_model.encoder.layer.20.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.15.attention.output.dense.weight', 'base_model.encoder.layer.15.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.11.attention.self.query.bias', 'base_model.encoder.layer.4.attention.self.key.bias', 'base_model.encoder.layer.16.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.13.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.11.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.8.attention.self.value.bias', 'base_model.encoder.layer.2.attention.self.value.weight', 'base_model.encoder.layer.13.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.5.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.15.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.22.output.LayerNorm.weight', 'base_model.encoder.layer.3.attention.self.value.bias', 'base_model.encoder.layer.6.attention.self.key.bias', 'base_model.encoder.layer.3.attention.output.LayerNorm.weight', 'base_model.encoder.layer.16.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.18.attention.self.query.bias', 'base_model.encoder.layer.2.output.LayerNorm.weight', 'base_model.encoder.layer.16.intermediate.dense.weight', 'base_model.encoder.layer.2.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.9.attention.self.value.bias', 'base_model.encoder.layer.4.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.14.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.7.attention.output.LayerNorm.bias', 'base_model.encoder.layer.8.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.21.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.16.attention.self.value.bias', 'base_model.encoder.layer.15.output.dense.weight', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.14.attention.output.dense.bias', 'base_model.encoder.layer.10.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.23.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.15.attention.self.query.weight', 'base_model.encoder.layer.22.attention.self.query.bias', 'base_model.encoder.layer.10.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.13.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.2.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.7.attention.self.key.bias', 'base_model.encoder.layer.13.output.dense.weight', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.17.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.17.attention.self.value.weight', 'base_model.encoder.layer.0.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.13.attention.self.key.bias', 'base_model.encoder.layer.14.attention.output.LayerNorm.bias', 'base_model.encoder.layer.18.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.22.attention.self.key.bias', 'base_model.encoder.layer.14.attention.output.dense.weight', 'base_model.encoder.layer.18.attention.self.query.weight', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.20.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.0.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.23.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.10.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.12.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.19.intermediate.dense.weight', 'base_model.encoder.layer.19.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.3.attention.output.dense.weight', 'base_model.encoder.layer.17.attention.self.query.weight', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.18.attention.output.dense.weight', 'base_model.encoder.layer.11.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.15.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.10.attention.output.LayerNorm.weight', 'base_model.encoder.layer.12.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.7.attention.self.value.bias', 'base_model.encoder.layer.20.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.11.attention.output.LayerNorm.weight', 'base_model.encoder.layer.0.output.LayerNorm.bias', 'base_model.encoder.layer.10.output.LayerNorm.weight', 'base_model.encoder.layer.5.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.8.intermediate.dense.bias', 'base_model.encoder.layer.11.attention.output.dense.bias', 'base_model.encoder.layer.11.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.4.attention.output.dense.weight', 'base_model.encoder.layer.6.attention.self.key.weight', 'base_model.encoder.layer.9.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.1.attention.output.dense.bias', 'base_model.encoder.layer.0.attention.output.LayerNorm.bias', 'base_model.encoder.layer.14.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.6.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.12.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.7.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.2.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.6.output.dense.bias', 'base_model.encoder.layer.5.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.21.attention.output.LayerNorm.weight', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.0.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.6.attention.self.query.weight', 'base_model.encoder.layer.19.attention.self.value.bias', 'base_model.encoder.layer.0.attention.self.value.weight', 'base_model.encoder.layer.6.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.4.intermediate.dense.bias', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.5.attention.output.dense.weight', 'base_model.encoder.layer.10.attention.output.dense.weight', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.7.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.2.attention.output.LayerNorm.weight', 'base_model.encoder.layer.5.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.0.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.10.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.7.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.13.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.19.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.20.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.21.attention.self.query.weight', 'base_model.encoder.layer.4.attention.self.value.bias', 'base_model.encoder.layer.18.attention.output.LayerNorm.bias', 'base_model.encoder.layer.4.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.15.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.9.intermediate.dense.weight', 'base_model.encoder.layer.12.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.2.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.21.attention.self.query.bias', 'base_model.encoder.layer.23.output.adapters.ep.adapter_down.0.weight', 'base_model.embeddings.token_type_embeddings.weight', 'base_model.encoder.layer.7.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.4.intermediate.dense.weight', 'base_model.encoder.layer.3.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.5.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.3.attention.self.query.weight', 'base_model.encoder.layer.10.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.11.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.18.output.dense.weight', 'base_model.encoder.layer.6.output.LayerNorm.bias', 'base_model.encoder.layer.19.output.LayerNorm.bias', 'base_model.encoder.layer.12.attention.self.query.bias', 'base_model.encoder.layer.13.attention.self.value.bias', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.3.intermediate.dense.weight', 'base_model.encoder.layer.1.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.8.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.0.attention.output.dense.bias', 'base_model.encoder.layer.22.attention.self.query.weight', 'base_model.encoder.layer.20.intermediate.dense.weight', 'base_model.encoder.layer.15.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.2.attention.self.key.weight', 'base_model.encoder.layer.22.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.12.output.dense.bias', 'base_model.encoder.layer.5.intermediate.dense.weight', 'base_model.encoder.layer.23.attention.self.query.weight', 'base_model.encoder.layer.7.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.0.attention.self.key.weight', 'base_model.encoder.layer.18.attention.output.LayerNorm.weight', 'base_model.encoder.layer.1.attention.self.query.bias', 'base_model.encoder.layer.14.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.19.attention.self.value.weight', 'base_model.encoder.layer.21.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.15.attention.output.dense.bias', 'base_model.encoder.layer.12.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.21.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.22.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.6.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.16.attention.self.value.weight', 'base_model.encoder.layer.4.output.LayerNorm.bias', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.6.attention.output.LayerNorm.weight', 'base_model.encoder.layer.2.output.LayerNorm.bias', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.17.attention.output.dense.weight', 'base_model.encoder.layer.15.attention.output.LayerNorm.bias', 'base_model.encoder.layer.19.output.dense.bias', 'base_model.encoder.layer.0.output.LayerNorm.weight', 'base_model.encoder.layer.11.attention.self.key.weight', 'base_model.encoder.layer.20.attention.self.value.bias', 'base_model.encoder.layer.0.attention.self.query.bias', 'base_model.encoder.layer.23.attention.self.value.weight', 'base_model.encoder.layer.1.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.5.output.dense.bias', 'base_model.encoder.layer.19.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.8.intermediate.dense.weight', 'base_model.encoder.layer.1.output.LayerNorm.weight', 'base_model.encoder.layer.9.attention.self.value.weight', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.13.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.18.attention.output.dense.bias', 'base_model.encoder.layer.3.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.9.attention.output.dense.bias', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.2.output.dense.bias', 'base_model.encoder.layer.17.attention.self.key.bias', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.7.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.19.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.3.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.10.output.dense.weight', 'base_model.encoder.layer.4.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.5.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.12.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.5.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.6.intermediate.dense.weight', 'base_model.encoder.layer.1.output.LayerNorm.bias', 'base_model.encoder.layer.17.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.14.attention.self.key.weight', 'base_model.encoder.layer.0.intermediate.dense.weight', 'base_model.encoder.layer.15.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.15.intermediate.dense.bias', 'base_model.encoder.layer.17.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.6.attention.self.query.bias', 'base_model.encoder.layer.3.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.3.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.17.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.8.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.16.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.9.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.1.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.12.attention.output.dense.weight', 'base_model.encoder.layer.19.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.23.attention.output.dense.weight', 'base_model.encoder.layer.4.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.18.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.20.attention.output.dense.weight', 'base_model.encoder.layer.21.attention.self.key.weight', 'base_model.encoder.layer.13.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.22.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.3.attention.self.key.weight', 'base_model.encoder.layer.6.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.20.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.20.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.11.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.14.output.dense.bias', 'base_model.encoder.layer.4.attention.self.query.weight', 'base_model.encoder.layer.15.output.dense.bias', 'base_model.encoder.layer.16.output.dense.weight', 'base_model.encoder.layer.12.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.19.intermediate.dense.bias', 'base_model.encoder.layer.7.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.11.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.5.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.10.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.12.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.14.intermediate.dense.weight', 'base_model.encoder.layer.9.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.1.attention.self.query.weight', 'base_model.encoder.layer.22.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.23.attention.output.LayerNorm.bias', 'base_model.encoder.layer.4.attention.self.value.weight', 'base_model.encoder.layer.15.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.12.attention.output.LayerNorm.bias', 'base_model.encoder.layer.16.attention.self.query.weight', 'base_model.encoder.layer.15.attention.self.key.bias', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.22.attention.output.dense.weight', 'base_model.encoder.layer.18.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.12.attention.self.key.bias', 'base_model.encoder.layer.17.output.dense.bias', 'base_model.encoder.layer.2.intermediate.dense.weight', 'base_model.encoder.layer.12.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.10.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.20.output.adapters.ts.adapter_down.0.weight', 'base_model.pooler.dense.weight', 'base_model.encoder.layer.6.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.9.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.17.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.17.attention.output.dense.bias', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.1.intermediate.dense.weight', 'base_model.encoder.layer.15.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.16.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.14.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.14.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.1.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.18.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.21.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.17.attention.self.value.bias', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.14.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.1.attention.self.value.weight', 'base_model.encoder.layer.3.attention.self.value.weight', 'base_model.encoder.layer.17.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.3.attention.self.key.bias', 'base_model.encoder.layer.9.output.dense.bias', 'base_model.encoder.layer.14.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.19.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.1.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.20.attention.self.query.bias', 'base_model.encoder.layer.11.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.18.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.15.attention.self.query.bias', 'base_model.encoder.layer.14.output.LayerNorm.bias', 'base_model.encoder.layer.0.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.1.attention.self.key.bias', 'base_model.encoder.layer.0.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.6.attention.output.dense.weight', 'base_model.encoder.layer.6.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.9.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.15.attention.self.value.weight', 'base_model.encoder.layer.22.output.adapters.ep.adapter_down.0.weight', 'base_model.pooler.dense.bias', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.10.attention.output.LayerNorm.bias', 'base_model.encoder.layer.0.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.13.attention.self.key.weight', 'base_model.encoder.layer.21.intermediate.dense.bias', 'base_model.embeddings.position_ids', 'base_model.encoder.layer.7.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.13.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.15.output.LayerNorm.weight', 'base_model.encoder.layer.19.attention.output.LayerNorm.weight', 'base_model.encoder.layer.5.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.8.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.8.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.11.output.adapters.tp.adapter_up.bias', 'base_model.embeddings.position_embeddings.weight', 'base_model.encoder.layer.12.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.17.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.1.output.dense.bias', 'base_model.encoder.layer.20.output.dense.weight', 'base_model.encoder.layer.4.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.21.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.1.output.dense.weight', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.0.output.dense.weight', 'base_model.encoder.layer.9.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.10.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.3.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.13.attention.output.dense.bias', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.1.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.11.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.10.output.LayerNorm.bias', 'base_model.encoder.layer.1.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.9.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.3.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.8.attention.self.query.weight', 'base_model.encoder.layer.12.output.dense.weight', 'base_model.encoder.layer.21.output.dense.bias', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.10.attention.self.query.weight', 'base_model.encoder.layer.13.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.21.output.dense.weight', 'base_model.encoder.layer.17.attention.self.query.bias', 'base_model.encoder.layer.0.attention.self.key.bias', 'base_model.encoder.layer.3.output.LayerNorm.bias', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.6.intermediate.dense.bias', 'base_model.encoder.layer.7.attention.self.query.bias', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.7.output.dense.bias', 'base_model.encoder.layer.9.attention.output.LayerNorm.bias', 'base_model.encoder.layer.11.output.LayerNorm.bias', 'base_model.encoder.layer.11.attention.self.value.weight', 'base_model.encoder.layer.14.attention.output.LayerNorm.weight', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.17.attention.self.key.weight', 'base_model.encoder.layer.22.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.5.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.16.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.16.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.16.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.4.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.14.attention.self.value.weight', 'base_model.encoder.layer.20.output.LayerNorm.weight', 'base_model.encoder.layer.19.attention.output.dense.bias', 'base_model.encoder.layer.1.attention.output.LayerNorm.weight', 'base_model.encoder.layer.14.intermediate.dense.bias', 'base_model.encoder.layer.3.output.dense.bias', 'base_model.encoder.layer.4.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.21.attention.self.value.bias', 'base_model.encoder.layer.16.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.3.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.19.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.1.attention.output.dense.weight', 'base_model.encoder.layer.14.attention.self.query.bias', 'base_model.encoder.layer.7.attention.self.value.weight', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.3.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.7.output.dense.weight', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.8.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.19.attention.self.query.bias', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.15.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.8.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.23.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.12.output.LayerNorm.bias', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.22.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.23.attention.self.key.bias', 'base_model.encoder.layer.21.attention.self.key.bias', 'base_model.encoder.layer.12.attention.output.dense.bias', 'base_model.encoder.layer.6.output.LayerNorm.weight', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.1.intermediate.dense.bias', 'base_model.encoder.layer.13.intermediate.dense.weight', 'base_model.encoder.layer.15.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.6.attention.self.value.weight', 'base_model.encoder.layer.16.attention.output.LayerNorm.bias', 'base_model.encoder.layer.17.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.22.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.23.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.12.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.17.attention.output.LayerNorm.weight', 'base_model.encoder.layer.8.output.LayerNorm.bias', 'base_model.encoder.layer.5.attention.self.query.weight', 'base_model.encoder.layer.22.intermediate.dense.bias', 'base_model.encoder.layer.7.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.2.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.19.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.6.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.23.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.23.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.21.attention.output.LayerNorm.bias', 'base_model.encoder.layer.1.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.6.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.20.intermediate.dense.bias', 'base_model.encoder.layer.8.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.20.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.23.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.2.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.7.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.7.intermediate.dense.bias', 'base_model.encoder.layer.21.intermediate.dense.weight', 'base_model.encoder.layer.20.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.9.attention.self.key.weight', 'base_model.encoder.layer.23.output.LayerNorm.bias', 'base_model.encoder.layer.8.attention.self.value.weight', 'base_model.encoder.layer.23.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.17.intermediate.dense.weight', 'base_model.encoder.layer.7.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.3.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.1.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.9.attention.self.key.bias', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.8.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.12.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.23.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.5.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.8.output.dense.bias', 'base_model.encoder.layer.14.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.14.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.23.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.17.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.16.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.10.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.16.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.18.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.3.output.dense.weight', 'base_model.encoder.layer.20.attention.output.LayerNorm.weight', 'base_model.encoder.layer.16.attention.output.dense.bias', 'base_model.encoder.layer.21.output.LayerNorm.bias', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.17.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.14.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.8.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.0.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.7.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.9.attention.output.LayerNorm.weight', 'base_model.encoder.layer.1.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.12.attention.self.value.weight', 'base_model.encoder.layer.21.output.LayerNorm.weight', 'base_model.encoder.layer.21.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.0.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.18.intermediate.dense.bias', 'base_model.encoder.layer.11.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.22.output.dense.bias', 'base_model.encoder.layer.17.attention.output.LayerNorm.bias', 'base_model.encoder.layer.4.attention.output.LayerNorm.bias', 'base_model.encoder.layer.9.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.2.attention.output.LayerNorm.bias', 'base_model.encoder.layer.4.attention.output.dense.bias', 'base_model.encoder.layer.2.output.adapters.es.adapter_down.0.weight', 'qa_outputs.weight', 'base_model.encoder.layer.19.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.3.intermediate.dense.bias', 'base_model.encoder.layer.21.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.1.attention.self.key.weight', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.0.intermediate.dense.bias', 'base_model.encoder.layer.20.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.3.output.LayerNorm.weight', 'base_model.encoder.layer.9.output.adapters.es.adapter_up.weight', 'qa_outputs.bias', 'base_model.encoder.layer.14.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.0.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.4.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.13.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.16.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.9.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.8.output.dense.weight', 'base_model.encoder.layer.7.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.10.attention.self.key.weight', 'base_model.encoder.layer.10.attention.output.dense.bias', 'base_model.encoder.layer.2.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.10.intermediate.dense.weight', 'base_model.encoder.layer.16.attention.self.key.weight', 'base_model.encoder.layer.0.attention.output.LayerNorm.weight', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.14.attention.self.value.bias', 'base_model.encoder.layer.2.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.15.output.LayerNorm.bias', 'base_model.encoder.layer.13.attention.output.dense.weight', 'base_model.encoder.layer.0.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.6.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.8.attention.self.key.weight', 'base_model.encoder.layer.5.attention.self.key.weight', 'base_model.encoder.layer.9.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.15.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.3.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.19.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.16.attention.output.dense.weight', 'base_model.encoder.layer.7.output.LayerNorm.bias', 'base_model.encoder.layer.1.attention.output.LayerNorm.bias', 'base_model.encoder.layer.12.attention.output.LayerNorm.weight', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.3.attention.output.dense.bias', 'base_model.encoder.layer.19.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.21.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.5.attention.output.LayerNorm.bias', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.9.intermediate.dense.bias', 'base_model.encoder.layer.18.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.10.intermediate.dense.bias', 'base_model.encoder.layer.13.attention.self.value.weight', 'base_model.encoder.layer.10.output.dense.bias', 'base_model.encoder.layer.5.attention.self.query.bias', 'base_model.encoder.layer.19.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.10.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.12.intermediate.dense.weight', 'base_model.encoder.layer.23.attention.self.key.weight', 'base_model.encoder.layer.15.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.5.output.dense.weight', 'base_model.encoder.layer.12.intermediate.dense.bias', 'base_model.encoder.layer.2.attention.self.value.bias', 'base_model.encoder.layer.17.output.LayerNorm.weight', 'base_model.encoder.layer.21.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.4.attention.output.LayerNorm.weight', 'base_model.encoder.layer.5.output.LayerNorm.weight', 'base_model.encoder.layer.2.attention.self.query.weight', 'base_model.encoder.layer.2.attention.output.dense.weight', 'base_model.encoder.layer.6.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.12.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.17.output.dense.weight', 'base_model.encoder.layer.22.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.18.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.11.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.13.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.2.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.10.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.8.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.10.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.4.output.dense.weight', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.6.output.dense.weight', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.18.output.LayerNorm.weight', 'base_model.encoder.layer.9.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.13.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.22.attention.self.value.bias', 'base_model.encoder.layer.20.attention.output.LayerNorm.bias', 'base_model.encoder.layer.22.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.14.attention.self.key.bias', 'base_model.encoder.layer.23.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.8.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.11.output.dense.bias', 'base_model.encoder.layer.16.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.18.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.14.output.LayerNorm.weight', 'base_model.encoder.layer.4.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.16.output.LayerNorm.weight', 'base_model.encoder.layer.19.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.8.output.LayerNorm.weight', 'base_model.encoder.layer.15.attention.output.LayerNorm.weight', 'base_model.encoder.layer.20.attention.self.key.weight', 'base_model.encoder.layer.8.attention.output.LayerNorm.bias', 'base_model.encoder.layer.0.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.5.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.15.attention.self.value.bias', 'base_model.encoder.layer.22.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.14.output.dense.weight', 'base_model.encoder.layer.14.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.15.attention.self.key.weight', 'base_model.encoder.layer.14.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.17.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.18.attention.self.key.bias', 'base_model.encoder.layer.23.attention.output.dense.bias', 'base_model.encoder.layer.4.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.23.output.dense.weight', 'base_model.encoder.layer.13.attention.output.LayerNorm.weight', 'base_model.encoder.layer.12.attention.self.key.weight', 'base_model.encoder.layer.23.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.8.attention.output.dense.bias', 'base_model.encoder.layer.7.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.17.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.2.attention.self.key.bias', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.16.attention.self.query.bias', 'base_model.encoder.layer.12.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.7.attention.output.LayerNorm.weight', 'base_model.encoder.layer.11.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.5.attention.self.key.bias', 'base_model.encoder.layer.13.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.14.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.23.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.1.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.22.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.0.attention.self.value.bias', 'base_model.encoder.layer.0.output.dense.bias', 'base_model.encoder.layer.13.attention.self.query.bias', 'base_model.encoder.layer.18.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.3.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.6.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.19.attention.self.key.weight', 'base_model.encoder.layer.11.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.0.attention.self.query.weight', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.7.output.LayerNorm.weight', 'base_model.encoder.layer.16.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.21.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.16.output.LayerNorm.bias', 'base_model.encoder.layer.8.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.17.intermediate.dense.bias', 'base_model.encoder.layer.23.intermediate.dense.weight', 'base_model.encoder.layer.8.attention.output.LayerNorm.weight', 'base_model.encoder.layer.13.output.dense.bias']
- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of XLMRobertaModel were not initialized from the model checkpoint at /cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//squad/xlm-KG_LR4e-5_EPOCH2.0_maxlen384_batchsize4_gradacc8 and are newly initialized: ['encoder.layer.14.attention.self.query.bias', 'encoder.layer.4.attention.self.query.bias', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.20.attention.self.key.weight', 'encoder.layer.8.attention.self.query.bias', 'encoder.layer.23.attention.output.dense.weight', 'encoder.layer.0.attention.output.dense.bias', 'encoder.layer.11.attention.self.value.bias', 'encoder.layer.20.intermediate.dense.weight', 'encoder.layer.23.attention.self.key.bias', 'encoder.layer.3.attention.self.value.weight', 'encoder.layer.16.attention.self.key.bias', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.8.attention.self.key.weight', 'encoder.layer.5.output.dense.weight', 'encoder.layer.22.attention.self.value.weight', 'encoder.layer.18.attention.output.dense.weight', 'encoder.layer.23.attention.self.key.weight', 'encoder.layer.17.attention.self.query.bias', 'encoder.layer.18.attention.output.LayerNorm.bias', 'encoder.layer.4.attention.self.query.weight', 'encoder.layer.4.output.dense.bias', 'encoder.layer.8.attention.self.value.bias', 'encoder.layer.0.attention.self.value.weight', 'encoder.layer.17.output.dense.weight', 'encoder.layer.19.attention.output.LayerNorm.bias', 'encoder.layer.19.attention.self.key.weight', 'encoder.layer.3.output.dense.weight', 'encoder.layer.15.attention.output.dense.bias', 'encoder.layer.8.attention.self.query.weight', 'encoder.layer.8.output.dense.weight', 'encoder.layer.15.attention.self.query.weight', 'encoder.layer.13.attention.self.key.weight', 'encoder.layer.17.attention.self.key.weight', 'encoder.layer.19.attention.output.LayerNorm.weight', 'encoder.layer.21.output.LayerNorm.bias', 'encoder.layer.9.attention.output.dense.weight', 'encoder.layer.23.output.dense.bias', 'encoder.layer.19.attention.output.dense.bias', 'encoder.layer.14.output.dense.bias', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.5.attention.output.dense.weight', 'encoder.layer.7.attention.output.LayerNorm.bias', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.16.intermediate.dense.bias', 'encoder.layer.5.attention.self.value.bias', 'encoder.layer.6.attention.output.dense.weight', 'encoder.layer.12.attention.self.value.weight', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.18.attention.self.query.bias', 'encoder.layer.23.attention.self.value.bias', 'encoder.layer.11.output.LayerNorm.weight', 'encoder.layer.21.attention.self.query.weight', 'encoder.layer.12.attention.self.query.weight', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.11.attention.self.value.weight', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.17.attention.self.value.bias', 'encoder.layer.9.attention.self.value.bias', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.7.attention.self.value.weight', 'encoder.layer.8.output.LayerNorm.weight', 'encoder.layer.7.attention.self.query.bias', 'encoder.layer.3.attention.self.key.bias', 'encoder.layer.3.output.dense.bias', 'encoder.layer.15.output.LayerNorm.bias', 'encoder.layer.19.output.LayerNorm.bias', 'encoder.layer.19.attention.self.query.bias', 'encoder.layer.7.output.LayerNorm.weight', 'encoder.layer.20.attention.output.dense.weight', 'encoder.layer.18.output.LayerNorm.weight', 'encoder.layer.20.attention.self.key.bias', 'encoder.layer.14.attention.self.value.weight', 'encoder.layer.6.attention.output.dense.bias', 'encoder.layer.21.attention.output.LayerNorm.weight', 'encoder.layer.1.attention.self.query.weight', 'encoder.layer.13.attention.output.dense.weight', 'encoder.layer.10.output.dense.weight', 'encoder.layer.2.attention.self.value.weight', 'encoder.layer.8.attention.self.key.bias', 'encoder.layer.1.attention.self.value.weight', 'embeddings.LayerNorm.weight', 'encoder.layer.2.attention.self.query.weight', 'encoder.layer.11.attention.output.LayerNorm.weight', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.18.intermediate.dense.bias', 'encoder.layer.22.output.dense.bias', 'encoder.layer.20.output.dense.weight', 'encoder.layer.10.attention.self.key.bias', 'encoder.layer.1.attention.output.dense.weight', 'encoder.layer.1.attention.self.query.bias', 'encoder.layer.15.attention.self.query.bias', 'encoder.layer.5.attention.output.LayerNorm.weight', 'encoder.layer.0.attention.self.query.weight', 'encoder.layer.22.attention.self.value.bias', 'encoder.layer.15.output.dense.bias', 'encoder.layer.7.attention.output.dense.bias', 'encoder.layer.7.attention.self.key.weight', 'encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.layer.14.output.LayerNorm.bias', 'encoder.layer.22.output.dense.weight', 'encoder.layer.13.attention.self.query.weight', 'encoder.layer.2.output.dense.bias', 'encoder.layer.22.output.LayerNorm.weight', 'encoder.layer.5.output.LayerNorm.bias', 'encoder.layer.2.attention.output.dense.bias', 'encoder.layer.15.output.LayerNorm.weight', 'encoder.layer.19.attention.self.value.bias', 'encoder.layer.18.output.LayerNorm.bias', 'encoder.layer.12.attention.self.value.bias', 'encoder.layer.9.output.dense.bias', 'encoder.layer.12.attention.self.query.bias', 'encoder.layer.9.attention.self.key.bias', 'encoder.layer.10.attention.output.LayerNorm.bias', 'encoder.layer.11.attention.output.dense.weight', 'encoder.layer.13.attention.self.value.bias', 'encoder.layer.15.attention.self.key.bias', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.15.attention.self.value.weight', 'encoder.layer.23.output.LayerNorm.bias', 'encoder.layer.5.attention.self.query.weight', 'encoder.layer.18.attention.self.key.bias', 'encoder.layer.16.intermediate.dense.weight', 'encoder.layer.21.output.dense.bias', 'encoder.layer.19.attention.self.key.bias', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.4.attention.output.dense.weight', 'encoder.layer.2.attention.self.key.bias', 'encoder.layer.2.attention.output.LayerNorm.weight', 'encoder.layer.20.attention.self.value.bias', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.16.output.LayerNorm.weight', 'encoder.layer.16.output.dense.weight', 'encoder.layer.6.attention.self.query.weight', 'encoder.layer.15.attention.self.key.weight', 'encoder.layer.23.intermediate.dense.weight', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.10.attention.self.query.bias', 'encoder.layer.1.output.dense.bias', 'encoder.layer.19.attention.self.query.weight', 'encoder.layer.12.intermediate.dense.weight', 'encoder.layer.12.attention.self.key.weight', 'encoder.layer.23.attention.self.query.weight', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.15.attention.output.dense.weight', 'encoder.layer.6.attention.self.key.weight', 'encoder.layer.8.attention.output.dense.weight', 'encoder.layer.5.output.dense.bias', 'encoder.layer.3.attention.self.query.bias', 'encoder.layer.5.attention.self.key.bias', 'encoder.layer.10.attention.output.dense.weight', 'encoder.layer.14.attention.output.LayerNorm.weight', 'embeddings.LayerNorm.bias', 'encoder.layer.11.attention.self.key.weight', 'encoder.layer.13.attention.self.key.bias', 'encoder.layer.6.output.dense.weight', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.1.attention.output.dense.bias', 'encoder.layer.21.attention.output.dense.bias', 'encoder.layer.23.attention.self.query.bias', 'encoder.layer.3.attention.output.dense.weight', 'encoder.layer.8.attention.output.LayerNorm.bias', 'encoder.layer.9.attention.self.key.weight', 'encoder.layer.4.attention.self.key.bias', 'encoder.layer.12.output.dense.bias', 'encoder.layer.23.output.dense.weight', 'encoder.layer.22.attention.self.key.weight', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.0.attention.self.query.bias', 'encoder.layer.21.attention.self.value.bias', 'encoder.layer.8.output.dense.bias', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.10.intermediate.dense.weight', 'encoder.layer.22.intermediate.dense.weight', 'encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.layer.10.output.LayerNorm.weight', 'encoder.layer.13.attention.self.query.bias', 'encoder.layer.9.output.LayerNorm.weight', 'encoder.layer.2.attention.self.value.bias', 'encoder.layer.17.intermediate.dense.weight', 'encoder.layer.2.attention.output.LayerNorm.bias', 'encoder.layer.16.attention.self.value.weight', 'encoder.layer.20.attention.self.query.bias', 'encoder.layer.16.attention.self.query.bias', 'encoder.layer.12.output.LayerNorm.bias', 'encoder.layer.23.attention.output.dense.bias', 'encoder.layer.16.attention.output.dense.bias', 'encoder.layer.22.attention.output.LayerNorm.weight', 'encoder.layer.2.attention.self.key.weight', 'encoder.layer.22.attention.self.key.bias', 'encoder.layer.20.attention.output.dense.bias', 'encoder.layer.4.attention.self.key.weight', 'encoder.layer.22.attention.output.dense.bias', 'encoder.layer.14.intermediate.dense.weight', 'encoder.layer.17.intermediate.dense.bias', 'encoder.layer.6.attention.output.LayerNorm.weight', 'encoder.layer.8.output.LayerNorm.bias', 'encoder.layer.21.intermediate.dense.weight', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.4.output.dense.weight', 'encoder.layer.19.attention.self.value.weight', 'encoder.layer.16.attention.self.value.bias', 'encoder.layer.17.attention.self.key.bias', 'encoder.layer.18.attention.self.query.weight', 'encoder.layer.3.attention.output.dense.bias', 'encoder.layer.6.attention.self.key.bias', 'encoder.layer.23.attention.output.LayerNorm.weight', 'encoder.layer.4.attention.output.dense.bias', 'encoder.layer.5.attention.self.key.weight', 'encoder.layer.13.attention.output.LayerNorm.weight', 'encoder.layer.15.output.dense.weight', 'encoder.layer.23.output.LayerNorm.weight', 'encoder.layer.4.attention.self.value.bias', 'encoder.layer.17.attention.self.query.weight', 'encoder.layer.11.output.dense.bias', 'encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.18.output.dense.weight', 'encoder.layer.13.intermediate.dense.bias', 'encoder.layer.12.attention.output.dense.weight', 'encoder.layer.19.attention.output.dense.weight', 'encoder.layer.21.attention.self.value.weight', 'encoder.layer.6.attention.self.query.bias', 'encoder.layer.1.attention.self.key.bias', 'encoder.layer.7.attention.output.dense.weight', 'encoder.layer.0.attention.self.value.bias', 'encoder.layer.7.attention.self.key.bias', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.7.output.dense.weight', 'encoder.layer.0.output.dense.weight', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.12.output.dense.weight', 'encoder.layer.19.intermediate.dense.bias', 'encoder.layer.1.attention.output.LayerNorm.weight', 'encoder.layer.11.output.dense.weight', 'encoder.layer.16.output.LayerNorm.bias', 'encoder.layer.0.attention.output.dense.weight', 'encoder.layer.22.output.LayerNorm.bias', 'encoder.layer.19.output.dense.weight', 'encoder.layer.12.attention.output.LayerNorm.weight', 'encoder.layer.18.attention.self.key.weight', 'encoder.layer.10.attention.self.value.weight', 'encoder.layer.0.attention.self.key.bias', 'encoder.layer.16.attention.self.key.weight', 'encoder.layer.10.attention.output.LayerNorm.weight', 'encoder.layer.23.intermediate.dense.bias', 'encoder.layer.10.attention.output.dense.bias', 'encoder.layer.10.output.dense.bias', 'encoder.layer.21.attention.self.key.weight', 'encoder.layer.14.attention.output.dense.weight', 'encoder.layer.2.attention.self.query.bias', 'embeddings.word_embeddings.weight', 'encoder.layer.13.intermediate.dense.weight', 'encoder.layer.22.attention.self.query.bias', 'encoder.layer.9.attention.output.LayerNorm.bias', 'encoder.layer.18.output.dense.bias', 'encoder.layer.5.attention.output.dense.bias', 'encoder.layer.1.attention.self.key.weight', 'encoder.layer.4.attention.output.LayerNorm.weight', 'encoder.layer.5.attention.self.value.weight', 'encoder.layer.22.attention.self.query.weight', 'encoder.layer.7.attention.self.query.weight', 'encoder.layer.9.output.LayerNorm.bias', 'encoder.layer.8.attention.output.LayerNorm.weight', 'encoder.layer.18.intermediate.dense.weight', 'encoder.layer.18.attention.output.dense.bias', 'encoder.layer.3.attention.self.value.bias', 'encoder.layer.13.attention.output.LayerNorm.bias', 'encoder.layer.14.attention.self.value.bias', 'encoder.layer.15.intermediate.dense.bias', 'encoder.layer.12.attention.output.dense.bias', 'encoder.layer.20.intermediate.dense.bias', 'encoder.layer.9.attention.self.query.bias', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.19.intermediate.dense.weight', 'encoder.layer.7.attention.output.LayerNorm.weight', 'encoder.layer.13.output.LayerNorm.bias', 'encoder.layer.14.intermediate.dense.bias', 'encoder.layer.15.intermediate.dense.weight', 'encoder.layer.7.intermediate.dense.bias', 'encoder.layer.21.attention.output.LayerNorm.bias', 'encoder.layer.17.attention.output.LayerNorm.bias', 'encoder.layer.21.output.dense.weight', 'encoder.layer.15.attention.output.LayerNorm.bias', 'encoder.layer.10.output.LayerNorm.bias', 'encoder.layer.16.attention.output.dense.weight', 'encoder.layer.8.attention.output.dense.bias', 'encoder.layer.17.output.LayerNorm.weight', 'encoder.layer.18.attention.output.LayerNorm.weight', 'encoder.layer.11.attention.self.query.weight', 'encoder.layer.11.attention.output.dense.bias', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.10.attention.self.key.weight', 'encoder.layer.12.output.LayerNorm.weight', 'encoder.layer.14.attention.self.query.weight', 'encoder.layer.18.attention.self.value.weight', 'embeddings.position_embeddings.weight', 'encoder.layer.12.attention.output.LayerNorm.bias', 'encoder.layer.6.attention.self.value.weight', 'encoder.layer.21.attention.self.query.bias', 'encoder.layer.15.attention.self.value.bias', 'encoder.layer.1.attention.self.value.bias', 'encoder.layer.17.attention.self.value.weight', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.14.attention.output.LayerNorm.bias', 'encoder.layer.18.attention.self.value.bias', 'encoder.layer.1.output.dense.weight', 'encoder.layer.10.attention.self.value.bias', 'encoder.layer.3.attention.self.query.weight', 'encoder.layer.16.attention.output.LayerNorm.bias', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.20.output.dense.bias', 'encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.layer.7.attention.self.value.bias', 'encoder.layer.7.output.LayerNorm.bias', 'encoder.layer.13.attention.self.value.weight', 'encoder.layer.17.output.dense.bias', 'encoder.layer.13.output.LayerNorm.weight', 'encoder.layer.21.intermediate.dense.bias', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.21.attention.self.key.bias', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.16.output.dense.bias', 'encoder.layer.11.output.LayerNorm.bias', 'encoder.layer.19.output.LayerNorm.weight', 'encoder.layer.13.output.dense.weight', 'encoder.layer.16.attention.self.query.weight', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.9.attention.output.dense.bias', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.20.attention.self.query.weight', 'encoder.layer.6.attention.self.value.bias', 'encoder.layer.17.output.LayerNorm.bias', 'encoder.layer.5.attention.self.query.bias', 'encoder.layer.12.intermediate.dense.bias', 'encoder.layer.10.attention.self.query.weight', 'encoder.layer.2.output.dense.weight', 'encoder.layer.17.attention.output.dense.weight', 'encoder.layer.14.output.LayerNorm.weight', 'encoder.layer.13.output.dense.bias', 'encoder.layer.19.output.dense.bias', 'encoder.layer.3.attention.self.key.weight', 'encoder.layer.22.attention.output.LayerNorm.bias', 'encoder.layer.22.attention.output.dense.weight', 'encoder.layer.15.attention.output.LayerNorm.weight', 'encoder.layer.20.attention.output.LayerNorm.bias', 'encoder.layer.9.attention.self.value.weight', 'encoder.layer.14.attention.self.key.weight', 'encoder.layer.23.attention.output.LayerNorm.bias', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.9.attention.output.LayerNorm.weight', 'encoder.layer.17.attention.output.LayerNorm.weight', 'encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.layer.20.output.LayerNorm.weight', 'encoder.layer.16.attention.output.LayerNorm.weight', 'encoder.layer.6.output.LayerNorm.bias', 'encoder.layer.4.attention.self.value.weight', 'encoder.layer.9.output.dense.weight', 'encoder.layer.11.attention.self.key.bias', 'encoder.layer.17.attention.output.dense.bias', 'encoder.layer.23.attention.self.value.weight', 'encoder.layer.6.output.dense.bias', 'encoder.layer.22.intermediate.dense.bias', 'encoder.layer.12.attention.self.key.bias', 'encoder.layer.13.attention.output.dense.bias', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.11.attention.self.query.bias', 'encoder.layer.21.attention.output.dense.weight', 'encoder.layer.20.attention.self.value.weight', 'encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.layer.20.attention.output.LayerNorm.weight', 'encoder.layer.0.attention.output.LayerNorm.weight', 'encoder.layer.4.attention.output.LayerNorm.bias', 'encoder.layer.14.output.dense.weight', 'encoder.layer.21.output.LayerNorm.weight', 'encoder.layer.7.output.dense.bias', 'encoder.layer.14.attention.output.dense.bias', 'encoder.layer.9.attention.self.query.weight', 'encoder.layer.2.attention.output.dense.weight', 'encoder.layer.8.attention.self.value.weight', 'encoder.layer.6.attention.output.LayerNorm.bias', 'encoder.layer.20.output.LayerNorm.bias', 'embeddings.token_type_embeddings.weight', 'encoder.layer.1.output.LayerNorm.bias', 'pooler.dense.bias', 'pooler.dense.weight', 'encoder.layer.0.attention.self.key.weight', 'encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.layer.14.attention.self.key.bias', 'encoder.layer.0.output.dense.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Overwriting existing adapter 'ep'.
Overwriting existing adapter 'tp'.
Overwriting existing adapter 'es'.
Overwriting existing adapter 'ts'.
Overwriting existing adapter fusion module 'ep,tp,es,ts'
05/09/2022 19:50:21 - INFO - __main__ -   Creating features from dataset file at .
/cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//squad/xlm-KG_LR4e-5_EPOCH2.0_maxlen384_batchsize4_gradacc8
XLMConfig {
  "architectures": [
    "XLMRobertaForMaskedLM"
  ],
  "asm": false,
  "attention_dropout": 0.1,
  "attention_probs_dropout_prob": 0.1,
  "bos_index": 0,
  "bos_token_id": 0,
  "causal": false,
  "dropout": 0.1,
  "emb_dim": 1024,
  "embed_init_std": 0.02209708691207961,
  "end_n_top": 5,
  "eos_index": 1,
  "eos_token_id": 2,
  "gelu_activation": true,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "init_std": 0.02,
  "initializer_range": 0.02,
  "intermediate_size": 4096,
  "is_encoder": true,
  "lang_id": 0,
  "layer_norm_eps": 1e-05,
  "mask_index": 5,
  "mask_token_id": 0,
  "max_position_embeddings": 514,
  "model_type": "xlm",
  "n_heads": 16,
  "n_langs": 1,
  "n_layers": 24,
  "output_past": true,
  "pad_index": 2,
  "pad_token_id": 1,
  "sinusoidal_embeddings": false,
  "start_n_top": 5,
  "summary_activation": null,
  "summary_first_dropout": 0.1,
  "summary_proj_to_labels": true,
  "summary_type": "first",
  "summary_use_proj": true,
  "transformers_version": "4.17.0",
  "type_vocab_size": 1,
  "unk_index": 3,
  "use_lang_emb": false,
  "vocab_size": 250002
}

  0%|          | 0/48 [00:00<?, ?it/s] 33%|███▎      | 16/48 [00:00<00:00, 128.87it/s] 60%|██████    | 29/48 [00:00<00:00, 113.47it/s] 92%|█████████▏| 44/48 [00:00<00:00, 126.62it/s]100%|██████████| 48/48 [00:00<00:00, 126.86it/s]
convert squad examples to features:   0%|          | 0/1190 [00:00<?, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.
convert squad examples to features:   0%|          | 1/1190 [00:00<02:52,  6.87it/s]convert squad examples to features:   3%|▎         | 33/1190 [00:00<00:07, 155.05it/s]convert squad examples to features:   5%|▌         | 65/1190 [00:00<00:05, 205.39it/s]convert squad examples to features:   8%|▊         | 97/1190 [00:00<00:04, 238.58it/s]convert squad examples to features:  14%|█▎        | 161/1190 [00:00<00:03, 329.88it/s]convert squad examples to features:  19%|█▉        | 225/1190 [00:00<00:03, 320.99it/s]convert squad examples to features:  22%|██▏       | 258/1190 [00:00<00:03, 305.88it/s]convert squad examples to features:  24%|██▍       | 289/1190 [00:01<00:02, 303.88it/s]convert squad examples to features:  27%|██▋       | 321/1190 [00:01<00:03, 285.69it/s]convert squad examples to features:  30%|██▉       | 353/1190 [00:01<00:03, 274.61it/s]convert squad examples to features:  32%|███▏      | 385/1190 [00:01<00:05, 157.80it/s]convert squad examples to features:  35%|███▌      | 417/1190 [00:01<00:04, 171.31it/s]convert squad examples to features:  38%|███▊      | 449/1190 [00:02<00:03, 187.63it/s]convert squad examples to features:  40%|████      | 481/1190 [00:02<00:03, 193.36it/s]convert squad examples to features:  43%|████▎     | 513/1190 [00:02<00:03, 194.05it/s]convert squad examples to features:  46%|████▌     | 545/1190 [00:02<00:03, 166.23it/s]convert squad examples to features:  48%|████▊     | 577/1190 [00:02<00:03, 171.19it/s]convert squad examples to features:  51%|█████     | 609/1190 [00:02<00:03, 167.41it/s]convert squad examples to features:  54%|█████▍    | 641/1190 [00:03<00:03, 180.38it/s]convert squad examples to features:  57%|█████▋    | 673/1190 [00:03<00:03, 166.72it/s]convert squad examples to features:  59%|█████▉    | 705/1190 [00:03<00:02, 175.75it/s]convert squad examples to features:  62%|██████▏   | 737/1190 [00:03<00:02, 201.12it/s]convert squad examples to features:  65%|██████▍   | 769/1190 [00:03<00:02, 208.99it/s]convert squad examples to features:  67%|██████▋   | 801/1190 [00:03<00:01, 228.56it/s]convert squad examples to features:  70%|███████   | 833/1190 [00:03<00:01, 223.21it/s]convert squad examples to features:  73%|███████▎  | 865/1190 [00:04<00:01, 202.53it/s]convert squad examples to features:  75%|███████▌  | 897/1190 [00:04<00:01, 190.90it/s]convert squad examples to features:  78%|███████▊  | 929/1190 [00:04<00:01, 177.84it/s]convert squad examples to features:  81%|████████  | 961/1190 [00:04<00:01, 163.61it/s]convert squad examples to features:  83%|████████▎ | 993/1190 [00:04<00:01, 171.80it/s]convert squad examples to features:  86%|████████▌ | 1025/1190 [00:05<00:00, 187.54it/s]convert squad examples to features:  89%|████████▉ | 1057/1190 [00:05<00:00, 209.53it/s]convert squad examples to features:  92%|█████████▏| 1089/1190 [00:05<00:00, 201.29it/s]convert squad examples to features:  94%|█████████▍| 1121/1190 [00:05<00:00, 196.38it/s]convert squad examples to features:  97%|█████████▋| 1153/1190 [00:05<00:00, 181.23it/s]convert squad examples to features: 100%|██████████| 1190/1190 [00:05<00:00, 205.33it/s]/cluster/project/sachan/yifan/softwares/anaconda/anaconda3/envs/xfactr/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2272: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

add example index and unique id:   0%|          | 0/1190 [00:00<?, ?it/s]add example index and unique id: 100%|██████████| 1190/1190 [00:00<00:00, 629172.04it/s]
05/09/2022 19:50:28 - INFO - __main__ -   Saving features into cached file ./cached_xquad.en.json_xlm-KG_LR4e-5_EPOCH2.0_maxlen384_batchsize4_gradacc8_384_en
05/09/2022 19:50:29 - INFO - __main__ -   ***** Running evaluation  *****
05/09/2022 19:50:29 - INFO - __main__ -     Num examples = 1270
05/09/2022 19:50:29 - INFO - __main__ -     Batch size = 8
Evaluating:   0%|          | 0/159 [00:00<?, ?it/s]Evaluating:   1%|          | 1/159 [00:01<04:12,  1.60s/it]Evaluating:   1%|▏         | 2/159 [00:01<02:16,  1.15it/s]Evaluating:   2%|▏         | 3/159 [00:02<01:38,  1.59it/s]Evaluating:   3%|▎         | 4/159 [00:02<01:20,  1.92it/s]Evaluating:   3%|▎         | 5/159 [00:03<01:10,  2.17it/s]Evaluating:   4%|▍         | 6/159 [00:03<01:04,  2.37it/s]Evaluating:   4%|▍         | 7/159 [00:03<01:00,  2.50it/s]Evaluating:   5%|▌         | 8/159 [00:04<00:57,  2.61it/s]Evaluating:   6%|▌         | 9/159 [00:04<00:56,  2.67it/s]Evaluating:   6%|▋         | 10/159 [00:04<00:54,  2.72it/s]Evaluating:   7%|▋         | 11/159 [00:05<00:53,  2.76it/s]Evaluating:   8%|▊         | 12/159 [00:05<00:52,  2.78it/s]Evaluating:   8%|▊         | 13/159 [00:05<00:52,  2.80it/s]Evaluating:   9%|▉         | 14/159 [00:06<00:51,  2.82it/s]Evaluating:   9%|▉         | 15/159 [00:06<00:50,  2.83it/s]Evaluating:  10%|█         | 16/159 [00:06<00:50,  2.84it/s]Evaluating:  11%|█         | 17/159 [00:07<00:49,  2.85it/s]Evaluating:  11%|█▏        | 18/159 [00:07<00:49,  2.85it/s]Evaluating:  12%|█▏        | 19/159 [00:07<00:49,  2.85it/s]Evaluating:  13%|█▎        | 20/159 [00:08<00:48,  2.85it/s]Evaluating:  13%|█▎        | 21/159 [00:08<00:48,  2.85it/s]Evaluating:  14%|█▍        | 22/159 [00:08<00:47,  2.86it/s]Evaluating:  14%|█▍        | 23/159 [00:09<00:47,  2.86it/s]Evaluating:  15%|█▌        | 24/159 [00:09<00:47,  2.86it/s]Evaluating:  16%|█▌        | 25/159 [00:10<00:47,  2.81it/s]Evaluating:  16%|█▋        | 26/159 [00:10<00:47,  2.82it/s]Evaluating:  17%|█▋        | 27/159 [00:10<00:46,  2.83it/s]Evaluating:  18%|█▊        | 28/159 [00:11<00:46,  2.84it/s]Evaluating:  18%|█▊        | 29/159 [00:11<00:45,  2.84it/s]Evaluating:  19%|█▉        | 30/159 [00:11<00:45,  2.84it/s]Evaluating:  19%|█▉        | 31/159 [00:12<00:45,  2.84it/s]Evaluating:  20%|██        | 32/159 [00:12<00:44,  2.84it/s]Evaluating:  21%|██        | 33/159 [00:12<00:44,  2.83it/s]Evaluating:  21%|██▏       | 34/159 [00:13<00:44,  2.83it/s]Evaluating:  22%|██▏       | 35/159 [00:13<00:43,  2.83it/s]Evaluating:  23%|██▎       | 36/159 [00:13<00:43,  2.83it/s]Evaluating:  23%|██▎       | 37/159 [00:14<00:43,  2.83it/s]Evaluating:  24%|██▍       | 38/159 [00:14<00:42,  2.82it/s]Evaluating:  25%|██▍       | 39/159 [00:14<00:42,  2.79it/s]Evaluating:  25%|██▌       | 40/159 [00:15<00:44,  2.70it/s]Evaluating:  26%|██▌       | 41/159 [00:15<00:45,  2.61it/s]Evaluating:  26%|██▋       | 42/159 [00:16<00:46,  2.49it/s]Evaluating:  27%|██▋       | 43/159 [00:16<00:45,  2.55it/s]Evaluating:  28%|██▊       | 44/159 [00:16<00:44,  2.59it/s]Evaluating:  28%|██▊       | 45/159 [00:17<00:43,  2.63it/s]Evaluating:  29%|██▉       | 46/159 [00:17<00:42,  2.65it/s]Evaluating:  30%|██▉       | 47/159 [00:18<00:41,  2.69it/s]Evaluating:  30%|███       | 48/159 [00:18<00:40,  2.73it/s]Evaluating:  31%|███       | 49/159 [00:18<00:39,  2.77it/s]Evaluating:  31%|███▏      | 50/159 [00:19<00:39,  2.78it/s]Evaluating:  32%|███▏      | 51/159 [00:19<00:38,  2.79it/s]Evaluating:  33%|███▎      | 52/159 [00:19<00:38,  2.78it/s]Evaluating:  33%|███▎      | 53/159 [00:20<00:38,  2.78it/s]Evaluating:  34%|███▍      | 54/159 [00:20<00:37,  2.79it/s]Evaluating:  35%|███▍      | 55/159 [00:20<00:37,  2.79it/s]Evaluating:  35%|███▌      | 56/159 [00:21<00:36,  2.80it/s]Evaluating:  36%|███▌      | 57/159 [00:21<00:36,  2.80it/s]Evaluating:  36%|███▋      | 58/159 [00:21<00:36,  2.80it/s]Evaluating:  37%|███▋      | 59/159 [00:22<00:35,  2.79it/s]Evaluating:  38%|███▊      | 60/159 [00:22<00:35,  2.80it/s]Evaluating:  38%|███▊      | 61/159 [00:23<00:35,  2.80it/s]Evaluating:  39%|███▉      | 62/159 [00:23<00:34,  2.81it/s]Evaluating:  40%|███▉      | 63/159 [00:23<00:34,  2.82it/s]Evaluating:  40%|████      | 64/159 [00:24<00:33,  2.82it/s]Evaluating:  41%|████      | 65/159 [00:24<00:33,  2.82it/s]Evaluating:  42%|████▏     | 66/159 [00:24<00:33,  2.79it/s]Evaluating:  42%|████▏     | 67/159 [00:25<00:32,  2.80it/s]Evaluating:  43%|████▎     | 68/159 [00:25<00:32,  2.80it/s]Evaluating:  43%|████▎     | 69/159 [00:25<00:32,  2.81it/s]Evaluating:  44%|████▍     | 70/159 [00:26<00:31,  2.81it/s]Evaluating:  45%|████▍     | 71/159 [00:26<00:31,  2.81it/s]Evaluating:  45%|████▌     | 72/159 [00:26<00:31,  2.80it/s]Evaluating:  46%|████▌     | 73/159 [00:27<00:30,  2.81it/s]Evaluating:  47%|████▋     | 74/159 [00:27<00:30,  2.81it/s]Evaluating:  47%|████▋     | 75/159 [00:28<00:30,  2.79it/s]Evaluating:  48%|████▊     | 76/159 [00:28<00:29,  2.80it/s]Evaluating:  48%|████▊     | 77/159 [00:28<00:29,  2.81it/s]Evaluating:  49%|████▉     | 78/159 [00:29<00:28,  2.81it/s]Evaluating:  50%|████▉     | 79/159 [00:29<00:28,  2.80it/s]Evaluating:  50%|█████     | 80/159 [00:29<00:28,  2.80it/s]Evaluating:  51%|█████     | 81/159 [00:30<00:27,  2.80it/s]Evaluating:  52%|█████▏    | 82/159 [00:30<00:27,  2.80it/s]Evaluating:  52%|█████▏    | 83/159 [00:30<00:27,  2.80it/s]Evaluating:  53%|█████▎    | 84/159 [00:31<00:26,  2.80it/s]Evaluating:  53%|█████▎    | 85/159 [00:31<00:26,  2.80it/s]Evaluating:  54%|█████▍    | 86/159 [00:31<00:26,  2.80it/s]Evaluating:  55%|█████▍    | 87/159 [00:32<00:25,  2.80it/s]Evaluating:  55%|█████▌    | 88/159 [00:32<00:25,  2.81it/s]Evaluating:  56%|█████▌    | 89/159 [00:33<00:24,  2.81it/s]Evaluating:  57%|█████▋    | 90/159 [00:33<00:25,  2.74it/s]Evaluating:  57%|█████▋    | 91/159 [00:33<00:24,  2.76it/s]Evaluating:  58%|█████▊    | 92/159 [00:34<00:24,  2.78it/s]Evaluating:  58%|█████▊    | 93/159 [00:34<00:23,  2.78it/s]Evaluating:  59%|█████▉    | 94/159 [00:34<00:23,  2.75it/s]Evaluating:  60%|█████▉    | 95/159 [00:35<00:23,  2.77it/s]Evaluating:  60%|██████    | 96/159 [00:35<00:22,  2.79it/s]Evaluating:  61%|██████    | 97/159 [00:35<00:22,  2.79it/s]Evaluating:  62%|██████▏   | 98/159 [00:36<00:21,  2.80it/s]Evaluating:  62%|██████▏   | 99/159 [00:36<00:22,  2.69it/s]Evaluating:  63%|██████▎   | 100/159 [00:37<00:22,  2.64it/s]Evaluating:  64%|██████▎   | 101/159 [00:37<00:22,  2.63it/s]Evaluating:  64%|██████▍   | 102/159 [00:37<00:21,  2.67it/s]Evaluating:  65%|██████▍   | 103/159 [00:38<00:20,  2.71it/s]Evaluating:  65%|██████▌   | 104/159 [00:38<00:20,  2.74it/s]Evaluating:  66%|██████▌   | 105/159 [00:38<00:19,  2.76it/s]Evaluating:  67%|██████▋   | 106/159 [00:39<00:19,  2.68it/s]Evaluating:  67%|██████▋   | 107/159 [00:39<00:19,  2.72it/s]Evaluating:  68%|██████▊   | 108/159 [00:40<00:18,  2.75it/s]Evaluating:  69%|██████▊   | 109/159 [00:40<00:18,  2.76it/s]Evaluating:  69%|██████▉   | 110/159 [00:40<00:17,  2.78it/s]Evaluating:  70%|██████▉   | 111/159 [00:41<00:17,  2.79it/s]Evaluating:  70%|███████   | 112/159 [00:41<00:17,  2.76it/s]Evaluating:  71%|███████   | 113/159 [00:41<00:16,  2.71it/s]Evaluating:  72%|███████▏  | 114/159 [00:42<00:17,  2.58it/s]Evaluating:  72%|███████▏  | 115/159 [00:42<00:17,  2.47it/s]Evaluating:  73%|███████▎  | 116/159 [00:43<00:17,  2.47it/s]Evaluating:  74%|███████▎  | 117/159 [00:43<00:18,  2.29it/s]Evaluating:  74%|███████▍  | 118/159 [00:44<00:17,  2.39it/s]Evaluating:  75%|███████▍  | 119/159 [00:44<00:16,  2.44it/s]Evaluating:  75%|███████▌  | 120/159 [00:44<00:15,  2.52it/s]Evaluating:  76%|███████▌  | 121/159 [00:45<00:15,  2.50it/s]Evaluating:  77%|███████▋  | 122/159 [00:45<00:14,  2.55it/s]Evaluating:  77%|███████▋  | 123/159 [00:45<00:13,  2.62it/s]Evaluating:  78%|███████▊  | 124/159 [00:46<00:13,  2.63it/s]Evaluating:  79%|███████▊  | 125/159 [00:46<00:12,  2.67it/s]Evaluating:  79%|███████▉  | 126/159 [00:47<00:12,  2.69it/s]Evaluating:  80%|███████▉  | 127/159 [00:47<00:11,  2.71it/s]Evaluating:  81%|████████  | 128/159 [00:47<00:11,  2.74it/s]Evaluating:  81%|████████  | 129/159 [00:48<00:10,  2.76it/s]Evaluating:  82%|████████▏ | 130/159 [00:48<00:10,  2.74it/s]Evaluating:  82%|████████▏ | 131/159 [00:48<00:10,  2.72it/s]Evaluating:  83%|████████▎ | 132/159 [00:49<00:10,  2.65it/s]Evaluating:  84%|████████▎ | 133/159 [00:49<00:10,  2.49it/s]Evaluating:  84%|████████▍ | 134/159 [00:50<00:10,  2.47it/s]Evaluating:  85%|████████▍ | 135/159 [00:50<00:09,  2.52it/s]Evaluating:  86%|████████▌ | 136/159 [00:50<00:09,  2.47it/s]Evaluating:  86%|████████▌ | 137/159 [00:51<00:08,  2.47it/s]Evaluating:  87%|████████▋ | 138/159 [00:51<00:08,  2.56it/s]Evaluating:  87%|████████▋ | 139/159 [00:52<00:07,  2.63it/s]Evaluating:  88%|████████▊ | 140/159 [00:52<00:07,  2.68it/s]Evaluating:  89%|████████▊ | 141/159 [00:52<00:06,  2.72it/s]Evaluating:  89%|████████▉ | 142/159 [00:53<00:06,  2.75it/s]Evaluating:  90%|████████▉ | 143/159 [00:53<00:05,  2.77it/s]Evaluating:  91%|█████████ | 144/159 [00:53<00:05,  2.78it/s]Evaluating:  91%|█████████ | 145/159 [00:54<00:05,  2.79it/s]Evaluating:  92%|█████████▏| 146/159 [00:54<00:04,  2.79it/s]Evaluating:  92%|█████████▏| 147/159 [00:54<00:04,  2.80it/s]Evaluating:  93%|█████████▎| 148/159 [00:55<00:03,  2.80it/s]Evaluating:  94%|█████████▎| 149/159 [00:55<00:03,  2.80it/s]Evaluating:  94%|█████████▍| 150/159 [00:55<00:03,  2.80it/s]Evaluating:  95%|█████████▍| 151/159 [00:56<00:02,  2.79it/s]Evaluating:  96%|█████████▌| 152/159 [00:56<00:02,  2.79it/s]Evaluating:  96%|█████████▌| 153/159 [00:57<00:02,  2.79it/s]Evaluating:  97%|█████████▋| 154/159 [00:57<00:01,  2.80it/s]Evaluating:  97%|█████████▋| 155/159 [00:57<00:01,  2.80it/s]Evaluating:  98%|█████████▊| 156/159 [00:58<00:01,  2.80it/s]Evaluating:  99%|█████████▊| 157/159 [00:58<00:00,  2.80it/s]Evaluating:  99%|█████████▉| 158/159 [00:58<00:00,  2.80it/s]Evaluating: 100%|██████████| 159/159 [00:59<00:00,  3.05it/s]Evaluating: 100%|██████████| 159/159 [00:59<00:00,  2.69it/s]
05/09/2022 19:51:28 - INFO - __main__ -     Evaluation done in total 59.061590 secs (0.046505 sec per example)
05/09/2022 19:51:32 - INFO - __main__ -   Results: {'exact': 76.5546218487395, 'f1': 87.36614480770889, 'total': 1190, 'HasAns_exact': 76.5546218487395, 'HasAns_f1': 87.36614480770889, 'HasAns_total': 1190, 'best_exact': 76.5546218487395, 'best_exact_thresh': 0.0, 'best_f1': 87.36614480770889, 'best_f1_thresh': 0.0}
  es 
2022-05-09 19:51:34.811559: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0
05/09/2022 19:51:38 - WARNING - __main__ -   Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, 16-bits training: False
You are using a model of type xlm-roberta to instantiate a model of type xlm. This is not supported for all configurations of models and can yield errors.
Some weights of the model checkpoint at /cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//squad/xlm-KG_LR4e-5_EPOCH2.0_maxlen384_batchsize4_gradacc8 were not used when initializing XLMRobertaModel: ['base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.5.attention.output.LayerNorm.bias', 'base_model.encoder.layer.4.attention.self.query.weight', 'base_model.encoder.layer.0.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.2.attention.self.value.bias', 'base_model.encoder.layer.13.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.7.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.8.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.9.attention.self.query.weight', 'base_model.encoder.layer.2.intermediate.dense.bias', 'base_model.encoder.layer.16.intermediate.dense.weight', 'base_model.encoder.layer.14.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.23.output.LayerNorm.bias', 'base_model.encoder.layer.7.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.2.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.16.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.3.output.dense.weight', 'base_model.encoder.layer.3.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.20.attention.self.value.bias', 'base_model.encoder.layer.22.attention.self.key.bias', 'base_model.encoder.layer.23.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.9.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.14.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.0.attention.self.query.weight', 'base_model.encoder.layer.4.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.14.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.0.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.15.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.5.attention.output.dense.bias', 'base_model.encoder.layer.5.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.9.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.0.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.4.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.3.attention.output.LayerNorm.bias', 'base_model.encoder.layer.8.intermediate.dense.weight', 'base_model.encoder.layer.16.output.dense.bias', 'base_model.encoder.layer.15.attention.self.query.bias', 'base_model.encoder.layer.23.attention.output.dense.bias', 'base_model.encoder.layer.9.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.22.output.dense.bias', 'base_model.encoder.layer.16.attention.output.dense.weight', 'base_model.encoder.layer.5.intermediate.dense.bias', 'base_model.encoder.layer.3.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.10.intermediate.dense.bias', 'base_model.encoder.layer.20.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.11.intermediate.dense.weight', 'base_model.encoder.layer.21.attention.self.key.bias', 'base_model.encoder.layer.5.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.20.attention.output.dense.weight', 'base_model.pooler.dense.bias', 'base_model.encoder.layer.10.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.22.intermediate.dense.bias', 'base_model.encoder.layer.4.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.7.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.3.attention.self.query.weight', 'base_model.encoder.layer.4.attention.self.query.bias', 'base_model.encoder.layer.23.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.8.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.23.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.3.attention.output.LayerNorm.weight', 'base_model.encoder.layer.0.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.21.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.1.output.dense.weight', 'base_model.encoder.layer.23.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.17.intermediate.dense.weight', 'base_model.embeddings.word_embeddings.weight', 'base_model.encoder.layer.14.output.LayerNorm.weight', 'base_model.encoder.layer.17.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.1.output.LayerNorm.weight', 'base_model.encoder.layer.18.output.dense.bias', 'base_model.encoder.layer.23.attention.output.LayerNorm.bias', 'base_model.encoder.layer.17.attention.self.query.weight', 'base_model.encoder.layer.12.output.dense.bias', 'base_model.encoder.layer.22.attention.self.query.weight', 'base_model.encoder.layer.4.output.LayerNorm.bias', 'base_model.encoder.layer.2.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.4.attention.output.LayerNorm.bias', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.3.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.8.attention.output.dense.weight', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.19.intermediate.dense.weight', 'base_model.encoder.layer.19.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.18.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.6.output.LayerNorm.weight', 'base_model.encoder.layer.9.output.LayerNorm.bias', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.10.output.dense.weight', 'base_model.encoder.layer.17.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.17.attention.self.value.bias', 'base_model.encoder.layer.2.attention.self.query.bias', 'base_model.encoder.layer.2.attention.output.dense.weight', 'base_model.encoder.layer.22.intermediate.dense.weight', 'base_model.encoder.layer.12.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.14.attention.self.query.weight', 'base_model.encoder.layer.18.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.3.output.dense.bias', 'base_model.encoder.layer.4.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.0.output.dense.weight', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.6.output.dense.weight', 'base_model.encoder.layer.8.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.2.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.9.output.dense.bias', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.11.output.dense.weight', 'base_model.encoder.layer.14.attention.output.LayerNorm.bias', 'base_model.encoder.layer.9.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.13.attention.self.key.weight', 'base_model.encoder.layer.23.attention.self.key.bias', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.8.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.0.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.0.attention.output.LayerNorm.weight', 'base_model.encoder.layer.15.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.0.attention.output.dense.bias', 'base_model.encoder.layer.5.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.11.output.LayerNorm.weight', 'base_model.encoder.layer.15.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.22.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.7.attention.self.key.bias', 'base_model.encoder.layer.8.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.12.output.LayerNorm.weight', 'base_model.encoder.layer.18.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.21.output.LayerNorm.weight', 'base_model.encoder.layer.4.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.17.attention.self.key.bias', 'base_model.encoder.layer.8.attention.self.key.bias', 'base_model.encoder.layer.18.output.dense.weight', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.2.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.5.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.14.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.5.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.20.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.22.attention.output.LayerNorm.weight', 'base_model.encoder.layer.21.output.dense.weight', 'base_model.encoder.layer.18.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.20.intermediate.dense.weight', 'base_model.encoder.layer.6.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.5.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.0.attention.output.dense.weight', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.7.attention.self.query.weight', 'base_model.encoder.layer.9.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.16.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.17.attention.output.dense.weight', 'base_model.encoder.layer.21.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.5.attention.self.query.bias', 'base_model.encoder.layer.19.attention.self.query.weight', 'base_model.encoder.layer.4.attention.output.dense.weight', 'base_model.encoder.layer.11.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.4.attention.self.value.weight', 'base_model.encoder.layer.17.attention.self.value.weight', 'base_model.encoder.layer.11.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.18.attention.output.LayerNorm.bias', 'base_model.encoder.layer.17.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.22.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.10.attention.self.query.bias', 'base_model.encoder.layer.20.attention.output.LayerNorm.bias', 'base_model.encoder.layer.8.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.11.attention.self.query.weight', 'base_model.encoder.layer.0.attention.self.key.bias', 'base_model.encoder.layer.1.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.6.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.6.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.15.attention.self.key.weight', 'base_model.encoder.layer.16.output.dense.weight', 'base_model.encoder.layer.20.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.9.attention.self.query.bias', 'base_model.encoder.layer.21.output.dense.bias', 'base_model.encoder.layer.1.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.15.attention.output.dense.bias', 'base_model.encoder.layer.17.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.1.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.20.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.7.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.21.attention.output.LayerNorm.weight', 'base_model.encoder.layer.13.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.16.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.22.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.3.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.2.output.dense.bias', 'base_model.encoder.layer.4.intermediate.dense.weight', 'base_model.encoder.layer.23.attention.output.dense.weight', 'base_model.encoder.layer.14.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.embeddings.LayerNorm.bias', 'base_model.encoder.layer.2.intermediate.dense.weight', 'base_model.encoder.layer.14.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.22.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.23.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.2.attention.self.key.bias', 'base_model.encoder.layer.6.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.7.attention.self.value.weight', 'base_model.encoder.layer.16.attention.self.value.weight', 'base_model.encoder.layer.16.attention.output.dense.bias', 'base_model.encoder.layer.15.attention.self.query.weight', 'base_model.encoder.layer.8.attention.self.value.bias', 'base_model.encoder.layer.1.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.15.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.17.attention.output.LayerNorm.weight', 'base_model.encoder.layer.2.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.8.attention.self.key.weight', 'base_model.encoder.layer.18.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.18.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.15.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.23.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.4.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.18.attention.self.query.bias', 'base_model.encoder.layer.22.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.1.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.7.attention.output.dense.weight', 'base_model.encoder.layer.19.output.LayerNorm.bias', 'base_model.encoder.layer.13.output.LayerNorm.bias', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.10.attention.self.key.weight', 'base_model.encoder.layer.7.output.dense.weight', 'base_model.encoder.layer.10.attention.output.LayerNorm.bias', 'base_model.encoder.layer.3.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.12.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.17.output.dense.bias', 'base_model.encoder.layer.19.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.4.attention.self.value.bias', 'base_model.encoder.layer.23.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.7.output.LayerNorm.bias', 'base_model.encoder.layer.20.attention.self.query.weight', 'base_model.encoder.layer.0.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.15.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.10.output.LayerNorm.weight', 'base_model.encoder.layer.12.attention.output.dense.weight', 'base_model.encoder.layer.22.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.3.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.12.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.19.attention.self.value.weight', 'base_model.encoder.layer.16.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.11.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.15.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.9.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.11.attention.self.value.weight', 'base_model.encoder.layer.2.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.21.intermediate.dense.bias', 'base_model.encoder.layer.10.attention.self.key.bias', 'base_model.encoder.layer.16.attention.self.query.weight', 'base_model.encoder.layer.21.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.23.output.dense.weight', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.6.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.2.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.14.attention.output.dense.weight', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.20.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.5.intermediate.dense.weight', 'base_model.encoder.layer.12.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.3.attention.output.dense.weight', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.7.intermediate.dense.bias', 'base_model.encoder.layer.8.attention.self.query.weight', 'base_model.encoder.layer.5.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.16.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.19.attention.self.value.bias', 'base_model.encoder.layer.3.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.0.output.LayerNorm.weight', 'base_model.encoder.layer.19.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.14.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.15.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.12.attention.output.dense.bias', 'base_model.encoder.layer.19.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.3.intermediate.dense.bias', 'base_model.encoder.layer.2.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.5.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.12.attention.self.query.bias', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.3.attention.self.query.bias', 'base_model.encoder.layer.15.attention.output.LayerNorm.bias', 'base_model.encoder.layer.16.output.LayerNorm.weight', 'base_model.encoder.layer.12.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.13.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.3.output.LayerNorm.bias', 'base_model.encoder.layer.17.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.10.attention.output.dense.bias', 'base_model.encoder.layer.12.output.LayerNorm.bias', 'base_model.encoder.layer.8.output.dense.weight', 'base_model.encoder.layer.17.intermediate.dense.bias', 'base_model.encoder.layer.1.attention.output.dense.bias', 'base_model.encoder.layer.9.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.18.intermediate.dense.weight', 'base_model.encoder.layer.18.attention.output.LayerNorm.weight', 'base_model.encoder.layer.6.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.11.attention.self.value.bias', 'base_model.encoder.layer.22.attention.self.value.weight', 'base_model.encoder.layer.11.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.19.intermediate.dense.bias', 'base_model.encoder.layer.21.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.0.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.23.attention.self.query.weight', 'base_model.encoder.layer.2.output.LayerNorm.weight', 'base_model.encoder.layer.7.attention.output.dense.bias', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.10.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.18.attention.output.dense.weight', 'base_model.encoder.layer.1.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.16.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.12.output.dense.weight', 'base_model.encoder.layer.5.output.LayerNorm.weight', 'base_model.encoder.layer.13.intermediate.dense.bias', 'base_model.encoder.layer.1.output.dense.bias', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.16.attention.output.LayerNorm.bias', 'base_model.encoder.layer.11.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.13.output.dense.weight', 'base_model.encoder.layer.17.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.2.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.14.attention.self.key.bias', 'base_model.encoder.layer.21.attention.self.value.bias', 'base_model.encoder.layer.9.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.10.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.7.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.17.attention.self.query.bias', 'base_model.encoder.layer.0.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.9.output.dense.weight', 'base_model.encoder.layer.12.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.16.attention.self.key.bias', 'base_model.encoder.layer.23.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.8.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.0.attention.output.LayerNorm.bias', 'base_model.encoder.layer.17.attention.output.LayerNorm.bias', 'base_model.encoder.layer.10.output.LayerNorm.bias', 'base_model.encoder.layer.10.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.15.intermediate.dense.bias', 'base_model.encoder.layer.19.output.dense.weight', 'base_model.encoder.layer.1.attention.output.dense.weight', 'base_model.encoder.layer.13.attention.self.value.weight', 'base_model.embeddings.position_embeddings.weight', 'base_model.encoder.layer.4.attention.self.key.bias', 'base_model.encoder.layer.21.attention.output.dense.bias', 'base_model.encoder.layer.18.attention.self.key.weight', 'base_model.encoder.layer.3.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.20.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.2.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.19.attention.output.dense.weight', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.6.attention.output.LayerNorm.weight', 'base_model.encoder.layer.6.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.3.attention.self.key.bias', 'base_model.encoder.layer.20.attention.self.value.weight', 'base_model.encoder.layer.0.attention.self.value.weight', 'base_model.encoder.layer.9.intermediate.dense.weight', 'base_model.encoder.layer.1.attention.output.LayerNorm.bias', 'base_model.encoder.layer.12.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.14.output.dense.weight', 'base_model.encoder.layer.18.output.LayerNorm.bias', 'base_model.encoder.layer.1.attention.self.key.bias', 'base_model.encoder.layer.8.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.11.attention.output.dense.weight', 'base_model.encoder.layer.3.attention.self.value.weight', 'base_model.encoder.layer.10.attention.self.value.bias', 'base_model.encoder.layer.7.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.17.output.dense.weight', 'base_model.encoder.layer.1.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.4.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.20.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.16.intermediate.dense.bias', 'base_model.encoder.layer.17.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.5.attention.self.query.weight', 'base_model.encoder.layer.10.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.13.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.19.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.6.attention.self.value.weight', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.13.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.1.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.8.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.12.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.19.attention.output.dense.bias', 'base_model.encoder.layer.20.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.20.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.5.attention.output.LayerNorm.weight', 'base_model.encoder.layer.17.output.LayerNorm.weight', 'base_model.encoder.layer.20.output.dense.bias', 'base_model.encoder.layer.16.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.16.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.7.attention.self.query.bias', 'base_model.encoder.layer.8.output.LayerNorm.weight', 'base_model.encoder.layer.13.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.13.attention.self.key.bias', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.6.attention.self.key.bias', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.11.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.3.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.10.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.15.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.14.attention.output.dense.bias', 'base_model.encoder.layer.4.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.4.attention.self.key.weight', 'base_model.encoder.layer.9.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.13.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.14.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.14.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.16.attention.self.key.weight', 'base_model.encoder.layer.4.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.0.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.17.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.5.attention.self.key.weight', 'base_model.encoder.layer.19.attention.self.key.bias', 'base_model.encoder.layer.22.attention.self.value.bias', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'qa_outputs.bias', 'base_model.encoder.layer.6.output.LayerNorm.bias', 'base_model.encoder.layer.15.output.dense.weight', 'base_model.encoder.layer.22.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.4.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.10.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.11.output.dense.bias', 'base_model.encoder.layer.23.output.LayerNorm.weight', 'base_model.encoder.layer.19.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.4.attention.output.LayerNorm.weight', 'base_model.encoder.layer.10.output.dense.bias', 'base_model.encoder.layer.13.attention.output.LayerNorm.bias', 'base_model.encoder.layer.0.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.18.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.6.attention.output.dense.weight', 'base_model.encoder.layer.10.attention.self.value.weight', 'base_model.encoder.layer.13.attention.self.query.bias', 'base_model.encoder.layer.14.attention.output.LayerNorm.weight', 'base_model.encoder.layer.19.attention.self.query.bias', 'base_model.encoder.layer.14.attention.self.value.bias', 'base_model.encoder.layer.15.output.dense.bias', 'base_model.encoder.layer.6.intermediate.dense.bias', 'base_model.encoder.layer.11.output.LayerNorm.bias', 'base_model.encoder.layer.23.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.18.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.2.attention.output.dense.bias', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.7.attention.output.LayerNorm.bias', 'base_model.encoder.layer.16.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.20.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.16.output.LayerNorm.bias', 'base_model.encoder.layer.2.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.9.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.8.attention.output.LayerNorm.weight', 'base_model.encoder.layer.12.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.22.output.LayerNorm.weight', 'base_model.encoder.layer.22.attention.output.dense.weight', 'base_model.encoder.layer.18.attention.self.value.bias', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.13.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.22.output.dense.weight', 'base_model.encoder.layer.0.output.dense.bias', 'base_model.encoder.layer.22.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.19.output.LayerNorm.weight', 'base_model.encoder.layer.10.attention.self.query.weight', 'base_model.encoder.layer.17.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.9.attention.output.dense.weight', 'base_model.encoder.layer.18.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.12.attention.output.LayerNorm.weight', 'base_model.encoder.layer.5.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.1.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.21.attention.self.query.bias', 'base_model.encoder.layer.17.attention.output.dense.bias', 'base_model.encoder.layer.5.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.5.attention.self.key.bias', 'base_model.encoder.layer.3.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.12.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.13.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.11.attention.output.LayerNorm.bias', 'base_model.encoder.layer.12.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.8.intermediate.dense.bias', 'base_model.encoder.layer.8.output.LayerNorm.bias', 'base_model.encoder.layer.21.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.0.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.13.attention.self.value.bias', 'base_model.encoder.layer.6.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.23.intermediate.dense.weight', 'base_model.encoder.layer.15.attention.self.value.weight', 'base_model.encoder.layer.4.attention.output.dense.bias', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.0.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.9.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.7.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.17.output.adapters.tp.adapter_up.bias', 'base_model.embeddings.token_type_embeddings.weight', 'base_model.encoder.layer.15.attention.output.LayerNorm.weight', 'base_model.encoder.layer.0.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.20.attention.self.query.bias', 'base_model.encoder.layer.17.output.adapters.tp.adapter_down.0.bias', 'base_model.embeddings.LayerNorm.weight', 'base_model.encoder.layer.2.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.1.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.13.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.15.output.LayerNorm.bias', 'base_model.encoder.layer.21.output.LayerNorm.bias', 'base_model.encoder.layer.23.attention.self.key.weight', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.9.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.8.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.16.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.11.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.1.output.LayerNorm.bias', 'base_model.encoder.layer.2.attention.self.value.weight', 'base_model.encoder.layer.21.attention.output.dense.weight', 'base_model.encoder.layer.5.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.22.attention.output.LayerNorm.bias', 'base_model.encoder.layer.8.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.14.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.9.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.13.attention.output.dense.bias', 'base_model.encoder.layer.4.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.3.output.LayerNorm.weight', 'base_model.encoder.layer.20.intermediate.dense.bias', 'base_model.encoder.layer.20.output.dense.weight', 'base_model.encoder.layer.13.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.7.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.8.output.dense.bias', 'base_model.encoder.layer.13.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.9.output.LayerNorm.weight', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.12.attention.self.value.bias', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.1.intermediate.dense.bias', 'base_model.encoder.layer.11.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.19.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.23.attention.self.value.bias', 'base_model.encoder.layer.6.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.14.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.17.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.12.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.9.attention.self.key.bias', 'base_model.encoder.layer.14.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.19.attention.output.LayerNorm.bias', 'base_model.encoder.layer.21.attention.output.LayerNorm.bias', 'base_model.encoder.layer.17.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.21.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.22.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.21.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.23.attention.self.value.weight', 'base_model.encoder.layer.10.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.22.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.6.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.15.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.3.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.1.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.18.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.16.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.6.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.15.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.0.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.11.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.23.attention.self.query.bias', 'base_model.encoder.layer.1.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.21.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.2.attention.output.LayerNorm.bias', 'base_model.encoder.layer.7.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.14.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.21.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.14.intermediate.dense.weight', 'base_model.encoder.layer.11.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.9.intermediate.dense.bias', 'base_model.encoder.layer.21.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.5.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.18.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.19.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.7.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.7.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.5.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.18.attention.self.value.weight', 'base_model.encoder.layer.1.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.0.intermediate.dense.weight', 'base_model.encoder.layer.21.attention.self.value.weight', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.13.intermediate.dense.weight', 'base_model.encoder.layer.22.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.11.attention.self.key.bias', 'base_model.encoder.layer.13.attention.self.query.weight', 'base_model.encoder.layer.10.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.14.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.2.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.7.intermediate.dense.weight', 'base_model.encoder.layer.2.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.13.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.16.attention.self.query.bias', 'base_model.encoder.layer.18.output.LayerNorm.weight', 'base_model.encoder.layer.10.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.20.attention.output.LayerNorm.weight', 'base_model.encoder.layer.11.attention.output.LayerNorm.weight', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.6.output.dense.bias', 'base_model.encoder.layer.12.attention.self.value.weight', 'base_model.encoder.layer.17.output.LayerNorm.bias', 'base_model.embeddings.position_ids', 'base_model.encoder.layer.19.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.2.attention.self.query.weight', 'base_model.encoder.layer.22.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.10.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.11.attention.self.key.weight', 'base_model.encoder.layer.20.attention.output.dense.bias', 'base_model.encoder.layer.6.attention.self.query.bias', 'base_model.encoder.layer.1.attention.self.query.weight', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.18.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.21.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.4.intermediate.dense.bias', 'base_model.encoder.layer.3.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.10.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.15.intermediate.dense.weight', 'base_model.encoder.layer.12.attention.output.LayerNorm.bias', 'base_model.encoder.layer.8.attention.output.dense.bias', 'base_model.encoder.layer.8.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.7.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.12.intermediate.dense.weight', 'base_model.encoder.layer.9.attention.self.key.weight', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.11.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.1.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.13.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.18.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.19.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.7.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.20.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.9.attention.self.value.weight', 'base_model.encoder.layer.13.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.12.attention.self.key.weight', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.21.attention.self.query.weight', 'base_model.encoder.layer.22.output.LayerNorm.bias', 'base_model.encoder.layer.7.output.dense.bias', 'base_model.encoder.layer.8.attention.output.LayerNorm.bias', 'base_model.encoder.layer.4.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.7.attention.output.LayerNorm.weight', 'base_model.encoder.layer.22.attention.self.key.weight', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.1.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.4.output.dense.bias', 'base_model.encoder.layer.8.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.11.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.21.intermediate.dense.weight', 'base_model.encoder.layer.3.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.1.attention.self.query.bias', 'base_model.encoder.layer.23.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.12.attention.self.query.weight', 'base_model.encoder.layer.22.attention.self.query.bias', 'base_model.encoder.layer.17.output.adapters.ts.adapter_up.weight', 'qa_outputs.weight', 'base_model.encoder.layer.12.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.20.attention.self.key.bias', 'base_model.encoder.layer.0.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.12.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.18.attention.self.query.weight', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.10.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.8.attention.self.value.weight', 'base_model.encoder.layer.5.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.16.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.10.intermediate.dense.weight', 'base_model.encoder.layer.9.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.10.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.14.output.LayerNorm.bias', 'base_model.encoder.layer.2.attention.self.key.weight', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.6.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.13.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.21.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.3.attention.output.dense.bias', 'base_model.encoder.layer.0.attention.self.key.weight', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.20.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.0.output.LayerNorm.bias', 'base_model.encoder.layer.8.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.19.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.11.attention.output.dense.bias', 'base_model.encoder.layer.16.attention.self.value.bias', 'base_model.encoder.layer.21.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.23.attention.output.LayerNorm.weight', 'base_model.encoder.layer.4.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.11.intermediate.dense.bias', 'base_model.encoder.layer.14.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.4.output.dense.weight', 'base_model.encoder.layer.5.output.dense.bias', 'base_model.encoder.layer.1.attention.self.value.weight', 'base_model.encoder.layer.12.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.23.output.dense.bias', 'base_model.encoder.layer.11.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.9.attention.output.dense.bias', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.9.attention.output.LayerNorm.weight', 'base_model.encoder.layer.5.output.LayerNorm.bias', 'base_model.encoder.layer.13.output.dense.bias', 'base_model.encoder.layer.9.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.23.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.23.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.22.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.14.attention.self.key.weight', 'base_model.encoder.layer.19.attention.output.LayerNorm.weight', 'base_model.encoder.layer.23.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.16.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.18.attention.output.dense.bias', 'base_model.encoder.layer.8.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.17.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.7.attention.self.value.bias', 'base_model.encoder.layer.1.attention.self.value.bias', 'base_model.encoder.layer.6.attention.output.dense.bias', 'base_model.encoder.layer.2.attention.output.LayerNorm.weight', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.20.output.LayerNorm.bias', 'base_model.encoder.layer.15.attention.self.value.bias', 'base_model.encoder.layer.9.attention.self.value.bias', 'base_model.encoder.layer.4.output.LayerNorm.weight', 'base_model.encoder.layer.5.attention.output.dense.weight', 'base_model.encoder.layer.10.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.13.attention.output.LayerNorm.weight', 'base_model.encoder.layer.16.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.2.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.21.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.10.attention.output.dense.weight', 'base_model.pooler.dense.weight', 'base_model.encoder.layer.8.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.23.intermediate.dense.bias', 'base_model.encoder.layer.11.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.2.output.LayerNorm.bias', 'base_model.encoder.layer.6.intermediate.dense.weight', 'base_model.encoder.layer.6.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.14.attention.self.query.bias', 'base_model.encoder.layer.14.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.3.attention.self.value.bias', 'base_model.encoder.layer.6.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.23.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.8.attention.self.query.bias', 'base_model.encoder.layer.5.attention.self.value.bias', 'base_model.encoder.layer.5.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.2.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.19.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.19.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.19.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.7.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.18.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.20.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.4.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.22.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.11.attention.self.query.bias', 'base_model.encoder.layer.19.output.dense.bias', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.5.output.dense.weight', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.19.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.11.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.12.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.19.attention.self.key.weight', 'base_model.encoder.layer.3.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.23.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.6.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.21.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.14.output.dense.bias', 'base_model.encoder.layer.3.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.0.intermediate.dense.bias', 'base_model.encoder.layer.18.intermediate.dense.bias', 'base_model.encoder.layer.5.attention.self.value.weight', 'base_model.encoder.layer.17.attention.self.key.weight', 'base_model.encoder.layer.6.attention.self.query.weight', 'base_model.encoder.layer.10.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.13.output.LayerNorm.weight', 'base_model.encoder.layer.20.output.LayerNorm.weight', 'base_model.encoder.layer.15.attention.output.dense.weight', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.6.attention.self.key.weight', 'base_model.encoder.layer.21.attention.self.key.weight', 'base_model.encoder.layer.6.attention.output.LayerNorm.bias', 'base_model.encoder.layer.22.attention.output.dense.bias', 'base_model.encoder.layer.12.intermediate.dense.bias', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.6.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.2.output.dense.weight', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.3.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.4.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.20.attention.self.key.weight', 'base_model.encoder.layer.15.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.1.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.15.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.18.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.14.attention.self.value.weight', 'base_model.encoder.layer.11.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.4.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.15.output.LayerNorm.weight', 'base_model.encoder.layer.10.attention.output.LayerNorm.weight', 'base_model.encoder.layer.16.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.18.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.21.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.14.intermediate.dense.bias', 'base_model.encoder.layer.12.attention.self.key.bias', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.17.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.15.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.22.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.0.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.5.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.6.attention.self.value.bias', 'base_model.encoder.layer.18.attention.self.key.bias', 'base_model.encoder.layer.20.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.23.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.7.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.7.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.1.attention.self.key.weight', 'base_model.encoder.layer.13.attention.output.dense.weight', 'base_model.encoder.layer.1.attention.output.LayerNorm.weight', 'base_model.encoder.layer.20.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.0.attention.self.query.bias', 'base_model.encoder.layer.7.output.LayerNorm.weight', 'base_model.encoder.layer.9.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.19.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.7.attention.self.key.weight', 'base_model.encoder.layer.15.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.0.attention.self.value.bias', 'base_model.encoder.layer.9.attention.output.LayerNorm.bias', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.15.attention.self.key.bias', 'base_model.encoder.layer.3.intermediate.dense.weight', 'base_model.encoder.layer.15.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.1.intermediate.dense.weight', 'base_model.encoder.layer.3.attention.self.key.weight', 'base_model.encoder.layer.22.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.16.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.16.attention.output.LayerNorm.weight', 'base_model.encoder.layer.20.output.adapters.ep.adapter_down.0.bias']
- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of XLMRobertaModel were not initialized from the model checkpoint at /cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//squad/xlm-KG_LR4e-5_EPOCH2.0_maxlen384_batchsize4_gradacc8 and are newly initialized: ['encoder.layer.13.intermediate.dense.weight', 'encoder.layer.2.attention.output.dense.bias', 'encoder.layer.1.attention.output.dense.weight', 'encoder.layer.12.attention.self.query.bias', 'encoder.layer.10.attention.self.value.bias', 'encoder.layer.10.attention.self.key.bias', 'encoder.layer.11.attention.output.dense.bias', 'encoder.layer.10.output.LayerNorm.weight', 'encoder.layer.6.attention.self.value.weight', 'encoder.layer.2.attention.self.query.bias', 'encoder.layer.15.attention.self.value.weight', 'encoder.layer.5.attention.self.value.weight', 'encoder.layer.12.attention.output.dense.weight', 'encoder.layer.14.attention.self.query.bias', 'encoder.layer.7.output.dense.bias', 'encoder.layer.22.attention.output.LayerNorm.bias', 'encoder.layer.19.output.dense.bias', 'encoder.layer.0.attention.self.value.bias', 'encoder.layer.19.attention.output.LayerNorm.weight', 'encoder.layer.5.attention.self.key.weight', 'encoder.layer.6.attention.self.query.bias', 'encoder.layer.21.attention.self.key.weight', 'encoder.layer.9.attention.self.value.bias', 'encoder.layer.7.attention.self.value.bias', 'encoder.layer.22.attention.self.query.weight', 'encoder.layer.16.attention.output.LayerNorm.bias', 'encoder.layer.18.attention.output.LayerNorm.weight', 'encoder.layer.22.attention.self.value.weight', 'encoder.layer.11.attention.self.query.bias', 'encoder.layer.0.output.dense.bias', 'encoder.layer.3.attention.self.key.bias', 'encoder.layer.20.output.LayerNorm.weight', 'encoder.layer.18.attention.self.key.weight', 'encoder.layer.19.output.dense.weight', 'encoder.layer.14.output.dense.weight', 'encoder.layer.4.attention.self.key.bias', 'encoder.layer.21.attention.output.LayerNorm.bias', 'encoder.layer.11.attention.output.dense.weight', 'encoder.layer.16.attention.self.key.bias', 'encoder.layer.13.output.LayerNorm.bias', 'encoder.layer.3.output.dense.weight', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.23.attention.self.key.bias', 'encoder.layer.8.attention.output.dense.bias', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.12.intermediate.dense.weight', 'encoder.layer.15.attention.self.value.bias', 'encoder.layer.23.output.dense.bias', 'encoder.layer.6.output.dense.weight', 'encoder.layer.3.attention.output.dense.weight', 'encoder.layer.11.attention.self.query.weight', 'encoder.layer.16.intermediate.dense.bias', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.14.attention.self.key.weight', 'encoder.layer.5.attention.output.dense.bias', 'encoder.layer.13.intermediate.dense.bias', 'encoder.layer.6.output.LayerNorm.bias', 'encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.layer.13.attention.self.key.weight', 'encoder.layer.13.attention.self.query.bias', 'encoder.layer.22.attention.output.dense.bias', 'encoder.layer.17.attention.self.value.bias', 'encoder.layer.3.attention.self.query.bias', 'encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.layer.8.output.LayerNorm.bias', 'encoder.layer.19.attention.self.query.weight', 'encoder.layer.17.intermediate.dense.weight', 'encoder.layer.8.attention.self.key.bias', 'encoder.layer.7.attention.output.dense.bias', 'encoder.layer.16.attention.output.dense.bias', 'encoder.layer.15.intermediate.dense.bias', 'encoder.layer.2.output.dense.weight', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.19.intermediate.dense.bias', 'encoder.layer.6.attention.output.LayerNorm.bias', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.12.output.dense.bias', 'encoder.layer.11.attention.self.value.bias', 'encoder.layer.19.output.LayerNorm.weight', 'encoder.layer.17.output.LayerNorm.weight', 'encoder.layer.17.attention.self.value.weight', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.9.output.LayerNorm.weight', 'encoder.layer.15.attention.output.dense.weight', 'encoder.layer.4.attention.output.dense.bias', 'encoder.layer.15.attention.self.key.bias', 'encoder.layer.20.attention.self.key.weight', 'encoder.layer.20.output.dense.weight', 'encoder.layer.14.attention.output.LayerNorm.weight', 'encoder.layer.16.attention.output.dense.weight', 'encoder.layer.16.attention.self.value.weight', 'encoder.layer.20.attention.output.dense.weight', 'encoder.layer.8.attention.self.value.weight', 'embeddings.LayerNorm.weight', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.18.attention.self.value.bias', 'encoder.layer.8.output.dense.bias', 'encoder.layer.23.attention.output.LayerNorm.bias', 'encoder.layer.22.attention.self.key.bias', 'encoder.layer.16.output.LayerNorm.bias', 'encoder.layer.20.intermediate.dense.bias', 'encoder.layer.8.output.LayerNorm.weight', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.3.attention.self.key.weight', 'encoder.layer.0.attention.self.key.bias', 'encoder.layer.9.attention.output.dense.bias', 'encoder.layer.17.output.dense.weight', 'encoder.layer.15.attention.output.LayerNorm.bias', 'encoder.layer.0.attention.output.dense.weight', 'encoder.layer.18.attention.output.dense.bias', 'embeddings.word_embeddings.weight', 'encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.layer.7.output.LayerNorm.bias', 'encoder.layer.0.attention.self.query.bias', 'encoder.layer.6.attention.self.key.weight', 'encoder.layer.12.intermediate.dense.bias', 'encoder.layer.14.attention.output.LayerNorm.bias', 'encoder.layer.20.intermediate.dense.weight', 'encoder.layer.16.attention.self.query.weight', 'encoder.layer.23.attention.output.LayerNorm.weight', 'encoder.layer.13.attention.output.LayerNorm.bias', 'encoder.layer.23.attention.output.dense.bias', 'encoder.layer.21.output.dense.weight', 'encoder.layer.23.attention.self.value.weight', 'encoder.layer.20.output.LayerNorm.bias', 'encoder.layer.22.attention.self.value.bias', 'encoder.layer.13.output.dense.weight', 'encoder.layer.12.output.LayerNorm.bias', 'encoder.layer.5.attention.self.key.bias', 'encoder.layer.6.output.dense.bias', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.15.output.dense.weight', 'encoder.layer.20.attention.self.value.weight', 'encoder.layer.22.intermediate.dense.weight', 'encoder.layer.14.attention.self.key.bias', 'encoder.layer.23.attention.self.query.bias', 'encoder.layer.15.output.LayerNorm.weight', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.8.attention.self.query.weight', 'encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.layer.22.output.dense.bias', 'encoder.layer.3.attention.self.query.weight', 'encoder.layer.12.attention.self.query.weight', 'encoder.layer.7.attention.self.query.weight', 'encoder.layer.1.attention.self.key.bias', 'encoder.layer.18.intermediate.dense.bias', 'encoder.layer.22.intermediate.dense.bias', 'encoder.layer.1.attention.self.key.weight', 'encoder.layer.7.output.LayerNorm.weight', 'encoder.layer.12.attention.output.dense.bias', 'encoder.layer.12.output.dense.weight', 'encoder.layer.0.attention.self.query.weight', 'encoder.layer.9.attention.output.LayerNorm.bias', 'encoder.layer.0.attention.self.value.weight', 'encoder.layer.21.attention.self.value.bias', 'encoder.layer.3.output.dense.bias', 'encoder.layer.9.output.dense.weight', 'encoder.layer.10.output.dense.weight', 'encoder.layer.6.attention.self.value.bias', 'encoder.layer.20.attention.output.LayerNorm.weight', 'encoder.layer.14.attention.output.dense.weight', 'encoder.layer.14.attention.self.value.weight', 'encoder.layer.19.intermediate.dense.weight', 'encoder.layer.19.attention.self.key.weight', 'encoder.layer.1.attention.self.query.bias', 'encoder.layer.20.attention.output.dense.bias', 'encoder.layer.21.output.dense.bias', 'encoder.layer.3.attention.self.value.weight', 'encoder.layer.1.attention.self.value.bias', 'encoder.layer.17.attention.output.dense.weight', 'encoder.layer.21.attention.self.key.bias', 'pooler.dense.weight', 'encoder.layer.9.attention.self.query.weight', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.18.attention.output.dense.weight', 'encoder.layer.11.output.LayerNorm.weight', 'encoder.layer.7.intermediate.dense.bias', 'encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.layer.12.attention.self.key.bias', 'encoder.layer.16.attention.output.LayerNorm.weight', 'encoder.layer.23.attention.self.key.weight', 'encoder.layer.23.attention.output.dense.weight', 'encoder.layer.10.attention.self.key.weight', 'encoder.layer.5.attention.self.value.bias', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.18.attention.output.LayerNorm.bias', 'encoder.layer.10.attention.output.dense.bias', 'encoder.layer.19.attention.self.value.weight', 'encoder.layer.18.output.LayerNorm.weight', 'encoder.layer.23.output.dense.weight', 'encoder.layer.4.output.dense.weight', 'encoder.layer.7.attention.self.query.bias', 'encoder.layer.11.attention.output.LayerNorm.weight', 'encoder.layer.9.attention.self.value.weight', 'encoder.layer.16.output.dense.weight', 'encoder.layer.18.attention.self.key.bias', 'encoder.layer.23.attention.self.query.weight', 'encoder.layer.21.attention.self.value.weight', 'encoder.layer.12.attention.output.LayerNorm.weight', 'encoder.layer.19.attention.output.LayerNorm.bias', 'encoder.layer.9.attention.self.key.bias', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.9.output.LayerNorm.bias', 'encoder.layer.15.attention.self.query.weight', 'encoder.layer.2.attention.self.value.bias', 'encoder.layer.5.output.dense.bias', 'encoder.layer.11.output.LayerNorm.bias', 'encoder.layer.6.attention.output.dense.weight', 'encoder.layer.17.attention.output.dense.bias', 'encoder.layer.0.attention.output.LayerNorm.weight', 'encoder.layer.4.attention.output.LayerNorm.bias', 'encoder.layer.9.attention.output.LayerNorm.weight', 'encoder.layer.14.output.LayerNorm.weight', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.4.attention.self.value.weight', 'encoder.layer.13.attention.self.value.weight', 'encoder.layer.8.attention.self.key.weight', 'encoder.layer.13.attention.self.key.bias', 'encoder.layer.21.output.LayerNorm.bias', 'encoder.layer.1.output.dense.weight', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.18.output.LayerNorm.bias', 'encoder.layer.10.attention.self.query.bias', 'encoder.layer.20.attention.self.query.weight', 'encoder.layer.11.attention.self.value.weight', 'encoder.layer.4.output.LayerNorm.bias', 'embeddings.position_embeddings.weight', 'encoder.layer.22.output.LayerNorm.weight', 'encoder.layer.12.attention.self.value.weight', 'encoder.layer.17.attention.self.query.weight', 'encoder.layer.1.attention.output.dense.bias', 'encoder.layer.8.attention.output.LayerNorm.bias', 'encoder.layer.19.attention.output.dense.weight', 'encoder.layer.3.attention.self.value.bias', 'encoder.layer.20.attention.output.LayerNorm.bias', 'encoder.layer.15.attention.output.LayerNorm.weight', 'encoder.layer.8.attention.self.query.bias', 'encoder.layer.16.output.LayerNorm.weight', 'encoder.layer.12.output.LayerNorm.weight', 'encoder.layer.20.attention.self.query.bias', 'encoder.layer.14.attention.self.value.bias', 'encoder.layer.21.attention.output.dense.weight', 'encoder.layer.1.attention.output.LayerNorm.weight', 'encoder.layer.7.output.dense.weight', 'encoder.layer.4.attention.self.value.bias', 'encoder.layer.2.attention.output.LayerNorm.weight', 'encoder.layer.9.output.dense.bias', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.11.output.dense.bias', 'encoder.layer.17.attention.output.LayerNorm.weight', 'encoder.layer.11.output.dense.weight', 'encoder.layer.2.attention.self.key.weight', 'encoder.layer.20.attention.self.value.bias', 'encoder.layer.4.output.dense.bias', 'encoder.layer.9.attention.self.query.bias', 'encoder.layer.3.attention.output.dense.bias', 'encoder.layer.4.attention.output.dense.weight', 'encoder.layer.9.attention.output.dense.weight', 'encoder.layer.14.attention.self.query.weight', 'encoder.layer.15.output.LayerNorm.bias', 'encoder.layer.14.intermediate.dense.weight', 'encoder.layer.14.output.LayerNorm.bias', 'encoder.layer.19.output.LayerNorm.bias', 'encoder.layer.7.attention.self.value.weight', 'encoder.layer.4.attention.self.query.bias', 'encoder.layer.23.output.LayerNorm.weight', 'pooler.dense.bias', 'encoder.layer.22.output.LayerNorm.bias', 'encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.layer.17.attention.self.query.bias', 'encoder.layer.20.output.dense.bias', 'encoder.layer.18.attention.self.query.weight', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.15.attention.self.query.bias', 'encoder.layer.21.attention.self.query.weight', 'encoder.layer.16.attention.self.query.bias', 'encoder.layer.2.attention.output.LayerNorm.bias', 'encoder.layer.11.attention.self.key.weight', 'encoder.layer.0.attention.output.dense.bias', 'encoder.layer.14.output.dense.bias', 'encoder.layer.5.attention.output.LayerNorm.weight', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.8.attention.output.dense.weight', 'encoder.layer.23.output.LayerNorm.bias', 'encoder.layer.6.attention.self.query.weight', 'encoder.layer.10.intermediate.dense.weight', 'encoder.layer.12.attention.self.key.weight', 'encoder.layer.12.attention.self.value.bias', 'encoder.layer.20.attention.self.key.bias', 'encoder.layer.12.attention.output.LayerNorm.bias', 'encoder.layer.6.attention.self.key.bias', 'encoder.layer.7.attention.output.LayerNorm.bias', 'encoder.layer.8.attention.self.value.bias', 'encoder.layer.10.attention.output.dense.weight', 'encoder.layer.23.intermediate.dense.bias', 'encoder.layer.13.attention.self.value.bias', 'encoder.layer.10.attention.self.query.weight', 'encoder.layer.6.attention.output.dense.bias', 'encoder.layer.22.attention.self.query.bias', 'encoder.layer.13.attention.output.dense.weight', 'encoder.layer.0.output.dense.weight', 'encoder.layer.21.attention.self.query.bias', 'encoder.layer.13.output.LayerNorm.weight', 'encoder.layer.17.attention.output.LayerNorm.bias', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.7.attention.self.key.weight', 'encoder.layer.18.output.dense.weight', 'encoder.layer.5.output.dense.weight', 'encoder.layer.21.intermediate.dense.weight', 'encoder.layer.19.attention.output.dense.bias', 'encoder.layer.13.attention.output.LayerNorm.weight', 'encoder.layer.10.output.dense.bias', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.21.intermediate.dense.bias', 'encoder.layer.14.attention.output.dense.bias', 'encoder.layer.15.attention.output.dense.bias', 'encoder.layer.21.attention.output.LayerNorm.weight', 'encoder.layer.23.intermediate.dense.weight', 'encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.22.output.dense.weight', 'encoder.layer.0.attention.self.key.weight', 'encoder.layer.17.output.LayerNorm.bias', 'encoder.layer.17.attention.self.key.bias', 'encoder.layer.2.output.dense.bias', 'encoder.layer.18.output.dense.bias', 'encoder.layer.5.attention.self.query.bias', 'encoder.layer.7.attention.output.LayerNorm.weight', 'encoder.layer.2.attention.self.value.weight', 'encoder.layer.15.output.dense.bias', 'encoder.layer.18.attention.self.query.bias', 'encoder.layer.19.attention.self.value.bias', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.16.attention.self.value.bias', 'encoder.layer.21.attention.output.dense.bias', 'encoder.layer.5.output.LayerNorm.bias', 'encoder.layer.16.attention.self.key.weight', 'encoder.layer.14.intermediate.dense.bias', 'encoder.layer.15.attention.self.key.weight', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.16.intermediate.dense.weight', 'encoder.layer.23.attention.self.value.bias', 'encoder.layer.1.attention.self.query.weight', 'encoder.layer.18.intermediate.dense.weight', 'encoder.layer.8.attention.output.LayerNorm.weight', 'encoder.layer.22.attention.output.dense.weight', 'encoder.layer.13.attention.self.query.weight', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.10.attention.output.LayerNorm.weight', 'encoder.layer.15.intermediate.dense.weight', 'encoder.layer.22.attention.output.LayerNorm.weight', 'encoder.layer.1.attention.self.value.weight', 'encoder.layer.13.output.dense.bias', 'encoder.layer.13.attention.output.dense.bias', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.18.attention.self.value.weight', 'encoder.layer.10.attention.self.value.weight', 'encoder.layer.16.output.dense.bias', 'embeddings.LayerNorm.bias', 'encoder.layer.10.attention.output.LayerNorm.bias', 'encoder.layer.7.attention.self.key.bias', 'encoder.layer.17.attention.self.key.weight', 'encoder.layer.4.attention.output.LayerNorm.weight', 'encoder.layer.8.output.dense.weight', 'encoder.layer.6.attention.output.LayerNorm.weight', 'encoder.layer.2.attention.self.query.weight', 'encoder.layer.19.attention.self.query.bias', 'encoder.layer.19.attention.self.key.bias', 'encoder.layer.11.attention.self.key.bias', 'encoder.layer.17.output.dense.bias', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.7.attention.output.dense.weight', 'encoder.layer.9.attention.self.key.weight', 'encoder.layer.10.output.LayerNorm.bias', 'encoder.layer.2.attention.self.key.bias', 'embeddings.token_type_embeddings.weight', 'encoder.layer.4.attention.self.query.weight', 'encoder.layer.5.attention.output.dense.weight', 'encoder.layer.17.intermediate.dense.bias', 'encoder.layer.21.output.LayerNorm.weight', 'encoder.layer.1.output.dense.bias', 'encoder.layer.5.attention.self.query.weight', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.4.attention.self.key.weight', 'encoder.layer.2.attention.output.dense.weight', 'encoder.layer.22.attention.self.key.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Overwriting existing adapter 'ep'.
Overwriting existing adapter 'tp'.
Overwriting existing adapter 'es'.
Overwriting existing adapter 'ts'.
Overwriting existing adapter fusion module 'ep,tp,es,ts'
05/09/2022 19:52:02 - INFO - __main__ -   lang2id = None
05/09/2022 19:52:05 - INFO - __main__ -   Training/evaluation parameters Namespace(adam_epsilon=1e-08, cache_dir='', config_name='', data_dir=None, device=device(type='cuda'), do_eval=True, do_lower_case=False, do_train=False, doc_stride=128, eval_all_checkpoints=False, eval_lang='es', evaluate_during_training=False, fp16=False, fp16_opt_level='O1', gradient_accumulation_steps=1, learning_rate=5e-05, local_rank=-1, logging_steps=50, max_answer_length=30, max_grad_norm=1.0, max_query_length=64, max_seq_length=384, max_steps=-1, model_name='xlm-KG', model_name_or_path='/cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//squad/xlm-KG_LR4e-5_EPOCH2.0_maxlen384_batchsize4_gradacc8', model_type='xlm', modelkg_dir='/cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/adapter/xlmr_adapter', n_best_size=20, n_gpu=1, no_cuda=False, null_score_diff_threshold=0.0, num_train_epochs=3.0, output_dir='/cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//squad/xlm-KG_LR4e-5_EPOCH2.0_maxlen384_batchsize4_gradacc8/predictions/xquad/', overwrite_cache=False, overwrite_output_dir=False, per_gpu_eval_batch_size=8, per_gpu_train_batch_size=8, predict_file='/cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/download//xquad//xquad.es.json', save_steps=50, seed=42, server_ip='', server_port='', threads=1, tokenizer_name='', train_file=None, train_lang='en', verbose_logging=False, version_2_with_negative=False, warmup_steps=0, weight_decay=0.0)
05/09/2022 19:52:05 - INFO - __main__ -   Loading checkpoint /cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//squad/xlm-KG_LR4e-5_EPOCH2.0_maxlen384_batchsize4_gradacc8 for evaluation
05/09/2022 19:52:05 - INFO - __main__ -   Evaluate the following checkpoints: ['/cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//squad/xlm-KG_LR4e-5_EPOCH2.0_maxlen384_batchsize4_gradacc8']
Some weights of the model checkpoint at /cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//squad/xlm-KG_LR4e-5_EPOCH2.0_maxlen384_batchsize4_gradacc8 were not used when initializing XLMRobertaModel: ['base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.5.attention.output.LayerNorm.bias', 'base_model.encoder.layer.4.attention.self.query.weight', 'base_model.encoder.layer.0.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.2.attention.self.value.bias', 'base_model.encoder.layer.13.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.7.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.8.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.9.attention.self.query.weight', 'base_model.encoder.layer.2.intermediate.dense.bias', 'base_model.encoder.layer.16.intermediate.dense.weight', 'base_model.encoder.layer.14.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.23.output.LayerNorm.bias', 'base_model.encoder.layer.7.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.2.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.16.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.3.output.dense.weight', 'base_model.encoder.layer.3.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.20.attention.self.value.bias', 'base_model.encoder.layer.22.attention.self.key.bias', 'base_model.encoder.layer.23.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.9.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.14.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.0.attention.self.query.weight', 'base_model.encoder.layer.4.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.14.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.0.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.15.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.5.attention.output.dense.bias', 'base_model.encoder.layer.5.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.9.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.0.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.4.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.3.attention.output.LayerNorm.bias', 'base_model.encoder.layer.8.intermediate.dense.weight', 'base_model.encoder.layer.16.output.dense.bias', 'base_model.encoder.layer.15.attention.self.query.bias', 'base_model.encoder.layer.23.attention.output.dense.bias', 'base_model.encoder.layer.9.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.22.output.dense.bias', 'base_model.encoder.layer.16.attention.output.dense.weight', 'base_model.encoder.layer.5.intermediate.dense.bias', 'base_model.encoder.layer.3.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.10.intermediate.dense.bias', 'base_model.encoder.layer.20.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.11.intermediate.dense.weight', 'base_model.encoder.layer.21.attention.self.key.bias', 'base_model.encoder.layer.5.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.20.attention.output.dense.weight', 'base_model.pooler.dense.bias', 'base_model.encoder.layer.10.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.22.intermediate.dense.bias', 'base_model.encoder.layer.4.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.7.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.3.attention.self.query.weight', 'base_model.encoder.layer.4.attention.self.query.bias', 'base_model.encoder.layer.23.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.8.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.23.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.3.attention.output.LayerNorm.weight', 'base_model.encoder.layer.0.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.21.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.1.output.dense.weight', 'base_model.encoder.layer.23.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.17.intermediate.dense.weight', 'base_model.embeddings.word_embeddings.weight', 'base_model.encoder.layer.14.output.LayerNorm.weight', 'base_model.encoder.layer.17.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.1.output.LayerNorm.weight', 'base_model.encoder.layer.18.output.dense.bias', 'base_model.encoder.layer.23.attention.output.LayerNorm.bias', 'base_model.encoder.layer.17.attention.self.query.weight', 'base_model.encoder.layer.12.output.dense.bias', 'base_model.encoder.layer.22.attention.self.query.weight', 'base_model.encoder.layer.4.output.LayerNorm.bias', 'base_model.encoder.layer.2.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.4.attention.output.LayerNorm.bias', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.3.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.8.attention.output.dense.weight', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.19.intermediate.dense.weight', 'base_model.encoder.layer.19.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.18.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.6.output.LayerNorm.weight', 'base_model.encoder.layer.9.output.LayerNorm.bias', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.10.output.dense.weight', 'base_model.encoder.layer.17.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.17.attention.self.value.bias', 'base_model.encoder.layer.2.attention.self.query.bias', 'base_model.encoder.layer.2.attention.output.dense.weight', 'base_model.encoder.layer.22.intermediate.dense.weight', 'base_model.encoder.layer.12.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.14.attention.self.query.weight', 'base_model.encoder.layer.18.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.3.output.dense.bias', 'base_model.encoder.layer.4.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.0.output.dense.weight', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.6.output.dense.weight', 'base_model.encoder.layer.8.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.2.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.9.output.dense.bias', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.11.output.dense.weight', 'base_model.encoder.layer.14.attention.output.LayerNorm.bias', 'base_model.encoder.layer.9.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.13.attention.self.key.weight', 'base_model.encoder.layer.23.attention.self.key.bias', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.8.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.0.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.0.attention.output.LayerNorm.weight', 'base_model.encoder.layer.15.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.0.attention.output.dense.bias', 'base_model.encoder.layer.5.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.11.output.LayerNorm.weight', 'base_model.encoder.layer.15.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.22.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.7.attention.self.key.bias', 'base_model.encoder.layer.8.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.12.output.LayerNorm.weight', 'base_model.encoder.layer.18.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.21.output.LayerNorm.weight', 'base_model.encoder.layer.4.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.17.attention.self.key.bias', 'base_model.encoder.layer.8.attention.self.key.bias', 'base_model.encoder.layer.18.output.dense.weight', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.2.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.5.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.14.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.5.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.20.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.22.attention.output.LayerNorm.weight', 'base_model.encoder.layer.21.output.dense.weight', 'base_model.encoder.layer.18.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.20.intermediate.dense.weight', 'base_model.encoder.layer.6.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.5.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.0.attention.output.dense.weight', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.7.attention.self.query.weight', 'base_model.encoder.layer.9.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.16.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.17.attention.output.dense.weight', 'base_model.encoder.layer.21.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.5.attention.self.query.bias', 'base_model.encoder.layer.19.attention.self.query.weight', 'base_model.encoder.layer.4.attention.output.dense.weight', 'base_model.encoder.layer.11.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.4.attention.self.value.weight', 'base_model.encoder.layer.17.attention.self.value.weight', 'base_model.encoder.layer.11.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.18.attention.output.LayerNorm.bias', 'base_model.encoder.layer.17.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.22.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.10.attention.self.query.bias', 'base_model.encoder.layer.20.attention.output.LayerNorm.bias', 'base_model.encoder.layer.8.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.11.attention.self.query.weight', 'base_model.encoder.layer.0.attention.self.key.bias', 'base_model.encoder.layer.1.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.6.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.6.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.15.attention.self.key.weight', 'base_model.encoder.layer.16.output.dense.weight', 'base_model.encoder.layer.20.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.9.attention.self.query.bias', 'base_model.encoder.layer.21.output.dense.bias', 'base_model.encoder.layer.1.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.15.attention.output.dense.bias', 'base_model.encoder.layer.17.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.1.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.20.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.7.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.21.attention.output.LayerNorm.weight', 'base_model.encoder.layer.13.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.16.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.22.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.3.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.2.output.dense.bias', 'base_model.encoder.layer.4.intermediate.dense.weight', 'base_model.encoder.layer.23.attention.output.dense.weight', 'base_model.encoder.layer.14.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.embeddings.LayerNorm.bias', 'base_model.encoder.layer.2.intermediate.dense.weight', 'base_model.encoder.layer.14.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.22.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.23.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.2.attention.self.key.bias', 'base_model.encoder.layer.6.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.7.attention.self.value.weight', 'base_model.encoder.layer.16.attention.self.value.weight', 'base_model.encoder.layer.16.attention.output.dense.bias', 'base_model.encoder.layer.15.attention.self.query.weight', 'base_model.encoder.layer.8.attention.self.value.bias', 'base_model.encoder.layer.1.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.15.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.17.attention.output.LayerNorm.weight', 'base_model.encoder.layer.2.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.8.attention.self.key.weight', 'base_model.encoder.layer.18.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.18.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.15.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.23.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.4.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.18.attention.self.query.bias', 'base_model.encoder.layer.22.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.1.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.7.attention.output.dense.weight', 'base_model.encoder.layer.19.output.LayerNorm.bias', 'base_model.encoder.layer.13.output.LayerNorm.bias', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.10.attention.self.key.weight', 'base_model.encoder.layer.7.output.dense.weight', 'base_model.encoder.layer.10.attention.output.LayerNorm.bias', 'base_model.encoder.layer.3.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.12.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.17.output.dense.bias', 'base_model.encoder.layer.19.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.4.attention.self.value.bias', 'base_model.encoder.layer.23.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.7.output.LayerNorm.bias', 'base_model.encoder.layer.20.attention.self.query.weight', 'base_model.encoder.layer.0.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.15.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.10.output.LayerNorm.weight', 'base_model.encoder.layer.12.attention.output.dense.weight', 'base_model.encoder.layer.22.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.3.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.12.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.19.attention.self.value.weight', 'base_model.encoder.layer.16.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.11.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.15.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.9.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.11.attention.self.value.weight', 'base_model.encoder.layer.2.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.21.intermediate.dense.bias', 'base_model.encoder.layer.10.attention.self.key.bias', 'base_model.encoder.layer.16.attention.self.query.weight', 'base_model.encoder.layer.21.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.23.output.dense.weight', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.6.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.2.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.14.attention.output.dense.weight', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.20.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.5.intermediate.dense.weight', 'base_model.encoder.layer.12.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.3.attention.output.dense.weight', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.7.intermediate.dense.bias', 'base_model.encoder.layer.8.attention.self.query.weight', 'base_model.encoder.layer.5.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.16.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.19.attention.self.value.bias', 'base_model.encoder.layer.3.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.0.output.LayerNorm.weight', 'base_model.encoder.layer.19.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.14.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.15.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.12.attention.output.dense.bias', 'base_model.encoder.layer.19.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.3.intermediate.dense.bias', 'base_model.encoder.layer.2.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.5.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.12.attention.self.query.bias', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.3.attention.self.query.bias', 'base_model.encoder.layer.15.attention.output.LayerNorm.bias', 'base_model.encoder.layer.16.output.LayerNorm.weight', 'base_model.encoder.layer.12.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.13.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.3.output.LayerNorm.bias', 'base_model.encoder.layer.17.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.10.attention.output.dense.bias', 'base_model.encoder.layer.12.output.LayerNorm.bias', 'base_model.encoder.layer.8.output.dense.weight', 'base_model.encoder.layer.17.intermediate.dense.bias', 'base_model.encoder.layer.1.attention.output.dense.bias', 'base_model.encoder.layer.9.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.18.intermediate.dense.weight', 'base_model.encoder.layer.18.attention.output.LayerNorm.weight', 'base_model.encoder.layer.6.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.11.attention.self.value.bias', 'base_model.encoder.layer.22.attention.self.value.weight', 'base_model.encoder.layer.11.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.19.intermediate.dense.bias', 'base_model.encoder.layer.21.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.0.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.23.attention.self.query.weight', 'base_model.encoder.layer.2.output.LayerNorm.weight', 'base_model.encoder.layer.7.attention.output.dense.bias', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.10.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.18.attention.output.dense.weight', 'base_model.encoder.layer.1.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.16.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.12.output.dense.weight', 'base_model.encoder.layer.5.output.LayerNorm.weight', 'base_model.encoder.layer.13.intermediate.dense.bias', 'base_model.encoder.layer.1.output.dense.bias', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.16.attention.output.LayerNorm.bias', 'base_model.encoder.layer.11.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.13.output.dense.weight', 'base_model.encoder.layer.17.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.2.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.14.attention.self.key.bias', 'base_model.encoder.layer.21.attention.self.value.bias', 'base_model.encoder.layer.9.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.10.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.7.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.17.attention.self.query.bias', 'base_model.encoder.layer.0.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.9.output.dense.weight', 'base_model.encoder.layer.12.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.16.attention.self.key.bias', 'base_model.encoder.layer.23.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.8.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.0.attention.output.LayerNorm.bias', 'base_model.encoder.layer.17.attention.output.LayerNorm.bias', 'base_model.encoder.layer.10.output.LayerNorm.bias', 'base_model.encoder.layer.10.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.15.intermediate.dense.bias', 'base_model.encoder.layer.19.output.dense.weight', 'base_model.encoder.layer.1.attention.output.dense.weight', 'base_model.encoder.layer.13.attention.self.value.weight', 'base_model.embeddings.position_embeddings.weight', 'base_model.encoder.layer.4.attention.self.key.bias', 'base_model.encoder.layer.21.attention.output.dense.bias', 'base_model.encoder.layer.18.attention.self.key.weight', 'base_model.encoder.layer.3.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.20.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.2.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.19.attention.output.dense.weight', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.6.attention.output.LayerNorm.weight', 'base_model.encoder.layer.6.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.3.attention.self.key.bias', 'base_model.encoder.layer.20.attention.self.value.weight', 'base_model.encoder.layer.0.attention.self.value.weight', 'base_model.encoder.layer.9.intermediate.dense.weight', 'base_model.encoder.layer.1.attention.output.LayerNorm.bias', 'base_model.encoder.layer.12.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.14.output.dense.weight', 'base_model.encoder.layer.18.output.LayerNorm.bias', 'base_model.encoder.layer.1.attention.self.key.bias', 'base_model.encoder.layer.8.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.11.attention.output.dense.weight', 'base_model.encoder.layer.3.attention.self.value.weight', 'base_model.encoder.layer.10.attention.self.value.bias', 'base_model.encoder.layer.7.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.17.output.dense.weight', 'base_model.encoder.layer.1.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.4.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.20.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.16.intermediate.dense.bias', 'base_model.encoder.layer.17.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.5.attention.self.query.weight', 'base_model.encoder.layer.10.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.13.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.19.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.6.attention.self.value.weight', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.13.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.1.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.8.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.12.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.19.attention.output.dense.bias', 'base_model.encoder.layer.20.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.20.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.5.attention.output.LayerNorm.weight', 'base_model.encoder.layer.17.output.LayerNorm.weight', 'base_model.encoder.layer.20.output.dense.bias', 'base_model.encoder.layer.16.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.16.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.7.attention.self.query.bias', 'base_model.encoder.layer.8.output.LayerNorm.weight', 'base_model.encoder.layer.13.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.13.attention.self.key.bias', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.6.attention.self.key.bias', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.11.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.3.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.10.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.15.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.14.attention.output.dense.bias', 'base_model.encoder.layer.4.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.4.attention.self.key.weight', 'base_model.encoder.layer.9.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.13.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.14.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.14.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.16.attention.self.key.weight', 'base_model.encoder.layer.4.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.0.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.17.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.5.attention.self.key.weight', 'base_model.encoder.layer.19.attention.self.key.bias', 'base_model.encoder.layer.22.attention.self.value.bias', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'qa_outputs.bias', 'base_model.encoder.layer.6.output.LayerNorm.bias', 'base_model.encoder.layer.15.output.dense.weight', 'base_model.encoder.layer.22.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.4.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.10.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.11.output.dense.bias', 'base_model.encoder.layer.23.output.LayerNorm.weight', 'base_model.encoder.layer.19.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.4.attention.output.LayerNorm.weight', 'base_model.encoder.layer.10.output.dense.bias', 'base_model.encoder.layer.13.attention.output.LayerNorm.bias', 'base_model.encoder.layer.0.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.18.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.6.attention.output.dense.weight', 'base_model.encoder.layer.10.attention.self.value.weight', 'base_model.encoder.layer.13.attention.self.query.bias', 'base_model.encoder.layer.14.attention.output.LayerNorm.weight', 'base_model.encoder.layer.19.attention.self.query.bias', 'base_model.encoder.layer.14.attention.self.value.bias', 'base_model.encoder.layer.15.output.dense.bias', 'base_model.encoder.layer.6.intermediate.dense.bias', 'base_model.encoder.layer.11.output.LayerNorm.bias', 'base_model.encoder.layer.23.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.18.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.2.attention.output.dense.bias', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.7.attention.output.LayerNorm.bias', 'base_model.encoder.layer.16.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.20.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.16.output.LayerNorm.bias', 'base_model.encoder.layer.2.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.9.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.8.attention.output.LayerNorm.weight', 'base_model.encoder.layer.12.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.22.output.LayerNorm.weight', 'base_model.encoder.layer.22.attention.output.dense.weight', 'base_model.encoder.layer.18.attention.self.value.bias', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.13.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.22.output.dense.weight', 'base_model.encoder.layer.0.output.dense.bias', 'base_model.encoder.layer.22.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.19.output.LayerNorm.weight', 'base_model.encoder.layer.10.attention.self.query.weight', 'base_model.encoder.layer.17.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.9.attention.output.dense.weight', 'base_model.encoder.layer.18.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.12.attention.output.LayerNorm.weight', 'base_model.encoder.layer.5.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.1.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.21.attention.self.query.bias', 'base_model.encoder.layer.17.attention.output.dense.bias', 'base_model.encoder.layer.5.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.5.attention.self.key.bias', 'base_model.encoder.layer.3.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.12.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.13.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.11.attention.output.LayerNorm.bias', 'base_model.encoder.layer.12.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.8.intermediate.dense.bias', 'base_model.encoder.layer.8.output.LayerNorm.bias', 'base_model.encoder.layer.21.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.0.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.13.attention.self.value.bias', 'base_model.encoder.layer.6.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.23.intermediate.dense.weight', 'base_model.encoder.layer.15.attention.self.value.weight', 'base_model.encoder.layer.4.attention.output.dense.bias', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.0.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.9.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.7.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.17.output.adapters.tp.adapter_up.bias', 'base_model.embeddings.token_type_embeddings.weight', 'base_model.encoder.layer.15.attention.output.LayerNorm.weight', 'base_model.encoder.layer.0.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.20.attention.self.query.bias', 'base_model.encoder.layer.17.output.adapters.tp.adapter_down.0.bias', 'base_model.embeddings.LayerNorm.weight', 'base_model.encoder.layer.2.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.1.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.13.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.15.output.LayerNorm.bias', 'base_model.encoder.layer.21.output.LayerNorm.bias', 'base_model.encoder.layer.23.attention.self.key.weight', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.9.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.8.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.16.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.11.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.1.output.LayerNorm.bias', 'base_model.encoder.layer.2.attention.self.value.weight', 'base_model.encoder.layer.21.attention.output.dense.weight', 'base_model.encoder.layer.5.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.22.attention.output.LayerNorm.bias', 'base_model.encoder.layer.8.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.14.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.9.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.13.attention.output.dense.bias', 'base_model.encoder.layer.4.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.3.output.LayerNorm.weight', 'base_model.encoder.layer.20.intermediate.dense.bias', 'base_model.encoder.layer.20.output.dense.weight', 'base_model.encoder.layer.13.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.7.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.8.output.dense.bias', 'base_model.encoder.layer.13.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.9.output.LayerNorm.weight', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.12.attention.self.value.bias', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.1.intermediate.dense.bias', 'base_model.encoder.layer.11.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.19.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.23.attention.self.value.bias', 'base_model.encoder.layer.6.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.14.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.17.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.12.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.9.attention.self.key.bias', 'base_model.encoder.layer.14.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.19.attention.output.LayerNorm.bias', 'base_model.encoder.layer.21.attention.output.LayerNorm.bias', 'base_model.encoder.layer.17.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.21.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.22.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.21.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.23.attention.self.value.weight', 'base_model.encoder.layer.10.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.22.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.6.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.15.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.3.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.1.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.18.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.16.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.6.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.15.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.0.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.11.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.23.attention.self.query.bias', 'base_model.encoder.layer.1.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.21.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.2.attention.output.LayerNorm.bias', 'base_model.encoder.layer.7.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.14.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.21.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.14.intermediate.dense.weight', 'base_model.encoder.layer.11.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.9.intermediate.dense.bias', 'base_model.encoder.layer.21.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.5.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.18.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.19.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.7.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.7.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.5.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.18.attention.self.value.weight', 'base_model.encoder.layer.1.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.0.intermediate.dense.weight', 'base_model.encoder.layer.21.attention.self.value.weight', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.13.intermediate.dense.weight', 'base_model.encoder.layer.22.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.11.attention.self.key.bias', 'base_model.encoder.layer.13.attention.self.query.weight', 'base_model.encoder.layer.10.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.14.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.2.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.7.intermediate.dense.weight', 'base_model.encoder.layer.2.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.13.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.16.attention.self.query.bias', 'base_model.encoder.layer.18.output.LayerNorm.weight', 'base_model.encoder.layer.10.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.20.attention.output.LayerNorm.weight', 'base_model.encoder.layer.11.attention.output.LayerNorm.weight', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.6.output.dense.bias', 'base_model.encoder.layer.12.attention.self.value.weight', 'base_model.encoder.layer.17.output.LayerNorm.bias', 'base_model.embeddings.position_ids', 'base_model.encoder.layer.19.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.2.attention.self.query.weight', 'base_model.encoder.layer.22.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.10.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.11.attention.self.key.weight', 'base_model.encoder.layer.20.attention.output.dense.bias', 'base_model.encoder.layer.6.attention.self.query.bias', 'base_model.encoder.layer.1.attention.self.query.weight', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.18.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.21.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.4.intermediate.dense.bias', 'base_model.encoder.layer.3.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.10.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.15.intermediate.dense.weight', 'base_model.encoder.layer.12.attention.output.LayerNorm.bias', 'base_model.encoder.layer.8.attention.output.dense.bias', 'base_model.encoder.layer.8.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.7.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.12.intermediate.dense.weight', 'base_model.encoder.layer.9.attention.self.key.weight', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.11.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.1.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.13.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.18.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.19.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.7.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.20.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.9.attention.self.value.weight', 'base_model.encoder.layer.13.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.12.attention.self.key.weight', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.21.attention.self.query.weight', 'base_model.encoder.layer.22.output.LayerNorm.bias', 'base_model.encoder.layer.7.output.dense.bias', 'base_model.encoder.layer.8.attention.output.LayerNorm.bias', 'base_model.encoder.layer.4.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.7.attention.output.LayerNorm.weight', 'base_model.encoder.layer.22.attention.self.key.weight', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.1.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.4.output.dense.bias', 'base_model.encoder.layer.8.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.11.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.21.intermediate.dense.weight', 'base_model.encoder.layer.3.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.1.attention.self.query.bias', 'base_model.encoder.layer.23.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.12.attention.self.query.weight', 'base_model.encoder.layer.22.attention.self.query.bias', 'base_model.encoder.layer.17.output.adapters.ts.adapter_up.weight', 'qa_outputs.weight', 'base_model.encoder.layer.12.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.20.attention.self.key.bias', 'base_model.encoder.layer.0.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.12.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.18.attention.self.query.weight', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.10.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.8.attention.self.value.weight', 'base_model.encoder.layer.5.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.16.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.10.intermediate.dense.weight', 'base_model.encoder.layer.9.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.10.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.14.output.LayerNorm.bias', 'base_model.encoder.layer.2.attention.self.key.weight', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.6.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.13.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.21.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.3.attention.output.dense.bias', 'base_model.encoder.layer.0.attention.self.key.weight', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.20.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.0.output.LayerNorm.bias', 'base_model.encoder.layer.8.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.19.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.11.attention.output.dense.bias', 'base_model.encoder.layer.16.attention.self.value.bias', 'base_model.encoder.layer.21.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.23.attention.output.LayerNorm.weight', 'base_model.encoder.layer.4.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.11.intermediate.dense.bias', 'base_model.encoder.layer.14.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.4.output.dense.weight', 'base_model.encoder.layer.5.output.dense.bias', 'base_model.encoder.layer.1.attention.self.value.weight', 'base_model.encoder.layer.12.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.23.output.dense.bias', 'base_model.encoder.layer.11.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.9.attention.output.dense.bias', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.9.attention.output.LayerNorm.weight', 'base_model.encoder.layer.5.output.LayerNorm.bias', 'base_model.encoder.layer.13.output.dense.bias', 'base_model.encoder.layer.9.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.23.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.23.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.22.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.14.attention.self.key.weight', 'base_model.encoder.layer.19.attention.output.LayerNorm.weight', 'base_model.encoder.layer.23.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.16.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.18.attention.output.dense.bias', 'base_model.encoder.layer.8.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.17.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.7.attention.self.value.bias', 'base_model.encoder.layer.1.attention.self.value.bias', 'base_model.encoder.layer.6.attention.output.dense.bias', 'base_model.encoder.layer.2.attention.output.LayerNorm.weight', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.20.output.LayerNorm.bias', 'base_model.encoder.layer.15.attention.self.value.bias', 'base_model.encoder.layer.9.attention.self.value.bias', 'base_model.encoder.layer.4.output.LayerNorm.weight', 'base_model.encoder.layer.5.attention.output.dense.weight', 'base_model.encoder.layer.10.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.13.attention.output.LayerNorm.weight', 'base_model.encoder.layer.16.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.2.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.21.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.10.attention.output.dense.weight', 'base_model.pooler.dense.weight', 'base_model.encoder.layer.8.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.23.intermediate.dense.bias', 'base_model.encoder.layer.11.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.2.output.LayerNorm.bias', 'base_model.encoder.layer.6.intermediate.dense.weight', 'base_model.encoder.layer.6.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.14.attention.self.query.bias', 'base_model.encoder.layer.14.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.3.attention.self.value.bias', 'base_model.encoder.layer.6.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.23.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.8.attention.self.query.bias', 'base_model.encoder.layer.5.attention.self.value.bias', 'base_model.encoder.layer.5.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.2.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.19.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.19.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.19.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.7.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.18.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.20.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.4.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.22.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.11.attention.self.query.bias', 'base_model.encoder.layer.19.output.dense.bias', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.5.output.dense.weight', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.19.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.11.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.12.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.19.attention.self.key.weight', 'base_model.encoder.layer.3.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.23.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.6.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.21.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.14.output.dense.bias', 'base_model.encoder.layer.3.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.0.intermediate.dense.bias', 'base_model.encoder.layer.18.intermediate.dense.bias', 'base_model.encoder.layer.5.attention.self.value.weight', 'base_model.encoder.layer.17.attention.self.key.weight', 'base_model.encoder.layer.6.attention.self.query.weight', 'base_model.encoder.layer.10.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.13.output.LayerNorm.weight', 'base_model.encoder.layer.20.output.LayerNorm.weight', 'base_model.encoder.layer.15.attention.output.dense.weight', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.6.attention.self.key.weight', 'base_model.encoder.layer.21.attention.self.key.weight', 'base_model.encoder.layer.6.attention.output.LayerNorm.bias', 'base_model.encoder.layer.22.attention.output.dense.bias', 'base_model.encoder.layer.12.intermediate.dense.bias', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.6.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.2.output.dense.weight', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.3.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.4.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.20.attention.self.key.weight', 'base_model.encoder.layer.15.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.1.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.15.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.18.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.14.attention.self.value.weight', 'base_model.encoder.layer.11.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.4.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.15.output.LayerNorm.weight', 'base_model.encoder.layer.10.attention.output.LayerNorm.weight', 'base_model.encoder.layer.16.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.18.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.21.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.14.intermediate.dense.bias', 'base_model.encoder.layer.12.attention.self.key.bias', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.17.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.15.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.22.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.0.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.5.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.6.attention.self.value.bias', 'base_model.encoder.layer.18.attention.self.key.bias', 'base_model.encoder.layer.20.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.23.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.7.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.7.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.1.attention.self.key.weight', 'base_model.encoder.layer.13.attention.output.dense.weight', 'base_model.encoder.layer.1.attention.output.LayerNorm.weight', 'base_model.encoder.layer.20.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.0.attention.self.query.bias', 'base_model.encoder.layer.7.output.LayerNorm.weight', 'base_model.encoder.layer.9.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.19.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.7.attention.self.key.weight', 'base_model.encoder.layer.15.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.0.attention.self.value.bias', 'base_model.encoder.layer.9.attention.output.LayerNorm.bias', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.15.attention.self.key.bias', 'base_model.encoder.layer.3.intermediate.dense.weight', 'base_model.encoder.layer.15.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.1.intermediate.dense.weight', 'base_model.encoder.layer.3.attention.self.key.weight', 'base_model.encoder.layer.22.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.16.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.16.attention.output.LayerNorm.weight', 'base_model.encoder.layer.20.output.adapters.ep.adapter_down.0.bias']
- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of XLMRobertaModel were not initialized from the model checkpoint at /cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//squad/xlm-KG_LR4e-5_EPOCH2.0_maxlen384_batchsize4_gradacc8 and are newly initialized: ['encoder.layer.13.intermediate.dense.weight', 'encoder.layer.2.attention.output.dense.bias', 'encoder.layer.1.attention.output.dense.weight', 'encoder.layer.12.attention.self.query.bias', 'encoder.layer.10.attention.self.value.bias', 'encoder.layer.10.attention.self.key.bias', 'encoder.layer.11.attention.output.dense.bias', 'encoder.layer.10.output.LayerNorm.weight', 'encoder.layer.6.attention.self.value.weight', 'encoder.layer.2.attention.self.query.bias', 'encoder.layer.15.attention.self.value.weight', 'encoder.layer.5.attention.self.value.weight', 'encoder.layer.12.attention.output.dense.weight', 'encoder.layer.14.attention.self.query.bias', 'encoder.layer.7.output.dense.bias', 'encoder.layer.22.attention.output.LayerNorm.bias', 'encoder.layer.19.output.dense.bias', 'encoder.layer.0.attention.self.value.bias', 'encoder.layer.19.attention.output.LayerNorm.weight', 'encoder.layer.5.attention.self.key.weight', 'encoder.layer.6.attention.self.query.bias', 'encoder.layer.21.attention.self.key.weight', 'encoder.layer.9.attention.self.value.bias', 'encoder.layer.7.attention.self.value.bias', 'encoder.layer.22.attention.self.query.weight', 'encoder.layer.16.attention.output.LayerNorm.bias', 'encoder.layer.18.attention.output.LayerNorm.weight', 'encoder.layer.22.attention.self.value.weight', 'encoder.layer.11.attention.self.query.bias', 'encoder.layer.0.output.dense.bias', 'encoder.layer.3.attention.self.key.bias', 'encoder.layer.20.output.LayerNorm.weight', 'encoder.layer.18.attention.self.key.weight', 'encoder.layer.19.output.dense.weight', 'encoder.layer.14.output.dense.weight', 'encoder.layer.4.attention.self.key.bias', 'encoder.layer.21.attention.output.LayerNorm.bias', 'encoder.layer.11.attention.output.dense.weight', 'encoder.layer.16.attention.self.key.bias', 'encoder.layer.13.output.LayerNorm.bias', 'encoder.layer.3.output.dense.weight', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.23.attention.self.key.bias', 'encoder.layer.8.attention.output.dense.bias', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.12.intermediate.dense.weight', 'encoder.layer.15.attention.self.value.bias', 'encoder.layer.23.output.dense.bias', 'encoder.layer.6.output.dense.weight', 'encoder.layer.3.attention.output.dense.weight', 'encoder.layer.11.attention.self.query.weight', 'encoder.layer.16.intermediate.dense.bias', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.14.attention.self.key.weight', 'encoder.layer.5.attention.output.dense.bias', 'encoder.layer.13.intermediate.dense.bias', 'encoder.layer.6.output.LayerNorm.bias', 'encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.layer.13.attention.self.key.weight', 'encoder.layer.13.attention.self.query.bias', 'encoder.layer.22.attention.output.dense.bias', 'encoder.layer.17.attention.self.value.bias', 'encoder.layer.3.attention.self.query.bias', 'encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.layer.8.output.LayerNorm.bias', 'encoder.layer.19.attention.self.query.weight', 'encoder.layer.17.intermediate.dense.weight', 'encoder.layer.8.attention.self.key.bias', 'encoder.layer.7.attention.output.dense.bias', 'encoder.layer.16.attention.output.dense.bias', 'encoder.layer.15.intermediate.dense.bias', 'encoder.layer.2.output.dense.weight', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.19.intermediate.dense.bias', 'encoder.layer.6.attention.output.LayerNorm.bias', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.12.output.dense.bias', 'encoder.layer.11.attention.self.value.bias', 'encoder.layer.19.output.LayerNorm.weight', 'encoder.layer.17.output.LayerNorm.weight', 'encoder.layer.17.attention.self.value.weight', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.9.output.LayerNorm.weight', 'encoder.layer.15.attention.output.dense.weight', 'encoder.layer.4.attention.output.dense.bias', 'encoder.layer.15.attention.self.key.bias', 'encoder.layer.20.attention.self.key.weight', 'encoder.layer.20.output.dense.weight', 'encoder.layer.14.attention.output.LayerNorm.weight', 'encoder.layer.16.attention.output.dense.weight', 'encoder.layer.16.attention.self.value.weight', 'encoder.layer.20.attention.output.dense.weight', 'encoder.layer.8.attention.self.value.weight', 'embeddings.LayerNorm.weight', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.18.attention.self.value.bias', 'encoder.layer.8.output.dense.bias', 'encoder.layer.23.attention.output.LayerNorm.bias', 'encoder.layer.22.attention.self.key.bias', 'encoder.layer.16.output.LayerNorm.bias', 'encoder.layer.20.intermediate.dense.bias', 'encoder.layer.8.output.LayerNorm.weight', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.3.attention.self.key.weight', 'encoder.layer.0.attention.self.key.bias', 'encoder.layer.9.attention.output.dense.bias', 'encoder.layer.17.output.dense.weight', 'encoder.layer.15.attention.output.LayerNorm.bias', 'encoder.layer.0.attention.output.dense.weight', 'encoder.layer.18.attention.output.dense.bias', 'embeddings.word_embeddings.weight', 'encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.layer.7.output.LayerNorm.bias', 'encoder.layer.0.attention.self.query.bias', 'encoder.layer.6.attention.self.key.weight', 'encoder.layer.12.intermediate.dense.bias', 'encoder.layer.14.attention.output.LayerNorm.bias', 'encoder.layer.20.intermediate.dense.weight', 'encoder.layer.16.attention.self.query.weight', 'encoder.layer.23.attention.output.LayerNorm.weight', 'encoder.layer.13.attention.output.LayerNorm.bias', 'encoder.layer.23.attention.output.dense.bias', 'encoder.layer.21.output.dense.weight', 'encoder.layer.23.attention.self.value.weight', 'encoder.layer.20.output.LayerNorm.bias', 'encoder.layer.22.attention.self.value.bias', 'encoder.layer.13.output.dense.weight', 'encoder.layer.12.output.LayerNorm.bias', 'encoder.layer.5.attention.self.key.bias', 'encoder.layer.6.output.dense.bias', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.15.output.dense.weight', 'encoder.layer.20.attention.self.value.weight', 'encoder.layer.22.intermediate.dense.weight', 'encoder.layer.14.attention.self.key.bias', 'encoder.layer.23.attention.self.query.bias', 'encoder.layer.15.output.LayerNorm.weight', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.8.attention.self.query.weight', 'encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.layer.22.output.dense.bias', 'encoder.layer.3.attention.self.query.weight', 'encoder.layer.12.attention.self.query.weight', 'encoder.layer.7.attention.self.query.weight', 'encoder.layer.1.attention.self.key.bias', 'encoder.layer.18.intermediate.dense.bias', 'encoder.layer.22.intermediate.dense.bias', 'encoder.layer.1.attention.self.key.weight', 'encoder.layer.7.output.LayerNorm.weight', 'encoder.layer.12.attention.output.dense.bias', 'encoder.layer.12.output.dense.weight', 'encoder.layer.0.attention.self.query.weight', 'encoder.layer.9.attention.output.LayerNorm.bias', 'encoder.layer.0.attention.self.value.weight', 'encoder.layer.21.attention.self.value.bias', 'encoder.layer.3.output.dense.bias', 'encoder.layer.9.output.dense.weight', 'encoder.layer.10.output.dense.weight', 'encoder.layer.6.attention.self.value.bias', 'encoder.layer.20.attention.output.LayerNorm.weight', 'encoder.layer.14.attention.output.dense.weight', 'encoder.layer.14.attention.self.value.weight', 'encoder.layer.19.intermediate.dense.weight', 'encoder.layer.19.attention.self.key.weight', 'encoder.layer.1.attention.self.query.bias', 'encoder.layer.20.attention.output.dense.bias', 'encoder.layer.21.output.dense.bias', 'encoder.layer.3.attention.self.value.weight', 'encoder.layer.1.attention.self.value.bias', 'encoder.layer.17.attention.output.dense.weight', 'encoder.layer.21.attention.self.key.bias', 'pooler.dense.weight', 'encoder.layer.9.attention.self.query.weight', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.18.attention.output.dense.weight', 'encoder.layer.11.output.LayerNorm.weight', 'encoder.layer.7.intermediate.dense.bias', 'encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.layer.12.attention.self.key.bias', 'encoder.layer.16.attention.output.LayerNorm.weight', 'encoder.layer.23.attention.self.key.weight', 'encoder.layer.23.attention.output.dense.weight', 'encoder.layer.10.attention.self.key.weight', 'encoder.layer.5.attention.self.value.bias', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.18.attention.output.LayerNorm.bias', 'encoder.layer.10.attention.output.dense.bias', 'encoder.layer.19.attention.self.value.weight', 'encoder.layer.18.output.LayerNorm.weight', 'encoder.layer.23.output.dense.weight', 'encoder.layer.4.output.dense.weight', 'encoder.layer.7.attention.self.query.bias', 'encoder.layer.11.attention.output.LayerNorm.weight', 'encoder.layer.9.attention.self.value.weight', 'encoder.layer.16.output.dense.weight', 'encoder.layer.18.attention.self.key.bias', 'encoder.layer.23.attention.self.query.weight', 'encoder.layer.21.attention.self.value.weight', 'encoder.layer.12.attention.output.LayerNorm.weight', 'encoder.layer.19.attention.output.LayerNorm.bias', 'encoder.layer.9.attention.self.key.bias', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.9.output.LayerNorm.bias', 'encoder.layer.15.attention.self.query.weight', 'encoder.layer.2.attention.self.value.bias', 'encoder.layer.5.output.dense.bias', 'encoder.layer.11.output.LayerNorm.bias', 'encoder.layer.6.attention.output.dense.weight', 'encoder.layer.17.attention.output.dense.bias', 'encoder.layer.0.attention.output.LayerNorm.weight', 'encoder.layer.4.attention.output.LayerNorm.bias', 'encoder.layer.9.attention.output.LayerNorm.weight', 'encoder.layer.14.output.LayerNorm.weight', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.4.attention.self.value.weight', 'encoder.layer.13.attention.self.value.weight', 'encoder.layer.8.attention.self.key.weight', 'encoder.layer.13.attention.self.key.bias', 'encoder.layer.21.output.LayerNorm.bias', 'encoder.layer.1.output.dense.weight', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.18.output.LayerNorm.bias', 'encoder.layer.10.attention.self.query.bias', 'encoder.layer.20.attention.self.query.weight', 'encoder.layer.11.attention.self.value.weight', 'encoder.layer.4.output.LayerNorm.bias', 'embeddings.position_embeddings.weight', 'encoder.layer.22.output.LayerNorm.weight', 'encoder.layer.12.attention.self.value.weight', 'encoder.layer.17.attention.self.query.weight', 'encoder.layer.1.attention.output.dense.bias', 'encoder.layer.8.attention.output.LayerNorm.bias', 'encoder.layer.19.attention.output.dense.weight', 'encoder.layer.3.attention.self.value.bias', 'encoder.layer.20.attention.output.LayerNorm.bias', 'encoder.layer.15.attention.output.LayerNorm.weight', 'encoder.layer.8.attention.self.query.bias', 'encoder.layer.16.output.LayerNorm.weight', 'encoder.layer.12.output.LayerNorm.weight', 'encoder.layer.20.attention.self.query.bias', 'encoder.layer.14.attention.self.value.bias', 'encoder.layer.21.attention.output.dense.weight', 'encoder.layer.1.attention.output.LayerNorm.weight', 'encoder.layer.7.output.dense.weight', 'encoder.layer.4.attention.self.value.bias', 'encoder.layer.2.attention.output.LayerNorm.weight', 'encoder.layer.9.output.dense.bias', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.11.output.dense.bias', 'encoder.layer.17.attention.output.LayerNorm.weight', 'encoder.layer.11.output.dense.weight', 'encoder.layer.2.attention.self.key.weight', 'encoder.layer.20.attention.self.value.bias', 'encoder.layer.4.output.dense.bias', 'encoder.layer.9.attention.self.query.bias', 'encoder.layer.3.attention.output.dense.bias', 'encoder.layer.4.attention.output.dense.weight', 'encoder.layer.9.attention.output.dense.weight', 'encoder.layer.14.attention.self.query.weight', 'encoder.layer.15.output.LayerNorm.bias', 'encoder.layer.14.intermediate.dense.weight', 'encoder.layer.14.output.LayerNorm.bias', 'encoder.layer.19.output.LayerNorm.bias', 'encoder.layer.7.attention.self.value.weight', 'encoder.layer.4.attention.self.query.bias', 'encoder.layer.23.output.LayerNorm.weight', 'pooler.dense.bias', 'encoder.layer.22.output.LayerNorm.bias', 'encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.layer.17.attention.self.query.bias', 'encoder.layer.20.output.dense.bias', 'encoder.layer.18.attention.self.query.weight', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.15.attention.self.query.bias', 'encoder.layer.21.attention.self.query.weight', 'encoder.layer.16.attention.self.query.bias', 'encoder.layer.2.attention.output.LayerNorm.bias', 'encoder.layer.11.attention.self.key.weight', 'encoder.layer.0.attention.output.dense.bias', 'encoder.layer.14.output.dense.bias', 'encoder.layer.5.attention.output.LayerNorm.weight', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.8.attention.output.dense.weight', 'encoder.layer.23.output.LayerNorm.bias', 'encoder.layer.6.attention.self.query.weight', 'encoder.layer.10.intermediate.dense.weight', 'encoder.layer.12.attention.self.key.weight', 'encoder.layer.12.attention.self.value.bias', 'encoder.layer.20.attention.self.key.bias', 'encoder.layer.12.attention.output.LayerNorm.bias', 'encoder.layer.6.attention.self.key.bias', 'encoder.layer.7.attention.output.LayerNorm.bias', 'encoder.layer.8.attention.self.value.bias', 'encoder.layer.10.attention.output.dense.weight', 'encoder.layer.23.intermediate.dense.bias', 'encoder.layer.13.attention.self.value.bias', 'encoder.layer.10.attention.self.query.weight', 'encoder.layer.6.attention.output.dense.bias', 'encoder.layer.22.attention.self.query.bias', 'encoder.layer.13.attention.output.dense.weight', 'encoder.layer.0.output.dense.weight', 'encoder.layer.21.attention.self.query.bias', 'encoder.layer.13.output.LayerNorm.weight', 'encoder.layer.17.attention.output.LayerNorm.bias', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.7.attention.self.key.weight', 'encoder.layer.18.output.dense.weight', 'encoder.layer.5.output.dense.weight', 'encoder.layer.21.intermediate.dense.weight', 'encoder.layer.19.attention.output.dense.bias', 'encoder.layer.13.attention.output.LayerNorm.weight', 'encoder.layer.10.output.dense.bias', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.21.intermediate.dense.bias', 'encoder.layer.14.attention.output.dense.bias', 'encoder.layer.15.attention.output.dense.bias', 'encoder.layer.21.attention.output.LayerNorm.weight', 'encoder.layer.23.intermediate.dense.weight', 'encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.22.output.dense.weight', 'encoder.layer.0.attention.self.key.weight', 'encoder.layer.17.output.LayerNorm.bias', 'encoder.layer.17.attention.self.key.bias', 'encoder.layer.2.output.dense.bias', 'encoder.layer.18.output.dense.bias', 'encoder.layer.5.attention.self.query.bias', 'encoder.layer.7.attention.output.LayerNorm.weight', 'encoder.layer.2.attention.self.value.weight', 'encoder.layer.15.output.dense.bias', 'encoder.layer.18.attention.self.query.bias', 'encoder.layer.19.attention.self.value.bias', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.16.attention.self.value.bias', 'encoder.layer.21.attention.output.dense.bias', 'encoder.layer.5.output.LayerNorm.bias', 'encoder.layer.16.attention.self.key.weight', 'encoder.layer.14.intermediate.dense.bias', 'encoder.layer.15.attention.self.key.weight', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.16.intermediate.dense.weight', 'encoder.layer.23.attention.self.value.bias', 'encoder.layer.1.attention.self.query.weight', 'encoder.layer.18.intermediate.dense.weight', 'encoder.layer.8.attention.output.LayerNorm.weight', 'encoder.layer.22.attention.output.dense.weight', 'encoder.layer.13.attention.self.query.weight', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.10.attention.output.LayerNorm.weight', 'encoder.layer.15.intermediate.dense.weight', 'encoder.layer.22.attention.output.LayerNorm.weight', 'encoder.layer.1.attention.self.value.weight', 'encoder.layer.13.output.dense.bias', 'encoder.layer.13.attention.output.dense.bias', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.18.attention.self.value.weight', 'encoder.layer.10.attention.self.value.weight', 'encoder.layer.16.output.dense.bias', 'embeddings.LayerNorm.bias', 'encoder.layer.10.attention.output.LayerNorm.bias', 'encoder.layer.7.attention.self.key.bias', 'encoder.layer.17.attention.self.key.weight', 'encoder.layer.4.attention.output.LayerNorm.weight', 'encoder.layer.8.output.dense.weight', 'encoder.layer.6.attention.output.LayerNorm.weight', 'encoder.layer.2.attention.self.query.weight', 'encoder.layer.19.attention.self.query.bias', 'encoder.layer.19.attention.self.key.bias', 'encoder.layer.11.attention.self.key.bias', 'encoder.layer.17.output.dense.bias', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.7.attention.output.dense.weight', 'encoder.layer.9.attention.self.key.weight', 'encoder.layer.10.output.LayerNorm.bias', 'encoder.layer.2.attention.self.key.bias', 'embeddings.token_type_embeddings.weight', 'encoder.layer.4.attention.self.query.weight', 'encoder.layer.5.attention.output.dense.weight', 'encoder.layer.17.intermediate.dense.bias', 'encoder.layer.21.output.LayerNorm.weight', 'encoder.layer.1.output.dense.bias', 'encoder.layer.5.attention.self.query.weight', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.4.attention.self.key.weight', 'encoder.layer.2.attention.output.dense.weight', 'encoder.layer.22.attention.self.key.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Overwriting existing adapter 'ep'.
Overwriting existing adapter 'tp'.
Overwriting existing adapter 'es'.
Overwriting existing adapter 'ts'.
Overwriting existing adapter fusion module 'ep,tp,es,ts'
05/09/2022 19:52:40 - INFO - __main__ -   Creating features from dataset file at .
/cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//squad/xlm-KG_LR4e-5_EPOCH2.0_maxlen384_batchsize4_gradacc8
XLMConfig {
  "architectures": [
    "XLMRobertaForMaskedLM"
  ],
  "asm": false,
  "attention_dropout": 0.1,
  "attention_probs_dropout_prob": 0.1,
  "bos_index": 0,
  "bos_token_id": 0,
  "causal": false,
  "dropout": 0.1,
  "emb_dim": 1024,
  "embed_init_std": 0.02209708691207961,
  "end_n_top": 5,
  "eos_index": 1,
  "eos_token_id": 2,
  "gelu_activation": true,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "init_std": 0.02,
  "initializer_range": 0.02,
  "intermediate_size": 4096,
  "is_encoder": true,
  "lang_id": 0,
  "layer_norm_eps": 1e-05,
  "mask_index": 5,
  "mask_token_id": 0,
  "max_position_embeddings": 514,
  "model_type": "xlm",
  "n_heads": 16,
  "n_langs": 1,
  "n_layers": 24,
  "output_past": true,
  "pad_index": 2,
  "pad_token_id": 1,
  "sinusoidal_embeddings": false,
  "start_n_top": 5,
  "summary_activation": null,
  "summary_first_dropout": 0.1,
  "summary_proj_to_labels": true,
  "summary_type": "first",
  "summary_use_proj": true,
  "transformers_version": "4.17.0",
  "type_vocab_size": 1,
  "unk_index": 3,
  "use_lang_emb": false,
  "vocab_size": 250002
}

  0%|          | 0/48 [00:00<?, ?it/s] 29%|██▉       | 14/48 [00:00<00:00, 138.05it/s] 58%|█████▊    | 28/48 [00:00<00:00, 85.03it/s]  79%|███████▉  | 38/48 [00:00<00:00, 86.36it/s]100%|██████████| 48/48 [00:00<00:00, 93.87it/s]
convert squad examples to features:   0%|          | 0/1190 [00:00<?, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.
convert squad examples to features:   0%|          | 1/1190 [00:00<04:30,  4.39it/s]convert squad examples to features:   3%|▎         | 33/1190 [00:00<00:09, 124.48it/s]convert squad examples to features:   5%|▌         | 65/1190 [00:00<00:07, 156.64it/s]convert squad examples to features:   8%|▊         | 97/1190 [00:00<00:05, 187.92it/s]convert squad examples to features:  14%|█▎        | 161/1190 [00:00<00:04, 248.19it/s]convert squad examples to features:  16%|█▌        | 193/1190 [00:00<00:04, 245.41it/s]convert squad examples to features:  22%|██▏       | 257/1190 [00:01<00:03, 249.06it/s]convert squad examples to features:  24%|██▍       | 289/1190 [00:01<00:03, 247.82it/s]convert squad examples to features:  27%|██▋       | 321/1190 [00:01<00:03, 243.79it/s]convert squad examples to features:  30%|██▉       | 353/1190 [00:01<00:03, 249.23it/s]convert squad examples to features:  32%|███▏      | 385/1190 [00:02<00:05, 143.12it/s]convert squad examples to features:  35%|███▌      | 417/1190 [00:02<00:04, 156.69it/s]convert squad examples to features:  38%|███▊      | 449/1190 [00:02<00:04, 168.73it/s]convert squad examples to features:  40%|████      | 481/1190 [00:02<00:04, 176.42it/s]convert squad examples to features:  43%|████▎     | 513/1190 [00:02<00:03, 175.04it/s]convert squad examples to features:  46%|████▌     | 545/1190 [00:02<00:03, 165.29it/s]convert squad examples to features:  48%|████▊     | 577/1190 [00:03<00:03, 184.69it/s]convert squad examples to features:  51%|█████     | 609/1190 [00:03<00:03, 175.88it/s]convert squad examples to features:  54%|█████▍    | 641/1190 [00:03<00:03, 170.48it/s]convert squad examples to features:  57%|█████▋    | 673/1190 [00:03<00:03, 159.71it/s]convert squad examples to features:  59%|█████▉    | 705/1190 [00:03<00:02, 171.39it/s]convert squad examples to features:  62%|██████▏   | 737/1190 [00:04<00:02, 177.34it/s]convert squad examples to features:  65%|██████▍   | 769/1190 [00:04<00:02, 192.18it/s]convert squad examples to features:  67%|██████▋   | 801/1190 [00:04<00:01, 199.24it/s]convert squad examples to features:  70%|███████   | 833/1190 [00:04<00:01, 194.31it/s]convert squad examples to features:  73%|███████▎  | 865/1190 [00:04<00:01, 198.59it/s]convert squad examples to features:  75%|███████▌  | 897/1190 [00:04<00:01, 206.25it/s]convert squad examples to features:  78%|███████▊  | 929/1190 [00:04<00:01, 210.17it/s]convert squad examples to features:  81%|████████  | 961/1190 [00:05<00:01, 226.53it/s]convert squad examples to features:  83%|████████▎ | 993/1190 [00:05<00:00, 236.65it/s]convert squad examples to features:  86%|████████▌ | 1025/1190 [00:05<00:00, 235.58it/s]convert squad examples to features:  89%|████████▉ | 1057/1190 [00:05<00:00, 251.70it/s]convert squad examples to features:  92%|█████████▏| 1089/1190 [00:05<00:00, 243.30it/s]convert squad examples to features:  94%|█████████▍| 1121/1190 [00:05<00:00, 232.56it/s]convert squad examples to features:  97%|█████████▋| 1153/1190 [00:05<00:00, 197.97it/s]convert squad examples to features: 100%|██████████| 1190/1190 [00:05<00:00, 200.86it/s]/cluster/project/sachan/yifan/softwares/anaconda/anaconda3/envs/xfactr/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2272: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

add example index and unique id:   0%|          | 0/1190 [00:00<?, ?it/s]add example index and unique id: 100%|██████████| 1190/1190 [00:00<00:00, 519161.82it/s]
05/09/2022 19:52:47 - INFO - __main__ -   Saving features into cached file ./cached_xquad.es.json_xlm-KG_LR4e-5_EPOCH2.0_maxlen384_batchsize4_gradacc8_384_es
05/09/2022 19:52:48 - INFO - __main__ -   ***** Running evaluation  *****
05/09/2022 19:52:48 - INFO - __main__ -     Num examples = 1304
05/09/2022 19:52:48 - INFO - __main__ -     Batch size = 8
Evaluating:   0%|          | 0/163 [00:00<?, ?it/s]Evaluating:   1%|          | 1/163 [00:00<02:22,  1.14it/s]Evaluating:   1%|          | 2/163 [00:01<01:31,  1.75it/s]Evaluating:   2%|▏         | 3/163 [00:01<01:17,  2.07it/s]Evaluating:   2%|▏         | 4/163 [00:01<01:08,  2.31it/s]Evaluating:   3%|▎         | 5/163 [00:02<01:03,  2.47it/s]Evaluating:   4%|▎         | 6/163 [00:02<01:00,  2.58it/s]Evaluating:   4%|▍         | 7/163 [00:03<00:58,  2.66it/s]Evaluating:   5%|▍         | 8/163 [00:03<00:57,  2.71it/s]Evaluating:   6%|▌         | 9/163 [00:03<00:56,  2.75it/s]Evaluating:   6%|▌         | 10/163 [00:04<00:55,  2.76it/s]Evaluating:   7%|▋         | 11/163 [00:04<00:54,  2.78it/s]Evaluating:   7%|▋         | 12/163 [00:04<00:55,  2.72it/s]Evaluating:   8%|▊         | 13/163 [00:05<00:55,  2.71it/s]Evaluating:   9%|▊         | 14/163 [00:05<00:54,  2.74it/s]Evaluating:   9%|▉         | 15/163 [00:05<00:53,  2.76it/s]Evaluating:  10%|▉         | 16/163 [00:06<00:53,  2.73it/s]Evaluating:  10%|█         | 17/163 [00:06<00:54,  2.68it/s]Evaluating:  11%|█         | 18/163 [00:07<00:53,  2.71it/s]Evaluating:  12%|█▏        | 19/163 [00:07<00:54,  2.65it/s]Evaluating:  12%|█▏        | 20/163 [00:07<00:53,  2.67it/s]Evaluating:  13%|█▎        | 21/163 [00:08<00:52,  2.71it/s]Evaluating:  13%|█▎        | 22/163 [00:08<00:51,  2.74it/s]Evaluating:  14%|█▍        | 23/163 [00:08<00:50,  2.76it/s]Evaluating:  15%|█▍        | 24/163 [00:09<00:50,  2.77it/s]Evaluating:  15%|█▌        | 25/163 [00:09<00:50,  2.71it/s]Evaluating:  16%|█▌        | 26/163 [00:09<00:49,  2.75it/s]Evaluating:  17%|█▋        | 27/163 [00:10<00:49,  2.77it/s]Evaluating:  17%|█▋        | 28/163 [00:10<00:49,  2.74it/s]Evaluating:  18%|█▊        | 29/163 [00:11<00:49,  2.73it/s]Evaluating:  18%|█▊        | 30/163 [00:11<00:51,  2.59it/s]Evaluating:  19%|█▉        | 31/163 [00:11<00:50,  2.64it/s]Evaluating:  20%|█▉        | 32/163 [00:12<00:48,  2.70it/s]Evaluating:  20%|██        | 33/163 [00:12<00:47,  2.73it/s]Evaluating:  21%|██        | 34/163 [00:12<00:46,  2.76it/s]Evaluating:  21%|██▏       | 35/163 [00:13<00:46,  2.78it/s]Evaluating:  22%|██▏       | 36/163 [00:13<00:45,  2.79it/s]Evaluating:  23%|██▎       | 37/163 [00:14<00:45,  2.77it/s]Evaluating:  23%|██▎       | 38/163 [00:14<00:45,  2.74it/s]Evaluating:  24%|██▍       | 39/163 [00:14<00:45,  2.74it/s]Evaluating:  25%|██▍       | 40/163 [00:15<00:45,  2.71it/s]Evaluating:  25%|██▌       | 41/163 [00:15<00:45,  2.69it/s]Evaluating:  26%|██▌       | 42/163 [00:15<00:44,  2.70it/s]Evaluating:  26%|██▋       | 43/163 [00:16<00:45,  2.61it/s]Evaluating:  27%|██▋       | 44/163 [00:16<00:44,  2.65it/s]Evaluating:  28%|██▊       | 45/163 [00:17<00:43,  2.69it/s]Evaluating:  28%|██▊       | 46/163 [00:17<00:42,  2.72it/s]Evaluating:  29%|██▉       | 47/163 [00:17<00:42,  2.75it/s]Evaluating:  29%|██▉       | 48/163 [00:18<00:41,  2.77it/s]Evaluating:  30%|███       | 49/163 [00:18<00:41,  2.78it/s]Evaluating:  31%|███       | 50/163 [00:18<00:40,  2.79it/s]Evaluating:  31%|███▏      | 51/163 [00:19<00:39,  2.80it/s]Evaluating:  32%|███▏      | 52/163 [00:19<00:39,  2.80it/s]Evaluating:  33%|███▎      | 53/163 [00:19<00:39,  2.79it/s]Evaluating:  33%|███▎      | 54/163 [00:20<00:39,  2.78it/s]Evaluating:  34%|███▎      | 55/163 [00:20<00:38,  2.77it/s]Evaluating:  34%|███▍      | 56/163 [00:20<00:38,  2.78it/s]Evaluating:  35%|███▍      | 57/163 [00:21<00:38,  2.76it/s]Evaluating:  36%|███▌      | 58/163 [00:21<00:37,  2.76it/s]Evaluating:  36%|███▌      | 59/163 [00:22<00:37,  2.77it/s]Evaluating:  37%|███▋      | 60/163 [00:22<00:37,  2.76it/s]Evaluating:  37%|███▋      | 61/163 [00:22<00:37,  2.76it/s]Evaluating:  38%|███▊      | 62/163 [00:23<00:36,  2.76it/s]Evaluating:  39%|███▊      | 63/163 [00:23<00:36,  2.75it/s]Evaluating:  39%|███▉      | 64/163 [00:23<00:35,  2.76it/s]Evaluating:  40%|███▉      | 65/163 [00:24<00:35,  2.77it/s]Evaluating:  40%|████      | 66/163 [00:24<00:35,  2.77it/s]Evaluating:  41%|████      | 67/163 [00:24<00:34,  2.78it/s]Evaluating:  42%|████▏     | 68/163 [00:25<00:34,  2.78it/s]Evaluating:  42%|████▏     | 69/163 [00:25<00:33,  2.78it/s]Evaluating:  43%|████▎     | 70/163 [00:25<00:33,  2.78it/s]Evaluating:  44%|████▎     | 71/163 [00:26<00:33,  2.78it/s]Evaluating:  44%|████▍     | 72/163 [00:26<00:32,  2.77it/s]Evaluating:  45%|████▍     | 73/163 [00:27<00:32,  2.78it/s]Evaluating:  45%|████▌     | 74/163 [00:27<00:32,  2.78it/s]Evaluating:  46%|████▌     | 75/163 [00:27<00:31,  2.78it/s]Evaluating:  47%|████▋     | 76/163 [00:28<00:31,  2.79it/s]Evaluating:  47%|████▋     | 77/163 [00:28<00:30,  2.79it/s]Evaluating:  48%|████▊     | 78/163 [00:28<00:30,  2.78it/s]Evaluating:  48%|████▊     | 79/163 [00:29<00:30,  2.78it/s]Evaluating:  49%|████▉     | 80/163 [00:29<00:29,  2.78it/s]Evaluating:  50%|████▉     | 81/163 [00:29<00:29,  2.78it/s]Evaluating:  50%|█████     | 82/163 [00:30<00:29,  2.79it/s]Evaluating:  51%|█████     | 83/163 [00:30<00:28,  2.80it/s]Evaluating:  52%|█████▏    | 84/163 [00:31<00:28,  2.78it/s]Evaluating:  52%|█████▏    | 85/163 [00:31<00:27,  2.79it/s]Evaluating:  53%|█████▎    | 86/163 [00:31<00:27,  2.80it/s]Evaluating:  53%|█████▎    | 87/163 [00:32<00:27,  2.80it/s]Evaluating:  54%|█████▍    | 88/163 [00:32<00:27,  2.76it/s]Evaluating:  55%|█████▍    | 89/163 [00:32<00:27,  2.67it/s]Evaluating:  55%|█████▌    | 90/163 [00:33<00:27,  2.70it/s]Evaluating:  56%|█████▌    | 91/163 [00:33<00:26,  2.72it/s]Evaluating:  56%|█████▋    | 92/163 [00:33<00:25,  2.75it/s]Evaluating:  57%|█████▋    | 93/163 [00:34<00:26,  2.66it/s]Evaluating:  58%|█████▊    | 94/163 [00:34<00:26,  2.65it/s]Evaluating:  58%|█████▊    | 95/163 [00:35<00:26,  2.54it/s]Evaluating:  59%|█████▉    | 96/163 [00:35<00:26,  2.57it/s]Evaluating:  60%|█████▉    | 97/163 [00:35<00:26,  2.47it/s]Evaluating:  60%|██████    | 98/163 [00:36<00:26,  2.44it/s]Evaluating:  61%|██████    | 99/163 [00:36<00:25,  2.46it/s]Evaluating:  61%|██████▏   | 100/163 [00:37<00:25,  2.51it/s]Evaluating:  62%|██████▏   | 101/163 [00:37<00:24,  2.51it/s]Evaluating:  63%|██████▎   | 102/163 [00:37<00:23,  2.59it/s]Evaluating:  63%|██████▎   | 103/163 [00:38<00:23,  2.59it/s]Evaluating:  64%|██████▍   | 104/163 [00:38<00:22,  2.65it/s]Evaluating:  64%|██████▍   | 105/163 [00:39<00:21,  2.69it/s]Evaluating:  65%|██████▌   | 106/163 [00:39<00:20,  2.72it/s]Evaluating:  66%|██████▌   | 107/163 [00:39<00:20,  2.75it/s]Evaluating:  66%|██████▋   | 108/163 [00:40<00:19,  2.77it/s]Evaluating:  67%|██████▋   | 109/163 [00:40<00:19,  2.78it/s]Evaluating:  67%|██████▋   | 110/163 [00:40<00:19,  2.79it/s]Evaluating:  68%|██████▊   | 111/163 [00:41<00:18,  2.79it/s]Evaluating:  69%|██████▊   | 112/163 [00:41<00:18,  2.79it/s]Evaluating:  69%|██████▉   | 113/163 [00:41<00:17,  2.79it/s]Evaluating:  70%|██████▉   | 114/163 [00:42<00:17,  2.79it/s]Evaluating:  71%|███████   | 115/163 [00:42<00:17,  2.79it/s]Evaluating:  71%|███████   | 116/163 [00:42<00:16,  2.79it/s]Evaluating:  72%|███████▏  | 117/163 [00:43<00:16,  2.78it/s]Evaluating:  72%|███████▏  | 118/163 [00:43<00:16,  2.78it/s]Evaluating:  73%|███████▎  | 119/163 [00:44<00:15,  2.77it/s]Evaluating:  74%|███████▎  | 120/163 [00:44<00:15,  2.78it/s]Evaluating:  74%|███████▍  | 121/163 [00:44<00:15,  2.78it/s]Evaluating:  75%|███████▍  | 122/163 [00:45<00:14,  2.78it/s]Evaluating:  75%|███████▌  | 123/163 [00:45<00:14,  2.78it/s]Evaluating:  76%|███████▌  | 124/163 [00:45<00:13,  2.79it/s]Evaluating:  77%|███████▋  | 125/163 [00:46<00:13,  2.79it/s]Evaluating:  77%|███████▋  | 126/163 [00:46<00:13,  2.78it/s]Evaluating:  78%|███████▊  | 127/163 [00:46<00:12,  2.78it/s]Evaluating:  79%|███████▊  | 128/163 [00:47<00:12,  2.79it/s]Evaluating:  79%|███████▉  | 129/163 [00:47<00:12,  2.78it/s]Evaluating:  80%|███████▉  | 130/163 [00:48<00:11,  2.76it/s]Evaluating:  80%|████████  | 131/163 [00:48<00:11,  2.76it/s]Evaluating:  81%|████████  | 132/163 [00:48<00:11,  2.76it/s]Evaluating:  82%|████████▏ | 133/163 [00:49<00:10,  2.76it/s]Evaluating:  82%|████████▏ | 134/163 [00:49<00:10,  2.74it/s]Evaluating:  83%|████████▎ | 135/163 [00:49<00:10,  2.75it/s]Evaluating:  83%|████████▎ | 136/163 [00:50<00:09,  2.75it/s]Evaluating:  84%|████████▍ | 137/163 [00:50<00:09,  2.76it/s]Evaluating:  85%|████████▍ | 138/163 [00:50<00:09,  2.77it/s]Evaluating:  85%|████████▌ | 139/163 [00:51<00:08,  2.78it/s]Evaluating:  86%|████████▌ | 140/163 [00:51<00:08,  2.78it/s]Evaluating:  87%|████████▋ | 141/163 [00:51<00:07,  2.79it/s]Evaluating:  87%|████████▋ | 142/163 [00:52<00:07,  2.78it/s]Evaluating:  88%|████████▊ | 143/163 [00:52<00:07,  2.78it/s]Evaluating:  88%|████████▊ | 144/163 [00:53<00:06,  2.78it/s]Evaluating:  89%|████████▉ | 145/163 [00:53<00:06,  2.77it/s]Evaluating:  90%|████████▉ | 146/163 [00:53<00:06,  2.78it/s]Evaluating:  90%|█████████ | 147/163 [00:54<00:05,  2.78it/s]Evaluating:  91%|█████████ | 148/163 [00:54<00:05,  2.79it/s]Evaluating:  91%|█████████▏| 149/163 [00:54<00:05,  2.78it/s]Evaluating:  92%|█████████▏| 150/163 [00:55<00:04,  2.78it/s]Evaluating:  93%|█████████▎| 151/163 [00:55<00:04,  2.78it/s]Evaluating:  93%|█████████▎| 152/163 [00:55<00:03,  2.76it/s]Evaluating:  94%|█████████▍| 153/163 [00:56<00:03,  2.77it/s]Evaluating:  94%|█████████▍| 154/163 [00:56<00:03,  2.75it/s]Evaluating:  95%|█████████▌| 155/163 [00:57<00:02,  2.72it/s]Evaluating:  96%|█████████▌| 156/163 [00:57<00:02,  2.73it/s]Evaluating:  96%|█████████▋| 157/163 [00:57<00:02,  2.75it/s]Evaluating:  97%|█████████▋| 158/163 [00:58<00:01,  2.74it/s]Evaluating:  98%|█████████▊| 159/163 [00:58<00:01,  2.70it/s]Evaluating:  98%|█████████▊| 160/163 [00:58<00:01,  2.56it/s]Evaluating:  99%|█████████▉| 161/163 [00:59<00:00,  2.40it/s]Evaluating:  99%|█████████▉| 162/163 [00:59<00:00,  2.41it/s]Evaluating: 100%|██████████| 163/163 [01:00<00:00,  2.45it/s]Evaluating: 100%|██████████| 163/163 [01:00<00:00,  2.71it/s]
05/09/2022 19:53:48 - INFO - __main__ -     Evaluation done in total 60.255845 secs (0.046208 sec per example)
05/09/2022 19:53:52 - INFO - __main__ -   Results: {'exact': 65.3781512605042, 'f1': 82.13148090094725, 'total': 1190, 'HasAns_exact': 65.3781512605042, 'HasAns_f1': 82.13148090094725, 'HasAns_total': 1190, 'best_exact': 65.3781512605042, 'best_exact_thresh': 0.0, 'best_f1': 82.13148090094725, 'best_f1_thresh': 0.0}
  de 
2022-05-09 19:53:59.365852: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0
05/09/2022 19:54:07 - WARNING - __main__ -   Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, 16-bits training: False
You are using a model of type xlm-roberta to instantiate a model of type xlm. This is not supported for all configurations of models and can yield errors.
Some weights of the model checkpoint at /cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//squad/xlm-KG_LR4e-5_EPOCH2.0_maxlen384_batchsize4_gradacc8 were not used when initializing XLMRobertaModel: ['base_model.encoder.layer.10.attention.self.key.bias', 'base_model.encoder.layer.20.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.8.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.10.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.18.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.20.output.LayerNorm.bias', 'base_model.encoder.layer.15.attention.self.query.weight', 'base_model.encoder.layer.15.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.22.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.7.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.7.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.0.output.LayerNorm.bias', 'base_model.encoder.layer.22.attention.self.query.weight', 'base_model.encoder.layer.14.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.12.attention.self.value.weight', 'base_model.encoder.layer.11.attention.output.dense.weight', 'base_model.encoder.layer.16.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.22.attention.self.key.bias', 'base_model.encoder.layer.16.attention.self.key.weight', 'base_model.encoder.layer.3.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.9.intermediate.dense.weight', 'base_model.encoder.layer.7.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.8.attention.output.dense.weight', 'base_model.encoder.layer.21.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.6.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.14.attention.output.LayerNorm.bias', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.10.attention.self.value.weight', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.3.output.LayerNorm.weight', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.19.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.2.intermediate.dense.weight', 'base_model.encoder.layer.9.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.12.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.8.attention.output.LayerNorm.weight', 'base_model.encoder.layer.11.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.14.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'qa_outputs.bias', 'base_model.encoder.layer.2.attention.output.dense.bias', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.11.attention.self.query.weight', 'base_model.encoder.layer.4.attention.self.query.weight', 'base_model.encoder.layer.13.output.LayerNorm.bias', 'base_model.encoder.layer.16.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.23.intermediate.dense.bias', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.16.attention.self.key.bias', 'base_model.encoder.layer.3.attention.self.query.bias', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.1.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.2.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.11.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.20.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.22.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.9.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.21.intermediate.dense.weight', 'base_model.encoder.layer.6.attention.self.key.bias', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.13.attention.self.key.weight', 'base_model.encoder.layer.16.attention.output.LayerNorm.bias', 'base_model.encoder.layer.5.output.dense.weight', 'base_model.encoder.layer.7.attention.self.key.bias', 'base_model.encoder.layer.7.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.23.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.4.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.7.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.20.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.2.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.0.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.7.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.10.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.18.intermediate.dense.bias', 'base_model.encoder.layer.9.attention.self.query.weight', 'base_model.encoder.layer.9.output.dense.bias', 'base_model.encoder.layer.21.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.11.attention.output.dense.bias', 'base_model.encoder.layer.16.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.0.output.dense.weight', 'base_model.encoder.layer.6.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.0.output.dense.bias', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.4.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.12.output.dense.bias', 'base_model.encoder.layer.14.attention.self.value.bias', 'base_model.encoder.layer.11.attention.output.LayerNorm.weight', 'base_model.encoder.layer.4.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.8.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.19.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.22.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.8.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.9.attention.self.key.weight', 'base_model.encoder.layer.10.attention.self.query.weight', 'base_model.encoder.layer.10.attention.output.dense.weight', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.3.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.16.intermediate.dense.bias', 'base_model.encoder.layer.3.attention.self.key.weight', 'base_model.encoder.layer.18.attention.output.LayerNorm.weight', 'base_model.encoder.layer.23.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.0.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.19.intermediate.dense.bias', 'base_model.encoder.layer.1.output.LayerNorm.weight', 'base_model.encoder.layer.2.attention.self.key.weight', 'base_model.encoder.layer.2.output.dense.weight', 'base_model.encoder.layer.8.attention.output.LayerNorm.bias', 'base_model.encoder.layer.9.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.13.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.5.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.19.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.21.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.14.attention.self.key.weight', 'base_model.encoder.layer.16.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.10.attention.self.query.bias', 'base_model.encoder.layer.3.attention.output.LayerNorm.bias', 'base_model.encoder.layer.2.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.10.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.15.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.22.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.17.attention.self.value.weight', 'base_model.encoder.layer.3.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.6.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.18.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.2.attention.self.query.weight', 'base_model.encoder.layer.1.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.20.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.15.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.20.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.3.attention.output.dense.bias', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.18.attention.self.key.bias', 'base_model.encoder.layer.4.output.LayerNorm.weight', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.5.output.LayerNorm.weight', 'base_model.encoder.layer.6.attention.output.dense.weight', 'base_model.encoder.layer.15.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.10.attention.self.key.weight', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.11.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.16.attention.output.dense.weight', 'base_model.encoder.layer.17.intermediate.dense.weight', 'base_model.encoder.layer.20.attention.self.value.bias', 'base_model.encoder.layer.18.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.9.attention.self.key.bias', 'base_model.encoder.layer.19.attention.self.key.weight', 'base_model.encoder.layer.15.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.20.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.22.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.15.attention.output.LayerNorm.weight', 'base_model.encoder.layer.6.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.18.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.5.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.9.output.adapters.es.adapter_down.0.bias', 'base_model.embeddings.token_type_embeddings.weight', 'base_model.encoder.layer.19.output.LayerNorm.bias', 'base_model.encoder.layer.23.attention.self.query.weight', 'base_model.encoder.layer.19.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.23.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.18.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.9.attention.self.value.weight', 'base_model.encoder.layer.2.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.9.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.5.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.15.attention.self.key.weight', 'base_model.encoder.layer.10.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.2.attention.output.LayerNorm.weight', 'base_model.encoder.layer.9.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.10.output.dense.weight', 'base_model.encoder.layer.23.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.1.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.3.output.dense.weight', 'base_model.encoder.layer.6.output.dense.weight', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.15.output.LayerNorm.weight', 'base_model.encoder.layer.18.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.4.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.14.attention.self.query.bias', 'base_model.encoder.layer.16.intermediate.dense.weight', 'base_model.encoder.layer.19.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.6.attention.self.query.weight', 'base_model.encoder.layer.19.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.13.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.21.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.11.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.11.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.1.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.12.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.17.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.22.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.13.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.21.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.3.output.adapters.ts.adapter_down.0.weight', 'base_model.pooler.dense.bias', 'base_model.encoder.layer.2.attention.output.dense.weight', 'base_model.encoder.layer.6.attention.self.value.weight', 'base_model.encoder.layer.19.attention.self.key.bias', 'base_model.encoder.layer.12.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.15.attention.self.query.bias', 'base_model.encoder.layer.22.attention.self.query.bias', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.18.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.5.output.LayerNorm.bias', 'base_model.encoder.layer.1.attention.self.query.bias', 'base_model.encoder.layer.5.intermediate.dense.bias', 'base_model.encoder.layer.13.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.21.attention.output.LayerNorm.bias', 'base_model.encoder.layer.6.intermediate.dense.weight', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.22.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.0.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.6.attention.self.value.bias', 'base_model.encoder.layer.12.output.LayerNorm.weight', 'base_model.encoder.layer.3.attention.self.key.bias', 'base_model.encoder.layer.22.attention.output.dense.bias', 'base_model.encoder.layer.14.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.2.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.23.attention.self.value.bias', 'base_model.encoder.layer.14.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.4.intermediate.dense.bias', 'base_model.encoder.layer.13.intermediate.dense.bias', 'base_model.encoder.layer.23.attention.output.LayerNorm.bias', 'base_model.encoder.layer.2.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.7.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.8.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.8.output.LayerNorm.bias', 'base_model.encoder.layer.4.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.18.attention.self.key.weight', 'base_model.encoder.layer.20.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.1.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.2.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.23.attention.output.dense.bias', 'base_model.encoder.layer.0.attention.output.dense.bias', 'base_model.encoder.layer.12.attention.self.key.weight', 'base_model.encoder.layer.17.attention.self.value.bias', 'base_model.encoder.layer.20.intermediate.dense.weight', 'base_model.encoder.layer.2.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.3.intermediate.dense.bias', 'base_model.encoder.layer.5.attention.output.LayerNorm.weight', 'base_model.encoder.layer.16.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.9.attention.output.dense.weight', 'base_model.encoder.layer.1.attention.self.query.weight', 'base_model.encoder.layer.0.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.15.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.21.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.11.intermediate.dense.bias', 'base_model.encoder.layer.16.output.LayerNorm.bias', 'base_model.encoder.layer.8.attention.self.query.bias', 'base_model.encoder.layer.8.attention.self.query.weight', 'base_model.encoder.layer.17.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.20.attention.output.LayerNorm.bias', 'base_model.encoder.layer.23.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.20.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.8.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.11.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.5.attention.output.dense.weight', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.17.attention.output.LayerNorm.weight', 'base_model.encoder.layer.1.intermediate.dense.weight', 'base_model.encoder.layer.19.attention.output.LayerNorm.bias', 'base_model.encoder.layer.21.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.16.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.20.attention.output.dense.bias', 'base_model.encoder.layer.2.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.4.attention.self.key.bias', 'base_model.encoder.layer.15.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.4.attention.self.value.weight', 'base_model.encoder.layer.17.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.22.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.11.attention.output.LayerNorm.bias', 'base_model.encoder.layer.7.output.LayerNorm.bias', 'base_model.encoder.layer.17.attention.self.query.bias', 'base_model.encoder.layer.13.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.21.attention.self.key.bias', 'base_model.encoder.layer.7.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.7.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.10.intermediate.dense.weight', 'base_model.encoder.layer.3.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.0.output.adapters.tp.adapter_down.0.bias', 'base_model.embeddings.LayerNorm.bias', 'base_model.encoder.layer.17.attention.output.LayerNorm.bias', 'base_model.encoder.layer.13.attention.output.dense.weight', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.8.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.9.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.18.output.LayerNorm.bias', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.4.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.6.intermediate.dense.bias', 'base_model.encoder.layer.11.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.18.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.17.output.adapters.tp.adapter_down.0.bias', 'base_model.embeddings.position_embeddings.weight', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.19.intermediate.dense.weight', 'base_model.encoder.layer.10.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.3.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.9.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.21.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.15.attention.output.LayerNorm.bias', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.13.attention.output.dense.bias', 'base_model.pooler.dense.weight', 'base_model.encoder.layer.23.output.dense.bias', 'base_model.encoder.layer.6.attention.self.query.bias', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.9.output.LayerNorm.bias', 'base_model.encoder.layer.13.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.14.intermediate.dense.weight', 'base_model.encoder.layer.5.attention.self.value.bias', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.23.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.15.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.4.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.8.intermediate.dense.bias', 'base_model.encoder.layer.9.attention.self.query.bias', 'base_model.encoder.layer.13.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.3.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.12.output.dense.weight', 'base_model.encoder.layer.10.attention.output.LayerNorm.bias', 'base_model.encoder.layer.16.attention.output.LayerNorm.weight', 'base_model.encoder.layer.23.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.10.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.19.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.5.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.22.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.22.attention.output.LayerNorm.bias', 'base_model.encoder.layer.14.output.dense.weight', 'base_model.encoder.layer.4.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.9.output.dense.weight', 'base_model.encoder.layer.16.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.5.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.11.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.14.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.0.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.10.output.LayerNorm.bias', 'base_model.encoder.layer.13.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.22.attention.output.LayerNorm.weight', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.19.attention.output.dense.weight', 'base_model.encoder.layer.2.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.14.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.8.output.dense.weight', 'base_model.encoder.layer.8.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.15.attention.self.key.bias', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.23.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.0.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.11.attention.self.key.bias', 'base_model.encoder.layer.1.attention.output.dense.bias', 'base_model.encoder.layer.4.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.21.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.13.intermediate.dense.weight', 'base_model.encoder.layer.0.output.LayerNorm.weight', 'base_model.encoder.layer.18.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.19.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.13.attention.output.LayerNorm.weight', 'base_model.encoder.layer.16.attention.self.query.weight', 'base_model.encoder.layer.16.output.LayerNorm.weight', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.3.attention.self.value.bias', 'base_model.encoder.layer.6.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.8.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.0.intermediate.dense.weight', 'base_model.encoder.layer.10.intermediate.dense.bias', 'base_model.encoder.layer.4.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.18.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.17.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.20.attention.self.query.bias', 'base_model.encoder.layer.1.output.dense.weight', 'base_model.encoder.layer.0.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.1.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.13.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.23.output.LayerNorm.weight', 'base_model.encoder.layer.14.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.14.attention.self.value.weight', 'base_model.encoder.layer.23.attention.output.dense.weight', 'base_model.encoder.layer.15.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.5.attention.output.dense.bias', 'base_model.encoder.layer.20.output.LayerNorm.weight', 'base_model.encoder.layer.23.intermediate.dense.weight', 'qa_outputs.weight', 'base_model.encoder.layer.2.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.7.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.23.attention.self.key.weight', 'base_model.encoder.layer.0.attention.self.value.weight', 'base_model.encoder.layer.13.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.9.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.12.intermediate.dense.weight', 'base_model.encoder.layer.12.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.23.attention.self.query.bias', 'base_model.encoder.layer.9.output.LayerNorm.weight', 'base_model.encoder.layer.5.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.12.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.17.intermediate.dense.bias', 'base_model.encoder.layer.22.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.7.intermediate.dense.bias', 'base_model.encoder.layer.12.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.22.intermediate.dense.weight', 'base_model.encoder.layer.13.output.dense.bias', 'base_model.encoder.layer.13.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.0.attention.output.LayerNorm.bias', 'base_model.encoder.layer.23.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.4.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.18.output.dense.bias', 'base_model.encoder.layer.10.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.10.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.2.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.3.output.dense.bias', 'base_model.encoder.layer.13.attention.output.LayerNorm.bias', 'base_model.encoder.layer.6.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.12.attention.output.dense.weight', 'base_model.encoder.layer.4.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.6.output.dense.bias', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.22.attention.self.value.weight', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.19.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.4.attention.output.dense.weight', 'base_model.encoder.layer.17.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.1.attention.output.LayerNorm.weight', 'base_model.encoder.layer.16.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.1.attention.self.value.weight', 'base_model.encoder.layer.4.intermediate.dense.weight', 'base_model.encoder.layer.17.attention.self.key.bias', 'base_model.encoder.layer.10.attention.output.dense.bias', 'base_model.encoder.layer.12.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.15.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.22.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.17.output.dense.bias', 'base_model.encoder.layer.19.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.21.output.dense.bias', 'base_model.encoder.layer.18.attention.self.value.weight', 'base_model.encoder.layer.0.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.15.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.16.attention.self.value.bias', 'base_model.encoder.layer.22.attention.self.key.weight', 'base_model.encoder.layer.17.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.18.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.19.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.8.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.11.attention.self.query.bias', 'base_model.encoder.layer.19.attention.output.dense.bias', 'base_model.encoder.layer.1.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.15.output.dense.weight', 'base_model.encoder.layer.17.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.14.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.20.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.7.output.dense.bias', 'base_model.encoder.layer.11.output.dense.bias', 'base_model.encoder.layer.22.attention.self.value.bias', 'base_model.encoder.layer.9.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.9.attention.output.dense.bias', 'base_model.encoder.layer.7.output.dense.weight', 'base_model.encoder.layer.15.intermediate.dense.weight', 'base_model.encoder.layer.20.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.21.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.23.attention.self.key.bias', 'base_model.encoder.layer.14.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.16.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.9.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.3.intermediate.dense.weight', 'base_model.encoder.layer.6.attention.output.LayerNorm.bias', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.11.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.16.attention.self.value.weight', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.16.attention.self.query.bias', 'base_model.encoder.layer.21.attention.self.value.bias', 'base_model.encoder.layer.2.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.6.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.9.attention.output.LayerNorm.weight', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.1.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.13.output.dense.weight', 'base_model.embeddings.LayerNorm.weight', 'base_model.encoder.layer.5.attention.self.value.weight', 'base_model.encoder.layer.20.attention.output.dense.weight', 'base_model.encoder.layer.20.output.dense.weight', 'base_model.encoder.layer.15.output.dense.bias', 'base_model.encoder.layer.12.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.22.output.dense.weight', 'base_model.encoder.layer.22.attention.output.dense.weight', 'base_model.encoder.layer.16.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.7.attention.self.query.weight', 'base_model.encoder.layer.17.attention.output.dense.weight', 'base_model.encoder.layer.7.attention.self.query.bias', 'base_model.encoder.layer.2.intermediate.dense.bias', 'base_model.encoder.layer.22.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.0.attention.self.query.bias', 'base_model.encoder.layer.8.attention.output.dense.bias', 'base_model.encoder.layer.4.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.3.attention.self.query.weight', 'base_model.encoder.layer.3.attention.self.value.weight', 'base_model.encoder.layer.13.attention.self.key.bias', 'base_model.encoder.layer.3.output.LayerNorm.bias', 'base_model.encoder.layer.12.attention.self.query.bias', 'base_model.encoder.layer.11.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.11.intermediate.dense.weight', 'base_model.encoder.layer.12.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.18.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.18.attention.output.dense.bias', 'base_model.encoder.layer.5.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.0.attention.self.value.bias', 'base_model.encoder.layer.21.attention.self.query.weight', 'base_model.encoder.layer.18.intermediate.dense.weight', 'base_model.encoder.layer.14.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.17.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.0.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.8.attention.self.key.weight', 'base_model.encoder.layer.16.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.0.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.18.attention.self.query.bias', 'base_model.encoder.layer.21.attention.self.value.weight', 'base_model.encoder.layer.21.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.16.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.23.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.0.attention.self.query.weight', 'base_model.encoder.layer.7.attention.self.value.bias', 'base_model.encoder.layer.0.intermediate.dense.bias', 'base_model.encoder.layer.5.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.19.output.dense.bias', 'base_model.encoder.layer.23.output.LayerNorm.bias', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.5.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.11.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.14.intermediate.dense.bias', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.11.output.LayerNorm.bias', 'base_model.encoder.layer.22.output.LayerNorm.weight', 'base_model.encoder.layer.12.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.6.attention.output.dense.bias', 'base_model.encoder.layer.10.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.1.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.8.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.6.attention.self.key.weight', 'base_model.encoder.layer.17.attention.self.key.weight', 'base_model.encoder.layer.23.attention.self.value.weight', 'base_model.encoder.layer.4.attention.output.LayerNorm.weight', 'base_model.encoder.layer.6.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.23.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.8.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.2.attention.output.LayerNorm.bias', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.21.attention.self.key.weight', 'base_model.encoder.layer.21.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.8.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.9.intermediate.dense.bias', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.12.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.17.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.15.attention.output.dense.weight', 'base_model.encoder.layer.1.attention.self.value.bias', 'base_model.encoder.layer.1.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.22.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.2.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.20.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.1.attention.self.key.weight', 'base_model.encoder.layer.5.attention.self.key.bias', 'base_model.encoder.layer.1.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.6.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.18.attention.output.dense.weight', 'base_model.encoder.layer.8.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.4.attention.self.key.weight', 'base_model.encoder.layer.6.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.5.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.5.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.15.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.15.attention.self.value.bias', 'base_model.encoder.layer.3.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.0.attention.output.dense.weight', 'base_model.encoder.layer.15.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.21.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.9.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.4.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.10.output.dense.bias', 'base_model.encoder.layer.10.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.13.attention.self.query.bias', 'base_model.encoder.layer.13.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.16.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.21.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.5.attention.self.query.weight', 'base_model.encoder.layer.8.output.dense.bias', 'base_model.encoder.layer.20.output.dense.bias', 'base_model.encoder.layer.12.output.LayerNorm.bias', 'base_model.encoder.layer.4.attention.self.query.bias', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.19.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.16.output.dense.weight', 'base_model.encoder.layer.5.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.13.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.4.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.5.attention.self.query.bias', 'base_model.encoder.layer.9.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.11.attention.self.value.weight', 'base_model.encoder.layer.20.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.11.attention.self.key.weight', 'base_model.encoder.layer.14.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.7.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.18.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.1.attention.self.key.bias', 'base_model.encoder.layer.11.attention.self.value.bias', 'base_model.encoder.layer.1.attention.output.dense.weight', 'base_model.encoder.layer.6.attention.output.LayerNorm.weight', 'base_model.encoder.layer.14.output.LayerNorm.weight', 'base_model.encoder.layer.20.attention.self.query.weight', 'base_model.encoder.layer.21.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.8.attention.self.value.bias', 'base_model.encoder.layer.13.attention.self.value.weight', 'base_model.encoder.layer.3.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.14.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.7.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.7.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.6.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.1.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.10.attention.self.value.bias', 'base_model.encoder.layer.17.attention.output.dense.bias', 'base_model.encoder.layer.22.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.14.attention.output.LayerNorm.weight', 'base_model.encoder.layer.21.attention.output.dense.bias', 'base_model.encoder.layer.21.output.LayerNorm.weight', 'base_model.encoder.layer.18.attention.self.value.bias', 'base_model.encoder.layer.3.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.1.output.dense.bias', 'base_model.encoder.layer.10.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.14.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.17.attention.self.query.weight', 'base_model.encoder.layer.9.attention.self.value.bias', 'base_model.encoder.layer.12.attention.output.LayerNorm.bias', 'base_model.encoder.layer.15.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.9.attention.output.LayerNorm.bias', 'base_model.encoder.layer.2.output.LayerNorm.weight', 'base_model.encoder.layer.7.attention.self.value.weight', 'base_model.encoder.layer.19.attention.self.value.bias', 'base_model.encoder.layer.6.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.16.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.17.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.21.attention.self.query.bias', 'base_model.encoder.layer.18.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.21.intermediate.dense.bias', 'base_model.encoder.layer.17.output.LayerNorm.weight', 'base_model.encoder.layer.1.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.0.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.13.attention.self.value.bias', 'base_model.encoder.layer.19.attention.output.LayerNorm.weight', 'base_model.encoder.layer.3.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.8.intermediate.dense.weight', 'base_model.encoder.layer.5.attention.self.key.weight', 'base_model.encoder.layer.23.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.14.attention.self.key.bias', 'base_model.encoder.layer.8.attention.self.value.weight', 'base_model.encoder.layer.0.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.23.attention.output.LayerNorm.weight', 'base_model.encoder.layer.11.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.23.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.3.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.6.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.3.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.19.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.9.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.12.intermediate.dense.bias', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.5.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.0.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.21.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.16.attention.output.dense.bias', 'base_model.encoder.layer.4.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.17.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.18.output.dense.weight', 'base_model.encoder.layer.8.attention.self.key.bias', 'base_model.encoder.layer.12.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.10.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.14.output.dense.bias', 'base_model.encoder.layer.10.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.16.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.20.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.17.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.22.output.adapters.es.adapter_down.0.weight', 'base_model.embeddings.position_ids', 'base_model.encoder.layer.4.output.dense.weight', 'base_model.encoder.layer.16.output.dense.bias', 'base_model.encoder.layer.13.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.16.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.5.intermediate.dense.weight', 'base_model.encoder.layer.5.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.1.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.5.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.0.attention.output.LayerNorm.weight', 'base_model.encoder.layer.3.attention.output.dense.weight', 'base_model.encoder.layer.2.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.2.output.LayerNorm.bias', 'base_model.encoder.layer.8.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.8.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.6.output.LayerNorm.weight', 'base_model.encoder.layer.13.attention.self.query.weight', 'base_model.encoder.layer.14.attention.output.dense.weight', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.3.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.12.attention.output.LayerNorm.weight', 'base_model.encoder.layer.15.intermediate.dense.bias', 'base_model.encoder.layer.12.attention.self.value.bias', 'base_model.encoder.layer.20.intermediate.dense.bias', 'base_model.encoder.layer.22.output.dense.bias', 'base_model.encoder.layer.20.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.1.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.7.attention.self.key.weight', 'base_model.encoder.layer.11.output.LayerNorm.weight', 'base_model.encoder.layer.0.attention.self.key.bias', 'base_model.encoder.layer.20.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.19.output.dense.weight', 'base_model.encoder.layer.1.intermediate.dense.bias', 'base_model.encoder.layer.4.attention.self.value.bias', 'base_model.encoder.layer.12.attention.self.key.bias', 'base_model.encoder.layer.23.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.13.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.0.attention.self.key.weight', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.19.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.14.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.5.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.15.attention.output.dense.bias', 'base_model.encoder.layer.20.attention.self.key.weight', 'base_model.encoder.layer.23.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.21.attention.output.dense.weight', 'base_model.encoder.layer.9.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.7.output.LayerNorm.weight', 'base_model.encoder.layer.12.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.3.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.22.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.4.output.dense.bias', 'base_model.encoder.layer.12.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.20.attention.self.value.weight', 'base_model.encoder.layer.20.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.19.output.LayerNorm.weight', 'base_model.encoder.layer.7.attention.output.LayerNorm.weight', 'base_model.encoder.layer.15.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.7.attention.output.LayerNorm.bias', 'base_model.encoder.layer.7.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.14.output.LayerNorm.bias', 'base_model.encoder.layer.15.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.4.attention.output.LayerNorm.bias', 'base_model.encoder.layer.19.attention.self.query.weight', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.11.output.dense.weight', 'base_model.encoder.layer.11.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.14.attention.output.dense.bias', 'base_model.encoder.layer.7.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.6.output.LayerNorm.bias', 'base_model.encoder.layer.1.attention.output.LayerNorm.bias', 'base_model.encoder.layer.15.output.LayerNorm.bias', 'base_model.encoder.layer.6.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.19.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.7.intermediate.dense.weight', 'base_model.encoder.layer.21.attention.output.LayerNorm.weight', 'base_model.encoder.layer.23.output.dense.weight', 'base_model.encoder.layer.9.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.12.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.14.attention.self.query.weight', 'base_model.encoder.layer.1.output.LayerNorm.bias', 'base_model.encoder.layer.1.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.7.attention.output.dense.bias', 'base_model.encoder.layer.10.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.10.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.17.output.LayerNorm.bias', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.7.attention.output.dense.weight', 'base_model.encoder.layer.12.attention.output.dense.bias', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.11.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.18.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.18.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.10.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.21.output.LayerNorm.bias', 'base_model.encoder.layer.5.attention.output.LayerNorm.bias', 'base_model.encoder.layer.15.attention.self.value.weight', 'base_model.encoder.layer.19.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.4.attention.output.dense.bias', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.17.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.19.attention.self.query.bias', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.17.output.dense.weight', 'base_model.encoder.layer.4.output.LayerNorm.bias', 'base_model.encoder.layer.2.output.dense.bias', 'base_model.encoder.layer.14.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.0.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.21.output.dense.weight', 'base_model.encoder.layer.6.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.3.attention.output.LayerNorm.weight', 'base_model.encoder.layer.22.intermediate.dense.bias', 'base_model.encoder.layer.17.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.6.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.13.output.LayerNorm.weight', 'base_model.encoder.layer.19.attention.self.value.weight', 'base_model.encoder.layer.0.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.10.output.LayerNorm.weight', 'base_model.encoder.layer.23.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.2.attention.self.value.weight', 'base_model.encoder.layer.2.attention.self.query.bias', 'base_model.encoder.layer.5.output.dense.bias', 'base_model.encoder.layer.3.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.11.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.20.attention.output.LayerNorm.weight', 'base_model.encoder.layer.10.attention.output.LayerNorm.weight', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.2.attention.self.key.bias', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.2.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.7.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.2.attention.self.value.bias', 'base_model.encoder.layer.12.attention.self.query.weight', 'base_model.encoder.layer.12.output.adapters.ts.adapter_up.weight', 'base_model.embeddings.word_embeddings.weight', 'base_model.encoder.layer.17.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.13.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.22.output.LayerNorm.bias', 'base_model.encoder.layer.8.output.LayerNorm.weight', 'base_model.encoder.layer.18.attention.self.query.weight', 'base_model.encoder.layer.8.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.14.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.18.output.LayerNorm.weight', 'base_model.encoder.layer.20.attention.self.key.bias', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.18.attention.output.LayerNorm.bias', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.11.output.adapters.es.adapter_up.weight']
- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of XLMRobertaModel were not initialized from the model checkpoint at /cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//squad/xlm-KG_LR4e-5_EPOCH2.0_maxlen384_batchsize4_gradacc8 and are newly initialized: ['encoder.layer.15.attention.self.value.bias', 'encoder.layer.11.output.LayerNorm.weight', 'encoder.layer.17.output.dense.weight', 'encoder.layer.15.attention.output.dense.bias', 'encoder.layer.1.attention.self.query.weight', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.7.intermediate.dense.bias', 'encoder.layer.22.attention.self.value.weight', 'encoder.layer.18.output.dense.bias', 'encoder.layer.7.output.dense.weight', 'encoder.layer.7.attention.self.query.bias', 'encoder.layer.15.attention.self.key.bias', 'encoder.layer.12.attention.self.query.weight', 'encoder.layer.16.output.LayerNorm.bias', 'encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.layer.17.output.LayerNorm.weight', 'encoder.layer.16.attention.self.query.weight', 'encoder.layer.16.attention.self.key.weight', 'encoder.layer.10.output.dense.bias', 'encoder.layer.2.output.dense.weight', 'encoder.layer.16.attention.self.value.bias', 'encoder.layer.16.attention.self.value.weight', 'encoder.layer.18.attention.self.value.bias', 'encoder.layer.21.output.LayerNorm.bias', 'encoder.layer.20.intermediate.dense.weight', 'encoder.layer.15.output.LayerNorm.bias', 'encoder.layer.8.attention.self.value.bias', 'encoder.layer.15.attention.self.query.bias', 'embeddings.LayerNorm.weight', 'encoder.layer.12.output.dense.bias', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.19.intermediate.dense.weight', 'encoder.layer.15.intermediate.dense.weight', 'encoder.layer.10.intermediate.dense.weight', 'encoder.layer.5.attention.self.value.bias', 'embeddings.word_embeddings.weight', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.21.output.LayerNorm.weight', 'encoder.layer.19.attention.self.key.bias', 'encoder.layer.23.output.dense.bias', 'encoder.layer.6.attention.self.value.weight', 'encoder.layer.23.attention.output.LayerNorm.bias', 'encoder.layer.16.attention.output.dense.weight', 'encoder.layer.14.intermediate.dense.weight', 'encoder.layer.13.attention.self.query.bias', 'encoder.layer.22.attention.output.dense.weight', 'encoder.layer.19.attention.output.LayerNorm.weight', 'encoder.layer.8.output.dense.weight', 'encoder.layer.4.attention.output.LayerNorm.weight', 'encoder.layer.18.intermediate.dense.bias', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.2.attention.output.dense.bias', 'encoder.layer.4.output.dense.bias', 'encoder.layer.23.intermediate.dense.bias', 'encoder.layer.11.attention.self.query.weight', 'encoder.layer.22.attention.self.key.bias', 'encoder.layer.22.output.dense.bias', 'encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.13.output.LayerNorm.weight', 'encoder.layer.7.attention.self.key.bias', 'encoder.layer.19.intermediate.dense.bias', 'encoder.layer.7.attention.output.LayerNorm.weight', 'encoder.layer.6.attention.self.value.bias', 'encoder.layer.2.attention.self.value.weight', 'encoder.layer.4.output.dense.weight', 'encoder.layer.18.output.LayerNorm.weight', 'encoder.layer.20.attention.output.dense.bias', 'encoder.layer.22.output.LayerNorm.weight', 'encoder.layer.6.attention.self.query.weight', 'encoder.layer.12.attention.output.dense.weight', 'encoder.layer.12.output.dense.weight', 'encoder.layer.12.output.LayerNorm.bias', 'encoder.layer.20.attention.output.dense.weight', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.19.attention.self.value.bias', 'encoder.layer.5.attention.self.value.weight', 'encoder.layer.2.output.dense.bias', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.layer.22.attention.output.LayerNorm.bias', 'encoder.layer.9.attention.self.query.bias', 'encoder.layer.4.attention.self.query.bias', 'encoder.layer.19.attention.output.LayerNorm.bias', 'encoder.layer.8.output.LayerNorm.bias', 'encoder.layer.12.intermediate.dense.bias', 'encoder.layer.13.attention.self.value.bias', 'encoder.layer.6.output.dense.bias', 'encoder.layer.18.output.dense.weight', 'encoder.layer.20.attention.output.LayerNorm.weight', 'encoder.layer.20.intermediate.dense.bias', 'encoder.layer.14.attention.output.LayerNorm.weight', 'encoder.layer.1.output.dense.bias', 'encoder.layer.1.attention.self.key.weight', 'pooler.dense.weight', 'encoder.layer.5.attention.self.query.weight', 'encoder.layer.21.attention.output.dense.bias', 'encoder.layer.10.attention.self.query.weight', 'encoder.layer.2.attention.self.key.weight', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.13.attention.self.value.weight', 'encoder.layer.1.output.dense.weight', 'encoder.layer.17.output.LayerNorm.bias', 'encoder.layer.13.attention.output.dense.bias', 'encoder.layer.17.attention.output.dense.weight', 'encoder.layer.5.output.dense.weight', 'encoder.layer.11.attention.self.key.weight', 'encoder.layer.20.output.LayerNorm.weight', 'encoder.layer.4.attention.self.value.bias', 'encoder.layer.19.output.LayerNorm.bias', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.4.attention.self.key.bias', 'encoder.layer.0.attention.self.query.bias', 'encoder.layer.10.attention.self.query.bias', 'encoder.layer.21.attention.output.LayerNorm.bias', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.15.attention.self.query.weight', 'encoder.layer.8.output.dense.bias', 'encoder.layer.0.attention.self.key.weight', 'encoder.layer.0.attention.self.value.weight', 'encoder.layer.5.attention.self.key.weight', 'encoder.layer.18.attention.self.key.weight', 'encoder.layer.7.attention.output.dense.bias', 'encoder.layer.9.attention.output.LayerNorm.bias', 'encoder.layer.10.attention.output.dense.weight', 'encoder.layer.15.output.dense.bias', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.11.output.dense.weight', 'encoder.layer.12.intermediate.dense.weight', 'encoder.layer.18.attention.output.dense.bias', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.23.intermediate.dense.weight', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.0.attention.output.dense.weight', 'encoder.layer.6.attention.output.LayerNorm.weight', 'encoder.layer.9.output.LayerNorm.weight', 'encoder.layer.15.output.dense.weight', 'encoder.layer.22.attention.output.dense.bias', 'encoder.layer.18.attention.self.key.bias', 'encoder.layer.12.attention.self.query.bias', 'encoder.layer.7.attention.output.dense.weight', 'encoder.layer.5.attention.output.dense.weight', 'encoder.layer.9.attention.self.query.weight', 'encoder.layer.11.attention.self.value.bias', 'encoder.layer.23.attention.self.key.weight', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.11.attention.output.dense.weight', 'embeddings.LayerNorm.bias', 'encoder.layer.11.output.LayerNorm.bias', 'encoder.layer.13.attention.self.key.bias', 'encoder.layer.8.attention.output.dense.bias', 'encoder.layer.17.output.dense.bias', 'encoder.layer.7.output.LayerNorm.bias', 'encoder.layer.4.attention.self.value.weight', 'encoder.layer.18.attention.output.LayerNorm.weight', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.23.attention.self.query.bias', 'encoder.layer.7.output.dense.bias', 'encoder.layer.2.attention.output.dense.weight', 'encoder.layer.20.attention.self.value.weight', 'embeddings.position_embeddings.weight', 'encoder.layer.20.output.dense.weight', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.15.intermediate.dense.bias', 'encoder.layer.8.attention.output.dense.weight', 'encoder.layer.6.output.LayerNorm.bias', 'encoder.layer.13.attention.output.LayerNorm.weight', 'encoder.layer.5.attention.output.dense.bias', 'encoder.layer.19.attention.output.dense.bias', 'encoder.layer.23.attention.self.query.weight', 'encoder.layer.8.attention.self.key.weight', 'encoder.layer.12.output.LayerNorm.weight', 'encoder.layer.21.intermediate.dense.bias', 'encoder.layer.4.attention.output.dense.bias', 'encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.layer.14.output.dense.weight', 'encoder.layer.22.output.LayerNorm.bias', 'encoder.layer.14.attention.self.value.bias', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.13.output.dense.weight', 'encoder.layer.16.output.LayerNorm.weight', 'encoder.layer.20.attention.self.key.weight', 'encoder.layer.17.attention.self.key.bias', 'encoder.layer.7.attention.self.value.weight', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.11.attention.self.value.weight', 'encoder.layer.14.output.LayerNorm.bias', 'encoder.layer.2.attention.self.query.weight', 'encoder.layer.14.attention.self.value.weight', 'encoder.layer.13.intermediate.dense.bias', 'encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.layer.12.attention.output.dense.bias', 'encoder.layer.14.attention.output.dense.bias', 'encoder.layer.7.attention.self.value.bias', 'encoder.layer.10.attention.self.value.weight', 'encoder.layer.18.attention.self.query.bias', 'encoder.layer.12.attention.self.key.bias', 'encoder.layer.19.attention.self.query.bias', 'encoder.layer.3.attention.self.value.weight', 'encoder.layer.19.attention.self.value.weight', 'encoder.layer.16.output.dense.bias', 'encoder.layer.2.attention.output.LayerNorm.weight', 'encoder.layer.3.attention.output.dense.bias', 'encoder.layer.18.intermediate.dense.weight', 'encoder.layer.8.output.LayerNorm.weight', 'encoder.layer.21.output.dense.weight', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.13.attention.self.key.weight', 'encoder.layer.1.attention.self.value.bias', 'encoder.layer.22.attention.self.value.bias', 'encoder.layer.10.attention.output.LayerNorm.weight', 'encoder.layer.8.attention.output.LayerNorm.weight', 'encoder.layer.21.attention.output.dense.weight', 'encoder.layer.20.attention.self.value.bias', 'encoder.layer.9.attention.self.key.bias', 'encoder.layer.23.output.LayerNorm.weight', 'encoder.layer.12.attention.output.LayerNorm.weight', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.16.attention.output.LayerNorm.bias', 'encoder.layer.10.attention.output.dense.bias', 'encoder.layer.5.output.LayerNorm.bias', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.17.intermediate.dense.weight', 'encoder.layer.23.attention.self.value.bias', 'encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.layer.1.attention.output.dense.bias', 'encoder.layer.22.intermediate.dense.bias', 'encoder.layer.8.attention.self.query.weight', 'encoder.layer.10.attention.self.key.weight', 'encoder.layer.8.attention.self.value.weight', 'encoder.layer.5.attention.self.key.bias', 'encoder.layer.13.attention.self.query.weight', 'encoder.layer.15.attention.output.dense.weight', 'encoder.layer.15.attention.output.LayerNorm.bias', 'encoder.layer.19.output.dense.bias', 'encoder.layer.17.intermediate.dense.bias', 'encoder.layer.3.attention.self.query.bias', 'encoder.layer.9.output.LayerNorm.bias', 'encoder.layer.10.output.dense.weight', 'encoder.layer.20.attention.output.LayerNorm.bias', 'encoder.layer.6.attention.self.query.bias', 'encoder.layer.5.output.dense.bias', 'encoder.layer.13.attention.output.LayerNorm.bias', 'encoder.layer.22.attention.output.LayerNorm.weight', 'encoder.layer.17.attention.output.dense.bias', 'encoder.layer.20.attention.self.query.weight', 'encoder.layer.23.output.LayerNorm.bias', 'encoder.layer.10.attention.self.value.bias', 'encoder.layer.3.attention.self.key.bias', 'encoder.layer.21.intermediate.dense.weight', 'encoder.layer.9.attention.self.value.weight', 'encoder.layer.23.attention.output.LayerNorm.weight', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.9.output.dense.weight', 'encoder.layer.7.attention.self.key.weight', 'encoder.layer.8.attention.output.LayerNorm.bias', 'encoder.layer.18.attention.self.query.weight', 'encoder.layer.3.attention.self.key.weight', 'encoder.layer.17.attention.self.query.weight', 'encoder.layer.22.attention.self.query.weight', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.11.attention.output.LayerNorm.weight', 'encoder.layer.12.attention.output.LayerNorm.bias', 'encoder.layer.10.output.LayerNorm.bias', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.18.attention.output.dense.weight', 'encoder.layer.14.attention.output.LayerNorm.bias', 'encoder.layer.15.attention.output.LayerNorm.weight', 'encoder.layer.11.output.dense.bias', 'encoder.layer.2.attention.self.key.bias', 'encoder.layer.2.attention.output.LayerNorm.bias', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.0.attention.output.LayerNorm.weight', 'encoder.layer.19.output.LayerNorm.weight', 'encoder.layer.14.intermediate.dense.bias', 'encoder.layer.6.attention.self.key.weight', 'encoder.layer.21.attention.self.key.weight', 'encoder.layer.22.attention.self.query.bias', 'encoder.layer.21.attention.self.key.bias', 'encoder.layer.20.output.dense.bias', 'encoder.layer.13.output.dense.bias', 'encoder.layer.21.output.dense.bias', 'encoder.layer.18.attention.output.LayerNorm.bias', 'encoder.layer.7.attention.output.LayerNorm.bias', 'encoder.layer.0.output.dense.bias', 'encoder.layer.6.output.dense.weight', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.20.attention.self.key.bias', 'encoder.layer.3.attention.output.dense.weight', 'encoder.layer.23.attention.output.dense.bias', 'encoder.layer.17.attention.self.query.bias', 'encoder.layer.15.output.LayerNorm.weight', 'encoder.layer.14.attention.self.query.bias', 'encoder.layer.9.output.dense.bias', 'encoder.layer.20.attention.self.query.bias', 'encoder.layer.20.output.LayerNorm.bias', 'encoder.layer.19.attention.self.query.weight', 'encoder.layer.4.attention.self.query.weight', 'encoder.layer.21.attention.self.value.bias', 'encoder.layer.1.attention.output.LayerNorm.weight', 'encoder.layer.10.output.LayerNorm.weight', 'encoder.layer.13.attention.output.dense.weight', 'encoder.layer.3.output.dense.bias', 'encoder.layer.12.attention.self.key.weight', 'encoder.layer.16.intermediate.dense.bias', 'encoder.layer.16.attention.self.query.bias', 'encoder.layer.14.attention.output.dense.weight', 'encoder.layer.0.output.dense.weight', 'encoder.layer.17.attention.self.value.weight', 'encoder.layer.22.intermediate.dense.weight', 'encoder.layer.3.attention.self.value.bias', 'encoder.layer.3.attention.self.query.weight', 'encoder.layer.19.attention.self.key.weight', 'encoder.layer.16.intermediate.dense.weight', 'encoder.layer.0.attention.output.dense.bias', 'encoder.layer.6.attention.self.key.bias', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.1.attention.self.key.bias', 'encoder.layer.22.attention.self.key.weight', 'encoder.layer.1.attention.self.query.bias', 'encoder.layer.5.attention.output.LayerNorm.weight', 'encoder.layer.2.attention.self.value.bias', 'encoder.layer.17.attention.output.LayerNorm.weight', 'pooler.dense.bias', 'encoder.layer.21.attention.self.query.weight', 'encoder.layer.0.attention.self.value.bias', 'encoder.layer.10.attention.self.key.bias', 'encoder.layer.10.attention.output.LayerNorm.bias', 'encoder.layer.11.attention.self.query.bias', 'encoder.layer.16.attention.output.LayerNorm.weight', 'encoder.layer.18.output.LayerNorm.bias', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.21.attention.self.value.weight', 'encoder.layer.19.output.dense.weight', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.17.attention.self.key.weight', 'encoder.layer.4.attention.output.dense.weight', 'encoder.layer.21.attention.output.LayerNorm.weight', 'encoder.layer.18.attention.self.value.weight', 'encoder.layer.15.attention.self.key.weight', 'encoder.layer.23.output.dense.weight', 'encoder.layer.7.attention.self.query.weight', 'encoder.layer.3.output.dense.weight', 'encoder.layer.11.attention.self.key.bias', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.9.attention.output.LayerNorm.weight', 'encoder.layer.22.output.dense.weight', 'encoder.layer.21.attention.self.query.bias', 'encoder.layer.11.attention.output.dense.bias', 'encoder.layer.7.output.LayerNorm.weight', 'encoder.layer.13.output.LayerNorm.bias', 'encoder.layer.8.attention.self.key.bias', 'encoder.layer.9.attention.output.dense.bias', 'encoder.layer.14.attention.self.key.bias', 'encoder.layer.17.attention.output.LayerNorm.bias', 'encoder.layer.16.output.dense.weight', 'encoder.layer.8.attention.self.query.bias', 'encoder.layer.9.attention.self.value.bias', 'encoder.layer.14.output.dense.bias', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.14.attention.self.key.weight', 'encoder.layer.6.attention.output.dense.bias', 'encoder.layer.9.attention.self.key.weight', 'encoder.layer.13.intermediate.dense.weight', 'encoder.layer.16.attention.output.dense.bias', 'encoder.layer.14.attention.self.query.weight', 'encoder.layer.23.attention.output.dense.weight', 'encoder.layer.0.attention.self.query.weight', 'encoder.layer.1.attention.output.dense.weight', 'encoder.layer.14.output.LayerNorm.weight', 'encoder.layer.12.attention.self.value.weight', 'embeddings.token_type_embeddings.weight', 'encoder.layer.1.attention.self.value.weight', 'encoder.layer.4.attention.self.key.weight', 'encoder.layer.6.attention.output.dense.weight', 'encoder.layer.0.attention.self.key.bias', 'encoder.layer.2.attention.self.query.bias', 'encoder.layer.23.attention.self.value.weight', 'encoder.layer.6.attention.output.LayerNorm.bias', 'encoder.layer.16.attention.self.key.bias', 'encoder.layer.4.attention.output.LayerNorm.bias', 'encoder.layer.23.attention.self.key.bias', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.9.attention.output.dense.weight', 'encoder.layer.19.attention.output.dense.weight', 'encoder.layer.17.attention.self.value.bias', 'encoder.layer.5.attention.self.query.bias', 'encoder.layer.15.attention.self.value.weight', 'encoder.layer.12.attention.self.value.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Overwriting existing adapter 'ep'.
Overwriting existing adapter 'tp'.
Overwriting existing adapter 'es'.
Overwriting existing adapter 'ts'.
Overwriting existing adapter fusion module 'ep,tp,es,ts'
05/09/2022 19:54:33 - INFO - __main__ -   lang2id = None
05/09/2022 19:54:37 - INFO - __main__ -   Training/evaluation parameters Namespace(adam_epsilon=1e-08, cache_dir='', config_name='', data_dir=None, device=device(type='cuda'), do_eval=True, do_lower_case=False, do_train=False, doc_stride=128, eval_all_checkpoints=False, eval_lang='de', evaluate_during_training=False, fp16=False, fp16_opt_level='O1', gradient_accumulation_steps=1, learning_rate=5e-05, local_rank=-1, logging_steps=50, max_answer_length=30, max_grad_norm=1.0, max_query_length=64, max_seq_length=384, max_steps=-1, model_name='xlm-KG', model_name_or_path='/cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//squad/xlm-KG_LR4e-5_EPOCH2.0_maxlen384_batchsize4_gradacc8', model_type='xlm', modelkg_dir='/cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/adapter/xlmr_adapter', n_best_size=20, n_gpu=1, no_cuda=False, null_score_diff_threshold=0.0, num_train_epochs=3.0, output_dir='/cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//squad/xlm-KG_LR4e-5_EPOCH2.0_maxlen384_batchsize4_gradacc8/predictions/xquad/', overwrite_cache=False, overwrite_output_dir=False, per_gpu_eval_batch_size=8, per_gpu_train_batch_size=8, predict_file='/cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/download//xquad//xquad.de.json', save_steps=50, seed=42, server_ip='', server_port='', threads=1, tokenizer_name='', train_file=None, train_lang='en', verbose_logging=False, version_2_with_negative=False, warmup_steps=0, weight_decay=0.0)
05/09/2022 19:54:37 - INFO - __main__ -   Loading checkpoint /cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//squad/xlm-KG_LR4e-5_EPOCH2.0_maxlen384_batchsize4_gradacc8 for evaluation
05/09/2022 19:54:37 - INFO - __main__ -   Evaluate the following checkpoints: ['/cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//squad/xlm-KG_LR4e-5_EPOCH2.0_maxlen384_batchsize4_gradacc8']
Some weights of the model checkpoint at /cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//squad/xlm-KG_LR4e-5_EPOCH2.0_maxlen384_batchsize4_gradacc8 were not used when initializing XLMRobertaModel: ['base_model.encoder.layer.10.attention.self.key.bias', 'base_model.encoder.layer.20.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.8.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.10.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.18.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.20.output.LayerNorm.bias', 'base_model.encoder.layer.15.attention.self.query.weight', 'base_model.encoder.layer.15.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.22.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.7.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.7.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.0.output.LayerNorm.bias', 'base_model.encoder.layer.22.attention.self.query.weight', 'base_model.encoder.layer.14.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.12.attention.self.value.weight', 'base_model.encoder.layer.11.attention.output.dense.weight', 'base_model.encoder.layer.16.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.22.attention.self.key.bias', 'base_model.encoder.layer.16.attention.self.key.weight', 'base_model.encoder.layer.3.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.9.intermediate.dense.weight', 'base_model.encoder.layer.7.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.8.attention.output.dense.weight', 'base_model.encoder.layer.21.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.6.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.14.attention.output.LayerNorm.bias', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.10.attention.self.value.weight', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.3.output.LayerNorm.weight', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.19.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.2.intermediate.dense.weight', 'base_model.encoder.layer.9.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.12.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.8.attention.output.LayerNorm.weight', 'base_model.encoder.layer.11.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.14.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'qa_outputs.bias', 'base_model.encoder.layer.2.attention.output.dense.bias', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.11.attention.self.query.weight', 'base_model.encoder.layer.4.attention.self.query.weight', 'base_model.encoder.layer.13.output.LayerNorm.bias', 'base_model.encoder.layer.16.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.23.intermediate.dense.bias', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.16.attention.self.key.bias', 'base_model.encoder.layer.3.attention.self.query.bias', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.1.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.2.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.11.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.20.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.22.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.9.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.21.intermediate.dense.weight', 'base_model.encoder.layer.6.attention.self.key.bias', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.13.attention.self.key.weight', 'base_model.encoder.layer.16.attention.output.LayerNorm.bias', 'base_model.encoder.layer.5.output.dense.weight', 'base_model.encoder.layer.7.attention.self.key.bias', 'base_model.encoder.layer.7.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.23.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.4.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.7.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.20.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.2.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.0.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.7.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.10.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.18.intermediate.dense.bias', 'base_model.encoder.layer.9.attention.self.query.weight', 'base_model.encoder.layer.9.output.dense.bias', 'base_model.encoder.layer.21.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.11.attention.output.dense.bias', 'base_model.encoder.layer.16.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.0.output.dense.weight', 'base_model.encoder.layer.6.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.0.output.dense.bias', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.4.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.12.output.dense.bias', 'base_model.encoder.layer.14.attention.self.value.bias', 'base_model.encoder.layer.11.attention.output.LayerNorm.weight', 'base_model.encoder.layer.4.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.8.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.19.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.22.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.8.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.9.attention.self.key.weight', 'base_model.encoder.layer.10.attention.self.query.weight', 'base_model.encoder.layer.10.attention.output.dense.weight', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.3.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.16.intermediate.dense.bias', 'base_model.encoder.layer.3.attention.self.key.weight', 'base_model.encoder.layer.18.attention.output.LayerNorm.weight', 'base_model.encoder.layer.23.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.0.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.19.intermediate.dense.bias', 'base_model.encoder.layer.1.output.LayerNorm.weight', 'base_model.encoder.layer.2.attention.self.key.weight', 'base_model.encoder.layer.2.output.dense.weight', 'base_model.encoder.layer.8.attention.output.LayerNorm.bias', 'base_model.encoder.layer.9.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.13.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.5.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.19.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.21.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.14.attention.self.key.weight', 'base_model.encoder.layer.16.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.10.attention.self.query.bias', 'base_model.encoder.layer.3.attention.output.LayerNorm.bias', 'base_model.encoder.layer.2.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.10.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.15.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.22.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.17.attention.self.value.weight', 'base_model.encoder.layer.3.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.6.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.18.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.2.attention.self.query.weight', 'base_model.encoder.layer.1.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.20.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.15.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.20.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.3.attention.output.dense.bias', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.18.attention.self.key.bias', 'base_model.encoder.layer.4.output.LayerNorm.weight', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.5.output.LayerNorm.weight', 'base_model.encoder.layer.6.attention.output.dense.weight', 'base_model.encoder.layer.15.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.10.attention.self.key.weight', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.11.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.16.attention.output.dense.weight', 'base_model.encoder.layer.17.intermediate.dense.weight', 'base_model.encoder.layer.20.attention.self.value.bias', 'base_model.encoder.layer.18.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.9.attention.self.key.bias', 'base_model.encoder.layer.19.attention.self.key.weight', 'base_model.encoder.layer.15.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.20.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.22.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.15.attention.output.LayerNorm.weight', 'base_model.encoder.layer.6.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.18.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.5.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.9.output.adapters.es.adapter_down.0.bias', 'base_model.embeddings.token_type_embeddings.weight', 'base_model.encoder.layer.19.output.LayerNorm.bias', 'base_model.encoder.layer.23.attention.self.query.weight', 'base_model.encoder.layer.19.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.23.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.18.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.9.attention.self.value.weight', 'base_model.encoder.layer.2.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.9.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.5.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.15.attention.self.key.weight', 'base_model.encoder.layer.10.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.2.attention.output.LayerNorm.weight', 'base_model.encoder.layer.9.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.10.output.dense.weight', 'base_model.encoder.layer.23.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.1.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.3.output.dense.weight', 'base_model.encoder.layer.6.output.dense.weight', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.15.output.LayerNorm.weight', 'base_model.encoder.layer.18.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.4.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.14.attention.self.query.bias', 'base_model.encoder.layer.16.intermediate.dense.weight', 'base_model.encoder.layer.19.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.6.attention.self.query.weight', 'base_model.encoder.layer.19.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.13.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.21.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.11.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.11.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.1.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.12.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.17.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.22.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.13.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.21.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.3.output.adapters.ts.adapter_down.0.weight', 'base_model.pooler.dense.bias', 'base_model.encoder.layer.2.attention.output.dense.weight', 'base_model.encoder.layer.6.attention.self.value.weight', 'base_model.encoder.layer.19.attention.self.key.bias', 'base_model.encoder.layer.12.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.15.attention.self.query.bias', 'base_model.encoder.layer.22.attention.self.query.bias', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.18.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.5.output.LayerNorm.bias', 'base_model.encoder.layer.1.attention.self.query.bias', 'base_model.encoder.layer.5.intermediate.dense.bias', 'base_model.encoder.layer.13.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.21.attention.output.LayerNorm.bias', 'base_model.encoder.layer.6.intermediate.dense.weight', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.22.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.0.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.6.attention.self.value.bias', 'base_model.encoder.layer.12.output.LayerNorm.weight', 'base_model.encoder.layer.3.attention.self.key.bias', 'base_model.encoder.layer.22.attention.output.dense.bias', 'base_model.encoder.layer.14.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.2.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.23.attention.self.value.bias', 'base_model.encoder.layer.14.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.4.intermediate.dense.bias', 'base_model.encoder.layer.13.intermediate.dense.bias', 'base_model.encoder.layer.23.attention.output.LayerNorm.bias', 'base_model.encoder.layer.2.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.7.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.8.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.8.output.LayerNorm.bias', 'base_model.encoder.layer.4.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.18.attention.self.key.weight', 'base_model.encoder.layer.20.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.1.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.2.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.23.attention.output.dense.bias', 'base_model.encoder.layer.0.attention.output.dense.bias', 'base_model.encoder.layer.12.attention.self.key.weight', 'base_model.encoder.layer.17.attention.self.value.bias', 'base_model.encoder.layer.20.intermediate.dense.weight', 'base_model.encoder.layer.2.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.3.intermediate.dense.bias', 'base_model.encoder.layer.5.attention.output.LayerNorm.weight', 'base_model.encoder.layer.16.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.9.attention.output.dense.weight', 'base_model.encoder.layer.1.attention.self.query.weight', 'base_model.encoder.layer.0.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.15.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.21.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.11.intermediate.dense.bias', 'base_model.encoder.layer.16.output.LayerNorm.bias', 'base_model.encoder.layer.8.attention.self.query.bias', 'base_model.encoder.layer.8.attention.self.query.weight', 'base_model.encoder.layer.17.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.20.attention.output.LayerNorm.bias', 'base_model.encoder.layer.23.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.20.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.8.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.11.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.5.attention.output.dense.weight', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.17.attention.output.LayerNorm.weight', 'base_model.encoder.layer.1.intermediate.dense.weight', 'base_model.encoder.layer.19.attention.output.LayerNorm.bias', 'base_model.encoder.layer.21.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.16.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.20.attention.output.dense.bias', 'base_model.encoder.layer.2.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.4.attention.self.key.bias', 'base_model.encoder.layer.15.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.4.attention.self.value.weight', 'base_model.encoder.layer.17.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.22.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.11.attention.output.LayerNorm.bias', 'base_model.encoder.layer.7.output.LayerNorm.bias', 'base_model.encoder.layer.17.attention.self.query.bias', 'base_model.encoder.layer.13.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.21.attention.self.key.bias', 'base_model.encoder.layer.7.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.7.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.10.intermediate.dense.weight', 'base_model.encoder.layer.3.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.0.output.adapters.tp.adapter_down.0.bias', 'base_model.embeddings.LayerNorm.bias', 'base_model.encoder.layer.17.attention.output.LayerNorm.bias', 'base_model.encoder.layer.13.attention.output.dense.weight', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.8.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.9.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.18.output.LayerNorm.bias', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.4.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.6.intermediate.dense.bias', 'base_model.encoder.layer.11.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.18.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.17.output.adapters.tp.adapter_down.0.bias', 'base_model.embeddings.position_embeddings.weight', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.19.intermediate.dense.weight', 'base_model.encoder.layer.10.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.3.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.9.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.21.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.15.attention.output.LayerNorm.bias', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.13.attention.output.dense.bias', 'base_model.pooler.dense.weight', 'base_model.encoder.layer.23.output.dense.bias', 'base_model.encoder.layer.6.attention.self.query.bias', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.9.output.LayerNorm.bias', 'base_model.encoder.layer.13.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.14.intermediate.dense.weight', 'base_model.encoder.layer.5.attention.self.value.bias', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.23.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.15.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.4.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.8.intermediate.dense.bias', 'base_model.encoder.layer.9.attention.self.query.bias', 'base_model.encoder.layer.13.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.3.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.12.output.dense.weight', 'base_model.encoder.layer.10.attention.output.LayerNorm.bias', 'base_model.encoder.layer.16.attention.output.LayerNorm.weight', 'base_model.encoder.layer.23.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.10.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.19.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.5.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.22.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.22.attention.output.LayerNorm.bias', 'base_model.encoder.layer.14.output.dense.weight', 'base_model.encoder.layer.4.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.9.output.dense.weight', 'base_model.encoder.layer.16.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.5.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.11.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.14.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.0.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.10.output.LayerNorm.bias', 'base_model.encoder.layer.13.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.22.attention.output.LayerNorm.weight', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.19.attention.output.dense.weight', 'base_model.encoder.layer.2.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.14.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.8.output.dense.weight', 'base_model.encoder.layer.8.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.15.attention.self.key.bias', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.23.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.0.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.11.attention.self.key.bias', 'base_model.encoder.layer.1.attention.output.dense.bias', 'base_model.encoder.layer.4.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.21.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.13.intermediate.dense.weight', 'base_model.encoder.layer.0.output.LayerNorm.weight', 'base_model.encoder.layer.18.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.19.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.13.attention.output.LayerNorm.weight', 'base_model.encoder.layer.16.attention.self.query.weight', 'base_model.encoder.layer.16.output.LayerNorm.weight', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.3.attention.self.value.bias', 'base_model.encoder.layer.6.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.8.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.0.intermediate.dense.weight', 'base_model.encoder.layer.10.intermediate.dense.bias', 'base_model.encoder.layer.4.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.18.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.17.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.20.attention.self.query.bias', 'base_model.encoder.layer.1.output.dense.weight', 'base_model.encoder.layer.0.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.1.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.13.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.23.output.LayerNorm.weight', 'base_model.encoder.layer.14.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.14.attention.self.value.weight', 'base_model.encoder.layer.23.attention.output.dense.weight', 'base_model.encoder.layer.15.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.5.attention.output.dense.bias', 'base_model.encoder.layer.20.output.LayerNorm.weight', 'base_model.encoder.layer.23.intermediate.dense.weight', 'qa_outputs.weight', 'base_model.encoder.layer.2.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.7.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.23.attention.self.key.weight', 'base_model.encoder.layer.0.attention.self.value.weight', 'base_model.encoder.layer.13.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.9.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.12.intermediate.dense.weight', 'base_model.encoder.layer.12.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.23.attention.self.query.bias', 'base_model.encoder.layer.9.output.LayerNorm.weight', 'base_model.encoder.layer.5.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.12.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.17.intermediate.dense.bias', 'base_model.encoder.layer.22.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.7.intermediate.dense.bias', 'base_model.encoder.layer.12.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.22.intermediate.dense.weight', 'base_model.encoder.layer.13.output.dense.bias', 'base_model.encoder.layer.13.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.0.attention.output.LayerNorm.bias', 'base_model.encoder.layer.23.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.4.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.18.output.dense.bias', 'base_model.encoder.layer.10.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.10.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.2.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.3.output.dense.bias', 'base_model.encoder.layer.13.attention.output.LayerNorm.bias', 'base_model.encoder.layer.6.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.12.attention.output.dense.weight', 'base_model.encoder.layer.4.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.6.output.dense.bias', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.22.attention.self.value.weight', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.19.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.4.attention.output.dense.weight', 'base_model.encoder.layer.17.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.1.attention.output.LayerNorm.weight', 'base_model.encoder.layer.16.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.1.attention.self.value.weight', 'base_model.encoder.layer.4.intermediate.dense.weight', 'base_model.encoder.layer.17.attention.self.key.bias', 'base_model.encoder.layer.10.attention.output.dense.bias', 'base_model.encoder.layer.12.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.15.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.22.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.17.output.dense.bias', 'base_model.encoder.layer.19.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.21.output.dense.bias', 'base_model.encoder.layer.18.attention.self.value.weight', 'base_model.encoder.layer.0.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.15.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.16.attention.self.value.bias', 'base_model.encoder.layer.22.attention.self.key.weight', 'base_model.encoder.layer.17.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.18.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.19.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.8.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.11.attention.self.query.bias', 'base_model.encoder.layer.19.attention.output.dense.bias', 'base_model.encoder.layer.1.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.15.output.dense.weight', 'base_model.encoder.layer.17.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.14.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.20.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.7.output.dense.bias', 'base_model.encoder.layer.11.output.dense.bias', 'base_model.encoder.layer.22.attention.self.value.bias', 'base_model.encoder.layer.9.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.9.attention.output.dense.bias', 'base_model.encoder.layer.7.output.dense.weight', 'base_model.encoder.layer.15.intermediate.dense.weight', 'base_model.encoder.layer.20.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.21.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.23.attention.self.key.bias', 'base_model.encoder.layer.14.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.16.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.9.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.3.intermediate.dense.weight', 'base_model.encoder.layer.6.attention.output.LayerNorm.bias', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.11.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.16.attention.self.value.weight', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.16.attention.self.query.bias', 'base_model.encoder.layer.21.attention.self.value.bias', 'base_model.encoder.layer.2.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.6.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.9.attention.output.LayerNorm.weight', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.1.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.13.output.dense.weight', 'base_model.embeddings.LayerNorm.weight', 'base_model.encoder.layer.5.attention.self.value.weight', 'base_model.encoder.layer.20.attention.output.dense.weight', 'base_model.encoder.layer.20.output.dense.weight', 'base_model.encoder.layer.15.output.dense.bias', 'base_model.encoder.layer.12.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.22.output.dense.weight', 'base_model.encoder.layer.22.attention.output.dense.weight', 'base_model.encoder.layer.16.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.7.attention.self.query.weight', 'base_model.encoder.layer.17.attention.output.dense.weight', 'base_model.encoder.layer.7.attention.self.query.bias', 'base_model.encoder.layer.2.intermediate.dense.bias', 'base_model.encoder.layer.22.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.0.attention.self.query.bias', 'base_model.encoder.layer.8.attention.output.dense.bias', 'base_model.encoder.layer.4.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.3.attention.self.query.weight', 'base_model.encoder.layer.3.attention.self.value.weight', 'base_model.encoder.layer.13.attention.self.key.bias', 'base_model.encoder.layer.3.output.LayerNorm.bias', 'base_model.encoder.layer.12.attention.self.query.bias', 'base_model.encoder.layer.11.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.11.intermediate.dense.weight', 'base_model.encoder.layer.12.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.18.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.18.attention.output.dense.bias', 'base_model.encoder.layer.5.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.0.attention.self.value.bias', 'base_model.encoder.layer.21.attention.self.query.weight', 'base_model.encoder.layer.18.intermediate.dense.weight', 'base_model.encoder.layer.14.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.17.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.0.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.8.attention.self.key.weight', 'base_model.encoder.layer.16.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.0.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.18.attention.self.query.bias', 'base_model.encoder.layer.21.attention.self.value.weight', 'base_model.encoder.layer.21.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.16.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.23.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.0.attention.self.query.weight', 'base_model.encoder.layer.7.attention.self.value.bias', 'base_model.encoder.layer.0.intermediate.dense.bias', 'base_model.encoder.layer.5.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.19.output.dense.bias', 'base_model.encoder.layer.23.output.LayerNorm.bias', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.5.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.11.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.14.intermediate.dense.bias', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.11.output.LayerNorm.bias', 'base_model.encoder.layer.22.output.LayerNorm.weight', 'base_model.encoder.layer.12.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.6.attention.output.dense.bias', 'base_model.encoder.layer.10.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.1.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.8.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.6.attention.self.key.weight', 'base_model.encoder.layer.17.attention.self.key.weight', 'base_model.encoder.layer.23.attention.self.value.weight', 'base_model.encoder.layer.4.attention.output.LayerNorm.weight', 'base_model.encoder.layer.6.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.23.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.8.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.2.attention.output.LayerNorm.bias', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.21.attention.self.key.weight', 'base_model.encoder.layer.21.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.8.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.9.intermediate.dense.bias', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.12.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.17.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.15.attention.output.dense.weight', 'base_model.encoder.layer.1.attention.self.value.bias', 'base_model.encoder.layer.1.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.22.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.2.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.20.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.1.attention.self.key.weight', 'base_model.encoder.layer.5.attention.self.key.bias', 'base_model.encoder.layer.1.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.6.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.18.attention.output.dense.weight', 'base_model.encoder.layer.8.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.4.attention.self.key.weight', 'base_model.encoder.layer.6.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.5.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.5.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.15.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.15.attention.self.value.bias', 'base_model.encoder.layer.3.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.0.attention.output.dense.weight', 'base_model.encoder.layer.15.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.21.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.9.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.4.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.10.output.dense.bias', 'base_model.encoder.layer.10.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.13.attention.self.query.bias', 'base_model.encoder.layer.13.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.16.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.21.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.5.attention.self.query.weight', 'base_model.encoder.layer.8.output.dense.bias', 'base_model.encoder.layer.20.output.dense.bias', 'base_model.encoder.layer.12.output.LayerNorm.bias', 'base_model.encoder.layer.4.attention.self.query.bias', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.19.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.16.output.dense.weight', 'base_model.encoder.layer.5.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.13.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.4.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.5.attention.self.query.bias', 'base_model.encoder.layer.9.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.11.attention.self.value.weight', 'base_model.encoder.layer.20.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.11.attention.self.key.weight', 'base_model.encoder.layer.14.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.7.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.18.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.1.attention.self.key.bias', 'base_model.encoder.layer.11.attention.self.value.bias', 'base_model.encoder.layer.1.attention.output.dense.weight', 'base_model.encoder.layer.6.attention.output.LayerNorm.weight', 'base_model.encoder.layer.14.output.LayerNorm.weight', 'base_model.encoder.layer.20.attention.self.query.weight', 'base_model.encoder.layer.21.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.8.attention.self.value.bias', 'base_model.encoder.layer.13.attention.self.value.weight', 'base_model.encoder.layer.3.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.14.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.7.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.7.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.6.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.1.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.10.attention.self.value.bias', 'base_model.encoder.layer.17.attention.output.dense.bias', 'base_model.encoder.layer.22.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.14.attention.output.LayerNorm.weight', 'base_model.encoder.layer.21.attention.output.dense.bias', 'base_model.encoder.layer.21.output.LayerNorm.weight', 'base_model.encoder.layer.18.attention.self.value.bias', 'base_model.encoder.layer.3.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.1.output.dense.bias', 'base_model.encoder.layer.10.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.14.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.17.attention.self.query.weight', 'base_model.encoder.layer.9.attention.self.value.bias', 'base_model.encoder.layer.12.attention.output.LayerNorm.bias', 'base_model.encoder.layer.15.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.9.attention.output.LayerNorm.bias', 'base_model.encoder.layer.2.output.LayerNorm.weight', 'base_model.encoder.layer.7.attention.self.value.weight', 'base_model.encoder.layer.19.attention.self.value.bias', 'base_model.encoder.layer.6.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.16.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.17.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.21.attention.self.query.bias', 'base_model.encoder.layer.18.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.21.intermediate.dense.bias', 'base_model.encoder.layer.17.output.LayerNorm.weight', 'base_model.encoder.layer.1.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.0.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.13.attention.self.value.bias', 'base_model.encoder.layer.19.attention.output.LayerNorm.weight', 'base_model.encoder.layer.3.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.8.intermediate.dense.weight', 'base_model.encoder.layer.5.attention.self.key.weight', 'base_model.encoder.layer.23.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.14.attention.self.key.bias', 'base_model.encoder.layer.8.attention.self.value.weight', 'base_model.encoder.layer.0.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.23.attention.output.LayerNorm.weight', 'base_model.encoder.layer.11.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.23.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.3.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.6.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.3.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.19.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.9.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.12.intermediate.dense.bias', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.5.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.0.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.21.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.16.attention.output.dense.bias', 'base_model.encoder.layer.4.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.17.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.18.output.dense.weight', 'base_model.encoder.layer.8.attention.self.key.bias', 'base_model.encoder.layer.12.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.10.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.14.output.dense.bias', 'base_model.encoder.layer.10.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.16.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.20.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.17.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.22.output.adapters.es.adapter_down.0.weight', 'base_model.embeddings.position_ids', 'base_model.encoder.layer.4.output.dense.weight', 'base_model.encoder.layer.16.output.dense.bias', 'base_model.encoder.layer.13.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.16.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.5.intermediate.dense.weight', 'base_model.encoder.layer.5.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.1.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.5.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.0.attention.output.LayerNorm.weight', 'base_model.encoder.layer.3.attention.output.dense.weight', 'base_model.encoder.layer.2.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.2.output.LayerNorm.bias', 'base_model.encoder.layer.8.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.8.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.6.output.LayerNorm.weight', 'base_model.encoder.layer.13.attention.self.query.weight', 'base_model.encoder.layer.14.attention.output.dense.weight', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.3.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.12.attention.output.LayerNorm.weight', 'base_model.encoder.layer.15.intermediate.dense.bias', 'base_model.encoder.layer.12.attention.self.value.bias', 'base_model.encoder.layer.20.intermediate.dense.bias', 'base_model.encoder.layer.22.output.dense.bias', 'base_model.encoder.layer.20.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.1.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.7.attention.self.key.weight', 'base_model.encoder.layer.11.output.LayerNorm.weight', 'base_model.encoder.layer.0.attention.self.key.bias', 'base_model.encoder.layer.20.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.19.output.dense.weight', 'base_model.encoder.layer.1.intermediate.dense.bias', 'base_model.encoder.layer.4.attention.self.value.bias', 'base_model.encoder.layer.12.attention.self.key.bias', 'base_model.encoder.layer.23.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.13.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.0.attention.self.key.weight', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.19.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.14.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.5.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.15.attention.output.dense.bias', 'base_model.encoder.layer.20.attention.self.key.weight', 'base_model.encoder.layer.23.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.21.attention.output.dense.weight', 'base_model.encoder.layer.9.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.7.output.LayerNorm.weight', 'base_model.encoder.layer.12.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.3.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.22.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.4.output.dense.bias', 'base_model.encoder.layer.12.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.20.attention.self.value.weight', 'base_model.encoder.layer.20.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.19.output.LayerNorm.weight', 'base_model.encoder.layer.7.attention.output.LayerNorm.weight', 'base_model.encoder.layer.15.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.7.attention.output.LayerNorm.bias', 'base_model.encoder.layer.7.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.14.output.LayerNorm.bias', 'base_model.encoder.layer.15.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.4.attention.output.LayerNorm.bias', 'base_model.encoder.layer.19.attention.self.query.weight', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.11.output.dense.weight', 'base_model.encoder.layer.11.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.14.attention.output.dense.bias', 'base_model.encoder.layer.7.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.6.output.LayerNorm.bias', 'base_model.encoder.layer.1.attention.output.LayerNorm.bias', 'base_model.encoder.layer.15.output.LayerNorm.bias', 'base_model.encoder.layer.6.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.19.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.7.intermediate.dense.weight', 'base_model.encoder.layer.21.attention.output.LayerNorm.weight', 'base_model.encoder.layer.23.output.dense.weight', 'base_model.encoder.layer.9.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.12.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.14.attention.self.query.weight', 'base_model.encoder.layer.1.output.LayerNorm.bias', 'base_model.encoder.layer.1.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.7.attention.output.dense.bias', 'base_model.encoder.layer.10.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.10.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.17.output.LayerNorm.bias', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.7.attention.output.dense.weight', 'base_model.encoder.layer.12.attention.output.dense.bias', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.11.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.18.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.18.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.10.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.21.output.LayerNorm.bias', 'base_model.encoder.layer.5.attention.output.LayerNorm.bias', 'base_model.encoder.layer.15.attention.self.value.weight', 'base_model.encoder.layer.19.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.4.attention.output.dense.bias', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.17.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.19.attention.self.query.bias', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.17.output.dense.weight', 'base_model.encoder.layer.4.output.LayerNorm.bias', 'base_model.encoder.layer.2.output.dense.bias', 'base_model.encoder.layer.14.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.0.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.21.output.dense.weight', 'base_model.encoder.layer.6.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.3.attention.output.LayerNorm.weight', 'base_model.encoder.layer.22.intermediate.dense.bias', 'base_model.encoder.layer.17.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.6.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.13.output.LayerNorm.weight', 'base_model.encoder.layer.19.attention.self.value.weight', 'base_model.encoder.layer.0.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.10.output.LayerNorm.weight', 'base_model.encoder.layer.23.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.2.attention.self.value.weight', 'base_model.encoder.layer.2.attention.self.query.bias', 'base_model.encoder.layer.5.output.dense.bias', 'base_model.encoder.layer.3.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.11.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.20.attention.output.LayerNorm.weight', 'base_model.encoder.layer.10.attention.output.LayerNorm.weight', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.2.attention.self.key.bias', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.2.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.7.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.2.attention.self.value.bias', 'base_model.encoder.layer.12.attention.self.query.weight', 'base_model.encoder.layer.12.output.adapters.ts.adapter_up.weight', 'base_model.embeddings.word_embeddings.weight', 'base_model.encoder.layer.17.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.13.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.22.output.LayerNorm.bias', 'base_model.encoder.layer.8.output.LayerNorm.weight', 'base_model.encoder.layer.18.attention.self.query.weight', 'base_model.encoder.layer.8.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.14.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.18.output.LayerNorm.weight', 'base_model.encoder.layer.20.attention.self.key.bias', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.18.attention.output.LayerNorm.bias', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.11.output.adapters.es.adapter_up.weight']
- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of XLMRobertaModel were not initialized from the model checkpoint at /cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//squad/xlm-KG_LR4e-5_EPOCH2.0_maxlen384_batchsize4_gradacc8 and are newly initialized: ['encoder.layer.15.attention.self.value.bias', 'encoder.layer.11.output.LayerNorm.weight', 'encoder.layer.17.output.dense.weight', 'encoder.layer.15.attention.output.dense.bias', 'encoder.layer.1.attention.self.query.weight', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.7.intermediate.dense.bias', 'encoder.layer.22.attention.self.value.weight', 'encoder.layer.18.output.dense.bias', 'encoder.layer.7.output.dense.weight', 'encoder.layer.7.attention.self.query.bias', 'encoder.layer.15.attention.self.key.bias', 'encoder.layer.12.attention.self.query.weight', 'encoder.layer.16.output.LayerNorm.bias', 'encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.layer.17.output.LayerNorm.weight', 'encoder.layer.16.attention.self.query.weight', 'encoder.layer.16.attention.self.key.weight', 'encoder.layer.10.output.dense.bias', 'encoder.layer.2.output.dense.weight', 'encoder.layer.16.attention.self.value.bias', 'encoder.layer.16.attention.self.value.weight', 'encoder.layer.18.attention.self.value.bias', 'encoder.layer.21.output.LayerNorm.bias', 'encoder.layer.20.intermediate.dense.weight', 'encoder.layer.15.output.LayerNorm.bias', 'encoder.layer.8.attention.self.value.bias', 'encoder.layer.15.attention.self.query.bias', 'embeddings.LayerNorm.weight', 'encoder.layer.12.output.dense.bias', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.19.intermediate.dense.weight', 'encoder.layer.15.intermediate.dense.weight', 'encoder.layer.10.intermediate.dense.weight', 'encoder.layer.5.attention.self.value.bias', 'embeddings.word_embeddings.weight', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.21.output.LayerNorm.weight', 'encoder.layer.19.attention.self.key.bias', 'encoder.layer.23.output.dense.bias', 'encoder.layer.6.attention.self.value.weight', 'encoder.layer.23.attention.output.LayerNorm.bias', 'encoder.layer.16.attention.output.dense.weight', 'encoder.layer.14.intermediate.dense.weight', 'encoder.layer.13.attention.self.query.bias', 'encoder.layer.22.attention.output.dense.weight', 'encoder.layer.19.attention.output.LayerNorm.weight', 'encoder.layer.8.output.dense.weight', 'encoder.layer.4.attention.output.LayerNorm.weight', 'encoder.layer.18.intermediate.dense.bias', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.2.attention.output.dense.bias', 'encoder.layer.4.output.dense.bias', 'encoder.layer.23.intermediate.dense.bias', 'encoder.layer.11.attention.self.query.weight', 'encoder.layer.22.attention.self.key.bias', 'encoder.layer.22.output.dense.bias', 'encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.13.output.LayerNorm.weight', 'encoder.layer.7.attention.self.key.bias', 'encoder.layer.19.intermediate.dense.bias', 'encoder.layer.7.attention.output.LayerNorm.weight', 'encoder.layer.6.attention.self.value.bias', 'encoder.layer.2.attention.self.value.weight', 'encoder.layer.4.output.dense.weight', 'encoder.layer.18.output.LayerNorm.weight', 'encoder.layer.20.attention.output.dense.bias', 'encoder.layer.22.output.LayerNorm.weight', 'encoder.layer.6.attention.self.query.weight', 'encoder.layer.12.attention.output.dense.weight', 'encoder.layer.12.output.dense.weight', 'encoder.layer.12.output.LayerNorm.bias', 'encoder.layer.20.attention.output.dense.weight', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.19.attention.self.value.bias', 'encoder.layer.5.attention.self.value.weight', 'encoder.layer.2.output.dense.bias', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.layer.22.attention.output.LayerNorm.bias', 'encoder.layer.9.attention.self.query.bias', 'encoder.layer.4.attention.self.query.bias', 'encoder.layer.19.attention.output.LayerNorm.bias', 'encoder.layer.8.output.LayerNorm.bias', 'encoder.layer.12.intermediate.dense.bias', 'encoder.layer.13.attention.self.value.bias', 'encoder.layer.6.output.dense.bias', 'encoder.layer.18.output.dense.weight', 'encoder.layer.20.attention.output.LayerNorm.weight', 'encoder.layer.20.intermediate.dense.bias', 'encoder.layer.14.attention.output.LayerNorm.weight', 'encoder.layer.1.output.dense.bias', 'encoder.layer.1.attention.self.key.weight', 'pooler.dense.weight', 'encoder.layer.5.attention.self.query.weight', 'encoder.layer.21.attention.output.dense.bias', 'encoder.layer.10.attention.self.query.weight', 'encoder.layer.2.attention.self.key.weight', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.13.attention.self.value.weight', 'encoder.layer.1.output.dense.weight', 'encoder.layer.17.output.LayerNorm.bias', 'encoder.layer.13.attention.output.dense.bias', 'encoder.layer.17.attention.output.dense.weight', 'encoder.layer.5.output.dense.weight', 'encoder.layer.11.attention.self.key.weight', 'encoder.layer.20.output.LayerNorm.weight', 'encoder.layer.4.attention.self.value.bias', 'encoder.layer.19.output.LayerNorm.bias', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.4.attention.self.key.bias', 'encoder.layer.0.attention.self.query.bias', 'encoder.layer.10.attention.self.query.bias', 'encoder.layer.21.attention.output.LayerNorm.bias', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.15.attention.self.query.weight', 'encoder.layer.8.output.dense.bias', 'encoder.layer.0.attention.self.key.weight', 'encoder.layer.0.attention.self.value.weight', 'encoder.layer.5.attention.self.key.weight', 'encoder.layer.18.attention.self.key.weight', 'encoder.layer.7.attention.output.dense.bias', 'encoder.layer.9.attention.output.LayerNorm.bias', 'encoder.layer.10.attention.output.dense.weight', 'encoder.layer.15.output.dense.bias', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.11.output.dense.weight', 'encoder.layer.12.intermediate.dense.weight', 'encoder.layer.18.attention.output.dense.bias', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.23.intermediate.dense.weight', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.0.attention.output.dense.weight', 'encoder.layer.6.attention.output.LayerNorm.weight', 'encoder.layer.9.output.LayerNorm.weight', 'encoder.layer.15.output.dense.weight', 'encoder.layer.22.attention.output.dense.bias', 'encoder.layer.18.attention.self.key.bias', 'encoder.layer.12.attention.self.query.bias', 'encoder.layer.7.attention.output.dense.weight', 'encoder.layer.5.attention.output.dense.weight', 'encoder.layer.9.attention.self.query.weight', 'encoder.layer.11.attention.self.value.bias', 'encoder.layer.23.attention.self.key.weight', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.11.attention.output.dense.weight', 'embeddings.LayerNorm.bias', 'encoder.layer.11.output.LayerNorm.bias', 'encoder.layer.13.attention.self.key.bias', 'encoder.layer.8.attention.output.dense.bias', 'encoder.layer.17.output.dense.bias', 'encoder.layer.7.output.LayerNorm.bias', 'encoder.layer.4.attention.self.value.weight', 'encoder.layer.18.attention.output.LayerNorm.weight', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.23.attention.self.query.bias', 'encoder.layer.7.output.dense.bias', 'encoder.layer.2.attention.output.dense.weight', 'encoder.layer.20.attention.self.value.weight', 'embeddings.position_embeddings.weight', 'encoder.layer.20.output.dense.weight', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.15.intermediate.dense.bias', 'encoder.layer.8.attention.output.dense.weight', 'encoder.layer.6.output.LayerNorm.bias', 'encoder.layer.13.attention.output.LayerNorm.weight', 'encoder.layer.5.attention.output.dense.bias', 'encoder.layer.19.attention.output.dense.bias', 'encoder.layer.23.attention.self.query.weight', 'encoder.layer.8.attention.self.key.weight', 'encoder.layer.12.output.LayerNorm.weight', 'encoder.layer.21.intermediate.dense.bias', 'encoder.layer.4.attention.output.dense.bias', 'encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.layer.14.output.dense.weight', 'encoder.layer.22.output.LayerNorm.bias', 'encoder.layer.14.attention.self.value.bias', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.13.output.dense.weight', 'encoder.layer.16.output.LayerNorm.weight', 'encoder.layer.20.attention.self.key.weight', 'encoder.layer.17.attention.self.key.bias', 'encoder.layer.7.attention.self.value.weight', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.11.attention.self.value.weight', 'encoder.layer.14.output.LayerNorm.bias', 'encoder.layer.2.attention.self.query.weight', 'encoder.layer.14.attention.self.value.weight', 'encoder.layer.13.intermediate.dense.bias', 'encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.layer.12.attention.output.dense.bias', 'encoder.layer.14.attention.output.dense.bias', 'encoder.layer.7.attention.self.value.bias', 'encoder.layer.10.attention.self.value.weight', 'encoder.layer.18.attention.self.query.bias', 'encoder.layer.12.attention.self.key.bias', 'encoder.layer.19.attention.self.query.bias', 'encoder.layer.3.attention.self.value.weight', 'encoder.layer.19.attention.self.value.weight', 'encoder.layer.16.output.dense.bias', 'encoder.layer.2.attention.output.LayerNorm.weight', 'encoder.layer.3.attention.output.dense.bias', 'encoder.layer.18.intermediate.dense.weight', 'encoder.layer.8.output.LayerNorm.weight', 'encoder.layer.21.output.dense.weight', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.13.attention.self.key.weight', 'encoder.layer.1.attention.self.value.bias', 'encoder.layer.22.attention.self.value.bias', 'encoder.layer.10.attention.output.LayerNorm.weight', 'encoder.layer.8.attention.output.LayerNorm.weight', 'encoder.layer.21.attention.output.dense.weight', 'encoder.layer.20.attention.self.value.bias', 'encoder.layer.9.attention.self.key.bias', 'encoder.layer.23.output.LayerNorm.weight', 'encoder.layer.12.attention.output.LayerNorm.weight', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.16.attention.output.LayerNorm.bias', 'encoder.layer.10.attention.output.dense.bias', 'encoder.layer.5.output.LayerNorm.bias', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.17.intermediate.dense.weight', 'encoder.layer.23.attention.self.value.bias', 'encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.layer.1.attention.output.dense.bias', 'encoder.layer.22.intermediate.dense.bias', 'encoder.layer.8.attention.self.query.weight', 'encoder.layer.10.attention.self.key.weight', 'encoder.layer.8.attention.self.value.weight', 'encoder.layer.5.attention.self.key.bias', 'encoder.layer.13.attention.self.query.weight', 'encoder.layer.15.attention.output.dense.weight', 'encoder.layer.15.attention.output.LayerNorm.bias', 'encoder.layer.19.output.dense.bias', 'encoder.layer.17.intermediate.dense.bias', 'encoder.layer.3.attention.self.query.bias', 'encoder.layer.9.output.LayerNorm.bias', 'encoder.layer.10.output.dense.weight', 'encoder.layer.20.attention.output.LayerNorm.bias', 'encoder.layer.6.attention.self.query.bias', 'encoder.layer.5.output.dense.bias', 'encoder.layer.13.attention.output.LayerNorm.bias', 'encoder.layer.22.attention.output.LayerNorm.weight', 'encoder.layer.17.attention.output.dense.bias', 'encoder.layer.20.attention.self.query.weight', 'encoder.layer.23.output.LayerNorm.bias', 'encoder.layer.10.attention.self.value.bias', 'encoder.layer.3.attention.self.key.bias', 'encoder.layer.21.intermediate.dense.weight', 'encoder.layer.9.attention.self.value.weight', 'encoder.layer.23.attention.output.LayerNorm.weight', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.9.output.dense.weight', 'encoder.layer.7.attention.self.key.weight', 'encoder.layer.8.attention.output.LayerNorm.bias', 'encoder.layer.18.attention.self.query.weight', 'encoder.layer.3.attention.self.key.weight', 'encoder.layer.17.attention.self.query.weight', 'encoder.layer.22.attention.self.query.weight', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.11.attention.output.LayerNorm.weight', 'encoder.layer.12.attention.output.LayerNorm.bias', 'encoder.layer.10.output.LayerNorm.bias', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.18.attention.output.dense.weight', 'encoder.layer.14.attention.output.LayerNorm.bias', 'encoder.layer.15.attention.output.LayerNorm.weight', 'encoder.layer.11.output.dense.bias', 'encoder.layer.2.attention.self.key.bias', 'encoder.layer.2.attention.output.LayerNorm.bias', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.0.attention.output.LayerNorm.weight', 'encoder.layer.19.output.LayerNorm.weight', 'encoder.layer.14.intermediate.dense.bias', 'encoder.layer.6.attention.self.key.weight', 'encoder.layer.21.attention.self.key.weight', 'encoder.layer.22.attention.self.query.bias', 'encoder.layer.21.attention.self.key.bias', 'encoder.layer.20.output.dense.bias', 'encoder.layer.13.output.dense.bias', 'encoder.layer.21.output.dense.bias', 'encoder.layer.18.attention.output.LayerNorm.bias', 'encoder.layer.7.attention.output.LayerNorm.bias', 'encoder.layer.0.output.dense.bias', 'encoder.layer.6.output.dense.weight', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.20.attention.self.key.bias', 'encoder.layer.3.attention.output.dense.weight', 'encoder.layer.23.attention.output.dense.bias', 'encoder.layer.17.attention.self.query.bias', 'encoder.layer.15.output.LayerNorm.weight', 'encoder.layer.14.attention.self.query.bias', 'encoder.layer.9.output.dense.bias', 'encoder.layer.20.attention.self.query.bias', 'encoder.layer.20.output.LayerNorm.bias', 'encoder.layer.19.attention.self.query.weight', 'encoder.layer.4.attention.self.query.weight', 'encoder.layer.21.attention.self.value.bias', 'encoder.layer.1.attention.output.LayerNorm.weight', 'encoder.layer.10.output.LayerNorm.weight', 'encoder.layer.13.attention.output.dense.weight', 'encoder.layer.3.output.dense.bias', 'encoder.layer.12.attention.self.key.weight', 'encoder.layer.16.intermediate.dense.bias', 'encoder.layer.16.attention.self.query.bias', 'encoder.layer.14.attention.output.dense.weight', 'encoder.layer.0.output.dense.weight', 'encoder.layer.17.attention.self.value.weight', 'encoder.layer.22.intermediate.dense.weight', 'encoder.layer.3.attention.self.value.bias', 'encoder.layer.3.attention.self.query.weight', 'encoder.layer.19.attention.self.key.weight', 'encoder.layer.16.intermediate.dense.weight', 'encoder.layer.0.attention.output.dense.bias', 'encoder.layer.6.attention.self.key.bias', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.1.attention.self.key.bias', 'encoder.layer.22.attention.self.key.weight', 'encoder.layer.1.attention.self.query.bias', 'encoder.layer.5.attention.output.LayerNorm.weight', 'encoder.layer.2.attention.self.value.bias', 'encoder.layer.17.attention.output.LayerNorm.weight', 'pooler.dense.bias', 'encoder.layer.21.attention.self.query.weight', 'encoder.layer.0.attention.self.value.bias', 'encoder.layer.10.attention.self.key.bias', 'encoder.layer.10.attention.output.LayerNorm.bias', 'encoder.layer.11.attention.self.query.bias', 'encoder.layer.16.attention.output.LayerNorm.weight', 'encoder.layer.18.output.LayerNorm.bias', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.21.attention.self.value.weight', 'encoder.layer.19.output.dense.weight', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.17.attention.self.key.weight', 'encoder.layer.4.attention.output.dense.weight', 'encoder.layer.21.attention.output.LayerNorm.weight', 'encoder.layer.18.attention.self.value.weight', 'encoder.layer.15.attention.self.key.weight', 'encoder.layer.23.output.dense.weight', 'encoder.layer.7.attention.self.query.weight', 'encoder.layer.3.output.dense.weight', 'encoder.layer.11.attention.self.key.bias', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.9.attention.output.LayerNorm.weight', 'encoder.layer.22.output.dense.weight', 'encoder.layer.21.attention.self.query.bias', 'encoder.layer.11.attention.output.dense.bias', 'encoder.layer.7.output.LayerNorm.weight', 'encoder.layer.13.output.LayerNorm.bias', 'encoder.layer.8.attention.self.key.bias', 'encoder.layer.9.attention.output.dense.bias', 'encoder.layer.14.attention.self.key.bias', 'encoder.layer.17.attention.output.LayerNorm.bias', 'encoder.layer.16.output.dense.weight', 'encoder.layer.8.attention.self.query.bias', 'encoder.layer.9.attention.self.value.bias', 'encoder.layer.14.output.dense.bias', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.14.attention.self.key.weight', 'encoder.layer.6.attention.output.dense.bias', 'encoder.layer.9.attention.self.key.weight', 'encoder.layer.13.intermediate.dense.weight', 'encoder.layer.16.attention.output.dense.bias', 'encoder.layer.14.attention.self.query.weight', 'encoder.layer.23.attention.output.dense.weight', 'encoder.layer.0.attention.self.query.weight', 'encoder.layer.1.attention.output.dense.weight', 'encoder.layer.14.output.LayerNorm.weight', 'encoder.layer.12.attention.self.value.weight', 'embeddings.token_type_embeddings.weight', 'encoder.layer.1.attention.self.value.weight', 'encoder.layer.4.attention.self.key.weight', 'encoder.layer.6.attention.output.dense.weight', 'encoder.layer.0.attention.self.key.bias', 'encoder.layer.2.attention.self.query.bias', 'encoder.layer.23.attention.self.value.weight', 'encoder.layer.6.attention.output.LayerNorm.bias', 'encoder.layer.16.attention.self.key.bias', 'encoder.layer.4.attention.output.LayerNorm.bias', 'encoder.layer.23.attention.self.key.bias', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.9.attention.output.dense.weight', 'encoder.layer.19.attention.output.dense.weight', 'encoder.layer.17.attention.self.value.bias', 'encoder.layer.5.attention.self.query.bias', 'encoder.layer.15.attention.self.value.weight', 'encoder.layer.12.attention.self.value.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Overwriting existing adapter 'ep'.
Overwriting existing adapter 'tp'.
Overwriting existing adapter 'es'.
Overwriting existing adapter 'ts'.
Overwriting existing adapter fusion module 'ep,tp,es,ts'
05/09/2022 19:55:07 - INFO - __main__ -   Creating features from dataset file at .
/cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//squad/xlm-KG_LR4e-5_EPOCH2.0_maxlen384_batchsize4_gradacc8
XLMConfig {
  "architectures": [
    "XLMRobertaForMaskedLM"
  ],
  "asm": false,
  "attention_dropout": 0.1,
  "attention_probs_dropout_prob": 0.1,
  "bos_index": 0,
  "bos_token_id": 0,
  "causal": false,
  "dropout": 0.1,
  "emb_dim": 1024,
  "embed_init_std": 0.02209708691207961,
  "end_n_top": 5,
  "eos_index": 1,
  "eos_token_id": 2,
  "gelu_activation": true,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "init_std": 0.02,
  "initializer_range": 0.02,
  "intermediate_size": 4096,
  "is_encoder": true,
  "lang_id": 0,
  "layer_norm_eps": 1e-05,
  "mask_index": 5,
  "mask_token_id": 0,
  "max_position_embeddings": 514,
  "model_type": "xlm",
  "n_heads": 16,
  "n_langs": 1,
  "n_layers": 24,
  "output_past": true,
  "pad_index": 2,
  "pad_token_id": 1,
  "sinusoidal_embeddings": false,
  "start_n_top": 5,
  "summary_activation": null,
  "summary_first_dropout": 0.1,
  "summary_proj_to_labels": true,
  "summary_type": "first",
  "summary_use_proj": true,
  "transformers_version": "4.17.0",
  "type_vocab_size": 1,
  "unk_index": 3,
  "use_lang_emb": false,
  "vocab_size": 250002
}

  0%|          | 0/48 [00:00<?, ?it/s] 29%|██▉       | 14/48 [00:00<00:00, 133.53it/s] 58%|█████▊    | 28/48 [00:00<00:00, 99.56it/s]  81%|████████▏ | 39/48 [00:00<00:00, 102.43it/s]100%|██████████| 48/48 [00:00<00:00, 109.57it/s]
convert squad examples to features:   0%|          | 0/1190 [00:00<?, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.
convert squad examples to features:   0%|          | 1/1190 [00:00<03:12,  6.19it/s]convert squad examples to features:   5%|▌         | 65/1190 [00:00<00:04, 231.45it/s]convert squad examples to features:   8%|▊         | 97/1190 [00:00<00:04, 254.29it/s]convert squad examples to features:  14%|█▎        | 161/1190 [00:00<00:03, 316.15it/s]convert squad examples to features:  19%|█▉        | 225/1190 [00:00<00:02, 341.64it/s]convert squad examples to features:  22%|██▏       | 259/1190 [00:00<00:02, 326.54it/s]convert squad examples to features:  25%|██▍       | 292/1190 [00:00<00:02, 313.89it/s]convert squad examples to features:  27%|██▋       | 323/1190 [00:01<00:02, 293.54it/s]convert squad examples to features:  30%|██▉       | 353/1190 [00:01<00:02, 285.36it/s]convert squad examples to features:  32%|███▏      | 385/1190 [00:01<00:05, 150.18it/s]convert squad examples to features:  35%|███▌      | 417/1190 [00:01<00:04, 172.09it/s]convert squad examples to features:  38%|███▊      | 449/1190 [00:01<00:04, 179.02it/s]convert squad examples to features:  40%|████      | 481/1190 [00:02<00:03, 193.94it/s]convert squad examples to features:  43%|████▎     | 513/1190 [00:02<00:03, 207.65it/s]convert squad examples to features:  46%|████▌     | 545/1190 [00:02<00:03, 199.50it/s]convert squad examples to features:  48%|████▊     | 577/1190 [00:02<00:02, 207.81it/s]convert squad examples to features:  51%|█████     | 609/1190 [00:02<00:02, 209.37it/s]convert squad examples to features:  54%|█████▍    | 641/1190 [00:02<00:02, 208.24it/s]convert squad examples to features:  57%|█████▋    | 673/1190 [00:03<00:02, 202.74it/s]convert squad examples to features:  59%|█████▉    | 705/1190 [00:03<00:02, 220.50it/s]convert squad examples to features:  62%|██████▏   | 737/1190 [00:03<00:02, 219.26it/s]convert squad examples to features:  67%|██████▋   | 801/1190 [00:03<00:01, 263.45it/s]convert squad examples to features:  70%|███████   | 833/1190 [00:03<00:01, 245.64it/s]convert squad examples to features:  73%|███████▎  | 865/1190 [00:03<00:01, 241.30it/s]convert squad examples to features:  75%|███████▌  | 897/1190 [00:03<00:01, 234.78it/s]convert squad examples to features:  78%|███████▊  | 929/1190 [00:04<00:01, 235.39it/s]convert squad examples to features:  81%|████████  | 961/1190 [00:04<00:00, 242.68it/s]convert squad examples to features:  83%|████████▎ | 993/1190 [00:04<00:00, 258.57it/s]convert squad examples to features:  86%|████████▌ | 1025/1190 [00:04<00:00, 265.38it/s]convert squad examples to features:  89%|████████▉ | 1057/1190 [00:04<00:00, 262.36it/s]convert squad examples to features:  92%|█████████▏| 1089/1190 [00:04<00:00, 253.11it/s]convert squad examples to features:  94%|█████████▍| 1121/1190 [00:04<00:00, 259.42it/s]convert squad examples to features:  97%|█████████▋| 1153/1190 [00:04<00:00, 245.94it/s]convert squad examples to features: 100%|██████████| 1190/1190 [00:04<00:00, 241.22it/s]/cluster/project/sachan/yifan/softwares/anaconda/anaconda3/envs/xfactr/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2272: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

add example index and unique id:   0%|          | 0/1190 [00:00<?, ?it/s]add example index and unique id: 100%|██████████| 1190/1190 [00:00<00:00, 898671.54it/s]
05/09/2022 19:55:12 - INFO - __main__ -   Saving features into cached file ./cached_xquad.de.json_xlm-KG_LR4e-5_EPOCH2.0_maxlen384_batchsize4_gradacc8_384_de
05/09/2022 19:55:13 - INFO - __main__ -   ***** Running evaluation  *****
05/09/2022 19:55:13 - INFO - __main__ -     Num examples = 1303
05/09/2022 19:55:13 - INFO - __main__ -     Batch size = 8
Evaluating:   0%|          | 0/163 [00:00<?, ?it/s]Evaluating:   1%|          | 1/163 [00:00<02:07,  1.27it/s]Evaluating:   1%|          | 2/163 [00:01<01:25,  1.88it/s]Evaluating:   2%|▏         | 3/163 [00:01<01:12,  2.21it/s]Evaluating:   2%|▏         | 4/163 [00:01<01:05,  2.42it/s]Evaluating:   3%|▎         | 5/163 [00:02<01:01,  2.56it/s]Evaluating:   4%|▎         | 6/163 [00:02<00:59,  2.64it/s]Evaluating:   4%|▍         | 7/163 [00:02<00:57,  2.71it/s]Evaluating:   5%|▍         | 8/163 [00:03<00:56,  2.74it/s]Evaluating:   6%|▌         | 9/163 [00:03<00:55,  2.75it/s]Evaluating:   6%|▌         | 10/163 [00:03<00:55,  2.77it/s]Evaluating:   7%|▋         | 11/163 [00:04<00:54,  2.79it/s]Evaluating:   7%|▋         | 12/163 [00:04<00:54,  2.79it/s]Evaluating:   8%|▊         | 13/163 [00:05<00:53,  2.80it/s]Evaluating:   9%|▊         | 14/163 [00:05<00:53,  2.80it/s]Evaluating:   9%|▉         | 15/163 [00:05<00:52,  2.80it/s]Evaluating:  10%|▉         | 16/163 [00:06<00:52,  2.80it/s]Evaluating:  10%|█         | 17/163 [00:06<00:52,  2.80it/s]Evaluating:  11%|█         | 18/163 [00:06<00:51,  2.81it/s]Evaluating:  12%|█▏        | 19/163 [00:07<00:51,  2.81it/s]Evaluating:  12%|█▏        | 20/163 [00:07<00:50,  2.82it/s]Evaluating:  13%|█▎        | 21/163 [00:07<00:50,  2.82it/s]Evaluating:  13%|█▎        | 22/163 [00:08<00:49,  2.83it/s]Evaluating:  14%|█▍        | 23/163 [00:08<00:49,  2.83it/s]Evaluating:  15%|█▍        | 24/163 [00:08<00:49,  2.78it/s]Evaluating:  15%|█▌        | 25/163 [00:09<00:49,  2.79it/s]Evaluating:  16%|█▌        | 26/163 [00:09<00:48,  2.80it/s]Evaluating:  17%|█▋        | 27/163 [00:10<00:48,  2.80it/s]Evaluating:  17%|█▋        | 28/163 [00:10<00:48,  2.81it/s]Evaluating:  18%|█▊        | 29/163 [00:10<00:47,  2.81it/s]Evaluating:  18%|█▊        | 30/163 [00:11<00:47,  2.81it/s]Evaluating:  19%|█▉        | 31/163 [00:11<00:46,  2.81it/s]Evaluating:  20%|█▉        | 32/163 [00:11<00:46,  2.80it/s]Evaluating:  20%|██        | 33/163 [00:12<00:46,  2.80it/s]Evaluating:  21%|██        | 34/163 [00:12<00:46,  2.80it/s]Evaluating:  21%|██▏       | 35/163 [00:12<00:45,  2.79it/s]Evaluating:  22%|██▏       | 36/163 [00:13<00:45,  2.80it/s]Evaluating:  23%|██▎       | 37/163 [00:13<00:45,  2.79it/s]Evaluating:  23%|██▎       | 38/163 [00:13<00:44,  2.79it/s]Evaluating:  24%|██▍       | 39/163 [00:14<00:44,  2.79it/s]Evaluating:  25%|██▍       | 40/163 [00:14<00:44,  2.79it/s]Evaluating:  25%|██▌       | 41/163 [00:15<00:43,  2.78it/s]Evaluating:  26%|██▌       | 42/163 [00:15<00:43,  2.79it/s]Evaluating:  26%|██▋       | 43/163 [00:15<00:43,  2.79it/s]Evaluating:  27%|██▋       | 44/163 [00:16<00:42,  2.80it/s]Evaluating:  28%|██▊       | 45/163 [00:16<00:42,  2.80it/s]Evaluating:  28%|██▊       | 46/163 [00:16<00:41,  2.80it/s]Evaluating:  29%|██▉       | 47/163 [00:17<00:41,  2.80it/s]Evaluating:  29%|██▉       | 48/163 [00:17<00:41,  2.77it/s]Evaluating:  30%|███       | 49/163 [00:17<00:40,  2.78it/s]Evaluating:  31%|███       | 50/163 [00:18<00:40,  2.78it/s]Evaluating:  31%|███▏      | 51/163 [00:18<00:40,  2.76it/s]Evaluating:  32%|███▏      | 52/163 [00:19<00:40,  2.73it/s]Evaluating:  33%|███▎      | 53/163 [00:19<00:40,  2.72it/s]Evaluating:  33%|███▎      | 54/163 [00:19<00:39,  2.73it/s]Evaluating:  34%|███▎      | 55/163 [00:20<00:39,  2.74it/s]Evaluating:  34%|███▍      | 56/163 [00:20<00:39,  2.71it/s]Evaluating:  35%|███▍      | 57/163 [00:20<00:39,  2.72it/s]Evaluating:  36%|███▌      | 58/163 [00:21<00:38,  2.74it/s]Evaluating:  36%|███▌      | 59/163 [00:21<00:37,  2.75it/s]Evaluating:  37%|███▋      | 60/163 [00:21<00:37,  2.74it/s]Evaluating:  37%|███▋      | 61/163 [00:22<00:37,  2.74it/s]Evaluating:  38%|███▊      | 62/163 [00:22<00:37,  2.66it/s]Evaluating:  39%|███▊      | 63/163 [00:23<00:39,  2.56it/s]Evaluating:  39%|███▉      | 64/163 [00:23<00:40,  2.45it/s]Evaluating:  40%|███▉      | 65/163 [00:23<00:39,  2.46it/s]Evaluating:  40%|████      | 66/163 [00:24<00:38,  2.55it/s]Evaluating:  41%|████      | 67/163 [00:24<00:37,  2.53it/s]Evaluating:  42%|████▏     | 68/163 [00:25<00:38,  2.45it/s]Evaluating:  42%|████▏     | 69/163 [00:25<00:38,  2.41it/s]Evaluating:  43%|████▎     | 70/163 [00:25<00:37,  2.47it/s]Evaluating:  44%|████▎     | 71/163 [00:26<00:36,  2.50it/s]Evaluating:  44%|████▍     | 72/163 [00:26<00:36,  2.50it/s]Evaluating:  45%|████▍     | 73/163 [00:27<00:36,  2.47it/s]Evaluating:  45%|████▌     | 74/163 [00:27<00:35,  2.50it/s]Evaluating:  46%|████▌     | 75/163 [00:28<00:37,  2.35it/s]Evaluating:  47%|████▋     | 76/163 [00:28<00:36,  2.36it/s]Evaluating:  47%|████▋     | 77/163 [00:28<00:36,  2.38it/s]Evaluating:  48%|████▊     | 78/163 [00:29<00:34,  2.46it/s]Evaluating:  48%|████▊     | 79/163 [00:29<00:34,  2.44it/s]Evaluating:  49%|████▉     | 80/163 [00:30<00:34,  2.37it/s]Evaluating:  50%|████▉     | 81/163 [00:30<00:33,  2.42it/s]Evaluating:  50%|█████     | 82/163 [00:30<00:32,  2.46it/s]Evaluating:  51%|█████     | 83/163 [00:31<00:31,  2.54it/s]Evaluating:  52%|█████▏    | 84/163 [00:31<00:30,  2.61it/s]Evaluating:  52%|█████▏    | 85/163 [00:32<00:30,  2.60it/s]Evaluating:  53%|█████▎    | 86/163 [00:32<00:29,  2.60it/s]Evaluating:  53%|█████▎    | 87/163 [00:32<00:29,  2.57it/s]Evaluating:  54%|█████▍    | 88/163 [00:33<00:28,  2.60it/s]Evaluating:  55%|█████▍    | 89/163 [00:33<00:27,  2.65it/s]Evaluating:  55%|█████▌    | 90/163 [00:33<00:27,  2.69it/s]Evaluating:  56%|█████▌    | 91/163 [00:34<00:27,  2.63it/s]Evaluating:  56%|█████▋    | 92/163 [00:34<00:27,  2.59it/s]Evaluating:  57%|█████▋    | 93/163 [00:35<00:27,  2.51it/s]Evaluating:  58%|█████▊    | 94/163 [00:35<00:27,  2.54it/s]Evaluating:  58%|█████▊    | 95/163 [00:35<00:26,  2.60it/s]Evaluating:  59%|█████▉    | 96/163 [00:36<00:25,  2.61it/s]Evaluating:  60%|█████▉    | 97/163 [00:36<00:24,  2.66it/s]Evaluating:  60%|██████    | 98/163 [00:36<00:24,  2.69it/s]Evaluating:  61%|██████    | 99/163 [00:37<00:23,  2.72it/s]Evaluating:  61%|██████▏   | 100/163 [00:37<00:23,  2.74it/s]Evaluating:  62%|██████▏   | 101/163 [00:38<00:22,  2.75it/s]Evaluating:  63%|██████▎   | 102/163 [00:38<00:22,  2.76it/s]Evaluating:  63%|██████▎   | 103/163 [00:38<00:21,  2.76it/s]Evaluating:  64%|██████▍   | 104/163 [00:39<00:21,  2.77it/s]Evaluating:  64%|██████▍   | 105/163 [00:39<00:20,  2.77it/s]Evaluating:  65%|██████▌   | 106/163 [00:39<00:20,  2.77it/s]Evaluating:  66%|██████▌   | 107/163 [00:40<00:20,  2.71it/s]Evaluating:  66%|██████▋   | 108/163 [00:40<00:20,  2.74it/s]Evaluating:  67%|██████▋   | 109/163 [00:40<00:19,  2.75it/s]Evaluating:  67%|██████▋   | 110/163 [00:41<00:19,  2.75it/s]Evaluating:  68%|██████▊   | 111/163 [00:41<00:18,  2.77it/s]Evaluating:  69%|██████▊   | 112/163 [00:42<00:18,  2.77it/s]Evaluating:  69%|██████▉   | 113/163 [00:42<00:18,  2.69it/s]Evaluating:  70%|██████▉   | 114/163 [00:42<00:18,  2.72it/s]Evaluating:  71%|███████   | 115/163 [00:43<00:17,  2.74it/s]Evaluating:  71%|███████   | 116/163 [00:43<00:17,  2.76it/s]Evaluating:  72%|███████▏  | 117/163 [00:43<00:16,  2.77it/s]Evaluating:  72%|███████▏  | 118/163 [00:44<00:16,  2.77it/s]Evaluating:  73%|███████▎  | 119/163 [00:44<00:15,  2.78it/s]Evaluating:  74%|███████▎  | 120/163 [00:44<00:15,  2.78it/s]Evaluating:  74%|███████▍  | 121/163 [00:45<00:15,  2.78it/s]Evaluating:  75%|███████▍  | 122/163 [00:45<00:14,  2.78it/s]Evaluating:  75%|███████▌  | 123/163 [00:46<00:14,  2.78it/s]Evaluating:  76%|███████▌  | 124/163 [00:46<00:13,  2.79it/s]Evaluating:  77%|███████▋  | 125/163 [00:46<00:13,  2.79it/s]Evaluating:  77%|███████▋  | 126/163 [00:47<00:13,  2.79it/s]Evaluating:  78%|███████▊  | 127/163 [00:47<00:12,  2.79it/s]Evaluating:  79%|███████▊  | 128/163 [00:47<00:12,  2.78it/s]Evaluating:  79%|███████▉  | 129/163 [00:48<00:12,  2.78it/s]Evaluating:  80%|███████▉  | 130/163 [00:48<00:11,  2.78it/s]Evaluating:  80%|████████  | 131/163 [00:48<00:11,  2.78it/s]Evaluating:  81%|████████  | 132/163 [00:49<00:11,  2.79it/s]Evaluating:  82%|████████▏ | 133/163 [00:49<00:10,  2.80it/s]Evaluating:  82%|████████▏ | 134/163 [00:49<00:10,  2.80it/s]Evaluating:  83%|████████▎ | 135/163 [00:50<00:10,  2.80it/s]Evaluating:  83%|████████▎ | 136/163 [00:50<00:09,  2.80it/s]Evaluating:  84%|████████▍ | 137/163 [00:51<00:09,  2.80it/s]Evaluating:  85%|████████▍ | 138/163 [00:51<00:08,  2.79it/s]Evaluating:  85%|████████▌ | 139/163 [00:51<00:08,  2.80it/s]Evaluating:  86%|████████▌ | 140/163 [00:52<00:08,  2.80it/s]Evaluating:  87%|████████▋ | 141/163 [00:52<00:07,  2.80it/s]Evaluating:  87%|████████▋ | 142/163 [00:52<00:07,  2.80it/s]Evaluating:  88%|████████▊ | 143/163 [00:53<00:07,  2.80it/s]Evaluating:  88%|████████▊ | 144/163 [00:53<00:06,  2.80it/s]Evaluating:  89%|████████▉ | 145/163 [00:53<00:06,  2.80it/s]Evaluating:  90%|████████▉ | 146/163 [00:54<00:06,  2.80it/s]Evaluating:  90%|█████████ | 147/163 [00:54<00:05,  2.80it/s]Evaluating:  91%|█████████ | 148/163 [00:54<00:05,  2.79it/s]Evaluating:  91%|█████████▏| 149/163 [00:55<00:05,  2.79it/s]Evaluating:  92%|█████████▏| 150/163 [00:55<00:04,  2.79it/s]Evaluating:  93%|█████████▎| 151/163 [00:56<00:04,  2.79it/s]Evaluating:  93%|█████████▎| 152/163 [00:56<00:03,  2.79it/s]Evaluating:  94%|█████████▍| 153/163 [00:56<00:03,  2.80it/s]Evaluating:  94%|█████████▍| 154/163 [00:57<00:03,  2.79it/s]Evaluating:  95%|█████████▌| 155/163 [00:57<00:02,  2.79it/s]Evaluating:  96%|█████████▌| 156/163 [00:57<00:02,  2.79it/s]Evaluating:  96%|█████████▋| 157/163 [00:58<00:02,  2.79it/s]Evaluating:  97%|█████████▋| 158/163 [00:58<00:01,  2.79it/s]Evaluating:  98%|█████████▊| 159/163 [00:58<00:01,  2.79it/s]Evaluating:  98%|█████████▊| 160/163 [00:59<00:01,  2.79it/s]Evaluating:  99%|█████████▉| 161/163 [00:59<00:00,  2.78it/s]Evaluating:  99%|█████████▉| 162/163 [01:00<00:00,  2.76it/s]Evaluating: 100%|██████████| 163/163 [01:00<00:00,  2.85it/s]Evaluating: 100%|██████████| 163/163 [01:00<00:00,  2.70it/s]
05/09/2022 19:56:14 - INFO - __main__ -     Evaluation done in total 60.342718 secs (0.046311 sec per example)
05/09/2022 19:56:17 - INFO - __main__ -   Results: {'exact': 65.04201680672269, 'f1': 80.77852980331383, 'total': 1190, 'HasAns_exact': 65.04201680672269, 'HasAns_f1': 80.77852980331383, 'HasAns_total': 1190, 'best_exact': 65.04201680672269, 'best_exact_thresh': 0.0, 'best_f1': 80.77852980331383, 'best_f1_thresh': 0.0}
  el 
2022-05-09 19:56:23.184133: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0
05/09/2022 19:56:40 - WARNING - __main__ -   Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, 16-bits training: False
You are using a model of type xlm-roberta to instantiate a model of type xlm. This is not supported for all configurations of models and can yield errors.
Some weights of the model checkpoint at /cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//squad/xlm-KG_LR4e-5_EPOCH2.0_maxlen384_batchsize4_gradacc8 were not used when initializing XLMRobertaModel: ['base_model.encoder.layer.14.attention.self.value.weight', 'base_model.encoder.layer.7.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.23.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.18.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.11.attention.self.value.weight', 'base_model.encoder.layer.22.intermediate.dense.bias', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.1.output.dense.weight', 'base_model.encoder.layer.18.attention.self.value.bias', 'base_model.encoder.layer.5.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.5.attention.output.LayerNorm.bias', 'base_model.encoder.layer.13.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.21.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.22.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.12.attention.output.dense.bias', 'base_model.encoder.layer.22.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.6.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.8.intermediate.dense.weight', 'base_model.encoder.layer.11.attention.self.key.bias', 'base_model.encoder.layer.22.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.17.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.7.intermediate.dense.bias', 'base_model.encoder.layer.9.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.14.output.LayerNorm.bias', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.6.attention.self.value.bias', 'base_model.encoder.layer.10.attention.self.query.bias', 'base_model.encoder.layer.16.attention.self.query.weight', 'base_model.encoder.layer.19.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.16.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.0.attention.self.query.weight', 'base_model.encoder.layer.20.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.19.attention.output.dense.weight', 'base_model.encoder.layer.7.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.12.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.22.attention.output.dense.weight', 'base_model.encoder.layer.14.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.2.attention.self.value.bias', 'base_model.encoder.layer.1.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.5.output.LayerNorm.bias', 'base_model.encoder.layer.23.intermediate.dense.weight', 'base_model.encoder.layer.21.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.1.attention.output.dense.weight', 'base_model.encoder.layer.17.attention.self.value.bias', 'base_model.encoder.layer.6.attention.self.query.bias', 'base_model.encoder.layer.9.attention.output.LayerNorm.bias', 'base_model.encoder.layer.4.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.23.intermediate.dense.bias', 'base_model.encoder.layer.8.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.6.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.8.output.dense.weight', 'base_model.encoder.layer.15.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.18.attention.self.query.weight', 'base_model.encoder.layer.23.output.LayerNorm.bias', 'base_model.encoder.layer.4.attention.self.query.weight', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.16.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.21.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.4.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.4.intermediate.dense.weight', 'base_model.encoder.layer.5.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.6.attention.self.value.weight', 'base_model.encoder.layer.1.output.LayerNorm.weight', 'base_model.encoder.layer.1.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.11.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.16.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.22.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.19.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.6.attention.self.query.weight', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.6.output.dense.weight', 'base_model.encoder.layer.7.attention.self.key.bias', 'base_model.encoder.layer.21.output.LayerNorm.weight', 'base_model.encoder.layer.16.attention.self.query.bias', 'base_model.encoder.layer.13.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.14.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.1.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.10.output.dense.weight', 'base_model.encoder.layer.18.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.11.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.20.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.21.attention.output.LayerNorm.weight', 'base_model.encoder.layer.13.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.21.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.23.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.8.output.LayerNorm.bias', 'base_model.embeddings.word_embeddings.weight', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.9.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.0.attention.self.key.weight', 'base_model.encoder.layer.11.attention.self.query.bias', 'base_model.encoder.layer.8.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.18.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.5.attention.output.dense.weight', 'base_model.encoder.layer.11.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.11.attention.output.dense.weight', 'base_model.encoder.layer.3.output.dense.bias', 'base_model.encoder.layer.13.attention.self.key.weight', 'base_model.encoder.layer.8.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.12.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.2.output.dense.weight', 'base_model.encoder.layer.3.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.19.output.LayerNorm.bias', 'base_model.encoder.layer.3.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.6.attention.self.key.bias', 'base_model.encoder.layer.16.output.dense.bias', 'base_model.encoder.layer.23.attention.output.dense.bias', 'base_model.encoder.layer.2.attention.output.dense.bias', 'base_model.encoder.layer.23.attention.output.dense.weight', 'base_model.encoder.layer.23.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.5.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.15.attention.output.dense.weight', 'base_model.encoder.layer.13.attention.self.value.weight', 'base_model.encoder.layer.17.attention.output.LayerNorm.bias', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.14.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.17.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.17.attention.output.dense.bias', 'base_model.encoder.layer.18.attention.output.LayerNorm.weight', 'base_model.encoder.layer.6.attention.output.LayerNorm.weight', 'base_model.encoder.layer.1.output.dense.bias', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.6.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.9.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.13.output.LayerNorm.bias', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.9.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.12.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.10.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.12.attention.self.query.weight', 'base_model.encoder.layer.12.intermediate.dense.weight', 'base_model.encoder.layer.11.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.15.intermediate.dense.bias', 'base_model.encoder.layer.0.attention.output.LayerNorm.weight', 'base_model.encoder.layer.9.output.dense.weight', 'base_model.encoder.layer.1.attention.self.key.weight', 'base_model.encoder.layer.21.intermediate.dense.weight', 'base_model.encoder.layer.11.attention.output.dense.bias', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.13.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.6.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.14.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.3.intermediate.dense.bias', 'base_model.encoder.layer.1.attention.self.query.weight', 'base_model.encoder.layer.17.intermediate.dense.weight', 'base_model.encoder.layer.16.intermediate.dense.weight', 'base_model.encoder.layer.11.attention.self.query.weight', 'base_model.encoder.layer.23.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.1.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.5.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.15.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.0.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.7.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.2.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.18.attention.output.dense.bias', 'base_model.encoder.layer.21.attention.self.query.bias', 'base_model.encoder.layer.1.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.3.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.9.output.LayerNorm.bias', 'base_model.encoder.layer.20.intermediate.dense.weight', 'base_model.encoder.layer.20.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.3.attention.self.key.bias', 'base_model.encoder.layer.4.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.4.attention.output.LayerNorm.weight', 'base_model.encoder.layer.4.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.18.output.LayerNorm.bias', 'base_model.encoder.layer.21.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.6.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.8.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.15.attention.self.query.bias', 'base_model.encoder.layer.3.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.4.attention.self.key.bias', 'base_model.encoder.layer.5.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.17.attention.output.dense.weight', 'base_model.encoder.layer.21.attention.self.key.weight', 'base_model.encoder.layer.7.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.4.attention.self.key.weight', 'base_model.encoder.layer.17.intermediate.dense.bias', 'base_model.encoder.layer.17.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.22.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.5.attention.self.query.weight', 'base_model.encoder.layer.4.attention.self.value.weight', 'base_model.encoder.layer.12.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.10.output.LayerNorm.bias', 'base_model.encoder.layer.20.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.21.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.10.intermediate.dense.bias', 'base_model.encoder.layer.23.attention.self.value.bias', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.12.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.19.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.7.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.7.attention.output.LayerNorm.bias', 'base_model.encoder.layer.0.output.dense.bias', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.11.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.23.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.10.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.4.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.13.output.dense.weight', 'base_model.encoder.layer.16.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.18.attention.self.value.weight', 'base_model.encoder.layer.7.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.2.output.dense.bias', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.11.output.LayerNorm.bias', 'base_model.encoder.layer.23.output.LayerNorm.weight', 'base_model.encoder.layer.15.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.0.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.20.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.14.output.adapters.ep.adapter_up.weight', 'qa_outputs.bias', 'base_model.encoder.layer.10.attention.self.value.weight', 'base_model.encoder.layer.18.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.22.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.2.attention.self.key.weight', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.6.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.7.attention.output.dense.weight', 'base_model.encoder.layer.12.attention.self.value.weight', 'base_model.encoder.layer.12.output.LayerNorm.bias', 'base_model.encoder.layer.12.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.0.attention.output.LayerNorm.bias', 'base_model.encoder.layer.19.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.16.attention.output.LayerNorm.weight', 'base_model.encoder.layer.14.attention.self.value.bias', 'base_model.encoder.layer.6.attention.output.dense.weight', 'base_model.encoder.layer.8.attention.output.LayerNorm.bias', 'base_model.encoder.layer.17.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.21.attention.self.value.bias', 'base_model.encoder.layer.19.attention.self.key.bias', 'base_model.encoder.layer.9.output.dense.bias', 'base_model.encoder.layer.11.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.10.output.dense.bias', 'base_model.encoder.layer.4.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.5.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.6.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.15.output.LayerNorm.bias', 'base_model.encoder.layer.3.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.19.output.LayerNorm.weight', 'base_model.encoder.layer.5.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.10.attention.self.query.weight', 'base_model.encoder.layer.23.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.8.output.dense.bias', 'base_model.encoder.layer.13.output.LayerNorm.weight', 'base_model.encoder.layer.23.attention.output.LayerNorm.bias', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.11.output.dense.bias', 'base_model.encoder.layer.13.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.17.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.7.attention.output.LayerNorm.weight', 'base_model.encoder.layer.1.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.13.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.18.attention.self.key.weight', 'base_model.encoder.layer.8.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.5.output.dense.bias', 'base_model.encoder.layer.20.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.23.attention.self.key.bias', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.22.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.8.attention.output.dense.bias', 'base_model.encoder.layer.23.output.dense.weight', 'base_model.encoder.layer.14.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.15.attention.self.query.weight', 'base_model.encoder.layer.18.attention.output.LayerNorm.bias', 'base_model.encoder.layer.13.attention.self.query.bias', 'base_model.encoder.layer.10.attention.self.key.weight', 'base_model.encoder.layer.16.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.17.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.9.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.22.intermediate.dense.weight', 'base_model.encoder.layer.10.attention.output.dense.weight', 'base_model.encoder.layer.4.output.LayerNorm.weight', 'base_model.encoder.layer.12.attention.output.LayerNorm.bias', 'base_model.encoder.layer.8.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.3.attention.output.LayerNorm.bias', 'base_model.encoder.layer.12.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.21.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.3.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.4.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.7.attention.self.value.bias', 'base_model.encoder.layer.14.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.0.output.LayerNorm.weight', 'base_model.encoder.layer.1.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.2.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.16.attention.output.dense.bias', 'base_model.encoder.layer.23.attention.self.query.weight', 'base_model.encoder.layer.15.attention.self.key.weight', 'base_model.encoder.layer.12.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.13.attention.self.key.bias', 'base_model.encoder.layer.5.attention.output.dense.bias', 'base_model.encoder.layer.0.output.dense.weight', 'base_model.encoder.layer.19.attention.self.key.weight', 'base_model.encoder.layer.11.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.5.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.23.attention.self.query.bias', 'base_model.encoder.layer.7.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.9.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.22.attention.self.query.weight', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.4.attention.output.dense.weight', 'base_model.encoder.layer.10.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.16.output.LayerNorm.weight', 'base_model.encoder.layer.21.intermediate.dense.bias', 'base_model.encoder.layer.19.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.2.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.20.attention.self.key.weight', 'base_model.encoder.layer.3.intermediate.dense.weight', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.11.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.8.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.5.attention.output.LayerNorm.weight', 'base_model.encoder.layer.3.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.3.attention.self.query.weight', 'base_model.encoder.layer.10.attention.self.key.bias', 'base_model.encoder.layer.11.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.16.attention.output.LayerNorm.bias', 'base_model.encoder.layer.20.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.0.attention.self.query.bias', 'base_model.encoder.layer.9.attention.self.query.bias', 'base_model.encoder.layer.10.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.23.attention.self.value.weight', 'base_model.encoder.layer.7.attention.self.value.weight', 'base_model.encoder.layer.12.attention.self.key.weight', 'base_model.encoder.layer.13.attention.self.query.weight', 'base_model.encoder.layer.21.attention.output.dense.bias', 'base_model.encoder.layer.9.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.12.attention.output.LayerNorm.weight', 'base_model.encoder.layer.14.intermediate.dense.weight', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.2.attention.output.dense.weight', 'base_model.encoder.layer.1.attention.output.dense.bias', 'base_model.encoder.layer.11.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.10.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.17.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.0.attention.output.dense.weight', 'base_model.encoder.layer.11.output.LayerNorm.weight', 'base_model.encoder.layer.20.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.3.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.17.output.LayerNorm.bias', 'base_model.encoder.layer.12.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.23.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.23.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.3.attention.output.dense.bias', 'base_model.encoder.layer.13.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.19.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.5.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.4.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.8.attention.self.query.bias', 'base_model.pooler.dense.bias', 'base_model.encoder.layer.14.output.LayerNorm.weight', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.2.output.LayerNorm.weight', 'base_model.encoder.layer.11.output.dense.weight', 'base_model.encoder.layer.16.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.16.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.20.attention.self.value.bias', 'base_model.encoder.layer.9.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.14.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.14.attention.self.query.weight', 'base_model.encoder.layer.21.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.17.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.19.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.23.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.18.output.dense.bias', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.1.intermediate.dense.weight', 'base_model.encoder.layer.15.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.9.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.0.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.22.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.2.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.15.intermediate.dense.weight', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.17.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.18.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.9.attention.self.key.bias', 'base_model.encoder.layer.3.attention.output.LayerNorm.weight', 'base_model.encoder.layer.22.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.10.output.LayerNorm.weight', 'base_model.encoder.layer.16.attention.self.key.weight', 'base_model.encoder.layer.21.output.LayerNorm.bias', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.21.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.14.intermediate.dense.bias', 'base_model.encoder.layer.8.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.2.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.4.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.19.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.7.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.13.intermediate.dense.weight', 'base_model.encoder.layer.14.output.adapters.tp.adapter_up.weight', 'base_model.embeddings.position_embeddings.weight', 'base_model.encoder.layer.18.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.11.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.10.intermediate.dense.weight', 'base_model.encoder.layer.10.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.18.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.5.attention.self.value.bias', 'base_model.encoder.layer.1.attention.self.value.weight', 'base_model.encoder.layer.19.attention.self.query.bias', 'base_model.encoder.layer.2.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.14.attention.self.query.bias', 'base_model.encoder.layer.22.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.8.attention.self.key.bias', 'base_model.encoder.layer.7.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.2.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.6.intermediate.dense.weight', 'base_model.encoder.layer.10.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.2.attention.self.query.weight', 'base_model.encoder.layer.17.attention.self.query.weight', 'base_model.encoder.layer.10.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.3.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.2.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.7.attention.self.query.weight', 'base_model.encoder.layer.13.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.11.attention.self.value.bias', 'base_model.encoder.layer.10.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.18.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.3.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.5.attention.self.value.weight', 'base_model.encoder.layer.17.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.13.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.15.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.3.output.dense.weight', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.2.attention.self.query.bias', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.6.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.19.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.7.output.dense.weight', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.18.output.LayerNorm.weight', 'base_model.encoder.layer.5.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.15.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.15.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.18.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.15.attention.output.LayerNorm.weight', 'base_model.encoder.layer.17.attention.output.LayerNorm.weight', 'base_model.encoder.layer.2.attention.output.LayerNorm.weight', 'base_model.encoder.layer.0.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.19.attention.self.query.weight', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.embeddings.LayerNorm.bias', 'base_model.encoder.layer.15.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.8.attention.self.value.bias', 'base_model.encoder.layer.19.intermediate.dense.weight', 'base_model.encoder.layer.21.attention.output.dense.weight', 'base_model.encoder.layer.2.attention.output.LayerNorm.bias', 'base_model.encoder.layer.23.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.4.attention.output.LayerNorm.bias', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.19.attention.output.LayerNorm.weight', 'base_model.encoder.layer.20.attention.output.LayerNorm.weight', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.22.attention.self.key.weight', 'base_model.encoder.layer.9.intermediate.dense.bias', 'base_model.encoder.layer.3.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.11.attention.self.key.weight', 'base_model.encoder.layer.5.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.4.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.0.attention.self.key.bias', 'base_model.encoder.layer.13.attention.output.dense.bias', 'base_model.encoder.layer.20.output.LayerNorm.bias', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.22.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.11.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.3.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.3.attention.self.query.bias', 'base_model.encoder.layer.20.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.15.output.LayerNorm.weight', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.0.attention.self.value.bias', 'base_model.encoder.layer.7.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.17.output.dense.weight', 'base_model.encoder.layer.20.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.14.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.21.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.2.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.16.attention.self.value.weight', 'base_model.encoder.layer.23.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.18.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.20.intermediate.dense.bias', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.12.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.12.attention.output.dense.weight', 'base_model.encoder.layer.19.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.6.attention.self.key.weight', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.6.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.12.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.2.intermediate.dense.bias', 'base_model.encoder.layer.3.attention.self.value.bias', 'base_model.encoder.layer.14.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.embeddings.token_type_embeddings.weight', 'base_model.encoder.layer.2.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.14.output.dense.weight', 'base_model.encoder.layer.0.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.1.output.LayerNorm.bias', 'base_model.encoder.layer.5.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.20.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.7.output.dense.bias', 'base_model.encoder.layer.1.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.14.attention.output.LayerNorm.bias', 'base_model.encoder.layer.16.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.14.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.16.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.18.intermediate.dense.bias', 'base_model.encoder.layer.0.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.20.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.16.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.19.attention.self.value.weight', 'base_model.encoder.layer.8.output.LayerNorm.weight', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.2.intermediate.dense.weight', 'base_model.encoder.layer.19.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.15.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.16.output.LayerNorm.bias', 'base_model.encoder.layer.2.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.16.attention.output.dense.weight', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.8.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.0.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.1.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.7.output.LayerNorm.weight', 'base_model.encoder.layer.9.intermediate.dense.weight', 'base_model.encoder.layer.13.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.4.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.16.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.17.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.19.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.9.attention.output.LayerNorm.weight', 'base_model.encoder.layer.21.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.17.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.3.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.19.attention.output.dense.bias', 'base_model.encoder.layer.11.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.7.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.5.attention.self.query.bias', 'base_model.encoder.layer.13.intermediate.dense.bias', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.22.output.LayerNorm.weight', 'base_model.encoder.layer.4.attention.self.query.bias', 'base_model.encoder.layer.21.output.dense.bias', 'base_model.encoder.layer.20.attention.self.key.bias', 'base_model.encoder.layer.16.output.dense.weight', 'base_model.encoder.layer.15.output.dense.bias', 'base_model.encoder.layer.22.output.dense.bias', 'base_model.encoder.layer.1.attention.output.LayerNorm.bias', 'base_model.encoder.layer.1.intermediate.dense.bias', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.8.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.4.output.LayerNorm.bias', 'base_model.encoder.layer.13.attention.output.LayerNorm.weight', 'base_model.encoder.layer.14.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.10.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.4.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.9.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.20.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.18.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.16.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.12.attention.self.query.bias', 'base_model.encoder.layer.3.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.8.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.0.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.19.intermediate.dense.bias', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.8.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.20.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.6.attention.output.LayerNorm.bias', 'base_model.encoder.layer.16.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.1.attention.output.LayerNorm.weight', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.22.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.21.attention.self.query.weight', 'base_model.encoder.layer.19.output.dense.bias', 'base_model.encoder.layer.8.attention.self.key.weight', 'base_model.encoder.layer.16.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.15.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.1.attention.self.query.bias', 'base_model.encoder.layer.12.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.17.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.0.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.12.output.dense.weight', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.18.intermediate.dense.weight', 'base_model.encoder.layer.23.attention.self.key.weight', 'base_model.encoder.layer.8.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.14.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.20.output.dense.bias', 'base_model.encoder.layer.23.output.dense.bias', 'base_model.encoder.layer.20.attention.self.query.weight', 'base_model.encoder.layer.9.attention.self.key.weight', 'base_model.encoder.layer.14.output.dense.bias', 'base_model.encoder.layer.9.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.18.output.dense.weight', 'base_model.encoder.layer.13.output.dense.bias', 'base_model.encoder.layer.21.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.19.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.3.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.23.attention.output.LayerNorm.weight', 'base_model.encoder.layer.12.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.13.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.10.attention.self.value.bias', 'base_model.encoder.layer.18.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.5.intermediate.dense.bias', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.4.output.dense.bias', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.8.attention.output.LayerNorm.weight', 'base_model.encoder.layer.1.attention.self.key.bias', 'base_model.encoder.layer.6.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.13.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.2.attention.self.key.bias', 'base_model.encoder.layer.9.attention.self.query.weight', 'base_model.encoder.layer.12.attention.self.key.bias', 'base_model.encoder.layer.15.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.13.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.0.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.20.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.10.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.14.attention.self.key.bias', 'base_model.encoder.layer.1.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.3.output.LayerNorm.weight', 'base_model.encoder.layer.9.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.13.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.0.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.14.attention.output.dense.weight', 'base_model.encoder.layer.22.attention.self.key.bias', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.0.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.3.attention.self.value.weight', 'base_model.encoder.layer.17.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.5.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.4.intermediate.dense.bias', 'base_model.encoder.layer.13.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.17.attention.self.query.bias', 'base_model.encoder.layer.4.attention.output.dense.bias', 'base_model.encoder.layer.1.attention.self.value.bias', 'base_model.encoder.layer.2.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.0.intermediate.dense.weight', 'base_model.encoder.layer.1.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.4.attention.self.value.bias', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.12.attention.self.value.bias', 'base_model.encoder.layer.4.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.12.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.21.attention.self.value.weight', 'base_model.encoder.layer.11.intermediate.dense.bias', 'base_model.encoder.layer.22.attention.output.LayerNorm.weight', 'base_model.encoder.layer.7.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.9.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.4.output.dense.weight', 'base_model.encoder.layer.14.attention.output.LayerNorm.weight', 'base_model.encoder.layer.9.output.LayerNorm.weight', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.22.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.7.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.22.output.LayerNorm.bias', 'base_model.encoder.layer.22.attention.self.value.weight', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.20.output.dense.weight', 'base_model.encoder.layer.16.intermediate.dense.bias', 'base_model.encoder.layer.15.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.14.attention.self.key.weight', 'base_model.encoder.layer.18.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.6.output.dense.bias', 'base_model.encoder.layer.8.attention.self.value.weight', 'base_model.encoder.layer.4.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.17.attention.self.key.bias', 'base_model.encoder.layer.9.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.10.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.1.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.11.attention.output.LayerNorm.weight', 'base_model.encoder.layer.14.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.2.attention.self.value.weight', 'base_model.encoder.layer.9.attention.self.value.weight', 'base_model.encoder.layer.15.attention.self.key.bias', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.19.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.13.attention.output.LayerNorm.bias', 'base_model.encoder.layer.6.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.6.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.0.attention.output.dense.bias', 'base_model.encoder.layer.9.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.21.attention.output.LayerNorm.bias', 'base_model.encoder.layer.3.output.LayerNorm.bias', 'base_model.encoder.layer.20.attention.self.value.weight', 'base_model.encoder.layer.15.attention.self.value.weight', 'base_model.encoder.layer.10.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.6.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.19.attention.output.LayerNorm.bias', 'base_model.encoder.layer.3.attention.self.key.weight', 'base_model.encoder.layer.9.attention.output.dense.bias', 'base_model.encoder.layer.3.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.23.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.17.output.LayerNorm.weight', 'base_model.encoder.layer.16.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.5.intermediate.dense.weight', 'base_model.encoder.layer.10.attention.output.LayerNorm.weight', 'base_model.encoder.layer.23.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.21.attention.self.key.bias', 'base_model.encoder.layer.18.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.22.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.15.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.8.intermediate.dense.bias', 'base_model.encoder.layer.9.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.7.attention.self.query.bias', 'base_model.encoder.layer.17.attention.self.value.weight', 'base_model.encoder.layer.6.attention.output.dense.bias', 'base_model.encoder.layer.0.attention.self.value.weight', 'base_model.encoder.layer.10.attention.output.LayerNorm.bias', 'base_model.encoder.layer.7.output.adapters.tp.adapter_down.0.weight', 'base_model.pooler.dense.weight', 'base_model.encoder.layer.8.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.9.attention.self.value.bias', 'base_model.encoder.layer.2.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.22.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.6.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.6.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.10.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.17.output.dense.bias', 'base_model.encoder.layer.21.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.11.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.22.attention.output.LayerNorm.bias', 'base_model.encoder.layer.10.attention.output.dense.bias', 'base_model.encoder.layer.16.attention.self.value.bias', 'base_model.encoder.layer.6.output.LayerNorm.bias', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.7.output.LayerNorm.bias', 'base_model.encoder.layer.10.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.5.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.17.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.6.output.adapters.tp.adapter_down.0.weight', 'qa_outputs.weight', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.21.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.4.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.2.output.LayerNorm.bias', 'base_model.encoder.layer.18.attention.self.key.bias', 'base_model.encoder.layer.15.attention.self.value.bias', 'base_model.encoder.layer.22.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.1.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.embeddings.position_ids', 'base_model.encoder.layer.18.attention.output.dense.weight', 'base_model.encoder.layer.0.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.5.attention.self.key.bias', 'base_model.encoder.layer.8.attention.self.query.weight', 'base_model.encoder.layer.20.attention.self.query.bias', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.7.intermediate.dense.weight', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.17.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.14.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.3.attention.output.dense.weight', 'base_model.encoder.layer.0.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.20.attention.output.LayerNorm.bias', 'base_model.encoder.layer.13.attention.output.dense.weight', 'base_model.encoder.layer.1.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.21.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.20.attention.output.dense.bias', 'base_model.encoder.layer.7.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.11.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.21.output.dense.weight', 'base_model.encoder.layer.15.attention.output.LayerNorm.bias', 'base_model.encoder.layer.16.output.adapters.es.adapter_up.weight', 'base_model.embeddings.LayerNorm.weight', 'base_model.encoder.layer.15.attention.output.dense.bias', 'base_model.encoder.layer.23.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.11.attention.output.LayerNorm.bias', 'base_model.encoder.layer.12.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.20.attention.output.dense.weight', 'base_model.encoder.layer.7.attention.self.key.weight', 'base_model.encoder.layer.10.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.5.output.dense.weight', 'base_model.encoder.layer.2.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.6.output.LayerNorm.weight', 'base_model.encoder.layer.23.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.7.attention.output.dense.bias', 'base_model.encoder.layer.0.intermediate.dense.bias', 'base_model.encoder.layer.9.attention.output.dense.weight', 'base_model.encoder.layer.22.attention.self.query.bias', 'base_model.encoder.layer.8.attention.output.dense.weight', 'base_model.encoder.layer.12.output.dense.bias', 'base_model.encoder.layer.19.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.5.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.15.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.16.attention.self.key.bias', 'base_model.encoder.layer.8.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.13.attention.self.value.bias', 'base_model.encoder.layer.21.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.1.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.2.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.12.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.15.output.dense.weight', 'base_model.encoder.layer.20.output.LayerNorm.weight', 'base_model.encoder.layer.0.output.LayerNorm.bias', 'base_model.encoder.layer.4.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.22.attention.output.dense.bias', 'base_model.encoder.layer.8.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.19.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.11.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.5.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.22.attention.self.value.bias', 'base_model.encoder.layer.13.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.12.intermediate.dense.bias', 'base_model.encoder.layer.18.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.0.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.7.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.5.attention.self.key.weight', 'base_model.encoder.layer.15.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.15.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.18.attention.self.query.bias', 'base_model.encoder.layer.0.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.20.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.2.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.22.output.dense.weight', 'base_model.encoder.layer.17.attention.self.key.weight', 'base_model.encoder.layer.18.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.1.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.23.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.5.output.LayerNorm.weight', 'base_model.encoder.layer.6.intermediate.dense.bias', 'base_model.encoder.layer.14.attention.output.dense.bias', 'base_model.encoder.layer.19.output.dense.weight', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.19.attention.self.value.bias', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.12.output.LayerNorm.weight', 'base_model.encoder.layer.11.intermediate.dense.weight', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.key.weight']
- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of XLMRobertaModel were not initialized from the model checkpoint at /cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//squad/xlm-KG_LR4e-5_EPOCH2.0_maxlen384_batchsize4_gradacc8 and are newly initialized: ['encoder.layer.22.attention.self.key.bias', 'encoder.layer.16.attention.self.query.weight', 'encoder.layer.11.attention.output.LayerNorm.weight', 'encoder.layer.20.output.LayerNorm.bias', 'encoder.layer.16.attention.output.LayerNorm.bias', 'encoder.layer.23.attention.self.value.weight', 'encoder.layer.20.output.dense.bias', 'encoder.layer.10.attention.self.value.weight', 'encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.layer.13.attention.output.LayerNorm.bias', 'encoder.layer.18.intermediate.dense.bias', 'encoder.layer.13.attention.self.key.weight', 'encoder.layer.22.output.dense.weight', 'encoder.layer.12.output.dense.weight', 'encoder.layer.23.attention.output.LayerNorm.weight', 'encoder.layer.19.intermediate.dense.bias', 'encoder.layer.17.output.LayerNorm.weight', 'encoder.layer.8.attention.self.query.bias', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.6.attention.self.value.bias', 'encoder.layer.14.attention.self.query.bias', 'encoder.layer.12.attention.output.LayerNorm.bias', 'encoder.layer.3.attention.self.key.bias', 'encoder.layer.21.attention.self.query.weight', 'encoder.layer.18.attention.output.dense.weight', 'encoder.layer.15.output.LayerNorm.bias', 'encoder.layer.3.attention.output.dense.weight', 'encoder.layer.20.attention.output.dense.weight', 'encoder.layer.7.attention.self.key.weight', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.17.attention.output.LayerNorm.bias', 'encoder.layer.11.attention.self.query.weight', 'encoder.layer.20.attention.self.value.bias', 'encoder.layer.20.intermediate.dense.weight', 'encoder.layer.18.output.dense.bias', 'embeddings.word_embeddings.weight', 'encoder.layer.10.attention.output.LayerNorm.weight', 'encoder.layer.23.attention.output.dense.bias', 'encoder.layer.23.output.dense.weight', 'encoder.layer.8.output.LayerNorm.bias', 'encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.7.attention.self.value.bias', 'encoder.layer.17.attention.self.query.weight', 'encoder.layer.4.attention.self.query.weight', 'encoder.layer.6.attention.output.LayerNorm.bias', 'encoder.layer.4.attention.output.LayerNorm.bias', 'encoder.layer.6.attention.self.query.weight', 'encoder.layer.15.attention.self.key.bias', 'encoder.layer.6.output.dense.weight', 'encoder.layer.2.attention.self.query.weight', 'encoder.layer.14.output.dense.bias', 'encoder.layer.16.intermediate.dense.bias', 'encoder.layer.12.attention.self.query.weight', 'encoder.layer.5.attention.self.value.bias', 'embeddings.LayerNorm.weight', 'encoder.layer.14.output.dense.weight', 'encoder.layer.16.output.dense.weight', 'encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.layer.20.attention.self.key.bias', 'encoder.layer.6.attention.self.query.bias', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.2.attention.self.key.bias', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.5.output.LayerNorm.bias', 'encoder.layer.2.attention.self.value.weight', 'encoder.layer.19.attention.output.LayerNorm.weight', 'encoder.layer.16.output.LayerNorm.weight', 'encoder.layer.3.attention.self.query.weight', 'encoder.layer.11.output.dense.bias', 'encoder.layer.3.output.dense.weight', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.19.attention.output.LayerNorm.bias', 'encoder.layer.4.output.dense.weight', 'encoder.layer.10.output.LayerNorm.bias', 'encoder.layer.20.attention.self.key.weight', 'encoder.layer.1.output.dense.weight', 'encoder.layer.12.intermediate.dense.weight', 'encoder.layer.23.attention.self.key.bias', 'encoder.layer.11.attention.self.value.bias', 'encoder.layer.21.attention.self.value.weight', 'encoder.layer.18.attention.self.value.bias', 'encoder.layer.15.intermediate.dense.bias', 'encoder.layer.16.output.LayerNorm.bias', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.9.attention.self.value.bias', 'encoder.layer.11.attention.self.value.weight', 'encoder.layer.0.attention.self.value.weight', 'encoder.layer.23.attention.output.dense.weight', 'encoder.layer.8.attention.self.key.bias', 'encoder.layer.5.output.dense.weight', 'encoder.layer.13.intermediate.dense.weight', 'encoder.layer.17.attention.self.value.bias', 'encoder.layer.7.attention.self.key.bias', 'encoder.layer.17.attention.self.query.bias', 'encoder.layer.14.attention.output.LayerNorm.weight', 'encoder.layer.9.attention.output.dense.bias', 'encoder.layer.5.attention.self.value.weight', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.12.attention.output.LayerNorm.weight', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.22.attention.output.dense.bias', 'encoder.layer.19.attention.self.key.bias', 'encoder.layer.22.output.dense.bias', 'encoder.layer.19.attention.self.key.weight', 'encoder.layer.8.attention.output.dense.bias', 'encoder.layer.2.output.dense.bias', 'encoder.layer.10.attention.self.value.bias', 'encoder.layer.0.output.dense.weight', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.13.output.LayerNorm.weight', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.8.attention.self.value.bias', 'encoder.layer.7.output.dense.bias', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.14.attention.output.dense.bias', 'encoder.layer.21.output.LayerNorm.bias', 'encoder.layer.3.attention.self.key.weight', 'encoder.layer.15.attention.output.LayerNorm.weight', 'encoder.layer.10.attention.output.LayerNorm.bias', 'encoder.layer.9.attention.output.LayerNorm.bias', 'encoder.layer.8.attention.self.value.weight', 'encoder.layer.5.attention.self.query.bias', 'encoder.layer.20.attention.output.LayerNorm.bias', 'encoder.layer.14.attention.output.LayerNorm.bias', 'encoder.layer.12.output.dense.bias', 'encoder.layer.12.attention.self.key.bias', 'encoder.layer.15.output.dense.bias', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.8.attention.self.query.weight', 'encoder.layer.17.intermediate.dense.weight', 'encoder.layer.9.attention.output.dense.weight', 'encoder.layer.4.attention.self.key.bias', 'encoder.layer.1.attention.self.query.weight', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.23.attention.self.query.bias', 'encoder.layer.13.attention.self.value.weight', 'encoder.layer.5.attention.output.dense.bias', 'encoder.layer.21.intermediate.dense.weight', 'encoder.layer.12.attention.output.dense.bias', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.8.attention.output.LayerNorm.weight', 'encoder.layer.7.intermediate.dense.bias', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.10.attention.self.key.weight', 'encoder.layer.18.output.LayerNorm.weight', 'encoder.layer.19.attention.self.value.weight', 'encoder.layer.22.intermediate.dense.bias', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.5.attention.output.LayerNorm.weight', 'encoder.layer.9.attention.output.LayerNorm.weight', 'encoder.layer.11.attention.self.key.bias', 'encoder.layer.19.attention.self.query.weight', 'encoder.layer.13.attention.self.query.bias', 'encoder.layer.23.attention.self.value.bias', 'encoder.layer.15.attention.self.query.bias', 'encoder.layer.4.attention.self.value.bias', 'encoder.layer.14.attention.self.key.bias', 'encoder.layer.17.attention.output.dense.bias', 'encoder.layer.18.attention.self.value.weight', 'encoder.layer.15.attention.self.key.weight', 'encoder.layer.9.attention.self.key.weight', 'encoder.layer.11.output.dense.weight', 'encoder.layer.23.output.LayerNorm.bias', 'encoder.layer.18.attention.self.query.bias', 'encoder.layer.14.output.LayerNorm.weight', 'encoder.layer.7.output.LayerNorm.bias', 'encoder.layer.4.attention.output.dense.weight', 'encoder.layer.4.attention.output.LayerNorm.weight', 'encoder.layer.1.attention.self.key.bias', 'encoder.layer.2.attention.output.dense.weight', 'encoder.layer.13.output.dense.weight', 'encoder.layer.14.attention.output.dense.weight', 'encoder.layer.23.intermediate.dense.bias', 'encoder.layer.14.output.LayerNorm.bias', 'encoder.layer.5.attention.output.dense.weight', 'encoder.layer.16.attention.output.dense.bias', 'encoder.layer.9.attention.self.key.bias', 'encoder.layer.18.attention.output.dense.bias', 'encoder.layer.11.attention.output.dense.weight', 'encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.layer.18.output.LayerNorm.bias', 'encoder.layer.10.intermediate.dense.weight', 'encoder.layer.12.attention.self.value.bias', 'encoder.layer.7.output.dense.weight', 'encoder.layer.2.intermediate.dense.weight', 'pooler.dense.weight', 'encoder.layer.16.attention.self.key.bias', 'encoder.layer.11.attention.self.key.weight', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.2.attention.output.LayerNorm.bias', 'encoder.layer.11.attention.output.dense.bias', 'encoder.layer.15.attention.output.dense.bias', 'encoder.layer.15.output.LayerNorm.weight', 'encoder.layer.14.attention.self.query.weight', 'encoder.layer.18.attention.self.key.weight', 'encoder.layer.20.attention.self.query.weight', 'encoder.layer.14.intermediate.dense.bias', 'encoder.layer.23.attention.self.key.weight', 'encoder.layer.10.output.dense.bias', 'encoder.layer.17.attention.output.dense.weight', 'encoder.layer.21.attention.output.LayerNorm.weight', 'encoder.layer.20.attention.output.dense.bias', 'encoder.layer.7.attention.self.query.weight', 'encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.layer.18.attention.self.query.weight', 'encoder.layer.16.attention.output.LayerNorm.weight', 'encoder.layer.14.attention.self.value.weight', 'encoder.layer.2.attention.output.dense.bias', 'encoder.layer.3.attention.output.dense.bias', 'encoder.layer.13.attention.output.dense.weight', 'encoder.layer.4.attention.self.value.weight', 'encoder.layer.16.attention.self.value.weight', 'encoder.layer.10.attention.output.dense.bias', 'encoder.layer.10.attention.output.dense.weight', 'encoder.layer.21.intermediate.dense.bias', 'encoder.layer.21.attention.self.key.bias', 'encoder.layer.23.output.dense.bias', 'encoder.layer.1.output.dense.bias', 'encoder.layer.4.output.dense.bias', 'encoder.layer.11.attention.self.query.bias', 'encoder.layer.16.attention.self.value.bias', 'encoder.layer.1.attention.self.key.weight', 'pooler.dense.bias', 'encoder.layer.6.attention.self.key.weight', 'encoder.layer.16.attention.self.query.bias', 'encoder.layer.4.attention.self.query.bias', 'encoder.layer.8.attention.output.LayerNorm.bias', 'encoder.layer.21.attention.self.query.bias', 'encoder.layer.13.attention.self.key.bias', 'encoder.layer.6.attention.output.dense.bias', 'encoder.layer.16.intermediate.dense.weight', 'encoder.layer.15.attention.output.LayerNorm.bias', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.15.attention.self.query.weight', 'encoder.layer.17.output.LayerNorm.bias', 'encoder.layer.12.output.LayerNorm.weight', 'encoder.layer.22.attention.self.value.weight', 'embeddings.token_type_embeddings.weight', 'encoder.layer.19.attention.self.query.bias', 'encoder.layer.20.output.dense.weight', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.20.attention.self.query.bias', 'encoder.layer.18.attention.self.key.bias', 'encoder.layer.20.output.LayerNorm.weight', 'encoder.layer.19.output.dense.bias', 'encoder.layer.1.attention.output.LayerNorm.weight', 'encoder.layer.1.attention.self.value.bias', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.2.attention.self.query.bias', 'encoder.layer.22.attention.self.query.bias', 'embeddings.LayerNorm.bias', 'encoder.layer.22.attention.self.value.bias', 'encoder.layer.7.attention.self.query.bias', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.9.output.LayerNorm.bias', 'encoder.layer.0.output.dense.bias', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.15.attention.self.value.weight', 'encoder.layer.9.output.dense.weight', 'encoder.layer.17.output.dense.weight', 'encoder.layer.0.attention.self.key.bias', 'encoder.layer.19.intermediate.dense.weight', 'encoder.layer.3.attention.self.value.bias', 'encoder.layer.22.output.LayerNorm.bias', 'encoder.layer.7.attention.output.LayerNorm.bias', 'encoder.layer.2.attention.self.value.bias', 'encoder.layer.16.attention.self.key.weight', 'encoder.layer.19.attention.self.value.bias', 'encoder.layer.8.attention.output.dense.weight', 'encoder.layer.2.attention.output.LayerNorm.weight', 'encoder.layer.19.output.LayerNorm.bias', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.0.attention.output.dense.weight', 'encoder.layer.7.attention.output.dense.weight', 'encoder.layer.16.attention.output.dense.weight', 'encoder.layer.21.attention.output.LayerNorm.bias', 'encoder.layer.20.intermediate.dense.bias', 'encoder.layer.16.output.dense.bias', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.1.attention.output.dense.weight', 'encoder.layer.17.attention.self.key.bias', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.4.attention.self.key.weight', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.7.attention.self.value.weight', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.23.attention.output.LayerNorm.bias', 'encoder.layer.17.attention.self.value.weight', 'encoder.layer.14.attention.self.value.bias', 'encoder.layer.8.attention.self.key.weight', 'encoder.layer.7.output.LayerNorm.weight', 'encoder.layer.2.attention.self.key.weight', 'encoder.layer.15.intermediate.dense.weight', 'encoder.layer.13.intermediate.dense.bias', 'encoder.layer.9.output.LayerNorm.weight', 'encoder.layer.12.attention.self.query.bias', 'encoder.layer.6.attention.self.value.weight', 'encoder.layer.21.output.dense.weight', 'encoder.layer.8.output.dense.weight', 'encoder.layer.11.output.LayerNorm.bias', 'encoder.layer.12.attention.output.dense.weight', 'encoder.layer.13.attention.self.value.bias', 'encoder.layer.21.attention.self.key.weight', 'encoder.layer.2.output.dense.weight', 'encoder.layer.9.attention.self.value.weight', 'encoder.layer.15.attention.output.dense.weight', 'encoder.layer.0.attention.self.query.weight', 'encoder.layer.22.output.LayerNorm.weight', 'encoder.layer.23.output.LayerNorm.weight', 'encoder.layer.22.attention.output.dense.weight', 'encoder.layer.5.output.dense.bias', 'encoder.layer.4.attention.output.dense.bias', 'encoder.layer.19.attention.output.dense.bias', 'encoder.layer.17.attention.output.LayerNorm.weight', 'encoder.layer.0.attention.self.value.bias', 'encoder.layer.3.output.dense.bias', 'encoder.layer.9.attention.self.query.weight', 'encoder.layer.17.intermediate.dense.bias', 'encoder.layer.8.output.dense.bias', 'encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.22.intermediate.dense.weight', 'encoder.layer.21.attention.output.dense.bias', 'encoder.layer.6.attention.output.LayerNorm.weight', 'encoder.layer.10.attention.self.query.bias', 'encoder.layer.13.output.LayerNorm.bias', 'encoder.layer.5.attention.self.query.weight', 'encoder.layer.17.output.dense.bias', 'encoder.layer.15.attention.self.value.bias', 'encoder.layer.5.attention.self.key.bias', 'encoder.layer.23.intermediate.dense.weight', 'encoder.layer.22.attention.output.LayerNorm.bias', 'encoder.layer.12.intermediate.dense.bias', 'encoder.layer.9.output.dense.bias', 'encoder.layer.21.attention.self.value.bias', 'encoder.layer.12.output.LayerNorm.bias', 'encoder.layer.10.output.dense.weight', 'encoder.layer.18.output.dense.weight', 'encoder.layer.21.attention.output.dense.weight', 'encoder.layer.23.attention.self.query.weight', 'encoder.layer.10.attention.self.key.bias', 'encoder.layer.13.output.dense.bias', 'encoder.layer.22.attention.self.query.weight', 'encoder.layer.18.intermediate.dense.weight', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.17.attention.self.key.weight', 'encoder.layer.1.attention.self.query.bias', 'encoder.layer.21.output.dense.bias', 'encoder.layer.10.output.LayerNorm.weight', 'encoder.layer.13.attention.output.dense.bias', 'encoder.layer.6.attention.self.key.bias', 'encoder.layer.0.attention.output.dense.bias', 'encoder.layer.1.attention.self.value.weight', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.14.attention.self.key.weight', 'encoder.layer.10.attention.self.query.weight', 'encoder.layer.13.attention.self.query.weight', 'encoder.layer.18.attention.output.LayerNorm.bias', 'encoder.layer.0.attention.output.LayerNorm.weight', 'encoder.layer.12.attention.self.key.weight', 'encoder.layer.3.attention.self.query.bias', 'encoder.layer.19.attention.output.dense.weight', 'encoder.layer.9.attention.self.query.bias', 'encoder.layer.11.output.LayerNorm.weight', 'encoder.layer.19.output.dense.weight', 'encoder.layer.20.attention.self.value.weight', 'embeddings.position_embeddings.weight', 'encoder.layer.15.output.dense.weight', 'encoder.layer.0.attention.self.key.weight', 'encoder.layer.3.attention.self.value.weight', 'encoder.layer.13.attention.output.LayerNorm.weight', 'encoder.layer.14.intermediate.dense.weight', 'encoder.layer.18.attention.output.LayerNorm.weight', 'encoder.layer.21.output.LayerNorm.weight', 'encoder.layer.1.attention.output.dense.bias', 'encoder.layer.5.attention.self.key.weight', 'encoder.layer.7.attention.output.dense.bias', 'encoder.layer.22.attention.self.key.weight', 'encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.layer.6.output.LayerNorm.bias', 'encoder.layer.22.attention.output.LayerNorm.weight', 'encoder.layer.6.output.dense.bias', 'encoder.layer.7.attention.output.LayerNorm.weight', 'encoder.layer.8.output.LayerNorm.weight', 'encoder.layer.19.output.LayerNorm.weight', 'encoder.layer.20.attention.output.LayerNorm.weight', 'encoder.layer.0.attention.self.query.bias', 'encoder.layer.6.attention.output.dense.weight', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.12.attention.self.value.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Overwriting existing adapter 'ep'.
Overwriting existing adapter 'tp'.
Overwriting existing adapter 'es'.
Overwriting existing adapter 'ts'.
Overwriting existing adapter fusion module 'ep,tp,es,ts'
05/09/2022 19:57:07 - INFO - __main__ -   lang2id = None
05/09/2022 19:57:11 - INFO - __main__ -   Training/evaluation parameters Namespace(adam_epsilon=1e-08, cache_dir='', config_name='', data_dir=None, device=device(type='cuda'), do_eval=True, do_lower_case=False, do_train=False, doc_stride=128, eval_all_checkpoints=False, eval_lang='el', evaluate_during_training=False, fp16=False, fp16_opt_level='O1', gradient_accumulation_steps=1, learning_rate=5e-05, local_rank=-1, logging_steps=50, max_answer_length=30, max_grad_norm=1.0, max_query_length=64, max_seq_length=384, max_steps=-1, model_name='xlm-KG', model_name_or_path='/cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//squad/xlm-KG_LR4e-5_EPOCH2.0_maxlen384_batchsize4_gradacc8', model_type='xlm', modelkg_dir='/cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/adapter/xlmr_adapter', n_best_size=20, n_gpu=1, no_cuda=False, null_score_diff_threshold=0.0, num_train_epochs=3.0, output_dir='/cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//squad/xlm-KG_LR4e-5_EPOCH2.0_maxlen384_batchsize4_gradacc8/predictions/xquad/', overwrite_cache=False, overwrite_output_dir=False, per_gpu_eval_batch_size=8, per_gpu_train_batch_size=8, predict_file='/cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/download//xquad//xquad.el.json', save_steps=50, seed=42, server_ip='', server_port='', threads=1, tokenizer_name='', train_file=None, train_lang='en', verbose_logging=False, version_2_with_negative=False, warmup_steps=0, weight_decay=0.0)
05/09/2022 19:57:11 - INFO - __main__ -   Loading checkpoint /cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//squad/xlm-KG_LR4e-5_EPOCH2.0_maxlen384_batchsize4_gradacc8 for evaluation
05/09/2022 19:57:11 - INFO - __main__ -   Evaluate the following checkpoints: ['/cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//squad/xlm-KG_LR4e-5_EPOCH2.0_maxlen384_batchsize4_gradacc8']
Some weights of the model checkpoint at /cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//squad/xlm-KG_LR4e-5_EPOCH2.0_maxlen384_batchsize4_gradacc8 were not used when initializing XLMRobertaModel: ['base_model.encoder.layer.14.attention.self.value.weight', 'base_model.encoder.layer.7.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.23.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.18.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.11.attention.self.value.weight', 'base_model.encoder.layer.22.intermediate.dense.bias', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.1.output.dense.weight', 'base_model.encoder.layer.18.attention.self.value.bias', 'base_model.encoder.layer.5.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.5.attention.output.LayerNorm.bias', 'base_model.encoder.layer.13.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.21.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.22.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.12.attention.output.dense.bias', 'base_model.encoder.layer.22.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.6.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.8.intermediate.dense.weight', 'base_model.encoder.layer.11.attention.self.key.bias', 'base_model.encoder.layer.22.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.17.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.7.intermediate.dense.bias', 'base_model.encoder.layer.9.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.14.output.LayerNorm.bias', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.6.attention.self.value.bias', 'base_model.encoder.layer.10.attention.self.query.bias', 'base_model.encoder.layer.16.attention.self.query.weight', 'base_model.encoder.layer.19.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.16.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.0.attention.self.query.weight', 'base_model.encoder.layer.20.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.19.attention.output.dense.weight', 'base_model.encoder.layer.7.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.12.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.22.attention.output.dense.weight', 'base_model.encoder.layer.14.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.2.attention.self.value.bias', 'base_model.encoder.layer.1.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.5.output.LayerNorm.bias', 'base_model.encoder.layer.23.intermediate.dense.weight', 'base_model.encoder.layer.21.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.1.attention.output.dense.weight', 'base_model.encoder.layer.17.attention.self.value.bias', 'base_model.encoder.layer.6.attention.self.query.bias', 'base_model.encoder.layer.9.attention.output.LayerNorm.bias', 'base_model.encoder.layer.4.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.23.intermediate.dense.bias', 'base_model.encoder.layer.8.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.6.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.8.output.dense.weight', 'base_model.encoder.layer.15.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.18.attention.self.query.weight', 'base_model.encoder.layer.23.output.LayerNorm.bias', 'base_model.encoder.layer.4.attention.self.query.weight', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.16.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.21.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.4.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.4.intermediate.dense.weight', 'base_model.encoder.layer.5.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.6.attention.self.value.weight', 'base_model.encoder.layer.1.output.LayerNorm.weight', 'base_model.encoder.layer.1.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.11.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.16.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.22.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.19.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.6.attention.self.query.weight', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.6.output.dense.weight', 'base_model.encoder.layer.7.attention.self.key.bias', 'base_model.encoder.layer.21.output.LayerNorm.weight', 'base_model.encoder.layer.16.attention.self.query.bias', 'base_model.encoder.layer.13.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.14.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.1.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.10.output.dense.weight', 'base_model.encoder.layer.18.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.11.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.20.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.21.attention.output.LayerNorm.weight', 'base_model.encoder.layer.13.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.21.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.23.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.8.output.LayerNorm.bias', 'base_model.embeddings.word_embeddings.weight', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.9.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.0.attention.self.key.weight', 'base_model.encoder.layer.11.attention.self.query.bias', 'base_model.encoder.layer.8.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.18.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.5.attention.output.dense.weight', 'base_model.encoder.layer.11.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.11.attention.output.dense.weight', 'base_model.encoder.layer.3.output.dense.bias', 'base_model.encoder.layer.13.attention.self.key.weight', 'base_model.encoder.layer.8.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.12.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.2.output.dense.weight', 'base_model.encoder.layer.3.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.19.output.LayerNorm.bias', 'base_model.encoder.layer.3.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.6.attention.self.key.bias', 'base_model.encoder.layer.16.output.dense.bias', 'base_model.encoder.layer.23.attention.output.dense.bias', 'base_model.encoder.layer.2.attention.output.dense.bias', 'base_model.encoder.layer.23.attention.output.dense.weight', 'base_model.encoder.layer.23.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.5.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.15.attention.output.dense.weight', 'base_model.encoder.layer.13.attention.self.value.weight', 'base_model.encoder.layer.17.attention.output.LayerNorm.bias', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.14.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.17.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.17.attention.output.dense.bias', 'base_model.encoder.layer.18.attention.output.LayerNorm.weight', 'base_model.encoder.layer.6.attention.output.LayerNorm.weight', 'base_model.encoder.layer.1.output.dense.bias', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.6.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.9.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.13.output.LayerNorm.bias', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.9.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.12.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.10.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.12.attention.self.query.weight', 'base_model.encoder.layer.12.intermediate.dense.weight', 'base_model.encoder.layer.11.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.15.intermediate.dense.bias', 'base_model.encoder.layer.0.attention.output.LayerNorm.weight', 'base_model.encoder.layer.9.output.dense.weight', 'base_model.encoder.layer.1.attention.self.key.weight', 'base_model.encoder.layer.21.intermediate.dense.weight', 'base_model.encoder.layer.11.attention.output.dense.bias', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.13.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.6.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.14.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.3.intermediate.dense.bias', 'base_model.encoder.layer.1.attention.self.query.weight', 'base_model.encoder.layer.17.intermediate.dense.weight', 'base_model.encoder.layer.16.intermediate.dense.weight', 'base_model.encoder.layer.11.attention.self.query.weight', 'base_model.encoder.layer.23.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.1.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.5.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.15.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.0.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.7.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.2.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.18.attention.output.dense.bias', 'base_model.encoder.layer.21.attention.self.query.bias', 'base_model.encoder.layer.1.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.3.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.9.output.LayerNorm.bias', 'base_model.encoder.layer.20.intermediate.dense.weight', 'base_model.encoder.layer.20.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.3.attention.self.key.bias', 'base_model.encoder.layer.4.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.4.attention.output.LayerNorm.weight', 'base_model.encoder.layer.4.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.18.output.LayerNorm.bias', 'base_model.encoder.layer.21.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.6.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.8.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.15.attention.self.query.bias', 'base_model.encoder.layer.3.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.4.attention.self.key.bias', 'base_model.encoder.layer.5.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.17.attention.output.dense.weight', 'base_model.encoder.layer.21.attention.self.key.weight', 'base_model.encoder.layer.7.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.4.attention.self.key.weight', 'base_model.encoder.layer.17.intermediate.dense.bias', 'base_model.encoder.layer.17.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.22.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.5.attention.self.query.weight', 'base_model.encoder.layer.4.attention.self.value.weight', 'base_model.encoder.layer.12.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.10.output.LayerNorm.bias', 'base_model.encoder.layer.20.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.21.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.10.intermediate.dense.bias', 'base_model.encoder.layer.23.attention.self.value.bias', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.12.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.19.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.7.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.7.attention.output.LayerNorm.bias', 'base_model.encoder.layer.0.output.dense.bias', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.11.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.23.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.10.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.4.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.13.output.dense.weight', 'base_model.encoder.layer.16.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.18.attention.self.value.weight', 'base_model.encoder.layer.7.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.2.output.dense.bias', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.11.output.LayerNorm.bias', 'base_model.encoder.layer.23.output.LayerNorm.weight', 'base_model.encoder.layer.15.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.0.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.20.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.14.output.adapters.ep.adapter_up.weight', 'qa_outputs.bias', 'base_model.encoder.layer.10.attention.self.value.weight', 'base_model.encoder.layer.18.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.22.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.2.attention.self.key.weight', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.6.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.7.attention.output.dense.weight', 'base_model.encoder.layer.12.attention.self.value.weight', 'base_model.encoder.layer.12.output.LayerNorm.bias', 'base_model.encoder.layer.12.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.0.attention.output.LayerNorm.bias', 'base_model.encoder.layer.19.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.16.attention.output.LayerNorm.weight', 'base_model.encoder.layer.14.attention.self.value.bias', 'base_model.encoder.layer.6.attention.output.dense.weight', 'base_model.encoder.layer.8.attention.output.LayerNorm.bias', 'base_model.encoder.layer.17.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.21.attention.self.value.bias', 'base_model.encoder.layer.19.attention.self.key.bias', 'base_model.encoder.layer.9.output.dense.bias', 'base_model.encoder.layer.11.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.10.output.dense.bias', 'base_model.encoder.layer.4.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.5.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.6.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.15.output.LayerNorm.bias', 'base_model.encoder.layer.3.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.19.output.LayerNorm.weight', 'base_model.encoder.layer.5.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.10.attention.self.query.weight', 'base_model.encoder.layer.23.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.8.output.dense.bias', 'base_model.encoder.layer.13.output.LayerNorm.weight', 'base_model.encoder.layer.23.attention.output.LayerNorm.bias', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.11.output.dense.bias', 'base_model.encoder.layer.13.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.17.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.7.attention.output.LayerNorm.weight', 'base_model.encoder.layer.1.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.13.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.18.attention.self.key.weight', 'base_model.encoder.layer.8.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.5.output.dense.bias', 'base_model.encoder.layer.20.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.23.attention.self.key.bias', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.22.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.8.attention.output.dense.bias', 'base_model.encoder.layer.23.output.dense.weight', 'base_model.encoder.layer.14.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.15.attention.self.query.weight', 'base_model.encoder.layer.18.attention.output.LayerNorm.bias', 'base_model.encoder.layer.13.attention.self.query.bias', 'base_model.encoder.layer.10.attention.self.key.weight', 'base_model.encoder.layer.16.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.17.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.9.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.22.intermediate.dense.weight', 'base_model.encoder.layer.10.attention.output.dense.weight', 'base_model.encoder.layer.4.output.LayerNorm.weight', 'base_model.encoder.layer.12.attention.output.LayerNorm.bias', 'base_model.encoder.layer.8.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.3.attention.output.LayerNorm.bias', 'base_model.encoder.layer.12.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.21.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.3.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.4.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.7.attention.self.value.bias', 'base_model.encoder.layer.14.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.0.output.LayerNorm.weight', 'base_model.encoder.layer.1.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.2.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.16.attention.output.dense.bias', 'base_model.encoder.layer.23.attention.self.query.weight', 'base_model.encoder.layer.15.attention.self.key.weight', 'base_model.encoder.layer.12.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.13.attention.self.key.bias', 'base_model.encoder.layer.5.attention.output.dense.bias', 'base_model.encoder.layer.0.output.dense.weight', 'base_model.encoder.layer.19.attention.self.key.weight', 'base_model.encoder.layer.11.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.5.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.23.attention.self.query.bias', 'base_model.encoder.layer.7.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.9.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.22.attention.self.query.weight', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.4.attention.output.dense.weight', 'base_model.encoder.layer.10.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.16.output.LayerNorm.weight', 'base_model.encoder.layer.21.intermediate.dense.bias', 'base_model.encoder.layer.19.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.2.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.20.attention.self.key.weight', 'base_model.encoder.layer.3.intermediate.dense.weight', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.11.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.8.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.5.attention.output.LayerNorm.weight', 'base_model.encoder.layer.3.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.3.attention.self.query.weight', 'base_model.encoder.layer.10.attention.self.key.bias', 'base_model.encoder.layer.11.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.16.attention.output.LayerNorm.bias', 'base_model.encoder.layer.20.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.0.attention.self.query.bias', 'base_model.encoder.layer.9.attention.self.query.bias', 'base_model.encoder.layer.10.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.23.attention.self.value.weight', 'base_model.encoder.layer.7.attention.self.value.weight', 'base_model.encoder.layer.12.attention.self.key.weight', 'base_model.encoder.layer.13.attention.self.query.weight', 'base_model.encoder.layer.21.attention.output.dense.bias', 'base_model.encoder.layer.9.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.12.attention.output.LayerNorm.weight', 'base_model.encoder.layer.14.intermediate.dense.weight', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.2.attention.output.dense.weight', 'base_model.encoder.layer.1.attention.output.dense.bias', 'base_model.encoder.layer.11.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.10.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.17.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.0.attention.output.dense.weight', 'base_model.encoder.layer.11.output.LayerNorm.weight', 'base_model.encoder.layer.20.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.3.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.17.output.LayerNorm.bias', 'base_model.encoder.layer.12.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.23.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.23.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.3.attention.output.dense.bias', 'base_model.encoder.layer.13.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.19.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.5.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.4.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.8.attention.self.query.bias', 'base_model.pooler.dense.bias', 'base_model.encoder.layer.14.output.LayerNorm.weight', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.2.output.LayerNorm.weight', 'base_model.encoder.layer.11.output.dense.weight', 'base_model.encoder.layer.16.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.16.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.20.attention.self.value.bias', 'base_model.encoder.layer.9.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.14.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.14.attention.self.query.weight', 'base_model.encoder.layer.21.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.17.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.19.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.23.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.18.output.dense.bias', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.1.intermediate.dense.weight', 'base_model.encoder.layer.15.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.9.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.0.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.22.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.2.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.15.intermediate.dense.weight', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.17.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.18.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.9.attention.self.key.bias', 'base_model.encoder.layer.3.attention.output.LayerNorm.weight', 'base_model.encoder.layer.22.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.10.output.LayerNorm.weight', 'base_model.encoder.layer.16.attention.self.key.weight', 'base_model.encoder.layer.21.output.LayerNorm.bias', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.21.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.14.intermediate.dense.bias', 'base_model.encoder.layer.8.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.2.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.4.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.19.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.7.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.13.intermediate.dense.weight', 'base_model.encoder.layer.14.output.adapters.tp.adapter_up.weight', 'base_model.embeddings.position_embeddings.weight', 'base_model.encoder.layer.18.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.11.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.10.intermediate.dense.weight', 'base_model.encoder.layer.10.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.18.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.5.attention.self.value.bias', 'base_model.encoder.layer.1.attention.self.value.weight', 'base_model.encoder.layer.19.attention.self.query.bias', 'base_model.encoder.layer.2.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.14.attention.self.query.bias', 'base_model.encoder.layer.22.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.8.attention.self.key.bias', 'base_model.encoder.layer.7.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.2.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.6.intermediate.dense.weight', 'base_model.encoder.layer.10.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.2.attention.self.query.weight', 'base_model.encoder.layer.17.attention.self.query.weight', 'base_model.encoder.layer.10.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.3.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.2.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.7.attention.self.query.weight', 'base_model.encoder.layer.13.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.11.attention.self.value.bias', 'base_model.encoder.layer.10.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.18.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.3.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.5.attention.self.value.weight', 'base_model.encoder.layer.17.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.13.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.15.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.3.output.dense.weight', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.2.attention.self.query.bias', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.6.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.19.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.7.output.dense.weight', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.18.output.LayerNorm.weight', 'base_model.encoder.layer.5.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.15.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.15.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.18.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.15.attention.output.LayerNorm.weight', 'base_model.encoder.layer.17.attention.output.LayerNorm.weight', 'base_model.encoder.layer.2.attention.output.LayerNorm.weight', 'base_model.encoder.layer.0.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.19.attention.self.query.weight', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.embeddings.LayerNorm.bias', 'base_model.encoder.layer.15.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.8.attention.self.value.bias', 'base_model.encoder.layer.19.intermediate.dense.weight', 'base_model.encoder.layer.21.attention.output.dense.weight', 'base_model.encoder.layer.2.attention.output.LayerNorm.bias', 'base_model.encoder.layer.23.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.4.attention.output.LayerNorm.bias', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.19.attention.output.LayerNorm.weight', 'base_model.encoder.layer.20.attention.output.LayerNorm.weight', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.22.attention.self.key.weight', 'base_model.encoder.layer.9.intermediate.dense.bias', 'base_model.encoder.layer.3.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.11.attention.self.key.weight', 'base_model.encoder.layer.5.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.4.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.0.attention.self.key.bias', 'base_model.encoder.layer.13.attention.output.dense.bias', 'base_model.encoder.layer.20.output.LayerNorm.bias', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.22.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.11.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.3.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.3.attention.self.query.bias', 'base_model.encoder.layer.20.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.15.output.LayerNorm.weight', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.0.attention.self.value.bias', 'base_model.encoder.layer.7.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.17.output.dense.weight', 'base_model.encoder.layer.20.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.14.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.21.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.2.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.16.attention.self.value.weight', 'base_model.encoder.layer.23.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.18.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.20.intermediate.dense.bias', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.12.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.12.attention.output.dense.weight', 'base_model.encoder.layer.19.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.6.attention.self.key.weight', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.6.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.12.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.2.intermediate.dense.bias', 'base_model.encoder.layer.3.attention.self.value.bias', 'base_model.encoder.layer.14.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.embeddings.token_type_embeddings.weight', 'base_model.encoder.layer.2.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.14.output.dense.weight', 'base_model.encoder.layer.0.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.1.output.LayerNorm.bias', 'base_model.encoder.layer.5.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.20.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.7.output.dense.bias', 'base_model.encoder.layer.1.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.14.attention.output.LayerNorm.bias', 'base_model.encoder.layer.16.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.14.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.16.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.18.intermediate.dense.bias', 'base_model.encoder.layer.0.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.20.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.16.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.19.attention.self.value.weight', 'base_model.encoder.layer.8.output.LayerNorm.weight', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.2.intermediate.dense.weight', 'base_model.encoder.layer.19.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.15.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.16.output.LayerNorm.bias', 'base_model.encoder.layer.2.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.16.attention.output.dense.weight', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.8.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.0.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.1.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.7.output.LayerNorm.weight', 'base_model.encoder.layer.9.intermediate.dense.weight', 'base_model.encoder.layer.13.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.4.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.16.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.17.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.19.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.9.attention.output.LayerNorm.weight', 'base_model.encoder.layer.21.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.17.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.3.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.19.attention.output.dense.bias', 'base_model.encoder.layer.11.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.7.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.5.attention.self.query.bias', 'base_model.encoder.layer.13.intermediate.dense.bias', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.22.output.LayerNorm.weight', 'base_model.encoder.layer.4.attention.self.query.bias', 'base_model.encoder.layer.21.output.dense.bias', 'base_model.encoder.layer.20.attention.self.key.bias', 'base_model.encoder.layer.16.output.dense.weight', 'base_model.encoder.layer.15.output.dense.bias', 'base_model.encoder.layer.22.output.dense.bias', 'base_model.encoder.layer.1.attention.output.LayerNorm.bias', 'base_model.encoder.layer.1.intermediate.dense.bias', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.8.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.4.output.LayerNorm.bias', 'base_model.encoder.layer.13.attention.output.LayerNorm.weight', 'base_model.encoder.layer.14.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.10.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.4.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.9.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.20.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.18.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.16.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.12.attention.self.query.bias', 'base_model.encoder.layer.3.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.8.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.0.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.19.intermediate.dense.bias', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.8.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.20.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.6.attention.output.LayerNorm.bias', 'base_model.encoder.layer.16.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.1.attention.output.LayerNorm.weight', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.22.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.21.attention.self.query.weight', 'base_model.encoder.layer.19.output.dense.bias', 'base_model.encoder.layer.8.attention.self.key.weight', 'base_model.encoder.layer.16.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.15.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.1.attention.self.query.bias', 'base_model.encoder.layer.12.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.17.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.0.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.12.output.dense.weight', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.18.intermediate.dense.weight', 'base_model.encoder.layer.23.attention.self.key.weight', 'base_model.encoder.layer.8.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.14.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.20.output.dense.bias', 'base_model.encoder.layer.23.output.dense.bias', 'base_model.encoder.layer.20.attention.self.query.weight', 'base_model.encoder.layer.9.attention.self.key.weight', 'base_model.encoder.layer.14.output.dense.bias', 'base_model.encoder.layer.9.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.18.output.dense.weight', 'base_model.encoder.layer.13.output.dense.bias', 'base_model.encoder.layer.21.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.19.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.3.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.23.attention.output.LayerNorm.weight', 'base_model.encoder.layer.12.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.13.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.10.attention.self.value.bias', 'base_model.encoder.layer.18.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.5.intermediate.dense.bias', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.4.output.dense.bias', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.8.attention.output.LayerNorm.weight', 'base_model.encoder.layer.1.attention.self.key.bias', 'base_model.encoder.layer.6.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.13.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.2.attention.self.key.bias', 'base_model.encoder.layer.9.attention.self.query.weight', 'base_model.encoder.layer.12.attention.self.key.bias', 'base_model.encoder.layer.15.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.13.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.0.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.20.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.10.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.14.attention.self.key.bias', 'base_model.encoder.layer.1.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.3.output.LayerNorm.weight', 'base_model.encoder.layer.9.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.13.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.0.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.14.attention.output.dense.weight', 'base_model.encoder.layer.22.attention.self.key.bias', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.0.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.3.attention.self.value.weight', 'base_model.encoder.layer.17.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.5.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.4.intermediate.dense.bias', 'base_model.encoder.layer.13.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.17.attention.self.query.bias', 'base_model.encoder.layer.4.attention.output.dense.bias', 'base_model.encoder.layer.1.attention.self.value.bias', 'base_model.encoder.layer.2.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.0.intermediate.dense.weight', 'base_model.encoder.layer.1.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.4.attention.self.value.bias', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.12.attention.self.value.bias', 'base_model.encoder.layer.4.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.12.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.21.attention.self.value.weight', 'base_model.encoder.layer.11.intermediate.dense.bias', 'base_model.encoder.layer.22.attention.output.LayerNorm.weight', 'base_model.encoder.layer.7.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.9.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.4.output.dense.weight', 'base_model.encoder.layer.14.attention.output.LayerNorm.weight', 'base_model.encoder.layer.9.output.LayerNorm.weight', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.22.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.7.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.22.output.LayerNorm.bias', 'base_model.encoder.layer.22.attention.self.value.weight', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.20.output.dense.weight', 'base_model.encoder.layer.16.intermediate.dense.bias', 'base_model.encoder.layer.15.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.14.attention.self.key.weight', 'base_model.encoder.layer.18.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.6.output.dense.bias', 'base_model.encoder.layer.8.attention.self.value.weight', 'base_model.encoder.layer.4.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.17.attention.self.key.bias', 'base_model.encoder.layer.9.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.10.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.1.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.11.attention.output.LayerNorm.weight', 'base_model.encoder.layer.14.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.2.attention.self.value.weight', 'base_model.encoder.layer.9.attention.self.value.weight', 'base_model.encoder.layer.15.attention.self.key.bias', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.19.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.13.attention.output.LayerNorm.bias', 'base_model.encoder.layer.6.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.6.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.0.attention.output.dense.bias', 'base_model.encoder.layer.9.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.21.attention.output.LayerNorm.bias', 'base_model.encoder.layer.3.output.LayerNorm.bias', 'base_model.encoder.layer.20.attention.self.value.weight', 'base_model.encoder.layer.15.attention.self.value.weight', 'base_model.encoder.layer.10.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.6.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.19.attention.output.LayerNorm.bias', 'base_model.encoder.layer.3.attention.self.key.weight', 'base_model.encoder.layer.9.attention.output.dense.bias', 'base_model.encoder.layer.3.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.23.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.17.output.LayerNorm.weight', 'base_model.encoder.layer.16.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.5.intermediate.dense.weight', 'base_model.encoder.layer.10.attention.output.LayerNorm.weight', 'base_model.encoder.layer.23.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.21.attention.self.key.bias', 'base_model.encoder.layer.18.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.22.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.15.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.8.intermediate.dense.bias', 'base_model.encoder.layer.9.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.7.attention.self.query.bias', 'base_model.encoder.layer.17.attention.self.value.weight', 'base_model.encoder.layer.6.attention.output.dense.bias', 'base_model.encoder.layer.0.attention.self.value.weight', 'base_model.encoder.layer.10.attention.output.LayerNorm.bias', 'base_model.encoder.layer.7.output.adapters.tp.adapter_down.0.weight', 'base_model.pooler.dense.weight', 'base_model.encoder.layer.8.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.9.attention.self.value.bias', 'base_model.encoder.layer.2.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.22.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.6.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.6.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.10.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.17.output.dense.bias', 'base_model.encoder.layer.21.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.11.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.22.attention.output.LayerNorm.bias', 'base_model.encoder.layer.10.attention.output.dense.bias', 'base_model.encoder.layer.16.attention.self.value.bias', 'base_model.encoder.layer.6.output.LayerNorm.bias', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.7.output.LayerNorm.bias', 'base_model.encoder.layer.10.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.5.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.17.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.6.output.adapters.tp.adapter_down.0.weight', 'qa_outputs.weight', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.21.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.4.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.2.output.LayerNorm.bias', 'base_model.encoder.layer.18.attention.self.key.bias', 'base_model.encoder.layer.15.attention.self.value.bias', 'base_model.encoder.layer.22.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.1.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.embeddings.position_ids', 'base_model.encoder.layer.18.attention.output.dense.weight', 'base_model.encoder.layer.0.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.5.attention.self.key.bias', 'base_model.encoder.layer.8.attention.self.query.weight', 'base_model.encoder.layer.20.attention.self.query.bias', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.7.intermediate.dense.weight', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.17.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.14.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.3.attention.output.dense.weight', 'base_model.encoder.layer.0.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.20.attention.output.LayerNorm.bias', 'base_model.encoder.layer.13.attention.output.dense.weight', 'base_model.encoder.layer.1.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.21.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.20.attention.output.dense.bias', 'base_model.encoder.layer.7.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.11.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.21.output.dense.weight', 'base_model.encoder.layer.15.attention.output.LayerNorm.bias', 'base_model.encoder.layer.16.output.adapters.es.adapter_up.weight', 'base_model.embeddings.LayerNorm.weight', 'base_model.encoder.layer.15.attention.output.dense.bias', 'base_model.encoder.layer.23.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.11.attention.output.LayerNorm.bias', 'base_model.encoder.layer.12.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.20.attention.output.dense.weight', 'base_model.encoder.layer.7.attention.self.key.weight', 'base_model.encoder.layer.10.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.5.output.dense.weight', 'base_model.encoder.layer.2.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.6.output.LayerNorm.weight', 'base_model.encoder.layer.23.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.7.attention.output.dense.bias', 'base_model.encoder.layer.0.intermediate.dense.bias', 'base_model.encoder.layer.9.attention.output.dense.weight', 'base_model.encoder.layer.22.attention.self.query.bias', 'base_model.encoder.layer.8.attention.output.dense.weight', 'base_model.encoder.layer.12.output.dense.bias', 'base_model.encoder.layer.19.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.5.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.15.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.16.attention.self.key.bias', 'base_model.encoder.layer.8.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.13.attention.self.value.bias', 'base_model.encoder.layer.21.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.1.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.2.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.12.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.15.output.dense.weight', 'base_model.encoder.layer.20.output.LayerNorm.weight', 'base_model.encoder.layer.0.output.LayerNorm.bias', 'base_model.encoder.layer.4.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.22.attention.output.dense.bias', 'base_model.encoder.layer.8.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.19.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.11.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.5.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.22.attention.self.value.bias', 'base_model.encoder.layer.13.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.12.intermediate.dense.bias', 'base_model.encoder.layer.18.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.0.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.7.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.5.attention.self.key.weight', 'base_model.encoder.layer.15.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.15.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.18.attention.self.query.bias', 'base_model.encoder.layer.0.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.20.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.2.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.22.output.dense.weight', 'base_model.encoder.layer.17.attention.self.key.weight', 'base_model.encoder.layer.18.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.1.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.23.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.5.output.LayerNorm.weight', 'base_model.encoder.layer.6.intermediate.dense.bias', 'base_model.encoder.layer.14.attention.output.dense.bias', 'base_model.encoder.layer.19.output.dense.weight', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.19.attention.self.value.bias', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.12.output.LayerNorm.weight', 'base_model.encoder.layer.11.intermediate.dense.weight', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.key.weight']
- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of XLMRobertaModel were not initialized from the model checkpoint at /cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//squad/xlm-KG_LR4e-5_EPOCH2.0_maxlen384_batchsize4_gradacc8 and are newly initialized: ['encoder.layer.22.attention.self.key.bias', 'encoder.layer.16.attention.self.query.weight', 'encoder.layer.11.attention.output.LayerNorm.weight', 'encoder.layer.20.output.LayerNorm.bias', 'encoder.layer.16.attention.output.LayerNorm.bias', 'encoder.layer.23.attention.self.value.weight', 'encoder.layer.20.output.dense.bias', 'encoder.layer.10.attention.self.value.weight', 'encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.layer.13.attention.output.LayerNorm.bias', 'encoder.layer.18.intermediate.dense.bias', 'encoder.layer.13.attention.self.key.weight', 'encoder.layer.22.output.dense.weight', 'encoder.layer.12.output.dense.weight', 'encoder.layer.23.attention.output.LayerNorm.weight', 'encoder.layer.19.intermediate.dense.bias', 'encoder.layer.17.output.LayerNorm.weight', 'encoder.layer.8.attention.self.query.bias', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.6.attention.self.value.bias', 'encoder.layer.14.attention.self.query.bias', 'encoder.layer.12.attention.output.LayerNorm.bias', 'encoder.layer.3.attention.self.key.bias', 'encoder.layer.21.attention.self.query.weight', 'encoder.layer.18.attention.output.dense.weight', 'encoder.layer.15.output.LayerNorm.bias', 'encoder.layer.3.attention.output.dense.weight', 'encoder.layer.20.attention.output.dense.weight', 'encoder.layer.7.attention.self.key.weight', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.17.attention.output.LayerNorm.bias', 'encoder.layer.11.attention.self.query.weight', 'encoder.layer.20.attention.self.value.bias', 'encoder.layer.20.intermediate.dense.weight', 'encoder.layer.18.output.dense.bias', 'embeddings.word_embeddings.weight', 'encoder.layer.10.attention.output.LayerNorm.weight', 'encoder.layer.23.attention.output.dense.bias', 'encoder.layer.23.output.dense.weight', 'encoder.layer.8.output.LayerNorm.bias', 'encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.7.attention.self.value.bias', 'encoder.layer.17.attention.self.query.weight', 'encoder.layer.4.attention.self.query.weight', 'encoder.layer.6.attention.output.LayerNorm.bias', 'encoder.layer.4.attention.output.LayerNorm.bias', 'encoder.layer.6.attention.self.query.weight', 'encoder.layer.15.attention.self.key.bias', 'encoder.layer.6.output.dense.weight', 'encoder.layer.2.attention.self.query.weight', 'encoder.layer.14.output.dense.bias', 'encoder.layer.16.intermediate.dense.bias', 'encoder.layer.12.attention.self.query.weight', 'encoder.layer.5.attention.self.value.bias', 'embeddings.LayerNorm.weight', 'encoder.layer.14.output.dense.weight', 'encoder.layer.16.output.dense.weight', 'encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.layer.20.attention.self.key.bias', 'encoder.layer.6.attention.self.query.bias', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.2.attention.self.key.bias', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.5.output.LayerNorm.bias', 'encoder.layer.2.attention.self.value.weight', 'encoder.layer.19.attention.output.LayerNorm.weight', 'encoder.layer.16.output.LayerNorm.weight', 'encoder.layer.3.attention.self.query.weight', 'encoder.layer.11.output.dense.bias', 'encoder.layer.3.output.dense.weight', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.19.attention.output.LayerNorm.bias', 'encoder.layer.4.output.dense.weight', 'encoder.layer.10.output.LayerNorm.bias', 'encoder.layer.20.attention.self.key.weight', 'encoder.layer.1.output.dense.weight', 'encoder.layer.12.intermediate.dense.weight', 'encoder.layer.23.attention.self.key.bias', 'encoder.layer.11.attention.self.value.bias', 'encoder.layer.21.attention.self.value.weight', 'encoder.layer.18.attention.self.value.bias', 'encoder.layer.15.intermediate.dense.bias', 'encoder.layer.16.output.LayerNorm.bias', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.9.attention.self.value.bias', 'encoder.layer.11.attention.self.value.weight', 'encoder.layer.0.attention.self.value.weight', 'encoder.layer.23.attention.output.dense.weight', 'encoder.layer.8.attention.self.key.bias', 'encoder.layer.5.output.dense.weight', 'encoder.layer.13.intermediate.dense.weight', 'encoder.layer.17.attention.self.value.bias', 'encoder.layer.7.attention.self.key.bias', 'encoder.layer.17.attention.self.query.bias', 'encoder.layer.14.attention.output.LayerNorm.weight', 'encoder.layer.9.attention.output.dense.bias', 'encoder.layer.5.attention.self.value.weight', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.12.attention.output.LayerNorm.weight', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.22.attention.output.dense.bias', 'encoder.layer.19.attention.self.key.bias', 'encoder.layer.22.output.dense.bias', 'encoder.layer.19.attention.self.key.weight', 'encoder.layer.8.attention.output.dense.bias', 'encoder.layer.2.output.dense.bias', 'encoder.layer.10.attention.self.value.bias', 'encoder.layer.0.output.dense.weight', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.13.output.LayerNorm.weight', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.8.attention.self.value.bias', 'encoder.layer.7.output.dense.bias', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.14.attention.output.dense.bias', 'encoder.layer.21.output.LayerNorm.bias', 'encoder.layer.3.attention.self.key.weight', 'encoder.layer.15.attention.output.LayerNorm.weight', 'encoder.layer.10.attention.output.LayerNorm.bias', 'encoder.layer.9.attention.output.LayerNorm.bias', 'encoder.layer.8.attention.self.value.weight', 'encoder.layer.5.attention.self.query.bias', 'encoder.layer.20.attention.output.LayerNorm.bias', 'encoder.layer.14.attention.output.LayerNorm.bias', 'encoder.layer.12.output.dense.bias', 'encoder.layer.12.attention.self.key.bias', 'encoder.layer.15.output.dense.bias', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.8.attention.self.query.weight', 'encoder.layer.17.intermediate.dense.weight', 'encoder.layer.9.attention.output.dense.weight', 'encoder.layer.4.attention.self.key.bias', 'encoder.layer.1.attention.self.query.weight', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.23.attention.self.query.bias', 'encoder.layer.13.attention.self.value.weight', 'encoder.layer.5.attention.output.dense.bias', 'encoder.layer.21.intermediate.dense.weight', 'encoder.layer.12.attention.output.dense.bias', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.8.attention.output.LayerNorm.weight', 'encoder.layer.7.intermediate.dense.bias', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.10.attention.self.key.weight', 'encoder.layer.18.output.LayerNorm.weight', 'encoder.layer.19.attention.self.value.weight', 'encoder.layer.22.intermediate.dense.bias', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.5.attention.output.LayerNorm.weight', 'encoder.layer.9.attention.output.LayerNorm.weight', 'encoder.layer.11.attention.self.key.bias', 'encoder.layer.19.attention.self.query.weight', 'encoder.layer.13.attention.self.query.bias', 'encoder.layer.23.attention.self.value.bias', 'encoder.layer.15.attention.self.query.bias', 'encoder.layer.4.attention.self.value.bias', 'encoder.layer.14.attention.self.key.bias', 'encoder.layer.17.attention.output.dense.bias', 'encoder.layer.18.attention.self.value.weight', 'encoder.layer.15.attention.self.key.weight', 'encoder.layer.9.attention.self.key.weight', 'encoder.layer.11.output.dense.weight', 'encoder.layer.23.output.LayerNorm.bias', 'encoder.layer.18.attention.self.query.bias', 'encoder.layer.14.output.LayerNorm.weight', 'encoder.layer.7.output.LayerNorm.bias', 'encoder.layer.4.attention.output.dense.weight', 'encoder.layer.4.attention.output.LayerNorm.weight', 'encoder.layer.1.attention.self.key.bias', 'encoder.layer.2.attention.output.dense.weight', 'encoder.layer.13.output.dense.weight', 'encoder.layer.14.attention.output.dense.weight', 'encoder.layer.23.intermediate.dense.bias', 'encoder.layer.14.output.LayerNorm.bias', 'encoder.layer.5.attention.output.dense.weight', 'encoder.layer.16.attention.output.dense.bias', 'encoder.layer.9.attention.self.key.bias', 'encoder.layer.18.attention.output.dense.bias', 'encoder.layer.11.attention.output.dense.weight', 'encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.layer.18.output.LayerNorm.bias', 'encoder.layer.10.intermediate.dense.weight', 'encoder.layer.12.attention.self.value.bias', 'encoder.layer.7.output.dense.weight', 'encoder.layer.2.intermediate.dense.weight', 'pooler.dense.weight', 'encoder.layer.16.attention.self.key.bias', 'encoder.layer.11.attention.self.key.weight', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.2.attention.output.LayerNorm.bias', 'encoder.layer.11.attention.output.dense.bias', 'encoder.layer.15.attention.output.dense.bias', 'encoder.layer.15.output.LayerNorm.weight', 'encoder.layer.14.attention.self.query.weight', 'encoder.layer.18.attention.self.key.weight', 'encoder.layer.20.attention.self.query.weight', 'encoder.layer.14.intermediate.dense.bias', 'encoder.layer.23.attention.self.key.weight', 'encoder.layer.10.output.dense.bias', 'encoder.layer.17.attention.output.dense.weight', 'encoder.layer.21.attention.output.LayerNorm.weight', 'encoder.layer.20.attention.output.dense.bias', 'encoder.layer.7.attention.self.query.weight', 'encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.layer.18.attention.self.query.weight', 'encoder.layer.16.attention.output.LayerNorm.weight', 'encoder.layer.14.attention.self.value.weight', 'encoder.layer.2.attention.output.dense.bias', 'encoder.layer.3.attention.output.dense.bias', 'encoder.layer.13.attention.output.dense.weight', 'encoder.layer.4.attention.self.value.weight', 'encoder.layer.16.attention.self.value.weight', 'encoder.layer.10.attention.output.dense.bias', 'encoder.layer.10.attention.output.dense.weight', 'encoder.layer.21.intermediate.dense.bias', 'encoder.layer.21.attention.self.key.bias', 'encoder.layer.23.output.dense.bias', 'encoder.layer.1.output.dense.bias', 'encoder.layer.4.output.dense.bias', 'encoder.layer.11.attention.self.query.bias', 'encoder.layer.16.attention.self.value.bias', 'encoder.layer.1.attention.self.key.weight', 'pooler.dense.bias', 'encoder.layer.6.attention.self.key.weight', 'encoder.layer.16.attention.self.query.bias', 'encoder.layer.4.attention.self.query.bias', 'encoder.layer.8.attention.output.LayerNorm.bias', 'encoder.layer.21.attention.self.query.bias', 'encoder.layer.13.attention.self.key.bias', 'encoder.layer.6.attention.output.dense.bias', 'encoder.layer.16.intermediate.dense.weight', 'encoder.layer.15.attention.output.LayerNorm.bias', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.15.attention.self.query.weight', 'encoder.layer.17.output.LayerNorm.bias', 'encoder.layer.12.output.LayerNorm.weight', 'encoder.layer.22.attention.self.value.weight', 'embeddings.token_type_embeddings.weight', 'encoder.layer.19.attention.self.query.bias', 'encoder.layer.20.output.dense.weight', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.20.attention.self.query.bias', 'encoder.layer.18.attention.self.key.bias', 'encoder.layer.20.output.LayerNorm.weight', 'encoder.layer.19.output.dense.bias', 'encoder.layer.1.attention.output.LayerNorm.weight', 'encoder.layer.1.attention.self.value.bias', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.2.attention.self.query.bias', 'encoder.layer.22.attention.self.query.bias', 'embeddings.LayerNorm.bias', 'encoder.layer.22.attention.self.value.bias', 'encoder.layer.7.attention.self.query.bias', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.9.output.LayerNorm.bias', 'encoder.layer.0.output.dense.bias', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.15.attention.self.value.weight', 'encoder.layer.9.output.dense.weight', 'encoder.layer.17.output.dense.weight', 'encoder.layer.0.attention.self.key.bias', 'encoder.layer.19.intermediate.dense.weight', 'encoder.layer.3.attention.self.value.bias', 'encoder.layer.22.output.LayerNorm.bias', 'encoder.layer.7.attention.output.LayerNorm.bias', 'encoder.layer.2.attention.self.value.bias', 'encoder.layer.16.attention.self.key.weight', 'encoder.layer.19.attention.self.value.bias', 'encoder.layer.8.attention.output.dense.weight', 'encoder.layer.2.attention.output.LayerNorm.weight', 'encoder.layer.19.output.LayerNorm.bias', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.0.attention.output.dense.weight', 'encoder.layer.7.attention.output.dense.weight', 'encoder.layer.16.attention.output.dense.weight', 'encoder.layer.21.attention.output.LayerNorm.bias', 'encoder.layer.20.intermediate.dense.bias', 'encoder.layer.16.output.dense.bias', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.1.attention.output.dense.weight', 'encoder.layer.17.attention.self.key.bias', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.4.attention.self.key.weight', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.7.attention.self.value.weight', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.23.attention.output.LayerNorm.bias', 'encoder.layer.17.attention.self.value.weight', 'encoder.layer.14.attention.self.value.bias', 'encoder.layer.8.attention.self.key.weight', 'encoder.layer.7.output.LayerNorm.weight', 'encoder.layer.2.attention.self.key.weight', 'encoder.layer.15.intermediate.dense.weight', 'encoder.layer.13.intermediate.dense.bias', 'encoder.layer.9.output.LayerNorm.weight', 'encoder.layer.12.attention.self.query.bias', 'encoder.layer.6.attention.self.value.weight', 'encoder.layer.21.output.dense.weight', 'encoder.layer.8.output.dense.weight', 'encoder.layer.11.output.LayerNorm.bias', 'encoder.layer.12.attention.output.dense.weight', 'encoder.layer.13.attention.self.value.bias', 'encoder.layer.21.attention.self.key.weight', 'encoder.layer.2.output.dense.weight', 'encoder.layer.9.attention.self.value.weight', 'encoder.layer.15.attention.output.dense.weight', 'encoder.layer.0.attention.self.query.weight', 'encoder.layer.22.output.LayerNorm.weight', 'encoder.layer.23.output.LayerNorm.weight', 'encoder.layer.22.attention.output.dense.weight', 'encoder.layer.5.output.dense.bias', 'encoder.layer.4.attention.output.dense.bias', 'encoder.layer.19.attention.output.dense.bias', 'encoder.layer.17.attention.output.LayerNorm.weight', 'encoder.layer.0.attention.self.value.bias', 'encoder.layer.3.output.dense.bias', 'encoder.layer.9.attention.self.query.weight', 'encoder.layer.17.intermediate.dense.bias', 'encoder.layer.8.output.dense.bias', 'encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.22.intermediate.dense.weight', 'encoder.layer.21.attention.output.dense.bias', 'encoder.layer.6.attention.output.LayerNorm.weight', 'encoder.layer.10.attention.self.query.bias', 'encoder.layer.13.output.LayerNorm.bias', 'encoder.layer.5.attention.self.query.weight', 'encoder.layer.17.output.dense.bias', 'encoder.layer.15.attention.self.value.bias', 'encoder.layer.5.attention.self.key.bias', 'encoder.layer.23.intermediate.dense.weight', 'encoder.layer.22.attention.output.LayerNorm.bias', 'encoder.layer.12.intermediate.dense.bias', 'encoder.layer.9.output.dense.bias', 'encoder.layer.21.attention.self.value.bias', 'encoder.layer.12.output.LayerNorm.bias', 'encoder.layer.10.output.dense.weight', 'encoder.layer.18.output.dense.weight', 'encoder.layer.21.attention.output.dense.weight', 'encoder.layer.23.attention.self.query.weight', 'encoder.layer.10.attention.self.key.bias', 'encoder.layer.13.output.dense.bias', 'encoder.layer.22.attention.self.query.weight', 'encoder.layer.18.intermediate.dense.weight', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.17.attention.self.key.weight', 'encoder.layer.1.attention.self.query.bias', 'encoder.layer.21.output.dense.bias', 'encoder.layer.10.output.LayerNorm.weight', 'encoder.layer.13.attention.output.dense.bias', 'encoder.layer.6.attention.self.key.bias', 'encoder.layer.0.attention.output.dense.bias', 'encoder.layer.1.attention.self.value.weight', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.14.attention.self.key.weight', 'encoder.layer.10.attention.self.query.weight', 'encoder.layer.13.attention.self.query.weight', 'encoder.layer.18.attention.output.LayerNorm.bias', 'encoder.layer.0.attention.output.LayerNorm.weight', 'encoder.layer.12.attention.self.key.weight', 'encoder.layer.3.attention.self.query.bias', 'encoder.layer.19.attention.output.dense.weight', 'encoder.layer.9.attention.self.query.bias', 'encoder.layer.11.output.LayerNorm.weight', 'encoder.layer.19.output.dense.weight', 'encoder.layer.20.attention.self.value.weight', 'embeddings.position_embeddings.weight', 'encoder.layer.15.output.dense.weight', 'encoder.layer.0.attention.self.key.weight', 'encoder.layer.3.attention.self.value.weight', 'encoder.layer.13.attention.output.LayerNorm.weight', 'encoder.layer.14.intermediate.dense.weight', 'encoder.layer.18.attention.output.LayerNorm.weight', 'encoder.layer.21.output.LayerNorm.weight', 'encoder.layer.1.attention.output.dense.bias', 'encoder.layer.5.attention.self.key.weight', 'encoder.layer.7.attention.output.dense.bias', 'encoder.layer.22.attention.self.key.weight', 'encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.layer.6.output.LayerNorm.bias', 'encoder.layer.22.attention.output.LayerNorm.weight', 'encoder.layer.6.output.dense.bias', 'encoder.layer.7.attention.output.LayerNorm.weight', 'encoder.layer.8.output.LayerNorm.weight', 'encoder.layer.19.output.LayerNorm.weight', 'encoder.layer.20.attention.output.LayerNorm.weight', 'encoder.layer.0.attention.self.query.bias', 'encoder.layer.6.attention.output.dense.weight', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.12.attention.self.value.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Overwriting existing adapter 'ep'.
Overwriting existing adapter 'tp'.
Overwriting existing adapter 'es'.
Overwriting existing adapter 'ts'.
Overwriting existing adapter fusion module 'ep,tp,es,ts'
05/09/2022 19:57:41 - INFO - __main__ -   Creating features from dataset file at .
/cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//squad/xlm-KG_LR4e-5_EPOCH2.0_maxlen384_batchsize4_gradacc8
XLMConfig {
  "architectures": [
    "XLMRobertaForMaskedLM"
  ],
  "asm": false,
  "attention_dropout": 0.1,
  "attention_probs_dropout_prob": 0.1,
  "bos_index": 0,
  "bos_token_id": 0,
  "causal": false,
  "dropout": 0.1,
  "emb_dim": 1024,
  "embed_init_std": 0.02209708691207961,
  "end_n_top": 5,
  "eos_index": 1,
  "eos_token_id": 2,
  "gelu_activation": true,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "init_std": 0.02,
  "initializer_range": 0.02,
  "intermediate_size": 4096,
  "is_encoder": true,
  "lang_id": 0,
  "layer_norm_eps": 1e-05,
  "mask_index": 5,
  "mask_token_id": 0,
  "max_position_embeddings": 514,
  "model_type": "xlm",
  "n_heads": 16,
  "n_langs": 1,
  "n_layers": 24,
  "output_past": true,
  "pad_index": 2,
  "pad_token_id": 1,
  "sinusoidal_embeddings": false,
  "start_n_top": 5,
  "summary_activation": null,
  "summary_first_dropout": 0.1,
  "summary_proj_to_labels": true,
  "summary_type": "first",
  "summary_use_proj": true,
  "transformers_version": "4.17.0",
  "type_vocab_size": 1,
  "unk_index": 3,
  "use_lang_emb": false,
  "vocab_size": 250002
}

  0%|          | 0/48 [00:00<?, ?it/s] 27%|██▋       | 13/48 [00:00<00:00, 125.42it/s] 54%|█████▍    | 26/48 [00:00<00:00, 91.61it/s]  75%|███████▌  | 36/48 [00:00<00:00, 93.88it/s]100%|██████████| 48/48 [00:00<00:00, 103.28it/s]
convert squad examples to features:   0%|          | 0/1190 [00:00<?, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.
convert squad examples to features:   0%|          | 1/1190 [00:00<03:23,  5.84it/s]convert squad examples to features:   5%|▌         | 65/1190 [00:00<00:05, 192.53it/s]convert squad examples to features:   8%|▊         | 97/1190 [00:00<00:05, 206.14it/s]convert squad examples to features:  14%|█▎        | 161/1190 [00:00<00:03, 263.13it/s]convert squad examples to features:  19%|█▉        | 225/1190 [00:00<00:03, 279.67it/s]convert squad examples to features:  22%|██▏       | 257/1190 [00:01<00:03, 261.28it/s]convert squad examples to features:  24%|██▍       | 289/1190 [00:01<00:03, 253.51it/s]convert squad examples to features:  27%|██▋       | 321/1190 [00:01<00:03, 238.08it/s]convert squad examples to features:  30%|██▉       | 353/1190 [00:01<00:03, 248.21it/s]convert squad examples to features:  32%|███▏      | 385/1190 [00:02<00:06, 125.07it/s]convert squad examples to features:  35%|███▌      | 417/1190 [00:02<00:05, 136.79it/s]convert squad examples to features:  38%|███▊      | 449/1190 [00:02<00:05, 140.40it/s]convert squad examples to features:  40%|████      | 481/1190 [00:02<00:04, 157.03it/s]convert squad examples to features:  43%|████▎     | 513/1190 [00:02<00:04, 158.46it/s]convert squad examples to features:  46%|████▌     | 545/1190 [00:02<00:04, 160.47it/s]convert squad examples to features:  48%|████▊     | 577/1190 [00:03<00:03, 171.05it/s]convert squad examples to features:  51%|█████     | 609/1190 [00:03<00:03, 168.33it/s]convert squad examples to features:  54%|█████▍    | 641/1190 [00:03<00:03, 170.75it/s]convert squad examples to features:  57%|█████▋    | 673/1190 [00:03<00:03, 169.33it/s]convert squad examples to features:  59%|█████▉    | 705/1190 [00:03<00:02, 184.80it/s]convert squad examples to features:  62%|██████▏   | 737/1190 [00:03<00:02, 197.37it/s]convert squad examples to features:  65%|██████▍   | 769/1190 [00:04<00:02, 206.23it/s]convert squad examples to features:  67%|██████▋   | 801/1190 [00:04<00:01, 212.19it/s]convert squad examples to features:  70%|███████   | 833/1190 [00:04<00:01, 193.98it/s]convert squad examples to features:  73%|███████▎  | 865/1190 [00:04<00:01, 202.56it/s]convert squad examples to features:  75%|███████▌  | 897/1190 [00:04<00:01, 191.04it/s]convert squad examples to features:  78%|███████▊  | 929/1190 [00:05<00:01, 175.11it/s]convert squad examples to features:  81%|████████  | 961/1190 [00:05<00:01, 190.87it/s]convert squad examples to features:  83%|████████▎ | 993/1190 [00:05<00:00, 206.70it/s]convert squad examples to features:  86%|████████▌ | 1025/1190 [00:05<00:00, 220.72it/s]convert squad examples to features:  89%|████████▉ | 1057/1190 [00:05<00:00, 226.08it/s]convert squad examples to features:  92%|█████████▏| 1089/1190 [00:05<00:00, 226.46it/s]convert squad examples to features:  94%|█████████▍| 1121/1190 [00:05<00:00, 205.92it/s]convert squad examples to features:  97%|█████████▋| 1153/1190 [00:06<00:00, 198.25it/s]convert squad examples to features: 100%|██████████| 1190/1190 [00:06<00:00, 196.98it/s]
add example index and unique id:   0%|          | 0/1190 [00:00<?, ?it/s]add example index and unique id: 100%|██████████| 1190/1190 [00:00<00:00, 664344.70it/s]
05/09/2022 19:57:48 - INFO - __main__ -   Saving features into cached file ./cached_xquad.el.json_xlm-KG_LR4e-5_EPOCH2.0_maxlen384_batchsize4_gradacc8_384_el
05/09/2022 19:57:50 - INFO - __main__ -   ***** Running evaluation  *****
05/09/2022 19:57:50 - INFO - __main__ -     Num examples = 1488
05/09/2022 19:57:50 - INFO - __main__ -     Batch size = 8
Evaluating:   0%|          | 0/186 [00:00<?, ?it/s]Evaluating:   1%|          | 1/186 [00:00<02:37,  1.17it/s]Evaluating:   1%|          | 2/186 [00:01<01:42,  1.79it/s]Evaluating:   2%|▏         | 3/186 [00:01<01:25,  2.15it/s]Evaluating:   2%|▏         | 4/186 [00:01<01:16,  2.38it/s]Evaluating:   3%|▎         | 5/186 [00:02<01:11,  2.53it/s]Evaluating:   3%|▎         | 6/186 [00:02<01:08,  2.62it/s]Evaluating:   4%|▍         | 7/186 [00:02<01:06,  2.69it/s]Evaluating:   4%|▍         | 8/186 [00:03<01:04,  2.74it/s]Evaluating:   5%|▍         | 9/186 [00:03<01:04,  2.76it/s]Evaluating:   5%|▌         | 10/186 [00:04<01:03,  2.76it/s]Evaluating:   6%|▌         | 11/186 [00:04<01:03,  2.78it/s]Evaluating:   6%|▋         | 12/186 [00:04<01:02,  2.79it/s]Evaluating:   7%|▋         | 13/186 [00:05<01:01,  2.80it/s]Evaluating:   8%|▊         | 14/186 [00:05<01:01,  2.80it/s]Evaluating:   8%|▊         | 15/186 [00:05<01:01,  2.80it/s]Evaluating:   9%|▊         | 16/186 [00:06<01:00,  2.80it/s]Evaluating:   9%|▉         | 17/186 [00:06<01:00,  2.81it/s]Evaluating:  10%|▉         | 18/186 [00:06<01:00,  2.80it/s]Evaluating:  10%|█         | 19/186 [00:07<00:59,  2.80it/s]Evaluating:  11%|█         | 20/186 [00:07<00:59,  2.80it/s]Evaluating:  11%|█▏        | 21/186 [00:07<00:59,  2.79it/s]Evaluating:  12%|█▏        | 22/186 [00:08<00:58,  2.81it/s]Evaluating:  12%|█▏        | 23/186 [00:08<00:57,  2.81it/s]Evaluating:  13%|█▎        | 24/186 [00:09<00:57,  2.82it/s]Evaluating:  13%|█▎        | 25/186 [00:09<00:57,  2.81it/s]Evaluating:  14%|█▍        | 26/186 [00:09<00:56,  2.81it/s]Evaluating:  15%|█▍        | 27/186 [00:10<00:56,  2.82it/s]Evaluating:  15%|█▌        | 28/186 [00:10<00:56,  2.81it/s]Evaluating:  16%|█▌        | 29/186 [00:10<00:55,  2.82it/s]Evaluating:  16%|█▌        | 30/186 [00:11<00:55,  2.82it/s]Evaluating:  17%|█▋        | 31/186 [00:11<00:55,  2.81it/s]Evaluating:  17%|█▋        | 32/186 [00:11<00:54,  2.81it/s]Evaluating:  18%|█▊        | 33/186 [00:12<00:54,  2.81it/s]Evaluating:  18%|█▊        | 34/186 [00:12<00:54,  2.81it/s]Evaluating:  19%|█▉        | 35/186 [00:12<00:53,  2.80it/s]Evaluating:  19%|█▉        | 36/186 [00:13<00:53,  2.80it/s]Evaluating:  20%|█▉        | 37/186 [00:13<00:53,  2.80it/s]Evaluating:  20%|██        | 38/186 [00:14<00:52,  2.80it/s]Evaluating:  21%|██        | 39/186 [00:14<00:52,  2.80it/s]Evaluating:  22%|██▏       | 40/186 [00:14<00:52,  2.79it/s]Evaluating:  22%|██▏       | 41/186 [00:15<00:51,  2.80it/s]Evaluating:  23%|██▎       | 42/186 [00:15<00:51,  2.80it/s]Evaluating:  23%|██▎       | 43/186 [00:15<00:51,  2.80it/s]Evaluating:  24%|██▎       | 44/186 [00:16<00:50,  2.80it/s]Evaluating:  24%|██▍       | 45/186 [00:16<00:50,  2.80it/s]Evaluating:  25%|██▍       | 46/186 [00:16<00:49,  2.80it/s]Evaluating:  25%|██▌       | 47/186 [00:17<00:49,  2.80it/s]Evaluating:  26%|██▌       | 48/186 [00:17<00:49,  2.81it/s]Evaluating:  26%|██▋       | 49/186 [00:17<00:48,  2.81it/s]Evaluating:  27%|██▋       | 50/186 [00:18<00:48,  2.80it/s]Evaluating:  27%|██▋       | 51/186 [00:18<00:48,  2.80it/s]Evaluating:  28%|██▊       | 52/186 [00:19<00:47,  2.81it/s]Evaluating:  28%|██▊       | 53/186 [00:19<00:47,  2.80it/s]Evaluating:  29%|██▉       | 54/186 [00:19<00:47,  2.80it/s]Evaluating:  30%|██▉       | 55/186 [00:20<00:46,  2.79it/s]Evaluating:  30%|███       | 56/186 [00:20<00:47,  2.76it/s]Evaluating:  31%|███       | 57/186 [00:20<00:46,  2.75it/s]Evaluating:  31%|███       | 58/186 [00:21<00:46,  2.75it/s]Evaluating:  32%|███▏      | 59/186 [00:21<00:48,  2.63it/s]Evaluating:  32%|███▏      | 60/186 [00:22<00:48,  2.59it/s]Evaluating:  33%|███▎      | 61/186 [00:22<00:48,  2.59it/s]Evaluating:  33%|███▎      | 62/186 [00:22<00:47,  2.59it/s]Evaluating:  34%|███▍      | 63/186 [00:23<00:47,  2.57it/s]Evaluating:  34%|███▍      | 64/186 [00:23<00:46,  2.63it/s]Evaluating:  35%|███▍      | 65/186 [00:23<00:45,  2.65it/s]Evaluating:  35%|███▌      | 66/186 [00:24<00:45,  2.62it/s]Evaluating:  36%|███▌      | 67/186 [00:24<00:44,  2.65it/s]Evaluating:  37%|███▋      | 68/186 [00:25<00:43,  2.69it/s]Evaluating:  37%|███▋      | 69/186 [00:25<00:43,  2.72it/s]Evaluating:  38%|███▊      | 70/186 [00:25<00:42,  2.72it/s]Evaluating:  38%|███▊      | 71/186 [00:26<00:41,  2.74it/s]Evaluating:  39%|███▊      | 72/186 [00:26<00:43,  2.64it/s]Evaluating:  39%|███▉      | 73/186 [00:26<00:42,  2.67it/s]Evaluating:  40%|███▉      | 74/186 [00:27<00:41,  2.70it/s]Evaluating:  40%|████      | 75/186 [00:27<00:40,  2.73it/s]Evaluating:  41%|████      | 76/186 [00:27<00:41,  2.66it/s]Evaluating:  41%|████▏     | 77/186 [00:28<00:40,  2.70it/s]Evaluating:  42%|████▏     | 78/186 [00:28<00:40,  2.66it/s]Evaluating:  42%|████▏     | 79/186 [00:29<00:40,  2.63it/s]Evaluating:  43%|████▎     | 80/186 [00:29<00:41,  2.56it/s]Evaluating:  44%|████▎     | 81/186 [00:29<00:40,  2.57it/s]Evaluating:  44%|████▍     | 82/186 [00:30<00:40,  2.59it/s]Evaluating:  45%|████▍     | 83/186 [00:30<00:40,  2.55it/s]Evaluating:  45%|████▌     | 84/186 [00:31<00:40,  2.51it/s]Evaluating:  46%|████▌     | 85/186 [00:31<00:40,  2.50it/s]Evaluating:  46%|████▌     | 86/186 [00:31<00:39,  2.56it/s]Evaluating:  47%|████▋     | 87/186 [00:32<00:37,  2.62it/s]Evaluating:  47%|████▋     | 88/186 [00:32<00:36,  2.66it/s]Evaluating:  48%|████▊     | 89/186 [00:32<00:36,  2.69it/s]Evaluating:  48%|████▊     | 90/186 [00:33<00:35,  2.71it/s]Evaluating:  49%|████▉     | 91/186 [00:33<00:36,  2.57it/s]Evaluating:  49%|████▉     | 92/186 [00:34<00:36,  2.61it/s]Evaluating:  50%|█████     | 93/186 [00:34<00:36,  2.56it/s]Evaluating:  51%|█████     | 94/186 [00:34<00:36,  2.50it/s]Evaluating:  51%|█████     | 95/186 [00:35<00:35,  2.56it/s]Evaluating:  52%|█████▏    | 96/186 [00:35<00:34,  2.62it/s]Evaluating:  52%|█████▏    | 97/186 [00:36<00:33,  2.64it/s]Evaluating:  53%|█████▎    | 98/186 [00:36<00:32,  2.68it/s]Evaluating:  53%|█████▎    | 99/186 [00:36<00:32,  2.71it/s]Evaluating:  54%|█████▍    | 100/186 [00:37<00:31,  2.73it/s]Evaluating:  54%|█████▍    | 101/186 [00:37<00:30,  2.74it/s]Evaluating:  55%|█████▍    | 102/186 [00:37<00:30,  2.76it/s]Evaluating:  55%|█████▌    | 103/186 [00:38<00:30,  2.76it/s]Evaluating:  56%|█████▌    | 104/186 [00:38<00:29,  2.77it/s]Evaluating:  56%|█████▋    | 105/186 [00:38<00:29,  2.77it/s]Evaluating:  57%|█████▋    | 106/186 [00:39<00:29,  2.74it/s]Evaluating:  58%|█████▊    | 107/186 [00:39<00:28,  2.75it/s]Evaluating:  58%|█████▊    | 108/186 [00:40<00:28,  2.76it/s]Evaluating:  59%|█████▊    | 109/186 [00:40<00:27,  2.77it/s]Evaluating:  59%|█████▉    | 110/186 [00:40<00:27,  2.77it/s]Evaluating:  60%|█████▉    | 111/186 [00:41<00:27,  2.77it/s]Evaluating:  60%|██████    | 112/186 [00:41<00:26,  2.77it/s]Evaluating:  61%|██████    | 113/186 [00:41<00:26,  2.77it/s]Evaluating:  61%|██████▏   | 114/186 [00:42<00:25,  2.78it/s]Evaluating:  62%|██████▏   | 115/186 [00:42<00:25,  2.78it/s]Evaluating:  62%|██████▏   | 116/186 [00:42<00:25,  2.78it/s]Evaluating:  63%|██████▎   | 117/186 [00:43<00:24,  2.78it/s]Evaluating:  63%|██████▎   | 118/186 [00:43<00:24,  2.78it/s]Evaluating:  64%|██████▍   | 119/186 [00:44<00:24,  2.78it/s]Evaluating:  65%|██████▍   | 120/186 [00:44<00:23,  2.78it/s]Evaluating:  65%|██████▌   | 121/186 [00:44<00:23,  2.78it/s]Evaluating:  66%|██████▌   | 122/186 [00:45<00:23,  2.77it/s]Evaluating:  66%|██████▌   | 123/186 [00:45<00:22,  2.78it/s]Evaluating:  67%|██████▋   | 124/186 [00:45<00:22,  2.78it/s]Evaluating:  67%|██████▋   | 125/186 [00:46<00:21,  2.79it/s]Evaluating:  68%|██████▊   | 126/186 [00:46<00:21,  2.79it/s]Evaluating:  68%|██████▊   | 127/186 [00:46<00:21,  2.79it/s]Evaluating:  69%|██████▉   | 128/186 [00:47<00:20,  2.79it/s]Evaluating:  69%|██████▉   | 129/186 [00:47<00:20,  2.79it/s]Evaluating:  70%|██████▉   | 130/186 [00:47<00:20,  2.79it/s]Evaluating:  70%|███████   | 131/186 [00:48<00:19,  2.79it/s]Evaluating:  71%|███████   | 132/186 [00:48<00:19,  2.79it/s]Evaluating:  72%|███████▏  | 133/186 [00:49<00:18,  2.79it/s]Evaluating:  72%|███████▏  | 134/186 [00:49<00:18,  2.79it/s]Evaluating:  73%|███████▎  | 135/186 [00:49<00:18,  2.79it/s]Evaluating:  73%|███████▎  | 136/186 [00:50<00:17,  2.78it/s]Evaluating:  74%|███████▎  | 137/186 [00:50<00:17,  2.78it/s]Evaluating:  74%|███████▍  | 138/186 [00:50<00:17,  2.78it/s]Evaluating:  75%|███████▍  | 139/186 [00:51<00:16,  2.78it/s]Evaluating:  75%|███████▌  | 140/186 [00:51<00:16,  2.78it/s]Evaluating:  76%|███████▌  | 141/186 [00:51<00:16,  2.78it/s]Evaluating:  76%|███████▋  | 142/186 [00:52<00:15,  2.78it/s]Evaluating:  77%|███████▋  | 143/186 [00:52<00:15,  2.78it/s]Evaluating:  77%|███████▋  | 144/186 [00:53<00:15,  2.78it/s]Evaluating:  78%|███████▊  | 145/186 [00:53<00:14,  2.78it/s]Evaluating:  78%|███████▊  | 146/186 [00:53<00:14,  2.78it/s]Evaluating:  79%|███████▉  | 147/186 [00:54<00:14,  2.78it/s]Evaluating:  80%|███████▉  | 148/186 [00:54<00:13,  2.78it/s]Evaluating:  80%|████████  | 149/186 [00:54<00:13,  2.78it/s]Evaluating:  81%|████████  | 150/186 [00:55<00:12,  2.78it/s]Evaluating:  81%|████████  | 151/186 [00:55<00:12,  2.78it/s]Evaluating:  82%|████████▏ | 152/186 [00:55<00:12,  2.78it/s]Evaluating:  82%|████████▏ | 153/186 [00:56<00:11,  2.78it/s]Evaluating:  83%|████████▎ | 154/186 [00:56<00:11,  2.79it/s]Evaluating:  83%|████████▎ | 155/186 [00:56<00:11,  2.79it/s]Evaluating:  84%|████████▍ | 156/186 [00:57<00:10,  2.79it/s]Evaluating:  84%|████████▍ | 157/186 [00:57<00:10,  2.79it/s]Evaluating:  85%|████████▍ | 158/186 [00:58<00:10,  2.79it/s]Evaluating:  85%|████████▌ | 159/186 [00:58<00:09,  2.78it/s]Evaluating:  86%|████████▌ | 160/186 [00:58<00:09,  2.79it/s]Evaluating:  87%|████████▋ | 161/186 [00:59<00:09,  2.75it/s]Evaluating:  87%|████████▋ | 162/186 [00:59<00:08,  2.76it/s]Evaluating:  88%|████████▊ | 163/186 [00:59<00:08,  2.76it/s]Evaluating:  88%|████████▊ | 164/186 [01:00<00:07,  2.77it/s]Evaluating:  89%|████████▊ | 165/186 [01:00<00:07,  2.78it/s]Evaluating:  89%|████████▉ | 166/186 [01:00<00:07,  2.77it/s]Evaluating:  90%|████████▉ | 167/186 [01:01<00:06,  2.78it/s]Evaluating:  90%|█████████ | 168/186 [01:01<00:06,  2.78it/s]Evaluating:  91%|█████████ | 169/186 [01:01<00:06,  2.78it/s]Evaluating:  91%|█████████▏| 170/186 [01:02<00:05,  2.79it/s]Evaluating:  92%|█████████▏| 171/186 [01:02<00:05,  2.79it/s]Evaluating:  92%|█████████▏| 172/186 [01:03<00:05,  2.79it/s]Evaluating:  93%|█████████▎| 173/186 [01:03<00:04,  2.79it/s]Evaluating:  94%|█████████▎| 174/186 [01:03<00:04,  2.79it/s]Evaluating:  94%|█████████▍| 175/186 [01:04<00:03,  2.79it/s]Evaluating:  95%|█████████▍| 176/186 [01:04<00:03,  2.78it/s]Evaluating:  95%|█████████▌| 177/186 [01:04<00:03,  2.78it/s]Evaluating:  96%|█████████▌| 178/186 [01:05<00:02,  2.78it/s]Evaluating:  96%|█████████▌| 179/186 [01:05<00:02,  2.77it/s]Evaluating:  97%|█████████▋| 180/186 [01:05<00:02,  2.77it/s]Evaluating:  97%|█████████▋| 181/186 [01:06<00:01,  2.78it/s]Evaluating:  98%|█████████▊| 182/186 [01:06<00:01,  2.78it/s]Evaluating:  98%|█████████▊| 183/186 [01:07<00:01,  2.77it/s]Evaluating:  99%|█████████▉| 184/186 [01:07<00:00,  2.77it/s]Evaluating:  99%|█████████▉| 185/186 [01:07<00:00,  2.68it/s]Evaluating: 100%|██████████| 186/186 [01:08<00:00,  2.71it/s]Evaluating: 100%|██████████| 186/186 [01:08<00:00,  2.73it/s]
05/09/2022 19:58:58 - INFO - __main__ -     Evaluation done in total 68.154587 secs (0.045803 sec per example)
05/09/2022 19:59:02 - INFO - __main__ -   Results: {'exact': 63.445378151260506, 'f1': 80.1961574485665, 'total': 1190, 'HasAns_exact': 63.445378151260506, 'HasAns_f1': 80.1961574485665, 'HasAns_total': 1190, 'best_exact': 63.445378151260506, 'best_exact_thresh': 0.0, 'best_f1': 80.1961574485665, 'best_f1_thresh': 0.0}
  ru 
2022-05-09 19:59:08.366682: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0
05/09/2022 19:59:13 - WARNING - __main__ -   Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, 16-bits training: False
You are using a model of type xlm-roberta to instantiate a model of type xlm. This is not supported for all configurations of models and can yield errors.
Some weights of the model checkpoint at /cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//squad/xlm-KG_LR4e-5_EPOCH2.0_maxlen384_batchsize4_gradacc8 were not used when initializing XLMRobertaModel: ['base_model.encoder.layer.19.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.12.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.15.attention.self.key.weight', 'base_model.encoder.layer.8.intermediate.dense.bias', 'base_model.encoder.layer.22.intermediate.dense.bias', 'base_model.encoder.layer.6.output.dense.weight', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.5.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.10.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.5.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.23.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.19.attention.self.value.bias', 'base_model.encoder.layer.19.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.16.attention.self.key.weight', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.11.attention.output.dense.weight', 'base_model.encoder.layer.18.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.15.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.17.output.LayerNorm.weight', 'base_model.encoder.layer.20.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.23.attention.self.query.weight', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.10.attention.self.value.weight', 'base_model.encoder.layer.4.output.dense.weight', 'base_model.encoder.layer.5.attention.output.dense.weight', 'base_model.encoder.layer.5.attention.self.value.weight', 'base_model.encoder.layer.10.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.19.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.0.attention.output.dense.weight', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.1.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.17.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.3.attention.self.key.bias', 'base_model.encoder.layer.20.attention.output.dense.weight', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.4.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.10.attention.self.key.weight', 'base_model.encoder.layer.22.attention.self.value.weight', 'base_model.encoder.layer.0.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.7.attention.output.LayerNorm.weight', 'base_model.encoder.layer.2.attention.output.LayerNorm.weight', 'base_model.encoder.layer.6.output.LayerNorm.bias', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.22.attention.self.query.bias', 'base_model.encoder.layer.17.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.22.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.18.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.11.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.4.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.23.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.22.attention.self.key.weight', 'base_model.encoder.layer.16.attention.output.dense.weight', 'base_model.encoder.layer.11.output.dense.bias', 'base_model.encoder.layer.0.intermediate.dense.weight', 'base_model.encoder.layer.7.output.dense.weight', 'base_model.encoder.layer.3.attention.output.dense.bias', 'base_model.encoder.layer.17.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.4.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.1.attention.self.key.weight', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.10.attention.self.value.bias', 'base_model.encoder.layer.23.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.23.attention.output.LayerNorm.weight', 'base_model.encoder.layer.11.output.LayerNorm.weight', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.7.intermediate.dense.bias', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.12.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.3.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.1.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.9.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.15.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.21.attention.self.query.bias', 'base_model.encoder.layer.2.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.10.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.21.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.20.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.1.intermediate.dense.bias', 'base_model.encoder.layer.10.intermediate.dense.weight', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.17.attention.output.dense.weight', 'base_model.pooler.dense.weight', 'base_model.encoder.layer.21.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.15.intermediate.dense.weight', 'base_model.encoder.layer.7.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.8.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.2.attention.self.key.bias', 'base_model.encoder.layer.9.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.11.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.10.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.8.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.6.attention.self.value.weight', 'base_model.encoder.layer.13.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.17.attention.output.dense.bias', 'base_model.encoder.layer.20.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.12.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.23.output.dense.weight', 'base_model.encoder.layer.13.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.19.attention.output.dense.weight', 'base_model.encoder.layer.13.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.14.attention.self.query.bias', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.10.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.14.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.14.attention.self.value.weight', 'base_model.encoder.layer.21.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.21.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.23.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.22.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.5.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.6.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.19.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.7.attention.output.dense.weight', 'base_model.encoder.layer.10.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.12.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.11.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.10.output.dense.weight', 'base_model.encoder.layer.13.attention.self.query.weight', 'base_model.encoder.layer.14.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.16.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.2.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.7.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.10.output.LayerNorm.weight', 'base_model.encoder.layer.15.output.dense.weight', 'base_model.encoder.layer.21.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.7.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.11.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.17.attention.self.query.bias', 'base_model.encoder.layer.19.attention.self.value.weight', 'base_model.encoder.layer.0.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.12.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.1.attention.self.query.bias', 'base_model.encoder.layer.23.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.21.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.23.attention.self.query.bias', 'base_model.encoder.layer.23.attention.output.dense.bias', 'base_model.encoder.layer.5.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.13.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.11.attention.self.value.weight', 'base_model.encoder.layer.15.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.11.output.LayerNorm.bias', 'base_model.encoder.layer.1.intermediate.dense.weight', 'base_model.encoder.layer.0.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.4.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.3.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.14.attention.output.dense.weight', 'base_model.encoder.layer.0.output.LayerNorm.weight', 'base_model.encoder.layer.0.attention.self.value.weight', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.8.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.23.attention.output.LayerNorm.bias', 'base_model.encoder.layer.13.output.LayerNorm.weight', 'base_model.encoder.layer.23.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.17.attention.self.value.bias', 'base_model.encoder.layer.1.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.8.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.4.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.9.attention.output.dense.weight', 'base_model.encoder.layer.9.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.15.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.15.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.8.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.20.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.11.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.5.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.2.attention.self.query.weight', 'base_model.encoder.layer.10.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.4.attention.self.query.bias', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.9.attention.output.dense.bias', 'base_model.encoder.layer.6.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.8.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.1.attention.output.LayerNorm.weight', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.21.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.19.attention.self.key.weight', 'base_model.encoder.layer.6.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.21.attention.self.key.weight', 'base_model.encoder.layer.12.attention.output.dense.weight', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.1.output.dense.bias', 'base_model.encoder.layer.2.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.4.output.LayerNorm.weight', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.11.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.15.attention.self.value.weight', 'base_model.encoder.layer.8.output.dense.bias', 'base_model.encoder.layer.17.output.dense.weight', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.20.output.LayerNorm.bias', 'base_model.encoder.layer.4.attention.self.value.bias', 'base_model.encoder.layer.7.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.5.intermediate.dense.weight', 'base_model.encoder.layer.11.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.10.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.18.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.19.attention.output.dense.bias', 'base_model.encoder.layer.13.attention.self.query.bias', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.22.output.adapters.ts.adapter_down.0.bias', 'base_model.embeddings.word_embeddings.weight', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.2.output.LayerNorm.weight', 'base_model.encoder.layer.5.output.LayerNorm.weight', 'base_model.encoder.layer.10.output.dense.bias', 'base_model.encoder.layer.13.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.15.attention.output.dense.bias', 'base_model.encoder.layer.2.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.7.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.9.output.dense.weight', 'base_model.encoder.layer.12.intermediate.dense.bias', 'base_model.encoder.layer.4.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.3.attention.self.value.bias', 'base_model.encoder.layer.21.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.0.attention.self.query.weight', 'base_model.encoder.layer.18.attention.self.key.bias', 'base_model.encoder.layer.16.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.19.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.11.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.22.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.9.intermediate.dense.weight', 'base_model.encoder.layer.23.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.14.attention.self.key.weight', 'base_model.encoder.layer.17.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.5.intermediate.dense.bias', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.19.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.15.attention.self.query.bias', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.12.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.13.attention.output.LayerNorm.weight', 'base_model.encoder.layer.4.output.LayerNorm.bias', 'base_model.encoder.layer.22.attention.self.value.bias', 'base_model.encoder.layer.6.attention.output.LayerNorm.bias', 'base_model.encoder.layer.8.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.20.attention.self.query.bias', 'base_model.encoder.layer.11.output.dense.weight', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.1.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.19.output.LayerNorm.bias', 'base_model.encoder.layer.20.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.20.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.23.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.19.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.0.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.21.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.2.attention.self.query.bias', 'base_model.encoder.layer.19.intermediate.dense.weight', 'base_model.encoder.layer.11.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.6.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.16.attention.self.query.bias', 'base_model.encoder.layer.16.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.16.attention.self.query.weight', 'base_model.encoder.layer.1.output.dense.weight', 'base_model.encoder.layer.6.attention.output.LayerNorm.weight', 'base_model.encoder.layer.0.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.18.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.22.output.dense.weight', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.13.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.2.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.17.intermediate.dense.weight', 'base_model.encoder.layer.13.output.dense.bias', 'base_model.encoder.layer.18.attention.output.LayerNorm.bias', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.16.attention.output.dense.bias', 'base_model.encoder.layer.0.output.dense.weight', 'base_model.encoder.layer.3.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.6.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.13.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.15.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.16.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.10.output.LayerNorm.bias', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.8.attention.output.LayerNorm.bias', 'base_model.encoder.layer.14.attention.output.LayerNorm.bias', 'base_model.encoder.layer.16.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.1.attention.output.LayerNorm.bias', 'base_model.encoder.layer.16.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.6.attention.output.dense.bias', 'base_model.encoder.layer.1.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.7.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.16.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.4.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.20.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.17.intermediate.dense.bias', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.16.output.LayerNorm.bias', 'base_model.encoder.layer.18.output.dense.weight', 'base_model.encoder.layer.16.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.10.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.11.attention.self.key.bias', 'base_model.encoder.layer.23.attention.self.key.weight', 'base_model.encoder.layer.3.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.6.attention.output.dense.weight', 'base_model.encoder.layer.10.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.5.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.4.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.8.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.13.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.5.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.11.attention.self.query.weight', 'base_model.encoder.layer.5.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.16.intermediate.dense.weight', 'base_model.encoder.layer.16.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.1.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.22.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.17.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.21.intermediate.dense.weight', 'base_model.encoder.layer.17.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.4.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.9.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.5.output.dense.bias', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.3.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.9.output.LayerNorm.bias', 'base_model.encoder.layer.3.attention.self.value.weight', 'base_model.encoder.layer.17.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.15.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.23.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.7.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.18.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.3.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.0.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.7.output.dense.bias', 'base_model.encoder.layer.8.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.10.attention.output.dense.bias', 'base_model.encoder.layer.14.attention.self.query.weight', 'base_model.encoder.layer.19.intermediate.dense.bias', 'base_model.encoder.layer.20.attention.self.key.bias', 'base_model.encoder.layer.15.attention.self.key.bias', 'base_model.encoder.layer.1.attention.self.value.bias', 'base_model.encoder.layer.0.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.1.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.19.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.17.attention.self.value.weight', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.9.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.15.attention.self.query.weight', 'base_model.encoder.layer.18.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.3.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.12.output.LayerNorm.bias', 'base_model.encoder.layer.12.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.15.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.14.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.22.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.23.attention.self.value.weight', 'base_model.encoder.layer.13.attention.self.key.weight', 'base_model.encoder.layer.10.attention.self.key.bias', 'base_model.encoder.layer.11.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.21.attention.output.LayerNorm.bias', 'base_model.encoder.layer.22.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.21.output.LayerNorm.weight', 'base_model.encoder.layer.12.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.9.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.4.intermediate.dense.bias', 'base_model.encoder.layer.2.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.1.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.5.attention.output.dense.bias', 'base_model.encoder.layer.10.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.20.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.4.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.6.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.7.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.18.attention.self.query.bias', 'base_model.encoder.layer.15.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.4.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.6.attention.self.key.bias', 'base_model.encoder.layer.19.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.7.attention.self.key.weight', 'base_model.encoder.layer.18.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.19.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.7.output.LayerNorm.bias', 'base_model.encoder.layer.15.intermediate.dense.bias', 'base_model.encoder.layer.21.attention.output.dense.bias', 'base_model.encoder.layer.23.output.LayerNorm.weight', 'base_model.encoder.layer.0.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.3.attention.output.dense.weight', 'base_model.encoder.layer.18.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.17.output.LayerNorm.bias', 'base_model.encoder.layer.0.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.11.attention.output.LayerNorm.bias', 'base_model.encoder.layer.22.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.3.attention.self.key.weight', 'base_model.encoder.layer.11.intermediate.dense.bias', 'base_model.encoder.layer.17.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.14.intermediate.dense.bias', 'base_model.encoder.layer.2.attention.self.key.weight', 'base_model.encoder.layer.0.attention.output.LayerNorm.weight', 'base_model.encoder.layer.13.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.4.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.3.output.dense.bias', 'base_model.encoder.layer.7.attention.output.dense.bias', 'base_model.encoder.layer.6.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.15.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.18.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.13.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.14.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.15.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.2.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.20.attention.self.query.weight', 'base_model.encoder.layer.17.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.0.attention.self.query.bias', 'base_model.encoder.layer.7.attention.self.key.bias', 'base_model.encoder.layer.4.output.dense.bias', 'base_model.encoder.layer.19.attention.self.query.weight', 'base_model.encoder.layer.8.intermediate.dense.weight', 'base_model.encoder.layer.15.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.2.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.0.output.dense.bias', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.8.attention.output.dense.bias', 'base_model.encoder.layer.10.attention.output.dense.weight', 'base_model.encoder.layer.12.attention.self.value.bias', 'base_model.encoder.layer.14.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.3.output.LayerNorm.bias', 'base_model.encoder.layer.8.output.dense.weight', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.21.attention.self.query.weight', 'base_model.encoder.layer.21.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.6.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.22.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.12.output.LayerNorm.weight', 'base_model.encoder.layer.23.attention.output.dense.weight', 'base_model.encoder.layer.16.attention.self.key.bias', 'base_model.encoder.layer.18.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.0.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.12.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.23.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.21.output.LayerNorm.bias', 'base_model.encoder.layer.5.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.8.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.14.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.18.attention.output.dense.weight', 'base_model.encoder.layer.21.attention.output.dense.weight', 'base_model.encoder.layer.16.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.4.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.17.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.15.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.9.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.2.attention.self.value.bias', 'base_model.encoder.layer.11.attention.output.LayerNorm.weight', 'base_model.encoder.layer.5.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.3.attention.output.LayerNorm.bias', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.5.attention.self.query.weight', 'base_model.encoder.layer.19.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.19.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.15.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.6.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.15.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.22.attention.self.key.bias', 'base_model.encoder.layer.23.output.dense.bias', 'base_model.encoder.layer.1.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.4.attention.self.query.weight', 'base_model.encoder.layer.6.attention.self.query.bias', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.18.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.18.attention.self.key.weight', 'base_model.encoder.layer.21.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.15.output.dense.bias', 'base_model.encoder.layer.9.attention.output.LayerNorm.bias', 'base_model.encoder.layer.11.attention.output.dense.bias', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.22.attention.output.LayerNorm.bias', 'base_model.encoder.layer.14.output.LayerNorm.weight', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.21.attention.output.LayerNorm.weight', 'base_model.encoder.layer.12.attention.self.query.bias', 'base_model.encoder.layer.3.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.19.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.2.attention.output.dense.weight', 'base_model.encoder.layer.21.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.13.output.dense.weight', 'base_model.encoder.layer.20.attention.self.value.bias', 'base_model.encoder.layer.9.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.4.attention.output.dense.bias', 'base_model.encoder.layer.19.attention.output.LayerNorm.bias', 'base_model.embeddings.LayerNorm.bias', 'base_model.encoder.layer.5.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.20.output.dense.bias', 'base_model.encoder.layer.20.attention.output.LayerNorm.bias', 'base_model.encoder.layer.16.output.dense.bias', 'base_model.encoder.layer.22.output.LayerNorm.weight', 'base_model.encoder.layer.8.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.21.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.6.output.LayerNorm.weight', 'base_model.encoder.layer.9.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.14.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.15.attention.output.LayerNorm.weight', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.2.intermediate.dense.weight', 'base_model.encoder.layer.22.attention.output.LayerNorm.weight', 'base_model.embeddings.position_embeddings.weight', 'base_model.encoder.layer.7.attention.self.value.bias', 'base_model.encoder.layer.22.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.9.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.9.attention.self.value.weight', 'base_model.encoder.layer.7.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.23.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.22.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.10.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.3.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.5.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.23.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.0.output.LayerNorm.bias', 'base_model.encoder.layer.6.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.7.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.23.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.7.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.17.attention.self.key.weight', 'base_model.encoder.layer.2.output.LayerNorm.bias', 'base_model.encoder.layer.9.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.12.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.19.output.LayerNorm.weight', 'base_model.encoder.layer.3.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.5.attention.self.key.weight', 'base_model.encoder.layer.21.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.22.intermediate.dense.weight', 'base_model.encoder.layer.16.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.9.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.9.attention.output.LayerNorm.weight', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.21.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.11.intermediate.dense.weight', 'base_model.encoder.layer.6.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.12.attention.self.value.weight', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.3.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.13.attention.self.value.bias', 'base_model.encoder.layer.8.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.14.attention.output.LayerNorm.weight', 'base_model.encoder.layer.3.attention.self.query.bias', 'base_model.encoder.layer.20.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.20.attention.output.dense.bias', 'base_model.encoder.layer.22.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.9.attention.self.key.bias', 'base_model.encoder.layer.2.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.10.attention.output.LayerNorm.bias', 'base_model.encoder.layer.22.attention.output.dense.bias', 'base_model.encoder.layer.17.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.20.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.14.output.dense.weight', 'base_model.encoder.layer.19.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.14.attention.self.key.bias', 'base_model.encoder.layer.9.attention.self.key.weight', 'base_model.encoder.layer.16.output.dense.weight', 'base_model.encoder.layer.17.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.10.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.12.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.0.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.6.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.8.attention.output.dense.weight', 'base_model.encoder.layer.12.attention.output.dense.bias', 'base_model.encoder.layer.11.attention.self.key.weight', 'base_model.encoder.layer.9.attention.self.query.bias', 'base_model.encoder.layer.1.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.11.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.19.attention.output.LayerNorm.weight', 'base_model.encoder.layer.16.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.14.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.15.output.LayerNorm.weight', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.embeddings.LayerNorm.weight', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.21.attention.self.key.bias', 'base_model.encoder.layer.10.attention.self.query.weight', 'base_model.encoder.layer.21.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.16.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.1.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.13.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.8.output.LayerNorm.weight', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.12.attention.output.LayerNorm.bias', 'base_model.encoder.layer.7.intermediate.dense.weight', 'base_model.encoder.layer.17.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.15.attention.output.dense.weight', 'base_model.encoder.layer.1.attention.output.dense.weight', 'base_model.encoder.layer.21.output.dense.weight', 'base_model.encoder.layer.17.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.20.attention.output.LayerNorm.weight', 'base_model.encoder.layer.11.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.14.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.7.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.23.output.LayerNorm.bias', 'base_model.encoder.layer.16.attention.self.value.weight', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.12.attention.self.key.weight', 'base_model.encoder.layer.15.attention.output.LayerNorm.bias', 'base_model.encoder.layer.18.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.1.attention.self.key.bias', 'base_model.encoder.layer.2.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.4.attention.output.dense.weight', 'base_model.encoder.layer.18.output.dense.bias', 'base_model.encoder.layer.9.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.17.attention.output.LayerNorm.weight', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.18.intermediate.dense.bias', 'base_model.encoder.layer.23.intermediate.dense.bias', 'base_model.encoder.layer.22.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.12.output.dense.weight', 'base_model.encoder.layer.10.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.8.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.3.attention.output.LayerNorm.weight', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.4.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.0.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.4.intermediate.dense.weight', 'base_model.encoder.layer.1.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.6.attention.self.key.weight', 'base_model.encoder.layer.14.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.2.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.12.output.adapters.tp.adapter_down.0.weight', 'base_model.pooler.dense.bias', 'base_model.encoder.layer.0.attention.self.key.weight', 'base_model.encoder.layer.16.attention.self.value.bias', 'base_model.encoder.layer.3.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.14.output.dense.bias', 'base_model.encoder.layer.16.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.14.intermediate.dense.weight', 'base_model.encoder.layer.3.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.18.attention.self.value.weight', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.6.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.12.output.dense.bias', 'base_model.encoder.layer.23.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.15.output.LayerNorm.bias', 'base_model.encoder.layer.14.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.0.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.6.attention.self.value.bias', 'base_model.encoder.layer.8.attention.self.key.weight', 'base_model.encoder.layer.9.output.LayerNorm.weight', 'base_model.encoder.layer.2.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.21.attention.self.value.bias', 'base_model.encoder.layer.15.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.21.intermediate.dense.bias', 'base_model.encoder.layer.18.output.LayerNorm.bias', 'base_model.encoder.layer.20.intermediate.dense.bias', 'base_model.encoder.layer.23.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.3.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.13.intermediate.dense.weight', 'base_model.encoder.layer.19.output.dense.bias', 'base_model.encoder.layer.2.output.adapters.tp.adapter_down.0.weight', 'qa_outputs.weight', 'base_model.encoder.layer.18.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.11.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.17.attention.output.LayerNorm.bias', 'base_model.encoder.layer.17.attention.self.query.weight', 'base_model.encoder.layer.23.attention.self.key.bias', 'base_model.encoder.layer.11.attention.self.query.bias', 'base_model.encoder.layer.14.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.10.attention.self.query.bias', 'base_model.encoder.layer.5.attention.self.key.bias', 'base_model.encoder.layer.10.intermediate.dense.bias', 'base_model.encoder.layer.5.attention.output.LayerNorm.bias', 'base_model.encoder.layer.19.attention.self.key.bias', 'base_model.encoder.layer.9.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.22.attention.self.query.weight', 'base_model.encoder.layer.8.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.13.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.8.attention.self.value.weight', 'base_model.encoder.layer.12.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.5.attention.self.query.bias', 'base_model.encoder.layer.2.attention.output.dense.bias', 'base_model.encoder.layer.14.output.adapters.ts.adapter_up.bias', 'qa_outputs.bias', 'base_model.encoder.layer.18.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.20.attention.self.value.weight', 'base_model.encoder.layer.4.attention.output.LayerNorm.weight', 'base_model.encoder.layer.20.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.13.attention.output.dense.bias', 'base_model.encoder.layer.11.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.7.attention.self.value.weight', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.0.attention.self.value.bias', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.18.attention.self.value.bias', 'base_model.encoder.layer.16.attention.output.LayerNorm.bias', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.2.attention.output.LayerNorm.bias', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.14.output.LayerNorm.bias', 'base_model.encoder.layer.0.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.2.intermediate.dense.bias', 'base_model.encoder.layer.17.attention.self.key.bias', 'base_model.encoder.layer.0.attention.output.dense.bias', 'base_model.encoder.layer.5.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.2.output.dense.weight', 'base_model.encoder.layer.12.attention.self.query.weight', 'base_model.embeddings.position_ids', 'base_model.encoder.layer.5.attention.self.value.bias', 'base_model.encoder.layer.10.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.10.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.2.output.dense.bias', 'base_model.encoder.layer.6.output.dense.bias', 'base_model.encoder.layer.13.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.5.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.17.output.dense.bias', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.0.attention.output.LayerNorm.bias', 'base_model.encoder.layer.1.attention.self.query.weight', 'base_model.encoder.layer.1.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.5.output.dense.weight', 'base_model.encoder.layer.22.output.LayerNorm.bias', 'base_model.encoder.layer.23.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.3.intermediate.dense.bias', 'base_model.encoder.layer.13.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.3.attention.self.query.weight', 'base_model.encoder.layer.4.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.16.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.17.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.20.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.2.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.22.output.dense.bias', 'base_model.encoder.layer.22.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.3.output.LayerNorm.weight', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.6.intermediate.dense.bias', 'base_model.encoder.layer.7.attention.self.query.weight', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.12.intermediate.dense.weight', 'base_model.encoder.layer.13.attention.output.dense.weight', 'base_model.encoder.layer.16.output.LayerNorm.weight', 'base_model.encoder.layer.18.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.18.output.LayerNorm.weight', 'base_model.encoder.layer.18.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.8.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.18.attention.output.LayerNorm.weight', 'base_model.encoder.layer.3.intermediate.dense.weight', 'base_model.encoder.layer.18.intermediate.dense.weight', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.13.intermediate.dense.bias', 'base_model.encoder.layer.6.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.0.attention.self.key.bias', 'base_model.encoder.layer.7.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.17.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.19.output.dense.weight', 'base_model.encoder.layer.4.attention.output.LayerNorm.bias', 'base_model.encoder.layer.4.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.2.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.1.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.13.attention.output.LayerNorm.bias', 'base_model.encoder.layer.7.output.LayerNorm.weight', 'base_model.encoder.layer.14.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.21.output.dense.bias', 'base_model.encoder.layer.4.attention.self.value.weight', 'base_model.encoder.layer.19.attention.self.query.bias', 'base_model.encoder.layer.5.attention.output.LayerNorm.weight', 'base_model.encoder.layer.6.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.12.attention.output.LayerNorm.weight', 'base_model.encoder.layer.11.attention.self.value.bias', 'base_model.encoder.layer.9.attention.self.query.weight', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.13.attention.self.key.bias', 'base_model.encoder.layer.19.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.0.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.8.attention.self.value.bias', 'base_model.encoder.layer.12.output.adapters.ts.adapter_down.0.bias', 'base_model.embeddings.token_type_embeddings.weight', 'base_model.encoder.layer.1.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.14.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.14.attention.output.dense.bias', 'base_model.encoder.layer.20.output.LayerNorm.weight', 'base_model.encoder.layer.8.attention.self.query.bias', 'base_model.encoder.layer.11.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.6.attention.self.query.weight', 'base_model.encoder.layer.20.intermediate.dense.weight', 'base_model.encoder.layer.4.attention.self.key.bias', 'base_model.encoder.layer.22.attention.output.dense.weight', 'base_model.encoder.layer.6.intermediate.dense.weight', 'base_model.encoder.layer.20.attention.self.key.weight', 'base_model.encoder.layer.20.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.13.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.1.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.9.attention.self.value.bias', 'base_model.encoder.layer.4.attention.self.key.weight', 'base_model.encoder.layer.8.attention.self.key.bias', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.8.output.LayerNorm.bias', 'base_model.encoder.layer.7.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.7.attention.output.LayerNorm.bias', 'base_model.encoder.layer.0.intermediate.dense.bias', 'base_model.encoder.layer.12.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.18.attention.output.dense.bias', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.7.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.10.attention.output.LayerNorm.weight', 'base_model.encoder.layer.14.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.7.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.11.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.12.attention.self.key.bias', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.13.attention.self.value.weight', 'base_model.encoder.layer.3.output.dense.weight', 'base_model.encoder.layer.5.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.7.attention.self.query.bias', 'base_model.encoder.layer.2.attention.self.value.weight', 'base_model.encoder.layer.13.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.21.attention.self.value.weight', 'base_model.encoder.layer.16.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.9.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.20.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.20.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.1.output.LayerNorm.bias', 'base_model.encoder.layer.5.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.20.output.dense.weight', 'base_model.encoder.layer.22.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.1.output.LayerNorm.weight', 'base_model.encoder.layer.9.output.dense.bias', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.18.attention.self.query.weight', 'base_model.encoder.layer.19.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.5.output.LayerNorm.bias', 'base_model.encoder.layer.0.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.8.attention.self.query.weight', 'base_model.encoder.layer.16.intermediate.dense.bias', 'base_model.encoder.layer.23.attention.self.value.bias', 'base_model.encoder.layer.16.attention.output.LayerNorm.weight', 'base_model.encoder.layer.1.attention.self.value.weight', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.3.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.20.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.2.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.8.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.6.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.1.attention.output.dense.bias', 'base_model.encoder.layer.15.attention.self.value.bias', 'base_model.encoder.layer.9.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.13.output.LayerNorm.bias', 'base_model.encoder.layer.9.intermediate.dense.bias', 'base_model.encoder.layer.12.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.14.attention.self.value.bias', 'base_model.encoder.layer.22.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.3.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.23.intermediate.dense.weight', 'base_model.encoder.layer.8.attention.output.LayerNorm.weight']
- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of XLMRobertaModel were not initialized from the model checkpoint at /cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//squad/xlm-KG_LR4e-5_EPOCH2.0_maxlen384_batchsize4_gradacc8 and are newly initialized: ['encoder.layer.3.attention.self.key.weight', 'encoder.layer.5.output.dense.weight', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.12.attention.self.key.bias', 'encoder.layer.20.intermediate.dense.bias', 'encoder.layer.14.intermediate.dense.weight', 'encoder.layer.18.attention.output.dense.weight', 'encoder.layer.19.output.LayerNorm.bias', 'encoder.layer.11.attention.self.key.bias', 'encoder.layer.11.attention.output.dense.weight', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.12.attention.output.LayerNorm.weight', 'encoder.layer.12.intermediate.dense.weight', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.11.output.dense.weight', 'encoder.layer.5.attention.self.key.bias', 'embeddings.word_embeddings.weight', 'encoder.layer.10.attention.self.key.bias', 'encoder.layer.7.attention.self.key.bias', 'encoder.layer.16.attention.self.value.bias', 'encoder.layer.19.intermediate.dense.bias', 'encoder.layer.10.attention.output.dense.weight', 'encoder.layer.5.attention.self.key.weight', 'encoder.layer.17.attention.self.query.bias', 'encoder.layer.17.attention.output.LayerNorm.weight', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.17.attention.output.dense.bias', 'encoder.layer.1.attention.output.LayerNorm.weight', 'encoder.layer.23.attention.self.value.bias', 'encoder.layer.13.attention.output.LayerNorm.bias', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.14.output.LayerNorm.bias', 'encoder.layer.18.attention.self.query.bias', 'encoder.layer.18.attention.output.dense.bias', 'encoder.layer.17.attention.self.query.weight', 'encoder.layer.0.attention.output.dense.bias', 'encoder.layer.16.attention.output.LayerNorm.bias', 'encoder.layer.1.attention.output.dense.weight', 'encoder.layer.20.attention.self.value.bias', 'encoder.layer.8.output.dense.weight', 'encoder.layer.23.output.dense.bias', 'encoder.layer.0.attention.self.key.bias', 'encoder.layer.17.output.dense.bias', 'encoder.layer.14.attention.self.value.bias', 'encoder.layer.15.attention.self.value.weight', 'encoder.layer.21.attention.self.key.weight', 'encoder.layer.11.attention.self.value.weight', 'encoder.layer.22.attention.self.key.weight', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.8.attention.output.dense.bias', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.17.attention.self.value.weight', 'encoder.layer.12.attention.self.query.weight', 'encoder.layer.9.attention.self.key.weight', 'encoder.layer.23.attention.self.value.weight', 'encoder.layer.23.attention.self.query.weight', 'encoder.layer.6.attention.output.dense.weight', 'encoder.layer.3.output.dense.bias', 'encoder.layer.19.attention.self.value.bias', 'encoder.layer.4.attention.self.value.weight', 'encoder.layer.16.output.dense.weight', 'encoder.layer.8.attention.output.LayerNorm.weight', 'encoder.layer.21.attention.output.LayerNorm.weight', 'encoder.layer.2.attention.self.key.bias', 'encoder.layer.6.attention.self.key.weight', 'encoder.layer.11.attention.output.LayerNorm.weight', 'encoder.layer.3.attention.output.dense.bias', 'encoder.layer.23.attention.self.key.bias', 'encoder.layer.9.attention.self.query.bias', 'encoder.layer.13.attention.self.value.weight', 'encoder.layer.19.attention.self.query.weight', 'embeddings.LayerNorm.weight', 'encoder.layer.20.attention.output.dense.bias', 'encoder.layer.4.attention.self.value.bias', 'encoder.layer.15.output.dense.weight', 'encoder.layer.16.intermediate.dense.bias', 'encoder.layer.16.output.LayerNorm.bias', 'encoder.layer.18.intermediate.dense.bias', 'encoder.layer.9.attention.self.value.weight', 'encoder.layer.6.attention.self.key.bias', 'encoder.layer.13.intermediate.dense.weight', 'encoder.layer.15.output.dense.bias', 'encoder.layer.6.output.dense.weight', 'encoder.layer.19.attention.self.key.bias', 'encoder.layer.19.attention.output.dense.weight', 'encoder.layer.16.attention.output.LayerNorm.weight', 'encoder.layer.17.attention.self.key.bias', 'encoder.layer.0.output.dense.bias', 'encoder.layer.20.attention.output.LayerNorm.weight', 'encoder.layer.2.attention.output.LayerNorm.bias', 'encoder.layer.17.attention.self.value.bias', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.1.attention.self.query.weight', 'encoder.layer.14.attention.self.query.bias', 'encoder.layer.12.output.LayerNorm.bias', 'encoder.layer.14.attention.output.LayerNorm.weight', 'encoder.layer.23.output.LayerNorm.bias', 'encoder.layer.7.output.LayerNorm.weight', 'encoder.layer.19.attention.self.value.weight', 'encoder.layer.5.attention.output.dense.weight', 'encoder.layer.17.output.LayerNorm.bias', 'encoder.layer.6.attention.self.query.bias', 'encoder.layer.0.attention.self.key.weight', 'encoder.layer.15.attention.self.query.weight', 'encoder.layer.14.intermediate.dense.bias', 'encoder.layer.4.attention.output.LayerNorm.weight', 'encoder.layer.22.attention.self.query.bias', 'encoder.layer.21.attention.self.query.bias', 'encoder.layer.20.output.dense.weight', 'encoder.layer.8.attention.self.key.weight', 'encoder.layer.20.output.dense.bias', 'encoder.layer.1.output.dense.weight', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.23.attention.output.dense.bias', 'encoder.layer.18.attention.self.key.weight', 'encoder.layer.16.output.dense.bias', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.12.attention.self.value.bias', 'encoder.layer.10.output.dense.bias', 'encoder.layer.18.attention.output.LayerNorm.bias', 'encoder.layer.5.attention.self.value.weight', 'encoder.layer.22.attention.output.dense.bias', 'encoder.layer.8.output.LayerNorm.bias', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.1.attention.output.dense.bias', 'encoder.layer.21.attention.self.value.bias', 'encoder.layer.15.attention.output.dense.weight', 'encoder.layer.10.output.LayerNorm.bias', 'encoder.layer.13.attention.self.query.bias', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.23.attention.output.dense.weight', 'encoder.layer.21.attention.output.dense.bias', 'encoder.layer.15.attention.output.LayerNorm.bias', 'encoder.layer.2.attention.self.query.bias', 'encoder.layer.8.attention.self.value.bias', 'encoder.layer.6.attention.self.query.weight', 'encoder.layer.23.attention.output.LayerNorm.bias', 'encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.layer.3.attention.output.dense.weight', 'encoder.layer.15.attention.self.query.bias', 'encoder.layer.4.output.dense.bias', 'pooler.dense.bias', 'encoder.layer.22.attention.self.query.weight', 'encoder.layer.0.attention.self.value.bias', 'encoder.layer.5.output.LayerNorm.bias', 'encoder.layer.22.output.dense.bias', 'encoder.layer.14.output.LayerNorm.weight', 'embeddings.position_embeddings.weight', 'encoder.layer.0.attention.output.LayerNorm.weight', 'encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.layer.11.attention.self.query.bias', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.13.attention.self.key.bias', 'encoder.layer.23.intermediate.dense.bias', 'encoder.layer.7.attention.self.query.bias', 'encoder.layer.8.attention.self.key.bias', 'encoder.layer.10.output.dense.weight', 'pooler.dense.weight', 'encoder.layer.4.attention.self.query.bias', 'encoder.layer.3.attention.self.query.bias', 'encoder.layer.13.output.LayerNorm.bias', 'encoder.layer.22.attention.self.key.bias', 'encoder.layer.13.attention.self.query.weight', 'encoder.layer.7.attention.self.value.bias', 'encoder.layer.8.output.dense.bias', 'encoder.layer.20.attention.self.value.weight', 'encoder.layer.19.intermediate.dense.weight', 'encoder.layer.16.attention.output.dense.weight', 'encoder.layer.11.attention.self.key.weight', 'encoder.layer.18.attention.self.query.weight', 'encoder.layer.10.attention.output.LayerNorm.bias', 'encoder.layer.22.attention.self.value.bias', 'encoder.layer.1.attention.self.key.weight', 'encoder.layer.7.attention.output.LayerNorm.bias', 'encoder.layer.11.output.LayerNorm.weight', 'encoder.layer.23.intermediate.dense.weight', 'encoder.layer.14.attention.self.key.bias', 'encoder.layer.16.attention.self.query.weight', 'encoder.layer.6.output.LayerNorm.bias', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.6.output.dense.bias', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.12.attention.output.dense.bias', 'encoder.layer.18.output.dense.weight', 'encoder.layer.16.attention.self.key.bias', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.9.output.dense.bias', 'encoder.layer.22.intermediate.dense.bias', 'encoder.layer.19.output.LayerNorm.weight', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.19.attention.output.dense.bias', 'encoder.layer.21.attention.self.value.weight', 'encoder.layer.8.attention.output.LayerNorm.bias', 'encoder.layer.12.attention.self.key.weight', 'encoder.layer.22.attention.output.LayerNorm.bias', 'encoder.layer.19.output.dense.bias', 'encoder.layer.13.attention.self.value.bias', 'encoder.layer.17.intermediate.dense.weight', 'encoder.layer.1.attention.self.query.bias', 'encoder.layer.20.attention.self.query.weight', 'encoder.layer.7.attention.output.dense.bias', 'encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.layer.9.output.LayerNorm.weight', 'encoder.layer.7.output.LayerNorm.bias', 'encoder.layer.5.attention.self.value.bias', 'encoder.layer.12.output.LayerNorm.weight', 'encoder.layer.1.output.dense.bias', 'encoder.layer.22.intermediate.dense.weight', 'encoder.layer.23.output.dense.weight', 'encoder.layer.1.attention.self.value.bias', 'encoder.layer.10.output.LayerNorm.weight', 'encoder.layer.15.output.LayerNorm.weight', 'encoder.layer.16.attention.self.key.weight', 'encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.18.attention.self.value.weight', 'encoder.layer.21.attention.self.query.weight', 'embeddings.token_type_embeddings.weight', 'encoder.layer.10.attention.self.key.weight', 'encoder.layer.13.output.dense.weight', 'encoder.layer.22.output.dense.weight', 'encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.19.attention.output.LayerNorm.weight', 'encoder.layer.2.attention.self.value.bias', 'encoder.layer.19.attention.self.query.bias', 'encoder.layer.6.attention.self.value.weight', 'encoder.layer.2.attention.self.value.weight', 'encoder.layer.22.output.LayerNorm.bias', 'encoder.layer.3.attention.self.key.bias', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.9.attention.self.query.weight', 'encoder.layer.7.attention.output.LayerNorm.weight', 'encoder.layer.1.attention.self.key.bias', 'encoder.layer.7.output.dense.weight', 'encoder.layer.17.output.dense.weight', 'encoder.layer.10.attention.output.LayerNorm.weight', 'encoder.layer.19.output.dense.weight', 'encoder.layer.12.output.dense.bias', 'encoder.layer.17.attention.output.dense.weight', 'encoder.layer.18.output.LayerNorm.weight', 'encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.17.intermediate.dense.bias', 'encoder.layer.20.attention.self.query.bias', 'encoder.layer.12.attention.output.dense.weight', 'encoder.layer.6.attention.output.LayerNorm.weight', 'encoder.layer.4.attention.self.key.weight', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.9.attention.output.dense.bias', 'encoder.layer.12.attention.self.query.bias', 'encoder.layer.13.output.LayerNorm.weight', 'encoder.layer.15.attention.output.LayerNorm.weight', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.14.output.dense.bias', 'encoder.layer.14.attention.output.LayerNorm.bias', 'encoder.layer.8.attention.self.value.weight', 'encoder.layer.21.output.dense.weight', 'encoder.layer.12.attention.output.LayerNorm.bias', 'encoder.layer.3.attention.self.value.weight', 'encoder.layer.22.attention.output.dense.weight', 'encoder.layer.18.output.LayerNorm.bias', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.21.output.LayerNorm.bias', 'encoder.layer.10.attention.self.value.weight', 'encoder.layer.7.attention.self.value.weight', 'encoder.layer.15.attention.self.key.weight', 'encoder.layer.0.attention.self.value.weight', 'encoder.layer.13.attention.output.dense.bias', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.9.attention.output.LayerNorm.weight', 'encoder.layer.2.output.dense.weight', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.20.attention.self.key.bias', 'encoder.layer.6.attention.output.LayerNorm.bias', 'encoder.layer.17.attention.self.key.weight', 'encoder.layer.20.attention.output.LayerNorm.bias', 'encoder.layer.5.attention.output.dense.bias', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.16.output.LayerNorm.weight', 'encoder.layer.10.intermediate.dense.weight', 'encoder.layer.20.attention.self.key.weight', 'encoder.layer.15.attention.self.key.bias', 'encoder.layer.0.attention.self.query.weight', 'encoder.layer.6.attention.self.value.bias', 'encoder.layer.14.attention.output.dense.weight', 'encoder.layer.16.intermediate.dense.weight', 'encoder.layer.4.attention.self.key.bias', 'encoder.layer.23.attention.self.query.bias', 'encoder.layer.11.output.LayerNorm.bias', 'encoder.layer.23.attention.self.key.weight', 'encoder.layer.2.attention.output.dense.bias', 'encoder.layer.11.attention.self.value.bias', 'encoder.layer.14.attention.self.value.weight', 'encoder.layer.10.attention.self.query.weight', 'encoder.layer.10.attention.self.query.bias', 'encoder.layer.11.output.dense.bias', 'encoder.layer.9.attention.output.dense.weight', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.5.output.dense.bias', 'encoder.layer.19.attention.self.key.weight', 'encoder.layer.7.attention.self.key.weight', 'encoder.layer.11.attention.self.query.weight', 'encoder.layer.12.attention.self.value.weight', 'encoder.layer.15.intermediate.dense.bias', 'encoder.layer.1.attention.self.value.weight', 'encoder.layer.18.attention.self.value.bias', 'embeddings.LayerNorm.bias', 'encoder.layer.20.output.LayerNorm.bias', 'encoder.layer.20.intermediate.dense.weight', 'encoder.layer.2.attention.output.LayerNorm.weight', 'encoder.layer.11.attention.output.dense.bias', 'encoder.layer.7.attention.self.query.weight', 'encoder.layer.15.intermediate.dense.weight', 'encoder.layer.5.attention.output.LayerNorm.weight', 'encoder.layer.14.attention.self.key.weight', 'encoder.layer.13.intermediate.dense.bias', 'encoder.layer.7.output.dense.bias', 'encoder.layer.8.attention.output.dense.weight', 'encoder.layer.8.attention.self.query.bias', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.22.output.LayerNorm.weight', 'encoder.layer.10.attention.output.dense.bias', 'encoder.layer.9.attention.self.value.bias', 'encoder.layer.13.attention.output.dense.weight', 'encoder.layer.21.intermediate.dense.bias', 'encoder.layer.3.output.dense.weight', 'encoder.layer.2.attention.self.key.weight', 'encoder.layer.22.attention.self.value.weight', 'encoder.layer.5.attention.self.query.weight', 'encoder.layer.4.output.dense.weight', 'encoder.layer.9.output.LayerNorm.bias', 'encoder.layer.15.output.LayerNorm.bias', 'encoder.layer.20.output.LayerNorm.weight', 'encoder.layer.21.intermediate.dense.weight', 'encoder.layer.15.attention.self.value.bias', 'encoder.layer.3.attention.self.query.weight', 'encoder.layer.21.attention.output.LayerNorm.bias', 'encoder.layer.23.attention.output.LayerNorm.weight', 'encoder.layer.20.attention.output.dense.weight', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.9.output.dense.weight', 'encoder.layer.2.output.dense.bias', 'encoder.layer.7.intermediate.dense.bias', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.21.output.dense.bias', 'encoder.layer.19.attention.output.LayerNorm.bias', 'encoder.layer.7.attention.output.dense.weight', 'encoder.layer.18.attention.output.LayerNorm.weight', 'encoder.layer.16.attention.output.dense.bias', 'encoder.layer.17.output.LayerNorm.weight', 'encoder.layer.15.attention.output.dense.bias', 'encoder.layer.18.output.dense.bias', 'encoder.layer.12.output.dense.weight', 'encoder.layer.0.output.dense.weight', 'encoder.layer.14.attention.output.dense.bias', 'encoder.layer.23.output.LayerNorm.weight', 'encoder.layer.3.attention.self.value.bias', 'encoder.layer.16.attention.self.value.weight', 'encoder.layer.8.output.LayerNorm.weight', 'encoder.layer.10.attention.self.value.bias', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.9.attention.self.key.bias', 'encoder.layer.0.attention.self.query.bias', 'encoder.layer.21.attention.output.dense.weight', 'encoder.layer.4.attention.output.dense.weight', 'encoder.layer.0.attention.output.dense.weight', 'encoder.layer.4.attention.self.query.weight', 'encoder.layer.14.output.dense.weight', 'encoder.layer.2.attention.output.dense.weight', 'encoder.layer.4.attention.output.dense.bias', 'encoder.layer.9.attention.output.LayerNorm.bias', 'encoder.layer.2.attention.self.query.weight', 'encoder.layer.5.attention.self.query.bias', 'encoder.layer.17.attention.output.LayerNorm.bias', 'encoder.layer.14.attention.self.query.weight', 'encoder.layer.16.attention.self.query.bias', 'encoder.layer.8.attention.self.query.weight', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.13.attention.output.LayerNorm.weight', 'encoder.layer.21.output.LayerNorm.weight', 'encoder.layer.4.attention.output.LayerNorm.bias', 'encoder.layer.12.intermediate.dense.bias', 'encoder.layer.18.intermediate.dense.weight', 'encoder.layer.22.attention.output.LayerNorm.weight', 'encoder.layer.13.output.dense.bias', 'encoder.layer.13.attention.self.key.weight', 'encoder.layer.21.attention.self.key.bias', 'encoder.layer.18.attention.self.key.bias', 'encoder.layer.6.attention.output.dense.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Overwriting existing adapter 'ep'.
Overwriting existing adapter 'tp'.
Overwriting existing adapter 'es'.
Overwriting existing adapter 'ts'.
Overwriting existing adapter fusion module 'ep,tp,es,ts'
05/09/2022 19:59:38 - INFO - __main__ -   lang2id = None
05/09/2022 19:59:42 - INFO - __main__ -   Training/evaluation parameters Namespace(adam_epsilon=1e-08, cache_dir='', config_name='', data_dir=None, device=device(type='cuda'), do_eval=True, do_lower_case=False, do_train=False, doc_stride=128, eval_all_checkpoints=False, eval_lang='ru', evaluate_during_training=False, fp16=False, fp16_opt_level='O1', gradient_accumulation_steps=1, learning_rate=5e-05, local_rank=-1, logging_steps=50, max_answer_length=30, max_grad_norm=1.0, max_query_length=64, max_seq_length=384, max_steps=-1, model_name='xlm-KG', model_name_or_path='/cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//squad/xlm-KG_LR4e-5_EPOCH2.0_maxlen384_batchsize4_gradacc8', model_type='xlm', modelkg_dir='/cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/adapter/xlmr_adapter', n_best_size=20, n_gpu=1, no_cuda=False, null_score_diff_threshold=0.0, num_train_epochs=3.0, output_dir='/cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//squad/xlm-KG_LR4e-5_EPOCH2.0_maxlen384_batchsize4_gradacc8/predictions/xquad/', overwrite_cache=False, overwrite_output_dir=False, per_gpu_eval_batch_size=8, per_gpu_train_batch_size=8, predict_file='/cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/download//xquad//xquad.ru.json', save_steps=50, seed=42, server_ip='', server_port='', threads=1, tokenizer_name='', train_file=None, train_lang='en', verbose_logging=False, version_2_with_negative=False, warmup_steps=0, weight_decay=0.0)
05/09/2022 19:59:42 - INFO - __main__ -   Loading checkpoint /cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//squad/xlm-KG_LR4e-5_EPOCH2.0_maxlen384_batchsize4_gradacc8 for evaluation
05/09/2022 19:59:42 - INFO - __main__ -   Evaluate the following checkpoints: ['/cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//squad/xlm-KG_LR4e-5_EPOCH2.0_maxlen384_batchsize4_gradacc8']
Some weights of the model checkpoint at /cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//squad/xlm-KG_LR4e-5_EPOCH2.0_maxlen384_batchsize4_gradacc8 were not used when initializing XLMRobertaModel: ['base_model.encoder.layer.19.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.12.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.15.attention.self.key.weight', 'base_model.encoder.layer.8.intermediate.dense.bias', 'base_model.encoder.layer.22.intermediate.dense.bias', 'base_model.encoder.layer.6.output.dense.weight', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.5.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.10.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.5.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.23.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.19.attention.self.value.bias', 'base_model.encoder.layer.19.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.16.attention.self.key.weight', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.11.attention.output.dense.weight', 'base_model.encoder.layer.18.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.15.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.17.output.LayerNorm.weight', 'base_model.encoder.layer.20.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.23.attention.self.query.weight', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.10.attention.self.value.weight', 'base_model.encoder.layer.4.output.dense.weight', 'base_model.encoder.layer.5.attention.output.dense.weight', 'base_model.encoder.layer.5.attention.self.value.weight', 'base_model.encoder.layer.10.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.19.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.0.attention.output.dense.weight', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.1.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.17.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.3.attention.self.key.bias', 'base_model.encoder.layer.20.attention.output.dense.weight', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.4.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.10.attention.self.key.weight', 'base_model.encoder.layer.22.attention.self.value.weight', 'base_model.encoder.layer.0.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.7.attention.output.LayerNorm.weight', 'base_model.encoder.layer.2.attention.output.LayerNorm.weight', 'base_model.encoder.layer.6.output.LayerNorm.bias', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.22.attention.self.query.bias', 'base_model.encoder.layer.17.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.22.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.18.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.11.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.4.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.23.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.22.attention.self.key.weight', 'base_model.encoder.layer.16.attention.output.dense.weight', 'base_model.encoder.layer.11.output.dense.bias', 'base_model.encoder.layer.0.intermediate.dense.weight', 'base_model.encoder.layer.7.output.dense.weight', 'base_model.encoder.layer.3.attention.output.dense.bias', 'base_model.encoder.layer.17.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.4.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.1.attention.self.key.weight', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.10.attention.self.value.bias', 'base_model.encoder.layer.23.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.23.attention.output.LayerNorm.weight', 'base_model.encoder.layer.11.output.LayerNorm.weight', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.7.intermediate.dense.bias', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.12.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.3.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.1.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.9.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.15.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.21.attention.self.query.bias', 'base_model.encoder.layer.2.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.10.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.21.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.20.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.1.intermediate.dense.bias', 'base_model.encoder.layer.10.intermediate.dense.weight', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.17.attention.output.dense.weight', 'base_model.pooler.dense.weight', 'base_model.encoder.layer.21.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.15.intermediate.dense.weight', 'base_model.encoder.layer.7.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.8.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.2.attention.self.key.bias', 'base_model.encoder.layer.9.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.11.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.10.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.8.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.6.attention.self.value.weight', 'base_model.encoder.layer.13.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.17.attention.output.dense.bias', 'base_model.encoder.layer.20.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.12.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.23.output.dense.weight', 'base_model.encoder.layer.13.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.19.attention.output.dense.weight', 'base_model.encoder.layer.13.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.14.attention.self.query.bias', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.10.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.14.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.14.attention.self.value.weight', 'base_model.encoder.layer.21.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.21.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.23.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.22.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.5.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.6.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.19.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.7.attention.output.dense.weight', 'base_model.encoder.layer.10.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.12.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.11.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.10.output.dense.weight', 'base_model.encoder.layer.13.attention.self.query.weight', 'base_model.encoder.layer.14.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.16.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.2.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.7.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.10.output.LayerNorm.weight', 'base_model.encoder.layer.15.output.dense.weight', 'base_model.encoder.layer.21.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.7.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.11.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.17.attention.self.query.bias', 'base_model.encoder.layer.19.attention.self.value.weight', 'base_model.encoder.layer.0.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.12.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.1.attention.self.query.bias', 'base_model.encoder.layer.23.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.21.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.23.attention.self.query.bias', 'base_model.encoder.layer.23.attention.output.dense.bias', 'base_model.encoder.layer.5.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.13.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.11.attention.self.value.weight', 'base_model.encoder.layer.15.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.11.output.LayerNorm.bias', 'base_model.encoder.layer.1.intermediate.dense.weight', 'base_model.encoder.layer.0.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.4.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.3.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.14.attention.output.dense.weight', 'base_model.encoder.layer.0.output.LayerNorm.weight', 'base_model.encoder.layer.0.attention.self.value.weight', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.8.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.23.attention.output.LayerNorm.bias', 'base_model.encoder.layer.13.output.LayerNorm.weight', 'base_model.encoder.layer.23.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.17.attention.self.value.bias', 'base_model.encoder.layer.1.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.8.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.4.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.9.attention.output.dense.weight', 'base_model.encoder.layer.9.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.15.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.15.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.8.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.20.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.11.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.5.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.2.attention.self.query.weight', 'base_model.encoder.layer.10.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.4.attention.self.query.bias', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.9.attention.output.dense.bias', 'base_model.encoder.layer.6.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.8.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.1.attention.output.LayerNorm.weight', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.21.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.19.attention.self.key.weight', 'base_model.encoder.layer.6.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.21.attention.self.key.weight', 'base_model.encoder.layer.12.attention.output.dense.weight', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.1.output.dense.bias', 'base_model.encoder.layer.2.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.4.output.LayerNorm.weight', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.11.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.15.attention.self.value.weight', 'base_model.encoder.layer.8.output.dense.bias', 'base_model.encoder.layer.17.output.dense.weight', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.20.output.LayerNorm.bias', 'base_model.encoder.layer.4.attention.self.value.bias', 'base_model.encoder.layer.7.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.5.intermediate.dense.weight', 'base_model.encoder.layer.11.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.10.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.18.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.19.attention.output.dense.bias', 'base_model.encoder.layer.13.attention.self.query.bias', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.22.output.adapters.ts.adapter_down.0.bias', 'base_model.embeddings.word_embeddings.weight', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.2.output.LayerNorm.weight', 'base_model.encoder.layer.5.output.LayerNorm.weight', 'base_model.encoder.layer.10.output.dense.bias', 'base_model.encoder.layer.13.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.15.attention.output.dense.bias', 'base_model.encoder.layer.2.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.7.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.9.output.dense.weight', 'base_model.encoder.layer.12.intermediate.dense.bias', 'base_model.encoder.layer.4.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.3.attention.self.value.bias', 'base_model.encoder.layer.21.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.0.attention.self.query.weight', 'base_model.encoder.layer.18.attention.self.key.bias', 'base_model.encoder.layer.16.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.19.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.11.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.22.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.9.intermediate.dense.weight', 'base_model.encoder.layer.23.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.14.attention.self.key.weight', 'base_model.encoder.layer.17.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.5.intermediate.dense.bias', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.19.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.15.attention.self.query.bias', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.12.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.13.attention.output.LayerNorm.weight', 'base_model.encoder.layer.4.output.LayerNorm.bias', 'base_model.encoder.layer.22.attention.self.value.bias', 'base_model.encoder.layer.6.attention.output.LayerNorm.bias', 'base_model.encoder.layer.8.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.20.attention.self.query.bias', 'base_model.encoder.layer.11.output.dense.weight', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.1.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.19.output.LayerNorm.bias', 'base_model.encoder.layer.20.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.20.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.23.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.19.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.0.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.21.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.2.attention.self.query.bias', 'base_model.encoder.layer.19.intermediate.dense.weight', 'base_model.encoder.layer.11.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.6.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.16.attention.self.query.bias', 'base_model.encoder.layer.16.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.16.attention.self.query.weight', 'base_model.encoder.layer.1.output.dense.weight', 'base_model.encoder.layer.6.attention.output.LayerNorm.weight', 'base_model.encoder.layer.0.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.18.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.22.output.dense.weight', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.13.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.2.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.17.intermediate.dense.weight', 'base_model.encoder.layer.13.output.dense.bias', 'base_model.encoder.layer.18.attention.output.LayerNorm.bias', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.16.attention.output.dense.bias', 'base_model.encoder.layer.0.output.dense.weight', 'base_model.encoder.layer.3.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.6.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.13.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.15.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.16.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.10.output.LayerNorm.bias', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.8.attention.output.LayerNorm.bias', 'base_model.encoder.layer.14.attention.output.LayerNorm.bias', 'base_model.encoder.layer.16.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.1.attention.output.LayerNorm.bias', 'base_model.encoder.layer.16.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.6.attention.output.dense.bias', 'base_model.encoder.layer.1.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.7.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.16.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.4.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.20.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.17.intermediate.dense.bias', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.16.output.LayerNorm.bias', 'base_model.encoder.layer.18.output.dense.weight', 'base_model.encoder.layer.16.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.10.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.11.attention.self.key.bias', 'base_model.encoder.layer.23.attention.self.key.weight', 'base_model.encoder.layer.3.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.6.attention.output.dense.weight', 'base_model.encoder.layer.10.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.5.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.4.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.8.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.13.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.5.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.11.attention.self.query.weight', 'base_model.encoder.layer.5.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.16.intermediate.dense.weight', 'base_model.encoder.layer.16.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.1.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.22.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.17.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.21.intermediate.dense.weight', 'base_model.encoder.layer.17.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.4.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.9.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.5.output.dense.bias', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.3.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.9.output.LayerNorm.bias', 'base_model.encoder.layer.3.attention.self.value.weight', 'base_model.encoder.layer.17.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.15.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.23.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.7.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.18.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.3.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.0.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.7.output.dense.bias', 'base_model.encoder.layer.8.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.10.attention.output.dense.bias', 'base_model.encoder.layer.14.attention.self.query.weight', 'base_model.encoder.layer.19.intermediate.dense.bias', 'base_model.encoder.layer.20.attention.self.key.bias', 'base_model.encoder.layer.15.attention.self.key.bias', 'base_model.encoder.layer.1.attention.self.value.bias', 'base_model.encoder.layer.0.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.1.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.19.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.17.attention.self.value.weight', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.9.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.15.attention.self.query.weight', 'base_model.encoder.layer.18.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.3.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.12.output.LayerNorm.bias', 'base_model.encoder.layer.12.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.15.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.14.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.22.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.23.attention.self.value.weight', 'base_model.encoder.layer.13.attention.self.key.weight', 'base_model.encoder.layer.10.attention.self.key.bias', 'base_model.encoder.layer.11.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.21.attention.output.LayerNorm.bias', 'base_model.encoder.layer.22.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.21.output.LayerNorm.weight', 'base_model.encoder.layer.12.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.9.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.4.intermediate.dense.bias', 'base_model.encoder.layer.2.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.1.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.5.attention.output.dense.bias', 'base_model.encoder.layer.10.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.20.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.4.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.6.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.7.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.18.attention.self.query.bias', 'base_model.encoder.layer.15.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.4.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.6.attention.self.key.bias', 'base_model.encoder.layer.19.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.7.attention.self.key.weight', 'base_model.encoder.layer.18.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.19.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.7.output.LayerNorm.bias', 'base_model.encoder.layer.15.intermediate.dense.bias', 'base_model.encoder.layer.21.attention.output.dense.bias', 'base_model.encoder.layer.23.output.LayerNorm.weight', 'base_model.encoder.layer.0.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.3.attention.output.dense.weight', 'base_model.encoder.layer.18.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.17.output.LayerNorm.bias', 'base_model.encoder.layer.0.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.11.attention.output.LayerNorm.bias', 'base_model.encoder.layer.22.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.3.attention.self.key.weight', 'base_model.encoder.layer.11.intermediate.dense.bias', 'base_model.encoder.layer.17.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.14.intermediate.dense.bias', 'base_model.encoder.layer.2.attention.self.key.weight', 'base_model.encoder.layer.0.attention.output.LayerNorm.weight', 'base_model.encoder.layer.13.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.4.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.3.output.dense.bias', 'base_model.encoder.layer.7.attention.output.dense.bias', 'base_model.encoder.layer.6.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.15.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.18.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.13.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.14.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.15.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.2.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.20.attention.self.query.weight', 'base_model.encoder.layer.17.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.0.attention.self.query.bias', 'base_model.encoder.layer.7.attention.self.key.bias', 'base_model.encoder.layer.4.output.dense.bias', 'base_model.encoder.layer.19.attention.self.query.weight', 'base_model.encoder.layer.8.intermediate.dense.weight', 'base_model.encoder.layer.15.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.2.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.0.output.dense.bias', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.8.attention.output.dense.bias', 'base_model.encoder.layer.10.attention.output.dense.weight', 'base_model.encoder.layer.12.attention.self.value.bias', 'base_model.encoder.layer.14.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.3.output.LayerNorm.bias', 'base_model.encoder.layer.8.output.dense.weight', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.21.attention.self.query.weight', 'base_model.encoder.layer.21.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.6.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.22.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.12.output.LayerNorm.weight', 'base_model.encoder.layer.23.attention.output.dense.weight', 'base_model.encoder.layer.16.attention.self.key.bias', 'base_model.encoder.layer.18.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.0.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.12.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.23.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.21.output.LayerNorm.bias', 'base_model.encoder.layer.5.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.8.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.14.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.18.attention.output.dense.weight', 'base_model.encoder.layer.21.attention.output.dense.weight', 'base_model.encoder.layer.16.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.4.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.17.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.15.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.9.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.2.attention.self.value.bias', 'base_model.encoder.layer.11.attention.output.LayerNorm.weight', 'base_model.encoder.layer.5.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.3.attention.output.LayerNorm.bias', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.5.attention.self.query.weight', 'base_model.encoder.layer.19.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.19.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.15.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.6.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.15.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.22.attention.self.key.bias', 'base_model.encoder.layer.23.output.dense.bias', 'base_model.encoder.layer.1.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.4.attention.self.query.weight', 'base_model.encoder.layer.6.attention.self.query.bias', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.18.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.18.attention.self.key.weight', 'base_model.encoder.layer.21.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.15.output.dense.bias', 'base_model.encoder.layer.9.attention.output.LayerNorm.bias', 'base_model.encoder.layer.11.attention.output.dense.bias', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.22.attention.output.LayerNorm.bias', 'base_model.encoder.layer.14.output.LayerNorm.weight', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.21.attention.output.LayerNorm.weight', 'base_model.encoder.layer.12.attention.self.query.bias', 'base_model.encoder.layer.3.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.19.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.2.attention.output.dense.weight', 'base_model.encoder.layer.21.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.13.output.dense.weight', 'base_model.encoder.layer.20.attention.self.value.bias', 'base_model.encoder.layer.9.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.4.attention.output.dense.bias', 'base_model.encoder.layer.19.attention.output.LayerNorm.bias', 'base_model.embeddings.LayerNorm.bias', 'base_model.encoder.layer.5.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.20.output.dense.bias', 'base_model.encoder.layer.20.attention.output.LayerNorm.bias', 'base_model.encoder.layer.16.output.dense.bias', 'base_model.encoder.layer.22.output.LayerNorm.weight', 'base_model.encoder.layer.8.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.21.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.6.output.LayerNorm.weight', 'base_model.encoder.layer.9.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.14.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.15.attention.output.LayerNorm.weight', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.2.intermediate.dense.weight', 'base_model.encoder.layer.22.attention.output.LayerNorm.weight', 'base_model.embeddings.position_embeddings.weight', 'base_model.encoder.layer.7.attention.self.value.bias', 'base_model.encoder.layer.22.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.9.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.9.attention.self.value.weight', 'base_model.encoder.layer.7.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.23.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.22.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.10.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.3.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.5.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.23.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.0.output.LayerNorm.bias', 'base_model.encoder.layer.6.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.7.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.23.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.7.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.17.attention.self.key.weight', 'base_model.encoder.layer.2.output.LayerNorm.bias', 'base_model.encoder.layer.9.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.12.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.19.output.LayerNorm.weight', 'base_model.encoder.layer.3.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.5.attention.self.key.weight', 'base_model.encoder.layer.21.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.22.intermediate.dense.weight', 'base_model.encoder.layer.16.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.9.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.9.attention.output.LayerNorm.weight', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.21.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.11.intermediate.dense.weight', 'base_model.encoder.layer.6.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.12.attention.self.value.weight', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.3.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.13.attention.self.value.bias', 'base_model.encoder.layer.8.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.14.attention.output.LayerNorm.weight', 'base_model.encoder.layer.3.attention.self.query.bias', 'base_model.encoder.layer.20.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.20.attention.output.dense.bias', 'base_model.encoder.layer.22.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.9.attention.self.key.bias', 'base_model.encoder.layer.2.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.10.attention.output.LayerNorm.bias', 'base_model.encoder.layer.22.attention.output.dense.bias', 'base_model.encoder.layer.17.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.20.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.14.output.dense.weight', 'base_model.encoder.layer.19.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.14.attention.self.key.bias', 'base_model.encoder.layer.9.attention.self.key.weight', 'base_model.encoder.layer.16.output.dense.weight', 'base_model.encoder.layer.17.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.10.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.12.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.0.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.6.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.8.attention.output.dense.weight', 'base_model.encoder.layer.12.attention.output.dense.bias', 'base_model.encoder.layer.11.attention.self.key.weight', 'base_model.encoder.layer.9.attention.self.query.bias', 'base_model.encoder.layer.1.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.11.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.19.attention.output.LayerNorm.weight', 'base_model.encoder.layer.16.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.14.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.15.output.LayerNorm.weight', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.embeddings.LayerNorm.weight', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.21.attention.self.key.bias', 'base_model.encoder.layer.10.attention.self.query.weight', 'base_model.encoder.layer.21.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.16.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.1.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.13.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.8.output.LayerNorm.weight', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.12.attention.output.LayerNorm.bias', 'base_model.encoder.layer.7.intermediate.dense.weight', 'base_model.encoder.layer.17.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.15.attention.output.dense.weight', 'base_model.encoder.layer.1.attention.output.dense.weight', 'base_model.encoder.layer.21.output.dense.weight', 'base_model.encoder.layer.17.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.20.attention.output.LayerNorm.weight', 'base_model.encoder.layer.11.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.14.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.7.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.23.output.LayerNorm.bias', 'base_model.encoder.layer.16.attention.self.value.weight', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.12.attention.self.key.weight', 'base_model.encoder.layer.15.attention.output.LayerNorm.bias', 'base_model.encoder.layer.18.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.1.attention.self.key.bias', 'base_model.encoder.layer.2.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.4.attention.output.dense.weight', 'base_model.encoder.layer.18.output.dense.bias', 'base_model.encoder.layer.9.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.17.attention.output.LayerNorm.weight', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.18.intermediate.dense.bias', 'base_model.encoder.layer.23.intermediate.dense.bias', 'base_model.encoder.layer.22.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.12.output.dense.weight', 'base_model.encoder.layer.10.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.8.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.3.attention.output.LayerNorm.weight', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.4.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.0.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.4.intermediate.dense.weight', 'base_model.encoder.layer.1.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.6.attention.self.key.weight', 'base_model.encoder.layer.14.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.2.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.12.output.adapters.tp.adapter_down.0.weight', 'base_model.pooler.dense.bias', 'base_model.encoder.layer.0.attention.self.key.weight', 'base_model.encoder.layer.16.attention.self.value.bias', 'base_model.encoder.layer.3.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.14.output.dense.bias', 'base_model.encoder.layer.16.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.14.intermediate.dense.weight', 'base_model.encoder.layer.3.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.18.attention.self.value.weight', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.6.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.12.output.dense.bias', 'base_model.encoder.layer.23.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.15.output.LayerNorm.bias', 'base_model.encoder.layer.14.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.0.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.6.attention.self.value.bias', 'base_model.encoder.layer.8.attention.self.key.weight', 'base_model.encoder.layer.9.output.LayerNorm.weight', 'base_model.encoder.layer.2.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.21.attention.self.value.bias', 'base_model.encoder.layer.15.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.21.intermediate.dense.bias', 'base_model.encoder.layer.18.output.LayerNorm.bias', 'base_model.encoder.layer.20.intermediate.dense.bias', 'base_model.encoder.layer.23.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.3.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.13.intermediate.dense.weight', 'base_model.encoder.layer.19.output.dense.bias', 'base_model.encoder.layer.2.output.adapters.tp.adapter_down.0.weight', 'qa_outputs.weight', 'base_model.encoder.layer.18.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.11.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.17.attention.output.LayerNorm.bias', 'base_model.encoder.layer.17.attention.self.query.weight', 'base_model.encoder.layer.23.attention.self.key.bias', 'base_model.encoder.layer.11.attention.self.query.bias', 'base_model.encoder.layer.14.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.10.attention.self.query.bias', 'base_model.encoder.layer.5.attention.self.key.bias', 'base_model.encoder.layer.10.intermediate.dense.bias', 'base_model.encoder.layer.5.attention.output.LayerNorm.bias', 'base_model.encoder.layer.19.attention.self.key.bias', 'base_model.encoder.layer.9.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.22.attention.self.query.weight', 'base_model.encoder.layer.8.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.13.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.8.attention.self.value.weight', 'base_model.encoder.layer.12.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.5.attention.self.query.bias', 'base_model.encoder.layer.2.attention.output.dense.bias', 'base_model.encoder.layer.14.output.adapters.ts.adapter_up.bias', 'qa_outputs.bias', 'base_model.encoder.layer.18.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.20.attention.self.value.weight', 'base_model.encoder.layer.4.attention.output.LayerNorm.weight', 'base_model.encoder.layer.20.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.13.attention.output.dense.bias', 'base_model.encoder.layer.11.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.7.attention.self.value.weight', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.0.attention.self.value.bias', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.18.attention.self.value.bias', 'base_model.encoder.layer.16.attention.output.LayerNorm.bias', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.2.attention.output.LayerNorm.bias', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.14.output.LayerNorm.bias', 'base_model.encoder.layer.0.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.2.intermediate.dense.bias', 'base_model.encoder.layer.17.attention.self.key.bias', 'base_model.encoder.layer.0.attention.output.dense.bias', 'base_model.encoder.layer.5.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.2.output.dense.weight', 'base_model.encoder.layer.12.attention.self.query.weight', 'base_model.embeddings.position_ids', 'base_model.encoder.layer.5.attention.self.value.bias', 'base_model.encoder.layer.10.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.10.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.2.output.dense.bias', 'base_model.encoder.layer.6.output.dense.bias', 'base_model.encoder.layer.13.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.5.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.17.output.dense.bias', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.0.attention.output.LayerNorm.bias', 'base_model.encoder.layer.1.attention.self.query.weight', 'base_model.encoder.layer.1.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.5.output.dense.weight', 'base_model.encoder.layer.22.output.LayerNorm.bias', 'base_model.encoder.layer.23.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.3.intermediate.dense.bias', 'base_model.encoder.layer.13.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.3.attention.self.query.weight', 'base_model.encoder.layer.4.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.16.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.17.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.20.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.2.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.22.output.dense.bias', 'base_model.encoder.layer.22.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.3.output.LayerNorm.weight', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.6.intermediate.dense.bias', 'base_model.encoder.layer.7.attention.self.query.weight', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.12.intermediate.dense.weight', 'base_model.encoder.layer.13.attention.output.dense.weight', 'base_model.encoder.layer.16.output.LayerNorm.weight', 'base_model.encoder.layer.18.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.18.output.LayerNorm.weight', 'base_model.encoder.layer.18.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.8.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.18.attention.output.LayerNorm.weight', 'base_model.encoder.layer.3.intermediate.dense.weight', 'base_model.encoder.layer.18.intermediate.dense.weight', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.13.intermediate.dense.bias', 'base_model.encoder.layer.6.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.0.attention.self.key.bias', 'base_model.encoder.layer.7.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.17.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.19.output.dense.weight', 'base_model.encoder.layer.4.attention.output.LayerNorm.bias', 'base_model.encoder.layer.4.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.2.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.1.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.13.attention.output.LayerNorm.bias', 'base_model.encoder.layer.7.output.LayerNorm.weight', 'base_model.encoder.layer.14.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.21.output.dense.bias', 'base_model.encoder.layer.4.attention.self.value.weight', 'base_model.encoder.layer.19.attention.self.query.bias', 'base_model.encoder.layer.5.attention.output.LayerNorm.weight', 'base_model.encoder.layer.6.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.12.attention.output.LayerNorm.weight', 'base_model.encoder.layer.11.attention.self.value.bias', 'base_model.encoder.layer.9.attention.self.query.weight', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.13.attention.self.key.bias', 'base_model.encoder.layer.19.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.0.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.8.attention.self.value.bias', 'base_model.encoder.layer.12.output.adapters.ts.adapter_down.0.bias', 'base_model.embeddings.token_type_embeddings.weight', 'base_model.encoder.layer.1.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.14.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.14.attention.output.dense.bias', 'base_model.encoder.layer.20.output.LayerNorm.weight', 'base_model.encoder.layer.8.attention.self.query.bias', 'base_model.encoder.layer.11.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.6.attention.self.query.weight', 'base_model.encoder.layer.20.intermediate.dense.weight', 'base_model.encoder.layer.4.attention.self.key.bias', 'base_model.encoder.layer.22.attention.output.dense.weight', 'base_model.encoder.layer.6.intermediate.dense.weight', 'base_model.encoder.layer.20.attention.self.key.weight', 'base_model.encoder.layer.20.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.13.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.1.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.9.attention.self.value.bias', 'base_model.encoder.layer.4.attention.self.key.weight', 'base_model.encoder.layer.8.attention.self.key.bias', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.8.output.LayerNorm.bias', 'base_model.encoder.layer.7.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.7.attention.output.LayerNorm.bias', 'base_model.encoder.layer.0.intermediate.dense.bias', 'base_model.encoder.layer.12.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.18.attention.output.dense.bias', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.7.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.10.attention.output.LayerNorm.weight', 'base_model.encoder.layer.14.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.7.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.11.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.12.attention.self.key.bias', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.13.attention.self.value.weight', 'base_model.encoder.layer.3.output.dense.weight', 'base_model.encoder.layer.5.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.7.attention.self.query.bias', 'base_model.encoder.layer.2.attention.self.value.weight', 'base_model.encoder.layer.13.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.21.attention.self.value.weight', 'base_model.encoder.layer.16.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.9.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.20.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.20.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.1.output.LayerNorm.bias', 'base_model.encoder.layer.5.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.20.output.dense.weight', 'base_model.encoder.layer.22.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.1.output.LayerNorm.weight', 'base_model.encoder.layer.9.output.dense.bias', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.18.attention.self.query.weight', 'base_model.encoder.layer.19.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.5.output.LayerNorm.bias', 'base_model.encoder.layer.0.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.8.attention.self.query.weight', 'base_model.encoder.layer.16.intermediate.dense.bias', 'base_model.encoder.layer.23.attention.self.value.bias', 'base_model.encoder.layer.16.attention.output.LayerNorm.weight', 'base_model.encoder.layer.1.attention.self.value.weight', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.3.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.20.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.2.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.8.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.6.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.1.attention.output.dense.bias', 'base_model.encoder.layer.15.attention.self.value.bias', 'base_model.encoder.layer.9.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.13.output.LayerNorm.bias', 'base_model.encoder.layer.9.intermediate.dense.bias', 'base_model.encoder.layer.12.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.14.attention.self.value.bias', 'base_model.encoder.layer.22.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.3.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.23.intermediate.dense.weight', 'base_model.encoder.layer.8.attention.output.LayerNorm.weight']
- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of XLMRobertaModel were not initialized from the model checkpoint at /cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//squad/xlm-KG_LR4e-5_EPOCH2.0_maxlen384_batchsize4_gradacc8 and are newly initialized: ['encoder.layer.3.attention.self.key.weight', 'encoder.layer.5.output.dense.weight', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.12.attention.self.key.bias', 'encoder.layer.20.intermediate.dense.bias', 'encoder.layer.14.intermediate.dense.weight', 'encoder.layer.18.attention.output.dense.weight', 'encoder.layer.19.output.LayerNorm.bias', 'encoder.layer.11.attention.self.key.bias', 'encoder.layer.11.attention.output.dense.weight', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.12.attention.output.LayerNorm.weight', 'encoder.layer.12.intermediate.dense.weight', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.11.output.dense.weight', 'encoder.layer.5.attention.self.key.bias', 'embeddings.word_embeddings.weight', 'encoder.layer.10.attention.self.key.bias', 'encoder.layer.7.attention.self.key.bias', 'encoder.layer.16.attention.self.value.bias', 'encoder.layer.19.intermediate.dense.bias', 'encoder.layer.10.attention.output.dense.weight', 'encoder.layer.5.attention.self.key.weight', 'encoder.layer.17.attention.self.query.bias', 'encoder.layer.17.attention.output.LayerNorm.weight', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.17.attention.output.dense.bias', 'encoder.layer.1.attention.output.LayerNorm.weight', 'encoder.layer.23.attention.self.value.bias', 'encoder.layer.13.attention.output.LayerNorm.bias', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.14.output.LayerNorm.bias', 'encoder.layer.18.attention.self.query.bias', 'encoder.layer.18.attention.output.dense.bias', 'encoder.layer.17.attention.self.query.weight', 'encoder.layer.0.attention.output.dense.bias', 'encoder.layer.16.attention.output.LayerNorm.bias', 'encoder.layer.1.attention.output.dense.weight', 'encoder.layer.20.attention.self.value.bias', 'encoder.layer.8.output.dense.weight', 'encoder.layer.23.output.dense.bias', 'encoder.layer.0.attention.self.key.bias', 'encoder.layer.17.output.dense.bias', 'encoder.layer.14.attention.self.value.bias', 'encoder.layer.15.attention.self.value.weight', 'encoder.layer.21.attention.self.key.weight', 'encoder.layer.11.attention.self.value.weight', 'encoder.layer.22.attention.self.key.weight', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.8.attention.output.dense.bias', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.17.attention.self.value.weight', 'encoder.layer.12.attention.self.query.weight', 'encoder.layer.9.attention.self.key.weight', 'encoder.layer.23.attention.self.value.weight', 'encoder.layer.23.attention.self.query.weight', 'encoder.layer.6.attention.output.dense.weight', 'encoder.layer.3.output.dense.bias', 'encoder.layer.19.attention.self.value.bias', 'encoder.layer.4.attention.self.value.weight', 'encoder.layer.16.output.dense.weight', 'encoder.layer.8.attention.output.LayerNorm.weight', 'encoder.layer.21.attention.output.LayerNorm.weight', 'encoder.layer.2.attention.self.key.bias', 'encoder.layer.6.attention.self.key.weight', 'encoder.layer.11.attention.output.LayerNorm.weight', 'encoder.layer.3.attention.output.dense.bias', 'encoder.layer.23.attention.self.key.bias', 'encoder.layer.9.attention.self.query.bias', 'encoder.layer.13.attention.self.value.weight', 'encoder.layer.19.attention.self.query.weight', 'embeddings.LayerNorm.weight', 'encoder.layer.20.attention.output.dense.bias', 'encoder.layer.4.attention.self.value.bias', 'encoder.layer.15.output.dense.weight', 'encoder.layer.16.intermediate.dense.bias', 'encoder.layer.16.output.LayerNorm.bias', 'encoder.layer.18.intermediate.dense.bias', 'encoder.layer.9.attention.self.value.weight', 'encoder.layer.6.attention.self.key.bias', 'encoder.layer.13.intermediate.dense.weight', 'encoder.layer.15.output.dense.bias', 'encoder.layer.6.output.dense.weight', 'encoder.layer.19.attention.self.key.bias', 'encoder.layer.19.attention.output.dense.weight', 'encoder.layer.16.attention.output.LayerNorm.weight', 'encoder.layer.17.attention.self.key.bias', 'encoder.layer.0.output.dense.bias', 'encoder.layer.20.attention.output.LayerNorm.weight', 'encoder.layer.2.attention.output.LayerNorm.bias', 'encoder.layer.17.attention.self.value.bias', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.1.attention.self.query.weight', 'encoder.layer.14.attention.self.query.bias', 'encoder.layer.12.output.LayerNorm.bias', 'encoder.layer.14.attention.output.LayerNorm.weight', 'encoder.layer.23.output.LayerNorm.bias', 'encoder.layer.7.output.LayerNorm.weight', 'encoder.layer.19.attention.self.value.weight', 'encoder.layer.5.attention.output.dense.weight', 'encoder.layer.17.output.LayerNorm.bias', 'encoder.layer.6.attention.self.query.bias', 'encoder.layer.0.attention.self.key.weight', 'encoder.layer.15.attention.self.query.weight', 'encoder.layer.14.intermediate.dense.bias', 'encoder.layer.4.attention.output.LayerNorm.weight', 'encoder.layer.22.attention.self.query.bias', 'encoder.layer.21.attention.self.query.bias', 'encoder.layer.20.output.dense.weight', 'encoder.layer.8.attention.self.key.weight', 'encoder.layer.20.output.dense.bias', 'encoder.layer.1.output.dense.weight', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.23.attention.output.dense.bias', 'encoder.layer.18.attention.self.key.weight', 'encoder.layer.16.output.dense.bias', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.12.attention.self.value.bias', 'encoder.layer.10.output.dense.bias', 'encoder.layer.18.attention.output.LayerNorm.bias', 'encoder.layer.5.attention.self.value.weight', 'encoder.layer.22.attention.output.dense.bias', 'encoder.layer.8.output.LayerNorm.bias', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.1.attention.output.dense.bias', 'encoder.layer.21.attention.self.value.bias', 'encoder.layer.15.attention.output.dense.weight', 'encoder.layer.10.output.LayerNorm.bias', 'encoder.layer.13.attention.self.query.bias', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.23.attention.output.dense.weight', 'encoder.layer.21.attention.output.dense.bias', 'encoder.layer.15.attention.output.LayerNorm.bias', 'encoder.layer.2.attention.self.query.bias', 'encoder.layer.8.attention.self.value.bias', 'encoder.layer.6.attention.self.query.weight', 'encoder.layer.23.attention.output.LayerNorm.bias', 'encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.layer.3.attention.output.dense.weight', 'encoder.layer.15.attention.self.query.bias', 'encoder.layer.4.output.dense.bias', 'pooler.dense.bias', 'encoder.layer.22.attention.self.query.weight', 'encoder.layer.0.attention.self.value.bias', 'encoder.layer.5.output.LayerNorm.bias', 'encoder.layer.22.output.dense.bias', 'encoder.layer.14.output.LayerNorm.weight', 'embeddings.position_embeddings.weight', 'encoder.layer.0.attention.output.LayerNorm.weight', 'encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.layer.11.attention.self.query.bias', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.13.attention.self.key.bias', 'encoder.layer.23.intermediate.dense.bias', 'encoder.layer.7.attention.self.query.bias', 'encoder.layer.8.attention.self.key.bias', 'encoder.layer.10.output.dense.weight', 'pooler.dense.weight', 'encoder.layer.4.attention.self.query.bias', 'encoder.layer.3.attention.self.query.bias', 'encoder.layer.13.output.LayerNorm.bias', 'encoder.layer.22.attention.self.key.bias', 'encoder.layer.13.attention.self.query.weight', 'encoder.layer.7.attention.self.value.bias', 'encoder.layer.8.output.dense.bias', 'encoder.layer.20.attention.self.value.weight', 'encoder.layer.19.intermediate.dense.weight', 'encoder.layer.16.attention.output.dense.weight', 'encoder.layer.11.attention.self.key.weight', 'encoder.layer.18.attention.self.query.weight', 'encoder.layer.10.attention.output.LayerNorm.bias', 'encoder.layer.22.attention.self.value.bias', 'encoder.layer.1.attention.self.key.weight', 'encoder.layer.7.attention.output.LayerNorm.bias', 'encoder.layer.11.output.LayerNorm.weight', 'encoder.layer.23.intermediate.dense.weight', 'encoder.layer.14.attention.self.key.bias', 'encoder.layer.16.attention.self.query.weight', 'encoder.layer.6.output.LayerNorm.bias', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.6.output.dense.bias', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.12.attention.output.dense.bias', 'encoder.layer.18.output.dense.weight', 'encoder.layer.16.attention.self.key.bias', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.9.output.dense.bias', 'encoder.layer.22.intermediate.dense.bias', 'encoder.layer.19.output.LayerNorm.weight', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.19.attention.output.dense.bias', 'encoder.layer.21.attention.self.value.weight', 'encoder.layer.8.attention.output.LayerNorm.bias', 'encoder.layer.12.attention.self.key.weight', 'encoder.layer.22.attention.output.LayerNorm.bias', 'encoder.layer.19.output.dense.bias', 'encoder.layer.13.attention.self.value.bias', 'encoder.layer.17.intermediate.dense.weight', 'encoder.layer.1.attention.self.query.bias', 'encoder.layer.20.attention.self.query.weight', 'encoder.layer.7.attention.output.dense.bias', 'encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.layer.9.output.LayerNorm.weight', 'encoder.layer.7.output.LayerNorm.bias', 'encoder.layer.5.attention.self.value.bias', 'encoder.layer.12.output.LayerNorm.weight', 'encoder.layer.1.output.dense.bias', 'encoder.layer.22.intermediate.dense.weight', 'encoder.layer.23.output.dense.weight', 'encoder.layer.1.attention.self.value.bias', 'encoder.layer.10.output.LayerNorm.weight', 'encoder.layer.15.output.LayerNorm.weight', 'encoder.layer.16.attention.self.key.weight', 'encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.18.attention.self.value.weight', 'encoder.layer.21.attention.self.query.weight', 'embeddings.token_type_embeddings.weight', 'encoder.layer.10.attention.self.key.weight', 'encoder.layer.13.output.dense.weight', 'encoder.layer.22.output.dense.weight', 'encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.19.attention.output.LayerNorm.weight', 'encoder.layer.2.attention.self.value.bias', 'encoder.layer.19.attention.self.query.bias', 'encoder.layer.6.attention.self.value.weight', 'encoder.layer.2.attention.self.value.weight', 'encoder.layer.22.output.LayerNorm.bias', 'encoder.layer.3.attention.self.key.bias', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.9.attention.self.query.weight', 'encoder.layer.7.attention.output.LayerNorm.weight', 'encoder.layer.1.attention.self.key.bias', 'encoder.layer.7.output.dense.weight', 'encoder.layer.17.output.dense.weight', 'encoder.layer.10.attention.output.LayerNorm.weight', 'encoder.layer.19.output.dense.weight', 'encoder.layer.12.output.dense.bias', 'encoder.layer.17.attention.output.dense.weight', 'encoder.layer.18.output.LayerNorm.weight', 'encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.17.intermediate.dense.bias', 'encoder.layer.20.attention.self.query.bias', 'encoder.layer.12.attention.output.dense.weight', 'encoder.layer.6.attention.output.LayerNorm.weight', 'encoder.layer.4.attention.self.key.weight', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.9.attention.output.dense.bias', 'encoder.layer.12.attention.self.query.bias', 'encoder.layer.13.output.LayerNorm.weight', 'encoder.layer.15.attention.output.LayerNorm.weight', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.14.output.dense.bias', 'encoder.layer.14.attention.output.LayerNorm.bias', 'encoder.layer.8.attention.self.value.weight', 'encoder.layer.21.output.dense.weight', 'encoder.layer.12.attention.output.LayerNorm.bias', 'encoder.layer.3.attention.self.value.weight', 'encoder.layer.22.attention.output.dense.weight', 'encoder.layer.18.output.LayerNorm.bias', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.21.output.LayerNorm.bias', 'encoder.layer.10.attention.self.value.weight', 'encoder.layer.7.attention.self.value.weight', 'encoder.layer.15.attention.self.key.weight', 'encoder.layer.0.attention.self.value.weight', 'encoder.layer.13.attention.output.dense.bias', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.9.attention.output.LayerNorm.weight', 'encoder.layer.2.output.dense.weight', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.20.attention.self.key.bias', 'encoder.layer.6.attention.output.LayerNorm.bias', 'encoder.layer.17.attention.self.key.weight', 'encoder.layer.20.attention.output.LayerNorm.bias', 'encoder.layer.5.attention.output.dense.bias', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.16.output.LayerNorm.weight', 'encoder.layer.10.intermediate.dense.weight', 'encoder.layer.20.attention.self.key.weight', 'encoder.layer.15.attention.self.key.bias', 'encoder.layer.0.attention.self.query.weight', 'encoder.layer.6.attention.self.value.bias', 'encoder.layer.14.attention.output.dense.weight', 'encoder.layer.16.intermediate.dense.weight', 'encoder.layer.4.attention.self.key.bias', 'encoder.layer.23.attention.self.query.bias', 'encoder.layer.11.output.LayerNorm.bias', 'encoder.layer.23.attention.self.key.weight', 'encoder.layer.2.attention.output.dense.bias', 'encoder.layer.11.attention.self.value.bias', 'encoder.layer.14.attention.self.value.weight', 'encoder.layer.10.attention.self.query.weight', 'encoder.layer.10.attention.self.query.bias', 'encoder.layer.11.output.dense.bias', 'encoder.layer.9.attention.output.dense.weight', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.5.output.dense.bias', 'encoder.layer.19.attention.self.key.weight', 'encoder.layer.7.attention.self.key.weight', 'encoder.layer.11.attention.self.query.weight', 'encoder.layer.12.attention.self.value.weight', 'encoder.layer.15.intermediate.dense.bias', 'encoder.layer.1.attention.self.value.weight', 'encoder.layer.18.attention.self.value.bias', 'embeddings.LayerNorm.bias', 'encoder.layer.20.output.LayerNorm.bias', 'encoder.layer.20.intermediate.dense.weight', 'encoder.layer.2.attention.output.LayerNorm.weight', 'encoder.layer.11.attention.output.dense.bias', 'encoder.layer.7.attention.self.query.weight', 'encoder.layer.15.intermediate.dense.weight', 'encoder.layer.5.attention.output.LayerNorm.weight', 'encoder.layer.14.attention.self.key.weight', 'encoder.layer.13.intermediate.dense.bias', 'encoder.layer.7.output.dense.bias', 'encoder.layer.8.attention.output.dense.weight', 'encoder.layer.8.attention.self.query.bias', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.22.output.LayerNorm.weight', 'encoder.layer.10.attention.output.dense.bias', 'encoder.layer.9.attention.self.value.bias', 'encoder.layer.13.attention.output.dense.weight', 'encoder.layer.21.intermediate.dense.bias', 'encoder.layer.3.output.dense.weight', 'encoder.layer.2.attention.self.key.weight', 'encoder.layer.22.attention.self.value.weight', 'encoder.layer.5.attention.self.query.weight', 'encoder.layer.4.output.dense.weight', 'encoder.layer.9.output.LayerNorm.bias', 'encoder.layer.15.output.LayerNorm.bias', 'encoder.layer.20.output.LayerNorm.weight', 'encoder.layer.21.intermediate.dense.weight', 'encoder.layer.15.attention.self.value.bias', 'encoder.layer.3.attention.self.query.weight', 'encoder.layer.21.attention.output.LayerNorm.bias', 'encoder.layer.23.attention.output.LayerNorm.weight', 'encoder.layer.20.attention.output.dense.weight', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.9.output.dense.weight', 'encoder.layer.2.output.dense.bias', 'encoder.layer.7.intermediate.dense.bias', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.21.output.dense.bias', 'encoder.layer.19.attention.output.LayerNorm.bias', 'encoder.layer.7.attention.output.dense.weight', 'encoder.layer.18.attention.output.LayerNorm.weight', 'encoder.layer.16.attention.output.dense.bias', 'encoder.layer.17.output.LayerNorm.weight', 'encoder.layer.15.attention.output.dense.bias', 'encoder.layer.18.output.dense.bias', 'encoder.layer.12.output.dense.weight', 'encoder.layer.0.output.dense.weight', 'encoder.layer.14.attention.output.dense.bias', 'encoder.layer.23.output.LayerNorm.weight', 'encoder.layer.3.attention.self.value.bias', 'encoder.layer.16.attention.self.value.weight', 'encoder.layer.8.output.LayerNorm.weight', 'encoder.layer.10.attention.self.value.bias', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.9.attention.self.key.bias', 'encoder.layer.0.attention.self.query.bias', 'encoder.layer.21.attention.output.dense.weight', 'encoder.layer.4.attention.output.dense.weight', 'encoder.layer.0.attention.output.dense.weight', 'encoder.layer.4.attention.self.query.weight', 'encoder.layer.14.output.dense.weight', 'encoder.layer.2.attention.output.dense.weight', 'encoder.layer.4.attention.output.dense.bias', 'encoder.layer.9.attention.output.LayerNorm.bias', 'encoder.layer.2.attention.self.query.weight', 'encoder.layer.5.attention.self.query.bias', 'encoder.layer.17.attention.output.LayerNorm.bias', 'encoder.layer.14.attention.self.query.weight', 'encoder.layer.16.attention.self.query.bias', 'encoder.layer.8.attention.self.query.weight', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.13.attention.output.LayerNorm.weight', 'encoder.layer.21.output.LayerNorm.weight', 'encoder.layer.4.attention.output.LayerNorm.bias', 'encoder.layer.12.intermediate.dense.bias', 'encoder.layer.18.intermediate.dense.weight', 'encoder.layer.22.attention.output.LayerNorm.weight', 'encoder.layer.13.output.dense.bias', 'encoder.layer.13.attention.self.key.weight', 'encoder.layer.21.attention.self.key.bias', 'encoder.layer.18.attention.self.key.bias', 'encoder.layer.6.attention.output.dense.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Overwriting existing adapter 'ep'.
Overwriting existing adapter 'tp'.
Overwriting existing adapter 'es'.
Overwriting existing adapter 'ts'.
Overwriting existing adapter fusion module 'ep,tp,es,ts'
05/09/2022 20:00:23 - INFO - __main__ -   Creating features from dataset file at .
/cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//squad/xlm-KG_LR4e-5_EPOCH2.0_maxlen384_batchsize4_gradacc8
XLMConfig {
  "architectures": [
    "XLMRobertaForMaskedLM"
  ],
  "asm": false,
  "attention_dropout": 0.1,
  "attention_probs_dropout_prob": 0.1,
  "bos_index": 0,
  "bos_token_id": 0,
  "causal": false,
  "dropout": 0.1,
  "emb_dim": 1024,
  "embed_init_std": 0.02209708691207961,
  "end_n_top": 5,
  "eos_index": 1,
  "eos_token_id": 2,
  "gelu_activation": true,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "init_std": 0.02,
  "initializer_range": 0.02,
  "intermediate_size": 4096,
  "is_encoder": true,
  "lang_id": 0,
  "layer_norm_eps": 1e-05,
  "mask_index": 5,
  "mask_token_id": 0,
  "max_position_embeddings": 514,
  "model_type": "xlm",
  "n_heads": 16,
  "n_langs": 1,
  "n_layers": 24,
  "output_past": true,
  "pad_index": 2,
  "pad_token_id": 1,
  "sinusoidal_embeddings": false,
  "start_n_top": 5,
  "summary_activation": null,
  "summary_first_dropout": 0.1,
  "summary_proj_to_labels": true,
  "summary_type": "first",
  "summary_use_proj": true,
  "transformers_version": "4.17.0",
  "type_vocab_size": 1,
  "unk_index": 3,
  "use_lang_emb": false,
  "vocab_size": 250002
}

  0%|          | 0/48 [00:00<?, ?it/s] 19%|█▉        | 9/48 [00:00<00:00, 85.74it/s] 38%|███▊      | 18/48 [00:00<00:00, 77.18it/s] 58%|█████▊    | 28/48 [00:00<00:00, 85.71it/s] 81%|████████▏ | 39/48 [00:00<00:00, 93.21it/s]100%|██████████| 48/48 [00:00<00:00, 94.58it/s]
convert squad examples to features:   0%|          | 0/1190 [00:00<?, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.
convert squad examples to features:   0%|          | 1/1190 [00:00<03:50,  5.16it/s]convert squad examples to features:   5%|▌         | 65/1190 [00:00<00:05, 213.40it/s]convert squad examples to features:   8%|▊         | 97/1190 [00:00<00:04, 239.89it/s]convert squad examples to features:  14%|█▎        | 161/1190 [00:00<00:03, 288.77it/s]convert squad examples to features:  16%|█▌        | 193/1190 [00:00<00:03, 278.47it/s]convert squad examples to features:  19%|█▉        | 225/1190 [00:00<00:03, 283.47it/s]convert squad examples to features:  22%|██▏       | 257/1190 [00:01<00:03, 272.88it/s]convert squad examples to features:  24%|██▍       | 289/1190 [00:01<00:03, 263.91it/s]convert squad examples to features:  27%|██▋       | 321/1190 [00:01<00:03, 256.43it/s]convert squad examples to features:  30%|██▉       | 353/1190 [00:01<00:03, 270.37it/s]convert squad examples to features:  32%|███▏      | 385/1190 [00:01<00:05, 147.28it/s]convert squad examples to features:  35%|███▌      | 417/1190 [00:01<00:04, 160.32it/s]convert squad examples to features:  38%|███▊      | 449/1190 [00:02<00:04, 176.30it/s]convert squad examples to features:  40%|████      | 481/1190 [00:02<00:03, 188.12it/s]convert squad examples to features:  43%|████▎     | 513/1190 [00:02<00:03, 184.85it/s]convert squad examples to features:  46%|████▌     | 545/1190 [00:02<00:03, 183.64it/s]convert squad examples to features:  48%|████▊     | 577/1190 [00:02<00:03, 200.98it/s]convert squad examples to features:  51%|█████     | 609/1190 [00:02<00:03, 187.18it/s]convert squad examples to features:  54%|█████▍    | 641/1190 [00:03<00:03, 182.75it/s]convert squad examples to features:  57%|█████▋    | 673/1190 [00:03<00:02, 181.29it/s]convert squad examples to features:  59%|█████▉    | 705/1190 [00:03<00:02, 198.45it/s]convert squad examples to features:  62%|██████▏   | 737/1190 [00:03<00:02, 214.35it/s]convert squad examples to features:  65%|██████▍   | 769/1190 [00:03<00:01, 235.47it/s]convert squad examples to features:  67%|██████▋   | 801/1190 [00:03<00:01, 248.02it/s]convert squad examples to features:  70%|███████   | 833/1190 [00:03<00:01, 214.67it/s]convert squad examples to features:  73%|███████▎  | 865/1190 [00:04<00:01, 228.79it/s]convert squad examples to features:  75%|███████▌  | 897/1190 [00:04<00:01, 216.90it/s]convert squad examples to features:  78%|███████▊  | 929/1190 [00:04<00:01, 196.35it/s]convert squad examples to features:  81%|████████  | 961/1190 [00:04<00:01, 211.09it/s]convert squad examples to features:  83%|████████▎ | 993/1190 [00:04<00:00, 212.68it/s]convert squad examples to features:  86%|████████▌ | 1025/1190 [00:04<00:00, 219.42it/s]convert squad examples to features:  89%|████████▉ | 1057/1190 [00:04<00:00, 234.94it/s]convert squad examples to features:  94%|█████████▍| 1121/1190 [00:05<00:00, 242.95it/s]convert squad examples to features:  97%|█████████▋| 1153/1190 [00:05<00:00, 226.10it/s]convert squad examples to features: 100%|██████████| 1190/1190 [00:05<00:00, 219.35it/s]/cluster/project/sachan/yifan/softwares/anaconda/anaconda3/envs/xfactr/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2272: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

add example index and unique id:   0%|          | 0/1190 [00:00<?, ?it/s]add example index and unique id: 100%|██████████| 1190/1190 [00:00<00:00, 665052.87it/s]
05/09/2022 20:00:29 - INFO - __main__ -   Saving features into cached file ./cached_xquad.ru.json_xlm-KG_LR4e-5_EPOCH2.0_maxlen384_batchsize4_gradacc8_384_ru
05/09/2022 20:00:31 - INFO - __main__ -   ***** Running evaluation  *****
05/09/2022 20:00:31 - INFO - __main__ -     Num examples = 1332
05/09/2022 20:00:31 - INFO - __main__ -     Batch size = 8
Evaluating:   0%|          | 0/167 [00:00<?, ?it/s]Evaluating:   1%|          | 1/167 [00:01<03:01,  1.10s/it]Evaluating:   1%|          | 2/167 [00:01<01:49,  1.51it/s]Evaluating:   2%|▏         | 3/167 [00:01<01:25,  1.91it/s]Evaluating:   2%|▏         | 4/167 [00:02<01:14,  2.18it/s]Evaluating:   3%|▎         | 5/167 [00:02<01:08,  2.38it/s]Evaluating:   4%|▎         | 6/167 [00:02<01:04,  2.51it/s]Evaluating:   4%|▍         | 7/167 [00:03<01:01,  2.61it/s]Evaluating:   5%|▍         | 8/167 [00:03<00:59,  2.68it/s]Evaluating:   5%|▌         | 9/167 [00:03<00:57,  2.73it/s]Evaluating:   6%|▌         | 10/167 [00:04<00:58,  2.69it/s]Evaluating:   7%|▋         | 11/167 [00:04<00:57,  2.72it/s]Evaluating:   7%|▋         | 12/167 [00:05<00:56,  2.73it/s]Evaluating:   8%|▊         | 13/167 [00:05<00:56,  2.75it/s]Evaluating:   8%|▊         | 14/167 [00:05<00:55,  2.77it/s]Evaluating:   9%|▉         | 15/167 [00:06<00:54,  2.77it/s]Evaluating:  10%|▉         | 16/167 [00:06<00:54,  2.79it/s]Evaluating:  10%|█         | 17/167 [00:06<00:53,  2.80it/s]Evaluating:  11%|█         | 18/167 [00:07<00:53,  2.81it/s]Evaluating:  11%|█▏        | 19/167 [00:07<00:52,  2.81it/s]Evaluating:  12%|█▏        | 20/167 [00:07<00:52,  2.81it/s]Evaluating:  13%|█▎        | 21/167 [00:08<00:52,  2.80it/s]Evaluating:  13%|█▎        | 22/167 [00:08<00:51,  2.82it/s]Evaluating:  14%|█▍        | 23/167 [00:08<00:51,  2.81it/s]Evaluating:  14%|█▍        | 24/167 [00:09<00:50,  2.81it/s]Evaluating:  15%|█▍        | 25/167 [00:09<00:50,  2.80it/s]Evaluating:  16%|█▌        | 26/167 [00:10<00:50,  2.79it/s]Evaluating:  16%|█▌        | 27/167 [00:10<00:50,  2.79it/s]Evaluating:  17%|█▋        | 28/167 [00:10<00:49,  2.78it/s]Evaluating:  17%|█▋        | 29/167 [00:11<00:49,  2.77it/s]Evaluating:  18%|█▊        | 30/167 [00:11<00:49,  2.78it/s]Evaluating:  19%|█▊        | 31/167 [00:11<00:48,  2.78it/s]Evaluating:  19%|█▉        | 32/167 [00:12<00:48,  2.78it/s]Evaluating:  20%|█▉        | 33/167 [00:12<00:48,  2.78it/s]Evaluating:  20%|██        | 34/167 [00:12<00:47,  2.78it/s]Evaluating:  21%|██        | 35/167 [00:13<00:47,  2.79it/s]Evaluating:  22%|██▏       | 36/167 [00:13<00:46,  2.80it/s]Evaluating:  22%|██▏       | 37/167 [00:13<00:46,  2.80it/s]Evaluating:  23%|██▎       | 38/167 [00:14<00:46,  2.79it/s]Evaluating:  23%|██▎       | 39/167 [00:14<00:45,  2.80it/s]Evaluating:  24%|██▍       | 40/167 [00:15<00:45,  2.81it/s]Evaluating:  25%|██▍       | 41/167 [00:15<00:44,  2.81it/s]Evaluating:  25%|██▌       | 42/167 [00:15<00:44,  2.81it/s]Evaluating:  26%|██▌       | 43/167 [00:16<00:44,  2.80it/s]Evaluating:  26%|██▋       | 44/167 [00:16<00:43,  2.80it/s]Evaluating:  27%|██▋       | 45/167 [00:16<00:43,  2.79it/s]Evaluating:  28%|██▊       | 46/167 [00:17<00:43,  2.80it/s]Evaluating:  28%|██▊       | 47/167 [00:17<00:42,  2.80it/s]Evaluating:  29%|██▊       | 48/167 [00:17<00:42,  2.80it/s]Evaluating:  29%|██▉       | 49/167 [00:18<00:42,  2.79it/s]Evaluating:  30%|██▉       | 50/167 [00:18<00:41,  2.80it/s]Evaluating:  31%|███       | 51/167 [00:18<00:41,  2.80it/s]Evaluating:  31%|███       | 52/167 [00:19<00:41,  2.80it/s]Evaluating:  32%|███▏      | 53/167 [00:19<00:40,  2.79it/s]Evaluating:  32%|███▏      | 54/167 [00:20<00:40,  2.79it/s]Evaluating:  33%|███▎      | 55/167 [00:20<00:40,  2.73it/s]Evaluating:  34%|███▎      | 56/167 [00:20<00:40,  2.75it/s]Evaluating:  34%|███▍      | 57/167 [00:21<00:39,  2.76it/s]Evaluating:  35%|███▍      | 58/167 [00:21<00:39,  2.76it/s]Evaluating:  35%|███▌      | 59/167 [00:21<00:39,  2.74it/s]Evaluating:  36%|███▌      | 60/167 [00:22<00:38,  2.75it/s]Evaluating:  37%|███▋      | 61/167 [00:22<00:38,  2.76it/s]Evaluating:  37%|███▋      | 62/167 [00:22<00:38,  2.75it/s]Evaluating:  38%|███▊      | 63/167 [00:23<00:37,  2.75it/s]Evaluating:  38%|███▊      | 64/167 [00:23<00:37,  2.76it/s]Evaluating:  39%|███▉      | 65/167 [00:24<00:37,  2.75it/s]Evaluating:  40%|███▉      | 66/167 [00:24<00:36,  2.74it/s]Evaluating:  40%|████      | 67/167 [00:24<00:37,  2.69it/s]Evaluating:  41%|████      | 68/167 [00:25<00:37,  2.61it/s]Evaluating:  41%|████▏     | 69/167 [00:25<00:37,  2.65it/s]Evaluating:  42%|████▏     | 70/167 [00:25<00:37,  2.61it/s]Evaluating:  43%|████▎     | 71/167 [00:26<00:36,  2.66it/s]Evaluating:  43%|████▎     | 72/167 [00:26<00:35,  2.65it/s]Evaluating:  44%|████▎     | 73/167 [00:27<00:37,  2.53it/s]Evaluating:  44%|████▍     | 74/167 [00:27<00:35,  2.60it/s]Evaluating:  45%|████▍     | 75/167 [00:27<00:34,  2.66it/s]Evaluating:  46%|████▌     | 76/167 [00:28<00:33,  2.68it/s]Evaluating:  46%|████▌     | 77/167 [00:28<00:33,  2.71it/s]Evaluating:  47%|████▋     | 78/167 [00:28<00:32,  2.74it/s]Evaluating:  47%|████▋     | 79/167 [00:29<00:32,  2.75it/s]Evaluating:  48%|████▊     | 80/167 [00:29<00:32,  2.70it/s]Evaluating:  49%|████▊     | 81/167 [00:30<00:32,  2.65it/s]Evaluating:  49%|████▉     | 82/167 [00:30<00:32,  2.63it/s]Evaluating:  50%|████▉     | 83/167 [00:30<00:32,  2.61it/s]Evaluating:  50%|█████     | 84/167 [00:31<00:31,  2.60it/s]Evaluating:  51%|█████     | 85/167 [00:31<00:31,  2.62it/s]Evaluating:  51%|█████▏    | 86/167 [00:32<00:31,  2.61it/s]Evaluating:  52%|█████▏    | 87/167 [00:32<00:30,  2.64it/s]Evaluating:  53%|█████▎    | 88/167 [00:32<00:29,  2.68it/s]Evaluating:  53%|█████▎    | 89/167 [00:33<00:28,  2.72it/s]Evaluating:  54%|█████▍    | 90/167 [00:33<00:28,  2.73it/s]Evaluating:  54%|█████▍    | 91/167 [00:33<00:27,  2.75it/s]Evaluating:  55%|█████▌    | 92/167 [00:34<00:27,  2.76it/s]Evaluating:  56%|█████▌    | 93/167 [00:34<00:26,  2.74it/s]Evaluating:  56%|█████▋    | 94/167 [00:34<00:27,  2.65it/s]Evaluating:  57%|█████▋    | 95/167 [00:35<00:27,  2.58it/s]Evaluating:  57%|█████▋    | 96/167 [00:35<00:27,  2.55it/s]Evaluating:  58%|█████▊    | 97/167 [00:36<00:27,  2.51it/s]Evaluating:  59%|█████▊    | 98/167 [00:36<00:26,  2.58it/s]Evaluating:  59%|█████▉    | 99/167 [00:36<00:26,  2.61it/s]Evaluating:  60%|█████▉    | 100/167 [00:37<00:25,  2.67it/s]Evaluating:  60%|██████    | 101/167 [00:37<00:24,  2.70it/s]Evaluating:  61%|██████    | 102/167 [00:38<00:23,  2.72it/s]Evaluating:  62%|██████▏   | 103/167 [00:38<00:23,  2.69it/s]Evaluating:  62%|██████▏   | 104/167 [00:38<00:23,  2.69it/s]Evaluating:  63%|██████▎   | 105/167 [00:39<00:22,  2.72it/s]Evaluating:  63%|██████▎   | 106/167 [00:39<00:22,  2.73it/s]Evaluating:  64%|██████▍   | 107/167 [00:39<00:21,  2.75it/s]Evaluating:  65%|██████▍   | 108/167 [00:40<00:21,  2.76it/s]Evaluating:  65%|██████▌   | 109/167 [00:40<00:20,  2.77it/s]Evaluating:  66%|██████▌   | 110/167 [00:40<00:20,  2.78it/s]Evaluating:  66%|██████▋   | 111/167 [00:41<00:20,  2.77it/s]Evaluating:  67%|██████▋   | 112/167 [00:41<00:19,  2.78it/s]Evaluating:  68%|██████▊   | 113/167 [00:41<00:19,  2.77it/s]Evaluating:  68%|██████▊   | 114/167 [00:42<00:19,  2.78it/s]Evaluating:  69%|██████▉   | 115/167 [00:42<00:18,  2.77it/s]Evaluating:  69%|██████▉   | 116/167 [00:43<00:18,  2.77it/s]Evaluating:  70%|███████   | 117/167 [00:43<00:18,  2.76it/s]Evaluating:  71%|███████   | 118/167 [00:43<00:17,  2.76it/s]Evaluating:  71%|███████▏  | 119/167 [00:44<00:17,  2.77it/s]Evaluating:  72%|███████▏  | 120/167 [00:44<00:16,  2.77it/s]Evaluating:  72%|███████▏  | 121/167 [00:44<00:16,  2.76it/s]Evaluating:  73%|███████▎  | 122/167 [00:45<00:16,  2.77it/s]Evaluating:  74%|███████▎  | 123/167 [00:45<00:15,  2.78it/s]Evaluating:  74%|███████▍  | 124/167 [00:45<00:15,  2.77it/s]Evaluating:  75%|███████▍  | 125/167 [00:46<00:15,  2.77it/s]Evaluating:  75%|███████▌  | 126/167 [00:46<00:14,  2.78it/s]Evaluating:  76%|███████▌  | 127/167 [00:47<00:14,  2.78it/s]Evaluating:  77%|███████▋  | 128/167 [00:47<00:14,  2.78it/s]Evaluating:  77%|███████▋  | 129/167 [00:47<00:13,  2.78it/s]Evaluating:  78%|███████▊  | 130/167 [00:48<00:13,  2.78it/s]Evaluating:  78%|███████▊  | 131/167 [00:48<00:13,  2.77it/s]Evaluating:  79%|███████▉  | 132/167 [00:48<00:12,  2.77it/s]Evaluating:  80%|███████▉  | 133/167 [00:49<00:12,  2.77it/s]Evaluating:  80%|████████  | 134/167 [00:49<00:11,  2.76it/s]Evaluating:  81%|████████  | 135/167 [00:49<00:11,  2.69it/s]Evaluating:  81%|████████▏ | 136/167 [00:50<00:11,  2.71it/s]Evaluating:  82%|████████▏ | 137/167 [00:50<00:10,  2.73it/s]Evaluating:  83%|████████▎ | 138/167 [00:51<00:10,  2.75it/s]Evaluating:  83%|████████▎ | 139/167 [00:51<00:10,  2.76it/s]Evaluating:  84%|████████▍ | 140/167 [00:51<00:09,  2.77it/s]Evaluating:  84%|████████▍ | 141/167 [00:52<00:09,  2.76it/s]Evaluating:  85%|████████▌ | 142/167 [00:52<00:09,  2.72it/s]Evaluating:  86%|████████▌ | 143/167 [00:52<00:08,  2.73it/s]Evaluating:  86%|████████▌ | 144/167 [00:53<00:08,  2.56it/s]Evaluating:  87%|████████▋ | 145/167 [00:53<00:08,  2.51it/s]Evaluating:  87%|████████▋ | 146/167 [00:54<00:08,  2.52it/s]Evaluating:  88%|████████▊ | 147/167 [00:54<00:08,  2.44it/s]Evaluating:  89%|████████▊ | 148/167 [00:54<00:07,  2.51it/s]Evaluating:  89%|████████▉ | 149/167 [00:55<00:06,  2.58it/s]Evaluating:  90%|████████▉ | 150/167 [00:55<00:06,  2.55it/s]Evaluating:  90%|█████████ | 151/167 [00:56<00:06,  2.59it/s]Evaluating:  91%|█████████ | 152/167 [00:56<00:05,  2.62it/s]Evaluating:  92%|█████████▏| 153/167 [00:56<00:05,  2.58it/s]Evaluating:  92%|█████████▏| 154/167 [00:57<00:05,  2.59it/s]Evaluating:  93%|█████████▎| 155/167 [00:57<00:04,  2.64it/s]Evaluating:  93%|█████████▎| 156/167 [00:57<00:04,  2.66it/s]Evaluating:  94%|█████████▍| 157/167 [00:58<00:03,  2.70it/s]Evaluating:  95%|█████████▍| 158/167 [00:58<00:03,  2.70it/s]Evaluating:  95%|█████████▌| 159/167 [00:59<00:02,  2.72it/s]Evaluating:  96%|█████████▌| 160/167 [00:59<00:02,  2.74it/s]Evaluating:  96%|█████████▋| 161/167 [00:59<00:02,  2.72it/s]Evaluating:  97%|█████████▋| 162/167 [01:00<00:01,  2.74it/s]Evaluating:  98%|█████████▊| 163/167 [01:00<00:01,  2.75it/s]Evaluating:  98%|█████████▊| 164/167 [01:00<00:01,  2.75it/s]Evaluating:  99%|█████████▉| 165/167 [01:01<00:00,  2.75it/s]Evaluating:  99%|█████████▉| 166/167 [01:01<00:00,  2.76it/s]Evaluating: 100%|██████████| 167/167 [01:01<00:00,  3.22it/s]Evaluating: 100%|██████████| 167/167 [01:01<00:00,  2.70it/s]
05/09/2022 20:01:32 - INFO - __main__ -     Evaluation done in total 61.794421 secs (0.046392 sec per example)
05/09/2022 20:01:36 - INFO - __main__ -   Results: {'exact': 64.28571428571429, 'f1': 79.61440712617369, 'total': 1190, 'HasAns_exact': 64.28571428571429, 'HasAns_f1': 79.61440712617369, 'HasAns_total': 1190, 'best_exact': 64.28571428571429, 'best_exact_thresh': 0.0, 'best_f1': 79.61440712617369, 'best_f1_thresh': 0.0}
  tr 
2022-05-09 20:01:40.440040: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0
05/09/2022 20:01:50 - WARNING - __main__ -   Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, 16-bits training: False
You are using a model of type xlm-roberta to instantiate a model of type xlm. This is not supported for all configurations of models and can yield errors.
Some weights of the model checkpoint at /cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//squad/xlm-KG_LR4e-5_EPOCH2.0_maxlen384_batchsize4_gradacc8 were not used when initializing XLMRobertaModel: ['base_model.encoder.layer.12.output.dense.bias', 'base_model.encoder.layer.19.attention.self.value.weight', 'base_model.encoder.layer.3.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.0.attention.self.key.weight', 'base_model.encoder.layer.2.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.8.attention.self.query.weight', 'base_model.encoder.layer.11.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.9.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.4.output.LayerNorm.weight', 'base_model.encoder.layer.7.output.LayerNorm.bias', 'base_model.encoder.layer.9.attention.self.query.weight', 'base_model.encoder.layer.12.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.3.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.11.attention.self.value.weight', 'base_model.encoder.layer.10.output.LayerNorm.weight', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.17.output.LayerNorm.bias', 'base_model.encoder.layer.10.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.0.output.dense.bias', 'base_model.encoder.layer.22.attention.self.key.weight', 'base_model.encoder.layer.16.attention.output.dense.bias', 'base_model.encoder.layer.18.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.14.output.dense.weight', 'base_model.encoder.layer.2.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.10.attention.output.LayerNorm.bias', 'base_model.encoder.layer.19.output.LayerNorm.weight', 'base_model.encoder.layer.20.attention.output.LayerNorm.bias', 'base_model.encoder.layer.3.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.23.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.3.output.dense.weight', 'base_model.encoder.layer.19.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.20.attention.output.LayerNorm.weight', 'base_model.encoder.layer.21.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.23.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.14.output.LayerNorm.weight', 'base_model.encoder.layer.8.intermediate.dense.weight', 'base_model.encoder.layer.17.attention.self.query.bias', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.12.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.22.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.2.attention.self.value.bias', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.6.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.3.output.adapters.ep.adapter_up.bias', 'base_model.embeddings.LayerNorm.bias', 'base_model.encoder.layer.4.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.8.output.LayerNorm.weight', 'base_model.encoder.layer.21.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.10.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.21.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.6.attention.output.dense.bias', 'base_model.encoder.layer.19.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.20.output.LayerNorm.bias', 'base_model.encoder.layer.22.attention.self.query.weight', 'base_model.encoder.layer.12.attention.self.value.weight', 'base_model.encoder.layer.2.attention.output.dense.bias', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.5.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.18.attention.self.key.weight', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.8.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.23.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.15.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.16.attention.output.LayerNorm.weight', 'base_model.encoder.layer.9.attention.self.key.weight', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.23.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.20.attention.self.query.weight', 'base_model.encoder.layer.22.output.dense.weight', 'base_model.encoder.layer.23.attention.self.value.bias', 'base_model.encoder.layer.4.attention.self.key.bias', 'base_model.encoder.layer.6.output.LayerNorm.weight', 'base_model.encoder.layer.0.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.19.intermediate.dense.weight', 'base_model.encoder.layer.13.output.LayerNorm.bias', 'base_model.encoder.layer.22.output.LayerNorm.bias', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.0.attention.self.value.weight', 'base_model.encoder.layer.10.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.12.attention.self.query.bias', 'base_model.encoder.layer.23.attention.self.query.weight', 'base_model.encoder.layer.10.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.12.attention.output.dense.bias', 'base_model.encoder.layer.10.intermediate.dense.weight', 'base_model.encoder.layer.20.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.4.attention.output.dense.weight', 'base_model.encoder.layer.8.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.21.intermediate.dense.bias', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.7.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.6.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.11.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.12.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.6.attention.self.key.weight', 'base_model.encoder.layer.14.output.dense.bias', 'base_model.encoder.layer.20.intermediate.dense.weight', 'base_model.encoder.layer.3.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.12.attention.self.key.weight', 'base_model.encoder.layer.9.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.0.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.5.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.18.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.5.attention.self.key.bias', 'base_model.encoder.layer.12.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.4.attention.self.query.bias', 'base_model.encoder.layer.15.output.LayerNorm.weight', 'base_model.encoder.layer.21.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.19.attention.output.LayerNorm.bias', 'base_model.encoder.layer.15.output.dense.bias', 'base_model.encoder.layer.5.attention.self.key.weight', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.6.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.18.attention.self.key.bias', 'base_model.encoder.layer.13.attention.output.LayerNorm.bias', 'base_model.encoder.layer.15.intermediate.dense.bias', 'base_model.encoder.layer.20.output.dense.bias', 'base_model.encoder.layer.22.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.22.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.22.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.3.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.1.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.20.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.1.attention.output.dense.bias', 'base_model.encoder.layer.19.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.3.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.13.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.14.attention.self.key.bias', 'base_model.encoder.layer.3.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.5.output.dense.weight', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.11.attention.output.dense.weight', 'base_model.encoder.layer.16.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.11.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.3.attention.self.key.bias', 'base_model.encoder.layer.16.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.12.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.1.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.6.intermediate.dense.weight', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.1.attention.self.query.weight', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.7.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.9.attention.output.dense.weight', 'base_model.encoder.layer.20.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.23.intermediate.dense.weight', 'base_model.encoder.layer.1.attention.self.value.bias', 'base_model.encoder.layer.14.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.16.attention.self.key.weight', 'base_model.encoder.layer.12.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.1.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.1.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.15.attention.self.value.bias', 'base_model.encoder.layer.7.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.1.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.16.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.3.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.21.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.4.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.17.attention.output.dense.weight', 'base_model.encoder.layer.8.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.13.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.7.attention.self.key.bias', 'base_model.encoder.layer.16.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.13.intermediate.dense.bias', 'base_model.encoder.layer.14.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.19.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.17.attention.self.value.bias', 'base_model.encoder.layer.4.attention.self.value.bias', 'base_model.encoder.layer.11.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.12.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.23.output.dense.bias', 'base_model.encoder.layer.16.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.16.output.dense.bias', 'base_model.encoder.layer.20.attention.self.key.bias', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.7.output.dense.bias', 'base_model.encoder.layer.11.attention.output.LayerNorm.weight', 'base_model.encoder.layer.2.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.15.attention.output.LayerNorm.bias', 'base_model.encoder.layer.14.attention.self.value.bias', 'base_model.encoder.layer.20.output.dense.weight', 'base_model.encoder.layer.16.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.20.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.5.attention.self.value.weight', 'base_model.encoder.layer.11.intermediate.dense.bias', 'base_model.encoder.layer.14.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.10.attention.output.dense.bias', 'base_model.encoder.layer.22.attention.self.query.bias', 'base_model.encoder.layer.22.intermediate.dense.bias', 'base_model.encoder.layer.4.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.21.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.5.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.7.attention.self.value.weight', 'base_model.embeddings.LayerNorm.weight', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.5.attention.self.query.bias', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.8.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.9.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.18.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.0.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.17.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.12.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.1.attention.output.LayerNorm.bias', 'base_model.encoder.layer.19.attention.self.value.bias', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.18.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.11.intermediate.dense.weight', 'base_model.encoder.layer.14.attention.output.dense.weight', 'base_model.encoder.layer.19.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.7.attention.output.LayerNorm.weight', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.20.attention.output.dense.weight', 'base_model.encoder.layer.0.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.7.output.dense.weight', 'base_model.encoder.layer.23.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.18.attention.output.LayerNorm.weight', 'base_model.encoder.layer.19.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.2.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.15.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.16.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.17.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.9.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.13.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.12.output.LayerNorm.bias', 'base_model.encoder.layer.16.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.4.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.15.attention.output.LayerNorm.weight', 'base_model.encoder.layer.23.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.8.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.16.attention.self.key.bias', 'base_model.encoder.layer.0.attention.self.value.bias', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.8.attention.output.LayerNorm.bias', 'base_model.encoder.layer.19.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.11.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.23.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.2.attention.self.query.bias', 'base_model.encoder.layer.20.attention.self.key.weight', 'base_model.encoder.layer.23.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.13.attention.output.dense.bias', 'base_model.encoder.layer.22.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.9.output.dense.weight', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.9.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.12.attention.self.value.bias', 'base_model.encoder.layer.3.output.dense.bias', 'base_model.encoder.layer.9.attention.output.LayerNorm.weight', 'base_model.encoder.layer.14.attention.output.dense.bias', 'base_model.encoder.layer.23.output.LayerNorm.bias', 'base_model.encoder.layer.0.attention.output.dense.bias', 'base_model.encoder.layer.18.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.6.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.23.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.13.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.1.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.16.attention.output.dense.weight', 'base_model.encoder.layer.13.attention.self.value.weight', 'base_model.encoder.layer.21.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.4.attention.output.dense.bias', 'base_model.encoder.layer.4.attention.output.LayerNorm.bias', 'base_model.embeddings.position_embeddings.weight', 'base_model.encoder.layer.11.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.12.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.20.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.10.attention.self.query.bias', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.19.attention.self.query.bias', 'base_model.encoder.layer.17.attention.self.key.bias', 'base_model.encoder.layer.11.attention.output.dense.bias', 'base_model.encoder.layer.4.attention.self.value.weight', 'base_model.encoder.layer.14.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.19.attention.output.dense.weight', 'base_model.encoder.layer.20.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.4.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.19.attention.self.key.bias', 'base_model.encoder.layer.8.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.18.output.dense.weight', 'base_model.encoder.layer.20.output.LayerNorm.weight', 'base_model.encoder.layer.2.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.18.attention.output.LayerNorm.bias', 'base_model.encoder.layer.12.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.1.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.6.output.LayerNorm.bias', 'base_model.encoder.layer.6.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.14.attention.self.key.weight', 'base_model.encoder.layer.6.attention.self.value.weight', 'base_model.encoder.layer.9.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.23.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.9.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.17.intermediate.dense.bias', 'base_model.encoder.layer.8.attention.self.query.bias', 'base_model.encoder.layer.5.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.2.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.0.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.2.attention.self.value.weight', 'base_model.encoder.layer.4.output.LayerNorm.bias', 'base_model.encoder.layer.6.attention.output.LayerNorm.weight', 'base_model.encoder.layer.19.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.22.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.1.output.dense.bias', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.8.attention.self.key.bias', 'base_model.encoder.layer.22.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.12.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.21.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.11.attention.self.key.weight', 'base_model.encoder.layer.7.attention.self.query.weight', 'base_model.encoder.layer.14.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.4.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.21.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.5.attention.output.LayerNorm.weight', 'base_model.encoder.layer.13.attention.output.LayerNorm.weight', 'base_model.encoder.layer.18.intermediate.dense.weight', 'base_model.encoder.layer.8.intermediate.dense.bias', 'base_model.encoder.layer.5.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.13.attention.self.key.bias', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.5.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.1.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.10.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.22.attention.output.LayerNorm.bias', 'base_model.encoder.layer.23.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.6.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.2.output.LayerNorm.bias', 'base_model.encoder.layer.19.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.22.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.6.intermediate.dense.bias', 'base_model.encoder.layer.4.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.2.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.15.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.9.intermediate.dense.bias', 'base_model.encoder.layer.4.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.16.output.LayerNorm.weight', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.0.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.6.output.dense.bias', 'base_model.encoder.layer.7.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.17.output.dense.weight', 'base_model.encoder.layer.17.attention.output.LayerNorm.bias', 'base_model.encoder.layer.18.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.6.attention.output.LayerNorm.bias', 'base_model.encoder.layer.10.attention.self.query.weight', 'base_model.encoder.layer.21.output.dense.weight', 'base_model.encoder.layer.3.attention.self.value.bias', 'base_model.encoder.layer.10.attention.self.key.weight', 'base_model.encoder.layer.14.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.21.attention.output.LayerNorm.weight', 'base_model.encoder.layer.22.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.11.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.0.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.13.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.12.attention.output.LayerNorm.weight', 'base_model.encoder.layer.9.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.2.output.LayerNorm.weight', 'base_model.encoder.layer.14.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.5.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.8.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.14.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.14.attention.self.value.weight', 'base_model.encoder.layer.21.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.8.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.22.attention.self.value.bias', 'base_model.encoder.layer.2.attention.self.key.bias', 'base_model.encoder.layer.9.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.1.output.LayerNorm.weight', 'base_model.encoder.layer.0.output.dense.weight', 'base_model.pooler.dense.weight', 'base_model.embeddings.token_type_embeddings.weight', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.16.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.7.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.18.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.9.attention.self.value.weight', 'base_model.encoder.layer.2.attention.self.query.weight', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.7.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.16.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.16.attention.self.query.weight', 'base_model.encoder.layer.14.intermediate.dense.weight', 'base_model.encoder.layer.13.intermediate.dense.weight', 'base_model.encoder.layer.6.attention.self.key.bias', 'base_model.encoder.layer.13.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.21.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.15.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.3.attention.self.value.weight', 'base_model.encoder.layer.17.attention.self.query.weight', 'base_model.encoder.layer.13.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.5.attention.output.dense.weight', 'base_model.encoder.layer.6.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.23.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.18.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.2.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.8.attention.self.key.weight', 'base_model.encoder.layer.0.attention.self.query.weight', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.6.attention.self.value.bias', 'base_model.encoder.layer.8.attention.output.dense.weight', 'base_model.encoder.layer.4.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.19.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.5.output.LayerNorm.bias', 'base_model.encoder.layer.11.attention.self.query.weight', 'base_model.encoder.layer.18.output.dense.bias', 'base_model.encoder.layer.6.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.9.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.7.attention.self.query.bias', 'base_model.encoder.layer.16.output.LayerNorm.bias', 'base_model.encoder.layer.17.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.7.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.9.output.dense.bias', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.20.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.21.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.7.intermediate.dense.bias', 'base_model.encoder.layer.9.attention.self.key.bias', 'base_model.encoder.layer.19.output.LayerNorm.bias', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.8.output.LayerNorm.bias', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.13.attention.self.key.weight', 'base_model.encoder.layer.1.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.17.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.15.output.LayerNorm.bias', 'base_model.encoder.layer.20.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.21.attention.self.key.bias', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.2.attention.output.dense.weight', 'base_model.encoder.layer.13.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.0.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.10.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.13.attention.self.query.weight', 'base_model.encoder.layer.7.attention.output.dense.weight', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.8.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.7.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.19.intermediate.dense.bias', 'base_model.encoder.layer.1.intermediate.dense.weight', 'base_model.encoder.layer.8.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.11.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.4.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.5.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.18.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.11.output.dense.weight', 'base_model.encoder.layer.22.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.23.attention.self.query.bias', 'base_model.encoder.layer.1.attention.self.key.bias', 'base_model.encoder.layer.20.attention.self.query.bias', 'base_model.encoder.layer.7.attention.output.LayerNorm.bias', 'base_model.encoder.layer.7.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.2.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.8.attention.output.dense.bias', 'base_model.encoder.layer.16.intermediate.dense.bias', 'base_model.encoder.layer.7.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.15.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.22.attention.output.dense.bias', 'base_model.encoder.layer.7.attention.output.dense.bias', 'base_model.encoder.layer.1.output.LayerNorm.bias', 'base_model.encoder.layer.5.attention.self.value.bias', 'base_model.encoder.layer.10.output.dense.bias', 'base_model.encoder.layer.9.attention.output.dense.bias', 'base_model.encoder.layer.12.intermediate.dense.bias', 'base_model.encoder.layer.5.output.LayerNorm.weight', 'base_model.encoder.layer.7.output.LayerNorm.weight', 'base_model.encoder.layer.10.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.3.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.2.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.12.output.LayerNorm.weight', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.23.attention.output.dense.weight', 'base_model.encoder.layer.10.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.1.output.adapters.es.adapter_up.weight', 'base_model.embeddings.position_ids', 'base_model.encoder.layer.20.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.10.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.17.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.2.intermediate.dense.bias', 'base_model.encoder.layer.13.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.23.attention.self.value.weight', 'base_model.encoder.layer.9.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.21.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.5.intermediate.dense.bias', 'base_model.encoder.layer.6.attention.self.query.bias', 'base_model.encoder.layer.8.output.dense.bias', 'base_model.encoder.layer.12.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.4.intermediate.dense.bias', 'base_model.encoder.layer.2.output.dense.weight', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.0.intermediate.dense.weight', 'base_model.encoder.layer.3.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.16.output.dense.weight', 'base_model.encoder.layer.15.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.3.attention.output.LayerNorm.bias', 'base_model.encoder.layer.0.intermediate.dense.bias', 'base_model.encoder.layer.0.output.LayerNorm.bias', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.14.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.11.attention.self.query.bias', 'base_model.encoder.layer.11.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.11.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.16.attention.self.query.bias', 'base_model.encoder.layer.18.attention.self.query.bias', 'base_model.encoder.layer.21.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.23.output.LayerNorm.weight', 'base_model.encoder.layer.3.intermediate.dense.bias', 'base_model.encoder.layer.0.output.LayerNorm.weight', 'base_model.encoder.layer.1.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.8.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.18.output.LayerNorm.bias', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.22.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.18.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.18.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.0.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.18.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.5.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.15.attention.output.dense.bias', 'base_model.encoder.layer.6.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.18.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.20.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.17.output.dense.bias', 'base_model.encoder.layer.15.attention.self.query.weight', 'base_model.encoder.layer.9.attention.self.query.bias', 'base_model.encoder.layer.18.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.8.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.9.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.21.output.LayerNorm.bias', 'base_model.encoder.layer.18.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.1.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.2.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.14.output.LayerNorm.bias', 'base_model.encoder.layer.1.attention.output.dense.weight', 'base_model.encoder.layer.1.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.0.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.2.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.4.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.9.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.0.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.0.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.16.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.17.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.17.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.20.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.7.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.14.attention.self.query.bias', 'base_model.encoder.layer.22.attention.output.LayerNorm.weight', 'base_model.encoder.layer.13.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.19.attention.self.query.weight', 'base_model.encoder.layer.13.attention.self.query.bias', 'base_model.encoder.layer.15.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.0.attention.output.LayerNorm.weight', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.2.attention.self.key.weight', 'base_model.encoder.layer.13.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.14.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.16.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.15.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.2.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.9.output.LayerNorm.bias', 'base_model.encoder.layer.4.attention.self.key.weight', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.16.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.3.output.LayerNorm.weight', 'base_model.encoder.layer.0.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.5.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.6.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.10.attention.self.value.bias', 'base_model.encoder.layer.11.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.13.attention.self.value.bias', 'base_model.encoder.layer.10.attention.self.value.weight', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.14.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.19.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.21.output.LayerNorm.weight', 'base_model.encoder.layer.17.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.13.output.dense.weight', 'base_model.encoder.layer.14.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.8.attention.output.LayerNorm.weight', 'base_model.encoder.layer.15.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.21.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.2.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.22.output.LayerNorm.weight', 'base_model.encoder.layer.20.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.4.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.4.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.15.attention.output.dense.weight', 'base_model.encoder.layer.9.intermediate.dense.weight', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.13.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.23.attention.output.LayerNorm.weight', 'base_model.encoder.layer.22.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.10.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.11.output.LayerNorm.weight', 'base_model.encoder.layer.10.attention.output.dense.weight', 'base_model.encoder.layer.8.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.1.attention.self.key.weight', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.12.attention.output.LayerNorm.bias', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.20.intermediate.dense.bias', 'base_model.encoder.layer.12.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.16.attention.output.LayerNorm.bias', 'base_model.encoder.layer.22.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.12.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.22.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.11.attention.output.LayerNorm.bias', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.12.output.dense.weight', 'base_model.encoder.layer.3.attention.self.query.bias', 'base_model.encoder.layer.20.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.8.output.dense.weight', 'base_model.encoder.layer.19.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.15.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.12.attention.self.query.weight', 'base_model.encoder.layer.9.output.LayerNorm.weight', 'base_model.encoder.layer.0.attention.output.dense.weight', 'base_model.encoder.layer.11.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.16.intermediate.dense.weight', 'base_model.encoder.layer.7.attention.self.value.bias', 'base_model.encoder.layer.14.attention.self.query.weight', 'qa_outputs.weight', 'base_model.encoder.layer.2.intermediate.dense.weight', 'base_model.encoder.layer.15.attention.self.value.weight', 'base_model.encoder.layer.4.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.9.attention.output.LayerNorm.bias', 'base_model.encoder.layer.3.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.10.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.8.attention.self.value.weight', 'base_model.encoder.layer.3.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.10.attention.output.LayerNorm.weight', 'base_model.encoder.layer.23.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.15.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.5.intermediate.dense.weight', 'base_model.encoder.layer.18.attention.self.value.weight', 'base_model.encoder.layer.8.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.1.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.4.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.21.attention.self.key.weight', 'base_model.encoder.layer.5.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.22.output.dense.bias', 'base_model.encoder.layer.7.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.15.attention.self.key.weight', 'base_model.encoder.layer.13.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.13.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.3.attention.self.key.weight', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.5.attention.self.query.weight', 'base_model.encoder.layer.12.intermediate.dense.weight', 'base_model.encoder.layer.14.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.17.attention.output.LayerNorm.weight', 'base_model.encoder.layer.0.attention.self.key.bias', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.17.attention.output.dense.bias', 'base_model.encoder.layer.1.attention.self.query.bias', 'base_model.encoder.layer.5.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.18.attention.self.query.weight', 'base_model.encoder.layer.18.attention.output.dense.bias', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.13.output.LayerNorm.weight', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.embeddings.word_embeddings.weight', 'base_model.encoder.layer.22.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.19.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.17.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.19.output.dense.weight', 'base_model.encoder.layer.21.attention.self.query.bias', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.21.attention.self.value.bias', 'base_model.encoder.layer.18.attention.output.dense.weight', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.10.output.LayerNorm.bias', 'base_model.encoder.layer.5.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.15.attention.self.key.bias', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.7.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.0.attention.output.LayerNorm.bias', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.4.intermediate.dense.weight', 'base_model.encoder.layer.15.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.17.output.LayerNorm.weight', 'base_model.encoder.layer.14.output.adapters.es.adapter_down.0.bias', 'base_model.pooler.dense.bias', 'base_model.encoder.layer.21.attention.output.dense.bias', 'base_model.encoder.layer.11.attention.self.value.bias', 'base_model.encoder.layer.1.attention.self.value.weight', 'base_model.encoder.layer.14.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.23.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.17.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.2.attention.output.LayerNorm.weight', 'base_model.encoder.layer.19.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.23.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.15.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.9.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.10.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.23.attention.self.key.weight', 'base_model.encoder.layer.11.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.16.attention.self.value.bias', 'base_model.encoder.layer.19.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.17.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.23.attention.output.LayerNorm.bias', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.14.attention.output.LayerNorm.bias', 'base_model.encoder.layer.6.output.dense.weight', 'base_model.encoder.layer.19.attention.output.LayerNorm.weight', 'base_model.encoder.layer.17.intermediate.dense.weight', 'base_model.encoder.layer.18.intermediate.dense.bias', 'base_model.encoder.layer.22.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.11.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.5.output.dense.bias', 'base_model.encoder.layer.21.output.dense.bias', 'base_model.encoder.layer.6.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.3.attention.output.dense.weight', 'base_model.encoder.layer.18.output.LayerNorm.weight', 'base_model.encoder.layer.3.attention.self.query.weight', 'base_model.encoder.layer.16.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.17.attention.self.value.weight', 'base_model.encoder.layer.15.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.20.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.1.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.11.output.dense.bias', 'base_model.encoder.layer.21.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.19.attention.self.key.weight', 'base_model.encoder.layer.15.intermediate.dense.weight', 'base_model.encoder.layer.4.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.10.intermediate.dense.bias', 'base_model.encoder.layer.20.attention.output.dense.bias', 'base_model.encoder.layer.17.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.1.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.11.attention.self.key.bias', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.21.attention.self.value.weight', 'base_model.encoder.layer.10.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.23.attention.self.key.bias', 'base_model.encoder.layer.7.intermediate.dense.weight', 'base_model.encoder.layer.17.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.23.output.dense.weight', 'base_model.encoder.layer.1.attention.output.LayerNorm.weight', 'base_model.encoder.layer.13.attention.output.dense.weight', 'base_model.encoder.layer.7.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.1.intermediate.dense.bias', 'base_model.encoder.layer.12.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.12.attention.self.key.bias', 'base_model.encoder.layer.3.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.8.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.22.intermediate.dense.weight', 'base_model.encoder.layer.6.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.19.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.17.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.20.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.10.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.7.attention.self.key.weight', 'base_model.encoder.layer.23.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.23.attention.output.dense.bias', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.4.output.dense.bias', 'base_model.encoder.layer.6.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.16.attention.self.value.weight', 'base_model.encoder.layer.15.attention.self.query.bias', 'base_model.encoder.layer.5.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.11.output.LayerNorm.bias', 'base_model.encoder.layer.21.attention.output.LayerNorm.bias', 'base_model.encoder.layer.16.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.12.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.5.attention.output.LayerNorm.bias', 'base_model.encoder.layer.2.output.dense.bias', 'base_model.encoder.layer.8.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.21.attention.output.dense.weight', 'base_model.encoder.layer.2.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.12.attention.output.dense.weight', 'base_model.encoder.layer.11.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.6.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.10.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.2.attention.output.LayerNorm.bias', 'base_model.encoder.layer.13.output.dense.bias', 'base_model.encoder.layer.0.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.19.output.dense.bias', 'base_model.encoder.layer.6.attention.self.query.weight', 'base_model.encoder.layer.3.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.14.attention.output.LayerNorm.weight', 'base_model.encoder.layer.18.attention.self.value.bias', 'base_model.encoder.layer.21.intermediate.dense.weight', 'base_model.encoder.layer.14.output.adapters.ts.adapter_up.weight', 'qa_outputs.bias', 'base_model.encoder.layer.15.output.dense.weight', 'base_model.encoder.layer.6.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.0.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.5.attention.output.dense.bias', 'base_model.encoder.layer.18.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.3.attention.output.LayerNorm.weight', 'base_model.encoder.layer.22.attention.output.dense.weight', 'base_model.encoder.layer.21.attention.self.query.weight', 'base_model.encoder.layer.10.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.8.attention.self.value.bias', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.9.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.4.attention.self.query.weight', 'base_model.encoder.layer.3.output.LayerNorm.bias', 'base_model.encoder.layer.10.attention.self.key.bias', 'base_model.encoder.layer.15.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.19.attention.output.dense.bias', 'base_model.encoder.layer.23.intermediate.dense.bias', 'base_model.encoder.layer.4.attention.output.LayerNorm.weight', 'base_model.encoder.layer.20.attention.self.value.bias', 'base_model.encoder.layer.4.output.dense.weight', 'base_model.encoder.layer.22.attention.self.value.weight', 'base_model.encoder.layer.3.intermediate.dense.weight', 'base_model.encoder.layer.22.attention.self.key.bias', 'base_model.encoder.layer.10.output.dense.weight', 'base_model.encoder.layer.2.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.20.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.0.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.0.attention.self.query.bias', 'base_model.encoder.layer.3.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.9.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.15.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.13.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.7.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.11.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.5.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.6.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.13.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.6.attention.output.dense.weight', 'base_model.encoder.layer.5.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.14.intermediate.dense.bias', 'base_model.encoder.layer.17.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.3.attention.output.dense.bias', 'base_model.encoder.layer.16.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.17.attention.self.key.weight', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.1.output.dense.weight', 'base_model.encoder.layer.7.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.9.attention.self.value.bias', 'base_model.encoder.layer.20.attention.self.value.weight', 'base_model.encoder.layer.17.output.adapters.ep.adapter_up.weight']
- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of XLMRobertaModel were not initialized from the model checkpoint at /cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//squad/xlm-KG_LR4e-5_EPOCH2.0_maxlen384_batchsize4_gradacc8 and are newly initialized: ['encoder.layer.7.output.LayerNorm.bias', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.7.attention.self.value.bias', 'encoder.layer.11.attention.self.query.weight', 'encoder.layer.23.attention.self.value.bias', 'encoder.layer.16.output.LayerNorm.weight', 'encoder.layer.10.output.LayerNorm.weight', 'encoder.layer.6.attention.output.LayerNorm.weight', 'encoder.layer.12.output.LayerNorm.bias', 'encoder.layer.13.intermediate.dense.weight', 'encoder.layer.10.attention.self.query.bias', 'embeddings.LayerNorm.weight', 'encoder.layer.14.output.dense.weight', 'encoder.layer.8.attention.self.key.weight', 'encoder.layer.4.output.dense.bias', 'encoder.layer.11.output.dense.bias', 'encoder.layer.0.output.dense.weight', 'encoder.layer.22.attention.output.dense.weight', 'encoder.layer.21.intermediate.dense.weight', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.14.attention.output.LayerNorm.bias', 'encoder.layer.3.attention.self.query.bias', 'encoder.layer.12.attention.output.LayerNorm.bias', 'encoder.layer.22.attention.output.LayerNorm.weight', 'encoder.layer.23.attention.self.value.weight', 'encoder.layer.22.intermediate.dense.weight', 'encoder.layer.20.attention.self.value.bias', 'encoder.layer.19.output.dense.bias', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.7.intermediate.dense.bias', 'encoder.layer.13.output.LayerNorm.bias', 'encoder.layer.16.attention.output.LayerNorm.weight', 'encoder.layer.20.attention.self.value.weight', 'encoder.layer.2.output.dense.bias', 'encoder.layer.19.attention.self.query.bias', 'encoder.layer.12.attention.self.query.weight', 'encoder.layer.8.attention.self.query.weight', 'encoder.layer.20.intermediate.dense.bias', 'encoder.layer.18.intermediate.dense.bias', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.15.intermediate.dense.bias', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.17.attention.self.query.bias', 'encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.layer.13.attention.self.query.weight', 'encoder.layer.12.output.dense.weight', 'encoder.layer.22.output.dense.weight', 'encoder.layer.13.attention.output.dense.weight', 'encoder.layer.2.attention.output.LayerNorm.weight', 'encoder.layer.4.attention.self.query.weight', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.16.attention.self.key.bias', 'encoder.layer.9.attention.output.dense.weight', 'encoder.layer.20.attention.output.dense.weight', 'encoder.layer.19.attention.self.key.bias', 'encoder.layer.5.attention.output.LayerNorm.weight', 'encoder.layer.0.attention.self.value.weight', 'encoder.layer.23.output.LayerNorm.bias', 'encoder.layer.16.intermediate.dense.weight', 'encoder.layer.11.attention.self.value.bias', 'encoder.layer.10.output.dense.bias', 'encoder.layer.10.attention.self.query.weight', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.6.attention.self.query.bias', 'encoder.layer.17.attention.output.dense.weight', 'encoder.layer.19.attention.output.LayerNorm.weight', 'encoder.layer.22.attention.self.query.weight', 'encoder.layer.3.attention.self.query.weight', 'encoder.layer.23.attention.self.query.bias', 'encoder.layer.2.attention.self.value.bias', 'encoder.layer.8.attention.output.dense.weight', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.21.output.LayerNorm.bias', 'encoder.layer.6.attention.self.key.weight', 'encoder.layer.9.attention.output.LayerNorm.bias', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.5.output.LayerNorm.bias', 'encoder.layer.13.attention.output.dense.bias', 'encoder.layer.3.output.dense.weight', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.19.attention.output.dense.weight', 'encoder.layer.14.output.dense.bias', 'encoder.layer.16.attention.self.value.bias', 'encoder.layer.21.output.LayerNorm.weight', 'encoder.layer.20.attention.self.key.bias', 'encoder.layer.12.attention.self.query.bias', 'encoder.layer.12.attention.self.value.bias', 'encoder.layer.16.output.LayerNorm.bias', 'encoder.layer.5.attention.self.query.weight', 'encoder.layer.21.attention.output.dense.weight', 'encoder.layer.2.attention.output.dense.weight', 'encoder.layer.16.output.dense.bias', 'encoder.layer.21.attention.self.key.weight', 'encoder.layer.22.attention.self.key.bias', 'encoder.layer.11.attention.self.key.bias', 'pooler.dense.bias', 'encoder.layer.18.output.LayerNorm.bias', 'encoder.layer.2.attention.self.query.weight', 'encoder.layer.21.attention.self.query.bias', 'encoder.layer.13.attention.output.LayerNorm.bias', 'encoder.layer.20.intermediate.dense.weight', 'encoder.layer.21.attention.output.LayerNorm.bias', 'encoder.layer.15.output.dense.bias', 'encoder.layer.21.output.dense.weight', 'encoder.layer.18.output.LayerNorm.weight', 'encoder.layer.12.attention.output.dense.weight', 'encoder.layer.14.attention.self.key.bias', 'encoder.layer.18.attention.self.query.bias', 'encoder.layer.22.output.LayerNorm.weight', 'encoder.layer.3.attention.self.key.bias', 'encoder.layer.17.attention.output.LayerNorm.bias', 'encoder.layer.3.attention.self.key.weight', 'encoder.layer.4.attention.output.dense.bias', 'encoder.layer.21.attention.self.key.bias', 'encoder.layer.20.output.dense.weight', 'encoder.layer.17.attention.self.query.weight', 'encoder.layer.12.intermediate.dense.weight', 'pooler.dense.weight', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.10.output.LayerNorm.bias', 'encoder.layer.0.attention.self.query.bias', 'encoder.layer.15.attention.self.value.weight', 'encoder.layer.18.attention.self.value.bias', 'encoder.layer.3.attention.self.value.bias', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.8.attention.self.value.weight', 'embeddings.word_embeddings.weight', 'encoder.layer.6.attention.self.value.bias', 'encoder.layer.23.intermediate.dense.weight', 'encoder.layer.2.attention.self.key.weight', 'encoder.layer.23.attention.output.LayerNorm.bias', 'encoder.layer.17.attention.self.key.bias', 'encoder.layer.23.attention.self.key.weight', 'encoder.layer.1.attention.self.key.bias', 'encoder.layer.22.attention.self.query.bias', 'encoder.layer.15.attention.self.query.weight', 'encoder.layer.19.intermediate.dense.bias', 'encoder.layer.7.attention.output.LayerNorm.bias', 'encoder.layer.17.attention.self.value.weight', 'encoder.layer.18.attention.output.LayerNorm.weight', 'encoder.layer.10.attention.self.key.weight', 'encoder.layer.7.attention.self.value.weight', 'encoder.layer.21.attention.self.value.weight', 'encoder.layer.8.output.LayerNorm.bias', 'encoder.layer.15.attention.self.key.weight', 'encoder.layer.6.attention.self.query.weight', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.11.attention.self.key.weight', 'encoder.layer.8.attention.self.query.bias', 'encoder.layer.20.attention.self.query.bias', 'encoder.layer.5.attention.self.query.bias', 'encoder.layer.19.output.LayerNorm.bias', 'encoder.layer.1.attention.output.dense.bias', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.7.attention.output.dense.bias', 'encoder.layer.22.attention.self.key.weight', 'encoder.layer.6.output.dense.bias', 'encoder.layer.22.attention.self.value.bias', 'encoder.layer.14.attention.self.key.weight', 'encoder.layer.16.attention.self.value.weight', 'encoder.layer.14.attention.self.value.weight', 'encoder.layer.22.output.dense.bias', 'encoder.layer.7.output.dense.bias', 'encoder.layer.18.attention.output.LayerNorm.bias', 'encoder.layer.1.attention.self.query.bias', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.4.attention.output.dense.weight', 'encoder.layer.13.output.LayerNorm.weight', 'encoder.layer.14.attention.self.query.bias', 'encoder.layer.16.output.dense.weight', 'encoder.layer.22.intermediate.dense.bias', 'encoder.layer.4.attention.self.key.bias', 'encoder.layer.17.output.LayerNorm.bias', 'encoder.layer.1.attention.output.LayerNorm.weight', 'encoder.layer.8.output.dense.weight', 'encoder.layer.13.output.dense.bias', 'encoder.layer.8.attention.self.key.bias', 'encoder.layer.10.attention.output.dense.bias', 'encoder.layer.17.attention.self.value.bias', 'encoder.layer.11.output.LayerNorm.bias', 'encoder.layer.5.attention.self.key.bias', 'encoder.layer.17.attention.self.key.weight', 'encoder.layer.14.attention.output.LayerNorm.weight', 'encoder.layer.0.output.dense.bias', 'encoder.layer.21.intermediate.dense.bias', 'encoder.layer.14.attention.output.dense.weight', 'encoder.layer.5.attention.self.value.bias', 'encoder.layer.0.attention.self.query.weight', 'encoder.layer.2.attention.output.LayerNorm.bias', 'encoder.layer.3.output.dense.bias', 'encoder.layer.7.attention.self.query.weight', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.8.attention.output.LayerNorm.weight', 'encoder.layer.9.attention.output.dense.bias', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.16.attention.self.query.bias', 'embeddings.LayerNorm.bias', 'encoder.layer.12.output.LayerNorm.weight', 'encoder.layer.2.output.dense.weight', 'encoder.layer.5.attention.output.dense.weight', 'encoder.layer.12.attention.output.dense.bias', 'encoder.layer.18.attention.self.query.weight', 'encoder.layer.22.attention.output.LayerNorm.bias', 'encoder.layer.14.attention.self.value.bias', 'encoder.layer.8.attention.self.value.bias', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.16.attention.output.LayerNorm.bias', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.15.attention.output.LayerNorm.bias', 'encoder.layer.11.output.dense.weight', 'encoder.layer.15.attention.self.key.bias', 'encoder.layer.19.attention.output.dense.bias', 'encoder.layer.7.attention.output.dense.weight', 'encoder.layer.16.attention.self.key.weight', 'encoder.layer.2.attention.self.query.bias', 'encoder.layer.13.intermediate.dense.bias', 'encoder.layer.14.intermediate.dense.bias', 'encoder.layer.23.output.dense.bias', 'encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.layer.9.attention.self.value.bias', 'encoder.layer.9.attention.self.query.bias', 'encoder.layer.15.intermediate.dense.weight', 'encoder.layer.6.output.LayerNorm.bias', 'encoder.layer.14.output.LayerNorm.bias', 'encoder.layer.11.attention.output.dense.weight', 'encoder.layer.16.attention.output.dense.bias', 'encoder.layer.7.output.LayerNorm.weight', 'encoder.layer.1.attention.self.value.bias', 'encoder.layer.10.output.dense.weight', 'encoder.layer.0.attention.self.value.bias', 'encoder.layer.9.attention.self.value.weight', 'encoder.layer.3.attention.output.dense.weight', 'encoder.layer.7.output.dense.weight', 'encoder.layer.9.output.dense.weight', 'encoder.layer.11.attention.self.value.weight', 'encoder.layer.18.attention.self.key.weight', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.18.output.dense.weight', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.15.attention.output.dense.bias', 'encoder.layer.19.attention.self.value.bias', 'encoder.layer.6.attention.output.dense.bias', 'encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.layer.23.attention.self.key.bias', 'encoder.layer.9.output.LayerNorm.weight', 'encoder.layer.15.output.LayerNorm.weight', 'encoder.layer.8.attention.output.dense.bias', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.7.attention.self.key.bias', 'encoder.layer.17.intermediate.dense.weight', 'encoder.layer.9.attention.self.key.weight', 'encoder.layer.15.output.LayerNorm.bias', 'encoder.layer.11.attention.self.query.bias', 'encoder.layer.17.attention.output.LayerNorm.weight', 'encoder.layer.18.intermediate.dense.weight', 'encoder.layer.20.output.dense.bias', 'encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.layer.19.output.LayerNorm.weight', 'encoder.layer.17.output.dense.bias', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.17.attention.output.dense.bias', 'encoder.layer.2.attention.output.dense.bias', 'encoder.layer.4.output.dense.weight', 'encoder.layer.9.attention.self.query.weight', 'encoder.layer.20.attention.output.LayerNorm.bias', 'encoder.layer.0.attention.output.dense.bias', 'encoder.layer.12.intermediate.dense.bias', 'encoder.layer.19.attention.output.LayerNorm.bias', 'encoder.layer.23.attention.output.dense.weight', 'encoder.layer.18.attention.output.dense.weight', 'encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.layer.10.attention.self.key.bias', 'encoder.layer.12.attention.self.key.weight', 'encoder.layer.1.attention.self.key.weight', 'encoder.layer.7.attention.self.query.bias', 'encoder.layer.14.attention.output.dense.bias', 'encoder.layer.8.attention.output.LayerNorm.bias', 'encoder.layer.2.attention.self.value.weight', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.21.output.dense.bias', 'encoder.layer.1.attention.self.value.weight', 'encoder.layer.13.attention.output.LayerNorm.weight', 'encoder.layer.5.attention.self.key.weight', 'encoder.layer.6.attention.self.value.weight', 'encoder.layer.23.output.LayerNorm.weight', 'encoder.layer.15.output.dense.weight', 'encoder.layer.0.attention.self.key.bias', 'encoder.layer.20.output.LayerNorm.bias', 'encoder.layer.16.intermediate.dense.bias', 'encoder.layer.18.attention.self.key.bias', 'encoder.layer.12.attention.self.value.weight', 'embeddings.position_embeddings.weight', 'encoder.layer.23.attention.self.query.weight', 'encoder.layer.9.attention.self.key.bias', 'encoder.layer.16.attention.self.query.weight', 'encoder.layer.11.output.LayerNorm.weight', 'encoder.layer.19.output.dense.weight', 'encoder.layer.10.attention.output.LayerNorm.weight', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.5.attention.self.value.weight', 'encoder.layer.9.attention.output.LayerNorm.weight', 'encoder.layer.13.attention.self.key.weight', 'encoder.layer.9.output.dense.bias', 'encoder.layer.3.attention.output.dense.bias', 'encoder.layer.18.output.dense.bias', 'encoder.layer.19.intermediate.dense.weight', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.1.output.dense.weight', 'encoder.layer.22.output.LayerNorm.bias', 'encoder.layer.0.attention.output.LayerNorm.weight', 'encoder.layer.4.attention.self.query.bias', 'encoder.layer.6.attention.output.LayerNorm.bias', 'encoder.layer.4.attention.self.key.weight', 'encoder.layer.19.attention.self.query.weight', 'encoder.layer.1.output.dense.bias', 'encoder.layer.12.attention.output.LayerNorm.weight', 'encoder.layer.8.output.LayerNorm.weight', 'encoder.layer.22.attention.output.dense.bias', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.10.attention.output.dense.weight', 'encoder.layer.0.attention.self.key.weight', 'encoder.layer.15.attention.output.dense.weight', 'encoder.layer.7.attention.self.key.weight', 'encoder.layer.20.attention.output.LayerNorm.weight', 'encoder.layer.10.intermediate.dense.weight', 'encoder.layer.14.attention.self.query.weight', 'encoder.layer.21.attention.self.query.weight', 'encoder.layer.16.attention.output.dense.weight', 'encoder.layer.2.attention.self.key.bias', 'encoder.layer.18.attention.self.value.weight', 'encoder.layer.17.intermediate.dense.bias', 'encoder.layer.14.output.LayerNorm.weight', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.15.attention.self.value.bias', 'encoder.layer.4.attention.self.value.bias', 'encoder.layer.23.intermediate.dense.bias', 'encoder.layer.9.output.LayerNorm.bias', 'encoder.layer.5.output.dense.weight', 'encoder.layer.12.output.dense.bias', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.4.attention.output.LayerNorm.bias', 'encoder.layer.15.attention.output.LayerNorm.weight', 'encoder.layer.10.attention.self.value.bias', 'encoder.layer.20.attention.self.key.weight', 'encoder.layer.0.attention.output.dense.weight', 'encoder.layer.11.attention.output.LayerNorm.weight', 'embeddings.token_type_embeddings.weight', 'encoder.layer.11.attention.output.dense.bias', 'encoder.layer.14.intermediate.dense.weight', 'encoder.layer.10.attention.output.LayerNorm.bias', 'encoder.layer.19.attention.self.value.weight', 'encoder.layer.12.attention.self.key.bias', 'encoder.layer.21.attention.self.value.bias', 'encoder.layer.23.output.dense.weight', 'encoder.layer.19.attention.self.key.weight', 'encoder.layer.3.attention.self.value.weight', 'encoder.layer.6.attention.output.dense.weight', 'encoder.layer.15.attention.self.query.bias', 'encoder.layer.4.attention.self.value.weight', 'encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.13.output.dense.weight', 'encoder.layer.21.attention.output.dense.bias', 'encoder.layer.17.output.LayerNorm.weight', 'encoder.layer.1.attention.output.dense.weight', 'encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.layer.20.output.LayerNorm.weight', 'encoder.layer.22.attention.self.value.weight', 'encoder.layer.23.attention.output.LayerNorm.weight', 'encoder.layer.1.attention.self.query.weight', 'encoder.layer.13.attention.self.key.bias', 'encoder.layer.21.attention.output.LayerNorm.weight', 'encoder.layer.23.attention.output.dense.bias', 'encoder.layer.6.output.dense.weight', 'encoder.layer.20.attention.self.query.weight', 'encoder.layer.7.attention.output.LayerNorm.weight', 'encoder.layer.6.attention.self.key.bias', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.18.attention.output.dense.bias', 'encoder.layer.13.attention.self.query.bias', 'encoder.layer.4.attention.output.LayerNorm.weight', 'encoder.layer.13.attention.self.value.bias', 'encoder.layer.5.attention.output.dense.bias', 'encoder.layer.13.attention.self.value.weight', 'encoder.layer.10.attention.self.value.weight', 'encoder.layer.20.attention.output.dense.bias', 'encoder.layer.17.output.dense.weight', 'encoder.layer.8.output.dense.bias', 'encoder.layer.5.output.dense.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Overwriting existing adapter 'ep'.
Overwriting existing adapter 'tp'.
Overwriting existing adapter 'es'.
Overwriting existing adapter 'ts'.
Overwriting existing adapter fusion module 'ep,tp,es,ts'
05/09/2022 20:02:20 - INFO - __main__ -   lang2id = None
05/09/2022 20:02:23 - INFO - __main__ -   Training/evaluation parameters Namespace(adam_epsilon=1e-08, cache_dir='', config_name='', data_dir=None, device=device(type='cuda'), do_eval=True, do_lower_case=False, do_train=False, doc_stride=128, eval_all_checkpoints=False, eval_lang='tr', evaluate_during_training=False, fp16=False, fp16_opt_level='O1', gradient_accumulation_steps=1, learning_rate=5e-05, local_rank=-1, logging_steps=50, max_answer_length=30, max_grad_norm=1.0, max_query_length=64, max_seq_length=384, max_steps=-1, model_name='xlm-KG', model_name_or_path='/cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//squad/xlm-KG_LR4e-5_EPOCH2.0_maxlen384_batchsize4_gradacc8', model_type='xlm', modelkg_dir='/cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/adapter/xlmr_adapter', n_best_size=20, n_gpu=1, no_cuda=False, null_score_diff_threshold=0.0, num_train_epochs=3.0, output_dir='/cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//squad/xlm-KG_LR4e-5_EPOCH2.0_maxlen384_batchsize4_gradacc8/predictions/xquad/', overwrite_cache=False, overwrite_output_dir=False, per_gpu_eval_batch_size=8, per_gpu_train_batch_size=8, predict_file='/cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/download//xquad//xquad.tr.json', save_steps=50, seed=42, server_ip='', server_port='', threads=1, tokenizer_name='', train_file=None, train_lang='en', verbose_logging=False, version_2_with_negative=False, warmup_steps=0, weight_decay=0.0)
05/09/2022 20:02:23 - INFO - __main__ -   Loading checkpoint /cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//squad/xlm-KG_LR4e-5_EPOCH2.0_maxlen384_batchsize4_gradacc8 for evaluation
05/09/2022 20:02:23 - INFO - __main__ -   Evaluate the following checkpoints: ['/cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//squad/xlm-KG_LR4e-5_EPOCH2.0_maxlen384_batchsize4_gradacc8']
Some weights of the model checkpoint at /cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//squad/xlm-KG_LR4e-5_EPOCH2.0_maxlen384_batchsize4_gradacc8 were not used when initializing XLMRobertaModel: ['base_model.encoder.layer.12.output.dense.bias', 'base_model.encoder.layer.19.attention.self.value.weight', 'base_model.encoder.layer.3.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.0.attention.self.key.weight', 'base_model.encoder.layer.2.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.8.attention.self.query.weight', 'base_model.encoder.layer.11.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.9.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.4.output.LayerNorm.weight', 'base_model.encoder.layer.7.output.LayerNorm.bias', 'base_model.encoder.layer.9.attention.self.query.weight', 'base_model.encoder.layer.12.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.3.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.11.attention.self.value.weight', 'base_model.encoder.layer.10.output.LayerNorm.weight', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.17.output.LayerNorm.bias', 'base_model.encoder.layer.10.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.0.output.dense.bias', 'base_model.encoder.layer.22.attention.self.key.weight', 'base_model.encoder.layer.16.attention.output.dense.bias', 'base_model.encoder.layer.18.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.14.output.dense.weight', 'base_model.encoder.layer.2.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.10.attention.output.LayerNorm.bias', 'base_model.encoder.layer.19.output.LayerNorm.weight', 'base_model.encoder.layer.20.attention.output.LayerNorm.bias', 'base_model.encoder.layer.3.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.23.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.3.output.dense.weight', 'base_model.encoder.layer.19.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.20.attention.output.LayerNorm.weight', 'base_model.encoder.layer.21.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.23.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.14.output.LayerNorm.weight', 'base_model.encoder.layer.8.intermediate.dense.weight', 'base_model.encoder.layer.17.attention.self.query.bias', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.12.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.22.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.2.attention.self.value.bias', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.6.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.3.output.adapters.ep.adapter_up.bias', 'base_model.embeddings.LayerNorm.bias', 'base_model.encoder.layer.4.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.8.output.LayerNorm.weight', 'base_model.encoder.layer.21.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.10.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.21.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.6.attention.output.dense.bias', 'base_model.encoder.layer.19.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.20.output.LayerNorm.bias', 'base_model.encoder.layer.22.attention.self.query.weight', 'base_model.encoder.layer.12.attention.self.value.weight', 'base_model.encoder.layer.2.attention.output.dense.bias', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.5.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.18.attention.self.key.weight', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.8.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.23.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.15.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.16.attention.output.LayerNorm.weight', 'base_model.encoder.layer.9.attention.self.key.weight', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.23.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.20.attention.self.query.weight', 'base_model.encoder.layer.22.output.dense.weight', 'base_model.encoder.layer.23.attention.self.value.bias', 'base_model.encoder.layer.4.attention.self.key.bias', 'base_model.encoder.layer.6.output.LayerNorm.weight', 'base_model.encoder.layer.0.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.19.intermediate.dense.weight', 'base_model.encoder.layer.13.output.LayerNorm.bias', 'base_model.encoder.layer.22.output.LayerNorm.bias', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.0.attention.self.value.weight', 'base_model.encoder.layer.10.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.12.attention.self.query.bias', 'base_model.encoder.layer.23.attention.self.query.weight', 'base_model.encoder.layer.10.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.12.attention.output.dense.bias', 'base_model.encoder.layer.10.intermediate.dense.weight', 'base_model.encoder.layer.20.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.4.attention.output.dense.weight', 'base_model.encoder.layer.8.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.21.intermediate.dense.bias', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.7.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.6.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.11.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.12.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.6.attention.self.key.weight', 'base_model.encoder.layer.14.output.dense.bias', 'base_model.encoder.layer.20.intermediate.dense.weight', 'base_model.encoder.layer.3.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.12.attention.self.key.weight', 'base_model.encoder.layer.9.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.0.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.5.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.18.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.5.attention.self.key.bias', 'base_model.encoder.layer.12.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.4.attention.self.query.bias', 'base_model.encoder.layer.15.output.LayerNorm.weight', 'base_model.encoder.layer.21.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.19.attention.output.LayerNorm.bias', 'base_model.encoder.layer.15.output.dense.bias', 'base_model.encoder.layer.5.attention.self.key.weight', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.6.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.18.attention.self.key.bias', 'base_model.encoder.layer.13.attention.output.LayerNorm.bias', 'base_model.encoder.layer.15.intermediate.dense.bias', 'base_model.encoder.layer.20.output.dense.bias', 'base_model.encoder.layer.22.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.22.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.22.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.3.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.1.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.20.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.1.attention.output.dense.bias', 'base_model.encoder.layer.19.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.3.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.13.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.14.attention.self.key.bias', 'base_model.encoder.layer.3.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.5.output.dense.weight', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.11.attention.output.dense.weight', 'base_model.encoder.layer.16.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.11.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.3.attention.self.key.bias', 'base_model.encoder.layer.16.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.12.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.1.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.6.intermediate.dense.weight', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.1.attention.self.query.weight', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.7.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.9.attention.output.dense.weight', 'base_model.encoder.layer.20.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.23.intermediate.dense.weight', 'base_model.encoder.layer.1.attention.self.value.bias', 'base_model.encoder.layer.14.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.16.attention.self.key.weight', 'base_model.encoder.layer.12.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.1.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.1.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.15.attention.self.value.bias', 'base_model.encoder.layer.7.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.1.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.16.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.3.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.21.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.4.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.17.attention.output.dense.weight', 'base_model.encoder.layer.8.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.13.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.7.attention.self.key.bias', 'base_model.encoder.layer.16.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.13.intermediate.dense.bias', 'base_model.encoder.layer.14.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.19.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.17.attention.self.value.bias', 'base_model.encoder.layer.4.attention.self.value.bias', 'base_model.encoder.layer.11.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.12.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.23.output.dense.bias', 'base_model.encoder.layer.16.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.16.output.dense.bias', 'base_model.encoder.layer.20.attention.self.key.bias', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.7.output.dense.bias', 'base_model.encoder.layer.11.attention.output.LayerNorm.weight', 'base_model.encoder.layer.2.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.15.attention.output.LayerNorm.bias', 'base_model.encoder.layer.14.attention.self.value.bias', 'base_model.encoder.layer.20.output.dense.weight', 'base_model.encoder.layer.16.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.20.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.5.attention.self.value.weight', 'base_model.encoder.layer.11.intermediate.dense.bias', 'base_model.encoder.layer.14.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.10.attention.output.dense.bias', 'base_model.encoder.layer.22.attention.self.query.bias', 'base_model.encoder.layer.22.intermediate.dense.bias', 'base_model.encoder.layer.4.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.21.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.5.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.7.attention.self.value.weight', 'base_model.embeddings.LayerNorm.weight', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.5.attention.self.query.bias', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.8.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.9.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.18.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.0.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.17.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.12.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.1.attention.output.LayerNorm.bias', 'base_model.encoder.layer.19.attention.self.value.bias', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.18.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.11.intermediate.dense.weight', 'base_model.encoder.layer.14.attention.output.dense.weight', 'base_model.encoder.layer.19.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.7.attention.output.LayerNorm.weight', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.20.attention.output.dense.weight', 'base_model.encoder.layer.0.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.7.output.dense.weight', 'base_model.encoder.layer.23.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.18.attention.output.LayerNorm.weight', 'base_model.encoder.layer.19.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.2.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.15.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.16.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.17.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.9.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.13.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.12.output.LayerNorm.bias', 'base_model.encoder.layer.16.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.4.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.15.attention.output.LayerNorm.weight', 'base_model.encoder.layer.23.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.8.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.16.attention.self.key.bias', 'base_model.encoder.layer.0.attention.self.value.bias', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.8.attention.output.LayerNorm.bias', 'base_model.encoder.layer.19.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.11.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.23.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.2.attention.self.query.bias', 'base_model.encoder.layer.20.attention.self.key.weight', 'base_model.encoder.layer.23.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.13.attention.output.dense.bias', 'base_model.encoder.layer.22.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.9.output.dense.weight', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.9.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.12.attention.self.value.bias', 'base_model.encoder.layer.3.output.dense.bias', 'base_model.encoder.layer.9.attention.output.LayerNorm.weight', 'base_model.encoder.layer.14.attention.output.dense.bias', 'base_model.encoder.layer.23.output.LayerNorm.bias', 'base_model.encoder.layer.0.attention.output.dense.bias', 'base_model.encoder.layer.18.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.6.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.23.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.13.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.1.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.16.attention.output.dense.weight', 'base_model.encoder.layer.13.attention.self.value.weight', 'base_model.encoder.layer.21.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.4.attention.output.dense.bias', 'base_model.encoder.layer.4.attention.output.LayerNorm.bias', 'base_model.embeddings.position_embeddings.weight', 'base_model.encoder.layer.11.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.12.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.20.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.10.attention.self.query.bias', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.19.attention.self.query.bias', 'base_model.encoder.layer.17.attention.self.key.bias', 'base_model.encoder.layer.11.attention.output.dense.bias', 'base_model.encoder.layer.4.attention.self.value.weight', 'base_model.encoder.layer.14.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.19.attention.output.dense.weight', 'base_model.encoder.layer.20.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.4.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.19.attention.self.key.bias', 'base_model.encoder.layer.8.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.18.output.dense.weight', 'base_model.encoder.layer.20.output.LayerNorm.weight', 'base_model.encoder.layer.2.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.18.attention.output.LayerNorm.bias', 'base_model.encoder.layer.12.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.1.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.6.output.LayerNorm.bias', 'base_model.encoder.layer.6.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.14.attention.self.key.weight', 'base_model.encoder.layer.6.attention.self.value.weight', 'base_model.encoder.layer.9.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.23.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.9.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.17.intermediate.dense.bias', 'base_model.encoder.layer.8.attention.self.query.bias', 'base_model.encoder.layer.5.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.2.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.0.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.2.attention.self.value.weight', 'base_model.encoder.layer.4.output.LayerNorm.bias', 'base_model.encoder.layer.6.attention.output.LayerNorm.weight', 'base_model.encoder.layer.19.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.22.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.1.output.dense.bias', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.8.attention.self.key.bias', 'base_model.encoder.layer.22.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.12.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.21.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.11.attention.self.key.weight', 'base_model.encoder.layer.7.attention.self.query.weight', 'base_model.encoder.layer.14.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.4.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.21.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.5.attention.output.LayerNorm.weight', 'base_model.encoder.layer.13.attention.output.LayerNorm.weight', 'base_model.encoder.layer.18.intermediate.dense.weight', 'base_model.encoder.layer.8.intermediate.dense.bias', 'base_model.encoder.layer.5.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.13.attention.self.key.bias', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.5.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.1.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.10.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.22.attention.output.LayerNorm.bias', 'base_model.encoder.layer.23.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.6.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.2.output.LayerNorm.bias', 'base_model.encoder.layer.19.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.22.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.6.intermediate.dense.bias', 'base_model.encoder.layer.4.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.2.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.15.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.9.intermediate.dense.bias', 'base_model.encoder.layer.4.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.16.output.LayerNorm.weight', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.0.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.6.output.dense.bias', 'base_model.encoder.layer.7.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.17.output.dense.weight', 'base_model.encoder.layer.17.attention.output.LayerNorm.bias', 'base_model.encoder.layer.18.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.6.attention.output.LayerNorm.bias', 'base_model.encoder.layer.10.attention.self.query.weight', 'base_model.encoder.layer.21.output.dense.weight', 'base_model.encoder.layer.3.attention.self.value.bias', 'base_model.encoder.layer.10.attention.self.key.weight', 'base_model.encoder.layer.14.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.21.attention.output.LayerNorm.weight', 'base_model.encoder.layer.22.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.11.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.0.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.13.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.12.attention.output.LayerNorm.weight', 'base_model.encoder.layer.9.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.2.output.LayerNorm.weight', 'base_model.encoder.layer.14.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.5.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.8.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.14.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.14.attention.self.value.weight', 'base_model.encoder.layer.21.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.8.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.22.attention.self.value.bias', 'base_model.encoder.layer.2.attention.self.key.bias', 'base_model.encoder.layer.9.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.1.output.LayerNorm.weight', 'base_model.encoder.layer.0.output.dense.weight', 'base_model.pooler.dense.weight', 'base_model.embeddings.token_type_embeddings.weight', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.16.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.7.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.18.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.9.attention.self.value.weight', 'base_model.encoder.layer.2.attention.self.query.weight', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.7.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.16.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.16.attention.self.query.weight', 'base_model.encoder.layer.14.intermediate.dense.weight', 'base_model.encoder.layer.13.intermediate.dense.weight', 'base_model.encoder.layer.6.attention.self.key.bias', 'base_model.encoder.layer.13.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.21.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.15.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.3.attention.self.value.weight', 'base_model.encoder.layer.17.attention.self.query.weight', 'base_model.encoder.layer.13.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.5.attention.output.dense.weight', 'base_model.encoder.layer.6.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.23.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.18.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.2.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.8.attention.self.key.weight', 'base_model.encoder.layer.0.attention.self.query.weight', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.6.attention.self.value.bias', 'base_model.encoder.layer.8.attention.output.dense.weight', 'base_model.encoder.layer.4.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.19.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.5.output.LayerNorm.bias', 'base_model.encoder.layer.11.attention.self.query.weight', 'base_model.encoder.layer.18.output.dense.bias', 'base_model.encoder.layer.6.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.9.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.7.attention.self.query.bias', 'base_model.encoder.layer.16.output.LayerNorm.bias', 'base_model.encoder.layer.17.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.7.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.9.output.dense.bias', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.20.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.21.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.7.intermediate.dense.bias', 'base_model.encoder.layer.9.attention.self.key.bias', 'base_model.encoder.layer.19.output.LayerNorm.bias', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.8.output.LayerNorm.bias', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.13.attention.self.key.weight', 'base_model.encoder.layer.1.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.17.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.15.output.LayerNorm.bias', 'base_model.encoder.layer.20.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.21.attention.self.key.bias', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.2.attention.output.dense.weight', 'base_model.encoder.layer.13.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.0.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.10.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.13.attention.self.query.weight', 'base_model.encoder.layer.7.attention.output.dense.weight', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.8.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.7.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.19.intermediate.dense.bias', 'base_model.encoder.layer.1.intermediate.dense.weight', 'base_model.encoder.layer.8.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.11.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.4.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.5.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.18.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.11.output.dense.weight', 'base_model.encoder.layer.22.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.23.attention.self.query.bias', 'base_model.encoder.layer.1.attention.self.key.bias', 'base_model.encoder.layer.20.attention.self.query.bias', 'base_model.encoder.layer.7.attention.output.LayerNorm.bias', 'base_model.encoder.layer.7.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.2.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.8.attention.output.dense.bias', 'base_model.encoder.layer.16.intermediate.dense.bias', 'base_model.encoder.layer.7.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.15.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.22.attention.output.dense.bias', 'base_model.encoder.layer.7.attention.output.dense.bias', 'base_model.encoder.layer.1.output.LayerNorm.bias', 'base_model.encoder.layer.5.attention.self.value.bias', 'base_model.encoder.layer.10.output.dense.bias', 'base_model.encoder.layer.9.attention.output.dense.bias', 'base_model.encoder.layer.12.intermediate.dense.bias', 'base_model.encoder.layer.5.output.LayerNorm.weight', 'base_model.encoder.layer.7.output.LayerNorm.weight', 'base_model.encoder.layer.10.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.3.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.2.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.12.output.LayerNorm.weight', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.23.attention.output.dense.weight', 'base_model.encoder.layer.10.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.1.output.adapters.es.adapter_up.weight', 'base_model.embeddings.position_ids', 'base_model.encoder.layer.20.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.10.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.17.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.2.intermediate.dense.bias', 'base_model.encoder.layer.13.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.23.attention.self.value.weight', 'base_model.encoder.layer.9.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.21.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.5.intermediate.dense.bias', 'base_model.encoder.layer.6.attention.self.query.bias', 'base_model.encoder.layer.8.output.dense.bias', 'base_model.encoder.layer.12.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.4.intermediate.dense.bias', 'base_model.encoder.layer.2.output.dense.weight', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.0.intermediate.dense.weight', 'base_model.encoder.layer.3.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.16.output.dense.weight', 'base_model.encoder.layer.15.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.3.attention.output.LayerNorm.bias', 'base_model.encoder.layer.0.intermediate.dense.bias', 'base_model.encoder.layer.0.output.LayerNorm.bias', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.14.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.11.attention.self.query.bias', 'base_model.encoder.layer.11.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.11.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.16.attention.self.query.bias', 'base_model.encoder.layer.18.attention.self.query.bias', 'base_model.encoder.layer.21.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.23.output.LayerNorm.weight', 'base_model.encoder.layer.3.intermediate.dense.bias', 'base_model.encoder.layer.0.output.LayerNorm.weight', 'base_model.encoder.layer.1.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.8.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.18.output.LayerNorm.bias', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.22.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.18.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.18.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.0.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.18.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.5.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.15.attention.output.dense.bias', 'base_model.encoder.layer.6.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.18.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.20.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.17.output.dense.bias', 'base_model.encoder.layer.15.attention.self.query.weight', 'base_model.encoder.layer.9.attention.self.query.bias', 'base_model.encoder.layer.18.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.8.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.9.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.21.output.LayerNorm.bias', 'base_model.encoder.layer.18.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.1.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.2.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.14.output.LayerNorm.bias', 'base_model.encoder.layer.1.attention.output.dense.weight', 'base_model.encoder.layer.1.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.0.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.2.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.4.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.9.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.0.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.0.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.16.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.17.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.17.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.20.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.7.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.14.attention.self.query.bias', 'base_model.encoder.layer.22.attention.output.LayerNorm.weight', 'base_model.encoder.layer.13.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.19.attention.self.query.weight', 'base_model.encoder.layer.13.attention.self.query.bias', 'base_model.encoder.layer.15.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.0.attention.output.LayerNorm.weight', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.2.attention.self.key.weight', 'base_model.encoder.layer.13.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.14.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.16.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.15.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.2.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.9.output.LayerNorm.bias', 'base_model.encoder.layer.4.attention.self.key.weight', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.16.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.3.output.LayerNorm.weight', 'base_model.encoder.layer.0.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.5.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.6.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.10.attention.self.value.bias', 'base_model.encoder.layer.11.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.13.attention.self.value.bias', 'base_model.encoder.layer.10.attention.self.value.weight', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.14.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.19.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.21.output.LayerNorm.weight', 'base_model.encoder.layer.17.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.13.output.dense.weight', 'base_model.encoder.layer.14.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.8.attention.output.LayerNorm.weight', 'base_model.encoder.layer.15.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.21.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.2.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.22.output.LayerNorm.weight', 'base_model.encoder.layer.20.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.4.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.4.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.15.attention.output.dense.weight', 'base_model.encoder.layer.9.intermediate.dense.weight', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.13.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.23.attention.output.LayerNorm.weight', 'base_model.encoder.layer.22.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.10.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.11.output.LayerNorm.weight', 'base_model.encoder.layer.10.attention.output.dense.weight', 'base_model.encoder.layer.8.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.1.attention.self.key.weight', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.12.attention.output.LayerNorm.bias', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.20.intermediate.dense.bias', 'base_model.encoder.layer.12.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.16.attention.output.LayerNorm.bias', 'base_model.encoder.layer.22.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.12.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.22.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.11.attention.output.LayerNorm.bias', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.12.output.dense.weight', 'base_model.encoder.layer.3.attention.self.query.bias', 'base_model.encoder.layer.20.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.8.output.dense.weight', 'base_model.encoder.layer.19.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.15.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.12.attention.self.query.weight', 'base_model.encoder.layer.9.output.LayerNorm.weight', 'base_model.encoder.layer.0.attention.output.dense.weight', 'base_model.encoder.layer.11.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.16.intermediate.dense.weight', 'base_model.encoder.layer.7.attention.self.value.bias', 'base_model.encoder.layer.14.attention.self.query.weight', 'qa_outputs.weight', 'base_model.encoder.layer.2.intermediate.dense.weight', 'base_model.encoder.layer.15.attention.self.value.weight', 'base_model.encoder.layer.4.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.9.attention.output.LayerNorm.bias', 'base_model.encoder.layer.3.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.10.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.8.attention.self.value.weight', 'base_model.encoder.layer.3.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.10.attention.output.LayerNorm.weight', 'base_model.encoder.layer.23.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.15.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.5.intermediate.dense.weight', 'base_model.encoder.layer.18.attention.self.value.weight', 'base_model.encoder.layer.8.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.1.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.4.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.21.attention.self.key.weight', 'base_model.encoder.layer.5.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.22.output.dense.bias', 'base_model.encoder.layer.7.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.15.attention.self.key.weight', 'base_model.encoder.layer.13.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.13.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.3.attention.self.key.weight', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.5.attention.self.query.weight', 'base_model.encoder.layer.12.intermediate.dense.weight', 'base_model.encoder.layer.14.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.17.attention.output.LayerNorm.weight', 'base_model.encoder.layer.0.attention.self.key.bias', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.17.attention.output.dense.bias', 'base_model.encoder.layer.1.attention.self.query.bias', 'base_model.encoder.layer.5.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.18.attention.self.query.weight', 'base_model.encoder.layer.18.attention.output.dense.bias', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.13.output.LayerNorm.weight', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.embeddings.word_embeddings.weight', 'base_model.encoder.layer.22.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.19.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.17.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.19.output.dense.weight', 'base_model.encoder.layer.21.attention.self.query.bias', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.21.attention.self.value.bias', 'base_model.encoder.layer.18.attention.output.dense.weight', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.10.output.LayerNorm.bias', 'base_model.encoder.layer.5.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.15.attention.self.key.bias', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.7.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.0.attention.output.LayerNorm.bias', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.4.intermediate.dense.weight', 'base_model.encoder.layer.15.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.17.output.LayerNorm.weight', 'base_model.encoder.layer.14.output.adapters.es.adapter_down.0.bias', 'base_model.pooler.dense.bias', 'base_model.encoder.layer.21.attention.output.dense.bias', 'base_model.encoder.layer.11.attention.self.value.bias', 'base_model.encoder.layer.1.attention.self.value.weight', 'base_model.encoder.layer.14.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.23.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.17.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.2.attention.output.LayerNorm.weight', 'base_model.encoder.layer.19.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.23.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.15.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.9.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.10.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.23.attention.self.key.weight', 'base_model.encoder.layer.11.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.16.attention.self.value.bias', 'base_model.encoder.layer.19.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.17.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.23.attention.output.LayerNorm.bias', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.14.attention.output.LayerNorm.bias', 'base_model.encoder.layer.6.output.dense.weight', 'base_model.encoder.layer.19.attention.output.LayerNorm.weight', 'base_model.encoder.layer.17.intermediate.dense.weight', 'base_model.encoder.layer.18.intermediate.dense.bias', 'base_model.encoder.layer.22.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.11.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.5.output.dense.bias', 'base_model.encoder.layer.21.output.dense.bias', 'base_model.encoder.layer.6.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.3.attention.output.dense.weight', 'base_model.encoder.layer.18.output.LayerNorm.weight', 'base_model.encoder.layer.3.attention.self.query.weight', 'base_model.encoder.layer.16.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.17.attention.self.value.weight', 'base_model.encoder.layer.15.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.20.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.1.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.11.output.dense.bias', 'base_model.encoder.layer.21.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.19.attention.self.key.weight', 'base_model.encoder.layer.15.intermediate.dense.weight', 'base_model.encoder.layer.4.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.10.intermediate.dense.bias', 'base_model.encoder.layer.20.attention.output.dense.bias', 'base_model.encoder.layer.17.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.1.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.11.attention.self.key.bias', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.21.attention.self.value.weight', 'base_model.encoder.layer.10.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.23.attention.self.key.bias', 'base_model.encoder.layer.7.intermediate.dense.weight', 'base_model.encoder.layer.17.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.23.output.dense.weight', 'base_model.encoder.layer.1.attention.output.LayerNorm.weight', 'base_model.encoder.layer.13.attention.output.dense.weight', 'base_model.encoder.layer.7.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.1.intermediate.dense.bias', 'base_model.encoder.layer.12.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.12.attention.self.key.bias', 'base_model.encoder.layer.3.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.8.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.22.intermediate.dense.weight', 'base_model.encoder.layer.6.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.19.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.17.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.20.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.10.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.7.attention.self.key.weight', 'base_model.encoder.layer.23.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.23.attention.output.dense.bias', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.4.output.dense.bias', 'base_model.encoder.layer.6.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.16.attention.self.value.weight', 'base_model.encoder.layer.15.attention.self.query.bias', 'base_model.encoder.layer.5.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.11.output.LayerNorm.bias', 'base_model.encoder.layer.21.attention.output.LayerNorm.bias', 'base_model.encoder.layer.16.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.12.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.5.attention.output.LayerNorm.bias', 'base_model.encoder.layer.2.output.dense.bias', 'base_model.encoder.layer.8.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.21.attention.output.dense.weight', 'base_model.encoder.layer.2.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.12.attention.output.dense.weight', 'base_model.encoder.layer.11.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.6.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.10.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.2.attention.output.LayerNorm.bias', 'base_model.encoder.layer.13.output.dense.bias', 'base_model.encoder.layer.0.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.19.output.dense.bias', 'base_model.encoder.layer.6.attention.self.query.weight', 'base_model.encoder.layer.3.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.14.attention.output.LayerNorm.weight', 'base_model.encoder.layer.18.attention.self.value.bias', 'base_model.encoder.layer.21.intermediate.dense.weight', 'base_model.encoder.layer.14.output.adapters.ts.adapter_up.weight', 'qa_outputs.bias', 'base_model.encoder.layer.15.output.dense.weight', 'base_model.encoder.layer.6.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.0.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.5.attention.output.dense.bias', 'base_model.encoder.layer.18.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.3.attention.output.LayerNorm.weight', 'base_model.encoder.layer.22.attention.output.dense.weight', 'base_model.encoder.layer.21.attention.self.query.weight', 'base_model.encoder.layer.10.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.8.attention.self.value.bias', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.9.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.4.attention.self.query.weight', 'base_model.encoder.layer.3.output.LayerNorm.bias', 'base_model.encoder.layer.10.attention.self.key.bias', 'base_model.encoder.layer.15.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.19.attention.output.dense.bias', 'base_model.encoder.layer.23.intermediate.dense.bias', 'base_model.encoder.layer.4.attention.output.LayerNorm.weight', 'base_model.encoder.layer.20.attention.self.value.bias', 'base_model.encoder.layer.4.output.dense.weight', 'base_model.encoder.layer.22.attention.self.value.weight', 'base_model.encoder.layer.3.intermediate.dense.weight', 'base_model.encoder.layer.22.attention.self.key.bias', 'base_model.encoder.layer.10.output.dense.weight', 'base_model.encoder.layer.2.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.20.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.0.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.0.attention.self.query.bias', 'base_model.encoder.layer.3.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.9.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.15.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.13.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.7.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.11.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.5.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.6.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.13.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.6.attention.output.dense.weight', 'base_model.encoder.layer.5.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.14.intermediate.dense.bias', 'base_model.encoder.layer.17.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.3.attention.output.dense.bias', 'base_model.encoder.layer.16.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.17.attention.self.key.weight', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.1.output.dense.weight', 'base_model.encoder.layer.7.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.9.attention.self.value.bias', 'base_model.encoder.layer.20.attention.self.value.weight', 'base_model.encoder.layer.17.output.adapters.ep.adapter_up.weight']
- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of XLMRobertaModel were not initialized from the model checkpoint at /cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//squad/xlm-KG_LR4e-5_EPOCH2.0_maxlen384_batchsize4_gradacc8 and are newly initialized: ['encoder.layer.7.output.LayerNorm.bias', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.7.attention.self.value.bias', 'encoder.layer.11.attention.self.query.weight', 'encoder.layer.23.attention.self.value.bias', 'encoder.layer.16.output.LayerNorm.weight', 'encoder.layer.10.output.LayerNorm.weight', 'encoder.layer.6.attention.output.LayerNorm.weight', 'encoder.layer.12.output.LayerNorm.bias', 'encoder.layer.13.intermediate.dense.weight', 'encoder.layer.10.attention.self.query.bias', 'embeddings.LayerNorm.weight', 'encoder.layer.14.output.dense.weight', 'encoder.layer.8.attention.self.key.weight', 'encoder.layer.4.output.dense.bias', 'encoder.layer.11.output.dense.bias', 'encoder.layer.0.output.dense.weight', 'encoder.layer.22.attention.output.dense.weight', 'encoder.layer.21.intermediate.dense.weight', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.14.attention.output.LayerNorm.bias', 'encoder.layer.3.attention.self.query.bias', 'encoder.layer.12.attention.output.LayerNorm.bias', 'encoder.layer.22.attention.output.LayerNorm.weight', 'encoder.layer.23.attention.self.value.weight', 'encoder.layer.22.intermediate.dense.weight', 'encoder.layer.20.attention.self.value.bias', 'encoder.layer.19.output.dense.bias', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.7.intermediate.dense.bias', 'encoder.layer.13.output.LayerNorm.bias', 'encoder.layer.16.attention.output.LayerNorm.weight', 'encoder.layer.20.attention.self.value.weight', 'encoder.layer.2.output.dense.bias', 'encoder.layer.19.attention.self.query.bias', 'encoder.layer.12.attention.self.query.weight', 'encoder.layer.8.attention.self.query.weight', 'encoder.layer.20.intermediate.dense.bias', 'encoder.layer.18.intermediate.dense.bias', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.15.intermediate.dense.bias', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.17.attention.self.query.bias', 'encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.layer.13.attention.self.query.weight', 'encoder.layer.12.output.dense.weight', 'encoder.layer.22.output.dense.weight', 'encoder.layer.13.attention.output.dense.weight', 'encoder.layer.2.attention.output.LayerNorm.weight', 'encoder.layer.4.attention.self.query.weight', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.16.attention.self.key.bias', 'encoder.layer.9.attention.output.dense.weight', 'encoder.layer.20.attention.output.dense.weight', 'encoder.layer.19.attention.self.key.bias', 'encoder.layer.5.attention.output.LayerNorm.weight', 'encoder.layer.0.attention.self.value.weight', 'encoder.layer.23.output.LayerNorm.bias', 'encoder.layer.16.intermediate.dense.weight', 'encoder.layer.11.attention.self.value.bias', 'encoder.layer.10.output.dense.bias', 'encoder.layer.10.attention.self.query.weight', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.6.attention.self.query.bias', 'encoder.layer.17.attention.output.dense.weight', 'encoder.layer.19.attention.output.LayerNorm.weight', 'encoder.layer.22.attention.self.query.weight', 'encoder.layer.3.attention.self.query.weight', 'encoder.layer.23.attention.self.query.bias', 'encoder.layer.2.attention.self.value.bias', 'encoder.layer.8.attention.output.dense.weight', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.21.output.LayerNorm.bias', 'encoder.layer.6.attention.self.key.weight', 'encoder.layer.9.attention.output.LayerNorm.bias', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.5.output.LayerNorm.bias', 'encoder.layer.13.attention.output.dense.bias', 'encoder.layer.3.output.dense.weight', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.19.attention.output.dense.weight', 'encoder.layer.14.output.dense.bias', 'encoder.layer.16.attention.self.value.bias', 'encoder.layer.21.output.LayerNorm.weight', 'encoder.layer.20.attention.self.key.bias', 'encoder.layer.12.attention.self.query.bias', 'encoder.layer.12.attention.self.value.bias', 'encoder.layer.16.output.LayerNorm.bias', 'encoder.layer.5.attention.self.query.weight', 'encoder.layer.21.attention.output.dense.weight', 'encoder.layer.2.attention.output.dense.weight', 'encoder.layer.16.output.dense.bias', 'encoder.layer.21.attention.self.key.weight', 'encoder.layer.22.attention.self.key.bias', 'encoder.layer.11.attention.self.key.bias', 'pooler.dense.bias', 'encoder.layer.18.output.LayerNorm.bias', 'encoder.layer.2.attention.self.query.weight', 'encoder.layer.21.attention.self.query.bias', 'encoder.layer.13.attention.output.LayerNorm.bias', 'encoder.layer.20.intermediate.dense.weight', 'encoder.layer.21.attention.output.LayerNorm.bias', 'encoder.layer.15.output.dense.bias', 'encoder.layer.21.output.dense.weight', 'encoder.layer.18.output.LayerNorm.weight', 'encoder.layer.12.attention.output.dense.weight', 'encoder.layer.14.attention.self.key.bias', 'encoder.layer.18.attention.self.query.bias', 'encoder.layer.22.output.LayerNorm.weight', 'encoder.layer.3.attention.self.key.bias', 'encoder.layer.17.attention.output.LayerNorm.bias', 'encoder.layer.3.attention.self.key.weight', 'encoder.layer.4.attention.output.dense.bias', 'encoder.layer.21.attention.self.key.bias', 'encoder.layer.20.output.dense.weight', 'encoder.layer.17.attention.self.query.weight', 'encoder.layer.12.intermediate.dense.weight', 'pooler.dense.weight', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.10.output.LayerNorm.bias', 'encoder.layer.0.attention.self.query.bias', 'encoder.layer.15.attention.self.value.weight', 'encoder.layer.18.attention.self.value.bias', 'encoder.layer.3.attention.self.value.bias', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.8.attention.self.value.weight', 'embeddings.word_embeddings.weight', 'encoder.layer.6.attention.self.value.bias', 'encoder.layer.23.intermediate.dense.weight', 'encoder.layer.2.attention.self.key.weight', 'encoder.layer.23.attention.output.LayerNorm.bias', 'encoder.layer.17.attention.self.key.bias', 'encoder.layer.23.attention.self.key.weight', 'encoder.layer.1.attention.self.key.bias', 'encoder.layer.22.attention.self.query.bias', 'encoder.layer.15.attention.self.query.weight', 'encoder.layer.19.intermediate.dense.bias', 'encoder.layer.7.attention.output.LayerNorm.bias', 'encoder.layer.17.attention.self.value.weight', 'encoder.layer.18.attention.output.LayerNorm.weight', 'encoder.layer.10.attention.self.key.weight', 'encoder.layer.7.attention.self.value.weight', 'encoder.layer.21.attention.self.value.weight', 'encoder.layer.8.output.LayerNorm.bias', 'encoder.layer.15.attention.self.key.weight', 'encoder.layer.6.attention.self.query.weight', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.11.attention.self.key.weight', 'encoder.layer.8.attention.self.query.bias', 'encoder.layer.20.attention.self.query.bias', 'encoder.layer.5.attention.self.query.bias', 'encoder.layer.19.output.LayerNorm.bias', 'encoder.layer.1.attention.output.dense.bias', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.7.attention.output.dense.bias', 'encoder.layer.22.attention.self.key.weight', 'encoder.layer.6.output.dense.bias', 'encoder.layer.22.attention.self.value.bias', 'encoder.layer.14.attention.self.key.weight', 'encoder.layer.16.attention.self.value.weight', 'encoder.layer.14.attention.self.value.weight', 'encoder.layer.22.output.dense.bias', 'encoder.layer.7.output.dense.bias', 'encoder.layer.18.attention.output.LayerNorm.bias', 'encoder.layer.1.attention.self.query.bias', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.4.attention.output.dense.weight', 'encoder.layer.13.output.LayerNorm.weight', 'encoder.layer.14.attention.self.query.bias', 'encoder.layer.16.output.dense.weight', 'encoder.layer.22.intermediate.dense.bias', 'encoder.layer.4.attention.self.key.bias', 'encoder.layer.17.output.LayerNorm.bias', 'encoder.layer.1.attention.output.LayerNorm.weight', 'encoder.layer.8.output.dense.weight', 'encoder.layer.13.output.dense.bias', 'encoder.layer.8.attention.self.key.bias', 'encoder.layer.10.attention.output.dense.bias', 'encoder.layer.17.attention.self.value.bias', 'encoder.layer.11.output.LayerNorm.bias', 'encoder.layer.5.attention.self.key.bias', 'encoder.layer.17.attention.self.key.weight', 'encoder.layer.14.attention.output.LayerNorm.weight', 'encoder.layer.0.output.dense.bias', 'encoder.layer.21.intermediate.dense.bias', 'encoder.layer.14.attention.output.dense.weight', 'encoder.layer.5.attention.self.value.bias', 'encoder.layer.0.attention.self.query.weight', 'encoder.layer.2.attention.output.LayerNorm.bias', 'encoder.layer.3.output.dense.bias', 'encoder.layer.7.attention.self.query.weight', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.8.attention.output.LayerNorm.weight', 'encoder.layer.9.attention.output.dense.bias', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.16.attention.self.query.bias', 'embeddings.LayerNorm.bias', 'encoder.layer.12.output.LayerNorm.weight', 'encoder.layer.2.output.dense.weight', 'encoder.layer.5.attention.output.dense.weight', 'encoder.layer.12.attention.output.dense.bias', 'encoder.layer.18.attention.self.query.weight', 'encoder.layer.22.attention.output.LayerNorm.bias', 'encoder.layer.14.attention.self.value.bias', 'encoder.layer.8.attention.self.value.bias', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.16.attention.output.LayerNorm.bias', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.15.attention.output.LayerNorm.bias', 'encoder.layer.11.output.dense.weight', 'encoder.layer.15.attention.self.key.bias', 'encoder.layer.19.attention.output.dense.bias', 'encoder.layer.7.attention.output.dense.weight', 'encoder.layer.16.attention.self.key.weight', 'encoder.layer.2.attention.self.query.bias', 'encoder.layer.13.intermediate.dense.bias', 'encoder.layer.14.intermediate.dense.bias', 'encoder.layer.23.output.dense.bias', 'encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.layer.9.attention.self.value.bias', 'encoder.layer.9.attention.self.query.bias', 'encoder.layer.15.intermediate.dense.weight', 'encoder.layer.6.output.LayerNorm.bias', 'encoder.layer.14.output.LayerNorm.bias', 'encoder.layer.11.attention.output.dense.weight', 'encoder.layer.16.attention.output.dense.bias', 'encoder.layer.7.output.LayerNorm.weight', 'encoder.layer.1.attention.self.value.bias', 'encoder.layer.10.output.dense.weight', 'encoder.layer.0.attention.self.value.bias', 'encoder.layer.9.attention.self.value.weight', 'encoder.layer.3.attention.output.dense.weight', 'encoder.layer.7.output.dense.weight', 'encoder.layer.9.output.dense.weight', 'encoder.layer.11.attention.self.value.weight', 'encoder.layer.18.attention.self.key.weight', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.18.output.dense.weight', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.15.attention.output.dense.bias', 'encoder.layer.19.attention.self.value.bias', 'encoder.layer.6.attention.output.dense.bias', 'encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.layer.23.attention.self.key.bias', 'encoder.layer.9.output.LayerNorm.weight', 'encoder.layer.15.output.LayerNorm.weight', 'encoder.layer.8.attention.output.dense.bias', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.7.attention.self.key.bias', 'encoder.layer.17.intermediate.dense.weight', 'encoder.layer.9.attention.self.key.weight', 'encoder.layer.15.output.LayerNorm.bias', 'encoder.layer.11.attention.self.query.bias', 'encoder.layer.17.attention.output.LayerNorm.weight', 'encoder.layer.18.intermediate.dense.weight', 'encoder.layer.20.output.dense.bias', 'encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.layer.19.output.LayerNorm.weight', 'encoder.layer.17.output.dense.bias', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.17.attention.output.dense.bias', 'encoder.layer.2.attention.output.dense.bias', 'encoder.layer.4.output.dense.weight', 'encoder.layer.9.attention.self.query.weight', 'encoder.layer.20.attention.output.LayerNorm.bias', 'encoder.layer.0.attention.output.dense.bias', 'encoder.layer.12.intermediate.dense.bias', 'encoder.layer.19.attention.output.LayerNorm.bias', 'encoder.layer.23.attention.output.dense.weight', 'encoder.layer.18.attention.output.dense.weight', 'encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.layer.10.attention.self.key.bias', 'encoder.layer.12.attention.self.key.weight', 'encoder.layer.1.attention.self.key.weight', 'encoder.layer.7.attention.self.query.bias', 'encoder.layer.14.attention.output.dense.bias', 'encoder.layer.8.attention.output.LayerNorm.bias', 'encoder.layer.2.attention.self.value.weight', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.21.output.dense.bias', 'encoder.layer.1.attention.self.value.weight', 'encoder.layer.13.attention.output.LayerNorm.weight', 'encoder.layer.5.attention.self.key.weight', 'encoder.layer.6.attention.self.value.weight', 'encoder.layer.23.output.LayerNorm.weight', 'encoder.layer.15.output.dense.weight', 'encoder.layer.0.attention.self.key.bias', 'encoder.layer.20.output.LayerNorm.bias', 'encoder.layer.16.intermediate.dense.bias', 'encoder.layer.18.attention.self.key.bias', 'encoder.layer.12.attention.self.value.weight', 'embeddings.position_embeddings.weight', 'encoder.layer.23.attention.self.query.weight', 'encoder.layer.9.attention.self.key.bias', 'encoder.layer.16.attention.self.query.weight', 'encoder.layer.11.output.LayerNorm.weight', 'encoder.layer.19.output.dense.weight', 'encoder.layer.10.attention.output.LayerNorm.weight', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.5.attention.self.value.weight', 'encoder.layer.9.attention.output.LayerNorm.weight', 'encoder.layer.13.attention.self.key.weight', 'encoder.layer.9.output.dense.bias', 'encoder.layer.3.attention.output.dense.bias', 'encoder.layer.18.output.dense.bias', 'encoder.layer.19.intermediate.dense.weight', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.1.output.dense.weight', 'encoder.layer.22.output.LayerNorm.bias', 'encoder.layer.0.attention.output.LayerNorm.weight', 'encoder.layer.4.attention.self.query.bias', 'encoder.layer.6.attention.output.LayerNorm.bias', 'encoder.layer.4.attention.self.key.weight', 'encoder.layer.19.attention.self.query.weight', 'encoder.layer.1.output.dense.bias', 'encoder.layer.12.attention.output.LayerNorm.weight', 'encoder.layer.8.output.LayerNorm.weight', 'encoder.layer.22.attention.output.dense.bias', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.10.attention.output.dense.weight', 'encoder.layer.0.attention.self.key.weight', 'encoder.layer.15.attention.output.dense.weight', 'encoder.layer.7.attention.self.key.weight', 'encoder.layer.20.attention.output.LayerNorm.weight', 'encoder.layer.10.intermediate.dense.weight', 'encoder.layer.14.attention.self.query.weight', 'encoder.layer.21.attention.self.query.weight', 'encoder.layer.16.attention.output.dense.weight', 'encoder.layer.2.attention.self.key.bias', 'encoder.layer.18.attention.self.value.weight', 'encoder.layer.17.intermediate.dense.bias', 'encoder.layer.14.output.LayerNorm.weight', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.15.attention.self.value.bias', 'encoder.layer.4.attention.self.value.bias', 'encoder.layer.23.intermediate.dense.bias', 'encoder.layer.9.output.LayerNorm.bias', 'encoder.layer.5.output.dense.weight', 'encoder.layer.12.output.dense.bias', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.4.attention.output.LayerNorm.bias', 'encoder.layer.15.attention.output.LayerNorm.weight', 'encoder.layer.10.attention.self.value.bias', 'encoder.layer.20.attention.self.key.weight', 'encoder.layer.0.attention.output.dense.weight', 'encoder.layer.11.attention.output.LayerNorm.weight', 'embeddings.token_type_embeddings.weight', 'encoder.layer.11.attention.output.dense.bias', 'encoder.layer.14.intermediate.dense.weight', 'encoder.layer.10.attention.output.LayerNorm.bias', 'encoder.layer.19.attention.self.value.weight', 'encoder.layer.12.attention.self.key.bias', 'encoder.layer.21.attention.self.value.bias', 'encoder.layer.23.output.dense.weight', 'encoder.layer.19.attention.self.key.weight', 'encoder.layer.3.attention.self.value.weight', 'encoder.layer.6.attention.output.dense.weight', 'encoder.layer.15.attention.self.query.bias', 'encoder.layer.4.attention.self.value.weight', 'encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.13.output.dense.weight', 'encoder.layer.21.attention.output.dense.bias', 'encoder.layer.17.output.LayerNorm.weight', 'encoder.layer.1.attention.output.dense.weight', 'encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.layer.20.output.LayerNorm.weight', 'encoder.layer.22.attention.self.value.weight', 'encoder.layer.23.attention.output.LayerNorm.weight', 'encoder.layer.1.attention.self.query.weight', 'encoder.layer.13.attention.self.key.bias', 'encoder.layer.21.attention.output.LayerNorm.weight', 'encoder.layer.23.attention.output.dense.bias', 'encoder.layer.6.output.dense.weight', 'encoder.layer.20.attention.self.query.weight', 'encoder.layer.7.attention.output.LayerNorm.weight', 'encoder.layer.6.attention.self.key.bias', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.18.attention.output.dense.bias', 'encoder.layer.13.attention.self.query.bias', 'encoder.layer.4.attention.output.LayerNorm.weight', 'encoder.layer.13.attention.self.value.bias', 'encoder.layer.5.attention.output.dense.bias', 'encoder.layer.13.attention.self.value.weight', 'encoder.layer.10.attention.self.value.weight', 'encoder.layer.20.attention.output.dense.bias', 'encoder.layer.17.output.dense.weight', 'encoder.layer.8.output.dense.bias', 'encoder.layer.5.output.dense.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Overwriting existing adapter 'ep'.
Overwriting existing adapter 'tp'.
Overwriting existing adapter 'es'.
Overwriting existing adapter 'ts'.
Overwriting existing adapter fusion module 'ep,tp,es,ts'
05/09/2022 20:03:09 - INFO - __main__ -   Creating features from dataset file at .
/cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//squad/xlm-KG_LR4e-5_EPOCH2.0_maxlen384_batchsize4_gradacc8
XLMConfig {
  "architectures": [
    "XLMRobertaForMaskedLM"
  ],
  "asm": false,
  "attention_dropout": 0.1,
  "attention_probs_dropout_prob": 0.1,
  "bos_index": 0,
  "bos_token_id": 0,
  "causal": false,
  "dropout": 0.1,
  "emb_dim": 1024,
  "embed_init_std": 0.02209708691207961,
  "end_n_top": 5,
  "eos_index": 1,
  "eos_token_id": 2,
  "gelu_activation": true,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "init_std": 0.02,
  "initializer_range": 0.02,
  "intermediate_size": 4096,
  "is_encoder": true,
  "lang_id": 0,
  "layer_norm_eps": 1e-05,
  "mask_index": 5,
  "mask_token_id": 0,
  "max_position_embeddings": 514,
  "model_type": "xlm",
  "n_heads": 16,
  "n_langs": 1,
  "n_layers": 24,
  "output_past": true,
  "pad_index": 2,
  "pad_token_id": 1,
  "sinusoidal_embeddings": false,
  "start_n_top": 5,
  "summary_activation": null,
  "summary_first_dropout": 0.1,
  "summary_proj_to_labels": true,
  "summary_type": "first",
  "summary_use_proj": true,
  "transformers_version": "4.17.0",
  "type_vocab_size": 1,
  "unk_index": 3,
  "use_lang_emb": false,
  "vocab_size": 250002
}

  0%|          | 0/48 [00:00<?, ?it/s] 27%|██▋       | 13/48 [00:00<00:00, 128.61it/s] 54%|█████▍    | 26/48 [00:00<00:00, 109.67it/s] 79%|███████▉  | 38/48 [00:00<00:00, 109.60it/s]100%|██████████| 48/48 [00:00<00:00, 119.45it/s]
convert squad examples to features:   0%|          | 0/1190 [00:00<?, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.
convert squad examples to features:   0%|          | 1/1190 [00:00<02:51,  6.95it/s]convert squad examples to features:   5%|▌         | 65/1190 [00:00<00:04, 244.00it/s]convert squad examples to features:  11%|█         | 129/1190 [00:00<00:03, 297.98it/s]convert squad examples to features:  16%|█▌        | 193/1190 [00:00<00:02, 342.65it/s]convert squad examples to features:  22%|██▏       | 257/1190 [00:00<00:03, 307.54it/s]convert squad examples to features:  24%|██▍       | 289/1190 [00:00<00:02, 303.21it/s]convert squad examples to features:  27%|██▋       | 321/1190 [00:01<00:02, 295.18it/s]convert squad examples to features:  30%|██▉       | 353/1190 [00:01<00:03, 267.79it/s]convert squad examples to features:  32%|███▏      | 385/1190 [00:01<00:04, 167.92it/s]convert squad examples to features:  35%|███▌      | 417/1190 [00:01<00:04, 184.66it/s]convert squad examples to features:  38%|███▊      | 449/1190 [00:01<00:03, 204.85it/s]convert squad examples to features:  40%|████      | 481/1190 [00:02<00:03, 198.06it/s]convert squad examples to features:  43%|████▎     | 513/1190 [00:02<00:03, 215.30it/s]convert squad examples to features:  46%|████▌     | 545/1190 [00:02<00:03, 192.41it/s]convert squad examples to features:  48%|████▊     | 577/1190 [00:02<00:02, 207.12it/s]convert squad examples to features:  51%|█████     | 609/1190 [00:02<00:02, 205.52it/s]convert squad examples to features:  54%|█████▍    | 641/1190 [00:02<00:02, 219.83it/s]convert squad examples to features:  57%|█████▋    | 673/1190 [00:02<00:02, 223.44it/s]convert squad examples to features:  59%|█████▉    | 705/1190 [00:03<00:02, 199.17it/s]convert squad examples to features:  62%|██████▏   | 737/1190 [00:03<00:02, 217.26it/s]convert squad examples to features:  65%|██████▍   | 769/1190 [00:03<00:01, 236.98it/s]convert squad examples to features:  67%|██████▋   | 801/1190 [00:03<00:01, 251.50it/s]convert squad examples to features:  70%|███████   | 833/1190 [00:03<00:01, 223.90it/s]convert squad examples to features:  73%|███████▎  | 865/1190 [00:03<00:01, 238.51it/s]convert squad examples to features:  75%|███████▌  | 897/1190 [00:03<00:01, 242.55it/s]convert squad examples to features:  78%|███████▊  | 929/1190 [00:04<00:01, 232.08it/s]convert squad examples to features:  81%|████████  | 961/1190 [00:04<00:00, 237.46it/s]convert squad examples to features:  86%|████████▌ | 1025/1190 [00:04<00:00, 278.95it/s]convert squad examples to features:  92%|█████████▏| 1089/1190 [00:04<00:00, 286.86it/s]convert squad examples to features:  94%|█████████▍| 1121/1190 [00:04<00:00, 288.78it/s]convert squad examples to features:  97%|█████████▋| 1153/1190 [00:04<00:00, 256.61it/s]convert squad examples to features: 100%|██████████| 1190/1190 [00:04<00:00, 244.87it/s]/cluster/project/sachan/yifan/softwares/anaconda/anaconda3/envs/xfactr/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2272: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

add example index and unique id:   0%|          | 0/1190 [00:00<?, ?it/s]add example index and unique id: 100%|██████████| 1190/1190 [00:00<00:00, 862637.70it/s]
05/09/2022 20:03:14 - INFO - __main__ -   Saving features into cached file ./cached_xquad.tr.json_xlm-KG_LR4e-5_EPOCH2.0_maxlen384_batchsize4_gradacc8_384_tr
05/09/2022 20:03:16 - INFO - __main__ -   ***** Running evaluation  *****
05/09/2022 20:03:16 - INFO - __main__ -     Num examples = 1274
05/09/2022 20:03:16 - INFO - __main__ -     Batch size = 8
Evaluating:   0%|          | 0/160 [00:00<?, ?it/s]Evaluating:   1%|          | 1/160 [00:00<02:16,  1.17it/s]Evaluating:   1%|▏         | 2/160 [00:01<01:29,  1.77it/s]Evaluating:   2%|▏         | 3/160 [00:01<01:13,  2.13it/s]Evaluating:   2%|▎         | 4/160 [00:01<01:05,  2.36it/s]Evaluating:   3%|▎         | 5/160 [00:02<01:01,  2.52it/s]Evaluating:   4%|▍         | 6/160 [00:02<00:58,  2.62it/s]Evaluating:   4%|▍         | 7/160 [00:02<00:56,  2.70it/s]Evaluating:   5%|▌         | 8/160 [00:03<00:55,  2.74it/s]Evaluating:   6%|▌         | 9/160 [00:03<00:54,  2.76it/s]Evaluating:   6%|▋         | 10/160 [00:04<00:54,  2.78it/s]Evaluating:   7%|▋         | 11/160 [00:04<00:53,  2.79it/s]Evaluating:   8%|▊         | 12/160 [00:04<00:52,  2.80it/s]Evaluating:   8%|▊         | 13/160 [00:05<00:52,  2.81it/s]Evaluating:   9%|▉         | 14/160 [00:05<00:52,  2.80it/s]Evaluating:   9%|▉         | 15/160 [00:05<00:51,  2.81it/s]Evaluating:  10%|█         | 16/160 [00:06<00:51,  2.82it/s]Evaluating:  11%|█         | 17/160 [00:06<00:50,  2.81it/s]Evaluating:  11%|█▏        | 18/160 [00:06<00:50,  2.82it/s]Evaluating:  12%|█▏        | 19/160 [00:07<00:49,  2.82it/s]Evaluating:  12%|█▎        | 20/160 [00:07<00:49,  2.83it/s]Evaluating:  13%|█▎        | 21/160 [00:07<00:49,  2.81it/s]Evaluating:  14%|█▍        | 22/160 [00:08<00:48,  2.82it/s]Evaluating:  14%|█▍        | 23/160 [00:08<00:48,  2.82it/s]Evaluating:  15%|█▌        | 24/160 [00:09<00:48,  2.78it/s]Evaluating:  16%|█▌        | 25/160 [00:09<00:48,  2.78it/s]Evaluating:  16%|█▋        | 26/160 [00:09<00:48,  2.78it/s]Evaluating:  17%|█▋        | 27/160 [00:10<00:47,  2.79it/s]Evaluating:  18%|█▊        | 28/160 [00:10<00:47,  2.79it/s]Evaluating:  18%|█▊        | 29/160 [00:10<00:46,  2.80it/s]Evaluating:  19%|█▉        | 30/160 [00:11<00:46,  2.81it/s]Evaluating:  19%|█▉        | 31/160 [00:11<00:45,  2.81it/s]Evaluating:  20%|██        | 32/160 [00:11<00:45,  2.82it/s]Evaluating:  21%|██        | 33/160 [00:12<00:45,  2.82it/s]Evaluating:  21%|██▏       | 34/160 [00:12<00:44,  2.82it/s]Evaluating:  22%|██▏       | 35/160 [00:12<00:44,  2.82it/s]Evaluating:  22%|██▎       | 36/160 [00:13<00:44,  2.82it/s]Evaluating:  23%|██▎       | 37/160 [00:13<00:43,  2.82it/s]Evaluating:  24%|██▍       | 38/160 [00:14<00:43,  2.82it/s]Evaluating:  24%|██▍       | 39/160 [00:14<00:42,  2.82it/s]Evaluating:  25%|██▌       | 40/160 [00:14<00:42,  2.82it/s]Evaluating:  26%|██▌       | 41/160 [00:15<00:42,  2.82it/s]Evaluating:  26%|██▋       | 42/160 [00:15<00:41,  2.82it/s]Evaluating:  27%|██▋       | 43/160 [00:15<00:41,  2.81it/s]Evaluating:  28%|██▊       | 44/160 [00:16<00:41,  2.81it/s]Evaluating:  28%|██▊       | 45/160 [00:16<00:40,  2.82it/s]Evaluating:  29%|██▉       | 46/160 [00:16<00:40,  2.82it/s]Evaluating:  29%|██▉       | 47/160 [00:17<00:40,  2.82it/s]Evaluating:  30%|███       | 48/160 [00:17<00:40,  2.78it/s]Evaluating:  31%|███       | 49/160 [00:17<00:39,  2.80it/s]Evaluating:  31%|███▏      | 50/160 [00:18<00:39,  2.75it/s]Evaluating:  32%|███▏      | 51/160 [00:18<00:41,  2.64it/s]Evaluating:  32%|███▎      | 52/160 [00:19<00:40,  2.66it/s]Evaluating:  33%|███▎      | 53/160 [00:19<00:39,  2.69it/s]Evaluating:  34%|███▍      | 54/160 [00:19<00:39,  2.71it/s]Evaluating:  34%|███▍      | 55/160 [00:20<00:38,  2.73it/s]Evaluating:  35%|███▌      | 56/160 [00:20<00:37,  2.75it/s]Evaluating:  36%|███▌      | 57/160 [00:20<00:37,  2.76it/s]Evaluating:  36%|███▋      | 58/160 [00:21<00:36,  2.77it/s]Evaluating:  37%|███▋      | 59/160 [00:21<00:36,  2.75it/s]Evaluating:  38%|███▊      | 60/160 [00:21<00:36,  2.76it/s]Evaluating:  38%|███▊      | 61/160 [00:22<00:35,  2.77it/s]Evaluating:  39%|███▉      | 62/160 [00:22<00:35,  2.75it/s]Evaluating:  39%|███▉      | 63/160 [00:23<00:34,  2.77it/s]Evaluating:  40%|████      | 64/160 [00:23<00:34,  2.79it/s]Evaluating:  41%|████      | 65/160 [00:23<00:34,  2.77it/s]Evaluating:  41%|████▏     | 66/160 [00:24<00:34,  2.74it/s]Evaluating:  42%|████▏     | 67/160 [00:24<00:34,  2.73it/s]Evaluating:  42%|████▎     | 68/160 [00:24<00:33,  2.75it/s]Evaluating:  43%|████▎     | 69/160 [00:25<00:33,  2.74it/s]Evaluating:  44%|████▍     | 70/160 [00:25<00:33,  2.72it/s]Evaluating:  44%|████▍     | 71/160 [00:25<00:33,  2.68it/s]Evaluating:  45%|████▌     | 72/160 [00:26<00:32,  2.72it/s]Evaluating:  46%|████▌     | 73/160 [00:26<00:31,  2.75it/s]Evaluating:  46%|████▋     | 74/160 [00:27<00:31,  2.70it/s]Evaluating:  47%|████▋     | 75/160 [00:27<00:31,  2.70it/s]Evaluating:  48%|████▊     | 76/160 [00:27<00:30,  2.73it/s]Evaluating:  48%|████▊     | 77/160 [00:28<00:30,  2.75it/s]Evaluating:  49%|████▉     | 78/160 [00:28<00:29,  2.74it/s]Evaluating:  49%|████▉     | 79/160 [00:28<00:29,  2.73it/s]Evaluating:  50%|█████     | 80/160 [00:29<00:29,  2.73it/s]Evaluating:  51%|█████     | 81/160 [00:29<00:29,  2.64it/s]Evaluating:  51%|█████▏    | 82/160 [00:30<00:29,  2.60it/s]Evaluating:  52%|█████▏    | 83/160 [00:30<00:29,  2.63it/s]Evaluating:  52%|█████▎    | 84/160 [00:30<00:28,  2.68it/s]Evaluating:  53%|█████▎    | 85/160 [00:31<00:27,  2.72it/s]Evaluating:  54%|█████▍    | 86/160 [00:31<00:27,  2.74it/s]Evaluating:  54%|█████▍    | 87/160 [00:31<00:26,  2.76it/s]Evaluating:  55%|█████▌    | 88/160 [00:32<00:26,  2.77it/s]Evaluating:  56%|█████▌    | 89/160 [00:32<00:25,  2.78it/s]Evaluating:  56%|█████▋    | 90/160 [00:32<00:25,  2.78it/s]Evaluating:  57%|█████▋    | 91/160 [00:33<00:24,  2.79it/s]Evaluating:  57%|█████▊    | 92/160 [00:33<00:24,  2.79it/s]Evaluating:  58%|█████▊    | 93/160 [00:34<00:23,  2.79it/s]Evaluating:  59%|█████▉    | 94/160 [00:34<00:23,  2.79it/s]Evaluating:  59%|█████▉    | 95/160 [00:34<00:23,  2.79it/s]Evaluating:  60%|██████    | 96/160 [00:35<00:22,  2.80it/s]Evaluating:  61%|██████    | 97/160 [00:35<00:23,  2.68it/s]Evaluating:  61%|██████▏   | 98/160 [00:35<00:22,  2.72it/s]Evaluating:  62%|██████▏   | 99/160 [00:36<00:22,  2.73it/s]Evaluating:  62%|██████▎   | 100/160 [00:36<00:21,  2.73it/s]Evaluating:  63%|██████▎   | 101/160 [00:36<00:22,  2.67it/s]Evaluating:  64%|██████▍   | 102/160 [00:37<00:21,  2.71it/s]Evaluating:  64%|██████▍   | 103/160 [00:37<00:20,  2.74it/s]Evaluating:  65%|██████▌   | 104/160 [00:38<00:20,  2.68it/s]Evaluating:  66%|██████▌   | 105/160 [00:38<00:22,  2.47it/s]Evaluating:  66%|██████▋   | 106/160 [00:38<00:21,  2.52it/s]Evaluating:  67%|██████▋   | 107/160 [00:39<00:20,  2.56it/s]Evaluating:  68%|██████▊   | 108/160 [00:39<00:20,  2.59it/s]Evaluating:  68%|██████▊   | 109/160 [00:40<00:19,  2.64it/s]Evaluating:  69%|██████▉   | 110/160 [00:40<00:18,  2.68it/s]Evaluating:  69%|██████▉   | 111/160 [00:40<00:18,  2.71it/s]Evaluating:  70%|███████   | 112/160 [00:41<00:17,  2.74it/s]Evaluating:  71%|███████   | 113/160 [00:41<00:17,  2.73it/s]Evaluating:  71%|███████▏  | 114/160 [00:41<00:16,  2.74it/s]Evaluating:  72%|███████▏  | 115/160 [00:42<00:16,  2.75it/s]Evaluating:  72%|███████▎  | 116/160 [00:42<00:15,  2.76it/s]Evaluating:  73%|███████▎  | 117/160 [00:42<00:15,  2.77it/s]Evaluating:  74%|███████▍  | 118/160 [00:43<00:15,  2.77it/s]Evaluating:  74%|███████▍  | 119/160 [00:43<00:14,  2.78it/s]Evaluating:  75%|███████▌  | 120/160 [00:44<00:14,  2.78it/s]Evaluating:  76%|███████▌  | 121/160 [00:44<00:14,  2.78it/s]Evaluating:  76%|███████▋  | 122/160 [00:44<00:13,  2.72it/s]Evaluating:  77%|███████▋  | 123/160 [00:45<00:13,  2.74it/s]Evaluating:  78%|███████▊  | 124/160 [00:45<00:13,  2.74it/s]Evaluating:  78%|███████▊  | 125/160 [00:45<00:13,  2.64it/s]Evaluating:  79%|███████▉  | 126/160 [00:46<00:12,  2.65it/s]Evaluating:  79%|███████▉  | 127/160 [00:46<00:12,  2.68it/s]Evaluating:  80%|████████  | 128/160 [00:47<00:11,  2.70it/s]Evaluating:  81%|████████  | 129/160 [00:47<00:11,  2.73it/s]Evaluating:  81%|████████▏ | 130/160 [00:47<00:10,  2.75it/s]Evaluating:  82%|████████▏ | 131/160 [00:48<00:10,  2.77it/s]Evaluating:  82%|████████▎ | 132/160 [00:48<00:10,  2.69it/s]Evaluating:  83%|████████▎ | 133/160 [00:48<00:10,  2.65it/s]Evaluating:  84%|████████▍ | 134/160 [00:49<00:10,  2.58it/s]Evaluating:  84%|████████▍ | 135/160 [00:49<00:09,  2.65it/s]Evaluating:  85%|████████▌ | 136/160 [00:50<00:09,  2.66it/s]Evaluating:  86%|████████▌ | 137/160 [00:50<00:08,  2.70it/s]Evaluating:  86%|████████▋ | 138/160 [00:50<00:08,  2.73it/s]Evaluating:  87%|████████▋ | 139/160 [00:51<00:07,  2.73it/s]Evaluating:  88%|████████▊ | 140/160 [00:51<00:07,  2.75it/s]Evaluating:  88%|████████▊ | 141/160 [00:51<00:06,  2.76it/s]Evaluating:  89%|████████▉ | 142/160 [00:52<00:06,  2.77it/s]Evaluating:  89%|████████▉ | 143/160 [00:52<00:06,  2.74it/s]Evaluating:  90%|█████████ | 144/160 [00:52<00:05,  2.69it/s]Evaluating:  91%|█████████ | 145/160 [00:53<00:05,  2.59it/s]Evaluating:  91%|█████████▏| 146/160 [00:53<00:05,  2.51it/s]Evaluating:  92%|█████████▏| 147/160 [00:54<00:05,  2.59it/s]Evaluating:  92%|█████████▎| 148/160 [00:54<00:04,  2.56it/s]Evaluating:  93%|█████████▎| 149/160 [00:54<00:04,  2.62it/s]Evaluating:  94%|█████████▍| 150/160 [00:55<00:03,  2.58it/s]Evaluating:  94%|█████████▍| 151/160 [00:55<00:03,  2.47it/s]Evaluating:  95%|█████████▌| 152/160 [00:56<00:03,  2.53it/s]Evaluating:  96%|█████████▌| 153/160 [00:56<00:02,  2.60it/s]Evaluating:  96%|█████████▋| 154/160 [00:56<00:02,  2.65it/s]Evaluating:  97%|█████████▋| 155/160 [00:57<00:01,  2.68it/s]Evaluating:  98%|█████████▊| 156/160 [00:57<00:01,  2.71it/s]Evaluating:  98%|█████████▊| 157/160 [00:57<00:01,  2.73it/s]Evaluating:  99%|█████████▉| 158/160 [00:58<00:00,  2.74it/s]Evaluating:  99%|█████████▉| 159/160 [00:58<00:00,  2.75it/s]Evaluating: 100%|██████████| 160/160 [00:58<00:00,  3.51it/s]Evaluating: 100%|██████████| 160/160 [00:58<00:00,  2.72it/s]
05/09/2022 20:04:14 - INFO - __main__ -     Evaluation done in total 58.731571 secs (0.046100 sec per example)
05/09/2022 20:04:18 - INFO - __main__ -   Results: {'exact': 59.57983193277311, 'f1': 74.59960642635352, 'total': 1190, 'HasAns_exact': 59.57983193277311, 'HasAns_f1': 74.59960642635352, 'HasAns_total': 1190, 'best_exact': 59.57983193277311, 'best_exact_thresh': 0.0, 'best_f1': 74.59960642635352, 'best_f1_thresh': 0.0}
  ar 
2022-05-09 20:04:21.652615: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0
05/09/2022 20:04:27 - WARNING - __main__ -   Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, 16-bits training: False
You are using a model of type xlm-roberta to instantiate a model of type xlm. This is not supported for all configurations of models and can yield errors.
Some weights of the model checkpoint at /cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//squad/xlm-KG_LR4e-5_EPOCH2.0_maxlen384_batchsize4_gradacc8 were not used when initializing XLMRobertaModel: ['base_model.encoder.layer.5.output.dense.weight', 'base_model.encoder.layer.7.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.14.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.4.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.14.intermediate.dense.bias', 'base_model.encoder.layer.9.attention.output.LayerNorm.bias', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.16.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.10.output.LayerNorm.weight', 'base_model.encoder.layer.21.attention.self.key.bias', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.22.intermediate.dense.bias', 'base_model.encoder.layer.2.attention.self.value.bias', 'qa_outputs.bias', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.2.attention.self.query.bias', 'base_model.encoder.layer.21.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.20.attention.output.dense.weight', 'base_model.encoder.layer.0.attention.output.dense.bias', 'base_model.encoder.layer.2.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.13.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.0.output.LayerNorm.bias', 'base_model.encoder.layer.10.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.21.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.2.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.8.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.21.attention.output.dense.weight', 'base_model.encoder.layer.9.output.LayerNorm.bias', 'base_model.encoder.layer.2.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.17.attention.output.LayerNorm.bias', 'base_model.encoder.layer.22.attention.self.key.weight', 'base_model.encoder.layer.12.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.16.output.dense.bias', 'base_model.encoder.layer.13.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.18.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.13.attention.output.dense.bias', 'base_model.encoder.layer.19.output.LayerNorm.bias', 'base_model.encoder.layer.2.intermediate.dense.weight', 'base_model.encoder.layer.7.attention.output.dense.weight', 'base_model.encoder.layer.4.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.23.output.dense.bias', 'base_model.encoder.layer.10.attention.self.value.bias', 'base_model.encoder.layer.21.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.22.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.15.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.21.attention.output.LayerNorm.bias', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.15.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.15.attention.output.LayerNorm.weight', 'base_model.encoder.layer.14.attention.output.dense.weight', 'base_model.encoder.layer.8.attention.self.value.weight', 'base_model.encoder.layer.0.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.1.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.12.attention.self.value.weight', 'base_model.encoder.layer.5.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.15.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.11.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.4.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.11.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.4.attention.self.key.weight', 'base_model.encoder.layer.17.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.16.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.2.output.LayerNorm.weight', 'base_model.encoder.layer.1.attention.self.key.weight', 'base_model.encoder.layer.0.attention.self.key.weight', 'base_model.encoder.layer.5.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.15.attention.output.dense.bias', 'base_model.encoder.layer.4.output.LayerNorm.bias', 'base_model.encoder.layer.6.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.13.intermediate.dense.bias', 'base_model.encoder.layer.12.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.10.output.dense.weight', 'base_model.encoder.layer.23.intermediate.dense.bias', 'base_model.encoder.layer.1.intermediate.dense.weight', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.9.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.7.attention.self.query.weight', 'base_model.encoder.layer.13.attention.self.query.bias', 'base_model.encoder.layer.12.attention.output.LayerNorm.weight', 'base_model.encoder.layer.3.output.LayerNorm.bias', 'base_model.encoder.layer.20.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.3.attention.output.dense.bias', 'base_model.encoder.layer.17.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.9.output.dense.weight', 'base_model.encoder.layer.8.attention.output.LayerNorm.bias', 'base_model.encoder.layer.4.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.0.output.dense.weight', 'base_model.encoder.layer.7.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.16.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.1.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.13.attention.output.LayerNorm.bias', 'base_model.encoder.layer.23.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.15.output.dense.weight', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.7.output.dense.weight', 'base_model.encoder.layer.21.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.5.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.10.attention.output.dense.bias', 'base_model.encoder.layer.3.attention.self.value.weight', 'base_model.encoder.layer.21.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.9.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.11.intermediate.dense.weight', 'base_model.encoder.layer.5.attention.output.dense.weight', 'base_model.encoder.layer.14.attention.self.value.bias', 'base_model.encoder.layer.12.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.14.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.23.output.LayerNorm.bias', 'base_model.encoder.layer.13.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.4.attention.self.query.bias', 'base_model.encoder.layer.23.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.16.intermediate.dense.weight', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.21.intermediate.dense.bias', 'base_model.encoder.layer.4.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.8.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.9.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.22.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.13.attention.output.LayerNorm.weight', 'base_model.encoder.layer.23.attention.self.key.bias', 'base_model.encoder.layer.23.attention.self.value.weight', 'base_model.encoder.layer.9.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.21.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.22.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.23.attention.self.query.bias', 'base_model.encoder.layer.13.attention.self.key.weight', 'base_model.encoder.layer.18.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.17.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.3.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.2.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.3.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.2.attention.self.key.weight', 'base_model.encoder.layer.20.output.dense.weight', 'base_model.encoder.layer.17.attention.self.query.bias', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.8.output.LayerNorm.bias', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.12.attention.self.query.weight', 'base_model.encoder.layer.23.attention.output.LayerNorm.weight', 'base_model.pooler.dense.weight', 'base_model.encoder.layer.8.attention.output.dense.bias', 'base_model.encoder.layer.8.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.12.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.20.output.LayerNorm.weight', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.18.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.18.attention.self.value.weight', 'base_model.encoder.layer.9.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.22.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.9.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.9.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.6.output.LayerNorm.weight', 'base_model.encoder.layer.14.attention.self.query.bias', 'base_model.encoder.layer.18.attention.self.key.weight', 'base_model.encoder.layer.18.output.dense.weight', 'base_model.encoder.layer.23.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.2.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.15.attention.self.value.bias', 'base_model.embeddings.word_embeddings.weight', 'base_model.encoder.layer.2.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.16.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.20.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.10.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.21.attention.output.LayerNorm.weight', 'base_model.encoder.layer.17.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.8.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.0.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.13.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.22.attention.self.value.weight', 'base_model.encoder.layer.22.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.16.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.2.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.6.intermediate.dense.weight', 'base_model.encoder.layer.18.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.16.attention.self.query.bias', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.7.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.5.output.LayerNorm.weight', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.17.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.21.output.LayerNorm.weight', 'base_model.encoder.layer.22.attention.output.dense.weight', 'base_model.encoder.layer.13.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.16.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.2.output.dense.weight', 'base_model.encoder.layer.3.attention.output.dense.weight', 'base_model.encoder.layer.22.intermediate.dense.weight', 'base_model.encoder.layer.1.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.19.attention.self.key.weight', 'base_model.encoder.layer.20.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.22.attention.self.key.bias', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.17.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.12.output.dense.weight', 'base_model.encoder.layer.21.attention.self.query.weight', 'base_model.encoder.layer.21.intermediate.dense.weight', 'base_model.encoder.layer.13.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.4.output.dense.weight', 'base_model.encoder.layer.4.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.14.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.3.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.17.attention.self.query.weight', 'base_model.encoder.layer.8.attention.self.key.weight', 'base_model.encoder.layer.11.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.2.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.14.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.12.attention.self.query.bias', 'base_model.encoder.layer.10.attention.self.key.weight', 'base_model.encoder.layer.0.attention.output.LayerNorm.bias', 'base_model.encoder.layer.22.output.dense.bias', 'base_model.encoder.layer.0.attention.self.query.weight', 'base_model.encoder.layer.2.attention.self.query.weight', 'base_model.encoder.layer.17.intermediate.dense.weight', 'base_model.encoder.layer.15.attention.output.dense.weight', 'base_model.encoder.layer.0.attention.self.query.bias', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.1.attention.self.value.bias', 'base_model.encoder.layer.4.attention.output.LayerNorm.bias', 'base_model.encoder.layer.10.attention.output.dense.weight', 'base_model.encoder.layer.12.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.0.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.2.attention.self.key.bias', 'base_model.encoder.layer.15.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.19.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.21.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.11.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.18.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.2.attention.output.dense.bias', 'base_model.encoder.layer.3.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.19.attention.self.value.bias', 'base_model.encoder.layer.7.output.dense.bias', 'base_model.encoder.layer.0.attention.self.value.weight', 'base_model.encoder.layer.9.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.11.attention.output.dense.weight', 'base_model.encoder.layer.14.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.16.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.12.attention.output.dense.bias', 'base_model.encoder.layer.18.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.22.attention.output.dense.bias', 'base_model.encoder.layer.8.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.22.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.18.attention.self.value.bias', 'base_model.encoder.layer.22.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.6.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.19.attention.output.LayerNorm.bias', 'base_model.encoder.layer.3.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.0.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.6.attention.self.query.weight', 'base_model.encoder.layer.14.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.5.attention.self.key.bias', 'base_model.encoder.layer.18.attention.output.dense.bias', 'base_model.encoder.layer.19.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.19.output.dense.weight', 'base_model.encoder.layer.13.attention.self.value.weight', 'base_model.encoder.layer.3.output.dense.weight', 'base_model.encoder.layer.5.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.6.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.15.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.2.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.14.output.LayerNorm.weight', 'base_model.encoder.layer.16.attention.output.dense.bias', 'base_model.encoder.layer.18.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.1.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.2.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.5.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.16.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.20.attention.self.query.bias', 'base_model.encoder.layer.5.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.7.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.6.attention.self.key.bias', 'base_model.encoder.layer.3.output.LayerNorm.weight', 'base_model.encoder.layer.14.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.4.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.23.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.6.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.16.intermediate.dense.bias', 'base_model.encoder.layer.11.attention.self.value.bias', 'base_model.encoder.layer.5.intermediate.dense.bias', 'base_model.encoder.layer.21.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.4.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.7.attention.output.LayerNorm.weight', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.17.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.3.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.11.attention.output.LayerNorm.bias', 'base_model.encoder.layer.11.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.9.attention.output.LayerNorm.weight', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.12.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.22.attention.self.value.bias', 'base_model.encoder.layer.3.attention.output.LayerNorm.weight', 'base_model.encoder.layer.18.attention.self.key.bias', 'base_model.encoder.layer.2.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.22.output.LayerNorm.weight', 'base_model.encoder.layer.13.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.8.attention.self.key.bias', 'base_model.encoder.layer.6.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.3.attention.self.value.bias', 'base_model.encoder.layer.3.output.dense.bias', 'base_model.encoder.layer.10.attention.output.LayerNorm.bias', 'base_model.encoder.layer.11.attention.output.dense.bias', 'base_model.encoder.layer.19.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.20.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.6.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.14.intermediate.dense.weight', 'base_model.encoder.layer.20.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.4.output.dense.bias', 'base_model.encoder.layer.22.attention.output.LayerNorm.weight', 'base_model.encoder.layer.15.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.6.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.10.attention.self.query.bias', 'base_model.encoder.layer.14.attention.self.key.weight', 'base_model.encoder.layer.15.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.1.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.20.output.dense.bias', 'qa_outputs.weight', 'base_model.encoder.layer.13.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.4.intermediate.dense.weight', 'base_model.encoder.layer.5.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.15.attention.self.value.weight', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.6.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.14.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.17.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.7.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.3.attention.output.LayerNorm.bias', 'base_model.encoder.layer.10.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.18.attention.self.query.bias', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.3.intermediate.dense.weight', 'base_model.encoder.layer.6.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.0.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.0.intermediate.dense.bias', 'base_model.encoder.layer.16.output.LayerNorm.weight', 'base_model.encoder.layer.11.output.dense.weight', 'base_model.encoder.layer.16.attention.self.key.bias', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.8.output.dense.weight', 'base_model.encoder.layer.8.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.12.intermediate.dense.weight', 'base_model.encoder.layer.13.output.dense.weight', 'base_model.encoder.layer.13.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.19.attention.self.key.bias', 'base_model.encoder.layer.22.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.15.attention.self.query.bias', 'base_model.encoder.layer.21.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.15.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.15.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.21.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.10.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.16.output.dense.weight', 'base_model.encoder.layer.19.intermediate.dense.weight', 'base_model.encoder.layer.1.attention.output.LayerNorm.weight', 'base_model.encoder.layer.6.attention.output.dense.bias', 'base_model.encoder.layer.1.output.LayerNorm.weight', 'base_model.encoder.layer.12.output.LayerNorm.weight', 'base_model.encoder.layer.11.intermediate.dense.bias', 'base_model.encoder.layer.0.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.8.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.12.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.14.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.8.intermediate.dense.weight', 'base_model.encoder.layer.10.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.3.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.13.attention.self.value.bias', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.23.attention.self.key.weight', 'base_model.encoder.layer.12.attention.self.value.bias', 'base_model.encoder.layer.6.attention.output.dense.weight', 'base_model.encoder.layer.11.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.12.output.LayerNorm.bias', 'base_model.encoder.layer.15.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.10.output.LayerNorm.bias', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.20.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.15.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.19.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.23.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.0.attention.output.dense.weight', 'base_model.encoder.layer.17.attention.output.dense.weight', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.19.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.1.output.LayerNorm.bias', 'base_model.encoder.layer.16.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.19.intermediate.dense.bias', 'base_model.encoder.layer.14.attention.output.dense.bias', 'base_model.encoder.layer.12.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.20.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.5.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.2.output.dense.bias', 'base_model.encoder.layer.18.attention.output.LayerNorm.weight', 'base_model.encoder.layer.7.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.13.attention.self.key.bias', 'base_model.encoder.layer.6.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.21.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.10.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.17.output.dense.weight', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.17.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.6.attention.self.value.bias', 'base_model.encoder.layer.19.attention.output.LayerNorm.weight', 'base_model.encoder.layer.19.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.9.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.0.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.18.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.14.output.dense.bias', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.20.attention.output.LayerNorm.weight', 'base_model.encoder.layer.20.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.13.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.16.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.10.intermediate.dense.weight', 'base_model.encoder.layer.20.attention.self.value.bias', 'base_model.encoder.layer.23.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.12.attention.self.key.weight', 'base_model.encoder.layer.14.output.adapters.ts.adapter_down.0.bias', 'base_model.embeddings.LayerNorm.weight', 'base_model.encoder.layer.5.output.LayerNorm.bias', 'base_model.encoder.layer.19.attention.self.query.bias', 'base_model.encoder.layer.13.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.6.attention.output.LayerNorm.weight', 'base_model.encoder.layer.19.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.20.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.10.attention.self.query.weight', 'base_model.encoder.layer.1.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.11.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.9.attention.output.dense.weight', 'base_model.encoder.layer.7.output.LayerNorm.weight', 'base_model.encoder.layer.3.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.8.output.LayerNorm.weight', 'base_model.encoder.layer.16.attention.self.value.weight', 'base_model.encoder.layer.1.output.dense.bias', 'base_model.encoder.layer.18.output.LayerNorm.weight', 'base_model.encoder.layer.21.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.18.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.11.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.13.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.17.attention.self.key.bias', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.0.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.10.attention.self.key.bias', 'base_model.encoder.layer.22.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.16.attention.self.value.bias', 'base_model.encoder.layer.14.output.dense.weight', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.19.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.7.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.10.intermediate.dense.bias', 'base_model.encoder.layer.9.output.LayerNorm.weight', 'base_model.encoder.layer.18.attention.output.dense.weight', 'base_model.encoder.layer.7.intermediate.dense.weight', 'base_model.encoder.layer.6.output.dense.bias', 'base_model.encoder.layer.12.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.9.attention.self.value.bias', 'base_model.encoder.layer.9.attention.self.query.bias', 'base_model.encoder.layer.11.output.dense.bias', 'base_model.encoder.layer.0.output.LayerNorm.weight', 'base_model.encoder.layer.4.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.3.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.11.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.15.attention.output.LayerNorm.bias', 'base_model.encoder.layer.19.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.2.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.14.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.4.attention.output.dense.bias', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.22.attention.self.query.weight', 'base_model.encoder.layer.9.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.11.attention.output.LayerNorm.weight', 'base_model.encoder.layer.3.attention.self.query.bias', 'base_model.encoder.layer.22.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.14.attention.self.key.bias', 'base_model.encoder.layer.19.attention.self.query.weight', 'base_model.encoder.layer.11.attention.self.query.bias', 'base_model.encoder.layer.11.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.23.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.20.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.5.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.23.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.5.output.dense.bias', 'base_model.encoder.layer.10.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.5.attention.output.LayerNorm.weight', 'base_model.encoder.layer.1.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.11.attention.self.key.bias', 'base_model.encoder.layer.10.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.10.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.16.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.22.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.3.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.5.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.12.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.4.output.LayerNorm.weight', 'base_model.encoder.layer.17.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.11.attention.self.value.weight', 'base_model.encoder.layer.17.output.LayerNorm.bias', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.11.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.7.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.16.attention.self.key.weight', 'base_model.encoder.layer.20.output.LayerNorm.bias', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.13.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.12.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.14.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.16.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.1.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.5.attention.self.key.weight', 'base_model.encoder.layer.17.attention.self.value.weight', 'base_model.encoder.layer.20.attention.self.key.bias', 'base_model.encoder.layer.9.attention.output.dense.bias', 'base_model.encoder.layer.18.attention.self.query.weight', 'base_model.encoder.layer.17.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.21.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.4.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.13.attention.self.query.weight', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.14.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.13.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.0.attention.self.value.bias', 'base_model.encoder.layer.0.attention.output.LayerNorm.weight', 'base_model.encoder.layer.23.attention.self.value.bias', 'base_model.encoder.layer.5.attention.self.value.weight', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.4.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.1.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.8.attention.output.dense.weight', 'base_model.encoder.layer.1.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.0.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.18.intermediate.dense.bias', 'base_model.encoder.layer.17.attention.output.LayerNorm.weight', 'base_model.encoder.layer.17.output.LayerNorm.weight', 'base_model.encoder.layer.23.output.LayerNorm.weight', 'base_model.encoder.layer.6.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.20.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.14.attention.self.query.weight', 'base_model.encoder.layer.1.attention.self.query.bias', 'base_model.encoder.layer.23.intermediate.dense.weight', 'base_model.encoder.layer.15.output.LayerNorm.weight', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.9.intermediate.dense.weight', 'base_model.encoder.layer.7.attention.output.dense.bias', 'base_model.encoder.layer.19.attention.output.dense.bias', 'base_model.encoder.layer.19.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.2.attention.output.LayerNorm.weight', 'base_model.encoder.layer.6.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.0.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.8.intermediate.dense.bias', 'base_model.encoder.layer.21.output.dense.weight', 'base_model.encoder.layer.8.output.dense.bias', 'base_model.encoder.layer.10.attention.output.LayerNorm.weight', 'base_model.encoder.layer.16.attention.output.LayerNorm.bias', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.18.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.17.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.7.intermediate.dense.bias', 'base_model.encoder.layer.23.attention.output.LayerNorm.bias', 'base_model.encoder.layer.10.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.6.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.15.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.22.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.20.attention.output.dense.bias', 'base_model.encoder.layer.8.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.3.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.13.output.dense.bias', 'base_model.encoder.layer.23.attention.self.query.weight', 'base_model.encoder.layer.5.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.13.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.23.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.19.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.1.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.0.output.dense.bias', 'base_model.encoder.layer.17.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.16.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.7.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.5.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.10.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.2.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.4.attention.self.value.weight', 'base_model.encoder.layer.10.output.adapters.ts.adapter_down.0.bias', 'base_model.pooler.dense.bias', 'base_model.encoder.layer.12.output.dense.bias', 'base_model.encoder.layer.4.intermediate.dense.bias', 'base_model.encoder.layer.14.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.3.attention.self.key.bias', 'base_model.encoder.layer.21.output.LayerNorm.bias', 'base_model.encoder.layer.6.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.0.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.18.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.8.attention.output.LayerNorm.weight', 'base_model.encoder.layer.12.attention.output.LayerNorm.bias', 'base_model.encoder.layer.18.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.6.attention.self.query.bias', 'base_model.encoder.layer.10.attention.self.value.weight', 'base_model.encoder.layer.15.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.17.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.7.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.1.attention.output.dense.bias', 'base_model.encoder.layer.14.attention.self.value.weight', 'base_model.encoder.layer.21.attention.self.key.weight', 'base_model.encoder.layer.7.attention.self.key.bias', 'base_model.encoder.layer.23.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.5.attention.output.dense.bias', 'base_model.encoder.layer.12.intermediate.dense.bias', 'base_model.embeddings.position_embeddings.weight', 'base_model.encoder.layer.0.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.10.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.23.attention.output.dense.bias', 'base_model.encoder.layer.1.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.6.attention.self.value.weight', 'base_model.encoder.layer.1.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.8.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.21.output.dense.bias', 'base_model.encoder.layer.17.attention.self.key.weight', 'base_model.encoder.layer.15.attention.self.query.weight', 'base_model.encoder.layer.9.attention.self.key.weight', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.19.attention.self.value.weight', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.5.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.7.attention.output.LayerNorm.bias', 'base_model.encoder.layer.9.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.21.output.adapters.tp.adapter_down.0.bias', 'base_model.embeddings.position_ids', 'base_model.encoder.layer.4.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.9.output.dense.bias', 'base_model.encoder.layer.2.output.LayerNorm.bias', 'base_model.encoder.layer.9.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.7.attention.self.key.weight', 'base_model.encoder.layer.13.attention.output.dense.weight', 'base_model.encoder.layer.20.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.9.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.17.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.22.output.dense.weight', 'base_model.encoder.layer.3.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.14.output.LayerNorm.bias', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.2.attention.self.value.weight', 'base_model.encoder.layer.8.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.0.intermediate.dense.weight', 'base_model.encoder.layer.15.intermediate.dense.weight', 'base_model.encoder.layer.21.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.3.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.1.attention.self.query.weight', 'base_model.encoder.layer.7.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.6.attention.self.key.weight', 'base_model.encoder.layer.7.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.4.attention.output.LayerNorm.weight', 'base_model.encoder.layer.21.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.1.attention.output.LayerNorm.bias', 'base_model.encoder.layer.20.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.23.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.6.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.16.attention.output.dense.weight', 'base_model.encoder.layer.12.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.9.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.19.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.14.attention.output.LayerNorm.bias', 'base_model.encoder.layer.0.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.5.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.20.attention.self.value.weight', 'base_model.encoder.layer.21.attention.self.value.bias', 'base_model.encoder.layer.15.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.20.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.10.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.11.output.LayerNorm.weight', 'base_model.encoder.layer.12.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.15.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.13.output.LayerNorm.bias', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.11.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.19.output.dense.bias', 'base_model.encoder.layer.2.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.2.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.16.attention.output.LayerNorm.weight', 'base_model.encoder.layer.2.attention.output.dense.weight', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.23.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.2.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.18.attention.output.LayerNorm.bias', 'base_model.encoder.layer.1.attention.self.key.bias', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.20.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.0.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.18.output.dense.bias', 'base_model.encoder.layer.11.attention.self.key.weight', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.1.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.22.attention.self.query.bias', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.12.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.22.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.9.attention.self.key.bias', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.20.attention.output.LayerNorm.bias', 'base_model.encoder.layer.2.attention.output.LayerNorm.bias', 'base_model.encoder.layer.9.intermediate.dense.bias', 'base_model.encoder.layer.15.output.LayerNorm.bias', 'base_model.encoder.layer.15.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.9.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.10.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.1.output.dense.weight', 'base_model.encoder.layer.5.attention.output.LayerNorm.bias', 'base_model.encoder.layer.7.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.1.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.4.attention.output.dense.weight', 'base_model.encoder.layer.3.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.8.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.16.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.23.output.dense.weight', 'base_model.encoder.layer.18.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.4.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.11.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.23.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.2.intermediate.dense.bias', 'base_model.encoder.layer.11.attention.self.query.weight', 'base_model.encoder.layer.4.attention.self.key.bias', 'base_model.encoder.layer.21.attention.output.dense.bias', 'base_model.encoder.layer.22.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.8.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.16.output.LayerNorm.bias', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.4.attention.self.query.weight', 'base_model.encoder.layer.16.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.17.attention.self.value.bias', 'base_model.encoder.layer.10.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.16.attention.self.query.weight', 'base_model.encoder.layer.7.attention.self.value.weight', 'base_model.encoder.layer.12.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.23.attention.output.dense.weight', 'base_model.encoder.layer.7.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.8.attention.self.value.bias', 'base_model.encoder.layer.7.attention.self.query.bias', 'base_model.encoder.layer.17.output.dense.bias', 'base_model.encoder.layer.20.intermediate.dense.weight', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.17.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.4.attention.self.value.bias', 'base_model.encoder.layer.1.attention.output.dense.weight', 'base_model.encoder.layer.22.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.18.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.4.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.15.intermediate.dense.bias', 'base_model.encoder.layer.23.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.6.attention.output.LayerNorm.bias', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.0.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.8.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.5.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.15.attention.self.key.weight', 'base_model.encoder.layer.19.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.6.output.LayerNorm.bias', 'base_model.encoder.layer.6.output.dense.weight', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.22.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.1.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.22.attention.output.LayerNorm.bias', 'base_model.encoder.layer.5.intermediate.dense.weight', 'base_model.encoder.layer.13.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.17.intermediate.dense.bias', 'base_model.encoder.layer.9.attention.self.value.weight', 'base_model.encoder.layer.11.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.13.intermediate.dense.weight', 'base_model.encoder.layer.4.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.5.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.8.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.19.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.7.output.LayerNorm.bias', 'base_model.encoder.layer.1.intermediate.dense.bias', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.22.output.LayerNorm.bias', 'base_model.encoder.layer.19.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.20.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.5.attention.self.value.bias', 'base_model.encoder.layer.16.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.3.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.12.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.3.intermediate.dense.bias', 'base_model.encoder.layer.8.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.0.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.9.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.5.attention.self.query.weight', 'base_model.encoder.layer.12.attention.self.key.bias', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.20.attention.self.query.weight', 'base_model.encoder.layer.3.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.23.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.14.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.11.output.LayerNorm.bias', 'base_model.encoder.layer.11.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.8.attention.self.query.bias', 'base_model.encoder.layer.7.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.21.attention.self.query.bias', 'base_model.encoder.layer.1.attention.self.value.weight', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.14.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.21.attention.self.value.weight', 'base_model.encoder.layer.19.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.8.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.0.attention.self.key.bias', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.8.attention.self.query.weight', 'base_model.encoder.layer.19.attention.output.dense.weight', 'base_model.encoder.layer.3.attention.self.key.weight', 'base_model.encoder.layer.17.attention.output.dense.bias', 'base_model.encoder.layer.14.attention.output.LayerNorm.weight', 'base_model.encoder.layer.4.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.12.attention.output.dense.weight', 'base_model.encoder.layer.18.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.7.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.6.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.embeddings.token_type_embeddings.weight', 'base_model.encoder.layer.23.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.20.attention.self.key.weight', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.19.output.LayerNorm.weight', 'base_model.encoder.layer.20.intermediate.dense.bias', 'base_model.encoder.layer.15.attention.self.key.bias', 'base_model.encoder.layer.13.output.LayerNorm.weight', 'base_model.encoder.layer.3.attention.self.query.weight', 'base_model.encoder.layer.5.attention.self.query.bias', 'base_model.encoder.layer.7.attention.self.value.bias', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.embeddings.LayerNorm.bias', 'base_model.encoder.layer.18.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.10.output.dense.bias', 'base_model.encoder.layer.6.intermediate.dense.bias', 'base_model.encoder.layer.18.output.LayerNorm.bias', 'base_model.encoder.layer.15.output.dense.bias', 'base_model.encoder.layer.9.attention.self.query.weight', 'base_model.encoder.layer.11.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.18.intermediate.dense.weight']
- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of XLMRobertaModel were not initialized from the model checkpoint at /cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//squad/xlm-KG_LR4e-5_EPOCH2.0_maxlen384_batchsize4_gradacc8 and are newly initialized: ['encoder.layer.6.attention.self.key.weight', 'encoder.layer.2.attention.self.query.weight', 'encoder.layer.4.attention.self.key.weight', 'encoder.layer.16.attention.self.value.weight', 'encoder.layer.23.attention.self.key.weight', 'encoder.layer.5.attention.self.value.weight', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.1.attention.self.query.weight', 'encoder.layer.21.attention.self.query.bias', 'encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.21.intermediate.dense.weight', 'encoder.layer.3.attention.self.query.weight', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.8.attention.self.query.bias', 'encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.layer.21.attention.output.LayerNorm.weight', 'encoder.layer.14.attention.self.query.bias', 'encoder.layer.12.attention.output.dense.weight', 'encoder.layer.17.attention.output.dense.bias', 'encoder.layer.6.output.dense.bias', 'encoder.layer.15.attention.output.LayerNorm.weight', 'encoder.layer.19.output.LayerNorm.weight', 'encoder.layer.22.output.LayerNorm.bias', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.11.attention.output.dense.weight', 'encoder.layer.14.output.LayerNorm.weight', 'encoder.layer.23.intermediate.dense.weight', 'encoder.layer.2.attention.self.key.bias', 'encoder.layer.7.attention.output.dense.bias', 'encoder.layer.5.output.LayerNorm.bias', 'encoder.layer.14.attention.self.key.weight', 'encoder.layer.20.output.LayerNorm.bias', 'encoder.layer.10.attention.self.key.weight', 'encoder.layer.22.intermediate.dense.bias', 'encoder.layer.12.attention.self.query.weight', 'encoder.layer.13.attention.self.key.bias', 'encoder.layer.13.attention.output.LayerNorm.weight', 'encoder.layer.10.output.LayerNorm.weight', 'encoder.layer.9.output.LayerNorm.weight', 'encoder.layer.9.attention.output.dense.bias', 'encoder.layer.15.output.dense.bias', 'encoder.layer.3.attention.self.key.bias', 'encoder.layer.15.attention.output.dense.bias', 'encoder.layer.11.attention.self.key.weight', 'encoder.layer.0.output.dense.bias', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.17.output.dense.bias', 'encoder.layer.16.output.LayerNorm.bias', 'encoder.layer.22.output.LayerNorm.weight', 'encoder.layer.18.output.dense.bias', 'encoder.layer.20.attention.output.dense.bias', 'encoder.layer.4.intermediate.dense.weight', 'pooler.dense.bias', 'encoder.layer.1.output.dense.bias', 'encoder.layer.13.attention.output.dense.bias', 'encoder.layer.11.output.LayerNorm.bias', 'encoder.layer.23.attention.self.value.bias', 'encoder.layer.21.attention.output.dense.weight', 'encoder.layer.0.output.dense.weight', 'encoder.layer.3.output.dense.bias', 'encoder.layer.21.intermediate.dense.bias', 'encoder.layer.16.attention.self.query.weight', 'encoder.layer.1.attention.output.LayerNorm.weight', 'encoder.layer.9.attention.output.LayerNorm.bias', 'encoder.layer.7.attention.self.value.bias', 'embeddings.word_embeddings.weight', 'encoder.layer.16.attention.output.dense.weight', 'encoder.layer.16.output.dense.weight', 'encoder.layer.19.attention.output.dense.bias', 'encoder.layer.7.attention.self.key.weight', 'encoder.layer.18.output.dense.weight', 'encoder.layer.17.attention.self.key.bias', 'encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.layer.16.attention.output.LayerNorm.bias', 'encoder.layer.15.attention.output.dense.weight', 'encoder.layer.21.attention.output.LayerNorm.bias', 'encoder.layer.5.attention.output.LayerNorm.weight', 'encoder.layer.19.attention.self.key.weight', 'encoder.layer.19.intermediate.dense.bias', 'encoder.layer.19.attention.output.LayerNorm.weight', 'encoder.layer.23.attention.output.LayerNorm.bias', 'encoder.layer.17.attention.self.query.weight', 'encoder.layer.8.attention.output.LayerNorm.bias', 'encoder.layer.8.attention.self.value.bias', 'encoder.layer.2.output.dense.weight', 'encoder.layer.23.attention.output.dense.bias', 'encoder.layer.0.attention.self.query.bias', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.15.attention.self.value.weight', 'encoder.layer.4.attention.self.query.bias', 'encoder.layer.14.attention.output.dense.weight', 'encoder.layer.15.intermediate.dense.bias', 'encoder.layer.20.output.LayerNorm.weight', 'encoder.layer.9.attention.output.LayerNorm.weight', 'encoder.layer.0.attention.self.key.weight', 'encoder.layer.12.output.LayerNorm.bias', 'encoder.layer.14.attention.output.dense.bias', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.4.attention.output.dense.weight', 'encoder.layer.4.attention.output.dense.bias', 'encoder.layer.22.intermediate.dense.weight', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.13.output.LayerNorm.bias', 'encoder.layer.6.attention.self.value.weight', 'encoder.layer.5.output.dense.bias', 'encoder.layer.15.attention.self.value.bias', 'encoder.layer.17.attention.self.value.weight', 'encoder.layer.18.intermediate.dense.bias', 'encoder.layer.3.attention.self.value.weight', 'encoder.layer.21.output.LayerNorm.bias', 'encoder.layer.13.attention.self.query.weight', 'encoder.layer.17.output.LayerNorm.weight', 'encoder.layer.1.output.dense.weight', 'encoder.layer.5.attention.self.key.bias', 'encoder.layer.16.output.LayerNorm.weight', 'encoder.layer.20.output.dense.bias', 'encoder.layer.21.attention.self.value.bias', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.2.attention.self.key.weight', 'encoder.layer.9.output.dense.bias', 'encoder.layer.10.attention.output.LayerNorm.bias', 'encoder.layer.1.attention.self.value.bias', 'encoder.layer.12.attention.output.LayerNorm.weight', 'encoder.layer.2.attention.output.dense.weight', 'encoder.layer.14.intermediate.dense.weight', 'encoder.layer.0.attention.self.value.weight', 'encoder.layer.10.output.LayerNorm.bias', 'encoder.layer.23.intermediate.dense.bias', 'encoder.layer.9.attention.output.dense.weight', 'encoder.layer.18.output.LayerNorm.weight', 'encoder.layer.6.attention.output.dense.weight', 'encoder.layer.21.attention.self.value.weight', 'encoder.layer.16.attention.self.key.bias', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.13.attention.self.query.bias', 'encoder.layer.18.attention.output.LayerNorm.bias', 'encoder.layer.23.attention.output.LayerNorm.weight', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.15.attention.self.query.bias', 'encoder.layer.14.output.LayerNorm.bias', 'encoder.layer.18.attention.self.query.weight', 'encoder.layer.21.output.LayerNorm.weight', 'encoder.layer.14.intermediate.dense.bias', 'encoder.layer.5.attention.self.key.weight', 'encoder.layer.2.attention.output.dense.bias', 'encoder.layer.14.output.dense.bias', 'encoder.layer.23.attention.output.dense.weight', 'encoder.layer.7.output.LayerNorm.bias', 'encoder.layer.20.attention.self.value.bias', 'encoder.layer.1.attention.output.dense.bias', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.12.attention.self.value.bias', 'encoder.layer.6.attention.self.query.bias', 'encoder.layer.11.attention.self.query.bias', 'encoder.layer.19.attention.output.dense.weight', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.11.attention.self.query.weight', 'encoder.layer.13.output.dense.weight', 'encoder.layer.15.intermediate.dense.weight', 'encoder.layer.18.attention.output.dense.bias', 'encoder.layer.9.attention.self.query.weight', 'encoder.layer.8.attention.output.LayerNorm.weight', 'encoder.layer.12.intermediate.dense.weight', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.8.attention.output.dense.bias', 'encoder.layer.17.attention.output.LayerNorm.weight', 'encoder.layer.10.intermediate.dense.weight', 'encoder.layer.5.output.dense.weight', 'encoder.layer.12.attention.self.key.weight', 'encoder.layer.17.intermediate.dense.weight', 'encoder.layer.18.output.LayerNorm.bias', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.17.attention.self.query.bias', 'encoder.layer.7.attention.self.query.bias', 'encoder.layer.4.attention.output.LayerNorm.bias', 'encoder.layer.17.output.LayerNorm.bias', 'encoder.layer.8.output.LayerNorm.bias', 'encoder.layer.13.attention.self.key.weight', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.22.attention.self.query.weight', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.10.attention.self.query.bias', 'encoder.layer.13.intermediate.dense.weight', 'encoder.layer.21.attention.self.key.weight', 'encoder.layer.18.attention.self.value.bias', 'encoder.layer.7.output.dense.weight', 'encoder.layer.15.output.LayerNorm.weight', 'encoder.layer.6.attention.self.query.weight', 'encoder.layer.21.output.dense.weight', 'encoder.layer.22.attention.self.key.weight', 'encoder.layer.18.attention.output.LayerNorm.weight', 'encoder.layer.1.attention.self.query.bias', 'encoder.layer.22.attention.output.dense.weight', 'encoder.layer.12.attention.output.LayerNorm.bias', 'encoder.layer.4.output.dense.weight', 'encoder.layer.11.attention.output.LayerNorm.weight', 'encoder.layer.0.attention.output.dense.weight', 'encoder.layer.7.attention.output.LayerNorm.bias', 'embeddings.LayerNorm.bias', 'encoder.layer.8.output.dense.weight', 'encoder.layer.5.attention.self.query.weight', 'encoder.layer.9.attention.self.value.bias', 'encoder.layer.19.attention.self.value.bias', 'encoder.layer.7.attention.self.value.weight', 'encoder.layer.6.attention.self.key.bias', 'encoder.layer.20.attention.self.key.weight', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.23.attention.self.query.weight', 'encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.layer.20.attention.output.LayerNorm.weight', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.14.attention.self.key.bias', 'encoder.layer.23.attention.self.query.bias', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.layer.23.attention.self.value.weight', 'encoder.layer.2.output.dense.bias', 'encoder.layer.14.attention.self.value.bias', 'encoder.layer.12.attention.output.dense.bias', 'encoder.layer.21.attention.self.key.bias', 'encoder.layer.19.output.dense.bias', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.16.attention.self.query.bias', 'encoder.layer.3.output.dense.weight', 'encoder.layer.19.output.dense.weight', 'encoder.layer.20.attention.self.query.weight', 'encoder.layer.4.attention.self.key.bias', 'encoder.layer.22.output.dense.weight', 'encoder.layer.7.attention.output.dense.weight', 'encoder.layer.22.attention.self.value.weight', 'encoder.layer.1.attention.self.value.weight', 'encoder.layer.16.attention.self.key.weight', 'encoder.layer.7.attention.self.key.bias', 'encoder.layer.8.output.LayerNorm.weight', 'encoder.layer.11.attention.self.key.bias', 'encoder.layer.16.attention.self.value.bias', 'encoder.layer.1.attention.output.dense.weight', 'encoder.layer.11.output.LayerNorm.weight', 'encoder.layer.22.attention.output.LayerNorm.bias', 'encoder.layer.13.output.LayerNorm.weight', 'encoder.layer.16.intermediate.dense.bias', 'encoder.layer.16.attention.output.dense.bias', 'encoder.layer.5.attention.self.value.bias', 'encoder.layer.5.attention.output.dense.bias', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.18.attention.self.value.weight', 'encoder.layer.3.attention.output.dense.bias', 'encoder.layer.5.attention.output.dense.weight', 'encoder.layer.21.output.dense.bias', 'encoder.layer.3.attention.self.query.bias', 'encoder.layer.2.attention.output.LayerNorm.bias', 'encoder.layer.15.output.dense.weight', 'pooler.dense.weight', 'encoder.layer.15.attention.output.LayerNorm.bias', 'encoder.layer.17.attention.output.dense.weight', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.7.attention.self.query.weight', 'encoder.layer.13.attention.self.value.bias', 'encoder.layer.13.attention.output.LayerNorm.bias', 'encoder.layer.0.attention.self.query.weight', 'encoder.layer.10.output.dense.weight', 'encoder.layer.7.output.LayerNorm.weight', 'encoder.layer.5.attention.self.query.bias', 'encoder.layer.3.attention.self.value.bias', 'encoder.layer.23.output.dense.bias', 'encoder.layer.10.attention.self.value.weight', 'encoder.layer.15.attention.self.key.weight', 'encoder.layer.8.attention.self.value.weight', 'encoder.layer.4.output.dense.bias', 'encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.layer.19.attention.self.value.weight', 'encoder.layer.0.attention.self.value.bias', 'encoder.layer.12.attention.self.key.bias', 'encoder.layer.22.attention.self.query.bias', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.16.intermediate.dense.weight', 'encoder.layer.6.attention.self.value.bias', 'encoder.layer.6.attention.output.dense.bias', 'encoder.layer.11.attention.output.dense.bias', 'encoder.layer.14.attention.output.LayerNorm.bias', 'encoder.layer.21.attention.self.query.weight', 'encoder.layer.12.intermediate.dense.bias', 'encoder.layer.7.intermediate.dense.bias', 'encoder.layer.19.attention.self.query.weight', 'embeddings.position_embeddings.weight', 'encoder.layer.20.attention.self.value.weight', 'encoder.layer.6.output.LayerNorm.bias', 'encoder.layer.18.attention.output.dense.weight', 'encoder.layer.13.intermediate.dense.bias', 'encoder.layer.14.attention.self.value.weight', 'encoder.layer.19.attention.self.key.bias', 'encoder.layer.12.attention.self.query.bias', 'encoder.layer.15.attention.self.query.weight', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.22.attention.output.LayerNorm.weight', 'encoder.layer.0.attention.output.LayerNorm.weight', 'encoder.layer.10.attention.self.key.bias', 'encoder.layer.10.attention.self.query.weight', 'embeddings.token_type_embeddings.weight', 'encoder.layer.10.output.dense.bias', 'encoder.layer.8.attention.self.query.weight', 'encoder.layer.6.attention.output.LayerNorm.bias', 'encoder.layer.9.attention.self.query.bias', 'encoder.layer.15.attention.self.key.bias', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.6.attention.output.LayerNorm.weight', 'embeddings.LayerNorm.weight', 'encoder.layer.4.attention.self.value.weight', 'encoder.layer.15.output.LayerNorm.bias', 'encoder.layer.18.attention.self.key.bias', 'encoder.layer.20.attention.self.query.bias', 'encoder.layer.7.output.dense.bias', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.14.attention.self.query.weight', 'encoder.layer.4.attention.self.query.weight', 'encoder.layer.23.output.dense.weight', 'encoder.layer.2.attention.self.value.weight', 'encoder.layer.11.attention.self.value.weight', 'encoder.layer.22.attention.self.value.bias', 'encoder.layer.13.attention.output.dense.weight', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.13.output.dense.bias', 'encoder.layer.17.output.dense.weight', 'encoder.layer.1.attention.self.key.weight', 'encoder.layer.12.attention.self.value.weight', 'encoder.layer.11.output.dense.bias', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.11.output.dense.weight', 'encoder.layer.10.attention.output.dense.bias', 'encoder.layer.23.attention.self.key.bias', 'encoder.layer.3.attention.self.key.weight', 'encoder.layer.19.intermediate.dense.weight', 'encoder.layer.19.attention.self.query.bias', 'encoder.layer.10.attention.output.LayerNorm.weight', 'encoder.layer.3.attention.output.dense.weight', 'encoder.layer.10.attention.output.dense.weight', 'encoder.layer.20.attention.self.key.bias', 'encoder.layer.2.attention.output.LayerNorm.weight', 'encoder.layer.9.attention.self.key.weight', 'encoder.layer.20.intermediate.dense.weight', 'encoder.layer.12.output.dense.bias', 'encoder.layer.9.attention.self.value.weight', 'encoder.layer.22.attention.self.key.bias', 'encoder.layer.18.intermediate.dense.weight', 'encoder.layer.7.attention.output.LayerNorm.weight', 'encoder.layer.20.attention.output.LayerNorm.bias', 'encoder.layer.12.output.LayerNorm.weight', 'encoder.layer.8.attention.self.key.bias', 'encoder.layer.23.output.LayerNorm.weight', 'encoder.layer.8.attention.self.key.weight', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.2.attention.self.query.bias', 'encoder.layer.16.attention.output.LayerNorm.weight', 'encoder.layer.18.attention.self.query.bias', 'encoder.layer.20.intermediate.dense.bias', 'encoder.layer.20.output.dense.weight', 'encoder.layer.16.output.dense.bias', 'encoder.layer.19.attention.output.LayerNorm.bias', 'encoder.layer.23.output.LayerNorm.bias', 'encoder.layer.0.attention.self.key.bias', 'encoder.layer.1.attention.self.key.bias', 'encoder.layer.0.attention.output.dense.bias', 'encoder.layer.6.output.dense.weight', 'encoder.layer.14.output.dense.weight', 'encoder.layer.17.intermediate.dense.bias', 'encoder.layer.17.attention.output.LayerNorm.bias', 'encoder.layer.13.attention.self.value.weight', 'encoder.layer.9.output.LayerNorm.bias', 'encoder.layer.20.attention.output.dense.weight', 'encoder.layer.17.attention.self.value.bias', 'encoder.layer.12.output.dense.weight', 'encoder.layer.10.attention.self.value.bias', 'encoder.layer.19.output.LayerNorm.bias', 'encoder.layer.22.output.dense.bias', 'encoder.layer.14.attention.output.LayerNorm.weight', 'encoder.layer.2.attention.self.value.bias', 'encoder.layer.8.attention.output.dense.weight', 'encoder.layer.4.attention.self.value.bias', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.4.attention.output.LayerNorm.weight', 'encoder.layer.9.attention.self.key.bias', 'encoder.layer.11.attention.self.value.bias', 'encoder.layer.22.attention.output.dense.bias', 'encoder.layer.17.attention.self.key.weight', 'encoder.layer.9.output.dense.weight', 'encoder.layer.21.attention.output.dense.bias', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.8.output.dense.bias', 'encoder.layer.18.attention.self.key.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Overwriting existing adapter 'ep'.
Overwriting existing adapter 'tp'.
Overwriting existing adapter 'es'.
Overwriting existing adapter 'ts'.
Overwriting existing adapter fusion module 'ep,tp,es,ts'
05/09/2022 20:04:56 - INFO - __main__ -   lang2id = None
05/09/2022 20:05:00 - INFO - __main__ -   Training/evaluation parameters Namespace(adam_epsilon=1e-08, cache_dir='', config_name='', data_dir=None, device=device(type='cuda'), do_eval=True, do_lower_case=False, do_train=False, doc_stride=128, eval_all_checkpoints=False, eval_lang='ar', evaluate_during_training=False, fp16=False, fp16_opt_level='O1', gradient_accumulation_steps=1, learning_rate=5e-05, local_rank=-1, logging_steps=50, max_answer_length=30, max_grad_norm=1.0, max_query_length=64, max_seq_length=384, max_steps=-1, model_name='xlm-KG', model_name_or_path='/cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//squad/xlm-KG_LR4e-5_EPOCH2.0_maxlen384_batchsize4_gradacc8', model_type='xlm', modelkg_dir='/cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/adapter/xlmr_adapter', n_best_size=20, n_gpu=1, no_cuda=False, null_score_diff_threshold=0.0, num_train_epochs=3.0, output_dir='/cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//squad/xlm-KG_LR4e-5_EPOCH2.0_maxlen384_batchsize4_gradacc8/predictions/xquad/', overwrite_cache=False, overwrite_output_dir=False, per_gpu_eval_batch_size=8, per_gpu_train_batch_size=8, predict_file='/cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/download//xquad//xquad.ar.json', save_steps=50, seed=42, server_ip='', server_port='', threads=1, tokenizer_name='', train_file=None, train_lang='en', verbose_logging=False, version_2_with_negative=False, warmup_steps=0, weight_decay=0.0)
05/09/2022 20:05:00 - INFO - __main__ -   Loading checkpoint /cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//squad/xlm-KG_LR4e-5_EPOCH2.0_maxlen384_batchsize4_gradacc8 for evaluation
05/09/2022 20:05:00 - INFO - __main__ -   Evaluate the following checkpoints: ['/cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//squad/xlm-KG_LR4e-5_EPOCH2.0_maxlen384_batchsize4_gradacc8']
Some weights of the model checkpoint at /cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//squad/xlm-KG_LR4e-5_EPOCH2.0_maxlen384_batchsize4_gradacc8 were not used when initializing XLMRobertaModel: ['base_model.encoder.layer.5.output.dense.weight', 'base_model.encoder.layer.7.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.14.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.4.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.14.intermediate.dense.bias', 'base_model.encoder.layer.9.attention.output.LayerNorm.bias', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.16.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.10.output.LayerNorm.weight', 'base_model.encoder.layer.21.attention.self.key.bias', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.22.intermediate.dense.bias', 'base_model.encoder.layer.2.attention.self.value.bias', 'qa_outputs.bias', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.2.attention.self.query.bias', 'base_model.encoder.layer.21.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.20.attention.output.dense.weight', 'base_model.encoder.layer.0.attention.output.dense.bias', 'base_model.encoder.layer.2.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.13.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.0.output.LayerNorm.bias', 'base_model.encoder.layer.10.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.21.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.2.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.8.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.21.attention.output.dense.weight', 'base_model.encoder.layer.9.output.LayerNorm.bias', 'base_model.encoder.layer.2.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.17.attention.output.LayerNorm.bias', 'base_model.encoder.layer.22.attention.self.key.weight', 'base_model.encoder.layer.12.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.16.output.dense.bias', 'base_model.encoder.layer.13.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.18.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.13.attention.output.dense.bias', 'base_model.encoder.layer.19.output.LayerNorm.bias', 'base_model.encoder.layer.2.intermediate.dense.weight', 'base_model.encoder.layer.7.attention.output.dense.weight', 'base_model.encoder.layer.4.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.23.output.dense.bias', 'base_model.encoder.layer.10.attention.self.value.bias', 'base_model.encoder.layer.21.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.22.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.15.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.21.attention.output.LayerNorm.bias', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.15.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.15.attention.output.LayerNorm.weight', 'base_model.encoder.layer.14.attention.output.dense.weight', 'base_model.encoder.layer.8.attention.self.value.weight', 'base_model.encoder.layer.0.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.1.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.12.attention.self.value.weight', 'base_model.encoder.layer.5.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.15.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.11.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.4.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.11.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.4.attention.self.key.weight', 'base_model.encoder.layer.17.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.16.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.2.output.LayerNorm.weight', 'base_model.encoder.layer.1.attention.self.key.weight', 'base_model.encoder.layer.0.attention.self.key.weight', 'base_model.encoder.layer.5.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.15.attention.output.dense.bias', 'base_model.encoder.layer.4.output.LayerNorm.bias', 'base_model.encoder.layer.6.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.13.intermediate.dense.bias', 'base_model.encoder.layer.12.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.10.output.dense.weight', 'base_model.encoder.layer.23.intermediate.dense.bias', 'base_model.encoder.layer.1.intermediate.dense.weight', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.9.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.7.attention.self.query.weight', 'base_model.encoder.layer.13.attention.self.query.bias', 'base_model.encoder.layer.12.attention.output.LayerNorm.weight', 'base_model.encoder.layer.3.output.LayerNorm.bias', 'base_model.encoder.layer.20.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.3.attention.output.dense.bias', 'base_model.encoder.layer.17.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.9.output.dense.weight', 'base_model.encoder.layer.8.attention.output.LayerNorm.bias', 'base_model.encoder.layer.4.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.0.output.dense.weight', 'base_model.encoder.layer.7.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.16.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.1.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.13.attention.output.LayerNorm.bias', 'base_model.encoder.layer.23.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.15.output.dense.weight', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.7.output.dense.weight', 'base_model.encoder.layer.21.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.5.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.10.attention.output.dense.bias', 'base_model.encoder.layer.3.attention.self.value.weight', 'base_model.encoder.layer.21.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.9.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.11.intermediate.dense.weight', 'base_model.encoder.layer.5.attention.output.dense.weight', 'base_model.encoder.layer.14.attention.self.value.bias', 'base_model.encoder.layer.12.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.14.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.23.output.LayerNorm.bias', 'base_model.encoder.layer.13.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.4.attention.self.query.bias', 'base_model.encoder.layer.23.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.16.intermediate.dense.weight', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.21.intermediate.dense.bias', 'base_model.encoder.layer.4.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.8.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.9.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.22.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.13.attention.output.LayerNorm.weight', 'base_model.encoder.layer.23.attention.self.key.bias', 'base_model.encoder.layer.23.attention.self.value.weight', 'base_model.encoder.layer.9.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.21.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.22.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.23.attention.self.query.bias', 'base_model.encoder.layer.13.attention.self.key.weight', 'base_model.encoder.layer.18.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.17.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.3.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.2.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.3.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.2.attention.self.key.weight', 'base_model.encoder.layer.20.output.dense.weight', 'base_model.encoder.layer.17.attention.self.query.bias', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.8.output.LayerNorm.bias', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.12.attention.self.query.weight', 'base_model.encoder.layer.23.attention.output.LayerNorm.weight', 'base_model.pooler.dense.weight', 'base_model.encoder.layer.8.attention.output.dense.bias', 'base_model.encoder.layer.8.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.12.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.20.output.LayerNorm.weight', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.18.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.18.attention.self.value.weight', 'base_model.encoder.layer.9.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.22.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.9.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.9.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.6.output.LayerNorm.weight', 'base_model.encoder.layer.14.attention.self.query.bias', 'base_model.encoder.layer.18.attention.self.key.weight', 'base_model.encoder.layer.18.output.dense.weight', 'base_model.encoder.layer.23.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.2.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.15.attention.self.value.bias', 'base_model.embeddings.word_embeddings.weight', 'base_model.encoder.layer.2.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.16.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.20.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.10.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.21.attention.output.LayerNorm.weight', 'base_model.encoder.layer.17.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.8.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.0.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.13.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.22.attention.self.value.weight', 'base_model.encoder.layer.22.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.16.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.2.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.6.intermediate.dense.weight', 'base_model.encoder.layer.18.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.16.attention.self.query.bias', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.7.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.5.output.LayerNorm.weight', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.17.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.21.output.LayerNorm.weight', 'base_model.encoder.layer.22.attention.output.dense.weight', 'base_model.encoder.layer.13.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.16.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.2.output.dense.weight', 'base_model.encoder.layer.3.attention.output.dense.weight', 'base_model.encoder.layer.22.intermediate.dense.weight', 'base_model.encoder.layer.1.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.19.attention.self.key.weight', 'base_model.encoder.layer.20.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.22.attention.self.key.bias', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.17.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.12.output.dense.weight', 'base_model.encoder.layer.21.attention.self.query.weight', 'base_model.encoder.layer.21.intermediate.dense.weight', 'base_model.encoder.layer.13.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.4.output.dense.weight', 'base_model.encoder.layer.4.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.14.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.3.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.17.attention.self.query.weight', 'base_model.encoder.layer.8.attention.self.key.weight', 'base_model.encoder.layer.11.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.2.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.14.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.12.attention.self.query.bias', 'base_model.encoder.layer.10.attention.self.key.weight', 'base_model.encoder.layer.0.attention.output.LayerNorm.bias', 'base_model.encoder.layer.22.output.dense.bias', 'base_model.encoder.layer.0.attention.self.query.weight', 'base_model.encoder.layer.2.attention.self.query.weight', 'base_model.encoder.layer.17.intermediate.dense.weight', 'base_model.encoder.layer.15.attention.output.dense.weight', 'base_model.encoder.layer.0.attention.self.query.bias', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.1.attention.self.value.bias', 'base_model.encoder.layer.4.attention.output.LayerNorm.bias', 'base_model.encoder.layer.10.attention.output.dense.weight', 'base_model.encoder.layer.12.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.0.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.2.attention.self.key.bias', 'base_model.encoder.layer.15.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.19.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.21.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.11.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.18.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.2.attention.output.dense.bias', 'base_model.encoder.layer.3.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.19.attention.self.value.bias', 'base_model.encoder.layer.7.output.dense.bias', 'base_model.encoder.layer.0.attention.self.value.weight', 'base_model.encoder.layer.9.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.11.attention.output.dense.weight', 'base_model.encoder.layer.14.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.16.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.12.attention.output.dense.bias', 'base_model.encoder.layer.18.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.22.attention.output.dense.bias', 'base_model.encoder.layer.8.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.22.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.18.attention.self.value.bias', 'base_model.encoder.layer.22.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.6.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.19.attention.output.LayerNorm.bias', 'base_model.encoder.layer.3.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.0.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.6.attention.self.query.weight', 'base_model.encoder.layer.14.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.5.attention.self.key.bias', 'base_model.encoder.layer.18.attention.output.dense.bias', 'base_model.encoder.layer.19.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.19.output.dense.weight', 'base_model.encoder.layer.13.attention.self.value.weight', 'base_model.encoder.layer.3.output.dense.weight', 'base_model.encoder.layer.5.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.6.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.15.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.2.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.14.output.LayerNorm.weight', 'base_model.encoder.layer.16.attention.output.dense.bias', 'base_model.encoder.layer.18.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.1.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.2.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.5.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.16.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.20.attention.self.query.bias', 'base_model.encoder.layer.5.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.7.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.6.attention.self.key.bias', 'base_model.encoder.layer.3.output.LayerNorm.weight', 'base_model.encoder.layer.14.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.4.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.23.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.6.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.16.intermediate.dense.bias', 'base_model.encoder.layer.11.attention.self.value.bias', 'base_model.encoder.layer.5.intermediate.dense.bias', 'base_model.encoder.layer.21.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.4.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.7.attention.output.LayerNorm.weight', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.17.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.3.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.11.attention.output.LayerNorm.bias', 'base_model.encoder.layer.11.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.9.attention.output.LayerNorm.weight', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.12.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.22.attention.self.value.bias', 'base_model.encoder.layer.3.attention.output.LayerNorm.weight', 'base_model.encoder.layer.18.attention.self.key.bias', 'base_model.encoder.layer.2.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.22.output.LayerNorm.weight', 'base_model.encoder.layer.13.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.8.attention.self.key.bias', 'base_model.encoder.layer.6.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.3.attention.self.value.bias', 'base_model.encoder.layer.3.output.dense.bias', 'base_model.encoder.layer.10.attention.output.LayerNorm.bias', 'base_model.encoder.layer.11.attention.output.dense.bias', 'base_model.encoder.layer.19.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.20.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.6.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.14.intermediate.dense.weight', 'base_model.encoder.layer.20.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.4.output.dense.bias', 'base_model.encoder.layer.22.attention.output.LayerNorm.weight', 'base_model.encoder.layer.15.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.6.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.10.attention.self.query.bias', 'base_model.encoder.layer.14.attention.self.key.weight', 'base_model.encoder.layer.15.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.1.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.20.output.dense.bias', 'qa_outputs.weight', 'base_model.encoder.layer.13.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.4.intermediate.dense.weight', 'base_model.encoder.layer.5.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.15.attention.self.value.weight', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.6.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.14.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.17.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.7.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.3.attention.output.LayerNorm.bias', 'base_model.encoder.layer.10.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.18.attention.self.query.bias', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.3.intermediate.dense.weight', 'base_model.encoder.layer.6.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.0.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.0.intermediate.dense.bias', 'base_model.encoder.layer.16.output.LayerNorm.weight', 'base_model.encoder.layer.11.output.dense.weight', 'base_model.encoder.layer.16.attention.self.key.bias', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.8.output.dense.weight', 'base_model.encoder.layer.8.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.12.intermediate.dense.weight', 'base_model.encoder.layer.13.output.dense.weight', 'base_model.encoder.layer.13.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.19.attention.self.key.bias', 'base_model.encoder.layer.22.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.15.attention.self.query.bias', 'base_model.encoder.layer.21.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.15.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.15.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.21.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.10.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.16.output.dense.weight', 'base_model.encoder.layer.19.intermediate.dense.weight', 'base_model.encoder.layer.1.attention.output.LayerNorm.weight', 'base_model.encoder.layer.6.attention.output.dense.bias', 'base_model.encoder.layer.1.output.LayerNorm.weight', 'base_model.encoder.layer.12.output.LayerNorm.weight', 'base_model.encoder.layer.11.intermediate.dense.bias', 'base_model.encoder.layer.0.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.8.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.12.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.14.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.8.intermediate.dense.weight', 'base_model.encoder.layer.10.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.3.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.13.attention.self.value.bias', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.23.attention.self.key.weight', 'base_model.encoder.layer.12.attention.self.value.bias', 'base_model.encoder.layer.6.attention.output.dense.weight', 'base_model.encoder.layer.11.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.12.output.LayerNorm.bias', 'base_model.encoder.layer.15.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.10.output.LayerNorm.bias', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.20.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.15.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.19.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.23.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.0.attention.output.dense.weight', 'base_model.encoder.layer.17.attention.output.dense.weight', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.19.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.1.output.LayerNorm.bias', 'base_model.encoder.layer.16.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.19.intermediate.dense.bias', 'base_model.encoder.layer.14.attention.output.dense.bias', 'base_model.encoder.layer.12.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.20.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.5.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.2.output.dense.bias', 'base_model.encoder.layer.18.attention.output.LayerNorm.weight', 'base_model.encoder.layer.7.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.13.attention.self.key.bias', 'base_model.encoder.layer.6.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.21.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.10.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.17.output.dense.weight', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.17.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.6.attention.self.value.bias', 'base_model.encoder.layer.19.attention.output.LayerNorm.weight', 'base_model.encoder.layer.19.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.9.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.0.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.18.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.14.output.dense.bias', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.20.attention.output.LayerNorm.weight', 'base_model.encoder.layer.20.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.13.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.16.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.10.intermediate.dense.weight', 'base_model.encoder.layer.20.attention.self.value.bias', 'base_model.encoder.layer.23.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.12.attention.self.key.weight', 'base_model.encoder.layer.14.output.adapters.ts.adapter_down.0.bias', 'base_model.embeddings.LayerNorm.weight', 'base_model.encoder.layer.5.output.LayerNorm.bias', 'base_model.encoder.layer.19.attention.self.query.bias', 'base_model.encoder.layer.13.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.6.attention.output.LayerNorm.weight', 'base_model.encoder.layer.19.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.20.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.10.attention.self.query.weight', 'base_model.encoder.layer.1.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.11.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.9.attention.output.dense.weight', 'base_model.encoder.layer.7.output.LayerNorm.weight', 'base_model.encoder.layer.3.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.8.output.LayerNorm.weight', 'base_model.encoder.layer.16.attention.self.value.weight', 'base_model.encoder.layer.1.output.dense.bias', 'base_model.encoder.layer.18.output.LayerNorm.weight', 'base_model.encoder.layer.21.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.18.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.11.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.13.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.17.attention.self.key.bias', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.0.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.10.attention.self.key.bias', 'base_model.encoder.layer.22.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.16.attention.self.value.bias', 'base_model.encoder.layer.14.output.dense.weight', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.19.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.7.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.10.intermediate.dense.bias', 'base_model.encoder.layer.9.output.LayerNorm.weight', 'base_model.encoder.layer.18.attention.output.dense.weight', 'base_model.encoder.layer.7.intermediate.dense.weight', 'base_model.encoder.layer.6.output.dense.bias', 'base_model.encoder.layer.12.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.9.attention.self.value.bias', 'base_model.encoder.layer.9.attention.self.query.bias', 'base_model.encoder.layer.11.output.dense.bias', 'base_model.encoder.layer.0.output.LayerNorm.weight', 'base_model.encoder.layer.4.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.3.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.11.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.15.attention.output.LayerNorm.bias', 'base_model.encoder.layer.19.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.2.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.14.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.4.attention.output.dense.bias', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.22.attention.self.query.weight', 'base_model.encoder.layer.9.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.11.attention.output.LayerNorm.weight', 'base_model.encoder.layer.3.attention.self.query.bias', 'base_model.encoder.layer.22.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.14.attention.self.key.bias', 'base_model.encoder.layer.19.attention.self.query.weight', 'base_model.encoder.layer.11.attention.self.query.bias', 'base_model.encoder.layer.11.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.23.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.20.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.5.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.23.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.5.output.dense.bias', 'base_model.encoder.layer.10.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.5.attention.output.LayerNorm.weight', 'base_model.encoder.layer.1.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.11.attention.self.key.bias', 'base_model.encoder.layer.10.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.10.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.16.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.22.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.3.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.5.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.12.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.4.output.LayerNorm.weight', 'base_model.encoder.layer.17.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.11.attention.self.value.weight', 'base_model.encoder.layer.17.output.LayerNorm.bias', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.11.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.7.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.16.attention.self.key.weight', 'base_model.encoder.layer.20.output.LayerNorm.bias', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.13.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.12.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.14.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.16.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.1.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.5.attention.self.key.weight', 'base_model.encoder.layer.17.attention.self.value.weight', 'base_model.encoder.layer.20.attention.self.key.bias', 'base_model.encoder.layer.9.attention.output.dense.bias', 'base_model.encoder.layer.18.attention.self.query.weight', 'base_model.encoder.layer.17.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.21.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.4.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.13.attention.self.query.weight', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.14.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.13.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.0.attention.self.value.bias', 'base_model.encoder.layer.0.attention.output.LayerNorm.weight', 'base_model.encoder.layer.23.attention.self.value.bias', 'base_model.encoder.layer.5.attention.self.value.weight', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.4.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.1.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.8.attention.output.dense.weight', 'base_model.encoder.layer.1.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.0.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.18.intermediate.dense.bias', 'base_model.encoder.layer.17.attention.output.LayerNorm.weight', 'base_model.encoder.layer.17.output.LayerNorm.weight', 'base_model.encoder.layer.23.output.LayerNorm.weight', 'base_model.encoder.layer.6.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.20.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.14.attention.self.query.weight', 'base_model.encoder.layer.1.attention.self.query.bias', 'base_model.encoder.layer.23.intermediate.dense.weight', 'base_model.encoder.layer.15.output.LayerNorm.weight', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.9.intermediate.dense.weight', 'base_model.encoder.layer.7.attention.output.dense.bias', 'base_model.encoder.layer.19.attention.output.dense.bias', 'base_model.encoder.layer.19.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.2.attention.output.LayerNorm.weight', 'base_model.encoder.layer.6.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.0.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.8.intermediate.dense.bias', 'base_model.encoder.layer.21.output.dense.weight', 'base_model.encoder.layer.8.output.dense.bias', 'base_model.encoder.layer.10.attention.output.LayerNorm.weight', 'base_model.encoder.layer.16.attention.output.LayerNorm.bias', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.18.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.17.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.7.intermediate.dense.bias', 'base_model.encoder.layer.23.attention.output.LayerNorm.bias', 'base_model.encoder.layer.10.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.6.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.15.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.22.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.20.attention.output.dense.bias', 'base_model.encoder.layer.8.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.3.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.13.output.dense.bias', 'base_model.encoder.layer.23.attention.self.query.weight', 'base_model.encoder.layer.5.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.13.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.23.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.19.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.1.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.0.output.dense.bias', 'base_model.encoder.layer.17.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.16.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.7.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.5.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.10.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.2.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.4.attention.self.value.weight', 'base_model.encoder.layer.10.output.adapters.ts.adapter_down.0.bias', 'base_model.pooler.dense.bias', 'base_model.encoder.layer.12.output.dense.bias', 'base_model.encoder.layer.4.intermediate.dense.bias', 'base_model.encoder.layer.14.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.3.attention.self.key.bias', 'base_model.encoder.layer.21.output.LayerNorm.bias', 'base_model.encoder.layer.6.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.0.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.18.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.8.attention.output.LayerNorm.weight', 'base_model.encoder.layer.12.attention.output.LayerNorm.bias', 'base_model.encoder.layer.18.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.6.attention.self.query.bias', 'base_model.encoder.layer.10.attention.self.value.weight', 'base_model.encoder.layer.15.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.17.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.7.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.1.attention.output.dense.bias', 'base_model.encoder.layer.14.attention.self.value.weight', 'base_model.encoder.layer.21.attention.self.key.weight', 'base_model.encoder.layer.7.attention.self.key.bias', 'base_model.encoder.layer.23.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.5.attention.output.dense.bias', 'base_model.encoder.layer.12.intermediate.dense.bias', 'base_model.embeddings.position_embeddings.weight', 'base_model.encoder.layer.0.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.10.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.23.attention.output.dense.bias', 'base_model.encoder.layer.1.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.6.attention.self.value.weight', 'base_model.encoder.layer.1.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.8.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.21.output.dense.bias', 'base_model.encoder.layer.17.attention.self.key.weight', 'base_model.encoder.layer.15.attention.self.query.weight', 'base_model.encoder.layer.9.attention.self.key.weight', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.19.attention.self.value.weight', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.5.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.7.attention.output.LayerNorm.bias', 'base_model.encoder.layer.9.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.21.output.adapters.tp.adapter_down.0.bias', 'base_model.embeddings.position_ids', 'base_model.encoder.layer.4.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.9.output.dense.bias', 'base_model.encoder.layer.2.output.LayerNorm.bias', 'base_model.encoder.layer.9.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.7.attention.self.key.weight', 'base_model.encoder.layer.13.attention.output.dense.weight', 'base_model.encoder.layer.20.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.9.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.17.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.22.output.dense.weight', 'base_model.encoder.layer.3.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.14.output.LayerNorm.bias', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.2.attention.self.value.weight', 'base_model.encoder.layer.8.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.0.intermediate.dense.weight', 'base_model.encoder.layer.15.intermediate.dense.weight', 'base_model.encoder.layer.21.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.3.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.1.attention.self.query.weight', 'base_model.encoder.layer.7.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.6.attention.self.key.weight', 'base_model.encoder.layer.7.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.4.attention.output.LayerNorm.weight', 'base_model.encoder.layer.21.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.1.attention.output.LayerNorm.bias', 'base_model.encoder.layer.20.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.23.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.6.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.16.attention.output.dense.weight', 'base_model.encoder.layer.12.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.9.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.19.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.14.attention.output.LayerNorm.bias', 'base_model.encoder.layer.0.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.5.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.20.attention.self.value.weight', 'base_model.encoder.layer.21.attention.self.value.bias', 'base_model.encoder.layer.15.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.20.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.10.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.11.output.LayerNorm.weight', 'base_model.encoder.layer.12.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.15.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.13.output.LayerNorm.bias', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.11.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.19.output.dense.bias', 'base_model.encoder.layer.2.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.2.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.16.attention.output.LayerNorm.weight', 'base_model.encoder.layer.2.attention.output.dense.weight', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.23.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.2.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.18.attention.output.LayerNorm.bias', 'base_model.encoder.layer.1.attention.self.key.bias', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.20.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.0.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.18.output.dense.bias', 'base_model.encoder.layer.11.attention.self.key.weight', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.1.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.22.attention.self.query.bias', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.12.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.22.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.9.attention.self.key.bias', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.20.attention.output.LayerNorm.bias', 'base_model.encoder.layer.2.attention.output.LayerNorm.bias', 'base_model.encoder.layer.9.intermediate.dense.bias', 'base_model.encoder.layer.15.output.LayerNorm.bias', 'base_model.encoder.layer.15.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.9.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.10.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.1.output.dense.weight', 'base_model.encoder.layer.5.attention.output.LayerNorm.bias', 'base_model.encoder.layer.7.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.1.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.4.attention.output.dense.weight', 'base_model.encoder.layer.3.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.8.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.16.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.23.output.dense.weight', 'base_model.encoder.layer.18.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.4.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.11.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.23.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.2.intermediate.dense.bias', 'base_model.encoder.layer.11.attention.self.query.weight', 'base_model.encoder.layer.4.attention.self.key.bias', 'base_model.encoder.layer.21.attention.output.dense.bias', 'base_model.encoder.layer.22.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.8.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.16.output.LayerNorm.bias', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.4.attention.self.query.weight', 'base_model.encoder.layer.16.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.17.attention.self.value.bias', 'base_model.encoder.layer.10.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.16.attention.self.query.weight', 'base_model.encoder.layer.7.attention.self.value.weight', 'base_model.encoder.layer.12.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.23.attention.output.dense.weight', 'base_model.encoder.layer.7.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.8.attention.self.value.bias', 'base_model.encoder.layer.7.attention.self.query.bias', 'base_model.encoder.layer.17.output.dense.bias', 'base_model.encoder.layer.20.intermediate.dense.weight', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.17.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.4.attention.self.value.bias', 'base_model.encoder.layer.1.attention.output.dense.weight', 'base_model.encoder.layer.22.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.18.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.4.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.15.intermediate.dense.bias', 'base_model.encoder.layer.23.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.6.attention.output.LayerNorm.bias', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.0.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.8.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.5.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.15.attention.self.key.weight', 'base_model.encoder.layer.19.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.6.output.LayerNorm.bias', 'base_model.encoder.layer.6.output.dense.weight', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.22.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.1.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.22.attention.output.LayerNorm.bias', 'base_model.encoder.layer.5.intermediate.dense.weight', 'base_model.encoder.layer.13.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.17.intermediate.dense.bias', 'base_model.encoder.layer.9.attention.self.value.weight', 'base_model.encoder.layer.11.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.13.intermediate.dense.weight', 'base_model.encoder.layer.4.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.5.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.8.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.19.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.7.output.LayerNorm.bias', 'base_model.encoder.layer.1.intermediate.dense.bias', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.22.output.LayerNorm.bias', 'base_model.encoder.layer.19.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.20.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.5.attention.self.value.bias', 'base_model.encoder.layer.16.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.3.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.12.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.3.intermediate.dense.bias', 'base_model.encoder.layer.8.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.0.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.9.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.5.attention.self.query.weight', 'base_model.encoder.layer.12.attention.self.key.bias', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.20.attention.self.query.weight', 'base_model.encoder.layer.3.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.23.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.14.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.11.output.LayerNorm.bias', 'base_model.encoder.layer.11.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.8.attention.self.query.bias', 'base_model.encoder.layer.7.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.21.attention.self.query.bias', 'base_model.encoder.layer.1.attention.self.value.weight', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.14.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.21.attention.self.value.weight', 'base_model.encoder.layer.19.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.8.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.0.attention.self.key.bias', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.8.attention.self.query.weight', 'base_model.encoder.layer.19.attention.output.dense.weight', 'base_model.encoder.layer.3.attention.self.key.weight', 'base_model.encoder.layer.17.attention.output.dense.bias', 'base_model.encoder.layer.14.attention.output.LayerNorm.weight', 'base_model.encoder.layer.4.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.12.attention.output.dense.weight', 'base_model.encoder.layer.18.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.7.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.6.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.embeddings.token_type_embeddings.weight', 'base_model.encoder.layer.23.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.20.attention.self.key.weight', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.19.output.LayerNorm.weight', 'base_model.encoder.layer.20.intermediate.dense.bias', 'base_model.encoder.layer.15.attention.self.key.bias', 'base_model.encoder.layer.13.output.LayerNorm.weight', 'base_model.encoder.layer.3.attention.self.query.weight', 'base_model.encoder.layer.5.attention.self.query.bias', 'base_model.encoder.layer.7.attention.self.value.bias', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.embeddings.LayerNorm.bias', 'base_model.encoder.layer.18.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.10.output.dense.bias', 'base_model.encoder.layer.6.intermediate.dense.bias', 'base_model.encoder.layer.18.output.LayerNorm.bias', 'base_model.encoder.layer.15.output.dense.bias', 'base_model.encoder.layer.9.attention.self.query.weight', 'base_model.encoder.layer.11.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.18.intermediate.dense.weight']
- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of XLMRobertaModel were not initialized from the model checkpoint at /cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//squad/xlm-KG_LR4e-5_EPOCH2.0_maxlen384_batchsize4_gradacc8 and are newly initialized: ['encoder.layer.6.attention.self.key.weight', 'encoder.layer.2.attention.self.query.weight', 'encoder.layer.4.attention.self.key.weight', 'encoder.layer.16.attention.self.value.weight', 'encoder.layer.23.attention.self.key.weight', 'encoder.layer.5.attention.self.value.weight', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.1.attention.self.query.weight', 'encoder.layer.21.attention.self.query.bias', 'encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.21.intermediate.dense.weight', 'encoder.layer.3.attention.self.query.weight', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.8.attention.self.query.bias', 'encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.layer.21.attention.output.LayerNorm.weight', 'encoder.layer.14.attention.self.query.bias', 'encoder.layer.12.attention.output.dense.weight', 'encoder.layer.17.attention.output.dense.bias', 'encoder.layer.6.output.dense.bias', 'encoder.layer.15.attention.output.LayerNorm.weight', 'encoder.layer.19.output.LayerNorm.weight', 'encoder.layer.22.output.LayerNorm.bias', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.11.attention.output.dense.weight', 'encoder.layer.14.output.LayerNorm.weight', 'encoder.layer.23.intermediate.dense.weight', 'encoder.layer.2.attention.self.key.bias', 'encoder.layer.7.attention.output.dense.bias', 'encoder.layer.5.output.LayerNorm.bias', 'encoder.layer.14.attention.self.key.weight', 'encoder.layer.20.output.LayerNorm.bias', 'encoder.layer.10.attention.self.key.weight', 'encoder.layer.22.intermediate.dense.bias', 'encoder.layer.12.attention.self.query.weight', 'encoder.layer.13.attention.self.key.bias', 'encoder.layer.13.attention.output.LayerNorm.weight', 'encoder.layer.10.output.LayerNorm.weight', 'encoder.layer.9.output.LayerNorm.weight', 'encoder.layer.9.attention.output.dense.bias', 'encoder.layer.15.output.dense.bias', 'encoder.layer.3.attention.self.key.bias', 'encoder.layer.15.attention.output.dense.bias', 'encoder.layer.11.attention.self.key.weight', 'encoder.layer.0.output.dense.bias', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.17.output.dense.bias', 'encoder.layer.16.output.LayerNorm.bias', 'encoder.layer.22.output.LayerNorm.weight', 'encoder.layer.18.output.dense.bias', 'encoder.layer.20.attention.output.dense.bias', 'encoder.layer.4.intermediate.dense.weight', 'pooler.dense.bias', 'encoder.layer.1.output.dense.bias', 'encoder.layer.13.attention.output.dense.bias', 'encoder.layer.11.output.LayerNorm.bias', 'encoder.layer.23.attention.self.value.bias', 'encoder.layer.21.attention.output.dense.weight', 'encoder.layer.0.output.dense.weight', 'encoder.layer.3.output.dense.bias', 'encoder.layer.21.intermediate.dense.bias', 'encoder.layer.16.attention.self.query.weight', 'encoder.layer.1.attention.output.LayerNorm.weight', 'encoder.layer.9.attention.output.LayerNorm.bias', 'encoder.layer.7.attention.self.value.bias', 'embeddings.word_embeddings.weight', 'encoder.layer.16.attention.output.dense.weight', 'encoder.layer.16.output.dense.weight', 'encoder.layer.19.attention.output.dense.bias', 'encoder.layer.7.attention.self.key.weight', 'encoder.layer.18.output.dense.weight', 'encoder.layer.17.attention.self.key.bias', 'encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.layer.16.attention.output.LayerNorm.bias', 'encoder.layer.15.attention.output.dense.weight', 'encoder.layer.21.attention.output.LayerNorm.bias', 'encoder.layer.5.attention.output.LayerNorm.weight', 'encoder.layer.19.attention.self.key.weight', 'encoder.layer.19.intermediate.dense.bias', 'encoder.layer.19.attention.output.LayerNorm.weight', 'encoder.layer.23.attention.output.LayerNorm.bias', 'encoder.layer.17.attention.self.query.weight', 'encoder.layer.8.attention.output.LayerNorm.bias', 'encoder.layer.8.attention.self.value.bias', 'encoder.layer.2.output.dense.weight', 'encoder.layer.23.attention.output.dense.bias', 'encoder.layer.0.attention.self.query.bias', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.15.attention.self.value.weight', 'encoder.layer.4.attention.self.query.bias', 'encoder.layer.14.attention.output.dense.weight', 'encoder.layer.15.intermediate.dense.bias', 'encoder.layer.20.output.LayerNorm.weight', 'encoder.layer.9.attention.output.LayerNorm.weight', 'encoder.layer.0.attention.self.key.weight', 'encoder.layer.12.output.LayerNorm.bias', 'encoder.layer.14.attention.output.dense.bias', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.4.attention.output.dense.weight', 'encoder.layer.4.attention.output.dense.bias', 'encoder.layer.22.intermediate.dense.weight', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.13.output.LayerNorm.bias', 'encoder.layer.6.attention.self.value.weight', 'encoder.layer.5.output.dense.bias', 'encoder.layer.15.attention.self.value.bias', 'encoder.layer.17.attention.self.value.weight', 'encoder.layer.18.intermediate.dense.bias', 'encoder.layer.3.attention.self.value.weight', 'encoder.layer.21.output.LayerNorm.bias', 'encoder.layer.13.attention.self.query.weight', 'encoder.layer.17.output.LayerNorm.weight', 'encoder.layer.1.output.dense.weight', 'encoder.layer.5.attention.self.key.bias', 'encoder.layer.16.output.LayerNorm.weight', 'encoder.layer.20.output.dense.bias', 'encoder.layer.21.attention.self.value.bias', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.2.attention.self.key.weight', 'encoder.layer.9.output.dense.bias', 'encoder.layer.10.attention.output.LayerNorm.bias', 'encoder.layer.1.attention.self.value.bias', 'encoder.layer.12.attention.output.LayerNorm.weight', 'encoder.layer.2.attention.output.dense.weight', 'encoder.layer.14.intermediate.dense.weight', 'encoder.layer.0.attention.self.value.weight', 'encoder.layer.10.output.LayerNorm.bias', 'encoder.layer.23.intermediate.dense.bias', 'encoder.layer.9.attention.output.dense.weight', 'encoder.layer.18.output.LayerNorm.weight', 'encoder.layer.6.attention.output.dense.weight', 'encoder.layer.21.attention.self.value.weight', 'encoder.layer.16.attention.self.key.bias', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.13.attention.self.query.bias', 'encoder.layer.18.attention.output.LayerNorm.bias', 'encoder.layer.23.attention.output.LayerNorm.weight', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.15.attention.self.query.bias', 'encoder.layer.14.output.LayerNorm.bias', 'encoder.layer.18.attention.self.query.weight', 'encoder.layer.21.output.LayerNorm.weight', 'encoder.layer.14.intermediate.dense.bias', 'encoder.layer.5.attention.self.key.weight', 'encoder.layer.2.attention.output.dense.bias', 'encoder.layer.14.output.dense.bias', 'encoder.layer.23.attention.output.dense.weight', 'encoder.layer.7.output.LayerNorm.bias', 'encoder.layer.20.attention.self.value.bias', 'encoder.layer.1.attention.output.dense.bias', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.12.attention.self.value.bias', 'encoder.layer.6.attention.self.query.bias', 'encoder.layer.11.attention.self.query.bias', 'encoder.layer.19.attention.output.dense.weight', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.11.attention.self.query.weight', 'encoder.layer.13.output.dense.weight', 'encoder.layer.15.intermediate.dense.weight', 'encoder.layer.18.attention.output.dense.bias', 'encoder.layer.9.attention.self.query.weight', 'encoder.layer.8.attention.output.LayerNorm.weight', 'encoder.layer.12.intermediate.dense.weight', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.8.attention.output.dense.bias', 'encoder.layer.17.attention.output.LayerNorm.weight', 'encoder.layer.10.intermediate.dense.weight', 'encoder.layer.5.output.dense.weight', 'encoder.layer.12.attention.self.key.weight', 'encoder.layer.17.intermediate.dense.weight', 'encoder.layer.18.output.LayerNorm.bias', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.17.attention.self.query.bias', 'encoder.layer.7.attention.self.query.bias', 'encoder.layer.4.attention.output.LayerNorm.bias', 'encoder.layer.17.output.LayerNorm.bias', 'encoder.layer.8.output.LayerNorm.bias', 'encoder.layer.13.attention.self.key.weight', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.22.attention.self.query.weight', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.10.attention.self.query.bias', 'encoder.layer.13.intermediate.dense.weight', 'encoder.layer.21.attention.self.key.weight', 'encoder.layer.18.attention.self.value.bias', 'encoder.layer.7.output.dense.weight', 'encoder.layer.15.output.LayerNorm.weight', 'encoder.layer.6.attention.self.query.weight', 'encoder.layer.21.output.dense.weight', 'encoder.layer.22.attention.self.key.weight', 'encoder.layer.18.attention.output.LayerNorm.weight', 'encoder.layer.1.attention.self.query.bias', 'encoder.layer.22.attention.output.dense.weight', 'encoder.layer.12.attention.output.LayerNorm.bias', 'encoder.layer.4.output.dense.weight', 'encoder.layer.11.attention.output.LayerNorm.weight', 'encoder.layer.0.attention.output.dense.weight', 'encoder.layer.7.attention.output.LayerNorm.bias', 'embeddings.LayerNorm.bias', 'encoder.layer.8.output.dense.weight', 'encoder.layer.5.attention.self.query.weight', 'encoder.layer.9.attention.self.value.bias', 'encoder.layer.19.attention.self.value.bias', 'encoder.layer.7.attention.self.value.weight', 'encoder.layer.6.attention.self.key.bias', 'encoder.layer.20.attention.self.key.weight', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.23.attention.self.query.weight', 'encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.layer.20.attention.output.LayerNorm.weight', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.14.attention.self.key.bias', 'encoder.layer.23.attention.self.query.bias', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.layer.23.attention.self.value.weight', 'encoder.layer.2.output.dense.bias', 'encoder.layer.14.attention.self.value.bias', 'encoder.layer.12.attention.output.dense.bias', 'encoder.layer.21.attention.self.key.bias', 'encoder.layer.19.output.dense.bias', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.16.attention.self.query.bias', 'encoder.layer.3.output.dense.weight', 'encoder.layer.19.output.dense.weight', 'encoder.layer.20.attention.self.query.weight', 'encoder.layer.4.attention.self.key.bias', 'encoder.layer.22.output.dense.weight', 'encoder.layer.7.attention.output.dense.weight', 'encoder.layer.22.attention.self.value.weight', 'encoder.layer.1.attention.self.value.weight', 'encoder.layer.16.attention.self.key.weight', 'encoder.layer.7.attention.self.key.bias', 'encoder.layer.8.output.LayerNorm.weight', 'encoder.layer.11.attention.self.key.bias', 'encoder.layer.16.attention.self.value.bias', 'encoder.layer.1.attention.output.dense.weight', 'encoder.layer.11.output.LayerNorm.weight', 'encoder.layer.22.attention.output.LayerNorm.bias', 'encoder.layer.13.output.LayerNorm.weight', 'encoder.layer.16.intermediate.dense.bias', 'encoder.layer.16.attention.output.dense.bias', 'encoder.layer.5.attention.self.value.bias', 'encoder.layer.5.attention.output.dense.bias', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.18.attention.self.value.weight', 'encoder.layer.3.attention.output.dense.bias', 'encoder.layer.5.attention.output.dense.weight', 'encoder.layer.21.output.dense.bias', 'encoder.layer.3.attention.self.query.bias', 'encoder.layer.2.attention.output.LayerNorm.bias', 'encoder.layer.15.output.dense.weight', 'pooler.dense.weight', 'encoder.layer.15.attention.output.LayerNorm.bias', 'encoder.layer.17.attention.output.dense.weight', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.7.attention.self.query.weight', 'encoder.layer.13.attention.self.value.bias', 'encoder.layer.13.attention.output.LayerNorm.bias', 'encoder.layer.0.attention.self.query.weight', 'encoder.layer.10.output.dense.weight', 'encoder.layer.7.output.LayerNorm.weight', 'encoder.layer.5.attention.self.query.bias', 'encoder.layer.3.attention.self.value.bias', 'encoder.layer.23.output.dense.bias', 'encoder.layer.10.attention.self.value.weight', 'encoder.layer.15.attention.self.key.weight', 'encoder.layer.8.attention.self.value.weight', 'encoder.layer.4.output.dense.bias', 'encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.layer.19.attention.self.value.weight', 'encoder.layer.0.attention.self.value.bias', 'encoder.layer.12.attention.self.key.bias', 'encoder.layer.22.attention.self.query.bias', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.16.intermediate.dense.weight', 'encoder.layer.6.attention.self.value.bias', 'encoder.layer.6.attention.output.dense.bias', 'encoder.layer.11.attention.output.dense.bias', 'encoder.layer.14.attention.output.LayerNorm.bias', 'encoder.layer.21.attention.self.query.weight', 'encoder.layer.12.intermediate.dense.bias', 'encoder.layer.7.intermediate.dense.bias', 'encoder.layer.19.attention.self.query.weight', 'embeddings.position_embeddings.weight', 'encoder.layer.20.attention.self.value.weight', 'encoder.layer.6.output.LayerNorm.bias', 'encoder.layer.18.attention.output.dense.weight', 'encoder.layer.13.intermediate.dense.bias', 'encoder.layer.14.attention.self.value.weight', 'encoder.layer.19.attention.self.key.bias', 'encoder.layer.12.attention.self.query.bias', 'encoder.layer.15.attention.self.query.weight', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.22.attention.output.LayerNorm.weight', 'encoder.layer.0.attention.output.LayerNorm.weight', 'encoder.layer.10.attention.self.key.bias', 'encoder.layer.10.attention.self.query.weight', 'embeddings.token_type_embeddings.weight', 'encoder.layer.10.output.dense.bias', 'encoder.layer.8.attention.self.query.weight', 'encoder.layer.6.attention.output.LayerNorm.bias', 'encoder.layer.9.attention.self.query.bias', 'encoder.layer.15.attention.self.key.bias', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.6.attention.output.LayerNorm.weight', 'embeddings.LayerNorm.weight', 'encoder.layer.4.attention.self.value.weight', 'encoder.layer.15.output.LayerNorm.bias', 'encoder.layer.18.attention.self.key.bias', 'encoder.layer.20.attention.self.query.bias', 'encoder.layer.7.output.dense.bias', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.14.attention.self.query.weight', 'encoder.layer.4.attention.self.query.weight', 'encoder.layer.23.output.dense.weight', 'encoder.layer.2.attention.self.value.weight', 'encoder.layer.11.attention.self.value.weight', 'encoder.layer.22.attention.self.value.bias', 'encoder.layer.13.attention.output.dense.weight', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.13.output.dense.bias', 'encoder.layer.17.output.dense.weight', 'encoder.layer.1.attention.self.key.weight', 'encoder.layer.12.attention.self.value.weight', 'encoder.layer.11.output.dense.bias', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.11.output.dense.weight', 'encoder.layer.10.attention.output.dense.bias', 'encoder.layer.23.attention.self.key.bias', 'encoder.layer.3.attention.self.key.weight', 'encoder.layer.19.intermediate.dense.weight', 'encoder.layer.19.attention.self.query.bias', 'encoder.layer.10.attention.output.LayerNorm.weight', 'encoder.layer.3.attention.output.dense.weight', 'encoder.layer.10.attention.output.dense.weight', 'encoder.layer.20.attention.self.key.bias', 'encoder.layer.2.attention.output.LayerNorm.weight', 'encoder.layer.9.attention.self.key.weight', 'encoder.layer.20.intermediate.dense.weight', 'encoder.layer.12.output.dense.bias', 'encoder.layer.9.attention.self.value.weight', 'encoder.layer.22.attention.self.key.bias', 'encoder.layer.18.intermediate.dense.weight', 'encoder.layer.7.attention.output.LayerNorm.weight', 'encoder.layer.20.attention.output.LayerNorm.bias', 'encoder.layer.12.output.LayerNorm.weight', 'encoder.layer.8.attention.self.key.bias', 'encoder.layer.23.output.LayerNorm.weight', 'encoder.layer.8.attention.self.key.weight', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.2.attention.self.query.bias', 'encoder.layer.16.attention.output.LayerNorm.weight', 'encoder.layer.18.attention.self.query.bias', 'encoder.layer.20.intermediate.dense.bias', 'encoder.layer.20.output.dense.weight', 'encoder.layer.16.output.dense.bias', 'encoder.layer.19.attention.output.LayerNorm.bias', 'encoder.layer.23.output.LayerNorm.bias', 'encoder.layer.0.attention.self.key.bias', 'encoder.layer.1.attention.self.key.bias', 'encoder.layer.0.attention.output.dense.bias', 'encoder.layer.6.output.dense.weight', 'encoder.layer.14.output.dense.weight', 'encoder.layer.17.intermediate.dense.bias', 'encoder.layer.17.attention.output.LayerNorm.bias', 'encoder.layer.13.attention.self.value.weight', 'encoder.layer.9.output.LayerNorm.bias', 'encoder.layer.20.attention.output.dense.weight', 'encoder.layer.17.attention.self.value.bias', 'encoder.layer.12.output.dense.weight', 'encoder.layer.10.attention.self.value.bias', 'encoder.layer.19.output.LayerNorm.bias', 'encoder.layer.22.output.dense.bias', 'encoder.layer.14.attention.output.LayerNorm.weight', 'encoder.layer.2.attention.self.value.bias', 'encoder.layer.8.attention.output.dense.weight', 'encoder.layer.4.attention.self.value.bias', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.4.attention.output.LayerNorm.weight', 'encoder.layer.9.attention.self.key.bias', 'encoder.layer.11.attention.self.value.bias', 'encoder.layer.22.attention.output.dense.bias', 'encoder.layer.17.attention.self.key.weight', 'encoder.layer.9.output.dense.weight', 'encoder.layer.21.attention.output.dense.bias', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.8.output.dense.bias', 'encoder.layer.18.attention.self.key.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Overwriting existing adapter 'ep'.
Overwriting existing adapter 'tp'.
Overwriting existing adapter 'es'.
Overwriting existing adapter 'ts'.
Overwriting existing adapter fusion module 'ep,tp,es,ts'
05/09/2022 20:05:45 - INFO - __main__ -   Creating features from dataset file at .
/cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//squad/xlm-KG_LR4e-5_EPOCH2.0_maxlen384_batchsize4_gradacc8
XLMConfig {
  "architectures": [
    "XLMRobertaForMaskedLM"
  ],
  "asm": false,
  "attention_dropout": 0.1,
  "attention_probs_dropout_prob": 0.1,
  "bos_index": 0,
  "bos_token_id": 0,
  "causal": false,
  "dropout": 0.1,
  "emb_dim": 1024,
  "embed_init_std": 0.02209708691207961,
  "end_n_top": 5,
  "eos_index": 1,
  "eos_token_id": 2,
  "gelu_activation": true,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "init_std": 0.02,
  "initializer_range": 0.02,
  "intermediate_size": 4096,
  "is_encoder": true,
  "lang_id": 0,
  "layer_norm_eps": 1e-05,
  "mask_index": 5,
  "mask_token_id": 0,
  "max_position_embeddings": 514,
  "model_type": "xlm",
  "n_heads": 16,
  "n_langs": 1,
  "n_layers": 24,
  "output_past": true,
  "pad_index": 2,
  "pad_token_id": 1,
  "sinusoidal_embeddings": false,
  "start_n_top": 5,
  "summary_activation": null,
  "summary_first_dropout": 0.1,
  "summary_proj_to_labels": true,
  "summary_type": "first",
  "summary_use_proj": true,
  "transformers_version": "4.17.0",
  "type_vocab_size": 1,
  "unk_index": 3,
  "use_lang_emb": false,
  "vocab_size": 250002
}

  0%|          | 0/48 [00:00<?, ?it/s] 31%|███▏      | 15/48 [00:00<00:00, 144.56it/s] 62%|██████▎   | 30/48 [00:00<00:00, 102.96it/s] 88%|████████▊ | 42/48 [00:00<00:00, 108.33it/s]100%|██████████| 48/48 [00:00<00:00, 113.95it/s]
convert squad examples to features:   0%|          | 0/1190 [00:00<?, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.
convert squad examples to features:   0%|          | 1/1190 [00:00<04:01,  4.93it/s]convert squad examples to features:   5%|▌         | 65/1190 [00:00<00:06, 179.32it/s]convert squad examples to features:  11%|█         | 129/1190 [00:00<00:04, 257.62it/s]convert squad examples to features:  16%|█▌        | 193/1190 [00:00<00:03, 308.88it/s]convert squad examples to features:  19%|█▉        | 226/1190 [00:00<00:03, 289.43it/s]convert squad examples to features:  22%|██▏       | 257/1190 [00:01<00:03, 283.28it/s]convert squad examples to features:  24%|██▍       | 289/1190 [00:01<00:03, 256.89it/s]convert squad examples to features:  27%|██▋       | 321/1190 [00:01<00:03, 253.10it/s]convert squad examples to features:  30%|██▉       | 353/1190 [00:01<00:03, 235.99it/s]convert squad examples to features:  32%|███▏      | 385/1190 [00:01<00:06, 125.28it/s]convert squad examples to features:  35%|███▌      | 417/1190 [00:02<00:05, 138.64it/s]convert squad examples to features:  38%|███▊      | 449/1190 [00:02<00:04, 150.80it/s]convert squad examples to features:  40%|████      | 481/1190 [00:02<00:04, 163.81it/s]convert squad examples to features:  43%|████▎     | 513/1190 [00:02<00:03, 169.32it/s]convert squad examples to features:  46%|████▌     | 545/1190 [00:02<00:03, 178.24it/s]convert squad examples to features:  48%|████▊     | 577/1190 [00:02<00:03, 189.06it/s]convert squad examples to features:  51%|█████     | 609/1190 [00:03<00:03, 175.03it/s]convert squad examples to features:  54%|█████▍    | 641/1190 [00:03<00:03, 172.38it/s]convert squad examples to features:  57%|█████▋    | 673/1190 [00:03<00:02, 180.52it/s]convert squad examples to features:  59%|█████▉    | 705/1190 [00:03<00:02, 194.81it/s]convert squad examples to features:  62%|██████▏   | 737/1190 [00:03<00:02, 210.32it/s]convert squad examples to features:  65%|██████▍   | 769/1190 [00:03<00:01, 215.50it/s]convert squad examples to features:  67%|██████▋   | 801/1190 [00:04<00:01, 227.81it/s]convert squad examples to features:  70%|███████   | 833/1190 [00:04<00:01, 213.14it/s]convert squad examples to features:  73%|███████▎  | 865/1190 [00:04<00:01, 222.29it/s]convert squad examples to features:  75%|███████▌  | 897/1190 [00:04<00:01, 223.67it/s]convert squad examples to features:  78%|███████▊  | 929/1190 [00:04<00:01, 229.11it/s]convert squad examples to features:  81%|████████  | 961/1190 [00:04<00:00, 239.31it/s]convert squad examples to features:  83%|████████▎ | 993/1190 [00:04<00:00, 237.34it/s]convert squad examples to features:  86%|████████▌ | 1025/1190 [00:04<00:00, 250.51it/s]convert squad examples to features:  92%|█████████▏| 1089/1190 [00:05<00:00, 279.35it/s]convert squad examples to features:  94%|█████████▍| 1121/1190 [00:05<00:00, 271.57it/s]convert squad examples to features:  97%|█████████▋| 1153/1190 [00:05<00:00, 242.92it/s]convert squad examples to features: 100%|██████████| 1190/1190 [00:05<00:00, 215.75it/s]/cluster/project/sachan/yifan/softwares/anaconda/anaconda3/envs/xfactr/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2272: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

add example index and unique id:   0%|          | 0/1190 [00:00<?, ?it/s]add example index and unique id: 100%|██████████| 1190/1190 [00:00<00:00, 590607.24it/s]
05/09/2022 20:05:51 - INFO - __main__ -   Saving features into cached file ./cached_xquad.ar.json_xlm-KG_LR4e-5_EPOCH2.0_maxlen384_batchsize4_gradacc8_384_ar
05/09/2022 20:05:52 - INFO - __main__ -   ***** Running evaluation  *****
05/09/2022 20:05:52 - INFO - __main__ -     Num examples = 1318
05/09/2022 20:05:52 - INFO - __main__ -     Batch size = 8
Evaluating:   0%|          | 0/165 [00:00<?, ?it/s]Evaluating:   1%|          | 1/165 [00:00<02:32,  1.07it/s]Evaluating:   1%|          | 2/165 [00:01<01:36,  1.69it/s]Evaluating:   2%|▏         | 3/165 [00:01<01:18,  2.06it/s]Evaluating:   2%|▏         | 4/165 [00:02<01:10,  2.30it/s]Evaluating:   3%|▎         | 5/165 [00:02<01:04,  2.47it/s]Evaluating:   4%|▎         | 6/165 [00:02<01:01,  2.57it/s]Evaluating:   4%|▍         | 7/165 [00:03<00:59,  2.65it/s]Evaluating:   5%|▍         | 8/165 [00:03<00:57,  2.71it/s]Evaluating:   5%|▌         | 9/165 [00:03<00:56,  2.75it/s]Evaluating:   6%|▌         | 10/165 [00:04<00:56,  2.75it/s]Evaluating:   7%|▋         | 11/165 [00:04<00:56,  2.75it/s]Evaluating:   7%|▋         | 12/165 [00:04<00:55,  2.77it/s]Evaluating:   8%|▊         | 13/165 [00:05<00:55,  2.76it/s]Evaluating:   8%|▊         | 14/165 [00:05<00:54,  2.77it/s]Evaluating:   9%|▉         | 15/165 [00:05<00:54,  2.78it/s]Evaluating:  10%|▉         | 16/165 [00:06<00:53,  2.79it/s]Evaluating:  10%|█         | 17/165 [00:06<00:53,  2.75it/s]Evaluating:  11%|█         | 18/165 [00:07<00:53,  2.75it/s]Evaluating:  12%|█▏        | 19/165 [00:07<00:54,  2.66it/s]Evaluating:  12%|█▏        | 20/165 [00:07<00:55,  2.62it/s]Evaluating:  13%|█▎        | 21/165 [00:08<00:55,  2.61it/s]Evaluating:  13%|█▎        | 22/165 [00:08<00:57,  2.50it/s]Evaluating:  14%|█▍        | 23/165 [00:09<00:55,  2.54it/s]Evaluating:  15%|█▍        | 24/165 [00:09<00:56,  2.50it/s]Evaluating:  15%|█▌        | 25/165 [00:09<00:57,  2.44it/s]Evaluating:  16%|█▌        | 26/165 [00:10<00:55,  2.51it/s]Evaluating:  16%|█▋        | 27/165 [00:10<00:53,  2.59it/s]Evaluating:  17%|█▋        | 28/165 [00:10<00:51,  2.64it/s]Evaluating:  18%|█▊        | 29/165 [00:11<00:53,  2.56it/s]Evaluating:  18%|█▊        | 30/165 [00:11<00:51,  2.60it/s]Evaluating:  19%|█▉        | 31/165 [00:12<00:50,  2.64it/s]Evaluating:  19%|█▉        | 32/165 [00:12<00:50,  2.64it/s]Evaluating:  20%|██        | 33/165 [00:12<00:53,  2.48it/s]Evaluating:  21%|██        | 34/165 [00:13<00:54,  2.42it/s]Evaluating:  21%|██        | 35/165 [00:13<00:53,  2.42it/s]Evaluating:  22%|██▏       | 36/165 [00:14<00:52,  2.47it/s]Evaluating:  22%|██▏       | 37/165 [00:14<00:52,  2.44it/s]Evaluating:  23%|██▎       | 38/165 [00:14<00:50,  2.53it/s]Evaluating:  24%|██▎       | 39/165 [00:15<00:48,  2.60it/s]Evaluating:  24%|██▍       | 40/165 [00:15<00:49,  2.53it/s]Evaluating:  25%|██▍       | 41/165 [00:16<00:49,  2.49it/s]Evaluating:  25%|██▌       | 42/165 [00:16<00:47,  2.57it/s]Evaluating:  26%|██▌       | 43/165 [00:16<00:46,  2.60it/s]Evaluating:  27%|██▋       | 44/165 [00:17<00:45,  2.66it/s]Evaluating:  27%|██▋       | 45/165 [00:17<00:46,  2.58it/s]Evaluating:  28%|██▊       | 46/165 [00:18<00:46,  2.56it/s]Evaluating:  28%|██▊       | 47/165 [00:18<00:46,  2.55it/s]Evaluating:  29%|██▉       | 48/165 [00:18<00:47,  2.49it/s]Evaluating:  30%|██▉       | 49/165 [00:19<00:47,  2.43it/s]Evaluating:  30%|███       | 50/165 [00:19<00:47,  2.40it/s]Evaluating:  31%|███       | 51/165 [00:20<00:45,  2.49it/s]Evaluating:  32%|███▏      | 52/165 [00:20<00:45,  2.51it/s]Evaluating:  32%|███▏      | 53/165 [00:20<00:43,  2.57it/s]Evaluating:  33%|███▎      | 54/165 [00:21<00:42,  2.58it/s]Evaluating:  33%|███▎      | 55/165 [00:21<00:41,  2.63it/s]Evaluating:  34%|███▍      | 56/165 [00:22<00:41,  2.64it/s]Evaluating:  35%|███▍      | 57/165 [00:22<00:42,  2.55it/s]Evaluating:  35%|███▌      | 58/165 [00:22<00:41,  2.58it/s]Evaluating:  36%|███▌      | 59/165 [00:23<00:40,  2.62it/s]Evaluating:  36%|███▋      | 60/165 [00:23<00:39,  2.63it/s]Evaluating:  37%|███▋      | 61/165 [00:23<00:39,  2.65it/s]Evaluating:  38%|███▊      | 62/165 [00:24<00:38,  2.65it/s]Evaluating:  38%|███▊      | 63/165 [00:24<00:38,  2.68it/s]Evaluating:  39%|███▉      | 64/165 [00:25<00:37,  2.71it/s]Evaluating:  39%|███▉      | 65/165 [00:25<00:36,  2.73it/s]Evaluating:  40%|████      | 66/165 [00:25<00:36,  2.75it/s]Evaluating:  41%|████      | 67/165 [00:26<00:35,  2.76it/s]Evaluating:  41%|████      | 68/165 [00:26<00:34,  2.77it/s]Evaluating:  42%|████▏     | 69/165 [00:26<00:35,  2.74it/s]Evaluating:  42%|████▏     | 70/165 [00:27<00:34,  2.74it/s]Evaluating:  43%|████▎     | 71/165 [00:27<00:34,  2.76it/s]Evaluating:  44%|████▎     | 72/165 [00:27<00:33,  2.74it/s]Evaluating:  44%|████▍     | 73/165 [00:28<00:33,  2.75it/s]Evaluating:  45%|████▍     | 74/165 [00:28<00:33,  2.76it/s]Evaluating:  45%|████▌     | 75/165 [00:29<00:32,  2.76it/s]Evaluating:  46%|████▌     | 76/165 [00:29<00:32,  2.76it/s]Evaluating:  47%|████▋     | 77/165 [00:29<00:31,  2.77it/s]Evaluating:  47%|████▋     | 78/165 [00:30<00:31,  2.77it/s]Evaluating:  48%|████▊     | 79/165 [00:30<00:31,  2.76it/s]Evaluating:  48%|████▊     | 80/165 [00:30<00:30,  2.75it/s]Evaluating:  49%|████▉     | 81/165 [00:31<00:30,  2.75it/s]Evaluating:  50%|████▉     | 82/165 [00:31<00:30,  2.75it/s]Evaluating:  50%|█████     | 83/165 [00:31<00:29,  2.76it/s]Evaluating:  51%|█████     | 84/165 [00:32<00:29,  2.77it/s]Evaluating:  52%|█████▏    | 85/165 [00:32<00:28,  2.76it/s]Evaluating:  52%|█████▏    | 86/165 [00:32<00:28,  2.77it/s]Evaluating:  53%|█████▎    | 87/165 [00:33<00:28,  2.76it/s]Evaluating:  53%|█████▎    | 88/165 [00:33<00:27,  2.76it/s]Evaluating:  54%|█████▍    | 89/165 [00:34<00:27,  2.76it/s]Evaluating:  55%|█████▍    | 90/165 [00:34<00:27,  2.74it/s]Evaluating:  55%|█████▌    | 91/165 [00:34<00:26,  2.74it/s]Evaluating:  56%|█████▌    | 92/165 [00:35<00:26,  2.75it/s]Evaluating:  56%|█████▋    | 93/165 [00:35<00:26,  2.75it/s]Evaluating:  57%|█████▋    | 94/165 [00:35<00:25,  2.75it/s]Evaluating:  58%|█████▊    | 95/165 [00:36<00:25,  2.75it/s]Evaluating:  58%|█████▊    | 96/165 [00:36<00:25,  2.76it/s]Evaluating:  59%|█████▉    | 97/165 [00:36<00:24,  2.76it/s]Evaluating:  59%|█████▉    | 98/165 [00:37<00:24,  2.76it/s]Evaluating:  60%|██████    | 99/165 [00:37<00:23,  2.76it/s]Evaluating:  61%|██████    | 100/165 [00:38<00:23,  2.77it/s]Evaluating:  61%|██████    | 101/165 [00:38<00:23,  2.77it/s]Evaluating:  62%|██████▏   | 102/165 [00:38<00:22,  2.77it/s]Evaluating:  62%|██████▏   | 103/165 [00:39<00:22,  2.78it/s]Evaluating:  63%|██████▎   | 104/165 [00:39<00:21,  2.78it/s]Evaluating:  64%|██████▎   | 105/165 [00:39<00:21,  2.78it/s]Evaluating:  64%|██████▍   | 106/165 [00:40<00:21,  2.78it/s]Evaluating:  65%|██████▍   | 107/165 [00:40<00:20,  2.78it/s]Evaluating:  65%|██████▌   | 108/165 [00:40<00:20,  2.79it/s]Evaluating:  66%|██████▌   | 109/165 [00:41<00:20,  2.79it/s]Evaluating:  67%|██████▋   | 110/165 [00:41<00:19,  2.79it/s]Evaluating:  67%|██████▋   | 111/165 [00:42<00:19,  2.76it/s]Evaluating:  68%|██████▊   | 112/165 [00:42<00:19,  2.75it/s]Evaluating:  68%|██████▊   | 113/165 [00:42<00:18,  2.77it/s]Evaluating:  69%|██████▉   | 114/165 [00:43<00:18,  2.76it/s]Evaluating:  70%|██████▉   | 115/165 [00:43<00:18,  2.73it/s]Evaluating:  70%|███████   | 116/165 [00:43<00:18,  2.70it/s]Evaluating:  71%|███████   | 117/165 [00:44<00:18,  2.55it/s]Evaluating:  72%|███████▏  | 118/165 [00:44<00:18,  2.49it/s]Evaluating:  72%|███████▏  | 119/165 [00:45<00:18,  2.50it/s]Evaluating:  73%|███████▎  | 120/165 [00:45<00:18,  2.40it/s]Evaluating:  73%|███████▎  | 121/165 [00:46<00:19,  2.28it/s]Evaluating:  74%|███████▍  | 122/165 [00:46<00:18,  2.35it/s]Evaluating:  75%|███████▍  | 123/165 [00:46<00:17,  2.38it/s]Evaluating:  75%|███████▌  | 124/165 [00:47<00:17,  2.37it/s]Evaluating:  76%|███████▌  | 125/165 [00:47<00:16,  2.38it/s]Evaluating:  76%|███████▋  | 126/165 [00:48<00:15,  2.48it/s]Evaluating:  77%|███████▋  | 127/165 [00:48<00:15,  2.50it/s]Evaluating:  78%|███████▊  | 128/165 [00:48<00:14,  2.58it/s]Evaluating:  78%|███████▊  | 129/165 [00:49<00:13,  2.64it/s]Evaluating:  79%|███████▉  | 130/165 [00:49<00:13,  2.67it/s]Evaluating:  79%|███████▉  | 131/165 [00:49<00:12,  2.69it/s]Evaluating:  80%|████████  | 132/165 [00:50<00:12,  2.68it/s]Evaluating:  81%|████████  | 133/165 [00:50<00:12,  2.56it/s]Evaluating:  81%|████████  | 134/165 [00:51<00:11,  2.62it/s]Evaluating:  82%|████████▏ | 135/165 [00:51<00:11,  2.61it/s]Evaluating:  82%|████████▏ | 136/165 [00:51<00:10,  2.66it/s]Evaluating:  83%|████████▎ | 137/165 [00:52<00:10,  2.60it/s]Evaluating:  84%|████████▎ | 138/165 [00:52<00:10,  2.62it/s]Evaluating:  84%|████████▍ | 139/165 [00:53<00:09,  2.61it/s]Evaluating:  85%|████████▍ | 140/165 [00:53<00:09,  2.66it/s]Evaluating:  85%|████████▌ | 141/165 [00:53<00:08,  2.70it/s]Evaluating:  86%|████████▌ | 142/165 [00:54<00:08,  2.71it/s]Evaluating:  87%|████████▋ | 143/165 [00:54<00:08,  2.70it/s]Evaluating:  87%|████████▋ | 144/165 [00:54<00:07,  2.66it/s]Evaluating:  88%|████████▊ | 145/165 [00:55<00:07,  2.70it/s]Evaluating:  88%|████████▊ | 146/165 [00:55<00:07,  2.69it/s]Evaluating:  89%|████████▉ | 147/165 [00:55<00:06,  2.72it/s]Evaluating:  90%|████████▉ | 148/165 [00:56<00:06,  2.74it/s]Evaluating:  90%|█████████ | 149/165 [00:56<00:05,  2.75it/s]Evaluating:  91%|█████████ | 150/165 [00:57<00:05,  2.77it/s]Evaluating:  92%|█████████▏| 151/165 [00:57<00:05,  2.78it/s]Evaluating:  92%|█████████▏| 152/165 [00:57<00:04,  2.78it/s]Evaluating:  93%|█████████▎| 153/165 [00:58<00:04,  2.73it/s]Evaluating:  93%|█████████▎| 154/165 [00:58<00:04,  2.67it/s]Evaluating:  94%|█████████▍| 155/165 [00:58<00:03,  2.65it/s]Evaluating:  95%|█████████▍| 156/165 [00:59<00:03,  2.67it/s]Evaluating:  95%|█████████▌| 157/165 [00:59<00:02,  2.70it/s]Evaluating:  96%|█████████▌| 158/165 [00:59<00:02,  2.70it/s]Evaluating:  96%|█████████▋| 159/165 [01:00<00:02,  2.71it/s]Evaluating:  97%|█████████▋| 160/165 [01:00<00:01,  2.73it/s]Evaluating:  98%|█████████▊| 161/165 [01:01<00:01,  2.75it/s]Evaluating:  98%|█████████▊| 162/165 [01:01<00:01,  2.62it/s]Evaluating:  99%|█████████▉| 163/165 [01:01<00:00,  2.63it/s]Evaluating:  99%|█████████▉| 164/165 [01:02<00:00,  2.43it/s]Evaluating: 100%|██████████| 165/165 [01:02<00:00,  2.57it/s]Evaluating: 100%|██████████| 165/165 [01:02<00:00,  2.63it/s]
05/09/2022 20:06:55 - INFO - __main__ -     Evaluation done in total 62.698599 secs (0.047571 sec per example)
05/09/2022 20:06:59 - INFO - __main__ -   Results: {'exact': 57.47899159663866, 'f1': 74.46101850310727, 'total': 1190, 'HasAns_exact': 57.47899159663866, 'HasAns_f1': 74.46101850310727, 'HasAns_total': 1190, 'best_exact': 57.47899159663866, 'best_exact_thresh': 0.0, 'best_f1': 74.46101850310727, 'best_f1_thresh': 0.0}
  vi 
2022-05-09 20:07:06.776359: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0
05/09/2022 20:07:21 - WARNING - __main__ -   Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, 16-bits training: False
You are using a model of type xlm-roberta to instantiate a model of type xlm. This is not supported for all configurations of models and can yield errors.
Some weights of the model checkpoint at /cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//squad/xlm-KG_LR4e-5_EPOCH2.0_maxlen384_batchsize4_gradacc8 were not used when initializing XLMRobertaModel: ['base_model.encoder.layer.2.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.9.attention.self.query.weight', 'base_model.encoder.layer.17.attention.self.key.bias', 'base_model.encoder.layer.6.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.5.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.19.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.23.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.18.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.10.attention.self.value.bias', 'base_model.encoder.layer.17.attention.output.LayerNorm.weight', 'base_model.encoder.layer.9.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.7.attention.self.key.bias', 'base_model.encoder.layer.2.attention.output.LayerNorm.weight', 'base_model.encoder.layer.20.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.pooler.dense.weight', 'base_model.encoder.layer.1.output.LayerNorm.weight', 'base_model.encoder.layer.13.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.4.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.18.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.20.attention.self.query.bias', 'base_model.encoder.layer.10.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.8.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.8.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.12.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.22.attention.output.LayerNorm.weight', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.23.attention.output.dense.bias', 'base_model.encoder.layer.23.attention.self.key.weight', 'base_model.encoder.layer.10.attention.output.LayerNorm.bias', 'base_model.encoder.layer.10.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.2.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.10.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.12.attention.self.query.bias', 'base_model.encoder.layer.23.output.LayerNorm.bias', 'base_model.encoder.layer.2.output.LayerNorm.weight', 'base_model.encoder.layer.23.attention.output.LayerNorm.weight', 'base_model.encoder.layer.2.attention.output.dense.bias', 'base_model.encoder.layer.21.attention.self.key.bias', 'base_model.encoder.layer.4.attention.output.dense.bias', 'base_model.encoder.layer.12.attention.output.LayerNorm.bias', 'base_model.encoder.layer.1.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.4.attention.self.value.bias', 'base_model.embeddings.position_embeddings.weight', 'base_model.encoder.layer.4.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.17.attention.self.query.bias', 'base_model.encoder.layer.19.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.8.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.0.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.0.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.15.attention.self.key.bias', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.20.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.21.attention.self.query.bias', 'base_model.encoder.layer.19.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.17.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.10.attention.self.value.weight', 'base_model.encoder.layer.18.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.23.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.17.output.LayerNorm.weight', 'base_model.encoder.layer.19.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.17.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.11.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.21.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.19.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.10.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.10.attention.output.dense.weight', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.22.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.23.intermediate.dense.weight', 'base_model.encoder.layer.5.attention.output.LayerNorm.weight', 'base_model.encoder.layer.19.output.dense.bias', 'base_model.encoder.layer.9.output.dense.weight', 'base_model.encoder.layer.11.output.LayerNorm.weight', 'base_model.encoder.layer.15.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.8.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.7.attention.output.dense.weight', 'base_model.encoder.layer.14.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.16.output.dense.bias', 'base_model.encoder.layer.12.attention.self.key.bias', 'base_model.encoder.layer.18.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.16.attention.output.dense.weight', 'base_model.encoder.layer.20.output.dense.bias', 'base_model.encoder.layer.9.attention.output.dense.weight', 'base_model.encoder.layer.2.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.7.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.7.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.12.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.3.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.5.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.4.output.LayerNorm.bias', 'base_model.encoder.layer.0.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.13.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.0.attention.self.value.weight', 'base_model.encoder.layer.4.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.7.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.17.attention.output.dense.bias', 'base_model.encoder.layer.14.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.23.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.20.attention.self.key.weight', 'base_model.encoder.layer.13.output.LayerNorm.weight', 'base_model.encoder.layer.12.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.14.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.22.intermediate.dense.weight', 'base_model.encoder.layer.4.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.12.attention.output.dense.bias', 'base_model.encoder.layer.16.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.0.attention.output.LayerNorm.weight', 'base_model.encoder.layer.3.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.3.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.3.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.15.attention.output.LayerNorm.bias', 'base_model.encoder.layer.4.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.22.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.4.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.22.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.21.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.2.attention.self.key.bias', 'base_model.encoder.layer.2.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.9.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.0.attention.output.dense.weight', 'base_model.encoder.layer.7.output.dense.bias', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.15.output.LayerNorm.weight', 'base_model.encoder.layer.13.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.23.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.9.intermediate.dense.weight', 'base_model.encoder.layer.18.attention.self.key.bias', 'base_model.encoder.layer.20.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.15.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.15.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.17.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.23.intermediate.dense.bias', 'base_model.encoder.layer.4.output.LayerNorm.weight', 'base_model.encoder.layer.12.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.16.attention.output.LayerNorm.bias', 'base_model.encoder.layer.17.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.11.attention.self.key.weight', 'base_model.encoder.layer.1.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.13.intermediate.dense.bias', 'base_model.encoder.layer.8.attention.self.key.weight', 'base_model.encoder.layer.23.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.22.attention.self.key.weight', 'base_model.encoder.layer.13.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.15.attention.self.query.bias', 'base_model.encoder.layer.12.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.11.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.7.attention.output.LayerNorm.weight', 'base_model.encoder.layer.11.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.15.attention.output.LayerNorm.weight', 'base_model.encoder.layer.0.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.21.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.5.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.5.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.2.output.dense.weight', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.0.attention.output.LayerNorm.bias', 'base_model.encoder.layer.23.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.19.output.LayerNorm.bias', 'base_model.encoder.layer.5.attention.self.key.bias', 'base_model.encoder.layer.9.output.LayerNorm.weight', 'base_model.encoder.layer.13.attention.output.LayerNorm.bias', 'base_model.encoder.layer.1.attention.output.LayerNorm.bias', 'base_model.encoder.layer.11.intermediate.dense.weight', 'base_model.encoder.layer.2.attention.self.value.bias', 'base_model.encoder.layer.14.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.1.output.LayerNorm.bias', 'base_model.encoder.layer.16.output.LayerNorm.weight', 'base_model.encoder.layer.8.output.dense.bias', 'base_model.encoder.layer.17.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.20.attention.output.dense.bias', 'base_model.encoder.layer.14.attention.self.key.bias', 'base_model.encoder.layer.23.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.23.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.14.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.23.output.dense.bias', 'base_model.encoder.layer.1.output.dense.weight', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.15.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.13.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.21.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.0.output.LayerNorm.bias', 'base_model.encoder.layer.7.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.9.attention.self.query.bias', 'base_model.encoder.layer.10.output.adapters.ts.adapter_up.bias', 'base_model.embeddings.LayerNorm.weight', 'base_model.encoder.layer.11.output.dense.bias', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.19.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.1.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.2.attention.self.value.weight', 'base_model.encoder.layer.14.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.1.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.4.attention.output.LayerNorm.weight', 'base_model.encoder.layer.9.attention.self.key.weight', 'base_model.encoder.layer.6.attention.output.LayerNorm.bias', 'base_model.encoder.layer.3.attention.self.key.weight', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.4.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.5.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.22.output.LayerNorm.bias', 'base_model.encoder.layer.22.attention.self.query.weight', 'base_model.encoder.layer.22.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.14.attention.output.LayerNorm.weight', 'base_model.encoder.layer.18.intermediate.dense.weight', 'base_model.encoder.layer.1.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.0.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.21.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.19.attention.self.query.bias', 'base_model.encoder.layer.6.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.3.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.16.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.19.output.adapters.ep.adapter_down.0.weight', 'base_model.embeddings.word_embeddings.weight', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.23.attention.output.LayerNorm.bias', 'base_model.encoder.layer.0.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.7.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.14.output.dense.bias', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.21.attention.self.value.weight', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.21.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.15.output.dense.weight', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.11.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.16.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.11.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.4.intermediate.dense.bias', 'base_model.encoder.layer.18.intermediate.dense.bias', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.10.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.0.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.17.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.7.attention.output.LayerNorm.bias', 'base_model.encoder.layer.2.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.15.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.14.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.2.attention.self.key.weight', 'base_model.encoder.layer.10.output.dense.bias', 'base_model.encoder.layer.13.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.18.attention.self.value.weight', 'base_model.encoder.layer.5.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.8.attention.self.query.weight', 'base_model.encoder.layer.17.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.20.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.8.attention.output.dense.bias', 'base_model.encoder.layer.1.attention.self.value.weight', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.21.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.5.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.9.attention.output.dense.bias', 'base_model.encoder.layer.18.attention.output.LayerNorm.weight', 'base_model.encoder.layer.17.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.20.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.3.intermediate.dense.bias', 'base_model.encoder.layer.1.attention.output.dense.weight', 'base_model.encoder.layer.21.output.LayerNorm.bias', 'base_model.encoder.layer.9.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.21.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.0.attention.self.query.weight', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.10.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.2.attention.output.LayerNorm.bias', 'base_model.encoder.layer.11.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.13.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.13.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.19.output.dense.weight', 'base_model.encoder.layer.20.intermediate.dense.bias', 'base_model.encoder.layer.13.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.6.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.12.attention.output.LayerNorm.weight', 'base_model.encoder.layer.7.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.21.attention.output.LayerNorm.bias', 'base_model.encoder.layer.0.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.21.intermediate.dense.weight', 'base_model.encoder.layer.7.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.11.attention.self.value.weight', 'base_model.encoder.layer.3.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.19.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.4.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.5.attention.output.LayerNorm.bias', 'base_model.encoder.layer.0.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.19.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.5.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.16.output.LayerNorm.bias', 'base_model.encoder.layer.17.attention.self.value.bias', 'base_model.encoder.layer.11.output.LayerNorm.bias', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.10.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.4.output.dense.bias', 'base_model.encoder.layer.5.output.dense.weight', 'base_model.encoder.layer.9.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.6.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.0.output.dense.bias', 'base_model.encoder.layer.1.attention.self.key.bias', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.17.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.14.attention.self.query.bias', 'base_model.encoder.layer.16.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.5.attention.output.dense.weight', 'base_model.encoder.layer.9.intermediate.dense.bias', 'base_model.encoder.layer.22.attention.self.query.bias', 'base_model.encoder.layer.15.intermediate.dense.bias', 'base_model.encoder.layer.19.intermediate.dense.weight', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.11.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.20.output.LayerNorm.weight', 'base_model.encoder.layer.6.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.3.attention.output.LayerNorm.bias', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.14.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.12.attention.self.value.weight', 'base_model.encoder.layer.10.output.LayerNorm.weight', 'base_model.encoder.layer.6.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.15.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.17.output.dense.weight', 'base_model.encoder.layer.20.output.dense.weight', 'base_model.encoder.layer.21.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.5.output.LayerNorm.weight', 'base_model.encoder.layer.8.attention.output.LayerNorm.weight', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.22.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.13.attention.output.LayerNorm.weight', 'base_model.encoder.layer.17.attention.self.key.weight', 'base_model.encoder.layer.5.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.13.attention.output.dense.bias', 'base_model.encoder.layer.14.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.14.attention.self.query.weight', 'base_model.encoder.layer.18.output.LayerNorm.weight', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.11.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.5.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.9.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.15.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.3.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.7.attention.output.dense.bias', 'base_model.encoder.layer.8.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.20.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.8.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.3.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.18.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.5.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.21.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.16.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.2.intermediate.dense.weight', 'base_model.encoder.layer.7.attention.self.value.weight', 'base_model.encoder.layer.8.attention.self.query.bias', 'base_model.encoder.layer.16.attention.self.query.bias', 'base_model.encoder.layer.6.attention.self.value.bias', 'base_model.encoder.layer.4.attention.output.LayerNorm.bias', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.23.attention.self.query.weight', 'base_model.encoder.layer.17.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.8.intermediate.dense.bias', 'base_model.encoder.layer.15.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.3.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.18.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.19.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.21.output.dense.bias', 'base_model.encoder.layer.12.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.17.output.LayerNorm.bias', 'base_model.encoder.layer.1.attention.self.query.weight', 'base_model.encoder.layer.1.intermediate.dense.bias', 'base_model.encoder.layer.22.attention.self.value.bias', 'base_model.encoder.layer.11.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.10.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.18.attention.output.dense.bias', 'base_model.encoder.layer.22.attention.output.LayerNorm.bias', 'base_model.encoder.layer.7.intermediate.dense.weight', 'base_model.encoder.layer.19.attention.output.dense.weight', 'base_model.encoder.layer.12.output.LayerNorm.bias', 'base_model.encoder.layer.2.output.LayerNorm.bias', 'base_model.encoder.layer.4.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.3.output.dense.bias', 'base_model.encoder.layer.16.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.22.attention.self.value.weight', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.5.attention.self.query.weight', 'base_model.encoder.layer.21.intermediate.dense.bias', 'base_model.encoder.layer.14.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.21.attention.output.dense.bias', 'base_model.encoder.layer.12.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.14.attention.self.value.weight', 'base_model.encoder.layer.14.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.6.attention.self.value.weight', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.16.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.6.attention.self.query.bias', 'base_model.encoder.layer.22.output.dense.bias', 'base_model.encoder.layer.3.intermediate.dense.weight', 'base_model.encoder.layer.10.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.6.output.LayerNorm.bias', 'base_model.encoder.layer.22.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.11.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.22.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.1.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.2.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.6.attention.self.key.weight', 'base_model.encoder.layer.12.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.22.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.2.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.20.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.22.intermediate.dense.bias', 'base_model.encoder.layer.8.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'qa_outputs.bias', 'base_model.encoder.layer.11.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.14.attention.self.key.weight', 'base_model.encoder.layer.6.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.22.attention.self.key.bias', 'base_model.encoder.layer.13.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.15.attention.self.value.bias', 'base_model.encoder.layer.18.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.7.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.7.intermediate.dense.bias', 'base_model.encoder.layer.14.output.dense.weight', 'base_model.encoder.layer.21.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.3.output.LayerNorm.bias', 'base_model.encoder.layer.16.attention.self.value.weight', 'base_model.encoder.layer.6.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.23.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.3.attention.output.dense.weight', 'base_model.encoder.layer.5.attention.self.value.weight', 'base_model.encoder.layer.23.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.12.output.dense.bias', 'base_model.encoder.layer.2.attention.output.dense.weight', 'base_model.encoder.layer.7.output.LayerNorm.weight', 'base_model.encoder.layer.10.attention.output.LayerNorm.weight', 'base_model.encoder.layer.15.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.17.attention.output.dense.weight', 'base_model.encoder.layer.18.attention.output.LayerNorm.bias', 'base_model.encoder.layer.13.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.7.output.LayerNorm.bias', 'base_model.encoder.layer.21.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.1.intermediate.dense.weight', 'base_model.encoder.layer.11.intermediate.dense.bias', 'base_model.encoder.layer.6.output.dense.weight', 'base_model.encoder.layer.19.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.2.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.20.intermediate.dense.weight', 'base_model.encoder.layer.12.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.13.output.dense.bias', 'base_model.encoder.layer.19.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.9.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.15.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.18.attention.self.key.weight', 'base_model.encoder.layer.15.intermediate.dense.weight', 'base_model.encoder.layer.3.attention.output.dense.bias', 'base_model.encoder.layer.1.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.6.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.6.attention.output.dense.bias', 'base_model.encoder.layer.2.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.5.output.LayerNorm.bias', 'base_model.encoder.layer.20.attention.self.value.weight', 'base_model.encoder.layer.3.attention.self.query.bias', 'base_model.encoder.layer.16.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.14.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.2.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.5.intermediate.dense.weight', 'base_model.encoder.layer.8.output.LayerNorm.bias', 'base_model.encoder.layer.8.attention.self.key.bias', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.7.output.dense.weight', 'base_model.encoder.layer.18.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.16.attention.self.value.bias', 'base_model.encoder.layer.4.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.0.attention.self.query.bias', 'base_model.encoder.layer.5.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.7.attention.self.value.bias', 'base_model.encoder.layer.16.intermediate.dense.weight', 'base_model.encoder.layer.20.attention.self.query.weight', 'base_model.encoder.layer.16.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.19.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.4.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.6.attention.output.LayerNorm.weight', 'base_model.encoder.layer.8.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.20.attention.output.LayerNorm.weight', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.11.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.3.attention.self.query.weight', 'base_model.encoder.layer.13.attention.self.value.weight', 'base_model.encoder.layer.23.output.dense.weight', 'base_model.encoder.layer.0.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.16.attention.self.key.bias', 'base_model.encoder.layer.1.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.6.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.12.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.4.attention.self.key.bias', 'base_model.encoder.layer.14.attention.output.LayerNorm.bias', 'base_model.encoder.layer.17.attention.self.query.weight', 'base_model.encoder.layer.6.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.19.attention.self.query.weight', 'base_model.encoder.layer.19.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.21.attention.self.value.bias', 'base_model.encoder.layer.3.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.11.attention.self.query.bias', 'base_model.encoder.layer.2.intermediate.dense.bias', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.17.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.21.attention.output.LayerNorm.weight', 'base_model.encoder.layer.12.attention.self.key.weight', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.0.attention.self.key.bias', 'base_model.encoder.layer.18.output.dense.weight', 'base_model.encoder.layer.10.output.dense.weight', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.22.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.12.intermediate.dense.weight', 'base_model.encoder.layer.8.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.16.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.20.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.23.attention.self.query.bias', 'base_model.encoder.layer.7.attention.self.key.weight', 'base_model.encoder.layer.8.attention.output.dense.weight', 'base_model.encoder.layer.4.intermediate.dense.weight', 'base_model.encoder.layer.11.attention.output.dense.weight', 'base_model.encoder.layer.13.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.15.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.20.attention.output.dense.weight', 'base_model.encoder.layer.8.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.15.attention.self.key.weight', 'base_model.encoder.layer.14.output.LayerNorm.bias', 'base_model.encoder.layer.14.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.10.intermediate.dense.bias', 'base_model.encoder.layer.7.attention.self.query.bias', 'base_model.encoder.layer.10.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.20.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.23.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.20.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.13.attention.self.value.bias', 'base_model.encoder.layer.9.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.6.attention.self.query.weight', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.12.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.19.attention.output.LayerNorm.weight', 'base_model.encoder.layer.2.attention.self.query.bias', 'base_model.encoder.layer.23.output.LayerNorm.weight', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.7.attention.self.query.weight', 'base_model.encoder.layer.17.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.16.attention.output.dense.bias', 'base_model.encoder.layer.16.attention.self.key.weight', 'base_model.encoder.layer.1.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.19.attention.self.value.weight', 'base_model.encoder.layer.14.output.LayerNorm.weight', 'base_model.encoder.layer.6.attention.output.dense.weight', 'base_model.encoder.layer.0.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.2.output.dense.bias', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.0.output.dense.weight', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.3.attention.self.value.bias', 'base_model.encoder.layer.9.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.22.attention.output.dense.bias', 'base_model.encoder.layer.4.attention.self.query.bias', 'base_model.encoder.layer.23.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.20.attention.output.LayerNorm.bias', 'base_model.encoder.layer.19.attention.output.dense.bias', 'base_model.encoder.layer.3.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.4.attention.self.key.weight', 'base_model.encoder.layer.10.output.LayerNorm.bias', 'base_model.encoder.layer.3.attention.self.value.weight', 'base_model.encoder.layer.0.attention.self.value.bias', 'base_model.encoder.layer.22.output.LayerNorm.weight', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.3.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.19.intermediate.dense.bias', 'base_model.encoder.layer.4.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.7.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.8.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.16.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.4.output.dense.weight', 'base_model.encoder.layer.19.attention.output.LayerNorm.bias', 'base_model.encoder.layer.12.attention.output.dense.weight', 'base_model.encoder.layer.8.output.dense.weight', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.9.attention.self.value.weight', 'base_model.encoder.layer.19.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.1.attention.self.query.bias', 'base_model.encoder.layer.13.attention.self.key.weight', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.0.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.6.output.dense.bias', 'base_model.encoder.layer.23.attention.output.dense.weight', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.3.output.dense.weight', 'base_model.encoder.layer.22.attention.output.dense.weight', 'base_model.encoder.layer.4.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.5.attention.self.query.bias', 'base_model.encoder.layer.7.output.adapters.ts.adapter_up.bias', 'base_model.embeddings.token_type_embeddings.weight', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.8.attention.self.value.weight', 'base_model.encoder.layer.15.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.5.attention.output.dense.bias', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.19.attention.self.value.bias', 'base_model.encoder.layer.23.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.13.attention.self.query.weight', 'base_model.encoder.layer.13.attention.self.key.bias', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.11.attention.output.LayerNorm.weight', 'base_model.encoder.layer.9.output.LayerNorm.bias', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.6.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.23.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.11.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.21.output.dense.weight', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.5.output.dense.bias', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.15.attention.self.value.weight', 'base_model.encoder.layer.13.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.17.attention.self.value.weight', 'base_model.encoder.layer.8.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.14.attention.output.dense.weight', 'base_model.encoder.layer.14.attention.output.dense.bias', 'base_model.encoder.layer.2.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.17.intermediate.dense.bias', 'base_model.encoder.layer.1.attention.output.dense.bias', 'base_model.encoder.layer.15.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.18.attention.output.dense.weight', 'base_model.encoder.layer.17.intermediate.dense.weight', 'base_model.encoder.layer.6.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.7.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.18.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.17.output.dense.bias', 'base_model.encoder.layer.8.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.9.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.11.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.1.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.10.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.12.intermediate.dense.bias', 'base_model.encoder.layer.0.attention.output.dense.bias', 'base_model.encoder.layer.17.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.2.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.9.attention.output.LayerNorm.weight', 'base_model.encoder.layer.23.attention.self.value.weight', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.10.attention.self.key.bias', 'base_model.encoder.layer.12.output.LayerNorm.weight', 'base_model.encoder.layer.1.attention.self.key.weight', 'base_model.encoder.layer.21.output.LayerNorm.weight', 'base_model.encoder.layer.20.attention.self.value.bias', 'base_model.encoder.layer.20.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.18.attention.self.query.bias', 'base_model.encoder.layer.18.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.8.attention.self.value.bias', 'base_model.encoder.layer.11.attention.self.key.bias', 'base_model.encoder.layer.6.intermediate.dense.weight', 'base_model.encoder.layer.9.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.11.attention.output.dense.bias', 'base_model.encoder.layer.15.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.9.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.6.intermediate.dense.bias', 'qa_outputs.weight', 'base_model.encoder.layer.12.output.dense.weight', 'base_model.encoder.layer.3.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.3.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.8.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.1.attention.self.value.bias', 'base_model.encoder.layer.4.attention.self.value.weight', 'base_model.encoder.layer.15.attention.output.dense.bias', 'base_model.encoder.layer.14.intermediate.dense.bias', 'base_model.encoder.layer.19.attention.self.key.bias', 'base_model.encoder.layer.15.attention.output.dense.weight', 'base_model.encoder.layer.4.attention.output.dense.weight', 'base_model.encoder.layer.13.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.22.output.dense.weight', 'base_model.encoder.layer.16.intermediate.dense.bias', 'base_model.encoder.layer.17.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.14.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.11.output.dense.weight', 'base_model.encoder.layer.12.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.0.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.2.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.21.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.1.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.17.output.adapters.tp.adapter_down.0.bias', 'base_model.embeddings.position_ids', 'base_model.encoder.layer.5.attention.self.key.weight', 'base_model.encoder.layer.10.attention.self.key.weight', 'base_model.encoder.layer.4.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.21.attention.self.key.weight', 'base_model.encoder.layer.1.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.6.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.15.attention.self.query.weight', 'base_model.encoder.layer.18.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.23.attention.self.key.bias', 'base_model.encoder.layer.11.attention.self.value.bias', 'base_model.encoder.layer.9.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.13.attention.output.dense.weight', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.11.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.11.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.16.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.0.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.12.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.22.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.9.attention.self.key.bias', 'base_model.encoder.layer.8.output.LayerNorm.weight', 'base_model.encoder.layer.12.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.23.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.16.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.16.attention.self.query.weight', 'base_model.encoder.layer.4.attention.self.query.weight', 'base_model.encoder.layer.20.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.4.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.16.output.dense.weight', 'base_model.encoder.layer.3.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.19.output.LayerNorm.weight', 'base_model.encoder.layer.8.attention.output.LayerNorm.bias', 'base_model.encoder.layer.19.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.20.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.14.attention.self.value.bias', 'base_model.encoder.layer.23.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.6.attention.self.key.bias', 'base_model.encoder.layer.17.attention.output.LayerNorm.bias', 'base_model.encoder.layer.17.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.4.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.5.attention.self.value.bias', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.3.attention.output.LayerNorm.weight', 'base_model.encoder.layer.15.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.21.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.19.attention.self.key.weight', 'base_model.encoder.layer.20.output.LayerNorm.bias', 'base_model.encoder.layer.2.attention.self.query.weight', 'base_model.encoder.layer.15.output.dense.bias', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.18.attention.self.query.weight', 'base_model.encoder.layer.7.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.2.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.9.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.10.attention.output.dense.bias', 'base_model.encoder.layer.1.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.10.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.11.attention.self.query.weight', 'base_model.encoder.layer.16.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.21.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.13.intermediate.dense.weight', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.1.attention.output.LayerNorm.weight', 'base_model.encoder.layer.9.attention.output.LayerNorm.bias', 'base_model.encoder.layer.9.output.dense.bias', 'base_model.encoder.layer.10.attention.self.query.bias', 'base_model.encoder.layer.2.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.6.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.7.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.10.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.12.attention.self.query.weight', 'base_model.encoder.layer.12.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.13.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.14.intermediate.dense.weight', 'base_model.encoder.layer.20.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.20.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.21.attention.self.query.weight', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.13.output.dense.weight', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.18.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.22.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.0.output.LayerNorm.weight', 'base_model.encoder.layer.1.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.18.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.22.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.6.output.adapters.ep.adapter_down.0.bias', 'base_model.embeddings.LayerNorm.bias', 'base_model.encoder.layer.20.attention.self.key.bias', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.5.intermediate.dense.bias', 'base_model.encoder.layer.18.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.14.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.0.intermediate.dense.weight', 'base_model.encoder.layer.10.intermediate.dense.weight', 'base_model.encoder.layer.16.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.21.attention.output.dense.weight', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.22.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.13.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.2.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.0.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.18.output.LayerNorm.bias', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.12.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.8.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.22.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.7.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.18.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.15.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.3.attention.self.key.bias', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.5.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.7.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.18.attention.self.value.bias', 'base_model.encoder.layer.21.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.10.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.23.attention.self.value.bias', 'base_model.encoder.layer.15.output.LayerNorm.bias', 'base_model.encoder.layer.13.attention.self.query.bias', 'base_model.encoder.layer.5.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.5.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.11.attention.output.LayerNorm.bias', 'base_model.encoder.layer.13.output.LayerNorm.bias', 'base_model.encoder.layer.0.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.22.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.3.output.LayerNorm.weight', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.5.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.1.output.dense.bias', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.9.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.18.output.dense.bias', 'base_model.encoder.layer.16.attention.output.LayerNorm.weight', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.8.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.pooler.dense.bias', 'base_model.encoder.layer.10.attention.self.query.weight', 'base_model.encoder.layer.16.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.3.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.14.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.10.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.22.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.0.intermediate.dense.bias', 'base_model.encoder.layer.9.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.1.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.7.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.18.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.1.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.6.output.LayerNorm.weight', 'base_model.encoder.layer.12.attention.self.value.bias', 'base_model.encoder.layer.8.intermediate.dense.weight', 'base_model.encoder.layer.9.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.0.attention.self.key.weight', 'base_model.encoder.layer.9.attention.self.value.bias', 'base_model.encoder.layer.20.output.adapters.ts.adapter_up.weight']
- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of XLMRobertaModel were not initialized from the model checkpoint at /cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//squad/xlm-KG_LR4e-5_EPOCH2.0_maxlen384_batchsize4_gradacc8 and are newly initialized: ['encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.layer.21.output.LayerNorm.weight', 'encoder.layer.21.attention.output.dense.bias', 'encoder.layer.6.attention.self.key.weight', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.0.attention.self.value.weight', 'encoder.layer.4.attention.self.query.weight', 'encoder.layer.18.attention.output.LayerNorm.weight', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.16.output.dense.bias', 'encoder.layer.14.output.dense.weight', 'encoder.layer.10.attention.self.value.bias', 'encoder.layer.19.attention.output.dense.bias', 'encoder.layer.7.attention.output.dense.weight', 'encoder.layer.8.output.LayerNorm.bias', 'encoder.layer.0.attention.self.value.bias', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.23.output.LayerNorm.bias', 'encoder.layer.22.attention.self.value.bias', 'encoder.layer.3.output.dense.bias', 'encoder.layer.17.output.LayerNorm.bias', 'encoder.layer.16.attention.self.value.weight', 'encoder.layer.9.attention.self.key.bias', 'encoder.layer.18.attention.self.value.bias', 'encoder.layer.23.attention.output.dense.weight', 'encoder.layer.21.intermediate.dense.bias', 'encoder.layer.3.attention.self.key.bias', 'encoder.layer.4.attention.output.dense.weight', 'encoder.layer.20.intermediate.dense.weight', 'encoder.layer.17.attention.output.dense.bias', 'encoder.layer.9.output.LayerNorm.weight', 'encoder.layer.3.attention.self.key.weight', 'encoder.layer.4.attention.self.key.bias', 'encoder.layer.12.output.LayerNorm.bias', 'encoder.layer.15.attention.output.LayerNorm.bias', 'encoder.layer.4.attention.self.value.bias', 'encoder.layer.16.attention.self.key.bias', 'embeddings.word_embeddings.weight', 'encoder.layer.22.attention.self.key.bias', 'encoder.layer.23.attention.self.query.bias', 'encoder.layer.12.attention.output.LayerNorm.weight', 'encoder.layer.20.attention.output.LayerNorm.bias', 'encoder.layer.22.output.LayerNorm.weight', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.13.attention.self.key.weight', 'encoder.layer.8.output.dense.weight', 'encoder.layer.17.attention.self.query.bias', 'encoder.layer.20.intermediate.dense.bias', 'encoder.layer.13.attention.self.key.bias', 'encoder.layer.20.output.LayerNorm.weight', 'encoder.layer.21.output.LayerNorm.bias', 'encoder.layer.12.attention.output.LayerNorm.bias', 'encoder.layer.1.attention.self.query.weight', 'encoder.layer.11.attention.self.key.bias', 'encoder.layer.9.attention.self.query.bias', 'encoder.layer.3.attention.self.value.weight', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.3.attention.self.query.bias', 'encoder.layer.10.attention.self.query.bias', 'encoder.layer.5.output.LayerNorm.bias', 'encoder.layer.9.attention.output.LayerNorm.weight', 'encoder.layer.8.attention.self.query.weight', 'encoder.layer.4.output.dense.bias', 'encoder.layer.17.attention.self.value.weight', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.7.attention.output.dense.bias', 'encoder.layer.14.attention.self.value.weight', 'encoder.layer.19.attention.output.LayerNorm.weight', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.10.intermediate.dense.weight', 'encoder.layer.10.attention.output.LayerNorm.weight', 'encoder.layer.18.intermediate.dense.bias', 'encoder.layer.21.attention.self.query.bias', 'encoder.layer.5.attention.output.dense.weight', 'encoder.layer.22.output.dense.bias', 'encoder.layer.5.output.dense.bias', 'encoder.layer.13.output.LayerNorm.weight', 'encoder.layer.10.attention.output.dense.weight', 'encoder.layer.23.attention.self.value.bias', 'encoder.layer.14.attention.output.LayerNorm.bias', 'encoder.layer.2.attention.self.query.weight', 'encoder.layer.18.output.LayerNorm.bias', 'encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.layer.20.output.dense.bias', 'encoder.layer.6.attention.output.LayerNorm.bias', 'encoder.layer.7.attention.self.query.bias', 'encoder.layer.18.attention.self.value.weight', 'encoder.layer.19.attention.self.key.weight', 'encoder.layer.14.intermediate.dense.bias', 'encoder.layer.15.attention.output.dense.weight', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.16.intermediate.dense.weight', 'encoder.layer.20.attention.self.key.weight', 'encoder.layer.23.attention.self.key.weight', 'encoder.layer.12.intermediate.dense.weight', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.7.attention.output.LayerNorm.weight', 'encoder.layer.13.attention.self.value.bias', 'encoder.layer.20.output.dense.weight', 'encoder.layer.10.attention.self.value.weight', 'encoder.layer.20.attention.self.query.bias', 'encoder.layer.17.intermediate.dense.weight', 'encoder.layer.1.output.dense.weight', 'encoder.layer.13.attention.output.dense.weight', 'encoder.layer.5.attention.self.query.bias', 'encoder.layer.11.output.LayerNorm.weight', 'encoder.layer.2.attention.self.value.weight', 'encoder.layer.3.attention.self.query.weight', 'encoder.layer.1.output.dense.bias', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.13.attention.output.LayerNorm.bias', 'encoder.layer.16.attention.self.key.weight', 'encoder.layer.9.attention.self.query.weight', 'encoder.layer.12.attention.output.dense.weight', 'encoder.layer.1.attention.self.value.weight', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.4.attention.output.LayerNorm.weight', 'encoder.layer.17.attention.output.LayerNorm.bias', 'encoder.layer.2.attention.output.dense.bias', 'encoder.layer.9.attention.output.dense.bias', 'encoder.layer.11.attention.self.key.weight', 'encoder.layer.7.output.LayerNorm.weight', 'encoder.layer.7.attention.self.query.weight', 'encoder.layer.10.output.LayerNorm.weight', 'encoder.layer.12.attention.self.value.bias', 'embeddings.LayerNorm.bias', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.4.attention.output.LayerNorm.bias', 'encoder.layer.5.attention.output.LayerNorm.weight', 'encoder.layer.8.output.dense.bias', 'encoder.layer.20.output.LayerNorm.bias', 'encoder.layer.15.attention.self.key.bias', 'encoder.layer.21.attention.self.key.weight', 'encoder.layer.16.attention.output.dense.weight', 'encoder.layer.2.attention.self.query.bias', 'encoder.layer.15.output.dense.bias', 'encoder.layer.17.output.LayerNorm.weight', 'encoder.layer.9.attention.output.LayerNorm.bias', 'encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.21.attention.self.key.bias', 'encoder.layer.22.intermediate.dense.bias', 'encoder.layer.20.attention.self.query.weight', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.4.attention.self.value.weight', 'encoder.layer.7.attention.self.key.bias', 'encoder.layer.9.output.LayerNorm.bias', 'encoder.layer.2.attention.output.LayerNorm.weight', 'encoder.layer.17.output.dense.bias', 'encoder.layer.7.attention.self.value.bias', 'encoder.layer.12.output.dense.weight', 'encoder.layer.15.attention.output.dense.bias', 'encoder.layer.3.attention.output.dense.bias', 'encoder.layer.0.output.dense.weight', 'encoder.layer.5.attention.self.key.bias', 'encoder.layer.2.attention.output.LayerNorm.bias', 'encoder.layer.15.output.dense.weight', 'encoder.layer.2.output.dense.weight', 'encoder.layer.22.attention.output.LayerNorm.weight', 'encoder.layer.11.output.LayerNorm.bias', 'encoder.layer.19.attention.output.dense.weight', 'encoder.layer.0.attention.output.LayerNorm.weight', 'encoder.layer.23.attention.output.LayerNorm.weight', 'encoder.layer.18.attention.self.key.weight', 'encoder.layer.13.output.dense.bias', 'encoder.layer.18.intermediate.dense.weight', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.17.attention.output.LayerNorm.weight', 'encoder.layer.12.intermediate.dense.bias', 'encoder.layer.8.attention.output.dense.bias', 'encoder.layer.15.attention.self.value.bias', 'encoder.layer.14.attention.self.query.weight', 'encoder.layer.17.output.dense.weight', 'encoder.layer.18.output.LayerNorm.weight', 'encoder.layer.18.output.dense.weight', 'encoder.layer.14.attention.output.dense.weight', 'encoder.layer.20.attention.self.value.bias', 'encoder.layer.0.attention.self.query.weight', 'encoder.layer.19.attention.self.key.bias', 'encoder.layer.3.attention.output.dense.weight', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.2.attention.output.dense.weight', 'encoder.layer.8.attention.self.value.bias', 'encoder.layer.8.attention.output.LayerNorm.weight', 'encoder.layer.10.attention.self.key.weight', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.16.output.dense.weight', 'encoder.layer.4.attention.self.key.weight', 'encoder.layer.17.attention.self.key.weight', 'encoder.layer.14.attention.self.value.bias', 'encoder.layer.9.attention.self.value.bias', 'encoder.layer.8.intermediate.dense.bias', 'pooler.dense.bias', 'encoder.layer.17.attention.self.query.weight', 'encoder.layer.0.attention.output.dense.bias', 'encoder.layer.21.output.dense.weight', 'encoder.layer.13.intermediate.dense.bias', 'encoder.layer.16.intermediate.dense.bias', 'encoder.layer.1.attention.output.dense.weight', 'encoder.layer.5.attention.self.key.weight', 'encoder.layer.12.attention.self.query.bias', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.14.attention.self.key.weight', 'encoder.layer.14.output.LayerNorm.weight', 'encoder.layer.22.attention.output.dense.bias', 'encoder.layer.23.output.dense.weight', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.15.output.LayerNorm.weight', 'encoder.layer.13.attention.output.dense.bias', 'encoder.layer.19.attention.self.value.weight', 'encoder.layer.16.attention.self.query.weight', 'encoder.layer.10.output.dense.bias', 'encoder.layer.18.attention.self.query.weight', 'encoder.layer.9.output.dense.weight', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.19.output.LayerNorm.weight', 'encoder.layer.21.attention.self.value.weight', 'encoder.layer.0.output.dense.bias', 'encoder.layer.1.attention.self.query.bias', 'encoder.layer.17.attention.self.value.bias', 'encoder.layer.10.attention.output.dense.bias', 'encoder.layer.15.attention.self.query.weight', 'encoder.layer.9.attention.self.key.weight', 'encoder.layer.15.intermediate.dense.weight', 'encoder.layer.14.attention.output.dense.bias', 'encoder.layer.15.attention.output.LayerNorm.weight', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.15.intermediate.dense.bias', 'encoder.layer.16.output.LayerNorm.weight', 'encoder.layer.16.output.LayerNorm.bias', 'encoder.layer.13.attention.self.query.bias', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.22.output.dense.weight', 'encoder.layer.11.attention.output.dense.bias', 'encoder.layer.19.attention.output.LayerNorm.bias', 'encoder.layer.10.output.LayerNorm.bias', 'encoder.layer.8.attention.self.key.weight', 'encoder.layer.21.attention.output.LayerNorm.weight', 'encoder.layer.2.attention.self.key.bias', 'encoder.layer.2.attention.self.key.weight', 'encoder.layer.1.attention.self.key.bias', 'encoder.layer.12.attention.self.key.weight', 'encoder.layer.17.attention.output.dense.weight', 'encoder.layer.18.attention.self.key.bias', 'encoder.layer.23.intermediate.dense.weight', 'encoder.layer.10.attention.self.key.bias', 'encoder.layer.9.output.dense.bias', 'embeddings.token_type_embeddings.weight', 'encoder.layer.18.attention.self.query.bias', 'encoder.layer.8.attention.self.key.bias', 'encoder.layer.6.attention.self.value.bias', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.14.attention.self.key.bias', 'encoder.layer.0.attention.self.key.weight', 'embeddings.LayerNorm.weight', 'encoder.layer.8.output.LayerNorm.weight', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.1.attention.self.value.bias', 'encoder.layer.12.attention.self.value.weight', 'encoder.layer.5.attention.self.value.bias', 'encoder.layer.8.attention.output.dense.weight', 'encoder.layer.6.output.dense.weight', 'encoder.layer.18.attention.output.LayerNorm.bias', 'encoder.layer.6.attention.self.query.weight', 'encoder.layer.13.output.LayerNorm.bias', 'encoder.layer.2.output.dense.bias', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.11.attention.output.dense.weight', 'encoder.layer.14.output.LayerNorm.bias', 'encoder.layer.15.attention.self.value.weight', 'encoder.layer.4.attention.output.dense.bias', 'encoder.layer.13.attention.self.query.weight', 'encoder.layer.23.attention.output.dense.bias', 'encoder.layer.11.attention.self.value.weight', 'encoder.layer.8.attention.self.value.weight', 'encoder.layer.15.attention.self.key.weight', 'encoder.layer.12.attention.self.key.bias', 'encoder.layer.16.attention.output.dense.bias', 'encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.layer.9.attention.output.dense.weight', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.0.attention.output.dense.weight', 'encoder.layer.22.attention.self.query.bias', 'encoder.layer.11.attention.output.LayerNorm.weight', 'encoder.layer.23.attention.output.LayerNorm.bias', 'encoder.layer.0.attention.self.query.bias', 'encoder.layer.7.output.dense.bias', 'encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.layer.12.output.LayerNorm.weight', 'encoder.layer.8.attention.self.query.bias', 'encoder.layer.11.output.dense.bias', 'encoder.layer.14.attention.output.LayerNorm.weight', 'encoder.layer.6.attention.output.dense.weight', 'encoder.layer.19.output.dense.bias', 'encoder.layer.18.output.dense.bias', 'encoder.layer.8.attention.output.LayerNorm.bias', 'encoder.layer.21.intermediate.dense.weight', 'encoder.layer.7.attention.output.LayerNorm.bias', 'encoder.layer.13.attention.self.value.weight', 'encoder.layer.22.attention.self.key.weight', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.19.attention.self.query.bias', 'encoder.layer.14.output.dense.bias', 'encoder.layer.3.attention.self.value.bias', 'encoder.layer.6.attention.self.value.weight', 'encoder.layer.7.intermediate.dense.bias', 'encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.10.attention.self.query.weight', 'encoder.layer.13.attention.output.LayerNorm.weight', 'encoder.layer.23.intermediate.dense.bias', 'encoder.layer.19.intermediate.dense.weight', 'encoder.layer.21.attention.output.LayerNorm.bias', 'encoder.layer.9.attention.self.value.weight', 'encoder.layer.23.attention.self.value.weight', 'encoder.layer.12.output.dense.bias', 'encoder.layer.20.attention.output.dense.bias', 'encoder.layer.1.attention.self.key.weight', 'encoder.layer.23.attention.self.key.bias', 'encoder.layer.11.attention.self.query.weight', 'encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.layer.12.attention.output.dense.bias', 'encoder.layer.21.attention.output.dense.weight', 'encoder.layer.1.attention.output.LayerNorm.weight', 'encoder.layer.6.output.LayerNorm.bias', 'encoder.layer.19.output.dense.weight', 'encoder.layer.23.output.dense.bias', 'encoder.layer.5.output.dense.weight', 'encoder.layer.22.output.LayerNorm.bias', 'encoder.layer.17.attention.self.key.bias', 'encoder.layer.6.attention.self.key.bias', 'encoder.layer.20.attention.output.LayerNorm.weight', 'encoder.layer.15.attention.self.query.bias', 'encoder.layer.22.attention.self.value.weight', 'encoder.layer.7.output.LayerNorm.bias', 'encoder.layer.23.output.LayerNorm.weight', 'encoder.layer.19.output.LayerNorm.bias', 'encoder.layer.11.attention.self.query.bias', 'encoder.layer.4.attention.self.query.bias', 'encoder.layer.12.attention.self.query.weight', 'encoder.layer.3.output.dense.weight', 'encoder.layer.23.attention.self.query.weight', 'encoder.layer.5.attention.self.value.weight', 'encoder.layer.6.attention.self.query.bias', 'encoder.layer.13.intermediate.dense.weight', 'encoder.layer.7.attention.self.key.weight', 'encoder.layer.18.attention.output.dense.bias', 'encoder.layer.16.attention.self.value.bias', 'encoder.layer.19.attention.self.value.bias', 'encoder.layer.19.attention.self.query.weight', 'encoder.layer.0.attention.self.key.bias', 'encoder.layer.21.attention.self.value.bias', 'encoder.layer.20.attention.output.dense.weight', 'encoder.layer.17.intermediate.dense.bias', 'encoder.layer.16.attention.self.query.bias', 'encoder.layer.10.output.dense.weight', 'encoder.layer.22.attention.output.LayerNorm.bias', 'encoder.layer.5.attention.self.query.weight', 'encoder.layer.16.attention.output.LayerNorm.bias', 'encoder.layer.15.output.LayerNorm.bias', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.4.output.dense.weight', 'encoder.layer.21.attention.self.query.weight', 'encoder.layer.16.attention.output.LayerNorm.weight', 'encoder.layer.21.output.dense.bias', 'encoder.layer.11.attention.self.value.bias', 'encoder.layer.13.output.dense.weight', 'pooler.dense.weight', 'encoder.layer.6.attention.output.dense.bias', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.6.output.dense.bias', 'encoder.layer.22.attention.self.query.weight', 'encoder.layer.1.attention.output.dense.bias', 'encoder.layer.18.attention.output.dense.weight', 'encoder.layer.14.intermediate.dense.weight', 'encoder.layer.20.attention.self.value.weight', 'encoder.layer.22.attention.output.dense.weight', 'encoder.layer.7.attention.self.value.weight', 'encoder.layer.7.output.dense.weight', 'encoder.layer.22.intermediate.dense.weight', 'encoder.layer.11.output.dense.weight', 'encoder.layer.20.attention.self.key.bias', 'encoder.layer.14.attention.self.query.bias', 'encoder.layer.19.intermediate.dense.bias', 'encoder.layer.5.attention.output.dense.bias', 'encoder.layer.2.attention.self.value.bias', 'encoder.layer.6.attention.output.LayerNorm.weight', 'encoder.layer.0.intermediate.dense.bias', 'embeddings.position_embeddings.weight', 'encoder.layer.10.attention.output.LayerNorm.bias', 'encoder.layer.3.output.LayerNorm.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Overwriting existing adapter 'ep'.
Overwriting existing adapter 'tp'.
Overwriting existing adapter 'es'.
Overwriting existing adapter 'ts'.
Overwriting existing adapter fusion module 'ep,tp,es,ts'
05/09/2022 20:07:50 - INFO - __main__ -   lang2id = None
05/09/2022 20:07:54 - INFO - __main__ -   Training/evaluation parameters Namespace(adam_epsilon=1e-08, cache_dir='', config_name='', data_dir=None, device=device(type='cuda'), do_eval=True, do_lower_case=False, do_train=False, doc_stride=128, eval_all_checkpoints=False, eval_lang='vi', evaluate_during_training=False, fp16=False, fp16_opt_level='O1', gradient_accumulation_steps=1, learning_rate=5e-05, local_rank=-1, logging_steps=50, max_answer_length=30, max_grad_norm=1.0, max_query_length=64, max_seq_length=384, max_steps=-1, model_name='xlm-KG', model_name_or_path='/cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//squad/xlm-KG_LR4e-5_EPOCH2.0_maxlen384_batchsize4_gradacc8', model_type='xlm', modelkg_dir='/cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/adapter/xlmr_adapter', n_best_size=20, n_gpu=1, no_cuda=False, null_score_diff_threshold=0.0, num_train_epochs=3.0, output_dir='/cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//squad/xlm-KG_LR4e-5_EPOCH2.0_maxlen384_batchsize4_gradacc8/predictions/xquad/', overwrite_cache=False, overwrite_output_dir=False, per_gpu_eval_batch_size=8, per_gpu_train_batch_size=8, predict_file='/cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/download//xquad//xquad.vi.json', save_steps=50, seed=42, server_ip='', server_port='', threads=1, tokenizer_name='', train_file=None, train_lang='en', verbose_logging=False, version_2_with_negative=False, warmup_steps=0, weight_decay=0.0)
05/09/2022 20:07:54 - INFO - __main__ -   Loading checkpoint /cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//squad/xlm-KG_LR4e-5_EPOCH2.0_maxlen384_batchsize4_gradacc8 for evaluation
05/09/2022 20:07:54 - INFO - __main__ -   Evaluate the following checkpoints: ['/cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//squad/xlm-KG_LR4e-5_EPOCH2.0_maxlen384_batchsize4_gradacc8']
Some weights of the model checkpoint at /cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//squad/xlm-KG_LR4e-5_EPOCH2.0_maxlen384_batchsize4_gradacc8 were not used when initializing XLMRobertaModel: ['base_model.encoder.layer.2.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.9.attention.self.query.weight', 'base_model.encoder.layer.17.attention.self.key.bias', 'base_model.encoder.layer.6.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.5.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.19.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.23.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.18.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.10.attention.self.value.bias', 'base_model.encoder.layer.17.attention.output.LayerNorm.weight', 'base_model.encoder.layer.9.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.7.attention.self.key.bias', 'base_model.encoder.layer.2.attention.output.LayerNorm.weight', 'base_model.encoder.layer.20.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.pooler.dense.weight', 'base_model.encoder.layer.1.output.LayerNorm.weight', 'base_model.encoder.layer.13.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.4.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.18.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.20.attention.self.query.bias', 'base_model.encoder.layer.10.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.8.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.8.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.12.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.22.attention.output.LayerNorm.weight', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.23.attention.output.dense.bias', 'base_model.encoder.layer.23.attention.self.key.weight', 'base_model.encoder.layer.10.attention.output.LayerNorm.bias', 'base_model.encoder.layer.10.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.2.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.10.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.12.attention.self.query.bias', 'base_model.encoder.layer.23.output.LayerNorm.bias', 'base_model.encoder.layer.2.output.LayerNorm.weight', 'base_model.encoder.layer.23.attention.output.LayerNorm.weight', 'base_model.encoder.layer.2.attention.output.dense.bias', 'base_model.encoder.layer.21.attention.self.key.bias', 'base_model.encoder.layer.4.attention.output.dense.bias', 'base_model.encoder.layer.12.attention.output.LayerNorm.bias', 'base_model.encoder.layer.1.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.4.attention.self.value.bias', 'base_model.embeddings.position_embeddings.weight', 'base_model.encoder.layer.4.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.17.attention.self.query.bias', 'base_model.encoder.layer.19.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.8.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.0.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.0.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.15.attention.self.key.bias', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.20.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.21.attention.self.query.bias', 'base_model.encoder.layer.19.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.17.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.10.attention.self.value.weight', 'base_model.encoder.layer.18.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.23.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.17.output.LayerNorm.weight', 'base_model.encoder.layer.19.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.17.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.11.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.21.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.19.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.10.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.10.attention.output.dense.weight', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.22.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.23.intermediate.dense.weight', 'base_model.encoder.layer.5.attention.output.LayerNorm.weight', 'base_model.encoder.layer.19.output.dense.bias', 'base_model.encoder.layer.9.output.dense.weight', 'base_model.encoder.layer.11.output.LayerNorm.weight', 'base_model.encoder.layer.15.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.8.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.7.attention.output.dense.weight', 'base_model.encoder.layer.14.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.16.output.dense.bias', 'base_model.encoder.layer.12.attention.self.key.bias', 'base_model.encoder.layer.18.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.16.attention.output.dense.weight', 'base_model.encoder.layer.20.output.dense.bias', 'base_model.encoder.layer.9.attention.output.dense.weight', 'base_model.encoder.layer.2.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.7.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.7.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.12.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.3.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.5.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.4.output.LayerNorm.bias', 'base_model.encoder.layer.0.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.13.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.0.attention.self.value.weight', 'base_model.encoder.layer.4.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.7.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.17.attention.output.dense.bias', 'base_model.encoder.layer.14.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.23.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.20.attention.self.key.weight', 'base_model.encoder.layer.13.output.LayerNorm.weight', 'base_model.encoder.layer.12.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.14.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.22.intermediate.dense.weight', 'base_model.encoder.layer.4.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.12.attention.output.dense.bias', 'base_model.encoder.layer.16.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.0.attention.output.LayerNorm.weight', 'base_model.encoder.layer.3.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.3.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.3.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.15.attention.output.LayerNorm.bias', 'base_model.encoder.layer.4.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.22.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.4.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.22.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.21.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.2.attention.self.key.bias', 'base_model.encoder.layer.2.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.9.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.0.attention.output.dense.weight', 'base_model.encoder.layer.7.output.dense.bias', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.15.output.LayerNorm.weight', 'base_model.encoder.layer.13.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.23.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.9.intermediate.dense.weight', 'base_model.encoder.layer.18.attention.self.key.bias', 'base_model.encoder.layer.20.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.15.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.15.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.17.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.23.intermediate.dense.bias', 'base_model.encoder.layer.4.output.LayerNorm.weight', 'base_model.encoder.layer.12.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.16.attention.output.LayerNorm.bias', 'base_model.encoder.layer.17.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.11.attention.self.key.weight', 'base_model.encoder.layer.1.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.13.intermediate.dense.bias', 'base_model.encoder.layer.8.attention.self.key.weight', 'base_model.encoder.layer.23.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.22.attention.self.key.weight', 'base_model.encoder.layer.13.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.15.attention.self.query.bias', 'base_model.encoder.layer.12.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.11.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.7.attention.output.LayerNorm.weight', 'base_model.encoder.layer.11.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.15.attention.output.LayerNorm.weight', 'base_model.encoder.layer.0.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.21.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.5.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.5.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.2.output.dense.weight', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.0.attention.output.LayerNorm.bias', 'base_model.encoder.layer.23.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.19.output.LayerNorm.bias', 'base_model.encoder.layer.5.attention.self.key.bias', 'base_model.encoder.layer.9.output.LayerNorm.weight', 'base_model.encoder.layer.13.attention.output.LayerNorm.bias', 'base_model.encoder.layer.1.attention.output.LayerNorm.bias', 'base_model.encoder.layer.11.intermediate.dense.weight', 'base_model.encoder.layer.2.attention.self.value.bias', 'base_model.encoder.layer.14.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.1.output.LayerNorm.bias', 'base_model.encoder.layer.16.output.LayerNorm.weight', 'base_model.encoder.layer.8.output.dense.bias', 'base_model.encoder.layer.17.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.20.attention.output.dense.bias', 'base_model.encoder.layer.14.attention.self.key.bias', 'base_model.encoder.layer.23.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.23.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.14.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.23.output.dense.bias', 'base_model.encoder.layer.1.output.dense.weight', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.15.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.13.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.21.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.0.output.LayerNorm.bias', 'base_model.encoder.layer.7.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.9.attention.self.query.bias', 'base_model.encoder.layer.10.output.adapters.ts.adapter_up.bias', 'base_model.embeddings.LayerNorm.weight', 'base_model.encoder.layer.11.output.dense.bias', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.19.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.1.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.2.attention.self.value.weight', 'base_model.encoder.layer.14.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.1.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.4.attention.output.LayerNorm.weight', 'base_model.encoder.layer.9.attention.self.key.weight', 'base_model.encoder.layer.6.attention.output.LayerNorm.bias', 'base_model.encoder.layer.3.attention.self.key.weight', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.4.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.5.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.22.output.LayerNorm.bias', 'base_model.encoder.layer.22.attention.self.query.weight', 'base_model.encoder.layer.22.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.14.attention.output.LayerNorm.weight', 'base_model.encoder.layer.18.intermediate.dense.weight', 'base_model.encoder.layer.1.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.0.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.21.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.19.attention.self.query.bias', 'base_model.encoder.layer.6.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.3.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.16.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.19.output.adapters.ep.adapter_down.0.weight', 'base_model.embeddings.word_embeddings.weight', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.23.attention.output.LayerNorm.bias', 'base_model.encoder.layer.0.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.7.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.14.output.dense.bias', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.21.attention.self.value.weight', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.21.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.15.output.dense.weight', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.11.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.16.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.11.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.4.intermediate.dense.bias', 'base_model.encoder.layer.18.intermediate.dense.bias', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.10.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.0.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.17.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.7.attention.output.LayerNorm.bias', 'base_model.encoder.layer.2.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.15.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.14.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.2.attention.self.key.weight', 'base_model.encoder.layer.10.output.dense.bias', 'base_model.encoder.layer.13.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.18.attention.self.value.weight', 'base_model.encoder.layer.5.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.8.attention.self.query.weight', 'base_model.encoder.layer.17.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.20.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.8.attention.output.dense.bias', 'base_model.encoder.layer.1.attention.self.value.weight', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.21.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.5.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.9.attention.output.dense.bias', 'base_model.encoder.layer.18.attention.output.LayerNorm.weight', 'base_model.encoder.layer.17.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.20.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.3.intermediate.dense.bias', 'base_model.encoder.layer.1.attention.output.dense.weight', 'base_model.encoder.layer.21.output.LayerNorm.bias', 'base_model.encoder.layer.9.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.21.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.0.attention.self.query.weight', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.10.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.2.attention.output.LayerNorm.bias', 'base_model.encoder.layer.11.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.13.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.13.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.19.output.dense.weight', 'base_model.encoder.layer.20.intermediate.dense.bias', 'base_model.encoder.layer.13.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.6.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.12.attention.output.LayerNorm.weight', 'base_model.encoder.layer.7.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.21.attention.output.LayerNorm.bias', 'base_model.encoder.layer.0.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.21.intermediate.dense.weight', 'base_model.encoder.layer.7.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.11.attention.self.value.weight', 'base_model.encoder.layer.3.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.19.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.4.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.5.attention.output.LayerNorm.bias', 'base_model.encoder.layer.0.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.19.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.5.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.16.output.LayerNorm.bias', 'base_model.encoder.layer.17.attention.self.value.bias', 'base_model.encoder.layer.11.output.LayerNorm.bias', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.10.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.4.output.dense.bias', 'base_model.encoder.layer.5.output.dense.weight', 'base_model.encoder.layer.9.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.6.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.0.output.dense.bias', 'base_model.encoder.layer.1.attention.self.key.bias', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.17.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.14.attention.self.query.bias', 'base_model.encoder.layer.16.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.5.attention.output.dense.weight', 'base_model.encoder.layer.9.intermediate.dense.bias', 'base_model.encoder.layer.22.attention.self.query.bias', 'base_model.encoder.layer.15.intermediate.dense.bias', 'base_model.encoder.layer.19.intermediate.dense.weight', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.11.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.20.output.LayerNorm.weight', 'base_model.encoder.layer.6.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.3.attention.output.LayerNorm.bias', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.14.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.12.attention.self.value.weight', 'base_model.encoder.layer.10.output.LayerNorm.weight', 'base_model.encoder.layer.6.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.15.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.17.output.dense.weight', 'base_model.encoder.layer.20.output.dense.weight', 'base_model.encoder.layer.21.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.5.output.LayerNorm.weight', 'base_model.encoder.layer.8.attention.output.LayerNorm.weight', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.22.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.13.attention.output.LayerNorm.weight', 'base_model.encoder.layer.17.attention.self.key.weight', 'base_model.encoder.layer.5.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.13.attention.output.dense.bias', 'base_model.encoder.layer.14.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.14.attention.self.query.weight', 'base_model.encoder.layer.18.output.LayerNorm.weight', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.11.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.5.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.9.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.15.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.3.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.7.attention.output.dense.bias', 'base_model.encoder.layer.8.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.20.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.8.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.3.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.18.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.5.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.21.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.16.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.2.intermediate.dense.weight', 'base_model.encoder.layer.7.attention.self.value.weight', 'base_model.encoder.layer.8.attention.self.query.bias', 'base_model.encoder.layer.16.attention.self.query.bias', 'base_model.encoder.layer.6.attention.self.value.bias', 'base_model.encoder.layer.4.attention.output.LayerNorm.bias', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.23.attention.self.query.weight', 'base_model.encoder.layer.17.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.8.intermediate.dense.bias', 'base_model.encoder.layer.15.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.3.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.18.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.19.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.21.output.dense.bias', 'base_model.encoder.layer.12.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.17.output.LayerNorm.bias', 'base_model.encoder.layer.1.attention.self.query.weight', 'base_model.encoder.layer.1.intermediate.dense.bias', 'base_model.encoder.layer.22.attention.self.value.bias', 'base_model.encoder.layer.11.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.10.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.18.attention.output.dense.bias', 'base_model.encoder.layer.22.attention.output.LayerNorm.bias', 'base_model.encoder.layer.7.intermediate.dense.weight', 'base_model.encoder.layer.19.attention.output.dense.weight', 'base_model.encoder.layer.12.output.LayerNorm.bias', 'base_model.encoder.layer.2.output.LayerNorm.bias', 'base_model.encoder.layer.4.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.3.output.dense.bias', 'base_model.encoder.layer.16.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.22.attention.self.value.weight', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.5.attention.self.query.weight', 'base_model.encoder.layer.21.intermediate.dense.bias', 'base_model.encoder.layer.14.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.21.attention.output.dense.bias', 'base_model.encoder.layer.12.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.14.attention.self.value.weight', 'base_model.encoder.layer.14.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.6.attention.self.value.weight', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.16.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.6.attention.self.query.bias', 'base_model.encoder.layer.22.output.dense.bias', 'base_model.encoder.layer.3.intermediate.dense.weight', 'base_model.encoder.layer.10.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.6.output.LayerNorm.bias', 'base_model.encoder.layer.22.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.11.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.22.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.1.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.2.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.6.attention.self.key.weight', 'base_model.encoder.layer.12.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.22.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.2.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.20.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.22.intermediate.dense.bias', 'base_model.encoder.layer.8.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'qa_outputs.bias', 'base_model.encoder.layer.11.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.14.attention.self.key.weight', 'base_model.encoder.layer.6.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.22.attention.self.key.bias', 'base_model.encoder.layer.13.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.15.attention.self.value.bias', 'base_model.encoder.layer.18.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.7.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.7.intermediate.dense.bias', 'base_model.encoder.layer.14.output.dense.weight', 'base_model.encoder.layer.21.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.3.output.LayerNorm.bias', 'base_model.encoder.layer.16.attention.self.value.weight', 'base_model.encoder.layer.6.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.23.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.3.attention.output.dense.weight', 'base_model.encoder.layer.5.attention.self.value.weight', 'base_model.encoder.layer.23.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.12.output.dense.bias', 'base_model.encoder.layer.2.attention.output.dense.weight', 'base_model.encoder.layer.7.output.LayerNorm.weight', 'base_model.encoder.layer.10.attention.output.LayerNorm.weight', 'base_model.encoder.layer.15.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.17.attention.output.dense.weight', 'base_model.encoder.layer.18.attention.output.LayerNorm.bias', 'base_model.encoder.layer.13.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.7.output.LayerNorm.bias', 'base_model.encoder.layer.21.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.1.intermediate.dense.weight', 'base_model.encoder.layer.11.intermediate.dense.bias', 'base_model.encoder.layer.6.output.dense.weight', 'base_model.encoder.layer.19.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.2.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.20.intermediate.dense.weight', 'base_model.encoder.layer.12.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.13.output.dense.bias', 'base_model.encoder.layer.19.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.9.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.15.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.18.attention.self.key.weight', 'base_model.encoder.layer.15.intermediate.dense.weight', 'base_model.encoder.layer.3.attention.output.dense.bias', 'base_model.encoder.layer.1.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.6.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.6.attention.output.dense.bias', 'base_model.encoder.layer.2.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.5.output.LayerNorm.bias', 'base_model.encoder.layer.20.attention.self.value.weight', 'base_model.encoder.layer.3.attention.self.query.bias', 'base_model.encoder.layer.16.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.14.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.2.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.5.intermediate.dense.weight', 'base_model.encoder.layer.8.output.LayerNorm.bias', 'base_model.encoder.layer.8.attention.self.key.bias', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.7.output.dense.weight', 'base_model.encoder.layer.18.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.16.attention.self.value.bias', 'base_model.encoder.layer.4.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.0.attention.self.query.bias', 'base_model.encoder.layer.5.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.7.attention.self.value.bias', 'base_model.encoder.layer.16.intermediate.dense.weight', 'base_model.encoder.layer.20.attention.self.query.weight', 'base_model.encoder.layer.16.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.19.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.4.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.6.attention.output.LayerNorm.weight', 'base_model.encoder.layer.8.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.20.attention.output.LayerNorm.weight', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.11.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.3.attention.self.query.weight', 'base_model.encoder.layer.13.attention.self.value.weight', 'base_model.encoder.layer.23.output.dense.weight', 'base_model.encoder.layer.0.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.16.attention.self.key.bias', 'base_model.encoder.layer.1.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.6.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.12.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.4.attention.self.key.bias', 'base_model.encoder.layer.14.attention.output.LayerNorm.bias', 'base_model.encoder.layer.17.attention.self.query.weight', 'base_model.encoder.layer.6.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.19.attention.self.query.weight', 'base_model.encoder.layer.19.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.21.attention.self.value.bias', 'base_model.encoder.layer.3.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.11.attention.self.query.bias', 'base_model.encoder.layer.2.intermediate.dense.bias', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.17.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.21.attention.output.LayerNorm.weight', 'base_model.encoder.layer.12.attention.self.key.weight', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.0.attention.self.key.bias', 'base_model.encoder.layer.18.output.dense.weight', 'base_model.encoder.layer.10.output.dense.weight', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.22.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.12.intermediate.dense.weight', 'base_model.encoder.layer.8.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.16.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.20.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.23.attention.self.query.bias', 'base_model.encoder.layer.7.attention.self.key.weight', 'base_model.encoder.layer.8.attention.output.dense.weight', 'base_model.encoder.layer.4.intermediate.dense.weight', 'base_model.encoder.layer.11.attention.output.dense.weight', 'base_model.encoder.layer.13.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.15.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.20.attention.output.dense.weight', 'base_model.encoder.layer.8.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.15.attention.self.key.weight', 'base_model.encoder.layer.14.output.LayerNorm.bias', 'base_model.encoder.layer.14.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.10.intermediate.dense.bias', 'base_model.encoder.layer.7.attention.self.query.bias', 'base_model.encoder.layer.10.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.20.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.23.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.20.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.13.attention.self.value.bias', 'base_model.encoder.layer.9.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.6.attention.self.query.weight', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.12.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.19.attention.output.LayerNorm.weight', 'base_model.encoder.layer.2.attention.self.query.bias', 'base_model.encoder.layer.23.output.LayerNorm.weight', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.7.attention.self.query.weight', 'base_model.encoder.layer.17.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.16.attention.output.dense.bias', 'base_model.encoder.layer.16.attention.self.key.weight', 'base_model.encoder.layer.1.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.19.attention.self.value.weight', 'base_model.encoder.layer.14.output.LayerNorm.weight', 'base_model.encoder.layer.6.attention.output.dense.weight', 'base_model.encoder.layer.0.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.2.output.dense.bias', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.0.output.dense.weight', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.3.attention.self.value.bias', 'base_model.encoder.layer.9.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.22.attention.output.dense.bias', 'base_model.encoder.layer.4.attention.self.query.bias', 'base_model.encoder.layer.23.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.20.attention.output.LayerNorm.bias', 'base_model.encoder.layer.19.attention.output.dense.bias', 'base_model.encoder.layer.3.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.4.attention.self.key.weight', 'base_model.encoder.layer.10.output.LayerNorm.bias', 'base_model.encoder.layer.3.attention.self.value.weight', 'base_model.encoder.layer.0.attention.self.value.bias', 'base_model.encoder.layer.22.output.LayerNorm.weight', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.3.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.19.intermediate.dense.bias', 'base_model.encoder.layer.4.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.7.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.8.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.16.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.4.output.dense.weight', 'base_model.encoder.layer.19.attention.output.LayerNorm.bias', 'base_model.encoder.layer.12.attention.output.dense.weight', 'base_model.encoder.layer.8.output.dense.weight', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.9.attention.self.value.weight', 'base_model.encoder.layer.19.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.1.attention.self.query.bias', 'base_model.encoder.layer.13.attention.self.key.weight', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.0.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.6.output.dense.bias', 'base_model.encoder.layer.23.attention.output.dense.weight', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.3.output.dense.weight', 'base_model.encoder.layer.22.attention.output.dense.weight', 'base_model.encoder.layer.4.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.5.attention.self.query.bias', 'base_model.encoder.layer.7.output.adapters.ts.adapter_up.bias', 'base_model.embeddings.token_type_embeddings.weight', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.8.attention.self.value.weight', 'base_model.encoder.layer.15.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.5.attention.output.dense.bias', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.19.attention.self.value.bias', 'base_model.encoder.layer.23.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.13.attention.self.query.weight', 'base_model.encoder.layer.13.attention.self.key.bias', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.11.attention.output.LayerNorm.weight', 'base_model.encoder.layer.9.output.LayerNorm.bias', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.6.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.23.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.11.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.21.output.dense.weight', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.5.output.dense.bias', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.15.attention.self.value.weight', 'base_model.encoder.layer.13.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.17.attention.self.value.weight', 'base_model.encoder.layer.8.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.14.attention.output.dense.weight', 'base_model.encoder.layer.14.attention.output.dense.bias', 'base_model.encoder.layer.2.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.17.intermediate.dense.bias', 'base_model.encoder.layer.1.attention.output.dense.bias', 'base_model.encoder.layer.15.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.18.attention.output.dense.weight', 'base_model.encoder.layer.17.intermediate.dense.weight', 'base_model.encoder.layer.6.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.7.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.18.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.17.output.dense.bias', 'base_model.encoder.layer.8.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.9.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.11.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.1.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.10.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.12.intermediate.dense.bias', 'base_model.encoder.layer.0.attention.output.dense.bias', 'base_model.encoder.layer.17.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.2.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.9.attention.output.LayerNorm.weight', 'base_model.encoder.layer.23.attention.self.value.weight', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.10.attention.self.key.bias', 'base_model.encoder.layer.12.output.LayerNorm.weight', 'base_model.encoder.layer.1.attention.self.key.weight', 'base_model.encoder.layer.21.output.LayerNorm.weight', 'base_model.encoder.layer.20.attention.self.value.bias', 'base_model.encoder.layer.20.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.18.attention.self.query.bias', 'base_model.encoder.layer.18.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.8.attention.self.value.bias', 'base_model.encoder.layer.11.attention.self.key.bias', 'base_model.encoder.layer.6.intermediate.dense.weight', 'base_model.encoder.layer.9.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.11.attention.output.dense.bias', 'base_model.encoder.layer.15.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.9.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.6.intermediate.dense.bias', 'qa_outputs.weight', 'base_model.encoder.layer.12.output.dense.weight', 'base_model.encoder.layer.3.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.3.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.8.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.1.attention.self.value.bias', 'base_model.encoder.layer.4.attention.self.value.weight', 'base_model.encoder.layer.15.attention.output.dense.bias', 'base_model.encoder.layer.14.intermediate.dense.bias', 'base_model.encoder.layer.19.attention.self.key.bias', 'base_model.encoder.layer.15.attention.output.dense.weight', 'base_model.encoder.layer.4.attention.output.dense.weight', 'base_model.encoder.layer.13.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.22.output.dense.weight', 'base_model.encoder.layer.16.intermediate.dense.bias', 'base_model.encoder.layer.17.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.14.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.11.output.dense.weight', 'base_model.encoder.layer.12.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.0.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.2.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.21.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.1.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.17.output.adapters.tp.adapter_down.0.bias', 'base_model.embeddings.position_ids', 'base_model.encoder.layer.5.attention.self.key.weight', 'base_model.encoder.layer.10.attention.self.key.weight', 'base_model.encoder.layer.4.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.21.attention.self.key.weight', 'base_model.encoder.layer.1.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.6.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.15.attention.self.query.weight', 'base_model.encoder.layer.18.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.23.attention.self.key.bias', 'base_model.encoder.layer.11.attention.self.value.bias', 'base_model.encoder.layer.9.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.13.attention.output.dense.weight', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.11.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.11.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.16.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.0.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.12.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.22.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.9.attention.self.key.bias', 'base_model.encoder.layer.8.output.LayerNorm.weight', 'base_model.encoder.layer.12.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.23.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.16.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.16.attention.self.query.weight', 'base_model.encoder.layer.4.attention.self.query.weight', 'base_model.encoder.layer.20.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.4.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.16.output.dense.weight', 'base_model.encoder.layer.3.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.19.output.LayerNorm.weight', 'base_model.encoder.layer.8.attention.output.LayerNorm.bias', 'base_model.encoder.layer.19.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.20.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.14.attention.self.value.bias', 'base_model.encoder.layer.23.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.6.attention.self.key.bias', 'base_model.encoder.layer.17.attention.output.LayerNorm.bias', 'base_model.encoder.layer.17.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.4.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.5.attention.self.value.bias', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.3.attention.output.LayerNorm.weight', 'base_model.encoder.layer.15.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.21.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.19.attention.self.key.weight', 'base_model.encoder.layer.20.output.LayerNorm.bias', 'base_model.encoder.layer.2.attention.self.query.weight', 'base_model.encoder.layer.15.output.dense.bias', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.18.attention.self.query.weight', 'base_model.encoder.layer.7.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.2.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.9.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.10.attention.output.dense.bias', 'base_model.encoder.layer.1.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.10.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.11.attention.self.query.weight', 'base_model.encoder.layer.16.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.21.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.13.intermediate.dense.weight', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.1.attention.output.LayerNorm.weight', 'base_model.encoder.layer.9.attention.output.LayerNorm.bias', 'base_model.encoder.layer.9.output.dense.bias', 'base_model.encoder.layer.10.attention.self.query.bias', 'base_model.encoder.layer.2.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.6.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.7.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.10.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.12.attention.self.query.weight', 'base_model.encoder.layer.12.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.13.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.14.intermediate.dense.weight', 'base_model.encoder.layer.20.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.20.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.21.attention.self.query.weight', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.13.output.dense.weight', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.18.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.22.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.0.output.LayerNorm.weight', 'base_model.encoder.layer.1.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.18.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.22.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.6.output.adapters.ep.adapter_down.0.bias', 'base_model.embeddings.LayerNorm.bias', 'base_model.encoder.layer.20.attention.self.key.bias', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.5.intermediate.dense.bias', 'base_model.encoder.layer.18.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.14.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.0.intermediate.dense.weight', 'base_model.encoder.layer.10.intermediate.dense.weight', 'base_model.encoder.layer.16.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.21.attention.output.dense.weight', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.22.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.13.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.2.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.0.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.18.output.LayerNorm.bias', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.12.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.8.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.22.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.7.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.18.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.15.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.3.attention.self.key.bias', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.5.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.7.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.18.attention.self.value.bias', 'base_model.encoder.layer.21.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.10.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.23.attention.self.value.bias', 'base_model.encoder.layer.15.output.LayerNorm.bias', 'base_model.encoder.layer.13.attention.self.query.bias', 'base_model.encoder.layer.5.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.5.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.11.attention.output.LayerNorm.bias', 'base_model.encoder.layer.13.output.LayerNorm.bias', 'base_model.encoder.layer.0.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.22.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.3.output.LayerNorm.weight', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.5.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.1.output.dense.bias', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.9.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.18.output.dense.bias', 'base_model.encoder.layer.16.attention.output.LayerNorm.weight', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.8.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.pooler.dense.bias', 'base_model.encoder.layer.10.attention.self.query.weight', 'base_model.encoder.layer.16.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.3.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.14.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.10.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.22.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.0.intermediate.dense.bias', 'base_model.encoder.layer.9.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.1.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.7.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.18.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.1.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.6.output.LayerNorm.weight', 'base_model.encoder.layer.12.attention.self.value.bias', 'base_model.encoder.layer.8.intermediate.dense.weight', 'base_model.encoder.layer.9.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.0.attention.self.key.weight', 'base_model.encoder.layer.9.attention.self.value.bias', 'base_model.encoder.layer.20.output.adapters.ts.adapter_up.weight']
- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of XLMRobertaModel were not initialized from the model checkpoint at /cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//squad/xlm-KG_LR4e-5_EPOCH2.0_maxlen384_batchsize4_gradacc8 and are newly initialized: ['encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.layer.21.output.LayerNorm.weight', 'encoder.layer.21.attention.output.dense.bias', 'encoder.layer.6.attention.self.key.weight', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.0.attention.self.value.weight', 'encoder.layer.4.attention.self.query.weight', 'encoder.layer.18.attention.output.LayerNorm.weight', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.16.output.dense.bias', 'encoder.layer.14.output.dense.weight', 'encoder.layer.10.attention.self.value.bias', 'encoder.layer.19.attention.output.dense.bias', 'encoder.layer.7.attention.output.dense.weight', 'encoder.layer.8.output.LayerNorm.bias', 'encoder.layer.0.attention.self.value.bias', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.23.output.LayerNorm.bias', 'encoder.layer.22.attention.self.value.bias', 'encoder.layer.3.output.dense.bias', 'encoder.layer.17.output.LayerNorm.bias', 'encoder.layer.16.attention.self.value.weight', 'encoder.layer.9.attention.self.key.bias', 'encoder.layer.18.attention.self.value.bias', 'encoder.layer.23.attention.output.dense.weight', 'encoder.layer.21.intermediate.dense.bias', 'encoder.layer.3.attention.self.key.bias', 'encoder.layer.4.attention.output.dense.weight', 'encoder.layer.20.intermediate.dense.weight', 'encoder.layer.17.attention.output.dense.bias', 'encoder.layer.9.output.LayerNorm.weight', 'encoder.layer.3.attention.self.key.weight', 'encoder.layer.4.attention.self.key.bias', 'encoder.layer.12.output.LayerNorm.bias', 'encoder.layer.15.attention.output.LayerNorm.bias', 'encoder.layer.4.attention.self.value.bias', 'encoder.layer.16.attention.self.key.bias', 'embeddings.word_embeddings.weight', 'encoder.layer.22.attention.self.key.bias', 'encoder.layer.23.attention.self.query.bias', 'encoder.layer.12.attention.output.LayerNorm.weight', 'encoder.layer.20.attention.output.LayerNorm.bias', 'encoder.layer.22.output.LayerNorm.weight', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.13.attention.self.key.weight', 'encoder.layer.8.output.dense.weight', 'encoder.layer.17.attention.self.query.bias', 'encoder.layer.20.intermediate.dense.bias', 'encoder.layer.13.attention.self.key.bias', 'encoder.layer.20.output.LayerNorm.weight', 'encoder.layer.21.output.LayerNorm.bias', 'encoder.layer.12.attention.output.LayerNorm.bias', 'encoder.layer.1.attention.self.query.weight', 'encoder.layer.11.attention.self.key.bias', 'encoder.layer.9.attention.self.query.bias', 'encoder.layer.3.attention.self.value.weight', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.3.attention.self.query.bias', 'encoder.layer.10.attention.self.query.bias', 'encoder.layer.5.output.LayerNorm.bias', 'encoder.layer.9.attention.output.LayerNorm.weight', 'encoder.layer.8.attention.self.query.weight', 'encoder.layer.4.output.dense.bias', 'encoder.layer.17.attention.self.value.weight', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.7.attention.output.dense.bias', 'encoder.layer.14.attention.self.value.weight', 'encoder.layer.19.attention.output.LayerNorm.weight', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.10.intermediate.dense.weight', 'encoder.layer.10.attention.output.LayerNorm.weight', 'encoder.layer.18.intermediate.dense.bias', 'encoder.layer.21.attention.self.query.bias', 'encoder.layer.5.attention.output.dense.weight', 'encoder.layer.22.output.dense.bias', 'encoder.layer.5.output.dense.bias', 'encoder.layer.13.output.LayerNorm.weight', 'encoder.layer.10.attention.output.dense.weight', 'encoder.layer.23.attention.self.value.bias', 'encoder.layer.14.attention.output.LayerNorm.bias', 'encoder.layer.2.attention.self.query.weight', 'encoder.layer.18.output.LayerNorm.bias', 'encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.layer.20.output.dense.bias', 'encoder.layer.6.attention.output.LayerNorm.bias', 'encoder.layer.7.attention.self.query.bias', 'encoder.layer.18.attention.self.value.weight', 'encoder.layer.19.attention.self.key.weight', 'encoder.layer.14.intermediate.dense.bias', 'encoder.layer.15.attention.output.dense.weight', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.16.intermediate.dense.weight', 'encoder.layer.20.attention.self.key.weight', 'encoder.layer.23.attention.self.key.weight', 'encoder.layer.12.intermediate.dense.weight', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.7.attention.output.LayerNorm.weight', 'encoder.layer.13.attention.self.value.bias', 'encoder.layer.20.output.dense.weight', 'encoder.layer.10.attention.self.value.weight', 'encoder.layer.20.attention.self.query.bias', 'encoder.layer.17.intermediate.dense.weight', 'encoder.layer.1.output.dense.weight', 'encoder.layer.13.attention.output.dense.weight', 'encoder.layer.5.attention.self.query.bias', 'encoder.layer.11.output.LayerNorm.weight', 'encoder.layer.2.attention.self.value.weight', 'encoder.layer.3.attention.self.query.weight', 'encoder.layer.1.output.dense.bias', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.13.attention.output.LayerNorm.bias', 'encoder.layer.16.attention.self.key.weight', 'encoder.layer.9.attention.self.query.weight', 'encoder.layer.12.attention.output.dense.weight', 'encoder.layer.1.attention.self.value.weight', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.4.attention.output.LayerNorm.weight', 'encoder.layer.17.attention.output.LayerNorm.bias', 'encoder.layer.2.attention.output.dense.bias', 'encoder.layer.9.attention.output.dense.bias', 'encoder.layer.11.attention.self.key.weight', 'encoder.layer.7.output.LayerNorm.weight', 'encoder.layer.7.attention.self.query.weight', 'encoder.layer.10.output.LayerNorm.weight', 'encoder.layer.12.attention.self.value.bias', 'embeddings.LayerNorm.bias', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.4.attention.output.LayerNorm.bias', 'encoder.layer.5.attention.output.LayerNorm.weight', 'encoder.layer.8.output.dense.bias', 'encoder.layer.20.output.LayerNorm.bias', 'encoder.layer.15.attention.self.key.bias', 'encoder.layer.21.attention.self.key.weight', 'encoder.layer.16.attention.output.dense.weight', 'encoder.layer.2.attention.self.query.bias', 'encoder.layer.15.output.dense.bias', 'encoder.layer.17.output.LayerNorm.weight', 'encoder.layer.9.attention.output.LayerNorm.bias', 'encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.21.attention.self.key.bias', 'encoder.layer.22.intermediate.dense.bias', 'encoder.layer.20.attention.self.query.weight', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.4.attention.self.value.weight', 'encoder.layer.7.attention.self.key.bias', 'encoder.layer.9.output.LayerNorm.bias', 'encoder.layer.2.attention.output.LayerNorm.weight', 'encoder.layer.17.output.dense.bias', 'encoder.layer.7.attention.self.value.bias', 'encoder.layer.12.output.dense.weight', 'encoder.layer.15.attention.output.dense.bias', 'encoder.layer.3.attention.output.dense.bias', 'encoder.layer.0.output.dense.weight', 'encoder.layer.5.attention.self.key.bias', 'encoder.layer.2.attention.output.LayerNorm.bias', 'encoder.layer.15.output.dense.weight', 'encoder.layer.2.output.dense.weight', 'encoder.layer.22.attention.output.LayerNorm.weight', 'encoder.layer.11.output.LayerNorm.bias', 'encoder.layer.19.attention.output.dense.weight', 'encoder.layer.0.attention.output.LayerNorm.weight', 'encoder.layer.23.attention.output.LayerNorm.weight', 'encoder.layer.18.attention.self.key.weight', 'encoder.layer.13.output.dense.bias', 'encoder.layer.18.intermediate.dense.weight', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.17.attention.output.LayerNorm.weight', 'encoder.layer.12.intermediate.dense.bias', 'encoder.layer.8.attention.output.dense.bias', 'encoder.layer.15.attention.self.value.bias', 'encoder.layer.14.attention.self.query.weight', 'encoder.layer.17.output.dense.weight', 'encoder.layer.18.output.LayerNorm.weight', 'encoder.layer.18.output.dense.weight', 'encoder.layer.14.attention.output.dense.weight', 'encoder.layer.20.attention.self.value.bias', 'encoder.layer.0.attention.self.query.weight', 'encoder.layer.19.attention.self.key.bias', 'encoder.layer.3.attention.output.dense.weight', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.2.attention.output.dense.weight', 'encoder.layer.8.attention.self.value.bias', 'encoder.layer.8.attention.output.LayerNorm.weight', 'encoder.layer.10.attention.self.key.weight', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.16.output.dense.weight', 'encoder.layer.4.attention.self.key.weight', 'encoder.layer.17.attention.self.key.weight', 'encoder.layer.14.attention.self.value.bias', 'encoder.layer.9.attention.self.value.bias', 'encoder.layer.8.intermediate.dense.bias', 'pooler.dense.bias', 'encoder.layer.17.attention.self.query.weight', 'encoder.layer.0.attention.output.dense.bias', 'encoder.layer.21.output.dense.weight', 'encoder.layer.13.intermediate.dense.bias', 'encoder.layer.16.intermediate.dense.bias', 'encoder.layer.1.attention.output.dense.weight', 'encoder.layer.5.attention.self.key.weight', 'encoder.layer.12.attention.self.query.bias', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.14.attention.self.key.weight', 'encoder.layer.14.output.LayerNorm.weight', 'encoder.layer.22.attention.output.dense.bias', 'encoder.layer.23.output.dense.weight', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.15.output.LayerNorm.weight', 'encoder.layer.13.attention.output.dense.bias', 'encoder.layer.19.attention.self.value.weight', 'encoder.layer.16.attention.self.query.weight', 'encoder.layer.10.output.dense.bias', 'encoder.layer.18.attention.self.query.weight', 'encoder.layer.9.output.dense.weight', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.19.output.LayerNorm.weight', 'encoder.layer.21.attention.self.value.weight', 'encoder.layer.0.output.dense.bias', 'encoder.layer.1.attention.self.query.bias', 'encoder.layer.17.attention.self.value.bias', 'encoder.layer.10.attention.output.dense.bias', 'encoder.layer.15.attention.self.query.weight', 'encoder.layer.9.attention.self.key.weight', 'encoder.layer.15.intermediate.dense.weight', 'encoder.layer.14.attention.output.dense.bias', 'encoder.layer.15.attention.output.LayerNorm.weight', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.15.intermediate.dense.bias', 'encoder.layer.16.output.LayerNorm.weight', 'encoder.layer.16.output.LayerNorm.bias', 'encoder.layer.13.attention.self.query.bias', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.22.output.dense.weight', 'encoder.layer.11.attention.output.dense.bias', 'encoder.layer.19.attention.output.LayerNorm.bias', 'encoder.layer.10.output.LayerNorm.bias', 'encoder.layer.8.attention.self.key.weight', 'encoder.layer.21.attention.output.LayerNorm.weight', 'encoder.layer.2.attention.self.key.bias', 'encoder.layer.2.attention.self.key.weight', 'encoder.layer.1.attention.self.key.bias', 'encoder.layer.12.attention.self.key.weight', 'encoder.layer.17.attention.output.dense.weight', 'encoder.layer.18.attention.self.key.bias', 'encoder.layer.23.intermediate.dense.weight', 'encoder.layer.10.attention.self.key.bias', 'encoder.layer.9.output.dense.bias', 'embeddings.token_type_embeddings.weight', 'encoder.layer.18.attention.self.query.bias', 'encoder.layer.8.attention.self.key.bias', 'encoder.layer.6.attention.self.value.bias', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.14.attention.self.key.bias', 'encoder.layer.0.attention.self.key.weight', 'embeddings.LayerNorm.weight', 'encoder.layer.8.output.LayerNorm.weight', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.1.attention.self.value.bias', 'encoder.layer.12.attention.self.value.weight', 'encoder.layer.5.attention.self.value.bias', 'encoder.layer.8.attention.output.dense.weight', 'encoder.layer.6.output.dense.weight', 'encoder.layer.18.attention.output.LayerNorm.bias', 'encoder.layer.6.attention.self.query.weight', 'encoder.layer.13.output.LayerNorm.bias', 'encoder.layer.2.output.dense.bias', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.11.attention.output.dense.weight', 'encoder.layer.14.output.LayerNorm.bias', 'encoder.layer.15.attention.self.value.weight', 'encoder.layer.4.attention.output.dense.bias', 'encoder.layer.13.attention.self.query.weight', 'encoder.layer.23.attention.output.dense.bias', 'encoder.layer.11.attention.self.value.weight', 'encoder.layer.8.attention.self.value.weight', 'encoder.layer.15.attention.self.key.weight', 'encoder.layer.12.attention.self.key.bias', 'encoder.layer.16.attention.output.dense.bias', 'encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.layer.9.attention.output.dense.weight', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.0.attention.output.dense.weight', 'encoder.layer.22.attention.self.query.bias', 'encoder.layer.11.attention.output.LayerNorm.weight', 'encoder.layer.23.attention.output.LayerNorm.bias', 'encoder.layer.0.attention.self.query.bias', 'encoder.layer.7.output.dense.bias', 'encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.layer.12.output.LayerNorm.weight', 'encoder.layer.8.attention.self.query.bias', 'encoder.layer.11.output.dense.bias', 'encoder.layer.14.attention.output.LayerNorm.weight', 'encoder.layer.6.attention.output.dense.weight', 'encoder.layer.19.output.dense.bias', 'encoder.layer.18.output.dense.bias', 'encoder.layer.8.attention.output.LayerNorm.bias', 'encoder.layer.21.intermediate.dense.weight', 'encoder.layer.7.attention.output.LayerNorm.bias', 'encoder.layer.13.attention.self.value.weight', 'encoder.layer.22.attention.self.key.weight', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.19.attention.self.query.bias', 'encoder.layer.14.output.dense.bias', 'encoder.layer.3.attention.self.value.bias', 'encoder.layer.6.attention.self.value.weight', 'encoder.layer.7.intermediate.dense.bias', 'encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.10.attention.self.query.weight', 'encoder.layer.13.attention.output.LayerNorm.weight', 'encoder.layer.23.intermediate.dense.bias', 'encoder.layer.19.intermediate.dense.weight', 'encoder.layer.21.attention.output.LayerNorm.bias', 'encoder.layer.9.attention.self.value.weight', 'encoder.layer.23.attention.self.value.weight', 'encoder.layer.12.output.dense.bias', 'encoder.layer.20.attention.output.dense.bias', 'encoder.layer.1.attention.self.key.weight', 'encoder.layer.23.attention.self.key.bias', 'encoder.layer.11.attention.self.query.weight', 'encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.layer.12.attention.output.dense.bias', 'encoder.layer.21.attention.output.dense.weight', 'encoder.layer.1.attention.output.LayerNorm.weight', 'encoder.layer.6.output.LayerNorm.bias', 'encoder.layer.19.output.dense.weight', 'encoder.layer.23.output.dense.bias', 'encoder.layer.5.output.dense.weight', 'encoder.layer.22.output.LayerNorm.bias', 'encoder.layer.17.attention.self.key.bias', 'encoder.layer.6.attention.self.key.bias', 'encoder.layer.20.attention.output.LayerNorm.weight', 'encoder.layer.15.attention.self.query.bias', 'encoder.layer.22.attention.self.value.weight', 'encoder.layer.7.output.LayerNorm.bias', 'encoder.layer.23.output.LayerNorm.weight', 'encoder.layer.19.output.LayerNorm.bias', 'encoder.layer.11.attention.self.query.bias', 'encoder.layer.4.attention.self.query.bias', 'encoder.layer.12.attention.self.query.weight', 'encoder.layer.3.output.dense.weight', 'encoder.layer.23.attention.self.query.weight', 'encoder.layer.5.attention.self.value.weight', 'encoder.layer.6.attention.self.query.bias', 'encoder.layer.13.intermediate.dense.weight', 'encoder.layer.7.attention.self.key.weight', 'encoder.layer.18.attention.output.dense.bias', 'encoder.layer.16.attention.self.value.bias', 'encoder.layer.19.attention.self.value.bias', 'encoder.layer.19.attention.self.query.weight', 'encoder.layer.0.attention.self.key.bias', 'encoder.layer.21.attention.self.value.bias', 'encoder.layer.20.attention.output.dense.weight', 'encoder.layer.17.intermediate.dense.bias', 'encoder.layer.16.attention.self.query.bias', 'encoder.layer.10.output.dense.weight', 'encoder.layer.22.attention.output.LayerNorm.bias', 'encoder.layer.5.attention.self.query.weight', 'encoder.layer.16.attention.output.LayerNorm.bias', 'encoder.layer.15.output.LayerNorm.bias', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.4.output.dense.weight', 'encoder.layer.21.attention.self.query.weight', 'encoder.layer.16.attention.output.LayerNorm.weight', 'encoder.layer.21.output.dense.bias', 'encoder.layer.11.attention.self.value.bias', 'encoder.layer.13.output.dense.weight', 'pooler.dense.weight', 'encoder.layer.6.attention.output.dense.bias', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.6.output.dense.bias', 'encoder.layer.22.attention.self.query.weight', 'encoder.layer.1.attention.output.dense.bias', 'encoder.layer.18.attention.output.dense.weight', 'encoder.layer.14.intermediate.dense.weight', 'encoder.layer.20.attention.self.value.weight', 'encoder.layer.22.attention.output.dense.weight', 'encoder.layer.7.attention.self.value.weight', 'encoder.layer.7.output.dense.weight', 'encoder.layer.22.intermediate.dense.weight', 'encoder.layer.11.output.dense.weight', 'encoder.layer.20.attention.self.key.bias', 'encoder.layer.14.attention.self.query.bias', 'encoder.layer.19.intermediate.dense.bias', 'encoder.layer.5.attention.output.dense.bias', 'encoder.layer.2.attention.self.value.bias', 'encoder.layer.6.attention.output.LayerNorm.weight', 'encoder.layer.0.intermediate.dense.bias', 'embeddings.position_embeddings.weight', 'encoder.layer.10.attention.output.LayerNorm.bias', 'encoder.layer.3.output.LayerNorm.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Overwriting existing adapter 'ep'.
Overwriting existing adapter 'tp'.
Overwriting existing adapter 'es'.
Overwriting existing adapter 'ts'.
Overwriting existing adapter fusion module 'ep,tp,es,ts'
05/09/2022 20:08:38 - INFO - __main__ -   Creating features from dataset file at .
/cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//squad/xlm-KG_LR4e-5_EPOCH2.0_maxlen384_batchsize4_gradacc8
XLMConfig {
  "architectures": [
    "XLMRobertaForMaskedLM"
  ],
  "asm": false,
  "attention_dropout": 0.1,
  "attention_probs_dropout_prob": 0.1,
  "bos_index": 0,
  "bos_token_id": 0,
  "causal": false,
  "dropout": 0.1,
  "emb_dim": 1024,
  "embed_init_std": 0.02209708691207961,
  "end_n_top": 5,
  "eos_index": 1,
  "eos_token_id": 2,
  "gelu_activation": true,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "init_std": 0.02,
  "initializer_range": 0.02,
  "intermediate_size": 4096,
  "is_encoder": true,
  "lang_id": 0,
  "layer_norm_eps": 1e-05,
  "mask_index": 5,
  "mask_token_id": 0,
  "max_position_embeddings": 514,
  "model_type": "xlm",
  "n_heads": 16,
  "n_langs": 1,
  "n_layers": 24,
  "output_past": true,
  "pad_index": 2,
  "pad_token_id": 1,
  "sinusoidal_embeddings": false,
  "start_n_top": 5,
  "summary_activation": null,
  "summary_first_dropout": 0.1,
  "summary_proj_to_labels": true,
  "summary_type": "first",
  "summary_use_proj": true,
  "transformers_version": "4.17.0",
  "type_vocab_size": 1,
  "unk_index": 3,
  "use_lang_emb": false,
  "vocab_size": 250002
}

  0%|          | 0/48 [00:00<?, ?it/s] 31%|███▏      | 15/48 [00:00<00:00, 142.23it/s] 62%|██████▎   | 30/48 [00:00<00:00, 98.65it/s]  88%|████████▊ | 42/48 [00:00<00:00, 102.93it/s]100%|██████████| 48/48 [00:00<00:00, 105.01it/s]
convert squad examples to features:   0%|          | 0/1190 [00:00<?, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.
convert squad examples to features:   0%|          | 1/1190 [00:00<04:28,  4.43it/s]convert squad examples to features:   5%|▌         | 65/1190 [00:00<00:06, 164.46it/s]convert squad examples to features:   8%|▊         | 97/1190 [00:00<00:05, 198.85it/s]convert squad examples to features:  11%|█         | 129/1190 [00:00<00:04, 224.10it/s]convert squad examples to features:  14%|█▎        | 161/1190 [00:00<00:04, 247.06it/s]convert squad examples to features:  16%|█▌        | 193/1190 [00:00<00:03, 255.12it/s]convert squad examples to features:  19%|█▉        | 225/1190 [00:01<00:03, 267.03it/s]convert squad examples to features:  22%|██▏       | 257/1190 [00:01<00:03, 250.58it/s]convert squad examples to features:  24%|██▍       | 289/1190 [00:01<00:03, 243.08it/s]convert squad examples to features:  27%|██▋       | 321/1190 [00:01<00:03, 218.94it/s]convert squad examples to features:  30%|██▉       | 353/1190 [00:01<00:04, 209.15it/s]convert squad examples to features:  32%|███▏      | 385/1190 [00:02<00:07, 101.10it/s]convert squad examples to features:  35%|███▌      | 417/1190 [00:02<00:06, 113.01it/s]convert squad examples to features:  38%|███▊      | 449/1190 [00:02<00:06, 119.85it/s]convert squad examples to features:  40%|████      | 481/1190 [00:02<00:05, 135.69it/s]convert squad examples to features:  43%|████▎     | 513/1190 [00:03<00:04, 141.15it/s]convert squad examples to features:  46%|████▌     | 545/1190 [00:03<00:04, 139.05it/s]convert squad examples to features:  48%|████▊     | 577/1190 [00:03<00:04, 151.41it/s]convert squad examples to features:  51%|█████     | 609/1190 [00:03<00:03, 162.59it/s]convert squad examples to features:  54%|█████▍    | 641/1190 [00:03<00:03, 160.62it/s]convert squad examples to features:  57%|█████▋    | 673/1190 [00:04<00:03, 158.88it/s]convert squad examples to features:  59%|█████▉    | 705/1190 [00:04<00:02, 166.55it/s]convert squad examples to features:  62%|██████▏   | 737/1190 [00:04<00:02, 175.81it/s]convert squad examples to features:  65%|██████▍   | 769/1190 [00:04<00:02, 179.02it/s]convert squad examples to features:  67%|██████▋   | 801/1190 [00:04<00:02, 186.07it/s]convert squad examples to features:  70%|███████   | 833/1190 [00:05<00:02, 171.30it/s]convert squad examples to features:  73%|███████▎  | 865/1190 [00:05<00:01, 183.79it/s]convert squad examples to features:  75%|███████▌  | 897/1190 [00:05<00:01, 186.13it/s]convert squad examples to features:  78%|███████▊  | 929/1190 [00:05<00:01, 178.67it/s]convert squad examples to features:  81%|████████  | 961/1190 [00:05<00:01, 187.59it/s]convert squad examples to features:  83%|████████▎ | 993/1190 [00:05<00:01, 191.42it/s]convert squad examples to features:  86%|████████▌ | 1025/1190 [00:05<00:00, 210.18it/s]convert squad examples to features:  89%|████████▉ | 1057/1190 [00:06<00:00, 209.92it/s]convert squad examples to features:  92%|█████████▏| 1089/1190 [00:06<00:00, 216.06it/s]convert squad examples to features:  94%|█████████▍| 1121/1190 [00:06<00:00, 202.66it/s]convert squad examples to features:  97%|█████████▋| 1153/1190 [00:06<00:00, 192.13it/s]convert squad examples to features: 100%|██████████| 1190/1190 [00:06<00:00, 179.69it/s]/cluster/project/sachan/yifan/softwares/anaconda/anaconda3/envs/xfactr/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2272: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

add example index and unique id:   0%|          | 0/1190 [00:00<?, ?it/s]add example index and unique id: 100%|██████████| 1190/1190 [00:00<00:00, 557304.80it/s]
05/09/2022 20:08:45 - INFO - __main__ -   Saving features into cached file ./cached_xquad.vi.json_xlm-KG_LR4e-5_EPOCH2.0_maxlen384_batchsize4_gradacc8_384_vi
05/09/2022 20:08:46 - INFO - __main__ -   ***** Running evaluation  *****
05/09/2022 20:08:46 - INFO - __main__ -     Num examples = 1314
05/09/2022 20:08:46 - INFO - __main__ -     Batch size = 8
Evaluating:   0%|          | 0/165 [00:00<?, ?it/s]Evaluating:   1%|          | 1/165 [00:00<02:31,  1.08it/s]Evaluating:   1%|          | 2/165 [00:01<01:36,  1.69it/s]Evaluating:   2%|▏         | 3/165 [00:01<01:18,  2.06it/s]Evaluating:   2%|▏         | 4/165 [00:02<01:10,  2.29it/s]Evaluating:   3%|▎         | 5/165 [00:02<01:05,  2.45it/s]Evaluating:   4%|▎         | 6/165 [00:02<01:01,  2.57it/s]Evaluating:   4%|▍         | 7/165 [00:03<00:59,  2.64it/s]Evaluating:   5%|▍         | 8/165 [00:03<00:58,  2.70it/s]Evaluating:   5%|▌         | 9/165 [00:03<00:56,  2.74it/s]Evaluating:   6%|▌         | 10/165 [00:04<00:56,  2.76it/s]Evaluating:   7%|▋         | 11/165 [00:04<00:56,  2.75it/s]Evaluating:   7%|▋         | 12/165 [00:04<00:55,  2.77it/s]Evaluating:   8%|▊         | 13/165 [00:05<00:54,  2.79it/s]Evaluating:   8%|▊         | 14/165 [00:05<00:54,  2.79it/s]Evaluating:   9%|▉         | 15/165 [00:05<00:53,  2.80it/s]Evaluating:  10%|▉         | 16/165 [00:06<00:53,  2.80it/s]Evaluating:  10%|█         | 17/165 [00:06<00:52,  2.81it/s]Evaluating:  11%|█         | 18/165 [00:06<00:52,  2.81it/s]Evaluating:  12%|█▏        | 19/165 [00:07<00:51,  2.82it/s]Evaluating:  12%|█▏        | 20/165 [00:07<00:51,  2.82it/s]Evaluating:  13%|█▎        | 21/165 [00:08<00:51,  2.81it/s]Evaluating:  13%|█▎        | 22/165 [00:08<00:52,  2.73it/s]Evaluating:  14%|█▍        | 23/165 [00:08<00:54,  2.60it/s]Evaluating:  15%|█▍        | 24/165 [00:09<00:56,  2.52it/s]Evaluating:  15%|█▌        | 25/165 [00:09<00:57,  2.42it/s]Evaluating:  16%|█▌        | 26/165 [00:10<00:55,  2.50it/s]Evaluating:  16%|█▋        | 27/165 [00:10<00:53,  2.57it/s]Evaluating:  17%|█▋        | 28/165 [00:10<00:52,  2.62it/s]Evaluating:  18%|█▊        | 29/165 [00:11<00:53,  2.53it/s]Evaluating:  18%|█▊        | 30/165 [00:11<00:54,  2.48it/s]Evaluating:  19%|█▉        | 31/165 [00:12<00:52,  2.57it/s]Evaluating:  19%|█▉        | 32/165 [00:12<00:50,  2.61it/s]Evaluating:  20%|██        | 33/165 [00:12<00:53,  2.45it/s]Evaluating:  21%|██        | 34/165 [00:13<00:52,  2.52it/s]Evaluating:  21%|██        | 35/165 [00:13<00:50,  2.57it/s]Evaluating:  22%|██▏       | 36/165 [00:14<00:49,  2.60it/s]Evaluating:  22%|██▏       | 37/165 [00:14<00:50,  2.52it/s]Evaluating:  23%|██▎       | 38/165 [00:14<00:49,  2.57it/s]Evaluating:  24%|██▎       | 39/165 [00:15<00:49,  2.57it/s]Evaluating:  24%|██▍       | 40/165 [00:15<00:50,  2.47it/s]Evaluating:  25%|██▍       | 41/165 [00:16<00:50,  2.47it/s]Evaluating:  25%|██▌       | 42/165 [00:16<00:49,  2.51it/s]Evaluating:  26%|██▌       | 43/165 [00:16<00:47,  2.59it/s]Evaluating:  27%|██▋       | 44/165 [00:17<00:46,  2.62it/s]Evaluating:  27%|██▋       | 45/165 [00:17<00:47,  2.53it/s]Evaluating:  28%|██▊       | 46/165 [00:17<00:47,  2.49it/s]Evaluating:  28%|██▊       | 47/165 [00:18<00:45,  2.57it/s]Evaluating:  29%|██▉       | 48/165 [00:18<00:44,  2.62it/s]Evaluating:  30%|██▉       | 49/165 [00:19<00:43,  2.65it/s]Evaluating:  30%|███       | 50/165 [00:19<00:43,  2.62it/s]Evaluating:  31%|███       | 51/165 [00:19<00:42,  2.67it/s]Evaluating:  32%|███▏      | 52/165 [00:20<00:42,  2.66it/s]Evaluating:  32%|███▏      | 53/165 [00:20<00:42,  2.67it/s]Evaluating:  33%|███▎      | 54/165 [00:20<00:41,  2.70it/s]Evaluating:  33%|███▎      | 55/165 [00:21<00:40,  2.71it/s]Evaluating:  34%|███▍      | 56/165 [00:21<00:42,  2.59it/s]Evaluating:  35%|███▍      | 57/165 [00:22<00:45,  2.40it/s]Evaluating:  35%|███▌      | 58/165 [00:22<00:43,  2.47it/s]Evaluating:  36%|███▌      | 59/165 [00:22<00:41,  2.55it/s]Evaluating:  36%|███▋      | 60/165 [00:23<00:40,  2.57it/s]Evaluating:  37%|███▋      | 61/165 [00:23<00:40,  2.59it/s]Evaluating:  38%|███▊      | 62/165 [00:24<00:39,  2.60it/s]Evaluating:  38%|███▊      | 63/165 [00:24<00:38,  2.65it/s]Evaluating:  39%|███▉      | 64/165 [00:24<00:37,  2.70it/s]Evaluating:  39%|███▉      | 65/165 [00:25<00:36,  2.72it/s]Evaluating:  40%|████      | 66/165 [00:25<00:36,  2.74it/s]Evaluating:  41%|████      | 67/165 [00:25<00:35,  2.77it/s]Evaluating:  41%|████      | 68/165 [00:26<00:35,  2.72it/s]Evaluating:  42%|████▏     | 69/165 [00:26<00:35,  2.69it/s]Evaluating:  42%|████▏     | 70/165 [00:27<00:34,  2.72it/s]Evaluating:  43%|████▎     | 71/165 [00:27<00:34,  2.73it/s]Evaluating:  44%|████▎     | 72/165 [00:27<00:33,  2.74it/s]Evaluating:  44%|████▍     | 73/165 [00:28<00:33,  2.76it/s]Evaluating:  45%|████▍     | 74/165 [00:28<00:32,  2.78it/s]Evaluating:  45%|████▌     | 75/165 [00:28<00:34,  2.62it/s]Evaluating:  46%|████▌     | 76/165 [00:29<00:34,  2.60it/s]Evaluating:  47%|████▋     | 77/165 [00:29<00:33,  2.66it/s]Evaluating:  47%|████▋     | 78/165 [00:30<00:33,  2.63it/s]Evaluating:  48%|████▊     | 79/165 [00:30<00:32,  2.64it/s]Evaluating:  48%|████▊     | 80/165 [00:30<00:31,  2.68it/s]Evaluating:  49%|████▉     | 81/165 [00:31<00:31,  2.71it/s]Evaluating:  50%|████▉     | 82/165 [00:31<00:30,  2.74it/s]Evaluating:  50%|█████     | 83/165 [00:31<00:29,  2.75it/s]Evaluating:  51%|█████     | 84/165 [00:32<00:29,  2.76it/s]Evaluating:  52%|█████▏    | 85/165 [00:32<00:28,  2.77it/s]Evaluating:  52%|█████▏    | 86/165 [00:32<00:28,  2.77it/s]Evaluating:  53%|█████▎    | 87/165 [00:33<00:28,  2.77it/s]Evaluating:  53%|█████▎    | 88/165 [00:33<00:27,  2.77it/s]Evaluating:  54%|█████▍    | 89/165 [00:33<00:27,  2.78it/s]Evaluating:  55%|█████▍    | 90/165 [00:34<00:27,  2.77it/s]Evaluating:  55%|█████▌    | 91/165 [00:34<00:26,  2.78it/s]Evaluating:  56%|█████▌    | 92/165 [00:35<00:26,  2.77it/s]Evaluating:  56%|█████▋    | 93/165 [00:35<00:26,  2.76it/s]Evaluating:  57%|█████▋    | 94/165 [00:35<00:25,  2.75it/s]Evaluating:  58%|█████▊    | 95/165 [00:36<00:25,  2.75it/s]Evaluating:  58%|█████▊    | 96/165 [00:36<00:25,  2.75it/s]Evaluating:  59%|█████▉    | 97/165 [00:36<00:24,  2.75it/s]Evaluating:  59%|█████▉    | 98/165 [00:37<00:24,  2.75it/s]Evaluating:  60%|██████    | 99/165 [00:37<00:23,  2.75it/s]Evaluating:  61%|██████    | 100/165 [00:37<00:23,  2.75it/s]Evaluating:  61%|██████    | 101/165 [00:38<00:23,  2.76it/s]Evaluating:  62%|██████▏   | 102/165 [00:38<00:22,  2.77it/s]Evaluating:  62%|██████▏   | 103/165 [00:39<00:22,  2.78it/s]Evaluating:  63%|██████▎   | 104/165 [00:39<00:21,  2.78it/s]Evaluating:  64%|██████▎   | 105/165 [00:39<00:21,  2.78it/s]Evaluating:  64%|██████▍   | 106/165 [00:40<00:21,  2.77it/s]Evaluating:  65%|██████▍   | 107/165 [00:40<00:21,  2.75it/s]Evaluating:  65%|██████▌   | 108/165 [00:40<00:20,  2.76it/s]Evaluating:  66%|██████▌   | 109/165 [00:41<00:20,  2.77it/s]Evaluating:  67%|██████▋   | 110/165 [00:41<00:19,  2.77it/s]Evaluating:  67%|██████▋   | 111/165 [00:41<00:19,  2.77it/s]Evaluating:  68%|██████▊   | 112/165 [00:42<00:19,  2.78it/s]Evaluating:  68%|██████▊   | 113/165 [00:42<00:18,  2.78it/s]Evaluating:  69%|██████▉   | 114/165 [00:43<00:18,  2.78it/s]Evaluating:  70%|██████▉   | 115/165 [00:43<00:17,  2.78it/s]Evaluating:  70%|███████   | 116/165 [00:43<00:17,  2.78it/s]Evaluating:  71%|███████   | 117/165 [00:44<00:17,  2.78it/s]Evaluating:  72%|███████▏  | 118/165 [00:44<00:17,  2.76it/s]Evaluating:  72%|███████▏  | 119/165 [00:44<00:16,  2.77it/s]Evaluating:  73%|███████▎  | 120/165 [00:45<00:16,  2.77it/s]Evaluating:  73%|███████▎  | 121/165 [00:45<00:15,  2.77it/s]Evaluating:  74%|███████▍  | 122/165 [00:45<00:15,  2.77it/s]Evaluating:  75%|███████▍  | 123/165 [00:46<00:15,  2.77it/s]Evaluating:  75%|███████▌  | 124/165 [00:46<00:14,  2.77it/s]Evaluating:  76%|███████▌  | 125/165 [00:47<00:14,  2.77it/s]Evaluating:  76%|███████▋  | 126/165 [00:47<00:14,  2.77it/s]Evaluating:  77%|███████▋  | 127/165 [00:47<00:13,  2.77it/s]Evaluating:  78%|███████▊  | 128/165 [00:48<00:13,  2.77it/s]Evaluating:  78%|███████▊  | 129/165 [00:48<00:13,  2.76it/s]Evaluating:  79%|███████▉  | 130/165 [00:48<00:12,  2.76it/s]Evaluating:  79%|███████▉  | 131/165 [00:49<00:12,  2.74it/s]Evaluating:  80%|████████  | 132/165 [00:49<00:12,  2.70it/s]Evaluating:  81%|████████  | 133/165 [00:49<00:11,  2.68it/s]Evaluating:  81%|████████  | 134/165 [00:50<00:11,  2.62it/s]Evaluating:  82%|████████▏ | 135/165 [00:50<00:11,  2.64it/s]Evaluating:  82%|████████▏ | 136/165 [00:51<00:11,  2.62it/s]Evaluating:  83%|████████▎ | 137/165 [00:51<00:10,  2.64it/s]Evaluating:  84%|████████▎ | 138/165 [00:51<00:10,  2.54it/s]Evaluating:  84%|████████▍ | 139/165 [00:52<00:09,  2.61it/s]Evaluating:  85%|████████▍ | 140/165 [00:52<00:09,  2.66it/s]Evaluating:  85%|████████▌ | 141/165 [00:52<00:08,  2.70it/s]Evaluating:  86%|████████▌ | 142/165 [00:53<00:08,  2.72it/s]Evaluating:  87%|████████▋ | 143/165 [00:53<00:08,  2.71it/s]Evaluating:  87%|████████▋ | 144/165 [00:54<00:08,  2.58it/s]Evaluating:  88%|████████▊ | 145/165 [00:54<00:08,  2.41it/s]Evaluating:  88%|████████▊ | 146/165 [00:54<00:07,  2.50it/s]Evaluating:  89%|████████▉ | 147/165 [00:55<00:07,  2.56it/s]Evaluating:  90%|████████▉ | 148/165 [00:55<00:06,  2.48it/s]Evaluating:  90%|█████████ | 149/165 [00:56<00:06,  2.57it/s]Evaluating:  91%|█████████ | 150/165 [00:56<00:05,  2.57it/s]Evaluating:  92%|█████████▏| 151/165 [00:56<00:05,  2.61it/s]Evaluating:  92%|█████████▏| 152/165 [00:57<00:04,  2.64it/s]Evaluating:  93%|█████████▎| 153/165 [00:57<00:04,  2.68it/s]Evaluating:  93%|█████████▎| 154/165 [00:58<00:04,  2.68it/s]Evaluating:  94%|█████████▍| 155/165 [00:58<00:03,  2.60it/s]Evaluating:  95%|█████████▍| 156/165 [00:58<00:03,  2.60it/s]Evaluating:  95%|█████████▌| 157/165 [00:59<00:03,  2.59it/s]Evaluating:  96%|█████████▌| 158/165 [00:59<00:02,  2.44it/s]Evaluating:  96%|█████████▋| 159/165 [01:00<00:02,  2.53it/s]Evaluating:  97%|█████████▋| 160/165 [01:00<00:01,  2.60it/s]Evaluating:  98%|█████████▊| 161/165 [01:00<00:01,  2.45it/s]Evaluating:  98%|█████████▊| 162/165 [01:01<00:01,  2.42it/s]Evaluating:  99%|█████████▉| 163/165 [01:01<00:00,  2.49it/s]Evaluating:  99%|█████████▉| 164/165 [01:02<00:00,  2.52it/s]Evaluating: 100%|██████████| 165/165 [01:02<00:00,  3.12it/s]Evaluating: 100%|██████████| 165/165 [01:02<00:00,  2.65it/s]
05/09/2022 20:09:49 - INFO - __main__ -     Evaluation done in total 62.167030 secs (0.047311 sec per example)
05/09/2022 20:09:53 - INFO - __main__ -   Results: {'exact': 61.1764705882353, 'f1': 79.773181628474, 'total': 1190, 'HasAns_exact': 61.1764705882353, 'HasAns_f1': 79.773181628474, 'HasAns_total': 1190, 'best_exact': 61.1764705882353, 'best_exact_thresh': 0.0, 'best_f1': 79.773181628474, 'best_f1_thresh': 0.0}
  th 
2022-05-09 20:09:58.721304: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0
05/09/2022 20:10:19 - WARNING - __main__ -   Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, 16-bits training: False
You are using a model of type xlm-roberta to instantiate a model of type xlm. This is not supported for all configurations of models and can yield errors.
Some weights of the model checkpoint at /cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//squad/xlm-KG_LR4e-5_EPOCH2.0_maxlen384_batchsize4_gradacc8 were not used when initializing XLMRobertaModel: ['base_model.encoder.layer.6.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.9.attention.output.LayerNorm.bias', 'base_model.encoder.layer.17.attention.self.key.bias', 'base_model.encoder.layer.11.attention.self.value.bias', 'base_model.encoder.layer.9.attention.output.dense.weight', 'base_model.encoder.layer.13.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.20.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.4.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.3.attention.output.LayerNorm.weight', 'base_model.encoder.layer.16.attention.self.value.weight', 'base_model.encoder.layer.20.attention.self.query.weight', 'base_model.encoder.layer.13.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.21.output.dense.bias', 'base_model.encoder.layer.7.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.3.attention.self.value.weight', 'base_model.pooler.dense.weight', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.8.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.15.attention.self.key.bias', 'base_model.encoder.layer.18.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.0.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.9.attention.output.LayerNorm.weight', 'base_model.encoder.layer.14.intermediate.dense.bias', 'base_model.encoder.layer.2.attention.output.LayerNorm.weight', 'base_model.encoder.layer.23.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.0.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.6.output.LayerNorm.bias', 'base_model.encoder.layer.6.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.6.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.6.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.7.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.23.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.6.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.15.attention.output.dense.weight', 'base_model.encoder.layer.12.intermediate.dense.weight', 'base_model.encoder.layer.11.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.21.attention.output.dense.bias', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.20.output.LayerNorm.weight', 'base_model.encoder.layer.22.attention.output.LayerNorm.bias', 'base_model.encoder.layer.11.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.7.output.LayerNorm.bias', 'base_model.encoder.layer.1.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.3.output.LayerNorm.bias', 'base_model.encoder.layer.0.attention.output.LayerNorm.bias', 'base_model.encoder.layer.0.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.22.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.4.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.15.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.20.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.20.attention.self.key.weight', 'base_model.encoder.layer.16.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.13.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.10.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.9.intermediate.dense.weight', 'base_model.encoder.layer.17.attention.output.dense.weight', 'base_model.encoder.layer.4.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.5.attention.output.dense.bias', 'base_model.encoder.layer.21.intermediate.dense.weight', 'base_model.encoder.layer.19.attention.output.dense.bias', 'base_model.encoder.layer.17.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.18.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.6.attention.output.LayerNorm.weight', 'base_model.encoder.layer.17.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.19.attention.self.query.weight', 'base_model.encoder.layer.17.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.14.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.10.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.11.attention.self.query.bias', 'base_model.encoder.layer.19.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.10.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.12.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.0.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.19.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.0.attention.self.key.weight', 'base_model.encoder.layer.15.output.LayerNorm.bias', 'base_model.encoder.layer.12.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.9.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.21.attention.self.query.weight', 'base_model.encoder.layer.6.output.LayerNorm.weight', 'base_model.encoder.layer.3.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.0.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.1.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.22.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.5.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.0.intermediate.dense.bias', 'base_model.encoder.layer.15.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.13.attention.self.value.weight', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.19.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.23.attention.self.value.bias', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.15.intermediate.dense.bias', 'base_model.encoder.layer.5.output.LayerNorm.weight', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.15.output.LayerNorm.weight', 'base_model.encoder.layer.16.attention.output.dense.weight', 'base_model.encoder.layer.9.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.3.attention.self.value.bias', 'base_model.encoder.layer.6.attention.self.key.bias', 'base_model.encoder.layer.4.output.dense.weight', 'base_model.encoder.layer.22.output.dense.weight', 'base_model.encoder.layer.3.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.20.attention.output.LayerNorm.weight', 'base_model.encoder.layer.1.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.22.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.17.attention.self.query.weight', 'base_model.encoder.layer.6.attention.self.value.bias', 'base_model.encoder.layer.20.attention.output.LayerNorm.bias', 'base_model.encoder.layer.0.attention.output.dense.bias', 'base_model.encoder.layer.2.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.7.output.dense.bias', 'base_model.encoder.layer.23.output.LayerNorm.weight', 'base_model.encoder.layer.14.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.22.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.3.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.6.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.9.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.15.output.adapters.ep.adapter_down.0.weight', 'base_model.embeddings.LayerNorm.bias', 'base_model.encoder.layer.21.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.8.output.LayerNorm.bias', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.5.attention.output.LayerNorm.weight', 'base_model.encoder.layer.12.output.LayerNorm.weight', 'base_model.encoder.layer.8.attention.self.query.bias', 'base_model.encoder.layer.19.intermediate.dense.bias', 'base_model.encoder.layer.13.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.19.attention.self.value.bias', 'base_model.encoder.layer.22.attention.output.dense.weight', 'base_model.encoder.layer.17.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.23.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.23.attention.self.value.weight', 'base_model.encoder.layer.9.attention.self.value.bias', 'base_model.encoder.layer.11.attention.output.LayerNorm.bias', 'base_model.encoder.layer.6.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.5.attention.self.key.weight', 'base_model.encoder.layer.7.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.17.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.8.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.21.attention.self.value.bias', 'base_model.encoder.layer.8.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.15.attention.self.query.weight', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.2.output.dense.weight', 'base_model.encoder.layer.18.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.15.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.14.attention.output.LayerNorm.weight', 'base_model.encoder.layer.20.output.LayerNorm.bias', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.23.attention.output.LayerNorm.bias', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.9.attention.self.query.weight', 'base_model.encoder.layer.12.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.10.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.8.output.LayerNorm.weight', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.5.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.7.attention.self.value.bias', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.9.attention.self.value.weight', 'base_model.encoder.layer.9.output.dense.bias', 'base_model.encoder.layer.14.output.dense.weight', 'base_model.encoder.layer.16.attention.self.query.weight', 'base_model.encoder.layer.19.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.6.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.19.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.22.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.2.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.20.attention.output.dense.weight', 'base_model.encoder.layer.3.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.7.attention.self.key.bias', 'base_model.encoder.layer.5.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.11.output.dense.bias', 'base_model.encoder.layer.3.output.LayerNorm.weight', 'base_model.encoder.layer.21.attention.self.value.weight', 'base_model.encoder.layer.5.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.1.output.dense.weight', 'base_model.encoder.layer.12.output.dense.weight', 'base_model.encoder.layer.3.attention.self.query.weight', 'base_model.encoder.layer.11.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.19.intermediate.dense.weight', 'base_model.encoder.layer.18.output.LayerNorm.weight', 'base_model.encoder.layer.2.attention.self.query.weight', 'base_model.encoder.layer.4.output.LayerNorm.weight', 'base_model.encoder.layer.12.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.0.output.LayerNorm.bias', 'base_model.encoder.layer.10.attention.self.value.bias', 'base_model.encoder.layer.18.attention.self.value.weight', 'base_model.encoder.layer.4.output.dense.bias', 'base_model.encoder.layer.7.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.10.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.13.output.dense.bias', 'base_model.encoder.layer.13.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.20.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.21.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.21.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.10.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.3.intermediate.dense.bias', 'base_model.encoder.layer.14.intermediate.dense.weight', 'base_model.encoder.layer.19.output.dense.weight', 'base_model.encoder.layer.21.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.6.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.6.intermediate.dense.bias', 'base_model.encoder.layer.15.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.9.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.5.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.7.attention.output.dense.weight', 'base_model.encoder.layer.1.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.23.attention.self.query.weight', 'base_model.encoder.layer.12.attention.output.dense.weight', 'base_model.encoder.layer.22.attention.self.query.weight', 'base_model.encoder.layer.15.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.21.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.21.attention.self.query.bias', 'base_model.encoder.layer.0.attention.output.LayerNorm.weight', 'base_model.encoder.layer.14.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.15.attention.self.key.weight', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.10.attention.output.dense.bias', 'base_model.encoder.layer.10.output.dense.bias', 'base_model.encoder.layer.13.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.14.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.2.intermediate.dense.bias', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.20.attention.self.value.weight', 'base_model.encoder.layer.5.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.18.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.8.attention.output.dense.weight', 'base_model.encoder.layer.18.attention.self.query.bias', 'base_model.encoder.layer.22.attention.output.dense.bias', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.20.attention.self.value.bias', 'base_model.encoder.layer.18.output.dense.weight', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.12.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.1.attention.self.query.bias', 'base_model.encoder.layer.8.attention.self.query.weight', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.3.output.dense.bias', 'base_model.encoder.layer.19.attention.output.LayerNorm.weight', 'base_model.encoder.layer.21.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.10.attention.self.key.weight', 'base_model.encoder.layer.0.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.16.intermediate.dense.weight', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.1.output.LayerNorm.weight', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.5.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.17.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.1.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.18.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.11.attention.output.dense.weight', 'base_model.encoder.layer.4.attention.output.LayerNorm.bias', 'base_model.encoder.layer.3.intermediate.dense.weight', 'base_model.encoder.layer.11.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.20.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.5.output.dense.bias', 'base_model.encoder.layer.2.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.11.attention.self.query.weight', 'base_model.encoder.layer.1.attention.self.value.bias', 'base_model.encoder.layer.3.attention.output.dense.weight', 'base_model.encoder.layer.14.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.11.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.14.output.LayerNorm.weight', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.20.attention.output.dense.bias', 'base_model.encoder.layer.13.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.16.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.23.attention.output.dense.bias', 'base_model.encoder.layer.13.output.LayerNorm.bias', 'base_model.encoder.layer.22.output.adapters.ep.adapter_down.0.bias', 'qa_outputs.weight', 'base_model.encoder.layer.4.attention.output.dense.bias', 'base_model.encoder.layer.16.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.16.output.LayerNorm.weight', 'base_model.encoder.layer.0.output.dense.bias', 'base_model.encoder.layer.1.output.dense.bias', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.9.attention.output.dense.bias', 'base_model.encoder.layer.13.intermediate.dense.weight', 'base_model.encoder.layer.1.output.LayerNorm.bias', 'base_model.encoder.layer.3.attention.self.query.bias', 'base_model.encoder.layer.9.attention.self.key.weight', 'base_model.encoder.layer.11.attention.output.dense.bias', 'base_model.encoder.layer.12.output.dense.bias', 'base_model.encoder.layer.16.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.9.attention.self.key.bias', 'base_model.encoder.layer.4.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.18.attention.output.dense.weight', 'base_model.encoder.layer.13.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.14.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.23.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.19.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.10.intermediate.dense.weight', 'base_model.encoder.layer.15.attention.output.LayerNorm.bias', 'base_model.encoder.layer.12.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.3.attention.self.key.bias', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.10.attention.output.LayerNorm.bias', 'base_model.encoder.layer.17.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.18.attention.self.query.weight', 'base_model.encoder.layer.3.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.5.attention.self.query.weight', 'base_model.encoder.layer.18.attention.self.value.bias', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.21.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.22.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.9.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.4.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.15.attention.self.value.weight', 'base_model.encoder.layer.20.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.8.attention.output.LayerNorm.bias', 'base_model.encoder.layer.22.attention.self.key.weight', 'base_model.encoder.layer.14.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.18.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.23.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.10.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.20.attention.self.key.bias', 'base_model.encoder.layer.8.intermediate.dense.bias', 'base_model.encoder.layer.19.attention.self.value.weight', 'base_model.encoder.layer.6.attention.output.LayerNorm.bias', 'base_model.encoder.layer.21.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.9.intermediate.dense.bias', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.13.attention.output.dense.bias', 'base_model.encoder.layer.14.output.dense.bias', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.18.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.6.output.dense.bias', 'base_model.encoder.layer.20.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.8.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.3.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.13.output.LayerNorm.weight', 'base_model.encoder.layer.7.attention.self.key.weight', 'base_model.encoder.layer.6.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.0.attention.output.dense.weight', 'base_model.encoder.layer.14.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.14.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.9.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.9.attention.self.query.bias', 'base_model.encoder.layer.13.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.10.output.LayerNorm.bias', 'base_model.encoder.layer.21.attention.self.key.weight', 'base_model.encoder.layer.20.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.19.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.1.intermediate.dense.weight', 'base_model.encoder.layer.18.output.dense.bias', 'base_model.encoder.layer.11.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.7.output.dense.weight', 'base_model.encoder.layer.11.output.LayerNorm.bias', 'base_model.encoder.layer.16.output.dense.weight', 'base_model.encoder.layer.10.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.7.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.16.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.6.attention.self.value.weight', 'base_model.encoder.layer.14.attention.self.key.bias', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.19.attention.output.LayerNorm.bias', 'base_model.encoder.layer.8.attention.self.value.bias', 'base_model.encoder.layer.5.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.1.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.23.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.15.attention.output.LayerNorm.weight', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.17.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.18.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.4.output.LayerNorm.bias', 'base_model.encoder.layer.15.attention.self.value.bias', 'base_model.encoder.layer.2.attention.self.value.weight', 'base_model.encoder.layer.11.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.16.attention.self.value.bias', 'base_model.encoder.layer.6.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.17.attention.self.value.bias', 'base_model.encoder.layer.17.output.LayerNorm.bias', 'base_model.encoder.layer.16.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.1.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.19.attention.output.dense.weight', 'base_model.encoder.layer.9.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.12.attention.self.key.bias', 'base_model.encoder.layer.13.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.23.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.10.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.6.intermediate.dense.weight', 'base_model.encoder.layer.18.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.2.attention.output.dense.bias', 'base_model.encoder.layer.2.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.1.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.17.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.0.attention.self.value.bias', 'base_model.encoder.layer.10.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.7.attention.output.dense.bias', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.13.attention.output.dense.weight', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.2.attention.self.query.bias', 'base_model.encoder.layer.4.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.3.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.15.attention.output.dense.bias', 'base_model.encoder.layer.7.attention.self.query.bias', 'base_model.encoder.layer.10.attention.self.query.bias', 'base_model.encoder.layer.12.output.LayerNorm.bias', 'base_model.encoder.layer.2.output.LayerNorm.bias', 'base_model.encoder.layer.10.attention.output.LayerNorm.weight', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.21.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.7.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.9.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.8.attention.self.value.weight', 'base_model.encoder.layer.20.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.12.attention.self.query.bias', 'base_model.encoder.layer.0.output.LayerNorm.weight', 'base_model.encoder.layer.5.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.14.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.21.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.14.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.3.attention.output.dense.bias', 'base_model.encoder.layer.16.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.19.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.10.output.LayerNorm.weight', 'base_model.encoder.layer.18.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.6.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.8.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.15.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.11.attention.output.LayerNorm.weight', 'base_model.encoder.layer.22.attention.self.value.bias', 'base_model.encoder.layer.3.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.11.attention.self.value.weight', 'base_model.encoder.layer.19.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.2.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.13.attention.self.key.bias', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.13.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.18.intermediate.dense.weight', 'base_model.encoder.layer.14.attention.output.dense.bias', 'base_model.encoder.layer.9.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.22.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.10.attention.self.key.bias', 'base_model.encoder.layer.12.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.6.output.dense.weight', 'base_model.encoder.layer.15.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.16.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.3.output.dense.weight', 'base_model.encoder.layer.18.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.21.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.16.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.22.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.9.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.16.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.8.attention.output.dense.bias', 'base_model.encoder.layer.0.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.22.intermediate.dense.weight', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.5.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.1.attention.output.dense.bias', 'base_model.encoder.layer.7.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.4.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.4.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.23.output.LayerNorm.bias', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.6.attention.output.dense.weight', 'base_model.encoder.layer.1.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.10.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.22.output.LayerNorm.bias', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.0.attention.self.key.bias', 'base_model.encoder.layer.8.attention.self.key.bias', 'base_model.encoder.layer.11.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.16.attention.self.key.bias', 'base_model.encoder.layer.11.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.0.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.21.output.dense.weight', 'base_model.encoder.layer.20.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.14.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.16.output.LayerNorm.bias', 'base_model.encoder.layer.5.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.1.attention.output.LayerNorm.bias', 'base_model.encoder.layer.10.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.4.attention.self.key.bias', 'base_model.encoder.layer.4.attention.self.query.weight', 'base_model.encoder.layer.17.attention.output.LayerNorm.bias', 'base_model.encoder.layer.22.intermediate.dense.bias', 'base_model.encoder.layer.0.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.19.attention.self.key.bias', 'base_model.encoder.layer.0.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.23.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.1.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.20.output.adapters.tp.adapter_up.weight', 'base_model.embeddings.position_embeddings.weight', 'base_model.encoder.layer.9.output.LayerNorm.bias', 'base_model.encoder.layer.17.intermediate.dense.bias', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.12.attention.output.LayerNorm.weight', 'base_model.encoder.layer.10.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.2.attention.output.dense.weight', 'base_model.encoder.layer.17.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.11.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.2.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.22.output.LayerNorm.weight', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.14.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.9.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.23.intermediate.dense.bias', 'base_model.encoder.layer.4.attention.self.query.bias', 'base_model.encoder.layer.5.attention.self.value.weight', 'base_model.encoder.layer.20.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.1.attention.self.value.weight', 'base_model.encoder.layer.22.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.23.output.dense.bias', 'base_model.encoder.layer.16.attention.output.dense.bias', 'base_model.encoder.layer.12.attention.output.LayerNorm.bias', 'base_model.encoder.layer.7.attention.output.LayerNorm.bias', 'base_model.encoder.layer.10.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.11.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.8.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.8.attention.self.key.weight', 'base_model.encoder.layer.2.output.dense.bias', 'base_model.encoder.layer.6.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.2.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.2.attention.output.LayerNorm.bias', 'base_model.encoder.layer.7.output.LayerNorm.weight', 'base_model.encoder.layer.11.output.dense.weight', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.8.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.12.attention.self.value.weight', 'base_model.encoder.layer.17.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.19.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.19.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.22.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.7.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.22.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.23.output.dense.weight', 'base_model.encoder.layer.17.attention.self.query.bias', 'base_model.encoder.layer.1.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.13.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.9.output.LayerNorm.weight', 'base_model.encoder.layer.10.output.dense.weight', 'base_model.encoder.layer.16.attention.output.LayerNorm.weight', 'base_model.encoder.layer.16.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.20.output.dense.bias', 'base_model.encoder.layer.4.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.4.attention.self.value.weight', 'base_model.encoder.layer.11.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.12.attention.self.value.bias', 'base_model.encoder.layer.22.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.13.intermediate.dense.bias', 'base_model.encoder.layer.12.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.20.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.16.attention.output.LayerNorm.bias', 'base_model.encoder.layer.6.attention.output.dense.bias', 'base_model.encoder.layer.4.attention.output.LayerNorm.weight', 'base_model.encoder.layer.0.attention.self.query.weight', 'base_model.encoder.layer.5.attention.self.value.bias', 'base_model.encoder.layer.12.attention.self.key.weight', 'base_model.encoder.layer.19.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.23.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.16.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.16.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.3.attention.output.LayerNorm.bias', 'base_model.encoder.layer.12.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.21.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.1.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.23.attention.self.key.bias', 'base_model.encoder.layer.5.attention.self.key.bias', 'base_model.encoder.layer.21.attention.output.LayerNorm.bias', 'base_model.encoder.layer.17.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.17.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.9.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.22.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.19.output.adapters.ts.adapter_down.0.bias', 'base_model.pooler.dense.bias', 'base_model.encoder.layer.5.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.17.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.0.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.2.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.23.attention.self.query.bias', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.13.output.dense.weight', 'base_model.encoder.layer.17.output.dense.weight', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.18.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.15.output.dense.weight', 'base_model.encoder.layer.11.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.5.intermediate.dense.bias', 'base_model.encoder.layer.15.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.3.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.14.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.20.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.14.attention.self.value.bias', 'base_model.encoder.layer.12.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.8.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.13.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.13.attention.output.LayerNorm.bias', 'base_model.encoder.layer.5.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.21.intermediate.dense.bias', 'base_model.encoder.layer.19.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.11.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.4.attention.output.dense.weight', 'base_model.encoder.layer.14.attention.self.query.bias', 'base_model.encoder.layer.8.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.2.output.LayerNorm.weight', 'base_model.encoder.layer.16.attention.self.query.bias', 'base_model.encoder.layer.21.attention.self.key.bias', 'base_model.encoder.layer.0.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.23.attention.self.key.weight', 'base_model.encoder.layer.15.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.5.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.0.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.2.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.12.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.5.output.LayerNorm.bias', 'base_model.encoder.layer.12.attention.self.query.weight', 'base_model.encoder.layer.18.output.LayerNorm.bias', 'base_model.encoder.layer.20.intermediate.dense.weight', 'base_model.encoder.layer.5.attention.self.query.bias', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.7.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.11.attention.self.key.bias', 'base_model.encoder.layer.16.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.2.attention.self.key.bias', 'base_model.encoder.layer.1.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.7.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.9.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.15.output.dense.bias', 'base_model.encoder.layer.16.output.dense.bias', 'base_model.embeddings.LayerNorm.weight', 'base_model.encoder.layer.1.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.10.attention.self.value.weight', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.23.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.20.output.dense.weight', 'base_model.encoder.layer.9.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.0.attention.self.query.bias', 'base_model.encoder.layer.10.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.5.output.dense.weight', 'base_model.encoder.layer.10.attention.self.query.weight', 'base_model.encoder.layer.9.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.16.attention.self.key.weight', 'base_model.encoder.layer.19.attention.self.key.weight', 'base_model.encoder.layer.1.attention.self.key.bias', 'base_model.encoder.layer.7.attention.output.LayerNorm.weight', 'base_model.encoder.layer.3.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.2.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.17.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.11.output.LayerNorm.weight', 'base_model.encoder.layer.12.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.7.intermediate.dense.weight', 'base_model.encoder.layer.13.attention.output.LayerNorm.weight', 'base_model.encoder.layer.23.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.19.attention.self.query.bias', 'base_model.encoder.layer.15.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.15.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.1.attention.output.dense.weight', 'base_model.encoder.layer.18.attention.output.LayerNorm.bias', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.1.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.16.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.2.intermediate.dense.weight', 'base_model.encoder.layer.17.intermediate.dense.weight', 'base_model.encoder.layer.3.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.14.attention.self.key.weight', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.17.attention.self.key.weight', 'base_model.encoder.layer.19.output.dense.bias', 'base_model.encoder.layer.12.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.21.attention.output.dense.weight', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.11.intermediate.dense.weight', 'base_model.encoder.layer.19.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.8.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.22.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.17.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.23.attention.output.LayerNorm.weight', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.8.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.1.attention.self.key.weight', 'base_model.encoder.layer.0.output.dense.weight', 'base_model.encoder.layer.7.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.22.attention.self.value.weight', 'base_model.embeddings.token_type_embeddings.weight', 'base_model.encoder.layer.13.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.1.intermediate.dense.bias', 'base_model.encoder.layer.1.attention.self.query.weight', 'base_model.encoder.layer.17.output.LayerNorm.weight', 'base_model.encoder.layer.18.attention.self.key.weight', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.8.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.20.intermediate.dense.bias', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.11.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.2.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.15.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.4.attention.self.key.weight', 'base_model.encoder.layer.17.attention.self.value.weight', 'base_model.encoder.layer.21.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.22.attention.output.LayerNorm.weight', 'base_model.encoder.layer.8.intermediate.dense.weight', 'base_model.encoder.layer.8.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.14.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.3.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.13.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.11.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.14.attention.self.query.weight', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.4.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.18.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.21.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.2.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.21.output.LayerNorm.weight', 'base_model.encoder.layer.0.attention.self.value.weight', 'base_model.encoder.layer.0.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.5.attention.output.dense.weight', 'base_model.encoder.layer.17.attention.output.LayerNorm.weight', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.14.attention.self.value.weight', 'base_model.encoder.layer.12.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.2.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.7.intermediate.dense.bias', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.15.intermediate.dense.weight', 'base_model.encoder.layer.16.intermediate.dense.bias', 'base_model.encoder.layer.13.attention.self.query.weight', 'base_model.encoder.layer.12.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.20.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.2.attention.self.value.bias', 'base_model.encoder.layer.4.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.4.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.7.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.17.attention.output.dense.bias', 'base_model.encoder.layer.10.intermediate.dense.bias', 'base_model.encoder.layer.8.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.7.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.18.attention.self.key.bias', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.2.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.6.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.8.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.18.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.8.attention.output.LayerNorm.weight', 'base_model.encoder.layer.12.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.18.intermediate.dense.bias', 'base_model.encoder.layer.2.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.21.attention.output.LayerNorm.weight', 'base_model.encoder.layer.6.attention.self.key.weight', 'base_model.encoder.layer.4.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.4.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.20.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.4.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.2.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.4.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.6.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.10.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.12.attention.output.dense.bias', 'base_model.encoder.layer.18.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.18.attention.output.LayerNorm.weight', 'base_model.encoder.layer.21.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.23.attention.output.dense.weight', 'base_model.encoder.layer.1.attention.output.LayerNorm.weight', 'base_model.encoder.layer.5.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.18.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.5.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.7.attention.self.query.weight', 'base_model.encoder.layer.9.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.5.intermediate.dense.weight', 'base_model.encoder.layer.12.intermediate.dense.bias', 'base_model.encoder.layer.7.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.13.attention.self.key.weight', 'base_model.encoder.layer.3.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.15.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.6.attention.self.query.bias', 'base_model.encoder.layer.11.attention.self.key.weight', 'base_model.encoder.layer.21.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.0.intermediate.dense.weight', 'base_model.encoder.layer.22.attention.self.key.bias', 'base_model.encoder.layer.8.output.dense.bias', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.23.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.22.attention.self.query.bias', 'base_model.encoder.layer.20.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.13.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.18.attention.output.dense.bias', 'base_model.encoder.layer.15.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.8.output.dense.weight', 'base_model.encoder.layer.11.intermediate.dense.bias', 'base_model.encoder.layer.20.attention.self.query.bias', 'base_model.encoder.layer.17.output.dense.bias', 'base_model.encoder.layer.19.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.3.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.16.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.21.output.LayerNorm.bias', 'base_model.embeddings.word_embeddings.weight', 'base_model.encoder.layer.8.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.0.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.23.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.14.attention.output.LayerNorm.bias', 'base_model.encoder.layer.15.attention.self.query.bias', 'base_model.encoder.layer.1.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.23.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.13.attention.self.query.bias', 'base_model.encoder.layer.23.intermediate.dense.weight', 'base_model.encoder.layer.10.attention.output.dense.weight', 'qa_outputs.bias', 'base_model.encoder.layer.19.output.LayerNorm.weight', 'base_model.encoder.layer.7.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.13.attention.self.value.bias', 'base_model.encoder.layer.0.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.7.attention.self.value.weight', 'base_model.encoder.layer.4.intermediate.dense.bias', 'base_model.encoder.layer.14.output.LayerNorm.bias', 'base_model.encoder.layer.6.attention.self.query.weight', 'base_model.encoder.layer.22.output.dense.bias', 'base_model.encoder.layer.23.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.7.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.23.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.4.intermediate.dense.weight', 'base_model.encoder.layer.3.attention.self.key.weight', 'base_model.encoder.layer.3.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.4.attention.self.value.bias', 'base_model.encoder.layer.6.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.5.attention.output.LayerNorm.bias', 'base_model.encoder.layer.9.output.dense.weight', 'base_model.encoder.layer.14.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.22.output.adapters.es.adapter_up.weight', 'base_model.embeddings.position_ids', 'base_model.encoder.layer.2.attention.self.key.weight', 'base_model.encoder.layer.3.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.14.attention.output.dense.weight', 'base_model.encoder.layer.19.output.LayerNorm.bias', 'base_model.encoder.layer.15.output.adapters.es.adapter_up.bias']
- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of XLMRobertaModel were not initialized from the model checkpoint at /cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//squad/xlm-KG_LR4e-5_EPOCH2.0_maxlen384_batchsize4_gradacc8 and are newly initialized: ['encoder.layer.20.intermediate.dense.bias', 'encoder.layer.3.attention.self.key.weight', 'encoder.layer.23.output.dense.weight', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.4.attention.self.value.bias', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.14.attention.output.LayerNorm.bias', 'encoder.layer.2.attention.self.value.weight', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.12.attention.output.dense.weight', 'encoder.layer.14.attention.self.key.bias', 'encoder.layer.13.attention.self.value.weight', 'encoder.layer.18.attention.output.LayerNorm.weight', 'encoder.layer.8.attention.self.value.weight', 'encoder.layer.21.output.LayerNorm.bias', 'encoder.layer.12.attention.self.query.weight', 'encoder.layer.19.attention.self.key.weight', 'encoder.layer.4.attention.self.key.bias', 'encoder.layer.7.intermediate.dense.bias', 'encoder.layer.3.attention.self.value.weight', 'encoder.layer.3.output.dense.weight', 'encoder.layer.8.output.LayerNorm.weight', 'encoder.layer.14.output.dense.weight', 'encoder.layer.17.output.LayerNorm.weight', 'encoder.layer.1.attention.output.dense.bias', 'encoder.layer.16.attention.self.key.weight', 'encoder.layer.0.attention.output.dense.weight', 'encoder.layer.13.output.dense.bias', 'encoder.layer.19.attention.self.value.weight', 'encoder.layer.22.attention.output.LayerNorm.bias', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.10.attention.self.value.bias', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.21.attention.self.query.bias', 'encoder.layer.6.attention.output.dense.weight', 'encoder.layer.8.attention.output.LayerNorm.bias', 'encoder.layer.17.attention.self.query.bias', 'encoder.layer.8.attention.self.value.bias', 'encoder.layer.15.attention.self.value.weight', 'encoder.layer.14.attention.self.value.bias', 'encoder.layer.0.attention.self.value.weight', 'encoder.layer.7.attention.output.dense.bias', 'encoder.layer.4.attention.output.LayerNorm.weight', 'encoder.layer.4.attention.output.dense.bias', 'encoder.layer.7.output.dense.weight', 'encoder.layer.9.attention.self.key.bias', 'encoder.layer.11.output.LayerNorm.bias', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.8.output.LayerNorm.bias', 'encoder.layer.0.attention.self.key.weight', 'encoder.layer.11.output.dense.bias', 'encoder.layer.8.attention.output.dense.bias', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.23.attention.output.LayerNorm.bias', 'encoder.layer.9.output.LayerNorm.weight', 'encoder.layer.22.attention.self.key.bias', 'encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.layer.13.attention.output.LayerNorm.weight', 'encoder.layer.18.output.LayerNorm.bias', 'encoder.layer.6.attention.output.dense.bias', 'encoder.layer.17.attention.self.value.weight', 'encoder.layer.3.attention.self.value.bias', 'encoder.layer.17.attention.self.key.bias', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.13.attention.self.query.weight', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.9.output.dense.weight', 'encoder.layer.15.attention.output.LayerNorm.weight', 'encoder.layer.14.output.LayerNorm.weight', 'encoder.layer.7.attention.self.value.bias', 'encoder.layer.14.output.dense.bias', 'encoder.layer.21.output.LayerNorm.weight', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.11.output.dense.weight', 'encoder.layer.1.attention.self.query.weight', 'encoder.layer.1.attention.self.key.weight', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.16.attention.output.LayerNorm.weight', 'encoder.layer.7.output.dense.bias', 'encoder.layer.10.intermediate.dense.weight', 'encoder.layer.8.output.dense.bias', 'encoder.layer.6.attention.self.value.weight', 'encoder.layer.23.attention.self.value.weight', 'encoder.layer.12.output.LayerNorm.bias', 'encoder.layer.22.attention.output.dense.weight', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.18.attention.output.dense.weight', 'encoder.layer.5.attention.output.dense.weight', 'encoder.layer.13.attention.self.key.weight', 'encoder.layer.18.output.LayerNorm.weight', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.22.attention.self.query.weight', 'encoder.layer.20.attention.output.LayerNorm.weight', 'encoder.layer.1.attention.self.value.weight', 'encoder.layer.10.output.LayerNorm.bias', 'encoder.layer.11.attention.self.key.bias', 'encoder.layer.18.output.dense.weight', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.21.attention.output.LayerNorm.bias', 'encoder.layer.9.attention.self.key.weight', 'encoder.layer.17.attention.self.key.weight', 'encoder.layer.13.intermediate.dense.weight', 'encoder.layer.14.attention.output.dense.bias', 'encoder.layer.21.output.dense.bias', 'encoder.layer.23.output.dense.bias', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.10.attention.output.dense.weight', 'encoder.layer.4.attention.self.key.weight', 'encoder.layer.15.attention.output.LayerNorm.bias', 'encoder.layer.16.attention.output.dense.bias', 'encoder.layer.2.attention.output.dense.bias', 'encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.layer.5.attention.self.query.bias', 'encoder.layer.6.output.dense.weight', 'encoder.layer.19.output.LayerNorm.bias', 'encoder.layer.23.attention.self.key.weight', 'encoder.layer.17.attention.output.LayerNorm.weight', 'encoder.layer.19.output.dense.weight', 'encoder.layer.5.attention.self.value.bias', 'encoder.layer.16.attention.self.value.bias', 'encoder.layer.1.attention.self.query.bias', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.22.attention.self.key.weight', 'encoder.layer.8.attention.self.query.bias', 'encoder.layer.1.attention.output.dense.weight', 'encoder.layer.6.output.LayerNorm.bias', 'encoder.layer.15.intermediate.dense.bias', 'embeddings.word_embeddings.weight', 'encoder.layer.18.intermediate.dense.bias', 'pooler.dense.weight', 'encoder.layer.17.output.LayerNorm.bias', 'encoder.layer.18.attention.self.key.weight', 'encoder.layer.12.attention.output.dense.bias', 'encoder.layer.21.attention.self.value.weight', 'encoder.layer.1.attention.self.key.bias', 'encoder.layer.7.attention.self.value.weight', 'encoder.layer.14.attention.output.dense.weight', 'encoder.layer.20.attention.self.value.weight', 'encoder.layer.13.intermediate.dense.bias', 'encoder.layer.20.attention.self.query.weight', 'encoder.layer.12.output.dense.bias', 'encoder.layer.19.output.dense.bias', 'encoder.layer.10.attention.output.dense.bias', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.21.output.dense.weight', 'encoder.layer.22.output.dense.bias', 'encoder.layer.9.attention.output.dense.bias', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.8.attention.self.query.weight', 'encoder.layer.17.attention.self.query.weight', 'encoder.layer.4.output.dense.weight', 'encoder.layer.6.attention.self.value.bias', 'encoder.layer.6.attention.output.LayerNorm.weight', 'encoder.layer.19.attention.self.query.bias', 'encoder.layer.5.attention.output.dense.bias', 'encoder.layer.3.attention.output.dense.weight', 'encoder.layer.18.attention.output.dense.bias', 'encoder.layer.12.intermediate.dense.bias', 'encoder.layer.18.output.dense.bias', 'encoder.layer.22.output.LayerNorm.weight', 'encoder.layer.15.attention.self.value.bias', 'encoder.layer.15.intermediate.dense.weight', 'encoder.layer.20.output.LayerNorm.bias', 'encoder.layer.21.attention.output.dense.weight', 'encoder.layer.18.attention.self.query.weight', 'encoder.layer.21.attention.self.key.bias', 'encoder.layer.6.output.dense.bias', 'encoder.layer.19.attention.self.value.bias', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.22.attention.self.query.bias', 'encoder.layer.9.attention.self.query.bias', 'encoder.layer.11.output.LayerNorm.weight', 'encoder.layer.19.attention.output.LayerNorm.bias', 'encoder.layer.16.intermediate.dense.bias', 'encoder.layer.8.attention.output.dense.weight', 'encoder.layer.5.output.dense.weight', 'encoder.layer.16.attention.self.key.bias', 'encoder.layer.15.attention.self.key.bias', 'encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.layer.23.output.LayerNorm.weight', 'encoder.layer.20.attention.self.key.bias', 'encoder.layer.21.attention.self.value.bias', 'encoder.layer.2.attention.self.query.bias', 'encoder.layer.4.attention.self.query.bias', 'encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.layer.8.output.dense.weight', 'encoder.layer.19.intermediate.dense.bias', 'encoder.layer.15.output.dense.bias', 'encoder.layer.18.attention.self.key.bias', 'encoder.layer.14.attention.self.value.weight', 'encoder.layer.13.output.LayerNorm.weight', 'encoder.layer.14.attention.self.key.weight', 'encoder.layer.10.attention.self.value.weight', 'encoder.layer.11.attention.self.value.weight', 'encoder.layer.15.attention.self.query.bias', 'encoder.layer.12.intermediate.dense.weight', 'encoder.layer.13.attention.self.value.bias', 'encoder.layer.23.attention.self.query.weight', 'encoder.layer.10.attention.self.query.bias', 'encoder.layer.22.attention.output.LayerNorm.weight', 'encoder.layer.22.intermediate.dense.weight', 'encoder.layer.11.attention.output.LayerNorm.weight', 'encoder.layer.23.attention.output.dense.bias', 'encoder.layer.12.attention.output.LayerNorm.bias', 'encoder.layer.13.output.LayerNorm.bias', 'encoder.layer.2.attention.output.LayerNorm.weight', 'encoder.layer.5.output.dense.bias', 'encoder.layer.11.attention.self.value.bias', 'encoder.layer.0.attention.self.query.weight', 'encoder.layer.6.attention.output.LayerNorm.bias', 'encoder.layer.17.output.dense.weight', 'encoder.layer.9.attention.self.query.weight', 'encoder.layer.12.output.dense.weight', 'encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.layer.7.attention.output.LayerNorm.bias', 'encoder.layer.3.attention.self.query.bias', 'embeddings.token_type_embeddings.weight', 'encoder.layer.12.attention.self.value.bias', 'encoder.layer.3.output.dense.bias', 'encoder.layer.15.attention.output.dense.weight', 'encoder.layer.5.attention.self.key.weight', 'encoder.layer.15.attention.self.key.weight', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.12.attention.self.value.weight', 'encoder.layer.16.output.dense.weight', 'encoder.layer.6.attention.self.key.bias', 'encoder.layer.14.attention.output.LayerNorm.weight', 'encoder.layer.18.attention.output.LayerNorm.bias', 'encoder.layer.20.output.dense.weight', 'encoder.layer.2.attention.self.value.bias', 'encoder.layer.20.attention.output.dense.weight', 'encoder.layer.23.attention.output.dense.weight', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.7.attention.self.query.bias', 'encoder.layer.9.attention.output.dense.weight', 'encoder.layer.7.attention.self.key.weight', 'encoder.layer.16.output.dense.bias', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.22.output.dense.weight', 'encoder.layer.5.attention.self.key.bias', 'encoder.layer.2.output.dense.weight', 'encoder.layer.15.attention.self.query.weight', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.21.intermediate.dense.weight', 'encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.layer.1.output.dense.bias', 'encoder.layer.15.output.dense.weight', 'encoder.layer.9.output.dense.bias', 'encoder.layer.17.attention.output.dense.bias', 'encoder.layer.16.attention.self.query.weight', 'encoder.layer.4.attention.self.query.weight', 'encoder.layer.4.attention.output.dense.weight', 'encoder.layer.10.attention.self.key.bias', 'encoder.layer.11.attention.self.query.weight', 'encoder.layer.22.intermediate.dense.bias', 'encoder.layer.19.attention.output.LayerNorm.weight', 'encoder.layer.7.output.LayerNorm.weight', 'encoder.layer.21.attention.self.query.weight', 'encoder.layer.14.output.LayerNorm.bias', 'encoder.layer.2.attention.output.LayerNorm.bias', 'encoder.layer.16.output.LayerNorm.bias', 'encoder.layer.11.attention.output.dense.weight', 'encoder.layer.8.attention.self.key.weight', 'encoder.layer.14.attention.self.query.bias', 'encoder.layer.0.attention.self.query.bias', 'encoder.layer.7.attention.self.query.weight', 'encoder.layer.18.attention.self.query.bias', 'encoder.layer.20.attention.self.query.bias', 'encoder.layer.22.attention.self.value.bias', 'encoder.layer.11.attention.self.query.bias', 'encoder.layer.17.output.dense.bias', 'encoder.layer.5.attention.self.value.weight', 'encoder.layer.12.attention.self.query.bias', 'encoder.layer.16.output.LayerNorm.weight', 'encoder.layer.6.attention.self.key.weight', 'encoder.layer.23.intermediate.dense.bias', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.0.output.dense.weight', 'encoder.layer.9.output.LayerNorm.bias', 'encoder.layer.17.attention.self.value.bias', 'encoder.layer.10.output.dense.weight', 'encoder.layer.1.attention.output.LayerNorm.weight', 'encoder.layer.19.attention.output.dense.weight', 'encoder.layer.5.attention.self.query.weight', 'encoder.layer.20.attention.output.LayerNorm.bias', 'encoder.layer.22.attention.output.dense.bias', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.3.attention.self.query.weight', 'encoder.layer.17.intermediate.dense.weight', 'encoder.layer.19.intermediate.dense.weight', 'encoder.layer.7.attention.self.key.bias', 'encoder.layer.20.output.LayerNorm.weight', 'encoder.layer.5.output.LayerNorm.bias', 'encoder.layer.20.attention.self.key.weight', 'encoder.layer.13.attention.self.query.bias', 'encoder.layer.17.attention.output.dense.weight', 'encoder.layer.13.attention.output.dense.bias', 'embeddings.position_embeddings.weight', 'encoder.layer.19.attention.self.query.weight', 'encoder.layer.10.attention.self.query.weight', 'encoder.layer.4.attention.self.value.weight', 'encoder.layer.19.attention.self.key.bias', 'encoder.layer.20.attention.output.dense.bias', 'encoder.layer.13.attention.self.key.bias', 'pooler.dense.bias', 'encoder.layer.9.attention.self.value.weight', 'encoder.layer.14.intermediate.dense.weight', 'encoder.layer.18.intermediate.dense.weight', 'encoder.layer.16.attention.self.value.weight', 'encoder.layer.23.attention.self.value.bias', 'encoder.layer.16.attention.output.dense.weight', 'embeddings.LayerNorm.weight', 'encoder.layer.7.attention.output.dense.weight', 'encoder.layer.12.output.LayerNorm.weight', 'encoder.layer.9.attention.output.LayerNorm.bias', 'encoder.layer.18.attention.self.value.weight', 'encoder.layer.20.output.dense.bias', 'encoder.layer.23.intermediate.dense.weight', 'encoder.layer.22.output.LayerNorm.bias', 'encoder.layer.21.attention.output.dense.bias', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.17.intermediate.dense.bias', 'encoder.layer.5.attention.output.LayerNorm.weight', 'encoder.layer.3.attention.output.dense.bias', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.12.attention.output.LayerNorm.weight', 'encoder.layer.6.attention.self.query.weight', 'encoder.layer.8.attention.self.key.bias', 'encoder.layer.10.attention.output.LayerNorm.weight', 'encoder.layer.0.attention.output.dense.bias', 'encoder.layer.7.output.LayerNorm.bias', 'encoder.layer.23.attention.output.LayerNorm.weight', 'encoder.layer.0.output.dense.bias', 'encoder.layer.1.attention.self.value.bias', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.12.attention.self.key.bias', 'encoder.layer.21.attention.self.key.weight', 'encoder.layer.15.output.LayerNorm.weight', 'encoder.layer.10.attention.output.LayerNorm.bias', 'encoder.layer.10.output.dense.bias', 'encoder.layer.13.attention.output.LayerNorm.bias', 'encoder.layer.10.attention.self.key.weight', 'encoder.layer.14.attention.self.query.weight', 'encoder.layer.2.attention.self.key.bias', 'encoder.layer.14.intermediate.dense.bias', 'encoder.layer.15.output.LayerNorm.bias', 'encoder.layer.6.attention.self.query.bias', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.0.attention.self.key.bias', 'encoder.layer.8.attention.output.LayerNorm.weight', 'encoder.layer.23.output.LayerNorm.bias', 'encoder.layer.2.attention.output.dense.weight', 'encoder.layer.1.output.dense.weight', 'encoder.layer.12.attention.self.key.weight', 'encoder.layer.4.output.dense.bias', 'encoder.layer.10.output.LayerNorm.weight', 'encoder.layer.23.attention.self.key.bias', 'encoder.layer.18.attention.self.value.bias', 'encoder.layer.0.attention.output.LayerNorm.weight', 'encoder.layer.2.output.dense.bias', 'encoder.layer.7.attention.output.LayerNorm.weight', 'encoder.layer.16.attention.output.LayerNorm.bias', 'encoder.layer.16.intermediate.dense.weight', 'encoder.layer.13.output.dense.weight', 'embeddings.LayerNorm.bias', 'encoder.layer.23.attention.self.query.bias', 'encoder.layer.21.attention.output.LayerNorm.weight', 'encoder.layer.11.attention.output.dense.bias', 'encoder.layer.20.attention.self.value.bias', 'encoder.layer.11.attention.self.key.weight', 'encoder.layer.16.attention.self.query.bias', 'encoder.layer.17.attention.output.LayerNorm.bias', 'encoder.layer.9.attention.output.LayerNorm.weight', 'encoder.layer.19.output.LayerNorm.weight', 'encoder.layer.2.attention.self.key.weight', 'encoder.layer.22.attention.self.value.weight', 'encoder.layer.3.attention.self.key.bias', 'encoder.layer.0.attention.self.value.bias', 'encoder.layer.20.intermediate.dense.weight', 'encoder.layer.9.attention.self.value.bias', 'encoder.layer.15.attention.output.dense.bias', 'encoder.layer.21.intermediate.dense.bias', 'encoder.layer.2.attention.self.query.weight', 'encoder.layer.19.attention.output.dense.bias', 'encoder.layer.13.attention.output.dense.weight', 'encoder.layer.4.attention.output.LayerNorm.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Overwriting existing adapter 'ep'.
Overwriting existing adapter 'tp'.
Overwriting existing adapter 'es'.
Overwriting existing adapter 'ts'.
Overwriting existing adapter fusion module 'ep,tp,es,ts'
05/09/2022 20:10:51 - INFO - __main__ -   lang2id = None
05/09/2022 20:10:55 - INFO - __main__ -   Training/evaluation parameters Namespace(adam_epsilon=1e-08, cache_dir='', config_name='', data_dir=None, device=device(type='cuda'), do_eval=True, do_lower_case=False, do_train=False, doc_stride=128, eval_all_checkpoints=False, eval_lang='th', evaluate_during_training=False, fp16=False, fp16_opt_level='O1', gradient_accumulation_steps=1, learning_rate=5e-05, local_rank=-1, logging_steps=50, max_answer_length=30, max_grad_norm=1.0, max_query_length=64, max_seq_length=384, max_steps=-1, model_name='xlm-KG', model_name_or_path='/cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//squad/xlm-KG_LR4e-5_EPOCH2.0_maxlen384_batchsize4_gradacc8', model_type='xlm', modelkg_dir='/cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/adapter/xlmr_adapter', n_best_size=20, n_gpu=1, no_cuda=False, null_score_diff_threshold=0.0, num_train_epochs=3.0, output_dir='/cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//squad/xlm-KG_LR4e-5_EPOCH2.0_maxlen384_batchsize4_gradacc8/predictions/xquad/', overwrite_cache=False, overwrite_output_dir=False, per_gpu_eval_batch_size=8, per_gpu_train_batch_size=8, predict_file='/cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/download//xquad//xquad.th.json', save_steps=50, seed=42, server_ip='', server_port='', threads=1, tokenizer_name='', train_file=None, train_lang='en', verbose_logging=False, version_2_with_negative=False, warmup_steps=0, weight_decay=0.0)
05/09/2022 20:10:55 - INFO - __main__ -   Loading checkpoint /cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//squad/xlm-KG_LR4e-5_EPOCH2.0_maxlen384_batchsize4_gradacc8 for evaluation
05/09/2022 20:10:55 - INFO - __main__ -   Evaluate the following checkpoints: ['/cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//squad/xlm-KG_LR4e-5_EPOCH2.0_maxlen384_batchsize4_gradacc8']
Some weights of the model checkpoint at /cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//squad/xlm-KG_LR4e-5_EPOCH2.0_maxlen384_batchsize4_gradacc8 were not used when initializing XLMRobertaModel: ['base_model.encoder.layer.6.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.9.attention.output.LayerNorm.bias', 'base_model.encoder.layer.17.attention.self.key.bias', 'base_model.encoder.layer.11.attention.self.value.bias', 'base_model.encoder.layer.9.attention.output.dense.weight', 'base_model.encoder.layer.13.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.20.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.4.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.3.attention.output.LayerNorm.weight', 'base_model.encoder.layer.16.attention.self.value.weight', 'base_model.encoder.layer.20.attention.self.query.weight', 'base_model.encoder.layer.13.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.21.output.dense.bias', 'base_model.encoder.layer.7.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.3.attention.self.value.weight', 'base_model.pooler.dense.weight', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.8.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.15.attention.self.key.bias', 'base_model.encoder.layer.18.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.0.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.9.attention.output.LayerNorm.weight', 'base_model.encoder.layer.14.intermediate.dense.bias', 'base_model.encoder.layer.2.attention.output.LayerNorm.weight', 'base_model.encoder.layer.23.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.0.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.6.output.LayerNorm.bias', 'base_model.encoder.layer.6.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.6.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.6.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.7.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.23.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.6.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.15.attention.output.dense.weight', 'base_model.encoder.layer.12.intermediate.dense.weight', 'base_model.encoder.layer.11.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.21.attention.output.dense.bias', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.20.output.LayerNorm.weight', 'base_model.encoder.layer.22.attention.output.LayerNorm.bias', 'base_model.encoder.layer.11.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.7.output.LayerNorm.bias', 'base_model.encoder.layer.1.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.3.output.LayerNorm.bias', 'base_model.encoder.layer.0.attention.output.LayerNorm.bias', 'base_model.encoder.layer.0.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.22.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.4.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.15.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.20.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.20.attention.self.key.weight', 'base_model.encoder.layer.16.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.13.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.10.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.9.intermediate.dense.weight', 'base_model.encoder.layer.17.attention.output.dense.weight', 'base_model.encoder.layer.4.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.5.attention.output.dense.bias', 'base_model.encoder.layer.21.intermediate.dense.weight', 'base_model.encoder.layer.19.attention.output.dense.bias', 'base_model.encoder.layer.17.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.18.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.6.attention.output.LayerNorm.weight', 'base_model.encoder.layer.17.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.19.attention.self.query.weight', 'base_model.encoder.layer.17.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.14.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.10.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.11.attention.self.query.bias', 'base_model.encoder.layer.19.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.10.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.12.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.0.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.19.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.0.attention.self.key.weight', 'base_model.encoder.layer.15.output.LayerNorm.bias', 'base_model.encoder.layer.12.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.9.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.21.attention.self.query.weight', 'base_model.encoder.layer.6.output.LayerNorm.weight', 'base_model.encoder.layer.3.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.0.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.1.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.22.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.5.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.0.intermediate.dense.bias', 'base_model.encoder.layer.15.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.13.attention.self.value.weight', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.19.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.23.attention.self.value.bias', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.15.intermediate.dense.bias', 'base_model.encoder.layer.5.output.LayerNorm.weight', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.15.output.LayerNorm.weight', 'base_model.encoder.layer.16.attention.output.dense.weight', 'base_model.encoder.layer.9.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.3.attention.self.value.bias', 'base_model.encoder.layer.6.attention.self.key.bias', 'base_model.encoder.layer.4.output.dense.weight', 'base_model.encoder.layer.22.output.dense.weight', 'base_model.encoder.layer.3.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.20.attention.output.LayerNorm.weight', 'base_model.encoder.layer.1.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.22.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.17.attention.self.query.weight', 'base_model.encoder.layer.6.attention.self.value.bias', 'base_model.encoder.layer.20.attention.output.LayerNorm.bias', 'base_model.encoder.layer.0.attention.output.dense.bias', 'base_model.encoder.layer.2.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.7.output.dense.bias', 'base_model.encoder.layer.23.output.LayerNorm.weight', 'base_model.encoder.layer.14.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.22.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.3.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.6.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.9.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.15.output.adapters.ep.adapter_down.0.weight', 'base_model.embeddings.LayerNorm.bias', 'base_model.encoder.layer.21.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.8.output.LayerNorm.bias', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.5.attention.output.LayerNorm.weight', 'base_model.encoder.layer.12.output.LayerNorm.weight', 'base_model.encoder.layer.8.attention.self.query.bias', 'base_model.encoder.layer.19.intermediate.dense.bias', 'base_model.encoder.layer.13.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.19.attention.self.value.bias', 'base_model.encoder.layer.22.attention.output.dense.weight', 'base_model.encoder.layer.17.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.23.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.23.attention.self.value.weight', 'base_model.encoder.layer.9.attention.self.value.bias', 'base_model.encoder.layer.11.attention.output.LayerNorm.bias', 'base_model.encoder.layer.6.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.5.attention.self.key.weight', 'base_model.encoder.layer.7.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.17.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.8.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.21.attention.self.value.bias', 'base_model.encoder.layer.8.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.15.attention.self.query.weight', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.2.output.dense.weight', 'base_model.encoder.layer.18.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.15.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.14.attention.output.LayerNorm.weight', 'base_model.encoder.layer.20.output.LayerNorm.bias', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.23.attention.output.LayerNorm.bias', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.9.attention.self.query.weight', 'base_model.encoder.layer.12.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.10.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.8.output.LayerNorm.weight', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.5.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.7.attention.self.value.bias', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.9.attention.self.value.weight', 'base_model.encoder.layer.9.output.dense.bias', 'base_model.encoder.layer.14.output.dense.weight', 'base_model.encoder.layer.16.attention.self.query.weight', 'base_model.encoder.layer.19.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.6.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.19.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.22.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.2.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.20.attention.output.dense.weight', 'base_model.encoder.layer.3.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.7.attention.self.key.bias', 'base_model.encoder.layer.5.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.11.output.dense.bias', 'base_model.encoder.layer.3.output.LayerNorm.weight', 'base_model.encoder.layer.21.attention.self.value.weight', 'base_model.encoder.layer.5.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.1.output.dense.weight', 'base_model.encoder.layer.12.output.dense.weight', 'base_model.encoder.layer.3.attention.self.query.weight', 'base_model.encoder.layer.11.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.19.intermediate.dense.weight', 'base_model.encoder.layer.18.output.LayerNorm.weight', 'base_model.encoder.layer.2.attention.self.query.weight', 'base_model.encoder.layer.4.output.LayerNorm.weight', 'base_model.encoder.layer.12.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.0.output.LayerNorm.bias', 'base_model.encoder.layer.10.attention.self.value.bias', 'base_model.encoder.layer.18.attention.self.value.weight', 'base_model.encoder.layer.4.output.dense.bias', 'base_model.encoder.layer.7.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.10.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.13.output.dense.bias', 'base_model.encoder.layer.13.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.20.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.21.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.21.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.10.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.3.intermediate.dense.bias', 'base_model.encoder.layer.14.intermediate.dense.weight', 'base_model.encoder.layer.19.output.dense.weight', 'base_model.encoder.layer.21.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.6.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.6.intermediate.dense.bias', 'base_model.encoder.layer.15.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.9.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.5.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.7.attention.output.dense.weight', 'base_model.encoder.layer.1.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.23.attention.self.query.weight', 'base_model.encoder.layer.12.attention.output.dense.weight', 'base_model.encoder.layer.22.attention.self.query.weight', 'base_model.encoder.layer.15.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.21.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.21.attention.self.query.bias', 'base_model.encoder.layer.0.attention.output.LayerNorm.weight', 'base_model.encoder.layer.14.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.15.attention.self.key.weight', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.10.attention.output.dense.bias', 'base_model.encoder.layer.10.output.dense.bias', 'base_model.encoder.layer.13.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.14.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.2.intermediate.dense.bias', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.20.attention.self.value.weight', 'base_model.encoder.layer.5.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.18.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.8.attention.output.dense.weight', 'base_model.encoder.layer.18.attention.self.query.bias', 'base_model.encoder.layer.22.attention.output.dense.bias', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.20.attention.self.value.bias', 'base_model.encoder.layer.18.output.dense.weight', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.12.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.1.attention.self.query.bias', 'base_model.encoder.layer.8.attention.self.query.weight', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.3.output.dense.bias', 'base_model.encoder.layer.19.attention.output.LayerNorm.weight', 'base_model.encoder.layer.21.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.10.attention.self.key.weight', 'base_model.encoder.layer.0.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.16.intermediate.dense.weight', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.1.output.LayerNorm.weight', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.5.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.17.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.1.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.18.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.11.attention.output.dense.weight', 'base_model.encoder.layer.4.attention.output.LayerNorm.bias', 'base_model.encoder.layer.3.intermediate.dense.weight', 'base_model.encoder.layer.11.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.20.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.5.output.dense.bias', 'base_model.encoder.layer.2.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.11.attention.self.query.weight', 'base_model.encoder.layer.1.attention.self.value.bias', 'base_model.encoder.layer.3.attention.output.dense.weight', 'base_model.encoder.layer.14.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.11.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.14.output.LayerNorm.weight', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.20.attention.output.dense.bias', 'base_model.encoder.layer.13.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.16.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.23.attention.output.dense.bias', 'base_model.encoder.layer.13.output.LayerNorm.bias', 'base_model.encoder.layer.22.output.adapters.ep.adapter_down.0.bias', 'qa_outputs.weight', 'base_model.encoder.layer.4.attention.output.dense.bias', 'base_model.encoder.layer.16.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.16.output.LayerNorm.weight', 'base_model.encoder.layer.0.output.dense.bias', 'base_model.encoder.layer.1.output.dense.bias', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.9.attention.output.dense.bias', 'base_model.encoder.layer.13.intermediate.dense.weight', 'base_model.encoder.layer.1.output.LayerNorm.bias', 'base_model.encoder.layer.3.attention.self.query.bias', 'base_model.encoder.layer.9.attention.self.key.weight', 'base_model.encoder.layer.11.attention.output.dense.bias', 'base_model.encoder.layer.12.output.dense.bias', 'base_model.encoder.layer.16.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.9.attention.self.key.bias', 'base_model.encoder.layer.4.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.18.attention.output.dense.weight', 'base_model.encoder.layer.13.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.14.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.23.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.19.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.10.intermediate.dense.weight', 'base_model.encoder.layer.15.attention.output.LayerNorm.bias', 'base_model.encoder.layer.12.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.3.attention.self.key.bias', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.10.attention.output.LayerNorm.bias', 'base_model.encoder.layer.17.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.18.attention.self.query.weight', 'base_model.encoder.layer.3.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.5.attention.self.query.weight', 'base_model.encoder.layer.18.attention.self.value.bias', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.21.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.22.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.9.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.4.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.15.attention.self.value.weight', 'base_model.encoder.layer.20.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.8.attention.output.LayerNorm.bias', 'base_model.encoder.layer.22.attention.self.key.weight', 'base_model.encoder.layer.14.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.18.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.23.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.10.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.20.attention.self.key.bias', 'base_model.encoder.layer.8.intermediate.dense.bias', 'base_model.encoder.layer.19.attention.self.value.weight', 'base_model.encoder.layer.6.attention.output.LayerNorm.bias', 'base_model.encoder.layer.21.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.9.intermediate.dense.bias', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.13.attention.output.dense.bias', 'base_model.encoder.layer.14.output.dense.bias', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.18.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.6.output.dense.bias', 'base_model.encoder.layer.20.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.8.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.3.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.13.output.LayerNorm.weight', 'base_model.encoder.layer.7.attention.self.key.weight', 'base_model.encoder.layer.6.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.0.attention.output.dense.weight', 'base_model.encoder.layer.14.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.14.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.9.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.9.attention.self.query.bias', 'base_model.encoder.layer.13.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.10.output.LayerNorm.bias', 'base_model.encoder.layer.21.attention.self.key.weight', 'base_model.encoder.layer.20.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.19.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.1.intermediate.dense.weight', 'base_model.encoder.layer.18.output.dense.bias', 'base_model.encoder.layer.11.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.7.output.dense.weight', 'base_model.encoder.layer.11.output.LayerNorm.bias', 'base_model.encoder.layer.16.output.dense.weight', 'base_model.encoder.layer.10.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.7.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.16.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.6.attention.self.value.weight', 'base_model.encoder.layer.14.attention.self.key.bias', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.19.attention.output.LayerNorm.bias', 'base_model.encoder.layer.8.attention.self.value.bias', 'base_model.encoder.layer.5.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.1.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.23.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.15.attention.output.LayerNorm.weight', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.17.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.18.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.4.output.LayerNorm.bias', 'base_model.encoder.layer.15.attention.self.value.bias', 'base_model.encoder.layer.2.attention.self.value.weight', 'base_model.encoder.layer.11.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.16.attention.self.value.bias', 'base_model.encoder.layer.6.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.17.attention.self.value.bias', 'base_model.encoder.layer.17.output.LayerNorm.bias', 'base_model.encoder.layer.16.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.1.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.19.attention.output.dense.weight', 'base_model.encoder.layer.9.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.12.attention.self.key.bias', 'base_model.encoder.layer.13.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.23.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.10.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.6.intermediate.dense.weight', 'base_model.encoder.layer.18.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.2.attention.output.dense.bias', 'base_model.encoder.layer.2.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.1.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.17.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.0.attention.self.value.bias', 'base_model.encoder.layer.10.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.7.attention.output.dense.bias', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.13.attention.output.dense.weight', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.2.attention.self.query.bias', 'base_model.encoder.layer.4.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.3.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.15.attention.output.dense.bias', 'base_model.encoder.layer.7.attention.self.query.bias', 'base_model.encoder.layer.10.attention.self.query.bias', 'base_model.encoder.layer.12.output.LayerNorm.bias', 'base_model.encoder.layer.2.output.LayerNorm.bias', 'base_model.encoder.layer.10.attention.output.LayerNorm.weight', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.21.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.7.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.9.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.8.attention.self.value.weight', 'base_model.encoder.layer.20.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.12.attention.self.query.bias', 'base_model.encoder.layer.0.output.LayerNorm.weight', 'base_model.encoder.layer.5.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.14.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.21.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.14.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.3.attention.output.dense.bias', 'base_model.encoder.layer.16.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.19.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.10.output.LayerNorm.weight', 'base_model.encoder.layer.18.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.6.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.8.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.15.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.11.attention.output.LayerNorm.weight', 'base_model.encoder.layer.22.attention.self.value.bias', 'base_model.encoder.layer.3.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.11.attention.self.value.weight', 'base_model.encoder.layer.19.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.2.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.13.attention.self.key.bias', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.13.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.18.intermediate.dense.weight', 'base_model.encoder.layer.14.attention.output.dense.bias', 'base_model.encoder.layer.9.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.22.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.10.attention.self.key.bias', 'base_model.encoder.layer.12.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.6.output.dense.weight', 'base_model.encoder.layer.15.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.16.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.3.output.dense.weight', 'base_model.encoder.layer.18.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.21.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.16.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.22.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.9.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.16.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.8.attention.output.dense.bias', 'base_model.encoder.layer.0.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.22.intermediate.dense.weight', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.5.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.1.attention.output.dense.bias', 'base_model.encoder.layer.7.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.4.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.4.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.23.output.LayerNorm.bias', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.6.attention.output.dense.weight', 'base_model.encoder.layer.1.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.10.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.22.output.LayerNorm.bias', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.0.attention.self.key.bias', 'base_model.encoder.layer.8.attention.self.key.bias', 'base_model.encoder.layer.11.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.16.attention.self.key.bias', 'base_model.encoder.layer.11.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.0.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.21.output.dense.weight', 'base_model.encoder.layer.20.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.14.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.16.output.LayerNorm.bias', 'base_model.encoder.layer.5.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.1.attention.output.LayerNorm.bias', 'base_model.encoder.layer.10.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.4.attention.self.key.bias', 'base_model.encoder.layer.4.attention.self.query.weight', 'base_model.encoder.layer.17.attention.output.LayerNorm.bias', 'base_model.encoder.layer.22.intermediate.dense.bias', 'base_model.encoder.layer.0.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.19.attention.self.key.bias', 'base_model.encoder.layer.0.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.23.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.1.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.20.output.adapters.tp.adapter_up.weight', 'base_model.embeddings.position_embeddings.weight', 'base_model.encoder.layer.9.output.LayerNorm.bias', 'base_model.encoder.layer.17.intermediate.dense.bias', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.12.attention.output.LayerNorm.weight', 'base_model.encoder.layer.10.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.2.attention.output.dense.weight', 'base_model.encoder.layer.17.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.11.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.2.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.22.output.LayerNorm.weight', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.14.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.9.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.23.intermediate.dense.bias', 'base_model.encoder.layer.4.attention.self.query.bias', 'base_model.encoder.layer.5.attention.self.value.weight', 'base_model.encoder.layer.20.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.1.attention.self.value.weight', 'base_model.encoder.layer.22.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.23.output.dense.bias', 'base_model.encoder.layer.16.attention.output.dense.bias', 'base_model.encoder.layer.12.attention.output.LayerNorm.bias', 'base_model.encoder.layer.7.attention.output.LayerNorm.bias', 'base_model.encoder.layer.10.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.11.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.8.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.8.attention.self.key.weight', 'base_model.encoder.layer.2.output.dense.bias', 'base_model.encoder.layer.6.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.2.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.2.attention.output.LayerNorm.bias', 'base_model.encoder.layer.7.output.LayerNorm.weight', 'base_model.encoder.layer.11.output.dense.weight', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.8.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.12.attention.self.value.weight', 'base_model.encoder.layer.17.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.19.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.19.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.22.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.7.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.22.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.23.output.dense.weight', 'base_model.encoder.layer.17.attention.self.query.bias', 'base_model.encoder.layer.1.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.13.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.9.output.LayerNorm.weight', 'base_model.encoder.layer.10.output.dense.weight', 'base_model.encoder.layer.16.attention.output.LayerNorm.weight', 'base_model.encoder.layer.16.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.20.output.dense.bias', 'base_model.encoder.layer.4.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.4.attention.self.value.weight', 'base_model.encoder.layer.11.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.12.attention.self.value.bias', 'base_model.encoder.layer.22.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.13.intermediate.dense.bias', 'base_model.encoder.layer.12.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.20.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.16.attention.output.LayerNorm.bias', 'base_model.encoder.layer.6.attention.output.dense.bias', 'base_model.encoder.layer.4.attention.output.LayerNorm.weight', 'base_model.encoder.layer.0.attention.self.query.weight', 'base_model.encoder.layer.5.attention.self.value.bias', 'base_model.encoder.layer.12.attention.self.key.weight', 'base_model.encoder.layer.19.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.23.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.16.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.16.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.3.attention.output.LayerNorm.bias', 'base_model.encoder.layer.12.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.21.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.1.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.23.attention.self.key.bias', 'base_model.encoder.layer.5.attention.self.key.bias', 'base_model.encoder.layer.21.attention.output.LayerNorm.bias', 'base_model.encoder.layer.17.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.17.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.9.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.22.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.19.output.adapters.ts.adapter_down.0.bias', 'base_model.pooler.dense.bias', 'base_model.encoder.layer.5.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.17.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.0.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.2.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.23.attention.self.query.bias', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.13.output.dense.weight', 'base_model.encoder.layer.17.output.dense.weight', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.18.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.15.output.dense.weight', 'base_model.encoder.layer.11.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.5.intermediate.dense.bias', 'base_model.encoder.layer.15.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.3.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.14.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.20.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.14.attention.self.value.bias', 'base_model.encoder.layer.12.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.8.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.13.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.13.attention.output.LayerNorm.bias', 'base_model.encoder.layer.5.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.21.intermediate.dense.bias', 'base_model.encoder.layer.19.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.11.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.4.attention.output.dense.weight', 'base_model.encoder.layer.14.attention.self.query.bias', 'base_model.encoder.layer.8.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.2.output.LayerNorm.weight', 'base_model.encoder.layer.16.attention.self.query.bias', 'base_model.encoder.layer.21.attention.self.key.bias', 'base_model.encoder.layer.0.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.23.attention.self.key.weight', 'base_model.encoder.layer.15.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.5.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.0.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.2.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.12.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.5.output.LayerNorm.bias', 'base_model.encoder.layer.12.attention.self.query.weight', 'base_model.encoder.layer.18.output.LayerNorm.bias', 'base_model.encoder.layer.20.intermediate.dense.weight', 'base_model.encoder.layer.5.attention.self.query.bias', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.7.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.11.attention.self.key.bias', 'base_model.encoder.layer.16.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.2.attention.self.key.bias', 'base_model.encoder.layer.1.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.7.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.9.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.15.output.dense.bias', 'base_model.encoder.layer.16.output.dense.bias', 'base_model.embeddings.LayerNorm.weight', 'base_model.encoder.layer.1.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.10.attention.self.value.weight', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.23.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.20.output.dense.weight', 'base_model.encoder.layer.9.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.0.attention.self.query.bias', 'base_model.encoder.layer.10.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.5.output.dense.weight', 'base_model.encoder.layer.10.attention.self.query.weight', 'base_model.encoder.layer.9.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.16.attention.self.key.weight', 'base_model.encoder.layer.19.attention.self.key.weight', 'base_model.encoder.layer.1.attention.self.key.bias', 'base_model.encoder.layer.7.attention.output.LayerNorm.weight', 'base_model.encoder.layer.3.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.2.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.17.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.11.output.LayerNorm.weight', 'base_model.encoder.layer.12.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.7.intermediate.dense.weight', 'base_model.encoder.layer.13.attention.output.LayerNorm.weight', 'base_model.encoder.layer.23.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.19.attention.self.query.bias', 'base_model.encoder.layer.15.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.15.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.1.attention.output.dense.weight', 'base_model.encoder.layer.18.attention.output.LayerNorm.bias', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.1.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.16.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.2.intermediate.dense.weight', 'base_model.encoder.layer.17.intermediate.dense.weight', 'base_model.encoder.layer.3.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.14.attention.self.key.weight', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.17.attention.self.key.weight', 'base_model.encoder.layer.19.output.dense.bias', 'base_model.encoder.layer.12.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.21.attention.output.dense.weight', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.11.intermediate.dense.weight', 'base_model.encoder.layer.19.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.8.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.22.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.17.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.23.attention.output.LayerNorm.weight', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.8.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.1.attention.self.key.weight', 'base_model.encoder.layer.0.output.dense.weight', 'base_model.encoder.layer.7.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.22.attention.self.value.weight', 'base_model.embeddings.token_type_embeddings.weight', 'base_model.encoder.layer.13.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.1.intermediate.dense.bias', 'base_model.encoder.layer.1.attention.self.query.weight', 'base_model.encoder.layer.17.output.LayerNorm.weight', 'base_model.encoder.layer.18.attention.self.key.weight', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.8.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.20.intermediate.dense.bias', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.11.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.2.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.15.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.4.attention.self.key.weight', 'base_model.encoder.layer.17.attention.self.value.weight', 'base_model.encoder.layer.21.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.22.attention.output.LayerNorm.weight', 'base_model.encoder.layer.8.intermediate.dense.weight', 'base_model.encoder.layer.8.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.14.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.3.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.13.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.11.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.14.attention.self.query.weight', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.4.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.18.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.21.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.2.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.21.output.LayerNorm.weight', 'base_model.encoder.layer.0.attention.self.value.weight', 'base_model.encoder.layer.0.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.5.attention.output.dense.weight', 'base_model.encoder.layer.17.attention.output.LayerNorm.weight', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.14.attention.self.value.weight', 'base_model.encoder.layer.12.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.2.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.7.intermediate.dense.bias', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.15.intermediate.dense.weight', 'base_model.encoder.layer.16.intermediate.dense.bias', 'base_model.encoder.layer.13.attention.self.query.weight', 'base_model.encoder.layer.12.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.20.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.2.attention.self.value.bias', 'base_model.encoder.layer.4.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.4.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.7.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.17.attention.output.dense.bias', 'base_model.encoder.layer.10.intermediate.dense.bias', 'base_model.encoder.layer.8.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.7.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.18.attention.self.key.bias', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.2.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.6.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.8.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.18.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.8.attention.output.LayerNorm.weight', 'base_model.encoder.layer.12.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.18.intermediate.dense.bias', 'base_model.encoder.layer.2.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.21.attention.output.LayerNorm.weight', 'base_model.encoder.layer.6.attention.self.key.weight', 'base_model.encoder.layer.4.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.4.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.20.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.4.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.2.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.4.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.6.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.10.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.12.attention.output.dense.bias', 'base_model.encoder.layer.18.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.18.attention.output.LayerNorm.weight', 'base_model.encoder.layer.21.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.23.attention.output.dense.weight', 'base_model.encoder.layer.1.attention.output.LayerNorm.weight', 'base_model.encoder.layer.5.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.18.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.5.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.7.attention.self.query.weight', 'base_model.encoder.layer.9.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.5.intermediate.dense.weight', 'base_model.encoder.layer.12.intermediate.dense.bias', 'base_model.encoder.layer.7.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.13.attention.self.key.weight', 'base_model.encoder.layer.3.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.15.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.6.attention.self.query.bias', 'base_model.encoder.layer.11.attention.self.key.weight', 'base_model.encoder.layer.21.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.0.intermediate.dense.weight', 'base_model.encoder.layer.22.attention.self.key.bias', 'base_model.encoder.layer.8.output.dense.bias', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.23.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.22.attention.self.query.bias', 'base_model.encoder.layer.20.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.13.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.18.attention.output.dense.bias', 'base_model.encoder.layer.15.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.8.output.dense.weight', 'base_model.encoder.layer.11.intermediate.dense.bias', 'base_model.encoder.layer.20.attention.self.query.bias', 'base_model.encoder.layer.17.output.dense.bias', 'base_model.encoder.layer.19.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.3.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.16.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.21.output.LayerNorm.bias', 'base_model.embeddings.word_embeddings.weight', 'base_model.encoder.layer.8.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.0.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.23.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.14.attention.output.LayerNorm.bias', 'base_model.encoder.layer.15.attention.self.query.bias', 'base_model.encoder.layer.1.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.23.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.13.attention.self.query.bias', 'base_model.encoder.layer.23.intermediate.dense.weight', 'base_model.encoder.layer.10.attention.output.dense.weight', 'qa_outputs.bias', 'base_model.encoder.layer.19.output.LayerNorm.weight', 'base_model.encoder.layer.7.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.13.attention.self.value.bias', 'base_model.encoder.layer.0.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.7.attention.self.value.weight', 'base_model.encoder.layer.4.intermediate.dense.bias', 'base_model.encoder.layer.14.output.LayerNorm.bias', 'base_model.encoder.layer.6.attention.self.query.weight', 'base_model.encoder.layer.22.output.dense.bias', 'base_model.encoder.layer.23.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.7.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.23.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.4.intermediate.dense.weight', 'base_model.encoder.layer.3.attention.self.key.weight', 'base_model.encoder.layer.3.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.4.attention.self.value.bias', 'base_model.encoder.layer.6.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.5.attention.output.LayerNorm.bias', 'base_model.encoder.layer.9.output.dense.weight', 'base_model.encoder.layer.14.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.22.output.adapters.es.adapter_up.weight', 'base_model.embeddings.position_ids', 'base_model.encoder.layer.2.attention.self.key.weight', 'base_model.encoder.layer.3.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.14.attention.output.dense.weight', 'base_model.encoder.layer.19.output.LayerNorm.bias', 'base_model.encoder.layer.15.output.adapters.es.adapter_up.bias']
- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of XLMRobertaModel were not initialized from the model checkpoint at /cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//squad/xlm-KG_LR4e-5_EPOCH2.0_maxlen384_batchsize4_gradacc8 and are newly initialized: ['encoder.layer.20.intermediate.dense.bias', 'encoder.layer.3.attention.self.key.weight', 'encoder.layer.23.output.dense.weight', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.4.attention.self.value.bias', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.14.attention.output.LayerNorm.bias', 'encoder.layer.2.attention.self.value.weight', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.12.attention.output.dense.weight', 'encoder.layer.14.attention.self.key.bias', 'encoder.layer.13.attention.self.value.weight', 'encoder.layer.18.attention.output.LayerNorm.weight', 'encoder.layer.8.attention.self.value.weight', 'encoder.layer.21.output.LayerNorm.bias', 'encoder.layer.12.attention.self.query.weight', 'encoder.layer.19.attention.self.key.weight', 'encoder.layer.4.attention.self.key.bias', 'encoder.layer.7.intermediate.dense.bias', 'encoder.layer.3.attention.self.value.weight', 'encoder.layer.3.output.dense.weight', 'encoder.layer.8.output.LayerNorm.weight', 'encoder.layer.14.output.dense.weight', 'encoder.layer.17.output.LayerNorm.weight', 'encoder.layer.1.attention.output.dense.bias', 'encoder.layer.16.attention.self.key.weight', 'encoder.layer.0.attention.output.dense.weight', 'encoder.layer.13.output.dense.bias', 'encoder.layer.19.attention.self.value.weight', 'encoder.layer.22.attention.output.LayerNorm.bias', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.10.attention.self.value.bias', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.21.attention.self.query.bias', 'encoder.layer.6.attention.output.dense.weight', 'encoder.layer.8.attention.output.LayerNorm.bias', 'encoder.layer.17.attention.self.query.bias', 'encoder.layer.8.attention.self.value.bias', 'encoder.layer.15.attention.self.value.weight', 'encoder.layer.14.attention.self.value.bias', 'encoder.layer.0.attention.self.value.weight', 'encoder.layer.7.attention.output.dense.bias', 'encoder.layer.4.attention.output.LayerNorm.weight', 'encoder.layer.4.attention.output.dense.bias', 'encoder.layer.7.output.dense.weight', 'encoder.layer.9.attention.self.key.bias', 'encoder.layer.11.output.LayerNorm.bias', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.8.output.LayerNorm.bias', 'encoder.layer.0.attention.self.key.weight', 'encoder.layer.11.output.dense.bias', 'encoder.layer.8.attention.output.dense.bias', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.23.attention.output.LayerNorm.bias', 'encoder.layer.9.output.LayerNorm.weight', 'encoder.layer.22.attention.self.key.bias', 'encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.layer.13.attention.output.LayerNorm.weight', 'encoder.layer.18.output.LayerNorm.bias', 'encoder.layer.6.attention.output.dense.bias', 'encoder.layer.17.attention.self.value.weight', 'encoder.layer.3.attention.self.value.bias', 'encoder.layer.17.attention.self.key.bias', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.13.attention.self.query.weight', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.9.output.dense.weight', 'encoder.layer.15.attention.output.LayerNorm.weight', 'encoder.layer.14.output.LayerNorm.weight', 'encoder.layer.7.attention.self.value.bias', 'encoder.layer.14.output.dense.bias', 'encoder.layer.21.output.LayerNorm.weight', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.11.output.dense.weight', 'encoder.layer.1.attention.self.query.weight', 'encoder.layer.1.attention.self.key.weight', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.16.attention.output.LayerNorm.weight', 'encoder.layer.7.output.dense.bias', 'encoder.layer.10.intermediate.dense.weight', 'encoder.layer.8.output.dense.bias', 'encoder.layer.6.attention.self.value.weight', 'encoder.layer.23.attention.self.value.weight', 'encoder.layer.12.output.LayerNorm.bias', 'encoder.layer.22.attention.output.dense.weight', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.18.attention.output.dense.weight', 'encoder.layer.5.attention.output.dense.weight', 'encoder.layer.13.attention.self.key.weight', 'encoder.layer.18.output.LayerNorm.weight', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.22.attention.self.query.weight', 'encoder.layer.20.attention.output.LayerNorm.weight', 'encoder.layer.1.attention.self.value.weight', 'encoder.layer.10.output.LayerNorm.bias', 'encoder.layer.11.attention.self.key.bias', 'encoder.layer.18.output.dense.weight', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.21.attention.output.LayerNorm.bias', 'encoder.layer.9.attention.self.key.weight', 'encoder.layer.17.attention.self.key.weight', 'encoder.layer.13.intermediate.dense.weight', 'encoder.layer.14.attention.output.dense.bias', 'encoder.layer.21.output.dense.bias', 'encoder.layer.23.output.dense.bias', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.10.attention.output.dense.weight', 'encoder.layer.4.attention.self.key.weight', 'encoder.layer.15.attention.output.LayerNorm.bias', 'encoder.layer.16.attention.output.dense.bias', 'encoder.layer.2.attention.output.dense.bias', 'encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.layer.5.attention.self.query.bias', 'encoder.layer.6.output.dense.weight', 'encoder.layer.19.output.LayerNorm.bias', 'encoder.layer.23.attention.self.key.weight', 'encoder.layer.17.attention.output.LayerNorm.weight', 'encoder.layer.19.output.dense.weight', 'encoder.layer.5.attention.self.value.bias', 'encoder.layer.16.attention.self.value.bias', 'encoder.layer.1.attention.self.query.bias', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.22.attention.self.key.weight', 'encoder.layer.8.attention.self.query.bias', 'encoder.layer.1.attention.output.dense.weight', 'encoder.layer.6.output.LayerNorm.bias', 'encoder.layer.15.intermediate.dense.bias', 'embeddings.word_embeddings.weight', 'encoder.layer.18.intermediate.dense.bias', 'pooler.dense.weight', 'encoder.layer.17.output.LayerNorm.bias', 'encoder.layer.18.attention.self.key.weight', 'encoder.layer.12.attention.output.dense.bias', 'encoder.layer.21.attention.self.value.weight', 'encoder.layer.1.attention.self.key.bias', 'encoder.layer.7.attention.self.value.weight', 'encoder.layer.14.attention.output.dense.weight', 'encoder.layer.20.attention.self.value.weight', 'encoder.layer.13.intermediate.dense.bias', 'encoder.layer.20.attention.self.query.weight', 'encoder.layer.12.output.dense.bias', 'encoder.layer.19.output.dense.bias', 'encoder.layer.10.attention.output.dense.bias', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.21.output.dense.weight', 'encoder.layer.22.output.dense.bias', 'encoder.layer.9.attention.output.dense.bias', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.8.attention.self.query.weight', 'encoder.layer.17.attention.self.query.weight', 'encoder.layer.4.output.dense.weight', 'encoder.layer.6.attention.self.value.bias', 'encoder.layer.6.attention.output.LayerNorm.weight', 'encoder.layer.19.attention.self.query.bias', 'encoder.layer.5.attention.output.dense.bias', 'encoder.layer.3.attention.output.dense.weight', 'encoder.layer.18.attention.output.dense.bias', 'encoder.layer.12.intermediate.dense.bias', 'encoder.layer.18.output.dense.bias', 'encoder.layer.22.output.LayerNorm.weight', 'encoder.layer.15.attention.self.value.bias', 'encoder.layer.15.intermediate.dense.weight', 'encoder.layer.20.output.LayerNorm.bias', 'encoder.layer.21.attention.output.dense.weight', 'encoder.layer.18.attention.self.query.weight', 'encoder.layer.21.attention.self.key.bias', 'encoder.layer.6.output.dense.bias', 'encoder.layer.19.attention.self.value.bias', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.22.attention.self.query.bias', 'encoder.layer.9.attention.self.query.bias', 'encoder.layer.11.output.LayerNorm.weight', 'encoder.layer.19.attention.output.LayerNorm.bias', 'encoder.layer.16.intermediate.dense.bias', 'encoder.layer.8.attention.output.dense.weight', 'encoder.layer.5.output.dense.weight', 'encoder.layer.16.attention.self.key.bias', 'encoder.layer.15.attention.self.key.bias', 'encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.layer.23.output.LayerNorm.weight', 'encoder.layer.20.attention.self.key.bias', 'encoder.layer.21.attention.self.value.bias', 'encoder.layer.2.attention.self.query.bias', 'encoder.layer.4.attention.self.query.bias', 'encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.layer.8.output.dense.weight', 'encoder.layer.19.intermediate.dense.bias', 'encoder.layer.15.output.dense.bias', 'encoder.layer.18.attention.self.key.bias', 'encoder.layer.14.attention.self.value.weight', 'encoder.layer.13.output.LayerNorm.weight', 'encoder.layer.14.attention.self.key.weight', 'encoder.layer.10.attention.self.value.weight', 'encoder.layer.11.attention.self.value.weight', 'encoder.layer.15.attention.self.query.bias', 'encoder.layer.12.intermediate.dense.weight', 'encoder.layer.13.attention.self.value.bias', 'encoder.layer.23.attention.self.query.weight', 'encoder.layer.10.attention.self.query.bias', 'encoder.layer.22.attention.output.LayerNorm.weight', 'encoder.layer.22.intermediate.dense.weight', 'encoder.layer.11.attention.output.LayerNorm.weight', 'encoder.layer.23.attention.output.dense.bias', 'encoder.layer.12.attention.output.LayerNorm.bias', 'encoder.layer.13.output.LayerNorm.bias', 'encoder.layer.2.attention.output.LayerNorm.weight', 'encoder.layer.5.output.dense.bias', 'encoder.layer.11.attention.self.value.bias', 'encoder.layer.0.attention.self.query.weight', 'encoder.layer.6.attention.output.LayerNorm.bias', 'encoder.layer.17.output.dense.weight', 'encoder.layer.9.attention.self.query.weight', 'encoder.layer.12.output.dense.weight', 'encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.layer.7.attention.output.LayerNorm.bias', 'encoder.layer.3.attention.self.query.bias', 'embeddings.token_type_embeddings.weight', 'encoder.layer.12.attention.self.value.bias', 'encoder.layer.3.output.dense.bias', 'encoder.layer.15.attention.output.dense.weight', 'encoder.layer.5.attention.self.key.weight', 'encoder.layer.15.attention.self.key.weight', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.12.attention.self.value.weight', 'encoder.layer.16.output.dense.weight', 'encoder.layer.6.attention.self.key.bias', 'encoder.layer.14.attention.output.LayerNorm.weight', 'encoder.layer.18.attention.output.LayerNorm.bias', 'encoder.layer.20.output.dense.weight', 'encoder.layer.2.attention.self.value.bias', 'encoder.layer.20.attention.output.dense.weight', 'encoder.layer.23.attention.output.dense.weight', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.7.attention.self.query.bias', 'encoder.layer.9.attention.output.dense.weight', 'encoder.layer.7.attention.self.key.weight', 'encoder.layer.16.output.dense.bias', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.22.output.dense.weight', 'encoder.layer.5.attention.self.key.bias', 'encoder.layer.2.output.dense.weight', 'encoder.layer.15.attention.self.query.weight', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.21.intermediate.dense.weight', 'encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.layer.1.output.dense.bias', 'encoder.layer.15.output.dense.weight', 'encoder.layer.9.output.dense.bias', 'encoder.layer.17.attention.output.dense.bias', 'encoder.layer.16.attention.self.query.weight', 'encoder.layer.4.attention.self.query.weight', 'encoder.layer.4.attention.output.dense.weight', 'encoder.layer.10.attention.self.key.bias', 'encoder.layer.11.attention.self.query.weight', 'encoder.layer.22.intermediate.dense.bias', 'encoder.layer.19.attention.output.LayerNorm.weight', 'encoder.layer.7.output.LayerNorm.weight', 'encoder.layer.21.attention.self.query.weight', 'encoder.layer.14.output.LayerNorm.bias', 'encoder.layer.2.attention.output.LayerNorm.bias', 'encoder.layer.16.output.LayerNorm.bias', 'encoder.layer.11.attention.output.dense.weight', 'encoder.layer.8.attention.self.key.weight', 'encoder.layer.14.attention.self.query.bias', 'encoder.layer.0.attention.self.query.bias', 'encoder.layer.7.attention.self.query.weight', 'encoder.layer.18.attention.self.query.bias', 'encoder.layer.20.attention.self.query.bias', 'encoder.layer.22.attention.self.value.bias', 'encoder.layer.11.attention.self.query.bias', 'encoder.layer.17.output.dense.bias', 'encoder.layer.5.attention.self.value.weight', 'encoder.layer.12.attention.self.query.bias', 'encoder.layer.16.output.LayerNorm.weight', 'encoder.layer.6.attention.self.key.weight', 'encoder.layer.23.intermediate.dense.bias', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.0.output.dense.weight', 'encoder.layer.9.output.LayerNorm.bias', 'encoder.layer.17.attention.self.value.bias', 'encoder.layer.10.output.dense.weight', 'encoder.layer.1.attention.output.LayerNorm.weight', 'encoder.layer.19.attention.output.dense.weight', 'encoder.layer.5.attention.self.query.weight', 'encoder.layer.20.attention.output.LayerNorm.bias', 'encoder.layer.22.attention.output.dense.bias', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.3.attention.self.query.weight', 'encoder.layer.17.intermediate.dense.weight', 'encoder.layer.19.intermediate.dense.weight', 'encoder.layer.7.attention.self.key.bias', 'encoder.layer.20.output.LayerNorm.weight', 'encoder.layer.5.output.LayerNorm.bias', 'encoder.layer.20.attention.self.key.weight', 'encoder.layer.13.attention.self.query.bias', 'encoder.layer.17.attention.output.dense.weight', 'encoder.layer.13.attention.output.dense.bias', 'embeddings.position_embeddings.weight', 'encoder.layer.19.attention.self.query.weight', 'encoder.layer.10.attention.self.query.weight', 'encoder.layer.4.attention.self.value.weight', 'encoder.layer.19.attention.self.key.bias', 'encoder.layer.20.attention.output.dense.bias', 'encoder.layer.13.attention.self.key.bias', 'pooler.dense.bias', 'encoder.layer.9.attention.self.value.weight', 'encoder.layer.14.intermediate.dense.weight', 'encoder.layer.18.intermediate.dense.weight', 'encoder.layer.16.attention.self.value.weight', 'encoder.layer.23.attention.self.value.bias', 'encoder.layer.16.attention.output.dense.weight', 'embeddings.LayerNorm.weight', 'encoder.layer.7.attention.output.dense.weight', 'encoder.layer.12.output.LayerNorm.weight', 'encoder.layer.9.attention.output.LayerNorm.bias', 'encoder.layer.18.attention.self.value.weight', 'encoder.layer.20.output.dense.bias', 'encoder.layer.23.intermediate.dense.weight', 'encoder.layer.22.output.LayerNorm.bias', 'encoder.layer.21.attention.output.dense.bias', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.17.intermediate.dense.bias', 'encoder.layer.5.attention.output.LayerNorm.weight', 'encoder.layer.3.attention.output.dense.bias', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.12.attention.output.LayerNorm.weight', 'encoder.layer.6.attention.self.query.weight', 'encoder.layer.8.attention.self.key.bias', 'encoder.layer.10.attention.output.LayerNorm.weight', 'encoder.layer.0.attention.output.dense.bias', 'encoder.layer.7.output.LayerNorm.bias', 'encoder.layer.23.attention.output.LayerNorm.weight', 'encoder.layer.0.output.dense.bias', 'encoder.layer.1.attention.self.value.bias', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.12.attention.self.key.bias', 'encoder.layer.21.attention.self.key.weight', 'encoder.layer.15.output.LayerNorm.weight', 'encoder.layer.10.attention.output.LayerNorm.bias', 'encoder.layer.10.output.dense.bias', 'encoder.layer.13.attention.output.LayerNorm.bias', 'encoder.layer.10.attention.self.key.weight', 'encoder.layer.14.attention.self.query.weight', 'encoder.layer.2.attention.self.key.bias', 'encoder.layer.14.intermediate.dense.bias', 'encoder.layer.15.output.LayerNorm.bias', 'encoder.layer.6.attention.self.query.bias', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.0.attention.self.key.bias', 'encoder.layer.8.attention.output.LayerNorm.weight', 'encoder.layer.23.output.LayerNorm.bias', 'encoder.layer.2.attention.output.dense.weight', 'encoder.layer.1.output.dense.weight', 'encoder.layer.12.attention.self.key.weight', 'encoder.layer.4.output.dense.bias', 'encoder.layer.10.output.LayerNorm.weight', 'encoder.layer.23.attention.self.key.bias', 'encoder.layer.18.attention.self.value.bias', 'encoder.layer.0.attention.output.LayerNorm.weight', 'encoder.layer.2.output.dense.bias', 'encoder.layer.7.attention.output.LayerNorm.weight', 'encoder.layer.16.attention.output.LayerNorm.bias', 'encoder.layer.16.intermediate.dense.weight', 'encoder.layer.13.output.dense.weight', 'embeddings.LayerNorm.bias', 'encoder.layer.23.attention.self.query.bias', 'encoder.layer.21.attention.output.LayerNorm.weight', 'encoder.layer.11.attention.output.dense.bias', 'encoder.layer.20.attention.self.value.bias', 'encoder.layer.11.attention.self.key.weight', 'encoder.layer.16.attention.self.query.bias', 'encoder.layer.17.attention.output.LayerNorm.bias', 'encoder.layer.9.attention.output.LayerNorm.weight', 'encoder.layer.19.output.LayerNorm.weight', 'encoder.layer.2.attention.self.key.weight', 'encoder.layer.22.attention.self.value.weight', 'encoder.layer.3.attention.self.key.bias', 'encoder.layer.0.attention.self.value.bias', 'encoder.layer.20.intermediate.dense.weight', 'encoder.layer.9.attention.self.value.bias', 'encoder.layer.15.attention.output.dense.bias', 'encoder.layer.21.intermediate.dense.bias', 'encoder.layer.2.attention.self.query.weight', 'encoder.layer.19.attention.output.dense.bias', 'encoder.layer.13.attention.output.dense.weight', 'encoder.layer.4.attention.output.LayerNorm.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Overwriting existing adapter 'ep'.
Overwriting existing adapter 'tp'.
Overwriting existing adapter 'es'.
Overwriting existing adapter 'ts'.
Overwriting existing adapter fusion module 'ep,tp,es,ts'
05/09/2022 20:11:38 - INFO - __main__ -   Creating features from dataset file at .
/cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//squad/xlm-KG_LR4e-5_EPOCH2.0_maxlen384_batchsize4_gradacc8
XLMConfig {
  "architectures": [
    "XLMRobertaForMaskedLM"
  ],
  "asm": false,
  "attention_dropout": 0.1,
  "attention_probs_dropout_prob": 0.1,
  "bos_index": 0,
  "bos_token_id": 0,
  "causal": false,
  "dropout": 0.1,
  "emb_dim": 1024,
  "embed_init_std": 0.02209708691207961,
  "end_n_top": 5,
  "eos_index": 1,
  "eos_token_id": 2,
  "gelu_activation": true,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "init_std": 0.02,
  "initializer_range": 0.02,
  "intermediate_size": 4096,
  "is_encoder": true,
  "lang_id": 0,
  "layer_norm_eps": 1e-05,
  "mask_index": 5,
  "mask_token_id": 0,
  "max_position_embeddings": 514,
  "model_type": "xlm",
  "n_heads": 16,
  "n_langs": 1,
  "n_layers": 24,
  "output_past": true,
  "pad_index": 2,
  "pad_token_id": 1,
  "sinusoidal_embeddings": false,
  "start_n_top": 5,
  "summary_activation": null,
  "summary_first_dropout": 0.1,
  "summary_proj_to_labels": true,
  "summary_type": "first",
  "summary_use_proj": true,
  "transformers_version": "4.17.0",
  "type_vocab_size": 1,
  "unk_index": 3,
  "use_lang_emb": false,
  "vocab_size": 250002
}

  0%|          | 0/48 [00:00<?, ?it/s] 29%|██▉       | 14/48 [00:00<00:00, 132.45it/s] 58%|█████▊    | 28/48 [00:00<00:00, 100.69it/s] 83%|████████▎ | 40/48 [00:00<00:00, 106.25it/s]100%|██████████| 48/48 [00:00<00:00, 111.28it/s]
convert squad examples to features:   0%|          | 0/1190 [00:00<?, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.
convert squad examples to features:   0%|          | 1/1190 [00:00<02:46,  7.14it/s]convert squad examples to features:   5%|▌         | 65/1190 [00:00<00:04, 255.99it/s]convert squad examples to features:  11%|█         | 129/1190 [00:00<00:03, 350.80it/s]convert squad examples to features:  16%|█▌        | 193/1190 [00:00<00:02, 402.89it/s]convert squad examples to features:  22%|██▏       | 257/1190 [00:00<00:02, 402.81it/s]convert squad examples to features:  27%|██▋       | 321/1190 [00:00<00:02, 379.91it/s]convert squad examples to features:  32%|███▏      | 385/1190 [00:01<00:02, 270.03it/s]convert squad examples to features:  35%|███▌      | 417/1190 [00:01<00:02, 274.78it/s]convert squad examples to features:  38%|███▊      | 449/1190 [00:01<00:02, 283.04it/s]convert squad examples to features:  40%|████      | 481/1190 [00:01<00:02, 290.81it/s]convert squad examples to features:  46%|████▌     | 545/1190 [00:01<00:02, 271.94it/s]convert squad examples to features:  51%|█████     | 609/1190 [00:02<00:02, 278.72it/s]convert squad examples to features:  54%|█████▍    | 641/1190 [00:02<00:01, 282.93it/s]convert squad examples to features:  57%|█████▋    | 673/1190 [00:02<00:01, 278.20it/s]convert squad examples to features:  62%|██████▏   | 737/1190 [00:02<00:01, 311.59it/s]convert squad examples to features:  67%|██████▋   | 801/1190 [00:02<00:01, 312.73it/s]convert squad examples to features:  70%|███████   | 833/1190 [00:02<00:01, 281.12it/s]convert squad examples to features:  75%|███████▌  | 897/1190 [00:03<00:00, 296.28it/s]convert squad examples to features:  78%|███████▊  | 929/1190 [00:03<00:00, 268.73it/s]convert squad examples to features:  81%|████████  | 961/1190 [00:03<00:00, 268.56it/s]convert squad examples to features:  86%|████████▌ | 1025/1190 [00:03<00:00, 325.10it/s]convert squad examples to features:  92%|█████████▏| 1089/1190 [00:03<00:00, 342.87it/s]convert squad examples to features:  94%|█████████▍| 1124/1190 [00:03<00:00, 314.98it/s]convert squad examples to features:  97%|█████████▋| 1156/1190 [00:03<00:00, 284.23it/s]convert squad examples to features: 100%|██████████| 1190/1190 [00:03<00:00, 304.38it/s]
add example index and unique id:   0%|          | 0/1190 [00:00<?, ?it/s]add example index and unique id: 100%|██████████| 1190/1190 [00:00<00:00, 448367.03it/s]
05/09/2022 20:11:43 - INFO - __main__ -   Saving features into cached file ./cached_xquad.th.json_xlm-KG_LR4e-5_EPOCH2.0_maxlen384_batchsize4_gradacc8_384_th
05/09/2022 20:11:44 - INFO - __main__ -   ***** Running evaluation  *****
05/09/2022 20:11:44 - INFO - __main__ -     Num examples = 1314
05/09/2022 20:11:44 - INFO - __main__ -     Batch size = 8
Evaluating:   0%|          | 0/165 [00:00<?, ?it/s]Evaluating:   1%|          | 1/165 [00:00<02:21,  1.16it/s]Evaluating:   1%|          | 2/165 [00:01<01:32,  1.76it/s]Evaluating:   2%|▏         | 3/165 [00:01<01:16,  2.12it/s]Evaluating:   2%|▏         | 4/165 [00:01<01:08,  2.34it/s]Evaluating:   3%|▎         | 5/165 [00:02<01:04,  2.48it/s]Evaluating:   4%|▎         | 6/165 [00:02<01:01,  2.58it/s]Evaluating:   4%|▍         | 7/165 [00:03<00:59,  2.66it/s]Evaluating:   5%|▍         | 8/165 [00:03<00:58,  2.70it/s]Evaluating:   5%|▌         | 9/165 [00:03<00:56,  2.74it/s]Evaluating:   6%|▌         | 10/165 [00:04<00:56,  2.76it/s]Evaluating:   7%|▋         | 11/165 [00:04<00:55,  2.77it/s]Evaluating:   7%|▋         | 12/165 [00:04<00:55,  2.76it/s]Evaluating:   8%|▊         | 13/165 [00:05<00:54,  2.78it/s]Evaluating:   8%|▊         | 14/165 [00:05<00:54,  2.79it/s]Evaluating:   9%|▉         | 15/165 [00:05<00:53,  2.79it/s]Evaluating:  10%|▉         | 16/165 [00:06<00:53,  2.80it/s]Evaluating:  10%|█         | 17/165 [00:06<00:52,  2.80it/s]Evaluating:  11%|█         | 18/165 [00:06<00:52,  2.80it/s]Evaluating:  12%|█▏        | 19/165 [00:07<00:52,  2.81it/s]Evaluating:  12%|█▏        | 20/165 [00:07<00:51,  2.81it/s]Evaluating:  13%|█▎        | 21/165 [00:08<00:51,  2.80it/s]Evaluating:  13%|█▎        | 22/165 [00:08<00:51,  2.80it/s]Evaluating:  14%|█▍        | 23/165 [00:08<00:50,  2.81it/s]Evaluating:  15%|█▍        | 24/165 [00:09<00:51,  2.74it/s]Evaluating:  15%|█▌        | 25/165 [00:09<00:50,  2.77it/s]Evaluating:  16%|█▌        | 26/165 [00:09<00:50,  2.77it/s]Evaluating:  16%|█▋        | 27/165 [00:10<00:49,  2.78it/s]Evaluating:  17%|█▋        | 28/165 [00:10<00:49,  2.78it/s]Evaluating:  18%|█▊        | 29/165 [00:10<00:48,  2.79it/s]Evaluating:  18%|█▊        | 30/165 [00:11<00:48,  2.79it/s]Evaluating:  19%|█▉        | 31/165 [00:11<00:47,  2.80it/s]Evaluating:  19%|█▉        | 32/165 [00:11<00:47,  2.79it/s]Evaluating:  20%|██        | 33/165 [00:12<00:47,  2.80it/s]Evaluating:  21%|██        | 34/165 [00:12<00:46,  2.80it/s]Evaluating:  21%|██        | 35/165 [00:13<00:46,  2.80it/s]Evaluating:  22%|██▏       | 36/165 [00:13<00:46,  2.79it/s]Evaluating:  22%|██▏       | 37/165 [00:13<00:45,  2.80it/s]Evaluating:  23%|██▎       | 38/165 [00:14<00:45,  2.77it/s]Evaluating:  24%|██▎       | 39/165 [00:14<00:46,  2.74it/s]Evaluating:  24%|██▍       | 40/165 [00:14<00:46,  2.66it/s]Evaluating:  25%|██▍       | 41/165 [00:15<00:48,  2.57it/s]Evaluating:  25%|██▌       | 42/165 [00:15<00:46,  2.62it/s]Evaluating:  26%|██▌       | 43/165 [00:16<00:47,  2.58it/s]Evaluating:  27%|██▋       | 44/165 [00:16<00:46,  2.62it/s]Evaluating:  27%|██▋       | 45/165 [00:16<00:46,  2.56it/s]Evaluating:  28%|██▊       | 46/165 [00:17<00:48,  2.43it/s]Evaluating:  28%|██▊       | 47/165 [00:17<00:48,  2.45it/s]Evaluating:  29%|██▉       | 48/165 [00:18<00:47,  2.46it/s]Evaluating:  30%|██▉       | 49/165 [00:18<00:48,  2.41it/s]Evaluating:  30%|███       | 50/165 [00:18<00:46,  2.50it/s]Evaluating:  31%|███       | 51/165 [00:19<00:44,  2.55it/s]Evaluating:  32%|███▏      | 52/165 [00:19<00:43,  2.60it/s]Evaluating:  32%|███▏      | 53/165 [00:20<00:42,  2.62it/s]Evaluating:  33%|███▎      | 54/165 [00:20<00:43,  2.54it/s]Evaluating:  33%|███▎      | 55/165 [00:20<00:42,  2.56it/s]Evaluating:  34%|███▍      | 56/165 [00:21<00:42,  2.58it/s]Evaluating:  35%|███▍      | 57/165 [00:21<00:40,  2.64it/s]Evaluating:  35%|███▌      | 58/165 [00:21<00:39,  2.68it/s]Evaluating:  36%|███▌      | 59/165 [00:22<00:39,  2.70it/s]Evaluating:  36%|███▋      | 60/165 [00:22<00:38,  2.72it/s]Evaluating:  37%|███▋      | 61/165 [00:23<00:37,  2.74it/s]Evaluating:  38%|███▊      | 62/165 [00:23<00:38,  2.66it/s]Evaluating:  38%|███▊      | 63/165 [00:23<00:39,  2.57it/s]Evaluating:  39%|███▉      | 64/165 [00:24<00:41,  2.43it/s]Evaluating:  39%|███▉      | 65/165 [00:24<00:41,  2.43it/s]Evaluating:  40%|████      | 66/165 [00:25<00:39,  2.49it/s]Evaluating:  41%|████      | 67/165 [00:25<00:38,  2.57it/s]Evaluating:  41%|████      | 68/165 [00:25<00:36,  2.63it/s]Evaluating:  42%|████▏     | 69/165 [00:26<00:36,  2.61it/s]Evaluating:  42%|████▏     | 70/165 [00:26<00:36,  2.61it/s]Evaluating:  43%|████▎     | 71/165 [00:27<00:37,  2.53it/s]Evaluating:  44%|████▎     | 72/165 [00:27<00:36,  2.57it/s]Evaluating:  44%|████▍     | 73/165 [00:27<00:35,  2.59it/s]Evaluating:  45%|████▍     | 74/165 [00:28<00:36,  2.50it/s]Evaluating:  45%|████▌     | 75/165 [00:28<00:37,  2.37it/s]Evaluating:  46%|████▌     | 76/165 [00:29<00:37,  2.35it/s]Evaluating:  47%|████▋     | 77/165 [00:29<00:36,  2.40it/s]Evaluating:  47%|████▋     | 78/165 [00:29<00:35,  2.48it/s]Evaluating:  48%|████▊     | 79/165 [00:30<00:33,  2.56it/s]Evaluating:  48%|████▊     | 80/165 [00:30<00:32,  2.58it/s]Evaluating:  49%|████▉     | 81/165 [00:30<00:31,  2.64it/s]Evaluating:  50%|████▉     | 82/165 [00:31<00:31,  2.63it/s]Evaluating:  50%|█████     | 83/165 [00:31<00:31,  2.57it/s]Evaluating:  51%|█████     | 84/165 [00:32<00:30,  2.62it/s]Evaluating:  52%|█████▏    | 85/165 [00:32<00:30,  2.66it/s]Evaluating:  52%|█████▏    | 86/165 [00:32<00:29,  2.67it/s]Evaluating:  53%|█████▎    | 87/165 [00:33<00:29,  2.64it/s]Evaluating:  53%|█████▎    | 88/165 [00:33<00:28,  2.69it/s]Evaluating:  54%|█████▍    | 89/165 [00:33<00:28,  2.70it/s]Evaluating:  55%|█████▍    | 90/165 [00:34<00:28,  2.59it/s]Evaluating:  55%|█████▌    | 91/165 [00:34<00:29,  2.52it/s]Evaluating:  56%|█████▌    | 92/165 [00:35<00:28,  2.56it/s]Evaluating:  56%|█████▋    | 93/165 [00:35<00:29,  2.43it/s]Evaluating:  57%|█████▋    | 94/165 [00:36<00:29,  2.44it/s]Evaluating:  58%|█████▊    | 95/165 [00:36<00:28,  2.44it/s]Evaluating:  58%|█████▊    | 96/165 [00:36<00:27,  2.53it/s]Evaluating:  59%|█████▉    | 97/165 [00:37<00:26,  2.60it/s]Evaluating:  59%|█████▉    | 98/165 [00:37<00:25,  2.65it/s]Evaluating:  60%|██████    | 99/165 [00:37<00:24,  2.68it/s]Evaluating:  61%|██████    | 100/165 [00:38<00:24,  2.70it/s]Evaluating:  61%|██████    | 101/165 [00:38<00:23,  2.72it/s]Evaluating:  62%|██████▏   | 102/165 [00:39<00:22,  2.74it/s]Evaluating:  62%|██████▏   | 103/165 [00:39<00:22,  2.74it/s]Evaluating:  63%|██████▎   | 104/165 [00:39<00:22,  2.75it/s]Evaluating:  64%|██████▎   | 105/165 [00:40<00:21,  2.76it/s]Evaluating:  64%|██████▍   | 106/165 [00:40<00:21,  2.76it/s]Evaluating:  65%|██████▍   | 107/165 [00:40<00:21,  2.76it/s]Evaluating:  65%|██████▌   | 108/165 [00:41<00:20,  2.77it/s]Evaluating:  66%|██████▌   | 109/165 [00:41<00:20,  2.78it/s]Evaluating:  67%|██████▋   | 110/165 [00:41<00:19,  2.77it/s]Evaluating:  67%|██████▋   | 111/165 [00:42<00:19,  2.78it/s]Evaluating:  68%|██████▊   | 112/165 [00:42<00:19,  2.79it/s]Evaluating:  68%|██████▊   | 113/165 [00:42<00:18,  2.78it/s]Evaluating:  69%|██████▉   | 114/165 [00:43<00:18,  2.77it/s]Evaluating:  70%|██████▉   | 115/165 [00:43<00:18,  2.76it/s]Evaluating:  70%|███████   | 116/165 [00:44<00:17,  2.76it/s]Evaluating:  71%|███████   | 117/165 [00:44<00:17,  2.77it/s]Evaluating:  72%|███████▏  | 118/165 [00:44<00:16,  2.77it/s]Evaluating:  72%|███████▏  | 119/165 [00:45<00:16,  2.77it/s]Evaluating:  73%|███████▎  | 120/165 [00:45<00:16,  2.77it/s]Evaluating:  73%|███████▎  | 121/165 [00:45<00:15,  2.76it/s]Evaluating:  74%|███████▍  | 122/165 [00:46<00:15,  2.75it/s]Evaluating:  75%|███████▍  | 123/165 [00:46<00:15,  2.76it/s]Evaluating:  75%|███████▌  | 124/165 [00:46<00:14,  2.76it/s]Evaluating:  76%|███████▌  | 125/165 [00:47<00:14,  2.75it/s]Evaluating:  76%|███████▋  | 126/165 [00:47<00:14,  2.76it/s]Evaluating:  77%|███████▋  | 127/165 [00:48<00:13,  2.76it/s]Evaluating:  78%|███████▊  | 128/165 [00:48<00:13,  2.76it/s]Evaluating:  78%|███████▊  | 129/165 [00:48<00:13,  2.75it/s]Evaluating:  79%|███████▉  | 130/165 [00:49<00:12,  2.75it/s]Evaluating:  79%|███████▉  | 131/165 [00:49<00:12,  2.76it/s]Evaluating:  80%|████████  | 132/165 [00:49<00:11,  2.76it/s]Evaluating:  81%|████████  | 133/165 [00:50<00:11,  2.75it/s]Evaluating:  81%|████████  | 134/165 [00:50<00:11,  2.76it/s]Evaluating:  82%|████████▏ | 135/165 [00:50<00:10,  2.77it/s]Evaluating:  82%|████████▏ | 136/165 [00:51<00:10,  2.77it/s]Evaluating:  83%|████████▎ | 137/165 [00:51<00:10,  2.77it/s]Evaluating:  84%|████████▎ | 138/165 [00:52<00:09,  2.77it/s]Evaluating:  84%|████████▍ | 139/165 [00:52<00:09,  2.77it/s]Evaluating:  85%|████████▍ | 140/165 [00:52<00:08,  2.78it/s]Evaluating:  85%|████████▌ | 141/165 [00:53<00:08,  2.78it/s]Evaluating:  86%|████████▌ | 142/165 [00:53<00:08,  2.79it/s]Evaluating:  87%|████████▋ | 143/165 [00:53<00:07,  2.77it/s]Evaluating:  87%|████████▋ | 144/165 [00:54<00:07,  2.75it/s]Evaluating:  88%|████████▊ | 145/165 [00:54<00:07,  2.76it/s]Evaluating:  88%|████████▊ | 146/165 [00:54<00:06,  2.78it/s]Evaluating:  89%|████████▉ | 147/165 [00:55<00:06,  2.76it/s]Evaluating:  90%|████████▉ | 148/165 [00:55<00:06,  2.76it/s]Evaluating:  90%|█████████ | 149/165 [00:55<00:05,  2.77it/s]Evaluating:  91%|█████████ | 150/165 [00:56<00:05,  2.75it/s]Evaluating:  92%|█████████▏| 151/165 [00:56<00:05,  2.68it/s]Evaluating:  92%|█████████▏| 152/165 [00:57<00:04,  2.71it/s]Evaluating:  93%|█████████▎| 153/165 [00:57<00:04,  2.55it/s]Evaluating:  93%|█████████▎| 154/165 [00:58<00:04,  2.42it/s]Evaluating:  94%|█████████▍| 155/165 [00:58<00:04,  2.48it/s]Evaluating:  95%|█████████▍| 156/165 [00:58<00:03,  2.53it/s]Evaluating:  95%|█████████▌| 157/165 [00:59<00:03,  2.59it/s]Evaluating:  96%|█████████▌| 158/165 [00:59<00:02,  2.58it/s]Evaluating:  96%|█████████▋| 159/165 [00:59<00:02,  2.55it/s]Evaluating:  97%|█████████▋| 160/165 [01:00<00:01,  2.52it/s]Evaluating:  98%|█████████▊| 161/165 [01:00<00:01,  2.50it/s]Evaluating:  98%|█████████▊| 162/165 [01:01<00:01,  2.50it/s]Evaluating:  99%|█████████▉| 163/165 [01:01<00:00,  2.44it/s]Evaluating:  99%|█████████▉| 164/165 [01:02<00:00,  2.43it/s]Evaluating: 100%|██████████| 165/165 [01:02<00:00,  2.97it/s]Evaluating: 100%|██████████| 165/165 [01:02<00:00,  2.65it/s]
05/09/2022 20:12:46 - INFO - __main__ -     Evaluation done in total 62.173757 secs (0.047316 sec per example)
05/09/2022 20:12:55 - INFO - __main__ -   Results: {'exact': 61.51260504201681, 'f1': 72.23462018840164, 'total': 1190, 'HasAns_exact': 61.51260504201681, 'HasAns_f1': 72.23462018840164, 'HasAns_total': 1190, 'best_exact': 61.51260504201681, 'best_exact_thresh': 0.0, 'best_f1': 72.23462018840164, 'best_f1_thresh': 0.0}
  zh 
2022-05-09 20:13:02.320971: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0
05/09/2022 20:13:13 - WARNING - __main__ -   Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, 16-bits training: False
You are using a model of type xlm-roberta to instantiate a model of type xlm. This is not supported for all configurations of models and can yield errors.
Some weights of the model checkpoint at /cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//squad/xlm-KG_LR4e-5_EPOCH2.0_maxlen384_batchsize4_gradacc8 were not used when initializing XLMRobertaModel: ['base_model.encoder.layer.9.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.11.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.17.attention.output.LayerNorm.bias', 'base_model.encoder.layer.2.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.10.attention.output.dense.weight', 'base_model.encoder.layer.16.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.4.intermediate.dense.bias', 'base_model.encoder.layer.21.attention.output.dense.bias', 'base_model.encoder.layer.2.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.5.attention.output.dense.weight', 'base_model.encoder.layer.4.output.LayerNorm.bias', 'base_model.encoder.layer.4.output.dense.bias', 'base_model.encoder.layer.1.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.12.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.6.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.7.attention.output.dense.bias', 'base_model.encoder.layer.18.intermediate.dense.weight', 'base_model.encoder.layer.0.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.9.output.dense.bias', 'base_model.encoder.layer.2.attention.output.dense.weight', 'base_model.encoder.layer.10.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.15.attention.self.query.bias', 'base_model.encoder.layer.6.output.LayerNorm.weight', 'base_model.encoder.layer.18.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.10.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.20.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.23.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.13.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.14.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.21.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.3.output.dense.weight', 'base_model.encoder.layer.6.attention.self.value.weight', 'base_model.encoder.layer.13.attention.output.LayerNorm.bias', 'base_model.encoder.layer.15.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.16.intermediate.dense.weight', 'base_model.encoder.layer.18.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.18.attention.self.value.bias', 'base_model.encoder.layer.9.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.9.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.4.attention.self.key.weight', 'base_model.encoder.layer.14.attention.self.value.weight', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.21.attention.self.query.weight', 'base_model.encoder.layer.4.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.4.attention.output.dense.bias', 'base_model.encoder.layer.5.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.9.output.LayerNorm.bias', 'base_model.encoder.layer.16.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.22.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.17.intermediate.dense.bias', 'base_model.encoder.layer.22.output.dense.weight', 'base_model.encoder.layer.0.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.14.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.16.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.5.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.21.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.13.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.12.intermediate.dense.weight', 'base_model.encoder.layer.15.attention.output.LayerNorm.weight', 'base_model.encoder.layer.22.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.5.attention.output.dense.bias', 'base_model.encoder.layer.3.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.1.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.13.intermediate.dense.bias', 'base_model.encoder.layer.8.attention.output.LayerNorm.weight', 'base_model.encoder.layer.4.attention.output.LayerNorm.weight', 'base_model.encoder.layer.10.attention.self.value.bias', 'base_model.encoder.layer.14.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.2.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.11.intermediate.dense.weight', 'base_model.encoder.layer.12.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.18.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.16.attention.output.dense.bias', 'base_model.encoder.layer.10.attention.self.query.weight', 'base_model.encoder.layer.12.attention.output.dense.bias', 'base_model.encoder.layer.9.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.15.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.23.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.17.attention.self.value.bias', 'base_model.encoder.layer.18.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.18.attention.self.value.weight', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.6.attention.output.dense.weight', 'base_model.encoder.layer.19.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.20.intermediate.dense.weight', 'base_model.encoder.layer.21.attention.self.key.bias', 'base_model.encoder.layer.6.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.6.attention.self.key.weight', 'base_model.encoder.layer.6.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.12.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.18.attention.self.key.weight', 'base_model.encoder.layer.18.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.21.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.1.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.16.attention.self.value.weight', 'base_model.encoder.layer.12.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.2.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.15.intermediate.dense.weight', 'base_model.encoder.layer.20.output.dense.bias', 'base_model.encoder.layer.3.output.dense.bias', 'base_model.encoder.layer.7.intermediate.dense.bias', 'base_model.encoder.layer.20.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.22.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.10.output.LayerNorm.weight', 'base_model.encoder.layer.4.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.18.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.3.attention.output.LayerNorm.weight', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.14.output.LayerNorm.bias', 'base_model.encoder.layer.3.attention.self.query.bias', 'base_model.encoder.layer.10.attention.output.dense.bias', 'base_model.encoder.layer.5.intermediate.dense.bias', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.15.attention.self.key.bias', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.13.attention.self.query.bias', 'base_model.encoder.layer.22.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.0.attention.self.value.weight', 'base_model.encoder.layer.12.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.16.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.1.attention.self.value.weight', 'base_model.encoder.layer.9.attention.output.dense.weight', 'base_model.encoder.layer.5.attention.self.value.bias', 'base_model.encoder.layer.10.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.11.attention.self.value.weight', 'base_model.encoder.layer.11.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.15.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.10.output.LayerNorm.bias', 'base_model.encoder.layer.7.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.19.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'qa_outputs.weight', 'base_model.encoder.layer.6.output.dense.weight', 'base_model.encoder.layer.21.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.11.output.LayerNorm.weight', 'base_model.encoder.layer.19.intermediate.dense.weight', 'base_model.encoder.layer.15.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.15.attention.output.LayerNorm.bias', 'base_model.encoder.layer.12.output.LayerNorm.weight', 'base_model.encoder.layer.0.attention.self.query.bias', 'base_model.encoder.layer.2.attention.self.query.bias', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.6.output.dense.bias', 'base_model.encoder.layer.0.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.22.attention.self.query.weight', 'base_model.encoder.layer.22.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.12.attention.self.value.bias', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.4.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.5.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.6.attention.output.LayerNorm.bias', 'base_model.encoder.layer.10.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.11.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.23.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.11.output.dense.weight', 'base_model.encoder.layer.18.attention.self.query.bias', 'base_model.encoder.layer.21.output.dense.bias', 'base_model.encoder.layer.6.attention.self.value.bias', 'base_model.encoder.layer.18.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.17.intermediate.dense.weight', 'base_model.encoder.layer.1.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.5.output.dense.bias', 'base_model.encoder.layer.7.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.10.attention.output.LayerNorm.weight', 'base_model.encoder.layer.11.attention.self.key.bias', 'base_model.encoder.layer.14.output.LayerNorm.weight', 'base_model.encoder.layer.20.attention.self.value.bias', 'base_model.encoder.layer.2.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.5.attention.output.LayerNorm.weight', 'base_model.encoder.layer.15.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.7.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.20.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.10.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.19.attention.output.LayerNorm.weight', 'base_model.encoder.layer.14.attention.output.LayerNorm.bias', 'base_model.encoder.layer.8.output.dense.bias', 'base_model.encoder.layer.17.attention.output.dense.bias', 'base_model.encoder.layer.21.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.15.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.4.attention.self.value.bias', 'base_model.encoder.layer.19.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.3.intermediate.dense.bias', 'base_model.encoder.layer.3.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.19.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.19.attention.self.query.bias', 'base_model.encoder.layer.16.intermediate.dense.bias', 'base_model.encoder.layer.12.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.3.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.21.attention.output.dense.weight', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.11.attention.output.dense.bias', 'base_model.encoder.layer.17.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.19.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.13.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.20.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.23.output.LayerNorm.weight', 'base_model.encoder.layer.12.attention.output.LayerNorm.bias', 'base_model.encoder.layer.17.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.19.attention.self.key.weight', 'base_model.encoder.layer.5.attention.self.key.bias', 'base_model.encoder.layer.9.attention.self.key.bias', 'base_model.encoder.layer.21.output.LayerNorm.weight', 'base_model.embeddings.token_type_embeddings.weight', 'base_model.encoder.layer.7.attention.self.key.bias', 'base_model.encoder.layer.17.output.LayerNorm.weight', 'base_model.encoder.layer.9.attention.self.query.weight', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.21.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.2.output.dense.bias', 'base_model.encoder.layer.9.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.16.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.21.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.6.attention.output.LayerNorm.weight', 'base_model.encoder.layer.17.attention.self.value.weight', 'base_model.encoder.layer.23.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.8.output.dense.weight', 'base_model.encoder.layer.9.output.dense.weight', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.19.attention.self.query.weight', 'base_model.encoder.layer.23.intermediate.dense.weight', 'base_model.encoder.layer.18.output.dense.bias', 'base_model.encoder.layer.16.output.LayerNorm.weight', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.8.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.2.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.15.attention.self.value.bias', 'base_model.encoder.layer.17.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.20.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.18.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.4.attention.self.value.weight', 'base_model.encoder.layer.17.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.9.attention.output.LayerNorm.weight', 'base_model.encoder.layer.11.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.8.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.2.output.LayerNorm.weight', 'base_model.encoder.layer.21.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.20.output.dense.weight', 'base_model.encoder.layer.14.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.12.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.9.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.3.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.9.attention.self.value.bias', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.23.attention.self.key.weight', 'base_model.encoder.layer.10.attention.self.key.weight', 'base_model.encoder.layer.1.output.dense.bias', 'base_model.encoder.layer.10.attention.output.LayerNorm.bias', 'base_model.encoder.layer.2.output.adapters.tp.adapter_down.0.bias', 'qa_outputs.bias', 'base_model.encoder.layer.14.attention.self.value.bias', 'base_model.encoder.layer.13.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.2.attention.self.key.weight', 'base_model.encoder.layer.19.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.3.attention.self.key.weight', 'base_model.encoder.layer.11.attention.output.dense.weight', 'base_model.encoder.layer.21.output.dense.weight', 'base_model.encoder.layer.8.output.LayerNorm.weight', 'base_model.encoder.layer.16.attention.output.LayerNorm.bias', 'base_model.encoder.layer.3.attention.self.value.weight', 'base_model.encoder.layer.6.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.0.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.10.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.0.intermediate.dense.weight', 'base_model.encoder.layer.22.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.13.output.LayerNorm.weight', 'base_model.encoder.layer.7.attention.output.LayerNorm.bias', 'base_model.encoder.layer.19.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.15.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.20.output.LayerNorm.bias', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.22.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.20.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.5.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.11.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.22.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.14.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.20.attention.output.dense.bias', 'base_model.encoder.layer.10.attention.self.value.weight', 'base_model.encoder.layer.15.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.11.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.14.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.21.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.7.attention.output.dense.weight', 'base_model.encoder.layer.8.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.11.intermediate.dense.bias', 'base_model.encoder.layer.17.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.11.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.2.output.LayerNorm.bias', 'base_model.encoder.layer.8.attention.output.dense.bias', 'base_model.encoder.layer.19.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.21.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.13.attention.output.dense.bias', 'base_model.encoder.layer.20.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.7.attention.self.query.bias', 'base_model.encoder.layer.4.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.8.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.15.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.20.intermediate.dense.bias', 'base_model.encoder.layer.11.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.0.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.2.output.dense.weight', 'base_model.encoder.layer.8.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.19.attention.output.LayerNorm.bias', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.0.attention.output.LayerNorm.bias', 'base_model.encoder.layer.4.attention.output.dense.weight', 'base_model.encoder.layer.6.attention.output.dense.bias', 'base_model.encoder.layer.13.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.16.output.dense.weight', 'base_model.encoder.layer.5.output.dense.weight', 'base_model.encoder.layer.15.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.10.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.0.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.0.attention.self.value.bias', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.23.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.8.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.23.attention.self.query.bias', 'base_model.encoder.layer.3.output.LayerNorm.bias', 'base_model.encoder.layer.5.attention.output.LayerNorm.bias', 'base_model.encoder.layer.23.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.23.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.13.attention.output.dense.weight', 'base_model.encoder.layer.18.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.17.attention.self.query.bias', 'base_model.encoder.layer.16.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.21.attention.self.value.weight', 'base_model.encoder.layer.9.output.LayerNorm.weight', 'base_model.encoder.layer.21.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.15.attention.self.value.weight', 'base_model.encoder.layer.2.attention.self.value.bias', 'base_model.encoder.layer.4.attention.self.query.weight', 'base_model.encoder.layer.8.attention.self.value.bias', 'base_model.encoder.layer.7.output.dense.weight', 'base_model.encoder.layer.7.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.0.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.4.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.4.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.11.attention.output.LayerNorm.weight', 'base_model.encoder.layer.6.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.7.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.5.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.9.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.23.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.22.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.19.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.20.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.18.attention.output.LayerNorm.bias', 'base_model.pooler.dense.weight', 'base_model.encoder.layer.23.attention.self.query.weight', 'base_model.encoder.layer.11.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.21.attention.self.key.weight', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.7.attention.self.value.weight', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.3.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.3.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.9.attention.output.dense.bias', 'base_model.encoder.layer.5.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.6.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.16.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.22.attention.self.key.weight', 'base_model.encoder.layer.6.attention.self.key.bias', 'base_model.encoder.layer.8.attention.self.key.weight', 'base_model.encoder.layer.3.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.23.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.16.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.22.output.dense.bias', 'base_model.encoder.layer.20.attention.output.LayerNorm.weight', 'base_model.encoder.layer.15.attention.output.dense.bias', 'base_model.encoder.layer.0.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.12.output.dense.weight', 'base_model.encoder.layer.13.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.1.attention.output.LayerNorm.bias', 'base_model.encoder.layer.1.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.1.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.22.attention.output.dense.weight', 'base_model.encoder.layer.3.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.11.attention.output.LayerNorm.bias', 'base_model.encoder.layer.0.intermediate.dense.bias', 'base_model.encoder.layer.3.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.15.output.LayerNorm.bias', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.21.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.5.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.19.attention.self.key.bias', 'base_model.encoder.layer.2.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.19.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.16.attention.self.query.weight', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.2.intermediate.dense.weight', 'base_model.encoder.layer.19.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.9.attention.self.value.weight', 'base_model.encoder.layer.18.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.13.output.dense.bias', 'base_model.encoder.layer.6.attention.self.query.bias', 'base_model.encoder.layer.7.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.17.attention.output.dense.weight', 'base_model.encoder.layer.4.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.2.attention.output.dense.bias', 'base_model.encoder.layer.8.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.5.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.11.attention.self.key.weight', 'base_model.encoder.layer.14.attention.self.query.bias', 'base_model.encoder.layer.22.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.23.intermediate.dense.bias', 'base_model.encoder.layer.3.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.14.output.dense.bias', 'base_model.encoder.layer.16.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.19.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.23.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.23.attention.self.value.bias', 'base_model.encoder.layer.22.attention.output.LayerNorm.weight', 'base_model.encoder.layer.4.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.10.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.0.attention.self.query.weight', 'base_model.encoder.layer.12.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.23.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.3.attention.output.dense.bias', 'base_model.encoder.layer.14.attention.output.LayerNorm.weight', 'base_model.encoder.layer.14.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.19.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.14.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.1.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.10.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.21.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.20.attention.self.key.bias', 'base_model.encoder.layer.8.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.12.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.17.output.LayerNorm.bias', 'base_model.encoder.layer.16.attention.output.dense.weight', 'base_model.encoder.layer.4.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.8.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.7.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.7.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.19.attention.self.value.bias', 'base_model.encoder.layer.20.attention.self.key.weight', 'base_model.encoder.layer.17.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.20.attention.output.dense.weight', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.1.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.5.attention.self.value.weight', 'base_model.encoder.layer.18.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.17.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.12.attention.self.key.weight', 'base_model.encoder.layer.7.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.15.output.dense.bias', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.9.intermediate.dense.bias', 'base_model.encoder.layer.1.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.3.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.13.attention.self.value.bias', 'base_model.encoder.layer.17.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.17.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.20.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.21.attention.self.value.bias', 'base_model.encoder.layer.0.attention.output.dense.bias', 'base_model.encoder.layer.6.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.14.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.19.attention.output.dense.bias', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.23.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.2.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.1.attention.output.LayerNorm.weight', 'base_model.encoder.layer.22.attention.output.LayerNorm.bias', 'base_model.encoder.layer.7.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.1.attention.self.key.bias', 'base_model.encoder.layer.7.output.LayerNorm.weight', 'base_model.encoder.layer.10.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.17.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.4.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.3.attention.output.LayerNorm.bias', 'base_model.encoder.layer.4.attention.self.key.bias', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.1.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.21.output.LayerNorm.bias', 'base_model.encoder.layer.13.attention.self.query.weight', 'base_model.encoder.layer.23.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.19.intermediate.dense.bias', 'base_model.encoder.layer.16.attention.output.LayerNorm.weight', 'base_model.encoder.layer.8.attention.self.query.bias', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.17.attention.output.LayerNorm.weight', 'base_model.encoder.layer.22.intermediate.dense.weight', 'base_model.encoder.layer.3.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.6.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.12.attention.self.key.bias', 'base_model.encoder.layer.8.intermediate.dense.bias', 'base_model.encoder.layer.9.attention.self.key.weight', 'base_model.encoder.layer.11.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.18.output.LayerNorm.weight', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.22.output.LayerNorm.bias', 'base_model.encoder.layer.19.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.1.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.6.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.9.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.17.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.12.attention.output.dense.weight', 'base_model.encoder.layer.16.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.2.attention.self.query.weight', 'base_model.encoder.layer.12.intermediate.dense.bias', 'base_model.encoder.layer.21.attention.self.query.bias', 'base_model.encoder.layer.12.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.17.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.0.attention.self.key.weight', 'base_model.encoder.layer.9.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.3.attention.self.value.bias', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.7.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.0.attention.output.LayerNorm.weight', 'base_model.encoder.layer.0.output.LayerNorm.bias', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.19.output.LayerNorm.weight', 'base_model.encoder.layer.9.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.22.intermediate.dense.bias', 'base_model.encoder.layer.0.output.dense.weight', 'base_model.encoder.layer.22.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.6.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.16.attention.self.value.bias', 'base_model.encoder.layer.4.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.20.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.7.attention.self.value.bias', 'base_model.encoder.layer.15.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.23.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.15.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.10.intermediate.dense.weight', 'base_model.encoder.layer.6.intermediate.dense.bias', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.16.output.dense.bias', 'base_model.encoder.layer.23.output.dense.bias', 'base_model.encoder.layer.8.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.14.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.15.attention.output.dense.weight', 'base_model.encoder.layer.1.attention.self.query.weight', 'base_model.encoder.layer.13.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.10.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.15.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.18.attention.self.query.weight', 'base_model.encoder.layer.22.attention.self.value.bias', 'base_model.encoder.layer.23.output.dense.weight', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.0.output.dense.bias', 'base_model.encoder.layer.20.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.4.attention.self.query.bias', 'base_model.encoder.layer.1.attention.self.query.bias', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.12.attention.self.value.weight', 'base_model.encoder.layer.5.output.LayerNorm.bias', 'base_model.encoder.layer.11.attention.self.query.bias', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.22.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.17.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.4.intermediate.dense.weight', 'base_model.embeddings.position_embeddings.weight', 'base_model.encoder.layer.11.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.11.attention.self.value.bias', 'base_model.encoder.layer.4.output.LayerNorm.weight', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.4.output.dense.weight', 'base_model.encoder.layer.21.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.7.attention.self.key.weight', 'base_model.encoder.layer.9.attention.self.query.bias', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.22.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.8.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.8.attention.self.value.weight', 'base_model.encoder.layer.10.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.5.attention.self.key.weight', 'base_model.encoder.layer.2.attention.self.key.bias', 'base_model.encoder.layer.3.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.8.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.4.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.14.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.21.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.9.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.10.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.1.output.LayerNorm.bias', 'base_model.encoder.layer.6.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.2.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.13.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.6.output.LayerNorm.bias', 'base_model.encoder.layer.2.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.1.intermediate.dense.weight', 'base_model.encoder.layer.14.intermediate.dense.bias', 'base_model.encoder.layer.10.attention.self.query.bias', 'base_model.encoder.layer.12.output.dense.bias', 'base_model.encoder.layer.16.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.15.output.LayerNorm.weight', 'base_model.encoder.layer.9.intermediate.dense.weight', 'base_model.encoder.layer.19.attention.output.dense.weight', 'base_model.encoder.layer.10.output.dense.weight', 'base_model.encoder.layer.13.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.14.attention.output.dense.bias', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.0.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.11.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.14.intermediate.dense.weight', 'base_model.encoder.layer.7.output.dense.bias', 'base_model.encoder.layer.16.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.5.output.LayerNorm.weight', 'base_model.encoder.layer.5.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.5.intermediate.dense.weight', 'base_model.encoder.layer.12.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.18.output.dense.weight', 'base_model.encoder.layer.18.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.17.output.dense.bias', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.2.attention.output.LayerNorm.bias', 'base_model.encoder.layer.13.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.20.attention.self.query.bias', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.4.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.5.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.5.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.23.attention.output.dense.bias', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.17.attention.self.query.weight', 'base_model.encoder.layer.18.attention.self.key.bias', 'base_model.encoder.layer.18.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.13.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.13.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.3.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.15.output.dense.weight', 'base_model.encoder.layer.5.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.21.intermediate.dense.weight', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.2.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.9.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.16.attention.self.key.bias', 'base_model.encoder.layer.22.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.12.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.7.intermediate.dense.weight', 'base_model.encoder.layer.0.attention.self.key.bias', 'base_model.encoder.layer.9.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.11.attention.self.query.weight', 'base_model.encoder.layer.23.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.14.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.15.attention.self.key.weight', 'base_model.encoder.layer.6.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.17.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.13.attention.self.value.weight', 'base_model.encoder.layer.10.attention.self.key.bias', 'base_model.encoder.layer.8.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.3.output.LayerNorm.weight', 'base_model.pooler.dense.bias', 'base_model.encoder.layer.18.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.0.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.1.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.15.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.0.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.14.attention.self.key.weight', 'base_model.encoder.layer.21.intermediate.dense.bias', 'base_model.encoder.layer.22.attention.self.value.weight', 'base_model.encoder.layer.14.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.23.attention.output.LayerNorm.bias', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.6.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.8.attention.output.dense.weight', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.20.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.15.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.13.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.18.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.10.intermediate.dense.bias', 'base_model.encoder.layer.12.attention.output.LayerNorm.weight', 'base_model.encoder.layer.13.output.LayerNorm.bias', 'base_model.encoder.layer.21.output.adapters.ep.adapter_down.0.weight', 'base_model.embeddings.LayerNorm.weight', 'base_model.encoder.layer.17.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.19.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.3.attention.self.key.bias', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.6.intermediate.dense.weight', 'base_model.encoder.layer.3.intermediate.dense.weight', 'base_model.encoder.layer.9.attention.output.LayerNorm.bias', 'base_model.encoder.layer.13.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.19.attention.self.value.weight', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.8.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.18.attention.output.dense.bias', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.8.output.LayerNorm.bias', 'base_model.encoder.layer.23.attention.self.value.weight', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.12.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.16.attention.self.key.weight', 'base_model.encoder.layer.1.output.dense.weight', 'base_model.encoder.layer.17.output.dense.weight', 'base_model.encoder.layer.12.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.20.attention.self.query.weight', 'base_model.encoder.layer.11.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.19.output.dense.weight', 'base_model.embeddings.LayerNorm.bias', 'base_model.encoder.layer.0.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.8.attention.output.LayerNorm.bias', 'base_model.encoder.layer.1.attention.output.dense.bias', 'base_model.encoder.layer.14.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.2.attention.output.LayerNorm.weight', 'base_model.encoder.layer.14.output.dense.weight', 'base_model.encoder.layer.1.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.9.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.1.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.17.attention.self.key.bias', 'base_model.encoder.layer.22.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.1.attention.output.dense.weight', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.15.intermediate.dense.bias', 'base_model.encoder.layer.13.attention.self.key.bias', 'base_model.encoder.layer.6.attention.self.query.weight', 'base_model.encoder.layer.21.attention.output.LayerNorm.weight', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.14.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.8.intermediate.dense.weight', 'base_model.encoder.layer.17.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.18.output.adapters.ts.adapter_up.bias', 'base_model.embeddings.position_ids', 'base_model.encoder.layer.7.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.15.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.22.attention.self.key.bias', 'base_model.encoder.layer.22.attention.self.query.bias', 'base_model.encoder.layer.5.attention.self.query.bias', 'base_model.encoder.layer.6.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.0.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.0.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.2.intermediate.dense.bias', 'base_model.encoder.layer.18.intermediate.dense.bias', 'base_model.encoder.layer.23.output.LayerNorm.bias', 'base_model.encoder.layer.20.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.11.output.dense.bias', 'base_model.encoder.layer.10.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.8.attention.self.key.bias', 'base_model.encoder.layer.5.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.1.output.LayerNorm.weight', 'base_model.encoder.layer.12.attention.self.query.bias', 'base_model.encoder.layer.0.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.8.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.5.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.7.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.19.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.1.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.10.output.dense.bias', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.16.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.20.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.18.output.LayerNorm.bias', 'base_model.embeddings.word_embeddings.weight', 'base_model.encoder.layer.1.attention.self.key.weight', 'base_model.encoder.layer.5.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.7.attention.self.query.weight', 'base_model.encoder.layer.22.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.13.intermediate.dense.weight', 'base_model.encoder.layer.7.attention.output.LayerNorm.weight', 'base_model.encoder.layer.11.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.19.output.LayerNorm.bias', 'base_model.encoder.layer.6.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.18.attention.output.LayerNorm.weight', 'base_model.encoder.layer.4.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.20.output.LayerNorm.weight', 'base_model.encoder.layer.11.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.14.attention.self.query.weight', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.23.attention.self.key.bias', 'base_model.encoder.layer.3.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.9.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.9.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.10.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.13.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.13.attention.output.LayerNorm.weight', 'base_model.encoder.layer.3.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.15.attention.self.query.weight', 'base_model.encoder.layer.7.output.LayerNorm.bias', 'base_model.encoder.layer.6.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.3.attention.self.query.weight', 'base_model.encoder.layer.14.attention.output.dense.weight', 'base_model.encoder.layer.22.output.LayerNorm.weight', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.0.output.LayerNorm.weight', 'base_model.encoder.layer.11.output.LayerNorm.bias', 'base_model.encoder.layer.14.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.10.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.20.attention.output.LayerNorm.bias', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.2.attention.self.value.weight', 'base_model.encoder.layer.0.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.4.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.12.attention.self.query.weight', 'base_model.encoder.layer.2.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.16.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.2.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.19.output.dense.bias', 'base_model.encoder.layer.7.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.8.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.5.attention.self.query.weight', 'base_model.encoder.layer.3.attention.output.dense.weight', 'base_model.encoder.layer.2.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.12.output.LayerNorm.bias', 'base_model.encoder.layer.12.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.14.attention.self.key.bias', 'base_model.encoder.layer.1.attention.self.value.bias', 'base_model.encoder.layer.13.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.1.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.8.attention.self.query.weight', 'base_model.encoder.layer.20.attention.self.value.weight', 'base_model.encoder.layer.11.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.12.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.16.attention.self.query.bias', 'base_model.encoder.layer.23.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.4.attention.output.LayerNorm.bias', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.7.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.0.attention.output.dense.weight', 'base_model.encoder.layer.4.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.21.attention.output.LayerNorm.bias', 'base_model.encoder.layer.1.intermediate.dense.bias', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.2.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.13.attention.self.key.weight', 'base_model.encoder.layer.22.attention.output.dense.bias', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.5.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.16.output.LayerNorm.bias', 'base_model.encoder.layer.16.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.7.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.16.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.20.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.17.attention.self.key.weight', 'base_model.encoder.layer.20.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.13.output.dense.weight', 'base_model.encoder.layer.18.attention.output.dense.weight', 'base_model.encoder.layer.23.attention.output.dense.weight', 'base_model.encoder.layer.23.attention.output.LayerNorm.weight']
- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of XLMRobertaModel were not initialized from the model checkpoint at /cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//squad/xlm-KG_LR4e-5_EPOCH2.0_maxlen384_batchsize4_gradacc8 and are newly initialized: ['encoder.layer.5.attention.self.key.bias', 'encoder.layer.3.attention.self.query.bias', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.21.attention.output.dense.bias', 'encoder.layer.17.output.LayerNorm.weight', 'encoder.layer.11.output.dense.bias', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.10.output.LayerNorm.bias', 'encoder.layer.16.attention.output.dense.bias', 'encoder.layer.22.attention.self.value.weight', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.11.output.dense.weight', 'encoder.layer.9.attention.self.key.weight', 'encoder.layer.8.attention.output.dense.weight', 'encoder.layer.12.output.dense.bias', 'encoder.layer.12.output.dense.weight', 'encoder.layer.11.attention.output.dense.weight', 'encoder.layer.1.attention.self.query.weight', 'encoder.layer.22.attention.output.dense.weight', 'encoder.layer.12.intermediate.dense.weight', 'encoder.layer.16.attention.self.query.bias', 'encoder.layer.19.attention.output.LayerNorm.bias', 'encoder.layer.4.output.dense.bias', 'encoder.layer.8.attention.output.LayerNorm.bias', 'encoder.layer.15.attention.self.key.weight', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.18.attention.self.key.bias', 'encoder.layer.11.attention.self.key.weight', 'encoder.layer.15.output.LayerNorm.bias', 'encoder.layer.2.attention.self.key.weight', 'encoder.layer.18.output.dense.weight', 'encoder.layer.17.attention.output.dense.bias', 'encoder.layer.4.attention.self.key.weight', 'encoder.layer.12.intermediate.dense.bias', 'encoder.layer.15.output.dense.bias', 'encoder.layer.1.attention.output.dense.bias', 'encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.10.attention.self.query.weight', 'encoder.layer.22.attention.self.query.bias', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.7.attention.output.dense.weight', 'encoder.layer.23.attention.self.query.bias', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.3.attention.self.query.weight', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.9.attention.self.value.bias', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.10.attention.self.key.weight', 'encoder.layer.1.attention.self.query.bias', 'encoder.layer.11.output.LayerNorm.weight', 'encoder.layer.16.intermediate.dense.weight', 'encoder.layer.6.attention.self.key.weight', 'encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.layer.8.attention.self.key.bias', 'encoder.layer.20.attention.self.key.bias', 'encoder.layer.14.attention.output.LayerNorm.weight', 'encoder.layer.21.attention.self.query.bias', 'encoder.layer.22.attention.self.query.weight', 'encoder.layer.18.attention.self.value.weight', 'encoder.layer.5.output.dense.bias', 'encoder.layer.17.output.dense.bias', 'encoder.layer.2.attention.output.dense.bias', 'encoder.layer.14.attention.self.key.bias', 'encoder.layer.3.attention.self.key.weight', 'encoder.layer.15.attention.self.value.weight', 'encoder.layer.13.output.LayerNorm.bias', 'encoder.layer.10.attention.self.key.bias', 'encoder.layer.13.attention.output.LayerNorm.bias', 'encoder.layer.17.attention.self.query.bias', 'encoder.layer.2.output.dense.bias', 'encoder.layer.23.attention.output.LayerNorm.bias', 'encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.layer.16.output.dense.weight', 'encoder.layer.6.output.dense.bias', 'encoder.layer.14.attention.self.query.weight', 'encoder.layer.15.attention.self.query.bias', 'encoder.layer.6.attention.output.LayerNorm.weight', 'encoder.layer.21.output.LayerNorm.bias', 'encoder.layer.16.attention.output.LayerNorm.bias', 'encoder.layer.14.attention.output.dense.weight', 'encoder.layer.14.attention.self.key.weight', 'encoder.layer.4.attention.output.LayerNorm.bias', 'embeddings.LayerNorm.bias', 'encoder.layer.23.output.LayerNorm.bias', 'encoder.layer.4.attention.output.dense.bias', 'encoder.layer.8.attention.self.value.weight', 'encoder.layer.19.attention.output.LayerNorm.weight', 'encoder.layer.22.output.dense.bias', 'encoder.layer.22.intermediate.dense.weight', 'encoder.layer.17.attention.self.value.bias', 'encoder.layer.22.attention.self.key.weight', 'encoder.layer.15.attention.output.LayerNorm.weight', 'encoder.layer.15.attention.output.dense.bias', 'encoder.layer.16.attention.self.key.weight', 'encoder.layer.14.output.LayerNorm.weight', 'encoder.layer.13.attention.self.key.bias', 'encoder.layer.10.output.LayerNorm.weight', 'encoder.layer.18.attention.self.value.bias', 'encoder.layer.8.attention.self.key.weight', 'encoder.layer.20.output.dense.bias', 'encoder.layer.10.intermediate.dense.weight', 'encoder.layer.20.attention.output.dense.bias', 'encoder.layer.1.attention.self.key.bias', 'encoder.layer.7.attention.self.value.weight', 'encoder.layer.21.intermediate.dense.bias', 'encoder.layer.11.attention.output.dense.bias', 'encoder.layer.8.attention.output.dense.bias', 'encoder.layer.3.output.dense.weight', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.15.intermediate.dense.bias', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.2.output.dense.weight', 'encoder.layer.7.attention.output.dense.bias', 'encoder.layer.17.attention.self.value.weight', 'encoder.layer.4.attention.self.value.weight', 'encoder.layer.22.attention.self.key.bias', 'encoder.layer.15.attention.self.value.bias', 'encoder.layer.21.output.dense.bias', 'encoder.layer.6.attention.output.LayerNorm.bias', 'encoder.layer.20.output.LayerNorm.weight', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.16.intermediate.dense.bias', 'encoder.layer.6.attention.self.key.bias', 'encoder.layer.19.attention.output.dense.bias', 'encoder.layer.8.output.LayerNorm.bias', 'encoder.layer.6.attention.self.value.weight', 'encoder.layer.4.attention.self.key.bias', 'encoder.layer.5.attention.self.value.weight', 'encoder.layer.3.attention.output.dense.weight', 'encoder.layer.15.output.dense.weight', 'encoder.layer.12.attention.self.key.bias', 'encoder.layer.20.intermediate.dense.weight', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.6.attention.output.dense.weight', 'encoder.layer.20.attention.output.LayerNorm.bias', 'encoder.layer.22.attention.output.LayerNorm.bias', 'encoder.layer.18.attention.output.LayerNorm.bias', 'embeddings.position_embeddings.weight', 'encoder.layer.19.output.LayerNorm.bias', 'encoder.layer.19.attention.self.value.bias', 'encoder.layer.10.output.dense.bias', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.17.output.LayerNorm.bias', 'encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.17.output.dense.weight', 'encoder.layer.13.intermediate.dense.bias', 'encoder.layer.19.output.dense.bias', 'encoder.layer.14.intermediate.dense.bias', 'encoder.layer.18.output.LayerNorm.bias', 'encoder.layer.0.attention.self.value.bias', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.layer.13.attention.self.value.weight', 'encoder.layer.17.attention.self.query.weight', 'encoder.layer.19.output.dense.weight', 'encoder.layer.17.attention.output.LayerNorm.bias', 'encoder.layer.18.intermediate.dense.weight', 'encoder.layer.7.attention.output.LayerNorm.bias', 'encoder.layer.22.output.LayerNorm.bias', 'encoder.layer.0.output.dense.bias', 'encoder.layer.2.attention.self.key.bias', 'encoder.layer.4.attention.output.dense.weight', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.3.attention.self.value.weight', 'encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.layer.16.attention.self.query.weight', 'encoder.layer.5.output.LayerNorm.bias', 'encoder.layer.11.attention.output.LayerNorm.weight', 'encoder.layer.8.attention.self.query.weight', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.7.output.LayerNorm.weight', 'encoder.layer.17.attention.output.LayerNorm.weight', 'encoder.layer.12.output.LayerNorm.bias', 'encoder.layer.23.intermediate.dense.weight', 'encoder.layer.14.attention.self.query.bias', 'encoder.layer.19.attention.self.value.weight', 'encoder.layer.22.output.LayerNorm.weight', 'encoder.layer.7.attention.self.key.weight', 'encoder.layer.12.attention.output.dense.weight', 'encoder.layer.11.output.LayerNorm.bias', 'encoder.layer.19.attention.self.key.weight', 'encoder.layer.13.attention.self.query.weight', 'encoder.layer.23.output.dense.weight', 'encoder.layer.12.attention.self.value.bias', 'encoder.layer.0.attention.self.value.weight', 'encoder.layer.7.attention.output.LayerNorm.weight', 'encoder.layer.13.attention.self.value.bias', 'encoder.layer.5.attention.self.key.weight', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.9.attention.self.query.bias', 'encoder.layer.5.attention.output.dense.weight', 'encoder.layer.19.intermediate.dense.weight', 'encoder.layer.10.attention.output.dense.weight', 'encoder.layer.13.attention.output.dense.bias', 'encoder.layer.23.attention.output.LayerNorm.weight', 'encoder.layer.2.attention.output.LayerNorm.bias', 'encoder.layer.13.attention.self.key.weight', 'encoder.layer.23.output.dense.bias', 'encoder.layer.0.attention.self.query.weight', 'encoder.layer.8.output.dense.weight', 'encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.layer.18.attention.output.dense.weight', 'encoder.layer.12.attention.self.value.weight', 'encoder.layer.21.attention.self.key.weight', 'encoder.layer.7.output.dense.bias', 'encoder.layer.23.attention.output.dense.weight', 'encoder.layer.6.attention.output.dense.bias', 'encoder.layer.21.attention.self.value.weight', 'encoder.layer.18.output.dense.bias', 'embeddings.LayerNorm.weight', 'pooler.dense.weight', 'encoder.layer.21.output.dense.weight', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.21.attention.self.value.bias', 'encoder.layer.21.attention.output.LayerNorm.bias', 'encoder.layer.14.attention.self.value.weight', 'encoder.layer.20.attention.self.key.weight', 'encoder.layer.15.output.LayerNorm.weight', 'encoder.layer.0.attention.output.dense.bias', 'encoder.layer.12.attention.output.LayerNorm.bias', 'encoder.layer.12.output.LayerNorm.weight', 'encoder.layer.23.attention.output.dense.bias', 'encoder.layer.22.attention.output.dense.bias', 'encoder.layer.14.intermediate.dense.weight', 'encoder.layer.23.attention.self.key.bias', 'encoder.layer.4.attention.self.query.weight', 'encoder.layer.22.intermediate.dense.bias', 'encoder.layer.10.attention.output.dense.bias', 'encoder.layer.19.attention.self.query.bias', 'encoder.layer.1.output.dense.bias', 'encoder.layer.13.output.dense.bias', 'encoder.layer.13.intermediate.dense.weight', 'encoder.layer.10.attention.output.LayerNorm.bias', 'encoder.layer.20.attention.self.value.weight', 'encoder.layer.12.attention.self.query.bias', 'encoder.layer.21.attention.output.LayerNorm.weight', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.23.attention.self.query.weight', 'encoder.layer.8.output.LayerNorm.weight', 'encoder.layer.13.attention.self.query.bias', 'encoder.layer.14.output.dense.bias', 'encoder.layer.10.attention.self.value.bias', 'encoder.layer.16.output.LayerNorm.weight', 'encoder.layer.12.attention.self.query.weight', 'encoder.layer.9.output.dense.weight', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.7.attention.self.query.weight', 'encoder.layer.9.output.LayerNorm.weight', 'pooler.dense.bias', 'encoder.layer.23.output.LayerNorm.weight', 'encoder.layer.1.attention.output.dense.weight', 'encoder.layer.16.output.LayerNorm.bias', 'encoder.layer.0.attention.self.key.weight', 'encoder.layer.16.attention.self.key.bias', 'encoder.layer.21.attention.output.dense.weight', 'encoder.layer.14.attention.output.dense.bias', 'encoder.layer.2.attention.self.query.weight', 'encoder.layer.16.attention.output.dense.weight', 'encoder.layer.5.attention.output.dense.bias', 'encoder.layer.2.attention.self.value.weight', 'encoder.layer.9.attention.output.LayerNorm.bias', 'encoder.layer.12.attention.self.key.weight', 'encoder.layer.9.output.LayerNorm.bias', 'encoder.layer.21.output.LayerNorm.weight', 'encoder.layer.15.attention.output.LayerNorm.bias', 'encoder.layer.6.output.dense.weight', 'encoder.layer.21.attention.self.key.bias', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.6.attention.self.value.bias', 'encoder.layer.0.attention.output.LayerNorm.weight', 'encoder.layer.1.attention.self.key.weight', 'encoder.layer.21.attention.self.query.weight', 'encoder.layer.6.output.LayerNorm.bias', 'encoder.layer.12.attention.output.dense.bias', 'encoder.layer.8.output.dense.bias', 'encoder.layer.7.attention.self.key.bias', 'encoder.layer.6.attention.self.query.bias', 'encoder.layer.22.output.dense.weight', 'encoder.layer.20.attention.self.query.bias', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.3.output.dense.bias', 'encoder.layer.17.attention.self.key.weight', 'encoder.layer.17.attention.output.dense.weight', 'encoder.layer.5.output.dense.weight', 'encoder.layer.15.attention.output.dense.weight', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.2.attention.output.LayerNorm.weight', 'encoder.layer.9.attention.output.dense.weight', 'encoder.layer.8.attention.output.LayerNorm.weight', 'encoder.layer.3.attention.output.dense.bias', 'encoder.layer.16.attention.self.value.bias', 'encoder.layer.19.intermediate.dense.bias', 'encoder.layer.2.attention.self.value.bias', 'encoder.layer.1.attention.self.value.weight', 'encoder.layer.2.attention.self.query.bias', 'encoder.layer.11.attention.self.query.bias', 'encoder.layer.13.attention.output.dense.weight', 'encoder.layer.5.attention.self.query.weight', 'encoder.layer.17.attention.self.key.bias', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.10.attention.output.LayerNorm.weight', 'encoder.layer.18.attention.output.LayerNorm.weight', 'encoder.layer.3.attention.self.key.bias', 'encoder.layer.17.intermediate.dense.weight', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.2.attention.output.dense.weight', 'encoder.layer.19.attention.self.key.bias', 'encoder.layer.11.attention.self.key.bias', 'encoder.layer.7.attention.self.value.bias', 'encoder.layer.9.attention.self.value.weight', 'encoder.layer.20.attention.self.query.weight', 'encoder.layer.1.attention.output.LayerNorm.weight', 'encoder.layer.15.attention.self.query.weight', 'encoder.layer.20.output.LayerNorm.bias', 'encoder.layer.14.attention.output.LayerNorm.bias', 'encoder.layer.0.output.dense.weight', 'encoder.layer.8.attention.self.query.bias', 'encoder.layer.10.output.dense.weight', 'encoder.layer.18.attention.self.query.bias', 'encoder.layer.0.attention.self.query.bias', 'encoder.layer.13.output.dense.weight', 'encoder.layer.7.attention.self.query.bias', 'encoder.layer.18.attention.self.key.weight', 'encoder.layer.13.output.LayerNorm.weight', 'encoder.layer.5.attention.self.value.bias', 'encoder.layer.9.attention.output.dense.bias', 'encoder.layer.9.attention.self.key.bias', 'encoder.layer.11.attention.self.value.weight', 'encoder.layer.20.attention.output.LayerNorm.weight', 'embeddings.token_type_embeddings.weight', 'encoder.layer.7.intermediate.dense.bias', 'encoder.layer.20.output.dense.weight', 'encoder.layer.4.output.dense.weight', 'encoder.layer.4.attention.self.value.bias', 'encoder.layer.5.attention.self.query.bias', 'encoder.layer.16.output.dense.bias', 'encoder.layer.11.attention.self.query.weight', 'encoder.layer.23.attention.self.value.weight', 'encoder.layer.14.attention.self.value.bias', 'encoder.layer.4.attention.self.query.bias', 'encoder.layer.20.attention.self.value.bias', 'encoder.layer.23.intermediate.dense.bias', 'encoder.layer.19.output.LayerNorm.weight', 'encoder.layer.1.attention.self.value.bias', 'encoder.layer.6.attention.self.query.weight', 'encoder.layer.17.intermediate.dense.bias', 'encoder.layer.18.attention.self.query.weight', 'encoder.layer.22.attention.self.value.bias', 'encoder.layer.16.attention.self.value.weight', 'encoder.layer.9.output.dense.bias', 'encoder.layer.22.attention.output.LayerNorm.weight', 'encoder.layer.1.output.dense.weight', 'encoder.layer.9.attention.self.query.weight', 'encoder.layer.14.output.dense.weight', 'encoder.layer.9.attention.output.LayerNorm.weight', 'encoder.layer.7.output.dense.weight', 'encoder.layer.10.attention.self.query.bias', 'encoder.layer.20.attention.output.dense.weight', 'encoder.layer.16.attention.output.LayerNorm.weight', 'encoder.layer.23.attention.self.key.weight', 'encoder.layer.15.intermediate.dense.weight', 'encoder.layer.20.intermediate.dense.bias', 'encoder.layer.19.attention.self.query.weight', 'encoder.layer.4.attention.output.LayerNorm.weight', 'encoder.layer.0.attention.output.dense.weight', 'encoder.layer.19.attention.output.dense.weight', 'encoder.layer.23.attention.self.value.bias', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.8.attention.self.value.bias', 'encoder.layer.11.attention.self.value.bias', 'encoder.layer.13.attention.output.LayerNorm.weight', 'encoder.layer.14.output.LayerNorm.bias', 'encoder.layer.3.attention.self.value.bias', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.18.intermediate.dense.bias', 'encoder.layer.12.attention.output.LayerNorm.weight', 'encoder.layer.18.output.LayerNorm.weight', 'encoder.layer.7.output.LayerNorm.bias', 'encoder.layer.0.attention.self.key.bias', 'encoder.layer.5.attention.output.LayerNorm.weight', 'encoder.layer.21.intermediate.dense.weight', 'encoder.layer.18.attention.output.dense.bias', 'embeddings.word_embeddings.weight', 'encoder.layer.15.attention.self.key.bias', 'encoder.layer.10.attention.self.value.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Overwriting existing adapter 'ep'.
Overwriting existing adapter 'tp'.
Overwriting existing adapter 'es'.
Overwriting existing adapter 'ts'.
Overwriting existing adapter fusion module 'ep,tp,es,ts'
05/09/2022 20:13:47 - INFO - __main__ -   lang2id = None
05/09/2022 20:13:51 - INFO - __main__ -   Training/evaluation parameters Namespace(adam_epsilon=1e-08, cache_dir='', config_name='', data_dir=None, device=device(type='cuda'), do_eval=True, do_lower_case=False, do_train=False, doc_stride=128, eval_all_checkpoints=False, eval_lang='zh', evaluate_during_training=False, fp16=False, fp16_opt_level='O1', gradient_accumulation_steps=1, learning_rate=5e-05, local_rank=-1, logging_steps=50, max_answer_length=30, max_grad_norm=1.0, max_query_length=64, max_seq_length=384, max_steps=-1, model_name='xlm-KG', model_name_or_path='/cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//squad/xlm-KG_LR4e-5_EPOCH2.0_maxlen384_batchsize4_gradacc8', model_type='xlm', modelkg_dir='/cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/adapter/xlmr_adapter', n_best_size=20, n_gpu=1, no_cuda=False, null_score_diff_threshold=0.0, num_train_epochs=3.0, output_dir='/cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//squad/xlm-KG_LR4e-5_EPOCH2.0_maxlen384_batchsize4_gradacc8/predictions/xquad/', overwrite_cache=False, overwrite_output_dir=False, per_gpu_eval_batch_size=8, per_gpu_train_batch_size=8, predict_file='/cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/download//xquad//xquad.zh.json', save_steps=50, seed=42, server_ip='', server_port='', threads=1, tokenizer_name='', train_file=None, train_lang='en', verbose_logging=False, version_2_with_negative=False, warmup_steps=0, weight_decay=0.0)
05/09/2022 20:13:51 - INFO - __main__ -   Loading checkpoint /cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//squad/xlm-KG_LR4e-5_EPOCH2.0_maxlen384_batchsize4_gradacc8 for evaluation
05/09/2022 20:13:51 - INFO - __main__ -   Evaluate the following checkpoints: ['/cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//squad/xlm-KG_LR4e-5_EPOCH2.0_maxlen384_batchsize4_gradacc8']
Some weights of the model checkpoint at /cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//squad/xlm-KG_LR4e-5_EPOCH2.0_maxlen384_batchsize4_gradacc8 were not used when initializing XLMRobertaModel: ['base_model.encoder.layer.9.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.11.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.17.attention.output.LayerNorm.bias', 'base_model.encoder.layer.2.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.10.attention.output.dense.weight', 'base_model.encoder.layer.16.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.4.intermediate.dense.bias', 'base_model.encoder.layer.21.attention.output.dense.bias', 'base_model.encoder.layer.2.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.5.attention.output.dense.weight', 'base_model.encoder.layer.4.output.LayerNorm.bias', 'base_model.encoder.layer.4.output.dense.bias', 'base_model.encoder.layer.1.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.12.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.6.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.7.attention.output.dense.bias', 'base_model.encoder.layer.18.intermediate.dense.weight', 'base_model.encoder.layer.0.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.9.output.dense.bias', 'base_model.encoder.layer.2.attention.output.dense.weight', 'base_model.encoder.layer.10.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.15.attention.self.query.bias', 'base_model.encoder.layer.6.output.LayerNorm.weight', 'base_model.encoder.layer.18.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.10.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.20.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.23.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.13.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.14.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.21.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.3.output.dense.weight', 'base_model.encoder.layer.6.attention.self.value.weight', 'base_model.encoder.layer.13.attention.output.LayerNorm.bias', 'base_model.encoder.layer.15.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.16.intermediate.dense.weight', 'base_model.encoder.layer.18.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.18.attention.self.value.bias', 'base_model.encoder.layer.9.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.9.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.4.attention.self.key.weight', 'base_model.encoder.layer.14.attention.self.value.weight', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.21.attention.self.query.weight', 'base_model.encoder.layer.4.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.4.attention.output.dense.bias', 'base_model.encoder.layer.5.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.9.output.LayerNorm.bias', 'base_model.encoder.layer.16.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.22.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.17.intermediate.dense.bias', 'base_model.encoder.layer.22.output.dense.weight', 'base_model.encoder.layer.0.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.14.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.16.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.5.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.21.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.13.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.12.intermediate.dense.weight', 'base_model.encoder.layer.15.attention.output.LayerNorm.weight', 'base_model.encoder.layer.22.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.5.attention.output.dense.bias', 'base_model.encoder.layer.3.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.1.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.13.intermediate.dense.bias', 'base_model.encoder.layer.8.attention.output.LayerNorm.weight', 'base_model.encoder.layer.4.attention.output.LayerNorm.weight', 'base_model.encoder.layer.10.attention.self.value.bias', 'base_model.encoder.layer.14.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.2.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.11.intermediate.dense.weight', 'base_model.encoder.layer.12.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.18.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.16.attention.output.dense.bias', 'base_model.encoder.layer.10.attention.self.query.weight', 'base_model.encoder.layer.12.attention.output.dense.bias', 'base_model.encoder.layer.9.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.15.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.23.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.17.attention.self.value.bias', 'base_model.encoder.layer.18.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.18.attention.self.value.weight', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.6.attention.output.dense.weight', 'base_model.encoder.layer.19.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.20.intermediate.dense.weight', 'base_model.encoder.layer.21.attention.self.key.bias', 'base_model.encoder.layer.6.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.6.attention.self.key.weight', 'base_model.encoder.layer.6.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.12.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.18.attention.self.key.weight', 'base_model.encoder.layer.18.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.21.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.1.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.16.attention.self.value.weight', 'base_model.encoder.layer.12.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.2.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.15.intermediate.dense.weight', 'base_model.encoder.layer.20.output.dense.bias', 'base_model.encoder.layer.3.output.dense.bias', 'base_model.encoder.layer.7.intermediate.dense.bias', 'base_model.encoder.layer.20.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.22.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.10.output.LayerNorm.weight', 'base_model.encoder.layer.4.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.18.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.3.attention.output.LayerNorm.weight', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.14.output.LayerNorm.bias', 'base_model.encoder.layer.3.attention.self.query.bias', 'base_model.encoder.layer.10.attention.output.dense.bias', 'base_model.encoder.layer.5.intermediate.dense.bias', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.15.attention.self.key.bias', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.13.attention.self.query.bias', 'base_model.encoder.layer.22.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.0.attention.self.value.weight', 'base_model.encoder.layer.12.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.16.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.1.attention.self.value.weight', 'base_model.encoder.layer.9.attention.output.dense.weight', 'base_model.encoder.layer.5.attention.self.value.bias', 'base_model.encoder.layer.10.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.11.attention.self.value.weight', 'base_model.encoder.layer.11.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.15.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.10.output.LayerNorm.bias', 'base_model.encoder.layer.7.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.19.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'qa_outputs.weight', 'base_model.encoder.layer.6.output.dense.weight', 'base_model.encoder.layer.21.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.11.output.LayerNorm.weight', 'base_model.encoder.layer.19.intermediate.dense.weight', 'base_model.encoder.layer.15.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.15.attention.output.LayerNorm.bias', 'base_model.encoder.layer.12.output.LayerNorm.weight', 'base_model.encoder.layer.0.attention.self.query.bias', 'base_model.encoder.layer.2.attention.self.query.bias', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.6.output.dense.bias', 'base_model.encoder.layer.0.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.22.attention.self.query.weight', 'base_model.encoder.layer.22.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.12.attention.self.value.bias', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.4.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.5.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.6.attention.output.LayerNorm.bias', 'base_model.encoder.layer.10.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.11.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.23.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.11.output.dense.weight', 'base_model.encoder.layer.18.attention.self.query.bias', 'base_model.encoder.layer.21.output.dense.bias', 'base_model.encoder.layer.6.attention.self.value.bias', 'base_model.encoder.layer.18.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.17.intermediate.dense.weight', 'base_model.encoder.layer.1.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.5.output.dense.bias', 'base_model.encoder.layer.7.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.10.attention.output.LayerNorm.weight', 'base_model.encoder.layer.11.attention.self.key.bias', 'base_model.encoder.layer.14.output.LayerNorm.weight', 'base_model.encoder.layer.20.attention.self.value.bias', 'base_model.encoder.layer.2.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.5.attention.output.LayerNorm.weight', 'base_model.encoder.layer.15.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.7.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.20.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.10.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.19.attention.output.LayerNorm.weight', 'base_model.encoder.layer.14.attention.output.LayerNorm.bias', 'base_model.encoder.layer.8.output.dense.bias', 'base_model.encoder.layer.17.attention.output.dense.bias', 'base_model.encoder.layer.21.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.15.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.4.attention.self.value.bias', 'base_model.encoder.layer.19.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.3.intermediate.dense.bias', 'base_model.encoder.layer.3.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.19.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.19.attention.self.query.bias', 'base_model.encoder.layer.16.intermediate.dense.bias', 'base_model.encoder.layer.12.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.3.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.21.attention.output.dense.weight', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.11.attention.output.dense.bias', 'base_model.encoder.layer.17.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.19.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.13.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.20.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.23.output.LayerNorm.weight', 'base_model.encoder.layer.12.attention.output.LayerNorm.bias', 'base_model.encoder.layer.17.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.19.attention.self.key.weight', 'base_model.encoder.layer.5.attention.self.key.bias', 'base_model.encoder.layer.9.attention.self.key.bias', 'base_model.encoder.layer.21.output.LayerNorm.weight', 'base_model.embeddings.token_type_embeddings.weight', 'base_model.encoder.layer.7.attention.self.key.bias', 'base_model.encoder.layer.17.output.LayerNorm.weight', 'base_model.encoder.layer.9.attention.self.query.weight', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.21.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.2.output.dense.bias', 'base_model.encoder.layer.9.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.16.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.21.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.6.attention.output.LayerNorm.weight', 'base_model.encoder.layer.17.attention.self.value.weight', 'base_model.encoder.layer.23.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.8.output.dense.weight', 'base_model.encoder.layer.9.output.dense.weight', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.19.attention.self.query.weight', 'base_model.encoder.layer.23.intermediate.dense.weight', 'base_model.encoder.layer.18.output.dense.bias', 'base_model.encoder.layer.16.output.LayerNorm.weight', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.8.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.2.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.15.attention.self.value.bias', 'base_model.encoder.layer.17.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.20.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.18.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.4.attention.self.value.weight', 'base_model.encoder.layer.17.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.9.attention.output.LayerNorm.weight', 'base_model.encoder.layer.11.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.8.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.2.output.LayerNorm.weight', 'base_model.encoder.layer.21.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.20.output.dense.weight', 'base_model.encoder.layer.14.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.12.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.9.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.3.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.9.attention.self.value.bias', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.23.attention.self.key.weight', 'base_model.encoder.layer.10.attention.self.key.weight', 'base_model.encoder.layer.1.output.dense.bias', 'base_model.encoder.layer.10.attention.output.LayerNorm.bias', 'base_model.encoder.layer.2.output.adapters.tp.adapter_down.0.bias', 'qa_outputs.bias', 'base_model.encoder.layer.14.attention.self.value.bias', 'base_model.encoder.layer.13.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.2.attention.self.key.weight', 'base_model.encoder.layer.19.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.3.attention.self.key.weight', 'base_model.encoder.layer.11.attention.output.dense.weight', 'base_model.encoder.layer.21.output.dense.weight', 'base_model.encoder.layer.8.output.LayerNorm.weight', 'base_model.encoder.layer.16.attention.output.LayerNorm.bias', 'base_model.encoder.layer.3.attention.self.value.weight', 'base_model.encoder.layer.6.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.0.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.10.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.0.intermediate.dense.weight', 'base_model.encoder.layer.22.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.13.output.LayerNorm.weight', 'base_model.encoder.layer.7.attention.output.LayerNorm.bias', 'base_model.encoder.layer.19.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.15.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.20.output.LayerNorm.bias', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.22.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.20.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.5.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.11.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.22.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.14.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.20.attention.output.dense.bias', 'base_model.encoder.layer.10.attention.self.value.weight', 'base_model.encoder.layer.15.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.11.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.14.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.21.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.7.attention.output.dense.weight', 'base_model.encoder.layer.8.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.11.intermediate.dense.bias', 'base_model.encoder.layer.17.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.11.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.2.output.LayerNorm.bias', 'base_model.encoder.layer.8.attention.output.dense.bias', 'base_model.encoder.layer.19.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.21.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.13.attention.output.dense.bias', 'base_model.encoder.layer.20.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.7.attention.self.query.bias', 'base_model.encoder.layer.4.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.8.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.15.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.20.intermediate.dense.bias', 'base_model.encoder.layer.11.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.0.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.2.output.dense.weight', 'base_model.encoder.layer.8.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.19.attention.output.LayerNorm.bias', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.0.attention.output.LayerNorm.bias', 'base_model.encoder.layer.4.attention.output.dense.weight', 'base_model.encoder.layer.6.attention.output.dense.bias', 'base_model.encoder.layer.13.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.16.output.dense.weight', 'base_model.encoder.layer.5.output.dense.weight', 'base_model.encoder.layer.15.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.10.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.0.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.0.attention.self.value.bias', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.23.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.8.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.23.attention.self.query.bias', 'base_model.encoder.layer.3.output.LayerNorm.bias', 'base_model.encoder.layer.5.attention.output.LayerNorm.bias', 'base_model.encoder.layer.23.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.23.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.13.attention.output.dense.weight', 'base_model.encoder.layer.18.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.17.attention.self.query.bias', 'base_model.encoder.layer.16.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.21.attention.self.value.weight', 'base_model.encoder.layer.9.output.LayerNorm.weight', 'base_model.encoder.layer.21.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.15.attention.self.value.weight', 'base_model.encoder.layer.2.attention.self.value.bias', 'base_model.encoder.layer.4.attention.self.query.weight', 'base_model.encoder.layer.8.attention.self.value.bias', 'base_model.encoder.layer.7.output.dense.weight', 'base_model.encoder.layer.7.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.0.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.4.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.4.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.11.attention.output.LayerNorm.weight', 'base_model.encoder.layer.6.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.7.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.5.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.9.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.23.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.22.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.19.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.20.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.18.attention.output.LayerNorm.bias', 'base_model.pooler.dense.weight', 'base_model.encoder.layer.23.attention.self.query.weight', 'base_model.encoder.layer.11.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.21.attention.self.key.weight', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.7.attention.self.value.weight', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.3.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.3.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.9.attention.output.dense.bias', 'base_model.encoder.layer.5.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.6.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.16.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.22.attention.self.key.weight', 'base_model.encoder.layer.6.attention.self.key.bias', 'base_model.encoder.layer.8.attention.self.key.weight', 'base_model.encoder.layer.3.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.23.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.16.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.22.output.dense.bias', 'base_model.encoder.layer.20.attention.output.LayerNorm.weight', 'base_model.encoder.layer.15.attention.output.dense.bias', 'base_model.encoder.layer.0.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.12.output.dense.weight', 'base_model.encoder.layer.13.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.1.attention.output.LayerNorm.bias', 'base_model.encoder.layer.1.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.1.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.22.attention.output.dense.weight', 'base_model.encoder.layer.3.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.11.attention.output.LayerNorm.bias', 'base_model.encoder.layer.0.intermediate.dense.bias', 'base_model.encoder.layer.3.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.15.output.LayerNorm.bias', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.21.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.5.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.19.attention.self.key.bias', 'base_model.encoder.layer.2.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.19.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.16.attention.self.query.weight', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.2.intermediate.dense.weight', 'base_model.encoder.layer.19.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.9.attention.self.value.weight', 'base_model.encoder.layer.18.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.13.output.dense.bias', 'base_model.encoder.layer.6.attention.self.query.bias', 'base_model.encoder.layer.7.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.17.attention.output.dense.weight', 'base_model.encoder.layer.4.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.2.attention.output.dense.bias', 'base_model.encoder.layer.8.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.5.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.11.attention.self.key.weight', 'base_model.encoder.layer.14.attention.self.query.bias', 'base_model.encoder.layer.22.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.23.intermediate.dense.bias', 'base_model.encoder.layer.3.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.14.output.dense.bias', 'base_model.encoder.layer.16.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.19.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.23.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.23.attention.self.value.bias', 'base_model.encoder.layer.22.attention.output.LayerNorm.weight', 'base_model.encoder.layer.4.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.10.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.0.attention.self.query.weight', 'base_model.encoder.layer.12.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.23.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.3.attention.output.dense.bias', 'base_model.encoder.layer.14.attention.output.LayerNorm.weight', 'base_model.encoder.layer.14.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.19.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.14.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.1.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.10.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.21.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.20.attention.self.key.bias', 'base_model.encoder.layer.8.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.12.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.17.output.LayerNorm.bias', 'base_model.encoder.layer.16.attention.output.dense.weight', 'base_model.encoder.layer.4.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.8.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.7.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.7.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.19.attention.self.value.bias', 'base_model.encoder.layer.20.attention.self.key.weight', 'base_model.encoder.layer.17.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.20.attention.output.dense.weight', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.1.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.5.attention.self.value.weight', 'base_model.encoder.layer.18.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.17.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.12.attention.self.key.weight', 'base_model.encoder.layer.7.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.15.output.dense.bias', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.9.intermediate.dense.bias', 'base_model.encoder.layer.1.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.3.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.13.attention.self.value.bias', 'base_model.encoder.layer.17.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.17.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.20.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.21.attention.self.value.bias', 'base_model.encoder.layer.0.attention.output.dense.bias', 'base_model.encoder.layer.6.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.14.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.19.attention.output.dense.bias', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.23.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.2.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.1.attention.output.LayerNorm.weight', 'base_model.encoder.layer.22.attention.output.LayerNorm.bias', 'base_model.encoder.layer.7.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.1.attention.self.key.bias', 'base_model.encoder.layer.7.output.LayerNorm.weight', 'base_model.encoder.layer.10.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.17.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.4.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.3.attention.output.LayerNorm.bias', 'base_model.encoder.layer.4.attention.self.key.bias', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.1.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.21.output.LayerNorm.bias', 'base_model.encoder.layer.13.attention.self.query.weight', 'base_model.encoder.layer.23.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.19.intermediate.dense.bias', 'base_model.encoder.layer.16.attention.output.LayerNorm.weight', 'base_model.encoder.layer.8.attention.self.query.bias', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.17.attention.output.LayerNorm.weight', 'base_model.encoder.layer.22.intermediate.dense.weight', 'base_model.encoder.layer.3.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.6.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.12.attention.self.key.bias', 'base_model.encoder.layer.8.intermediate.dense.bias', 'base_model.encoder.layer.9.attention.self.key.weight', 'base_model.encoder.layer.11.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.18.output.LayerNorm.weight', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.22.output.LayerNorm.bias', 'base_model.encoder.layer.19.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.1.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.6.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.9.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.17.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.12.attention.output.dense.weight', 'base_model.encoder.layer.16.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.2.attention.self.query.weight', 'base_model.encoder.layer.12.intermediate.dense.bias', 'base_model.encoder.layer.21.attention.self.query.bias', 'base_model.encoder.layer.12.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.17.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.0.attention.self.key.weight', 'base_model.encoder.layer.9.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.3.attention.self.value.bias', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.7.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.0.attention.output.LayerNorm.weight', 'base_model.encoder.layer.0.output.LayerNorm.bias', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.19.output.LayerNorm.weight', 'base_model.encoder.layer.9.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.22.intermediate.dense.bias', 'base_model.encoder.layer.0.output.dense.weight', 'base_model.encoder.layer.22.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.6.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.16.attention.self.value.bias', 'base_model.encoder.layer.4.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.20.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.7.attention.self.value.bias', 'base_model.encoder.layer.15.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.23.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.15.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.10.intermediate.dense.weight', 'base_model.encoder.layer.6.intermediate.dense.bias', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.16.output.dense.bias', 'base_model.encoder.layer.23.output.dense.bias', 'base_model.encoder.layer.8.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.14.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.15.attention.output.dense.weight', 'base_model.encoder.layer.1.attention.self.query.weight', 'base_model.encoder.layer.13.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.10.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.15.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.18.attention.self.query.weight', 'base_model.encoder.layer.22.attention.self.value.bias', 'base_model.encoder.layer.23.output.dense.weight', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.0.output.dense.bias', 'base_model.encoder.layer.20.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.4.attention.self.query.bias', 'base_model.encoder.layer.1.attention.self.query.bias', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.12.attention.self.value.weight', 'base_model.encoder.layer.5.output.LayerNorm.bias', 'base_model.encoder.layer.11.attention.self.query.bias', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.22.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.17.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.4.intermediate.dense.weight', 'base_model.embeddings.position_embeddings.weight', 'base_model.encoder.layer.11.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.11.attention.self.value.bias', 'base_model.encoder.layer.4.output.LayerNorm.weight', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.4.output.dense.weight', 'base_model.encoder.layer.21.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.7.attention.self.key.weight', 'base_model.encoder.layer.9.attention.self.query.bias', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.22.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.8.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.8.attention.self.value.weight', 'base_model.encoder.layer.10.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.5.attention.self.key.weight', 'base_model.encoder.layer.2.attention.self.key.bias', 'base_model.encoder.layer.3.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.8.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.4.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.14.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.21.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.9.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.10.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.1.output.LayerNorm.bias', 'base_model.encoder.layer.6.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.2.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.13.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.6.output.LayerNorm.bias', 'base_model.encoder.layer.2.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.1.intermediate.dense.weight', 'base_model.encoder.layer.14.intermediate.dense.bias', 'base_model.encoder.layer.10.attention.self.query.bias', 'base_model.encoder.layer.12.output.dense.bias', 'base_model.encoder.layer.16.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.15.output.LayerNorm.weight', 'base_model.encoder.layer.9.intermediate.dense.weight', 'base_model.encoder.layer.19.attention.output.dense.weight', 'base_model.encoder.layer.10.output.dense.weight', 'base_model.encoder.layer.13.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.14.attention.output.dense.bias', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.0.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.11.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.14.intermediate.dense.weight', 'base_model.encoder.layer.7.output.dense.bias', 'base_model.encoder.layer.16.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.5.output.LayerNorm.weight', 'base_model.encoder.layer.5.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.5.intermediate.dense.weight', 'base_model.encoder.layer.12.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.18.output.dense.weight', 'base_model.encoder.layer.18.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.17.output.dense.bias', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.2.attention.output.LayerNorm.bias', 'base_model.encoder.layer.13.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.20.attention.self.query.bias', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.4.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.5.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.5.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.23.attention.output.dense.bias', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.17.attention.self.query.weight', 'base_model.encoder.layer.18.attention.self.key.bias', 'base_model.encoder.layer.18.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.13.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.13.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.3.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.15.output.dense.weight', 'base_model.encoder.layer.5.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.21.intermediate.dense.weight', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.2.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.9.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.16.attention.self.key.bias', 'base_model.encoder.layer.22.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.12.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.7.intermediate.dense.weight', 'base_model.encoder.layer.0.attention.self.key.bias', 'base_model.encoder.layer.9.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.11.attention.self.query.weight', 'base_model.encoder.layer.23.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.14.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.15.attention.self.key.weight', 'base_model.encoder.layer.6.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.17.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.13.attention.self.value.weight', 'base_model.encoder.layer.10.attention.self.key.bias', 'base_model.encoder.layer.8.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.3.output.LayerNorm.weight', 'base_model.pooler.dense.bias', 'base_model.encoder.layer.18.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.0.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.1.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.15.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.0.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.14.attention.self.key.weight', 'base_model.encoder.layer.21.intermediate.dense.bias', 'base_model.encoder.layer.22.attention.self.value.weight', 'base_model.encoder.layer.14.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.23.attention.output.LayerNorm.bias', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.6.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.8.attention.output.dense.weight', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.20.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.15.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.13.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.18.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.10.intermediate.dense.bias', 'base_model.encoder.layer.12.attention.output.LayerNorm.weight', 'base_model.encoder.layer.13.output.LayerNorm.bias', 'base_model.encoder.layer.21.output.adapters.ep.adapter_down.0.weight', 'base_model.embeddings.LayerNorm.weight', 'base_model.encoder.layer.17.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.19.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.3.attention.self.key.bias', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.6.intermediate.dense.weight', 'base_model.encoder.layer.3.intermediate.dense.weight', 'base_model.encoder.layer.9.attention.output.LayerNorm.bias', 'base_model.encoder.layer.13.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.19.attention.self.value.weight', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.8.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.18.attention.output.dense.bias', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.8.output.LayerNorm.bias', 'base_model.encoder.layer.23.attention.self.value.weight', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.12.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.16.attention.self.key.weight', 'base_model.encoder.layer.1.output.dense.weight', 'base_model.encoder.layer.17.output.dense.weight', 'base_model.encoder.layer.12.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.20.attention.self.query.weight', 'base_model.encoder.layer.11.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.19.output.dense.weight', 'base_model.embeddings.LayerNorm.bias', 'base_model.encoder.layer.0.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.8.attention.output.LayerNorm.bias', 'base_model.encoder.layer.1.attention.output.dense.bias', 'base_model.encoder.layer.14.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.2.attention.output.LayerNorm.weight', 'base_model.encoder.layer.14.output.dense.weight', 'base_model.encoder.layer.1.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.9.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.1.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.17.attention.self.key.bias', 'base_model.encoder.layer.22.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.1.attention.output.dense.weight', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.15.intermediate.dense.bias', 'base_model.encoder.layer.13.attention.self.key.bias', 'base_model.encoder.layer.6.attention.self.query.weight', 'base_model.encoder.layer.21.attention.output.LayerNorm.weight', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.14.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.8.intermediate.dense.weight', 'base_model.encoder.layer.17.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.18.output.adapters.ts.adapter_up.bias', 'base_model.embeddings.position_ids', 'base_model.encoder.layer.7.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.15.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.22.attention.self.key.bias', 'base_model.encoder.layer.22.attention.self.query.bias', 'base_model.encoder.layer.5.attention.self.query.bias', 'base_model.encoder.layer.6.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.0.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.0.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.2.intermediate.dense.bias', 'base_model.encoder.layer.18.intermediate.dense.bias', 'base_model.encoder.layer.23.output.LayerNorm.bias', 'base_model.encoder.layer.20.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.11.output.dense.bias', 'base_model.encoder.layer.10.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.8.attention.self.key.bias', 'base_model.encoder.layer.5.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.1.output.LayerNorm.weight', 'base_model.encoder.layer.12.attention.self.query.bias', 'base_model.encoder.layer.0.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.8.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.5.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.7.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.19.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.1.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.10.output.dense.bias', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.16.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.20.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.18.output.LayerNorm.bias', 'base_model.embeddings.word_embeddings.weight', 'base_model.encoder.layer.1.attention.self.key.weight', 'base_model.encoder.layer.5.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.7.attention.self.query.weight', 'base_model.encoder.layer.22.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.13.intermediate.dense.weight', 'base_model.encoder.layer.7.attention.output.LayerNorm.weight', 'base_model.encoder.layer.11.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.19.output.LayerNorm.bias', 'base_model.encoder.layer.6.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.18.attention.output.LayerNorm.weight', 'base_model.encoder.layer.4.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.20.output.LayerNorm.weight', 'base_model.encoder.layer.11.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.14.attention.self.query.weight', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.23.attention.self.key.bias', 'base_model.encoder.layer.3.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.9.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.9.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.10.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.13.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.13.attention.output.LayerNorm.weight', 'base_model.encoder.layer.3.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.15.attention.self.query.weight', 'base_model.encoder.layer.7.output.LayerNorm.bias', 'base_model.encoder.layer.6.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.3.attention.self.query.weight', 'base_model.encoder.layer.14.attention.output.dense.weight', 'base_model.encoder.layer.22.output.LayerNorm.weight', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.0.output.LayerNorm.weight', 'base_model.encoder.layer.11.output.LayerNorm.bias', 'base_model.encoder.layer.14.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.10.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.20.attention.output.LayerNorm.bias', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.2.attention.self.value.weight', 'base_model.encoder.layer.0.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.4.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.12.attention.self.query.weight', 'base_model.encoder.layer.2.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.16.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.2.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.19.output.dense.bias', 'base_model.encoder.layer.7.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.8.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.5.attention.self.query.weight', 'base_model.encoder.layer.3.attention.output.dense.weight', 'base_model.encoder.layer.2.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.12.output.LayerNorm.bias', 'base_model.encoder.layer.12.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.14.attention.self.key.bias', 'base_model.encoder.layer.1.attention.self.value.bias', 'base_model.encoder.layer.13.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.1.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.8.attention.self.query.weight', 'base_model.encoder.layer.20.attention.self.value.weight', 'base_model.encoder.layer.11.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.12.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.16.attention.self.query.bias', 'base_model.encoder.layer.23.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.4.attention.output.LayerNorm.bias', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.7.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.0.attention.output.dense.weight', 'base_model.encoder.layer.4.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.21.attention.output.LayerNorm.bias', 'base_model.encoder.layer.1.intermediate.dense.bias', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.2.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.13.attention.self.key.weight', 'base_model.encoder.layer.22.attention.output.dense.bias', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.5.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.16.output.LayerNorm.bias', 'base_model.encoder.layer.16.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.7.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.16.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.20.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.17.attention.self.key.weight', 'base_model.encoder.layer.20.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.13.output.dense.weight', 'base_model.encoder.layer.18.attention.output.dense.weight', 'base_model.encoder.layer.23.attention.output.dense.weight', 'base_model.encoder.layer.23.attention.output.LayerNorm.weight']
- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of XLMRobertaModel were not initialized from the model checkpoint at /cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//squad/xlm-KG_LR4e-5_EPOCH2.0_maxlen384_batchsize4_gradacc8 and are newly initialized: ['encoder.layer.5.attention.self.key.bias', 'encoder.layer.3.attention.self.query.bias', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.21.attention.output.dense.bias', 'encoder.layer.17.output.LayerNorm.weight', 'encoder.layer.11.output.dense.bias', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.10.output.LayerNorm.bias', 'encoder.layer.16.attention.output.dense.bias', 'encoder.layer.22.attention.self.value.weight', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.11.output.dense.weight', 'encoder.layer.9.attention.self.key.weight', 'encoder.layer.8.attention.output.dense.weight', 'encoder.layer.12.output.dense.bias', 'encoder.layer.12.output.dense.weight', 'encoder.layer.11.attention.output.dense.weight', 'encoder.layer.1.attention.self.query.weight', 'encoder.layer.22.attention.output.dense.weight', 'encoder.layer.12.intermediate.dense.weight', 'encoder.layer.16.attention.self.query.bias', 'encoder.layer.19.attention.output.LayerNorm.bias', 'encoder.layer.4.output.dense.bias', 'encoder.layer.8.attention.output.LayerNorm.bias', 'encoder.layer.15.attention.self.key.weight', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.18.attention.self.key.bias', 'encoder.layer.11.attention.self.key.weight', 'encoder.layer.15.output.LayerNorm.bias', 'encoder.layer.2.attention.self.key.weight', 'encoder.layer.18.output.dense.weight', 'encoder.layer.17.attention.output.dense.bias', 'encoder.layer.4.attention.self.key.weight', 'encoder.layer.12.intermediate.dense.bias', 'encoder.layer.15.output.dense.bias', 'encoder.layer.1.attention.output.dense.bias', 'encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.10.attention.self.query.weight', 'encoder.layer.22.attention.self.query.bias', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.7.attention.output.dense.weight', 'encoder.layer.23.attention.self.query.bias', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.3.attention.self.query.weight', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.9.attention.self.value.bias', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.10.attention.self.key.weight', 'encoder.layer.1.attention.self.query.bias', 'encoder.layer.11.output.LayerNorm.weight', 'encoder.layer.16.intermediate.dense.weight', 'encoder.layer.6.attention.self.key.weight', 'encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.layer.8.attention.self.key.bias', 'encoder.layer.20.attention.self.key.bias', 'encoder.layer.14.attention.output.LayerNorm.weight', 'encoder.layer.21.attention.self.query.bias', 'encoder.layer.22.attention.self.query.weight', 'encoder.layer.18.attention.self.value.weight', 'encoder.layer.5.output.dense.bias', 'encoder.layer.17.output.dense.bias', 'encoder.layer.2.attention.output.dense.bias', 'encoder.layer.14.attention.self.key.bias', 'encoder.layer.3.attention.self.key.weight', 'encoder.layer.15.attention.self.value.weight', 'encoder.layer.13.output.LayerNorm.bias', 'encoder.layer.10.attention.self.key.bias', 'encoder.layer.13.attention.output.LayerNorm.bias', 'encoder.layer.17.attention.self.query.bias', 'encoder.layer.2.output.dense.bias', 'encoder.layer.23.attention.output.LayerNorm.bias', 'encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.layer.16.output.dense.weight', 'encoder.layer.6.output.dense.bias', 'encoder.layer.14.attention.self.query.weight', 'encoder.layer.15.attention.self.query.bias', 'encoder.layer.6.attention.output.LayerNorm.weight', 'encoder.layer.21.output.LayerNorm.bias', 'encoder.layer.16.attention.output.LayerNorm.bias', 'encoder.layer.14.attention.output.dense.weight', 'encoder.layer.14.attention.self.key.weight', 'encoder.layer.4.attention.output.LayerNorm.bias', 'embeddings.LayerNorm.bias', 'encoder.layer.23.output.LayerNorm.bias', 'encoder.layer.4.attention.output.dense.bias', 'encoder.layer.8.attention.self.value.weight', 'encoder.layer.19.attention.output.LayerNorm.weight', 'encoder.layer.22.output.dense.bias', 'encoder.layer.22.intermediate.dense.weight', 'encoder.layer.17.attention.self.value.bias', 'encoder.layer.22.attention.self.key.weight', 'encoder.layer.15.attention.output.LayerNorm.weight', 'encoder.layer.15.attention.output.dense.bias', 'encoder.layer.16.attention.self.key.weight', 'encoder.layer.14.output.LayerNorm.weight', 'encoder.layer.13.attention.self.key.bias', 'encoder.layer.10.output.LayerNorm.weight', 'encoder.layer.18.attention.self.value.bias', 'encoder.layer.8.attention.self.key.weight', 'encoder.layer.20.output.dense.bias', 'encoder.layer.10.intermediate.dense.weight', 'encoder.layer.20.attention.output.dense.bias', 'encoder.layer.1.attention.self.key.bias', 'encoder.layer.7.attention.self.value.weight', 'encoder.layer.21.intermediate.dense.bias', 'encoder.layer.11.attention.output.dense.bias', 'encoder.layer.8.attention.output.dense.bias', 'encoder.layer.3.output.dense.weight', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.15.intermediate.dense.bias', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.2.output.dense.weight', 'encoder.layer.7.attention.output.dense.bias', 'encoder.layer.17.attention.self.value.weight', 'encoder.layer.4.attention.self.value.weight', 'encoder.layer.22.attention.self.key.bias', 'encoder.layer.15.attention.self.value.bias', 'encoder.layer.21.output.dense.bias', 'encoder.layer.6.attention.output.LayerNorm.bias', 'encoder.layer.20.output.LayerNorm.weight', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.16.intermediate.dense.bias', 'encoder.layer.6.attention.self.key.bias', 'encoder.layer.19.attention.output.dense.bias', 'encoder.layer.8.output.LayerNorm.bias', 'encoder.layer.6.attention.self.value.weight', 'encoder.layer.4.attention.self.key.bias', 'encoder.layer.5.attention.self.value.weight', 'encoder.layer.3.attention.output.dense.weight', 'encoder.layer.15.output.dense.weight', 'encoder.layer.12.attention.self.key.bias', 'encoder.layer.20.intermediate.dense.weight', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.6.attention.output.dense.weight', 'encoder.layer.20.attention.output.LayerNorm.bias', 'encoder.layer.22.attention.output.LayerNorm.bias', 'encoder.layer.18.attention.output.LayerNorm.bias', 'embeddings.position_embeddings.weight', 'encoder.layer.19.output.LayerNorm.bias', 'encoder.layer.19.attention.self.value.bias', 'encoder.layer.10.output.dense.bias', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.17.output.LayerNorm.bias', 'encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.17.output.dense.weight', 'encoder.layer.13.intermediate.dense.bias', 'encoder.layer.19.output.dense.bias', 'encoder.layer.14.intermediate.dense.bias', 'encoder.layer.18.output.LayerNorm.bias', 'encoder.layer.0.attention.self.value.bias', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.layer.13.attention.self.value.weight', 'encoder.layer.17.attention.self.query.weight', 'encoder.layer.19.output.dense.weight', 'encoder.layer.17.attention.output.LayerNorm.bias', 'encoder.layer.18.intermediate.dense.weight', 'encoder.layer.7.attention.output.LayerNorm.bias', 'encoder.layer.22.output.LayerNorm.bias', 'encoder.layer.0.output.dense.bias', 'encoder.layer.2.attention.self.key.bias', 'encoder.layer.4.attention.output.dense.weight', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.3.attention.self.value.weight', 'encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.layer.16.attention.self.query.weight', 'encoder.layer.5.output.LayerNorm.bias', 'encoder.layer.11.attention.output.LayerNorm.weight', 'encoder.layer.8.attention.self.query.weight', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.7.output.LayerNorm.weight', 'encoder.layer.17.attention.output.LayerNorm.weight', 'encoder.layer.12.output.LayerNorm.bias', 'encoder.layer.23.intermediate.dense.weight', 'encoder.layer.14.attention.self.query.bias', 'encoder.layer.19.attention.self.value.weight', 'encoder.layer.22.output.LayerNorm.weight', 'encoder.layer.7.attention.self.key.weight', 'encoder.layer.12.attention.output.dense.weight', 'encoder.layer.11.output.LayerNorm.bias', 'encoder.layer.19.attention.self.key.weight', 'encoder.layer.13.attention.self.query.weight', 'encoder.layer.23.output.dense.weight', 'encoder.layer.12.attention.self.value.bias', 'encoder.layer.0.attention.self.value.weight', 'encoder.layer.7.attention.output.LayerNorm.weight', 'encoder.layer.13.attention.self.value.bias', 'encoder.layer.5.attention.self.key.weight', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.9.attention.self.query.bias', 'encoder.layer.5.attention.output.dense.weight', 'encoder.layer.19.intermediate.dense.weight', 'encoder.layer.10.attention.output.dense.weight', 'encoder.layer.13.attention.output.dense.bias', 'encoder.layer.23.attention.output.LayerNorm.weight', 'encoder.layer.2.attention.output.LayerNorm.bias', 'encoder.layer.13.attention.self.key.weight', 'encoder.layer.23.output.dense.bias', 'encoder.layer.0.attention.self.query.weight', 'encoder.layer.8.output.dense.weight', 'encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.layer.18.attention.output.dense.weight', 'encoder.layer.12.attention.self.value.weight', 'encoder.layer.21.attention.self.key.weight', 'encoder.layer.7.output.dense.bias', 'encoder.layer.23.attention.output.dense.weight', 'encoder.layer.6.attention.output.dense.bias', 'encoder.layer.21.attention.self.value.weight', 'encoder.layer.18.output.dense.bias', 'embeddings.LayerNorm.weight', 'pooler.dense.weight', 'encoder.layer.21.output.dense.weight', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.21.attention.self.value.bias', 'encoder.layer.21.attention.output.LayerNorm.bias', 'encoder.layer.14.attention.self.value.weight', 'encoder.layer.20.attention.self.key.weight', 'encoder.layer.15.output.LayerNorm.weight', 'encoder.layer.0.attention.output.dense.bias', 'encoder.layer.12.attention.output.LayerNorm.bias', 'encoder.layer.12.output.LayerNorm.weight', 'encoder.layer.23.attention.output.dense.bias', 'encoder.layer.22.attention.output.dense.bias', 'encoder.layer.14.intermediate.dense.weight', 'encoder.layer.23.attention.self.key.bias', 'encoder.layer.4.attention.self.query.weight', 'encoder.layer.22.intermediate.dense.bias', 'encoder.layer.10.attention.output.dense.bias', 'encoder.layer.19.attention.self.query.bias', 'encoder.layer.1.output.dense.bias', 'encoder.layer.13.output.dense.bias', 'encoder.layer.13.intermediate.dense.weight', 'encoder.layer.10.attention.output.LayerNorm.bias', 'encoder.layer.20.attention.self.value.weight', 'encoder.layer.12.attention.self.query.bias', 'encoder.layer.21.attention.output.LayerNorm.weight', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.23.attention.self.query.weight', 'encoder.layer.8.output.LayerNorm.weight', 'encoder.layer.13.attention.self.query.bias', 'encoder.layer.14.output.dense.bias', 'encoder.layer.10.attention.self.value.bias', 'encoder.layer.16.output.LayerNorm.weight', 'encoder.layer.12.attention.self.query.weight', 'encoder.layer.9.output.dense.weight', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.7.attention.self.query.weight', 'encoder.layer.9.output.LayerNorm.weight', 'pooler.dense.bias', 'encoder.layer.23.output.LayerNorm.weight', 'encoder.layer.1.attention.output.dense.weight', 'encoder.layer.16.output.LayerNorm.bias', 'encoder.layer.0.attention.self.key.weight', 'encoder.layer.16.attention.self.key.bias', 'encoder.layer.21.attention.output.dense.weight', 'encoder.layer.14.attention.output.dense.bias', 'encoder.layer.2.attention.self.query.weight', 'encoder.layer.16.attention.output.dense.weight', 'encoder.layer.5.attention.output.dense.bias', 'encoder.layer.2.attention.self.value.weight', 'encoder.layer.9.attention.output.LayerNorm.bias', 'encoder.layer.12.attention.self.key.weight', 'encoder.layer.9.output.LayerNorm.bias', 'encoder.layer.21.output.LayerNorm.weight', 'encoder.layer.15.attention.output.LayerNorm.bias', 'encoder.layer.6.output.dense.weight', 'encoder.layer.21.attention.self.key.bias', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.6.attention.self.value.bias', 'encoder.layer.0.attention.output.LayerNorm.weight', 'encoder.layer.1.attention.self.key.weight', 'encoder.layer.21.attention.self.query.weight', 'encoder.layer.6.output.LayerNorm.bias', 'encoder.layer.12.attention.output.dense.bias', 'encoder.layer.8.output.dense.bias', 'encoder.layer.7.attention.self.key.bias', 'encoder.layer.6.attention.self.query.bias', 'encoder.layer.22.output.dense.weight', 'encoder.layer.20.attention.self.query.bias', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.3.output.dense.bias', 'encoder.layer.17.attention.self.key.weight', 'encoder.layer.17.attention.output.dense.weight', 'encoder.layer.5.output.dense.weight', 'encoder.layer.15.attention.output.dense.weight', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.2.attention.output.LayerNorm.weight', 'encoder.layer.9.attention.output.dense.weight', 'encoder.layer.8.attention.output.LayerNorm.weight', 'encoder.layer.3.attention.output.dense.bias', 'encoder.layer.16.attention.self.value.bias', 'encoder.layer.19.intermediate.dense.bias', 'encoder.layer.2.attention.self.value.bias', 'encoder.layer.1.attention.self.value.weight', 'encoder.layer.2.attention.self.query.bias', 'encoder.layer.11.attention.self.query.bias', 'encoder.layer.13.attention.output.dense.weight', 'encoder.layer.5.attention.self.query.weight', 'encoder.layer.17.attention.self.key.bias', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.10.attention.output.LayerNorm.weight', 'encoder.layer.18.attention.output.LayerNorm.weight', 'encoder.layer.3.attention.self.key.bias', 'encoder.layer.17.intermediate.dense.weight', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.2.attention.output.dense.weight', 'encoder.layer.19.attention.self.key.bias', 'encoder.layer.11.attention.self.key.bias', 'encoder.layer.7.attention.self.value.bias', 'encoder.layer.9.attention.self.value.weight', 'encoder.layer.20.attention.self.query.weight', 'encoder.layer.1.attention.output.LayerNorm.weight', 'encoder.layer.15.attention.self.query.weight', 'encoder.layer.20.output.LayerNorm.bias', 'encoder.layer.14.attention.output.LayerNorm.bias', 'encoder.layer.0.output.dense.weight', 'encoder.layer.8.attention.self.query.bias', 'encoder.layer.10.output.dense.weight', 'encoder.layer.18.attention.self.query.bias', 'encoder.layer.0.attention.self.query.bias', 'encoder.layer.13.output.dense.weight', 'encoder.layer.7.attention.self.query.bias', 'encoder.layer.18.attention.self.key.weight', 'encoder.layer.13.output.LayerNorm.weight', 'encoder.layer.5.attention.self.value.bias', 'encoder.layer.9.attention.output.dense.bias', 'encoder.layer.9.attention.self.key.bias', 'encoder.layer.11.attention.self.value.weight', 'encoder.layer.20.attention.output.LayerNorm.weight', 'embeddings.token_type_embeddings.weight', 'encoder.layer.7.intermediate.dense.bias', 'encoder.layer.20.output.dense.weight', 'encoder.layer.4.output.dense.weight', 'encoder.layer.4.attention.self.value.bias', 'encoder.layer.5.attention.self.query.bias', 'encoder.layer.16.output.dense.bias', 'encoder.layer.11.attention.self.query.weight', 'encoder.layer.23.attention.self.value.weight', 'encoder.layer.14.attention.self.value.bias', 'encoder.layer.4.attention.self.query.bias', 'encoder.layer.20.attention.self.value.bias', 'encoder.layer.23.intermediate.dense.bias', 'encoder.layer.19.output.LayerNorm.weight', 'encoder.layer.1.attention.self.value.bias', 'encoder.layer.6.attention.self.query.weight', 'encoder.layer.17.intermediate.dense.bias', 'encoder.layer.18.attention.self.query.weight', 'encoder.layer.22.attention.self.value.bias', 'encoder.layer.16.attention.self.value.weight', 'encoder.layer.9.output.dense.bias', 'encoder.layer.22.attention.output.LayerNorm.weight', 'encoder.layer.1.output.dense.weight', 'encoder.layer.9.attention.self.query.weight', 'encoder.layer.14.output.dense.weight', 'encoder.layer.9.attention.output.LayerNorm.weight', 'encoder.layer.7.output.dense.weight', 'encoder.layer.10.attention.self.query.bias', 'encoder.layer.20.attention.output.dense.weight', 'encoder.layer.16.attention.output.LayerNorm.weight', 'encoder.layer.23.attention.self.key.weight', 'encoder.layer.15.intermediate.dense.weight', 'encoder.layer.20.intermediate.dense.bias', 'encoder.layer.19.attention.self.query.weight', 'encoder.layer.4.attention.output.LayerNorm.weight', 'encoder.layer.0.attention.output.dense.weight', 'encoder.layer.19.attention.output.dense.weight', 'encoder.layer.23.attention.self.value.bias', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.8.attention.self.value.bias', 'encoder.layer.11.attention.self.value.bias', 'encoder.layer.13.attention.output.LayerNorm.weight', 'encoder.layer.14.output.LayerNorm.bias', 'encoder.layer.3.attention.self.value.bias', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.18.intermediate.dense.bias', 'encoder.layer.12.attention.output.LayerNorm.weight', 'encoder.layer.18.output.LayerNorm.weight', 'encoder.layer.7.output.LayerNorm.bias', 'encoder.layer.0.attention.self.key.bias', 'encoder.layer.5.attention.output.LayerNorm.weight', 'encoder.layer.21.intermediate.dense.weight', 'encoder.layer.18.attention.output.dense.bias', 'embeddings.word_embeddings.weight', 'encoder.layer.15.attention.self.key.bias', 'encoder.layer.10.attention.self.value.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Overwriting existing adapter 'ep'.
Overwriting existing adapter 'tp'.
Overwriting existing adapter 'es'.
Overwriting existing adapter 'ts'.
Overwriting existing adapter fusion module 'ep,tp,es,ts'
05/09/2022 20:14:34 - INFO - __main__ -   Creating features from dataset file at .
/cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//squad/xlm-KG_LR4e-5_EPOCH2.0_maxlen384_batchsize4_gradacc8
XLMConfig {
  "architectures": [
    "XLMRobertaForMaskedLM"
  ],
  "asm": false,
  "attention_dropout": 0.1,
  "attention_probs_dropout_prob": 0.1,
  "bos_index": 0,
  "bos_token_id": 0,
  "causal": false,
  "dropout": 0.1,
  "emb_dim": 1024,
  "embed_init_std": 0.02209708691207961,
  "end_n_top": 5,
  "eos_index": 1,
  "eos_token_id": 2,
  "gelu_activation": true,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "init_std": 0.02,
  "initializer_range": 0.02,
  "intermediate_size": 4096,
  "is_encoder": true,
  "lang_id": 0,
  "layer_norm_eps": 1e-05,
  "mask_index": 5,
  "mask_token_id": 0,
  "max_position_embeddings": 514,
  "model_type": "xlm",
  "n_heads": 16,
  "n_langs": 1,
  "n_layers": 24,
  "output_past": true,
  "pad_index": 2,
  "pad_token_id": 1,
  "sinusoidal_embeddings": false,
  "start_n_top": 5,
  "summary_activation": null,
  "summary_first_dropout": 0.1,
  "summary_proj_to_labels": true,
  "summary_type": "first",
  "summary_use_proj": true,
  "transformers_version": "4.17.0",
  "type_vocab_size": 1,
  "unk_index": 3,
  "use_lang_emb": false,
  "vocab_size": 250002
}

  0%|          | 0/48 [00:00<?, ?it/s] 58%|█████▊    | 28/48 [00:00<00:00, 273.52it/s]100%|██████████| 48/48 [00:00<00:00, 308.02it/s]
convert squad examples to features:   0%|          | 0/1190 [00:00<?, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.
convert squad examples to features:   3%|▎         | 33/1190 [00:00<00:04, 282.87it/s]convert squad examples to features:   8%|▊         | 97/1190 [00:00<00:02, 450.01it/s]convert squad examples to features:  16%|█▌        | 193/1190 [00:00<00:01, 571.70it/s]convert squad examples to features:  24%|██▍       | 289/1190 [00:00<00:01, 616.79it/s]convert squad examples to features:  30%|██▉       | 353/1190 [00:00<00:01, 598.26it/s]convert squad examples to features:  35%|███▍      | 413/1190 [00:00<00:01, 478.64it/s]convert squad examples to features:  39%|███▉      | 463/1190 [00:00<00:01, 448.38it/s]convert squad examples to features:  43%|████▎     | 513/1190 [00:01<00:01, 456.15it/s]convert squad examples to features:  48%|████▊     | 577/1190 [00:01<00:01, 460.14it/s]convert squad examples to features:  54%|█████▍    | 641/1190 [00:01<00:01, 476.59it/s]convert squad examples to features:  59%|█████▉    | 705/1190 [00:01<00:00, 498.59it/s]convert squad examples to features:  67%|██████▋   | 801/1190 [00:01<00:00, 556.38it/s]convert squad examples to features:  72%|███████▏  | 857/1190 [00:01<00:00, 554.55it/s]convert squad examples to features:  77%|███████▋  | 913/1190 [00:01<00:00, 489.47it/s]convert squad examples to features:  81%|████████  | 963/1190 [00:02<00:00, 397.47it/s]convert squad examples to features:  86%|████████▌ | 1025/1190 [00:02<00:00, 438.08it/s]convert squad examples to features:  92%|█████████▏| 1089/1190 [00:02<00:00, 480.20it/s]convert squad examples to features:  97%|█████████▋| 1153/1190 [00:02<00:00, 470.13it/s]convert squad examples to features: 100%|██████████| 1190/1190 [00:02<00:00, 501.68it/s]/cluster/project/sachan/yifan/softwares/anaconda/anaconda3/envs/xfactr/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2272: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

add example index and unique id:   0%|          | 0/1190 [00:00<?, ?it/s]add example index and unique id: 100%|██████████| 1190/1190 [00:00<00:00, 563916.14it/s]
05/09/2022 20:14:37 - INFO - __main__ -   Saving features into cached file ./cached_xquad.zh.json_xlm-KG_LR4e-5_EPOCH2.0_maxlen384_batchsize4_gradacc8_384_zh
05/09/2022 20:14:38 - INFO - __main__ -   ***** Running evaluation  *****
05/09/2022 20:14:38 - INFO - __main__ -     Num examples = 1246
05/09/2022 20:14:38 - INFO - __main__ -     Batch size = 8
Evaluating:   0%|          | 0/156 [00:00<?, ?it/s]Evaluating:   1%|          | 1/156 [00:00<02:08,  1.20it/s]Evaluating:   1%|▏         | 2/156 [00:01<01:24,  1.81it/s]Evaluating:   2%|▏         | 3/156 [00:01<01:10,  2.17it/s]Evaluating:   3%|▎         | 4/156 [00:01<01:03,  2.39it/s]Evaluating:   3%|▎         | 5/156 [00:02<00:59,  2.54it/s]Evaluating:   4%|▍         | 6/156 [00:02<00:56,  2.64it/s]Evaluating:   4%|▍         | 7/156 [00:02<00:55,  2.70it/s]Evaluating:   5%|▌         | 8/156 [00:03<00:54,  2.74it/s]Evaluating:   6%|▌         | 9/156 [00:03<00:53,  2.75it/s]Evaluating:   6%|▋         | 10/156 [00:04<00:52,  2.76it/s]Evaluating:   7%|▋         | 11/156 [00:04<00:52,  2.78it/s]Evaluating:   8%|▊         | 12/156 [00:04<00:51,  2.79it/s]Evaluating:   8%|▊         | 13/156 [00:05<00:51,  2.79it/s]Evaluating:   9%|▉         | 14/156 [00:05<00:50,  2.80it/s]Evaluating:  10%|▉         | 15/156 [00:05<00:50,  2.81it/s]Evaluating:  10%|█         | 16/156 [00:06<00:49,  2.81it/s]Evaluating:  11%|█         | 17/156 [00:06<00:49,  2.82it/s]Evaluating:  12%|█▏        | 18/156 [00:06<00:48,  2.82it/s]Evaluating:  12%|█▏        | 19/156 [00:07<00:48,  2.82it/s]Evaluating:  13%|█▎        | 20/156 [00:07<00:48,  2.83it/s]Evaluating:  13%|█▎        | 21/156 [00:07<00:47,  2.83it/s]Evaluating:  14%|█▍        | 22/156 [00:08<00:47,  2.84it/s]Evaluating:  15%|█▍        | 23/156 [00:08<00:47,  2.83it/s]Evaluating:  15%|█▌        | 24/156 [00:08<00:46,  2.82it/s]Evaluating:  16%|█▌        | 25/156 [00:09<00:46,  2.83it/s]Evaluating:  17%|█▋        | 26/156 [00:09<00:46,  2.82it/s]Evaluating:  17%|█▋        | 27/156 [00:10<00:46,  2.80it/s]Evaluating:  18%|█▊        | 28/156 [00:10<00:45,  2.81it/s]Evaluating:  19%|█▊        | 29/156 [00:10<00:45,  2.81it/s]Evaluating:  19%|█▉        | 30/156 [00:11<00:44,  2.82it/s]Evaluating:  20%|█▉        | 31/156 [00:11<00:44,  2.81it/s]Evaluating:  21%|██        | 32/156 [00:11<00:44,  2.81it/s]Evaluating:  21%|██        | 33/156 [00:12<00:43,  2.81it/s]Evaluating:  22%|██▏       | 34/156 [00:12<00:43,  2.80it/s]Evaluating:  22%|██▏       | 35/156 [00:12<00:43,  2.80it/s]Evaluating:  23%|██▎       | 36/156 [00:13<00:42,  2.80it/s]Evaluating:  24%|██▎       | 37/156 [00:13<00:42,  2.80it/s]Evaluating:  24%|██▍       | 38/156 [00:13<00:42,  2.80it/s]Evaluating:  25%|██▌       | 39/156 [00:14<00:42,  2.74it/s]Evaluating:  26%|██▌       | 40/156 [00:14<00:42,  2.76it/s]Evaluating:  26%|██▋       | 41/156 [00:15<00:41,  2.77it/s]Evaluating:  27%|██▋       | 42/156 [00:15<00:40,  2.78it/s]Evaluating:  28%|██▊       | 43/156 [00:15<00:40,  2.78it/s]Evaluating:  28%|██▊       | 44/156 [00:16<00:40,  2.79it/s]Evaluating:  29%|██▉       | 45/156 [00:16<00:39,  2.80it/s]Evaluating:  29%|██▉       | 46/156 [00:16<00:39,  2.81it/s]Evaluating:  30%|███       | 47/156 [00:17<00:38,  2.81it/s]Evaluating:  31%|███       | 48/156 [00:17<00:38,  2.79it/s]Evaluating:  31%|███▏      | 49/156 [00:17<00:38,  2.80it/s]Evaluating:  32%|███▏      | 50/156 [00:18<00:37,  2.80it/s]Evaluating:  33%|███▎      | 51/156 [00:18<00:37,  2.79it/s]Evaluating:  33%|███▎      | 52/156 [00:18<00:37,  2.79it/s]Evaluating:  34%|███▍      | 53/156 [00:19<00:37,  2.77it/s]Evaluating:  35%|███▍      | 54/156 [00:19<00:36,  2.77it/s]Evaluating:  35%|███▌      | 55/156 [00:20<00:36,  2.77it/s]Evaluating:  36%|███▌      | 56/156 [00:20<00:36,  2.77it/s]Evaluating:  37%|███▋      | 57/156 [00:20<00:35,  2.79it/s]Evaluating:  37%|███▋      | 58/156 [00:21<00:35,  2.79it/s]Evaluating:  38%|███▊      | 59/156 [00:21<00:34,  2.79it/s]Evaluating:  38%|███▊      | 60/156 [00:21<00:34,  2.78it/s]Evaluating:  39%|███▉      | 61/156 [00:22<00:33,  2.79it/s]Evaluating:  40%|███▉      | 62/156 [00:22<00:33,  2.80it/s]Evaluating:  40%|████      | 63/156 [00:22<00:33,  2.79it/s]Evaluating:  41%|████      | 64/156 [00:23<00:32,  2.79it/s]Evaluating:  42%|████▏     | 65/156 [00:23<00:32,  2.79it/s]Evaluating:  42%|████▏     | 66/156 [00:24<00:32,  2.79it/s]Evaluating:  43%|████▎     | 67/156 [00:24<00:32,  2.78it/s]Evaluating:  44%|████▎     | 68/156 [00:24<00:31,  2.79it/s]Evaluating:  44%|████▍     | 69/156 [00:25<00:31,  2.80it/s]Evaluating:  45%|████▍     | 70/156 [00:25<00:30,  2.80it/s]Evaluating:  46%|████▌     | 71/156 [00:25<00:30,  2.80it/s]Evaluating:  46%|████▌     | 72/156 [00:26<00:30,  2.80it/s]Evaluating:  47%|████▋     | 73/156 [00:26<00:29,  2.80it/s]Evaluating:  47%|████▋     | 74/156 [00:26<00:29,  2.80it/s]Evaluating:  48%|████▊     | 75/156 [00:27<00:28,  2.80it/s]Evaluating:  49%|████▊     | 76/156 [00:27<00:28,  2.80it/s]Evaluating:  49%|████▉     | 77/156 [00:27<00:28,  2.80it/s]Evaluating:  50%|█████     | 78/156 [00:28<00:27,  2.80it/s]Evaluating:  51%|█████     | 79/156 [00:28<00:27,  2.80it/s]Evaluating:  51%|█████▏    | 80/156 [00:29<00:27,  2.80it/s]Evaluating:  52%|█████▏    | 81/156 [00:29<00:26,  2.80it/s]Evaluating:  53%|█████▎    | 82/156 [00:29<00:26,  2.80it/s]Evaluating:  53%|█████▎    | 83/156 [00:30<00:26,  2.80it/s]Evaluating:  54%|█████▍    | 84/156 [00:30<00:25,  2.79it/s]Evaluating:  54%|█████▍    | 85/156 [00:30<00:25,  2.79it/s]Evaluating:  55%|█████▌    | 86/156 [00:31<00:25,  2.78it/s]Evaluating:  56%|█████▌    | 87/156 [00:31<00:24,  2.79it/s]Evaluating:  56%|█████▋    | 88/156 [00:31<00:24,  2.78it/s]Evaluating:  57%|█████▋    | 89/156 [00:32<00:24,  2.78it/s]Evaluating:  58%|█████▊    | 90/156 [00:32<00:23,  2.78it/s]Evaluating:  58%|█████▊    | 91/156 [00:32<00:23,  2.78it/s]Evaluating:  59%|█████▉    | 92/156 [00:33<00:22,  2.79it/s]Evaluating:  60%|█████▉    | 93/156 [00:33<00:22,  2.79it/s]Evaluating:  60%|██████    | 94/156 [00:34<00:22,  2.79it/s]Evaluating:  61%|██████    | 95/156 [00:34<00:22,  2.77it/s]Evaluating:  62%|██████▏   | 96/156 [00:34<00:21,  2.78it/s]Evaluating:  62%|██████▏   | 97/156 [00:35<00:21,  2.78it/s]Evaluating:  63%|██████▎   | 98/156 [00:35<00:21,  2.75it/s]Evaluating:  63%|██████▎   | 99/156 [00:35<00:20,  2.76it/s]Evaluating:  64%|██████▍   | 100/156 [00:36<00:20,  2.78it/s]Evaluating:  65%|██████▍   | 101/156 [00:36<00:19,  2.78it/s]Evaluating:  65%|██████▌   | 102/156 [00:36<00:19,  2.79it/s]Evaluating:  66%|██████▌   | 103/156 [00:37<00:18,  2.80it/s]Evaluating:  67%|██████▋   | 104/156 [00:37<00:18,  2.77it/s]Evaluating:  67%|██████▋   | 105/156 [00:38<00:18,  2.78it/s]Evaluating:  68%|██████▊   | 106/156 [00:38<00:17,  2.79it/s]Evaluating:  69%|██████▊   | 107/156 [00:38<00:17,  2.80it/s]Evaluating:  69%|██████▉   | 108/156 [00:39<00:17,  2.80it/s]Evaluating:  70%|██████▉   | 109/156 [00:39<00:16,  2.80it/s]Evaluating:  71%|███████   | 110/156 [00:39<00:16,  2.76it/s]Evaluating:  71%|███████   | 111/156 [00:40<00:16,  2.73it/s]Evaluating:  72%|███████▏  | 112/156 [00:40<00:16,  2.72it/s]Evaluating:  72%|███████▏  | 113/156 [00:40<00:15,  2.74it/s]Evaluating:  73%|███████▎  | 114/156 [00:41<00:15,  2.75it/s]Evaluating:  74%|███████▎  | 115/156 [00:41<00:14,  2.77it/s]Evaluating:  74%|███████▍  | 116/156 [00:41<00:14,  2.77it/s]Evaluating:  75%|███████▌  | 117/156 [00:42<00:14,  2.78it/s]Evaluating:  76%|███████▌  | 118/156 [00:42<00:13,  2.78it/s]Evaluating:  76%|███████▋  | 119/156 [00:43<00:13,  2.79it/s]Evaluating:  77%|███████▋  | 120/156 [00:43<00:12,  2.79it/s]Evaluating:  78%|███████▊  | 121/156 [00:43<00:12,  2.79it/s]Evaluating:  78%|███████▊  | 122/156 [00:44<00:12,  2.78it/s]Evaluating:  79%|███████▉  | 123/156 [00:44<00:11,  2.76it/s]Evaluating:  79%|███████▉  | 124/156 [00:44<00:11,  2.72it/s]Evaluating:  80%|████████  | 125/156 [00:45<00:11,  2.74it/s]Evaluating:  81%|████████  | 126/156 [00:45<00:10,  2.76it/s]Evaluating:  81%|████████▏ | 127/156 [00:45<00:10,  2.77it/s]Evaluating:  82%|████████▏ | 128/156 [00:46<00:10,  2.77it/s]Evaluating:  83%|████████▎ | 129/156 [00:46<00:09,  2.77it/s]Evaluating:  83%|████████▎ | 130/156 [00:47<00:09,  2.78it/s]Evaluating:  84%|████████▍ | 131/156 [00:47<00:08,  2.78it/s]Evaluating:  85%|████████▍ | 132/156 [00:47<00:08,  2.79it/s]Evaluating:  85%|████████▌ | 133/156 [00:48<00:08,  2.79it/s]Evaluating:  86%|████████▌ | 134/156 [00:48<00:07,  2.79it/s]Evaluating:  87%|████████▋ | 135/156 [00:48<00:07,  2.80it/s]Evaluating:  87%|████████▋ | 136/156 [00:49<00:07,  2.79it/s]Evaluating:  88%|████████▊ | 137/156 [00:49<00:06,  2.80it/s]Evaluating:  88%|████████▊ | 138/156 [00:49<00:06,  2.80it/s]Evaluating:  89%|████████▉ | 139/156 [00:50<00:06,  2.80it/s]Evaluating:  90%|████████▉ | 140/156 [00:50<00:05,  2.79it/s]Evaluating:  90%|█████████ | 141/156 [00:50<00:05,  2.79it/s]Evaluating:  91%|█████████ | 142/156 [00:51<00:05,  2.78it/s]Evaluating:  92%|█████████▏| 143/156 [00:51<00:04,  2.78it/s]Evaluating:  92%|█████████▏| 144/156 [00:52<00:04,  2.78it/s]Evaluating:  93%|█████████▎| 145/156 [00:52<00:03,  2.78it/s]Evaluating:  94%|█████████▎| 146/156 [00:52<00:03,  2.78it/s]Evaluating:  94%|█████████▍| 147/156 [00:53<00:03,  2.78it/s]Evaluating:  95%|█████████▍| 148/156 [00:53<00:02,  2.76it/s]Evaluating:  96%|█████████▌| 149/156 [00:53<00:02,  2.77it/s]Evaluating:  96%|█████████▌| 150/156 [00:54<00:02,  2.78it/s]Evaluating:  97%|█████████▋| 151/156 [00:54<00:01,  2.78it/s]Evaluating:  97%|█████████▋| 152/156 [00:54<00:01,  2.78it/s]Evaluating:  98%|█████████▊| 153/156 [00:55<00:01,  2.78it/s]Evaluating:  99%|█████████▊| 154/156 [00:55<00:00,  2.77it/s]Evaluating:  99%|█████████▉| 155/156 [00:56<00:00,  2.77it/s]Evaluating: 100%|██████████| 156/156 [00:56<00:00,  3.02it/s]Evaluating: 100%|██████████| 156/156 [00:56<00:00,  2.77it/s]
05/09/2022 20:15:34 - INFO - __main__ -     Evaluation done in total 56.288813 secs (0.045176 sec per example)
05/09/2022 20:15:59 - INFO - __main__ -   Results: {'exact': 48.15126050420168, 'f1': 56.26397225556882, 'total': 1190, 'HasAns_exact': 48.15126050420168, 'HasAns_f1': 56.26397225556882, 'HasAns_total': 1190, 'best_exact': 48.15126050420168, 'best_exact_thresh': 0.0, 'best_f1': 56.26397225556882, 'best_f1_thresh': 0.0}
  hi 
2022-05-09 20:16:07.839375: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0
05/09/2022 20:16:26 - WARNING - __main__ -   Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, 16-bits training: False
You are using a model of type xlm-roberta to instantiate a model of type xlm. This is not supported for all configurations of models and can yield errors.
Some weights of the model checkpoint at /cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//squad/xlm-KG_LR4e-5_EPOCH2.0_maxlen384_batchsize4_gradacc8 were not used when initializing XLMRobertaModel: ['base_model.encoder.layer.8.attention.output.dense.bias', 'base_model.encoder.layer.13.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.22.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.1.attention.output.LayerNorm.weight', 'base_model.encoder.layer.20.attention.self.query.weight', 'base_model.encoder.layer.8.output.LayerNorm.weight', 'base_model.encoder.layer.13.attention.self.value.bias', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.pooler.dense.weight', 'base_model.encoder.layer.2.attention.output.LayerNorm.bias', 'base_model.encoder.layer.4.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.16.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.19.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.19.attention.self.key.bias', 'base_model.encoder.layer.1.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.23.attention.self.query.weight', 'base_model.encoder.layer.2.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.22.attention.self.query.bias', 'base_model.encoder.layer.9.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.13.attention.output.dense.weight', 'base_model.encoder.layer.5.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.15.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.1.attention.self.query.bias', 'base_model.encoder.layer.10.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.4.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.4.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.14.output.LayerNorm.bias', 'base_model.encoder.layer.0.attention.output.dense.bias', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.6.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.21.output.LayerNorm.weight', 'base_model.encoder.layer.23.attention.output.dense.bias', 'base_model.encoder.layer.5.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.23.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.20.intermediate.dense.bias', 'base_model.encoder.layer.12.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.12.attention.output.LayerNorm.weight', 'base_model.encoder.layer.2.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.13.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.16.attention.self.query.weight', 'base_model.encoder.layer.23.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.3.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.4.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.14.attention.output.dense.weight', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.0.output.LayerNorm.weight', 'base_model.encoder.layer.9.intermediate.dense.weight', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.22.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.7.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.9.attention.output.dense.weight', 'base_model.encoder.layer.7.output.dense.bias', 'base_model.encoder.layer.4.attention.output.LayerNorm.bias', 'base_model.encoder.layer.20.attention.output.LayerNorm.weight', 'qa_outputs.weight', 'base_model.encoder.layer.7.attention.output.dense.bias', 'base_model.encoder.layer.17.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.11.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.7.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.15.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.13.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.1.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.20.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.17.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.15.attention.output.LayerNorm.bias', 'base_model.encoder.layer.16.attention.self.key.weight', 'base_model.encoder.layer.2.output.dense.weight', 'base_model.encoder.layer.22.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.9.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.16.attention.output.dense.bias', 'base_model.encoder.layer.16.attention.output.LayerNorm.bias', 'base_model.encoder.layer.21.attention.self.query.bias', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.14.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.6.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.20.attention.self.query.bias', 'base_model.encoder.layer.4.output.dense.weight', 'base_model.encoder.layer.3.attention.self.key.bias', 'base_model.encoder.layer.22.output.LayerNorm.bias', 'base_model.encoder.layer.3.attention.self.value.bias', 'base_model.encoder.layer.0.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.21.attention.output.LayerNorm.weight', 'base_model.encoder.layer.1.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.19.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.12.output.LayerNorm.weight', 'base_model.encoder.layer.8.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.4.intermediate.dense.bias', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.9.attention.self.value.bias', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.16.attention.output.dense.weight', 'base_model.encoder.layer.17.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.15.attention.output.dense.weight', 'base_model.encoder.layer.18.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.3.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.18.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.6.attention.self.key.bias', 'base_model.encoder.layer.10.attention.self.key.weight', 'base_model.encoder.layer.13.attention.self.key.weight', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.4.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.12.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.22.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.7.attention.self.key.bias', 'base_model.encoder.layer.15.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.6.attention.output.LayerNorm.bias', 'base_model.encoder.layer.17.attention.self.key.weight', 'base_model.encoder.layer.15.attention.self.value.weight', 'base_model.encoder.layer.18.output.LayerNorm.bias', 'base_model.encoder.layer.15.attention.self.value.bias', 'base_model.encoder.layer.11.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.14.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.15.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.9.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.11.attention.output.dense.weight', 'base_model.encoder.layer.11.intermediate.dense.bias', 'base_model.encoder.layer.7.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.20.attention.output.LayerNorm.bias', 'base_model.encoder.layer.17.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.10.attention.self.query.weight', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.8.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.11.attention.output.dense.bias', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.0.attention.self.query.bias', 'base_model.encoder.layer.6.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.8.attention.self.key.bias', 'base_model.encoder.layer.8.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.1.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.2.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.11.intermediate.dense.weight', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.2.attention.self.value.weight', 'base_model.encoder.layer.4.attention.self.key.bias', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.15.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.12.output.dense.bias', 'base_model.encoder.layer.17.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.2.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.19.output.LayerNorm.bias', 'base_model.encoder.layer.21.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.21.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.8.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.19.attention.self.value.bias', 'base_model.encoder.layer.5.attention.output.LayerNorm.weight', 'base_model.encoder.layer.11.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.23.attention.self.value.bias', 'base_model.encoder.layer.14.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.20.output.LayerNorm.bias', 'base_model.encoder.layer.3.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.16.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.21.attention.output.LayerNorm.bias', 'base_model.encoder.layer.10.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.12.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.12.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.5.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.1.attention.output.dense.bias', 'base_model.encoder.layer.3.output.LayerNorm.weight', 'base_model.encoder.layer.22.output.dense.weight', 'base_model.encoder.layer.17.attention.output.dense.weight', 'base_model.encoder.layer.8.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.12.attention.output.LayerNorm.bias', 'base_model.encoder.layer.15.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.2.attention.output.dense.bias', 'base_model.encoder.layer.20.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.2.attention.self.key.bias', 'base_model.encoder.layer.5.attention.self.key.bias', 'base_model.encoder.layer.8.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.21.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.6.attention.self.value.weight', 'base_model.encoder.layer.7.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.0.intermediate.dense.weight', 'base_model.encoder.layer.2.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.22.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.7.attention.output.LayerNorm.bias', 'base_model.encoder.layer.4.attention.self.value.weight', 'base_model.encoder.layer.3.attention.self.query.weight', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.10.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.13.attention.self.query.bias', 'base_model.encoder.layer.7.attention.output.dense.weight', 'base_model.encoder.layer.7.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.13.output.dense.weight', 'base_model.encoder.layer.4.output.dense.bias', 'base_model.encoder.layer.2.output.dense.bias', 'base_model.encoder.layer.5.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.0.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.23.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.0.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.14.attention.output.dense.bias', 'base_model.encoder.layer.3.output.dense.bias', 'base_model.encoder.layer.18.output.dense.weight', 'base_model.encoder.layer.22.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.17.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.5.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.7.output.LayerNorm.weight', 'base_model.encoder.layer.1.attention.self.value.bias', 'base_model.encoder.layer.9.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.15.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.10.output.LayerNorm.weight', 'base_model.encoder.layer.19.attention.self.key.weight', 'base_model.encoder.layer.11.attention.self.key.weight', 'base_model.encoder.layer.15.attention.output.dense.bias', 'base_model.encoder.layer.6.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.15.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.22.attention.self.key.bias', 'base_model.encoder.layer.19.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.9.attention.self.value.weight', 'base_model.encoder.layer.17.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.20.attention.output.dense.weight', 'base_model.encoder.layer.3.attention.output.LayerNorm.bias', 'base_model.encoder.layer.18.output.dense.bias', 'base_model.encoder.layer.9.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.13.intermediate.dense.bias', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.8.attention.self.value.weight', 'base_model.encoder.layer.13.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.20.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.1.attention.self.key.weight', 'base_model.encoder.layer.9.output.LayerNorm.weight', 'base_model.encoder.layer.17.attention.self.key.bias', 'base_model.encoder.layer.22.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.12.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.18.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.17.output.LayerNorm.weight', 'base_model.encoder.layer.22.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.16.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.20.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.10.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.16.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.15.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.10.attention.self.value.bias', 'base_model.encoder.layer.1.output.LayerNorm.weight', 'base_model.encoder.layer.22.attention.output.dense.weight', 'base_model.encoder.layer.3.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.1.output.dense.bias', 'base_model.encoder.layer.15.output.LayerNorm.weight', 'base_model.encoder.layer.14.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.7.output.LayerNorm.bias', 'base_model.encoder.layer.17.attention.self.query.weight', 'base_model.encoder.layer.11.attention.self.query.bias', 'base_model.encoder.layer.8.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.12.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.7.attention.self.value.bias', 'base_model.encoder.layer.12.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.6.attention.output.dense.bias', 'base_model.encoder.layer.0.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.0.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.7.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.0.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.19.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.14.output.dense.weight', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.11.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.4.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.2.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.2.attention.self.query.bias', 'base_model.encoder.layer.21.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.5.intermediate.dense.bias', 'base_model.encoder.layer.22.attention.self.value.weight', 'base_model.encoder.layer.22.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.0.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.4.attention.self.query.bias', 'base_model.encoder.layer.9.attention.self.key.bias', 'base_model.encoder.layer.5.attention.self.value.weight', 'base_model.encoder.layer.2.output.LayerNorm.bias', 'base_model.encoder.layer.21.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.14.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.embeddings.position_embeddings.weight', 'base_model.encoder.layer.17.attention.self.value.bias', 'base_model.encoder.layer.20.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.10.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.4.attention.self.key.weight', 'base_model.encoder.layer.17.output.dense.weight', 'base_model.embeddings.LayerNorm.weight', 'base_model.embeddings.LayerNorm.bias', 'base_model.encoder.layer.15.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.14.attention.output.LayerNorm.bias', 'base_model.encoder.layer.11.output.dense.bias', 'base_model.encoder.layer.7.attention.self.query.weight', 'base_model.encoder.layer.21.attention.self.key.weight', 'base_model.encoder.layer.21.attention.output.dense.weight', 'base_model.encoder.layer.1.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.17.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.3.attention.self.key.weight', 'base_model.encoder.layer.11.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.2.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.18.attention.self.key.bias', 'base_model.encoder.layer.13.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.18.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.23.attention.self.value.weight', 'base_model.encoder.layer.19.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.9.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.4.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.17.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.3.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.1.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.0.attention.self.key.bias', 'base_model.encoder.layer.5.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.19.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.2.attention.self.key.weight', 'base_model.encoder.layer.1.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.20.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.13.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.13.attention.self.key.bias', 'base_model.encoder.layer.2.attention.self.value.bias', 'base_model.encoder.layer.16.output.LayerNorm.weight', 'base_model.encoder.layer.2.attention.self.query.weight', 'base_model.encoder.layer.12.output.LayerNorm.bias', 'base_model.encoder.layer.23.attention.output.dense.weight', 'base_model.encoder.layer.19.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.4.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.10.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.9.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.2.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.5.output.dense.bias', 'base_model.encoder.layer.8.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.9.attention.output.LayerNorm.weight', 'base_model.encoder.layer.11.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.1.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.19.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.5.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.9.output.dense.weight', 'base_model.encoder.layer.9.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.0.attention.output.LayerNorm.bias', 'base_model.encoder.layer.22.output.dense.bias', 'base_model.encoder.layer.12.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.10.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.23.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.15.output.dense.weight', 'base_model.embeddings.position_ids', 'base_model.encoder.layer.8.intermediate.dense.bias', 'base_model.encoder.layer.5.attention.output.dense.bias', 'base_model.encoder.layer.17.attention.self.value.weight', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.23.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.14.intermediate.dense.bias', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.23.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.9.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.13.attention.output.LayerNorm.weight', 'base_model.encoder.layer.21.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.15.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.12.output.dense.weight', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.17.attention.output.LayerNorm.bias', 'base_model.encoder.layer.7.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.5.attention.self.query.weight', 'base_model.encoder.layer.8.output.dense.weight', 'base_model.encoder.layer.0.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.7.output.dense.weight', 'base_model.encoder.layer.18.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.23.attention.self.key.weight', 'base_model.encoder.layer.21.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.14.attention.self.key.weight', 'base_model.encoder.layer.3.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.4.attention.self.query.weight', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.1.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.1.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.7.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.20.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.17.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.20.output.LayerNorm.weight', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.6.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.14.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.22.attention.output.LayerNorm.bias', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.16.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.2.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.23.output.dense.bias', 'base_model.encoder.layer.20.attention.output.dense.bias', 'base_model.encoder.layer.15.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.23.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.5.attention.output.LayerNorm.bias', 'base_model.encoder.layer.13.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.14.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.5.attention.self.key.weight', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.21.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.10.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.22.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.23.attention.output.LayerNorm.bias', 'base_model.encoder.layer.5.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.16.attention.output.LayerNorm.weight', 'base_model.encoder.layer.4.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.5.output.LayerNorm.bias', 'base_model.encoder.layer.8.attention.self.query.bias', 'base_model.encoder.layer.18.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.11.attention.self.value.weight', 'base_model.encoder.layer.3.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.13.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.21.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.15.attention.output.LayerNorm.weight', 'base_model.encoder.layer.3.intermediate.dense.weight', 'base_model.encoder.layer.2.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.7.attention.output.LayerNorm.weight', 'base_model.encoder.layer.18.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.10.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.7.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.14.attention.self.query.weight', 'base_model.encoder.layer.17.output.dense.bias', 'base_model.encoder.layer.13.attention.output.dense.bias', 'base_model.encoder.layer.13.intermediate.dense.weight', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.14.intermediate.dense.weight', 'base_model.encoder.layer.23.output.LayerNorm.bias', 'base_model.encoder.layer.11.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.16.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.3.intermediate.dense.bias', 'base_model.encoder.layer.17.intermediate.dense.bias', 'base_model.encoder.layer.0.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.8.attention.output.LayerNorm.weight', 'base_model.encoder.layer.19.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.4.attention.self.value.bias', 'base_model.encoder.layer.12.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.6.attention.self.value.bias', 'base_model.encoder.layer.17.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.20.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.13.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.12.attention.output.dense.bias', 'base_model.encoder.layer.16.attention.self.value.weight', 'base_model.encoder.layer.19.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.19.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.8.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.11.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.10.attention.self.value.weight', 'base_model.encoder.layer.23.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.6.attention.output.LayerNorm.weight', 'base_model.encoder.layer.8.output.dense.bias', 'base_model.encoder.layer.20.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.21.output.dense.bias', 'base_model.encoder.layer.8.output.LayerNorm.bias', 'base_model.encoder.layer.6.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.22.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.11.attention.output.LayerNorm.bias', 'base_model.encoder.layer.0.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.3.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.2.output.LayerNorm.weight', 'base_model.encoder.layer.19.output.dense.bias', 'base_model.encoder.layer.16.attention.self.value.bias', 'base_model.encoder.layer.3.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.14.attention.self.query.bias', 'base_model.encoder.layer.16.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.23.intermediate.dense.bias', 'base_model.encoder.layer.18.intermediate.dense.weight', 'base_model.encoder.layer.18.attention.self.query.weight', 'base_model.encoder.layer.22.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.15.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.16.output.dense.weight', 'base_model.encoder.layer.7.attention.self.query.bias', 'base_model.encoder.layer.14.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.15.intermediate.dense.weight', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.10.attention.output.LayerNorm.bias', 'base_model.encoder.layer.11.attention.self.value.bias', 'base_model.encoder.layer.7.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.9.output.LayerNorm.bias', 'base_model.encoder.layer.11.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.15.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.8.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.5.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.2.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.6.attention.self.query.weight', 'base_model.encoder.layer.20.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.19.attention.output.dense.bias', 'base_model.encoder.layer.19.attention.self.query.bias', 'base_model.encoder.layer.20.attention.self.key.bias', 'base_model.encoder.layer.5.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.9.attention.output.dense.bias', 'base_model.encoder.layer.13.attention.output.LayerNorm.bias', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.6.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.0.attention.self.value.bias', 'base_model.encoder.layer.9.output.dense.bias', 'base_model.encoder.layer.15.attention.self.key.bias', 'base_model.encoder.layer.17.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.15.intermediate.dense.bias', 'base_model.encoder.layer.3.attention.self.value.weight', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.16.output.LayerNorm.bias', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.21.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.13.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.22.attention.self.key.weight', 'base_model.encoder.layer.22.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.20.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.0.output.LayerNorm.bias', 'base_model.encoder.layer.12.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.18.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.1.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.5.intermediate.dense.weight', 'base_model.encoder.layer.15.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.5.output.dense.weight', 'base_model.encoder.layer.4.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.23.attention.self.key.bias', 'base_model.encoder.layer.11.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.0.attention.self.key.weight', 'base_model.encoder.layer.6.output.dense.bias', 'base_model.encoder.layer.2.intermediate.dense.bias', 'base_model.encoder.layer.6.attention.self.key.weight', 'base_model.encoder.layer.23.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.22.intermediate.dense.weight', 'base_model.encoder.layer.16.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.4.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.13.output.dense.bias', 'base_model.encoder.layer.12.intermediate.dense.bias', 'base_model.encoder.layer.19.intermediate.dense.bias', 'base_model.encoder.layer.2.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.5.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.14.attention.output.LayerNorm.weight', 'base_model.encoder.layer.1.intermediate.dense.bias', 'base_model.encoder.layer.1.attention.self.key.bias', 'base_model.encoder.layer.5.output.LayerNorm.weight', 'base_model.encoder.layer.17.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.23.attention.self.query.bias', 'base_model.encoder.layer.21.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.17.attention.output.dense.bias', 'base_model.encoder.layer.9.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.10.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.0.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.1.attention.output.LayerNorm.bias', 'base_model.encoder.layer.10.attention.output.dense.bias', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.14.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.6.intermediate.dense.weight', 'base_model.encoder.layer.3.attention.output.LayerNorm.weight', 'base_model.encoder.layer.17.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.11.output.LayerNorm.bias', 'base_model.encoder.layer.21.attention.self.value.weight', 'base_model.encoder.layer.22.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.21.attention.output.dense.bias', 'base_model.encoder.layer.23.output.LayerNorm.weight', 'base_model.encoder.layer.14.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.8.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.12.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.18.attention.output.LayerNorm.weight', 'base_model.encoder.layer.18.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.6.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.19.attention.output.dense.weight', 'base_model.encoder.layer.21.intermediate.dense.bias', 'base_model.encoder.layer.20.output.dense.weight', 'base_model.encoder.layer.16.intermediate.dense.bias', 'base_model.encoder.layer.7.attention.self.value.weight', 'base_model.encoder.layer.21.intermediate.dense.weight', 'base_model.encoder.layer.15.output.dense.bias', 'base_model.encoder.layer.3.attention.self.query.bias', 'base_model.encoder.layer.13.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.10.attention.output.LayerNorm.weight', 'base_model.encoder.layer.7.intermediate.dense.weight', 'base_model.encoder.layer.20.attention.self.key.weight', 'base_model.encoder.layer.3.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.9.attention.self.query.weight', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.9.intermediate.dense.bias', 'base_model.encoder.layer.21.output.dense.weight', 'base_model.encoder.layer.11.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.3.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.23.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.3.attention.output.dense.weight', 'base_model.encoder.layer.16.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.0.output.dense.weight', 'base_model.encoder.layer.10.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.12.attention.self.query.weight', 'base_model.encoder.layer.6.output.LayerNorm.bias', 'base_model.encoder.layer.18.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.13.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.21.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.5.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.13.output.LayerNorm.bias', 'base_model.encoder.layer.15.attention.self.key.weight', 'base_model.encoder.layer.3.attention.output.dense.bias', 'base_model.encoder.layer.13.attention.self.value.weight', 'base_model.encoder.layer.18.output.LayerNorm.weight', 'base_model.encoder.layer.4.attention.output.LayerNorm.weight', 'base_model.encoder.layer.10.output.dense.bias', 'base_model.encoder.layer.8.attention.self.query.weight', 'base_model.encoder.layer.11.output.dense.weight', 'base_model.encoder.layer.19.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.22.intermediate.dense.bias', 'base_model.encoder.layer.0.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.22.attention.self.query.weight', 'base_model.encoder.layer.10.attention.self.key.bias', 'base_model.embeddings.token_type_embeddings.weight', 'base_model.encoder.layer.14.output.LayerNorm.weight', 'base_model.encoder.layer.11.output.LayerNorm.weight', 'base_model.encoder.layer.11.attention.self.query.weight', 'base_model.encoder.layer.9.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.6.output.LayerNorm.weight', 'base_model.encoder.layer.12.attention.self.key.bias', 'base_model.encoder.layer.1.attention.self.value.weight', 'base_model.embeddings.word_embeddings.weight', 'base_model.encoder.layer.10.output.dense.weight', 'base_model.encoder.layer.21.output.LayerNorm.bias', 'base_model.encoder.layer.0.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.1.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.15.attention.self.query.bias', 'base_model.encoder.layer.18.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.21.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.15.attention.self.query.weight', 'base_model.encoder.layer.9.attention.self.query.bias', 'base_model.encoder.layer.0.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.6.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.4.attention.output.dense.weight', 'base_model.encoder.layer.8.attention.output.LayerNorm.bias', 'base_model.encoder.layer.11.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.19.output.LayerNorm.weight', 'base_model.encoder.layer.20.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.18.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.1.output.LayerNorm.bias', 'base_model.encoder.layer.7.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.pooler.dense.bias', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.9.attention.output.LayerNorm.bias', 'base_model.encoder.layer.9.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.13.output.LayerNorm.weight', 'base_model.encoder.layer.17.attention.self.query.bias', 'base_model.encoder.layer.12.intermediate.dense.weight', 'base_model.encoder.layer.21.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.10.output.LayerNorm.bias', 'base_model.encoder.layer.10.intermediate.dense.weight', 'base_model.encoder.layer.19.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.23.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.2.attention.output.LayerNorm.weight', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.20.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.10.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.14.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.12.attention.self.query.bias', 'base_model.encoder.layer.3.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.14.attention.self.value.bias', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.3.output.LayerNorm.bias', 'base_model.encoder.layer.21.attention.self.value.bias', 'base_model.encoder.layer.17.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.18.attention.self.query.bias', 'base_model.encoder.layer.13.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.18.attention.self.value.weight', 'base_model.encoder.layer.1.output.dense.weight', 'base_model.encoder.layer.3.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.16.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.23.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.23.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.9.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.16.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.11.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.8.attention.output.dense.weight', 'base_model.encoder.layer.6.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.23.attention.output.LayerNorm.weight', 'base_model.encoder.layer.6.attention.output.dense.weight', 'base_model.encoder.layer.6.intermediate.dense.bias', 'base_model.encoder.layer.0.attention.output.dense.weight', 'base_model.encoder.layer.12.attention.self.value.weight', 'base_model.encoder.layer.12.attention.self.key.weight', 'base_model.encoder.layer.15.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.21.attention.self.key.bias', 'base_model.encoder.layer.7.attention.self.key.weight', 'base_model.encoder.layer.21.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.16.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.7.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.16.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.0.intermediate.dense.bias', 'base_model.encoder.layer.9.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.17.intermediate.dense.weight', 'base_model.encoder.layer.20.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.12.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.22.attention.output.dense.bias', 'base_model.encoder.layer.19.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.19.attention.self.value.weight', 'base_model.encoder.layer.20.intermediate.dense.weight', 'base_model.encoder.layer.18.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.7.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.1.intermediate.dense.weight', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.22.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.12.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.5.attention.self.value.bias', 'base_model.encoder.layer.10.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.16.output.dense.bias', 'base_model.encoder.layer.19.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.3.output.dense.weight', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.23.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.21.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.7.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.3.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.6.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.18.attention.self.value.bias', 'base_model.encoder.layer.4.intermediate.dense.weight', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.1.attention.self.query.weight', 'base_model.encoder.layer.22.attention.output.LayerNorm.weight', 'base_model.encoder.layer.8.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.16.intermediate.dense.weight', 'base_model.encoder.layer.6.output.dense.weight', 'base_model.encoder.layer.23.output.dense.weight', 'base_model.encoder.layer.23.intermediate.dense.weight', 'base_model.encoder.layer.22.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.0.attention.self.query.weight', 'base_model.encoder.layer.8.attention.self.key.weight', 'base_model.encoder.layer.0.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.8.attention.self.value.bias', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.19.attention.output.LayerNorm.bias', 'base_model.encoder.layer.16.attention.self.query.bias', 'base_model.encoder.layer.0.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.2.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.18.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.7.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.11.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.14.output.dense.bias', 'base_model.encoder.layer.4.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.10.attention.self.query.bias', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.14.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.1.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.3.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.4.output.LayerNorm.bias', 'base_model.encoder.layer.4.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.11.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.14.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.18.attention.self.key.weight', 'base_model.encoder.layer.16.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.22.attention.self.value.bias', 'base_model.encoder.layer.8.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.5.attention.output.dense.weight', 'base_model.encoder.layer.15.output.LayerNorm.bias', 'base_model.encoder.layer.10.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.20.attention.self.value.bias', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.1.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.14.attention.self.value.weight', 'base_model.encoder.layer.19.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.12.attention.output.dense.weight', 'base_model.encoder.layer.4.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.12.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.10.attention.output.dense.weight', 'base_model.encoder.layer.11.attention.output.LayerNorm.weight', 'base_model.encoder.layer.16.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.19.attention.output.LayerNorm.weight', 'base_model.encoder.layer.4.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.6.attention.self.query.bias', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.1.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.20.attention.self.value.weight', 'base_model.encoder.layer.18.intermediate.dense.bias', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.6.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.0.attention.self.value.weight', 'base_model.encoder.layer.2.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.18.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.14.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.23.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.9.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.1.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.4.output.LayerNorm.weight', 'base_model.encoder.layer.2.intermediate.dense.weight', 'base_model.encoder.layer.6.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.12.attention.self.value.bias', 'base_model.encoder.layer.22.output.LayerNorm.weight', 'base_model.encoder.layer.5.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.21.attention.self.query.weight', 'base_model.encoder.layer.8.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.7.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.23.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.9.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.11.attention.self.key.bias', 'base_model.encoder.layer.7.intermediate.dense.bias', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.0.output.dense.bias', 'base_model.encoder.layer.11.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.10.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.18.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.14.attention.self.key.bias', 'base_model.encoder.layer.4.attention.output.dense.bias', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.10.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.8.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.5.attention.self.query.bias', 'base_model.encoder.layer.18.attention.output.dense.weight', 'base_model.encoder.layer.2.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.1.attention.output.dense.weight', 'qa_outputs.bias', 'base_model.encoder.layer.10.intermediate.dense.bias', 'base_model.encoder.layer.13.attention.self.query.weight', 'base_model.encoder.layer.8.intermediate.dense.weight', 'base_model.encoder.layer.6.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.18.attention.output.dense.bias', 'base_model.encoder.layer.19.attention.self.query.weight', 'base_model.encoder.layer.9.attention.self.key.weight', 'base_model.encoder.layer.8.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.13.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.20.output.dense.bias', 'base_model.encoder.layer.13.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.3.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.5.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.20.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.17.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.12.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.0.attention.output.LayerNorm.weight', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.2.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.19.output.dense.weight', 'base_model.encoder.layer.12.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.6.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.18.attention.output.LayerNorm.bias', 'base_model.encoder.layer.2.attention.output.dense.weight', 'base_model.encoder.layer.6.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.5.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.14.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.17.attention.output.LayerNorm.weight', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.5.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.16.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.14.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.17.output.LayerNorm.bias', 'base_model.encoder.layer.20.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.16.attention.self.key.bias', 'base_model.encoder.layer.13.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.4.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.19.intermediate.dense.weight']
- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of XLMRobertaModel were not initialized from the model checkpoint at /cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//squad/xlm-KG_LR4e-5_EPOCH2.0_maxlen384_batchsize4_gradacc8 and are newly initialized: ['encoder.layer.5.attention.self.key.bias', 'encoder.layer.10.attention.self.key.bias', 'encoder.layer.15.attention.output.dense.bias', 'encoder.layer.14.intermediate.dense.weight', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.9.attention.output.dense.weight', 'encoder.layer.10.output.LayerNorm.weight', 'encoder.layer.9.attention.self.value.bias', 'encoder.layer.1.attention.self.value.bias', 'encoder.layer.13.intermediate.dense.bias', 'encoder.layer.14.attention.self.key.weight', 'encoder.layer.3.attention.output.dense.weight', 'encoder.layer.17.output.LayerNorm.weight', 'encoder.layer.13.attention.output.dense.weight', 'encoder.layer.20.attention.output.dense.bias', 'encoder.layer.13.intermediate.dense.weight', 'encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.5.attention.self.key.weight', 'encoder.layer.18.attention.output.dense.weight', 'encoder.layer.20.attention.self.query.bias', 'encoder.layer.20.output.LayerNorm.weight', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.18.attention.self.query.weight', 'encoder.layer.20.attention.output.dense.weight', 'encoder.layer.3.attention.output.dense.bias', 'encoder.layer.20.attention.self.key.weight', 'encoder.layer.23.attention.self.value.bias', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.9.attention.self.key.bias', 'encoder.layer.9.attention.self.value.weight', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.2.output.dense.bias', 'encoder.layer.2.attention.self.value.weight', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.12.attention.self.key.weight', 'encoder.layer.13.attention.output.LayerNorm.weight', 'encoder.layer.21.attention.self.query.bias', 'encoder.layer.8.attention.output.dense.bias', 'encoder.layer.5.attention.self.query.bias', 'encoder.layer.19.output.dense.weight', 'encoder.layer.8.output.dense.bias', 'encoder.layer.6.output.dense.weight', 'encoder.layer.6.attention.output.dense.bias', 'encoder.layer.13.attention.self.query.weight', 'encoder.layer.18.attention.self.key.weight', 'encoder.layer.19.attention.output.dense.bias', 'encoder.layer.5.attention.self.value.weight', 'encoder.layer.13.attention.self.query.bias', 'encoder.layer.11.output.LayerNorm.weight', 'encoder.layer.23.intermediate.dense.weight', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.11.attention.self.query.bias', 'encoder.layer.15.attention.self.value.weight', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.19.attention.output.LayerNorm.weight', 'encoder.layer.6.attention.self.query.weight', 'encoder.layer.12.attention.self.query.bias', 'encoder.layer.11.attention.self.value.bias', 'encoder.layer.1.output.dense.bias', 'encoder.layer.10.attention.output.dense.bias', 'encoder.layer.5.output.LayerNorm.bias', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.19.attention.self.key.bias', 'encoder.layer.7.attention.self.key.bias', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.20.attention.self.query.weight', 'encoder.layer.4.attention.self.key.weight', 'embeddings.word_embeddings.weight', 'encoder.layer.12.attention.output.LayerNorm.weight', 'encoder.layer.2.attention.output.LayerNorm.bias', 'encoder.layer.14.output.dense.weight', 'encoder.layer.23.attention.output.LayerNorm.weight', 'encoder.layer.2.attention.self.value.bias', 'encoder.layer.17.attention.self.query.weight', 'encoder.layer.17.intermediate.dense.bias', 'encoder.layer.4.attention.output.dense.weight', 'encoder.layer.6.attention.self.value.weight', 'encoder.layer.18.attention.self.key.bias', 'encoder.layer.18.attention.self.value.bias', 'encoder.layer.14.output.LayerNorm.bias', 'encoder.layer.13.attention.output.dense.bias', 'embeddings.LayerNorm.weight', 'encoder.layer.5.attention.self.value.bias', 'encoder.layer.6.attention.self.value.bias', 'encoder.layer.19.intermediate.dense.bias', 'encoder.layer.9.attention.self.query.bias', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.8.attention.output.dense.weight', 'encoder.layer.7.attention.self.query.bias', 'encoder.layer.11.output.dense.weight', 'encoder.layer.1.attention.self.key.bias', 'encoder.layer.4.attention.output.dense.bias', 'encoder.layer.3.output.dense.bias', 'encoder.layer.23.attention.self.value.weight', 'encoder.layer.22.intermediate.dense.weight', 'encoder.layer.16.output.dense.bias', 'encoder.layer.13.output.LayerNorm.bias', 'encoder.layer.19.attention.self.value.bias', 'encoder.layer.16.attention.output.dense.bias', 'encoder.layer.2.attention.output.dense.bias', 'encoder.layer.18.intermediate.dense.bias', 'encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.layer.1.output.dense.weight', 'encoder.layer.5.attention.self.query.weight', 'encoder.layer.12.output.LayerNorm.bias', 'encoder.layer.21.attention.self.key.bias', 'encoder.layer.1.attention.output.dense.weight', 'encoder.layer.15.attention.output.dense.weight', 'encoder.layer.12.attention.self.value.bias', 'encoder.layer.1.attention.self.key.weight', 'encoder.layer.0.attention.self.query.bias', 'encoder.layer.11.attention.output.dense.weight', 'encoder.layer.0.attention.output.LayerNorm.weight', 'encoder.layer.3.output.dense.weight', 'encoder.layer.14.attention.self.value.weight', 'encoder.layer.9.attention.output.LayerNorm.weight', 'encoder.layer.16.attention.self.key.weight', 'encoder.layer.0.attention.self.value.bias', 'encoder.layer.0.attention.output.dense.bias', 'encoder.layer.9.attention.output.LayerNorm.bias', 'encoder.layer.4.attention.self.query.bias', 'encoder.layer.17.output.dense.weight', 'encoder.layer.6.attention.output.LayerNorm.bias', 'encoder.layer.18.attention.self.query.bias', 'encoder.layer.17.attention.self.query.bias', 'encoder.layer.4.attention.self.value.weight', 'encoder.layer.4.attention.output.LayerNorm.weight', 'encoder.layer.23.attention.output.dense.bias', 'encoder.layer.22.attention.self.value.bias', 'encoder.layer.10.attention.self.query.weight', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.18.attention.output.LayerNorm.weight', 'encoder.layer.21.intermediate.dense.bias', 'encoder.layer.3.attention.self.value.bias', 'encoder.layer.14.attention.output.LayerNorm.weight', 'encoder.layer.22.output.LayerNorm.weight', 'encoder.layer.9.attention.self.query.weight', 'encoder.layer.8.attention.self.key.bias', 'encoder.layer.17.attention.output.dense.bias', 'encoder.layer.14.attention.output.dense.weight', 'encoder.layer.11.output.LayerNorm.bias', 'encoder.layer.3.attention.self.value.weight', 'encoder.layer.15.output.dense.bias', 'pooler.dense.weight', 'encoder.layer.5.attention.output.dense.weight', 'encoder.layer.16.intermediate.dense.weight', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.10.attention.output.LayerNorm.weight', 'encoder.layer.13.output.LayerNorm.weight', 'encoder.layer.19.intermediate.dense.weight', 'encoder.layer.18.intermediate.dense.weight', 'encoder.layer.21.attention.output.dense.bias', 'encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.layer.10.attention.self.value.weight', 'encoder.layer.2.attention.self.key.bias', 'encoder.layer.8.attention.self.query.bias', 'encoder.layer.22.attention.output.LayerNorm.weight', 'encoder.layer.8.attention.self.key.weight', 'encoder.layer.11.output.dense.bias', 'encoder.layer.10.output.dense.weight', 'encoder.layer.8.attention.self.value.bias', 'encoder.layer.16.output.dense.weight', 'encoder.layer.5.attention.output.dense.bias', 'encoder.layer.4.attention.self.query.weight', 'encoder.layer.6.attention.output.LayerNorm.weight', 'encoder.layer.14.attention.output.dense.bias', 'encoder.layer.7.attention.self.value.weight', 'encoder.layer.6.attention.output.dense.weight', 'encoder.layer.8.attention.output.LayerNorm.weight', 'encoder.layer.17.attention.output.dense.weight', 'encoder.layer.15.attention.self.key.weight', 'encoder.layer.19.attention.output.LayerNorm.bias', 'encoder.layer.11.attention.self.key.bias', 'encoder.layer.12.output.LayerNorm.weight', 'encoder.layer.8.output.LayerNorm.bias', 'encoder.layer.12.attention.output.LayerNorm.bias', 'encoder.layer.22.attention.output.LayerNorm.bias', 'encoder.layer.19.attention.self.key.weight', 'encoder.layer.23.output.LayerNorm.weight', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.4.output.dense.weight', 'encoder.layer.12.intermediate.dense.bias', 'encoder.layer.20.attention.output.LayerNorm.bias', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.23.attention.self.query.weight', 'encoder.layer.14.attention.self.query.weight', 'encoder.layer.17.attention.self.key.weight', 'encoder.layer.20.attention.output.LayerNorm.weight', 'encoder.layer.2.attention.output.dense.weight', 'encoder.layer.5.attention.output.LayerNorm.weight', 'encoder.layer.21.output.LayerNorm.weight', 'encoder.layer.0.attention.self.query.weight', 'encoder.layer.23.attention.self.key.weight', 'encoder.layer.21.attention.output.dense.weight', 'encoder.layer.23.output.dense.weight', 'encoder.layer.6.output.dense.bias', 'encoder.layer.7.output.LayerNorm.weight', 'encoder.layer.16.attention.output.LayerNorm.bias', 'encoder.layer.16.attention.output.LayerNorm.weight', 'encoder.layer.13.attention.self.key.bias', 'encoder.layer.11.attention.output.dense.bias', 'encoder.layer.16.output.LayerNorm.bias', 'encoder.layer.9.output.LayerNorm.weight', 'encoder.layer.6.attention.self.key.bias', 'encoder.layer.14.intermediate.dense.bias', 'encoder.layer.4.attention.self.value.bias', 'encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.0.output.dense.weight', 'encoder.layer.20.output.dense.weight', 'encoder.layer.1.attention.output.LayerNorm.weight', 'encoder.layer.0.attention.self.key.weight', 'encoder.layer.14.attention.self.query.bias', 'encoder.layer.11.attention.self.value.weight', 'encoder.layer.18.output.LayerNorm.bias', 'embeddings.LayerNorm.bias', 'encoder.layer.17.output.LayerNorm.bias', 'encoder.layer.22.attention.self.query.weight', 'encoder.layer.1.attention.self.value.weight', 'encoder.layer.22.output.dense.weight', 'encoder.layer.15.output.LayerNorm.weight', 'encoder.layer.15.attention.self.query.bias', 'encoder.layer.0.attention.output.dense.weight', 'encoder.layer.16.attention.self.key.bias', 'encoder.layer.13.output.dense.weight', 'encoder.layer.4.output.dense.bias', 'encoder.layer.17.attention.self.key.bias', 'encoder.layer.13.attention.self.key.weight', 'encoder.layer.22.attention.output.dense.bias', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.15.attention.self.key.bias', 'encoder.layer.18.attention.self.value.weight', 'encoder.layer.17.output.dense.bias', 'encoder.layer.7.attention.output.LayerNorm.bias', 'encoder.layer.16.attention.self.query.weight', 'encoder.layer.7.attention.self.key.weight', 'encoder.layer.7.output.dense.bias', 'encoder.layer.23.output.dense.bias', 'encoder.layer.7.output.dense.weight', 'encoder.layer.11.attention.output.LayerNorm.weight', 'encoder.layer.13.attention.self.value.bias', 'encoder.layer.19.output.LayerNorm.weight', 'encoder.layer.7.attention.output.dense.bias', 'encoder.layer.16.attention.output.dense.weight', 'encoder.layer.20.attention.self.value.bias', 'encoder.layer.21.attention.output.LayerNorm.weight', 'encoder.layer.21.attention.output.LayerNorm.bias', 'encoder.layer.7.attention.output.dense.weight', 'encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.1.attention.output.dense.bias', 'encoder.layer.12.output.dense.weight', 'encoder.layer.6.attention.self.query.bias', 'pooler.dense.bias', 'encoder.layer.10.attention.self.value.bias', 'encoder.layer.13.attention.output.LayerNorm.bias', 'encoder.layer.15.output.dense.weight', 'encoder.layer.21.attention.self.value.weight', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.21.attention.self.key.weight', 'encoder.layer.12.attention.self.key.bias', 'encoder.layer.20.output.LayerNorm.bias', 'encoder.layer.15.output.LayerNorm.bias', 'encoder.layer.19.attention.self.value.weight', 'encoder.layer.1.attention.self.query.bias', 'encoder.layer.10.intermediate.dense.weight', 'encoder.layer.3.attention.self.query.weight', 'encoder.layer.18.output.dense.weight', 'encoder.layer.12.attention.self.value.weight', 'encoder.layer.12.output.dense.bias', 'encoder.layer.10.output.dense.bias', 'encoder.layer.16.output.LayerNorm.weight', 'encoder.layer.0.attention.self.value.weight', 'encoder.layer.18.attention.output.LayerNorm.bias', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.8.output.dense.weight', 'encoder.layer.15.intermediate.dense.bias', 'encoder.layer.13.output.dense.bias', 'encoder.layer.20.attention.self.value.weight', 'encoder.layer.20.intermediate.dense.bias', 'encoder.layer.19.output.dense.bias', 'encoder.layer.16.intermediate.dense.bias', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.10.attention.self.query.bias', 'encoder.layer.6.output.LayerNorm.bias', 'embeddings.token_type_embeddings.weight', 'encoder.layer.9.output.LayerNorm.bias', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.18.attention.output.dense.bias', 'encoder.layer.18.output.LayerNorm.weight', 'encoder.layer.23.attention.output.dense.weight', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.23.attention.self.query.bias', 'encoder.layer.15.intermediate.dense.weight', 'encoder.layer.21.intermediate.dense.weight', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.22.attention.self.key.weight', 'encoder.layer.9.output.dense.weight', 'encoder.layer.14.attention.output.LayerNorm.bias', 'encoder.layer.19.attention.self.query.weight', 'encoder.layer.11.attention.self.query.weight', 'encoder.layer.2.output.dense.weight', 'encoder.layer.16.attention.self.query.bias', 'encoder.layer.7.output.LayerNorm.bias', 'encoder.layer.12.intermediate.dense.weight', 'encoder.layer.17.intermediate.dense.weight', 'encoder.layer.12.attention.self.query.weight', 'encoder.layer.3.attention.self.key.bias', 'encoder.layer.20.output.dense.bias', 'encoder.layer.5.output.dense.weight', 'encoder.layer.4.attention.self.key.bias', 'encoder.layer.23.intermediate.dense.bias', 'encoder.layer.21.attention.self.value.bias', 'encoder.layer.15.attention.self.value.bias', 'encoder.layer.1.attention.self.query.weight', 'encoder.layer.8.output.LayerNorm.weight', 'encoder.layer.15.attention.output.LayerNorm.weight', 'encoder.layer.7.intermediate.dense.bias', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.14.attention.self.key.bias', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.22.intermediate.dense.bias', 'encoder.layer.16.attention.self.value.weight', 'encoder.layer.16.attention.self.value.bias', 'encoder.layer.20.attention.self.key.bias', 'encoder.layer.17.attention.self.value.bias', 'encoder.layer.23.attention.self.key.bias', 'encoder.layer.19.attention.self.query.bias', 'encoder.layer.7.attention.output.LayerNorm.weight', 'encoder.layer.10.output.LayerNorm.bias', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.18.output.dense.bias', 'encoder.layer.11.attention.self.key.weight', 'encoder.layer.23.output.LayerNorm.bias', 'encoder.layer.14.output.LayerNorm.weight', 'encoder.layer.17.attention.output.LayerNorm.weight', 'encoder.layer.9.attention.self.key.weight', 'encoder.layer.15.attention.output.LayerNorm.bias', 'encoder.layer.22.output.dense.bias', 'encoder.layer.2.attention.self.query.bias', 'encoder.layer.2.attention.self.query.weight', 'encoder.layer.3.attention.self.query.bias', 'encoder.layer.3.attention.self.key.weight', 'encoder.layer.2.attention.output.LayerNorm.weight', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.22.attention.self.query.bias', 'encoder.layer.22.attention.output.dense.weight', 'encoder.layer.7.attention.self.query.weight', 'encoder.layer.5.output.dense.bias', 'encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.19.output.LayerNorm.bias', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.10.attention.self.key.weight', 'encoder.layer.6.attention.self.key.weight', 'encoder.layer.0.output.dense.bias', 'encoder.layer.21.output.dense.weight', 'encoder.layer.22.attention.self.value.weight', 'encoder.layer.2.intermediate.dense.bias', 'embeddings.position_embeddings.weight', 'encoder.layer.21.output.LayerNorm.bias', 'encoder.layer.12.attention.output.dense.bias', 'encoder.layer.8.attention.output.LayerNorm.bias', 'encoder.layer.8.attention.self.query.weight', 'encoder.layer.14.attention.self.value.bias', 'encoder.layer.9.output.dense.bias', 'encoder.layer.13.attention.self.value.weight', 'encoder.layer.20.intermediate.dense.weight', 'encoder.layer.10.attention.output.LayerNorm.bias', 'encoder.layer.8.attention.self.value.weight', 'encoder.layer.4.attention.output.LayerNorm.bias', 'encoder.layer.23.attention.output.LayerNorm.bias', 'encoder.layer.21.output.dense.bias', 'encoder.layer.9.attention.output.dense.bias', 'encoder.layer.22.output.LayerNorm.bias', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.0.attention.self.key.bias', 'encoder.layer.7.attention.self.value.bias', 'encoder.layer.22.attention.self.key.bias', 'encoder.layer.15.attention.self.query.weight', 'encoder.layer.17.attention.self.value.weight', 'encoder.layer.2.attention.self.key.weight', 'encoder.layer.14.output.dense.bias', 'encoder.layer.19.attention.output.dense.weight', 'encoder.layer.17.attention.output.LayerNorm.bias', 'encoder.layer.21.attention.self.query.weight', 'encoder.layer.10.attention.output.dense.weight', 'encoder.layer.12.attention.output.dense.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Overwriting existing adapter 'ep'.
Overwriting existing adapter 'tp'.
Overwriting existing adapter 'es'.
Overwriting existing adapter 'ts'.
Overwriting existing adapter fusion module 'ep,tp,es,ts'
05/09/2022 20:16:56 - INFO - __main__ -   lang2id = None
05/09/2022 20:17:00 - INFO - __main__ -   Training/evaluation parameters Namespace(adam_epsilon=1e-08, cache_dir='', config_name='', data_dir=None, device=device(type='cuda'), do_eval=True, do_lower_case=False, do_train=False, doc_stride=128, eval_all_checkpoints=False, eval_lang='hi', evaluate_during_training=False, fp16=False, fp16_opt_level='O1', gradient_accumulation_steps=1, learning_rate=5e-05, local_rank=-1, logging_steps=50, max_answer_length=30, max_grad_norm=1.0, max_query_length=64, max_seq_length=384, max_steps=-1, model_name='xlm-KG', model_name_or_path='/cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//squad/xlm-KG_LR4e-5_EPOCH2.0_maxlen384_batchsize4_gradacc8', model_type='xlm', modelkg_dir='/cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/adapter/xlmr_adapter', n_best_size=20, n_gpu=1, no_cuda=False, null_score_diff_threshold=0.0, num_train_epochs=3.0, output_dir='/cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//squad/xlm-KG_LR4e-5_EPOCH2.0_maxlen384_batchsize4_gradacc8/predictions/xquad/', overwrite_cache=False, overwrite_output_dir=False, per_gpu_eval_batch_size=8, per_gpu_train_batch_size=8, predict_file='/cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/download//xquad//xquad.hi.json', save_steps=50, seed=42, server_ip='', server_port='', threads=1, tokenizer_name='', train_file=None, train_lang='en', verbose_logging=False, version_2_with_negative=False, warmup_steps=0, weight_decay=0.0)
05/09/2022 20:17:00 - INFO - __main__ -   Loading checkpoint /cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//squad/xlm-KG_LR4e-5_EPOCH2.0_maxlen384_batchsize4_gradacc8 for evaluation
05/09/2022 20:17:00 - INFO - __main__ -   Evaluate the following checkpoints: ['/cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//squad/xlm-KG_LR4e-5_EPOCH2.0_maxlen384_batchsize4_gradacc8']
Some weights of the model checkpoint at /cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//squad/xlm-KG_LR4e-5_EPOCH2.0_maxlen384_batchsize4_gradacc8 were not used when initializing XLMRobertaModel: ['base_model.encoder.layer.8.attention.output.dense.bias', 'base_model.encoder.layer.13.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.22.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.1.attention.output.LayerNorm.weight', 'base_model.encoder.layer.20.attention.self.query.weight', 'base_model.encoder.layer.8.output.LayerNorm.weight', 'base_model.encoder.layer.13.attention.self.value.bias', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.pooler.dense.weight', 'base_model.encoder.layer.2.attention.output.LayerNorm.bias', 'base_model.encoder.layer.4.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.16.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.19.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.19.attention.self.key.bias', 'base_model.encoder.layer.1.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.23.attention.self.query.weight', 'base_model.encoder.layer.2.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.22.attention.self.query.bias', 'base_model.encoder.layer.9.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.13.attention.output.dense.weight', 'base_model.encoder.layer.5.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.15.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.1.attention.self.query.bias', 'base_model.encoder.layer.10.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.4.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.4.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.14.output.LayerNorm.bias', 'base_model.encoder.layer.0.attention.output.dense.bias', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.6.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.21.output.LayerNorm.weight', 'base_model.encoder.layer.23.attention.output.dense.bias', 'base_model.encoder.layer.5.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.23.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.20.intermediate.dense.bias', 'base_model.encoder.layer.12.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.12.attention.output.LayerNorm.weight', 'base_model.encoder.layer.2.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.13.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.16.attention.self.query.weight', 'base_model.encoder.layer.23.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.3.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.4.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.14.attention.output.dense.weight', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.0.output.LayerNorm.weight', 'base_model.encoder.layer.9.intermediate.dense.weight', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.22.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.7.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.9.attention.output.dense.weight', 'base_model.encoder.layer.7.output.dense.bias', 'base_model.encoder.layer.4.attention.output.LayerNorm.bias', 'base_model.encoder.layer.20.attention.output.LayerNorm.weight', 'qa_outputs.weight', 'base_model.encoder.layer.7.attention.output.dense.bias', 'base_model.encoder.layer.17.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.11.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.7.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.15.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.13.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.1.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.20.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.17.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.15.attention.output.LayerNorm.bias', 'base_model.encoder.layer.16.attention.self.key.weight', 'base_model.encoder.layer.2.output.dense.weight', 'base_model.encoder.layer.22.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.9.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.16.attention.output.dense.bias', 'base_model.encoder.layer.16.attention.output.LayerNorm.bias', 'base_model.encoder.layer.21.attention.self.query.bias', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.14.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.6.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.20.attention.self.query.bias', 'base_model.encoder.layer.4.output.dense.weight', 'base_model.encoder.layer.3.attention.self.key.bias', 'base_model.encoder.layer.22.output.LayerNorm.bias', 'base_model.encoder.layer.3.attention.self.value.bias', 'base_model.encoder.layer.0.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.21.attention.output.LayerNorm.weight', 'base_model.encoder.layer.1.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.19.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.12.output.LayerNorm.weight', 'base_model.encoder.layer.8.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.4.intermediate.dense.bias', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.9.attention.self.value.bias', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.16.attention.output.dense.weight', 'base_model.encoder.layer.17.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.15.attention.output.dense.weight', 'base_model.encoder.layer.18.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.3.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.18.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.6.attention.self.key.bias', 'base_model.encoder.layer.10.attention.self.key.weight', 'base_model.encoder.layer.13.attention.self.key.weight', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.4.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.12.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.22.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.7.attention.self.key.bias', 'base_model.encoder.layer.15.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.6.attention.output.LayerNorm.bias', 'base_model.encoder.layer.17.attention.self.key.weight', 'base_model.encoder.layer.15.attention.self.value.weight', 'base_model.encoder.layer.18.output.LayerNorm.bias', 'base_model.encoder.layer.15.attention.self.value.bias', 'base_model.encoder.layer.11.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.14.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.15.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.9.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.11.attention.output.dense.weight', 'base_model.encoder.layer.11.intermediate.dense.bias', 'base_model.encoder.layer.7.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.20.attention.output.LayerNorm.bias', 'base_model.encoder.layer.17.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.10.attention.self.query.weight', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.8.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.11.attention.output.dense.bias', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.0.attention.self.query.bias', 'base_model.encoder.layer.6.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.8.attention.self.key.bias', 'base_model.encoder.layer.8.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.1.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.2.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.11.intermediate.dense.weight', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.2.attention.self.value.weight', 'base_model.encoder.layer.4.attention.self.key.bias', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.15.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.12.output.dense.bias', 'base_model.encoder.layer.17.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.2.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.19.output.LayerNorm.bias', 'base_model.encoder.layer.21.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.21.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.8.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.19.attention.self.value.bias', 'base_model.encoder.layer.5.attention.output.LayerNorm.weight', 'base_model.encoder.layer.11.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.23.attention.self.value.bias', 'base_model.encoder.layer.14.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.20.output.LayerNorm.bias', 'base_model.encoder.layer.3.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.16.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.21.attention.output.LayerNorm.bias', 'base_model.encoder.layer.10.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.12.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.12.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.5.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.1.attention.output.dense.bias', 'base_model.encoder.layer.3.output.LayerNorm.weight', 'base_model.encoder.layer.22.output.dense.weight', 'base_model.encoder.layer.17.attention.output.dense.weight', 'base_model.encoder.layer.8.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.12.attention.output.LayerNorm.bias', 'base_model.encoder.layer.15.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.2.attention.output.dense.bias', 'base_model.encoder.layer.20.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.2.attention.self.key.bias', 'base_model.encoder.layer.5.attention.self.key.bias', 'base_model.encoder.layer.8.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.21.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.6.attention.self.value.weight', 'base_model.encoder.layer.7.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.0.intermediate.dense.weight', 'base_model.encoder.layer.2.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.22.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.7.attention.output.LayerNorm.bias', 'base_model.encoder.layer.4.attention.self.value.weight', 'base_model.encoder.layer.3.attention.self.query.weight', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.10.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.13.attention.self.query.bias', 'base_model.encoder.layer.7.attention.output.dense.weight', 'base_model.encoder.layer.7.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.13.output.dense.weight', 'base_model.encoder.layer.4.output.dense.bias', 'base_model.encoder.layer.2.output.dense.bias', 'base_model.encoder.layer.5.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.0.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.23.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.0.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.14.attention.output.dense.bias', 'base_model.encoder.layer.3.output.dense.bias', 'base_model.encoder.layer.18.output.dense.weight', 'base_model.encoder.layer.22.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.17.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.5.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.7.output.LayerNorm.weight', 'base_model.encoder.layer.1.attention.self.value.bias', 'base_model.encoder.layer.9.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.15.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.10.output.LayerNorm.weight', 'base_model.encoder.layer.19.attention.self.key.weight', 'base_model.encoder.layer.11.attention.self.key.weight', 'base_model.encoder.layer.15.attention.output.dense.bias', 'base_model.encoder.layer.6.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.15.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.22.attention.self.key.bias', 'base_model.encoder.layer.19.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.9.attention.self.value.weight', 'base_model.encoder.layer.17.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.20.attention.output.dense.weight', 'base_model.encoder.layer.3.attention.output.LayerNorm.bias', 'base_model.encoder.layer.18.output.dense.bias', 'base_model.encoder.layer.9.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.13.intermediate.dense.bias', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.8.attention.self.value.weight', 'base_model.encoder.layer.13.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.20.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.1.attention.self.key.weight', 'base_model.encoder.layer.9.output.LayerNorm.weight', 'base_model.encoder.layer.17.attention.self.key.bias', 'base_model.encoder.layer.22.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.12.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.18.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.17.output.LayerNorm.weight', 'base_model.encoder.layer.22.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.16.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.20.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.10.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.16.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.15.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.10.attention.self.value.bias', 'base_model.encoder.layer.1.output.LayerNorm.weight', 'base_model.encoder.layer.22.attention.output.dense.weight', 'base_model.encoder.layer.3.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.1.output.dense.bias', 'base_model.encoder.layer.15.output.LayerNorm.weight', 'base_model.encoder.layer.14.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.7.output.LayerNorm.bias', 'base_model.encoder.layer.17.attention.self.query.weight', 'base_model.encoder.layer.11.attention.self.query.bias', 'base_model.encoder.layer.8.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.12.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.7.attention.self.value.bias', 'base_model.encoder.layer.12.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.6.attention.output.dense.bias', 'base_model.encoder.layer.0.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.0.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.7.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.0.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.19.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.14.output.dense.weight', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.11.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.4.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.2.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.2.attention.self.query.bias', 'base_model.encoder.layer.21.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.5.intermediate.dense.bias', 'base_model.encoder.layer.22.attention.self.value.weight', 'base_model.encoder.layer.22.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.0.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.4.attention.self.query.bias', 'base_model.encoder.layer.9.attention.self.key.bias', 'base_model.encoder.layer.5.attention.self.value.weight', 'base_model.encoder.layer.2.output.LayerNorm.bias', 'base_model.encoder.layer.21.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.14.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.embeddings.position_embeddings.weight', 'base_model.encoder.layer.17.attention.self.value.bias', 'base_model.encoder.layer.20.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.10.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.4.attention.self.key.weight', 'base_model.encoder.layer.17.output.dense.weight', 'base_model.embeddings.LayerNorm.weight', 'base_model.embeddings.LayerNorm.bias', 'base_model.encoder.layer.15.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.14.attention.output.LayerNorm.bias', 'base_model.encoder.layer.11.output.dense.bias', 'base_model.encoder.layer.7.attention.self.query.weight', 'base_model.encoder.layer.21.attention.self.key.weight', 'base_model.encoder.layer.21.attention.output.dense.weight', 'base_model.encoder.layer.1.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.17.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.3.attention.self.key.weight', 'base_model.encoder.layer.11.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.2.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.18.attention.self.key.bias', 'base_model.encoder.layer.13.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.18.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.23.attention.self.value.weight', 'base_model.encoder.layer.19.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.9.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.4.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.17.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.3.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.1.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.0.attention.self.key.bias', 'base_model.encoder.layer.5.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.19.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.2.attention.self.key.weight', 'base_model.encoder.layer.1.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.20.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.13.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.13.attention.self.key.bias', 'base_model.encoder.layer.2.attention.self.value.bias', 'base_model.encoder.layer.16.output.LayerNorm.weight', 'base_model.encoder.layer.2.attention.self.query.weight', 'base_model.encoder.layer.12.output.LayerNorm.bias', 'base_model.encoder.layer.23.attention.output.dense.weight', 'base_model.encoder.layer.19.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.4.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.10.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.9.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.2.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.5.output.dense.bias', 'base_model.encoder.layer.8.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.9.attention.output.LayerNorm.weight', 'base_model.encoder.layer.11.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.1.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.19.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.5.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.9.output.dense.weight', 'base_model.encoder.layer.9.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.0.attention.output.LayerNorm.bias', 'base_model.encoder.layer.22.output.dense.bias', 'base_model.encoder.layer.12.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.10.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.23.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.15.output.dense.weight', 'base_model.embeddings.position_ids', 'base_model.encoder.layer.8.intermediate.dense.bias', 'base_model.encoder.layer.5.attention.output.dense.bias', 'base_model.encoder.layer.17.attention.self.value.weight', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.23.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.14.intermediate.dense.bias', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.23.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.9.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.13.attention.output.LayerNorm.weight', 'base_model.encoder.layer.21.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.15.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.12.output.dense.weight', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.17.attention.output.LayerNorm.bias', 'base_model.encoder.layer.7.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.5.attention.self.query.weight', 'base_model.encoder.layer.8.output.dense.weight', 'base_model.encoder.layer.0.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.7.output.dense.weight', 'base_model.encoder.layer.18.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.23.attention.self.key.weight', 'base_model.encoder.layer.21.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.14.attention.self.key.weight', 'base_model.encoder.layer.3.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.4.attention.self.query.weight', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.1.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.1.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.7.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.20.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.17.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.20.output.LayerNorm.weight', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.6.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.14.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.22.attention.output.LayerNorm.bias', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.16.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.2.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.23.output.dense.bias', 'base_model.encoder.layer.20.attention.output.dense.bias', 'base_model.encoder.layer.15.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.23.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.5.attention.output.LayerNorm.bias', 'base_model.encoder.layer.13.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.14.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.5.attention.self.key.weight', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.21.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.10.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.22.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.23.attention.output.LayerNorm.bias', 'base_model.encoder.layer.5.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.16.attention.output.LayerNorm.weight', 'base_model.encoder.layer.4.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.5.output.LayerNorm.bias', 'base_model.encoder.layer.8.attention.self.query.bias', 'base_model.encoder.layer.18.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.11.attention.self.value.weight', 'base_model.encoder.layer.3.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.13.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.21.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.15.attention.output.LayerNorm.weight', 'base_model.encoder.layer.3.intermediate.dense.weight', 'base_model.encoder.layer.2.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.7.attention.output.LayerNorm.weight', 'base_model.encoder.layer.18.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.10.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.7.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.14.attention.self.query.weight', 'base_model.encoder.layer.17.output.dense.bias', 'base_model.encoder.layer.13.attention.output.dense.bias', 'base_model.encoder.layer.13.intermediate.dense.weight', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.14.intermediate.dense.weight', 'base_model.encoder.layer.23.output.LayerNorm.bias', 'base_model.encoder.layer.11.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.16.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.3.intermediate.dense.bias', 'base_model.encoder.layer.17.intermediate.dense.bias', 'base_model.encoder.layer.0.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.8.attention.output.LayerNorm.weight', 'base_model.encoder.layer.19.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.4.attention.self.value.bias', 'base_model.encoder.layer.12.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.6.attention.self.value.bias', 'base_model.encoder.layer.17.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.20.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.13.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.12.attention.output.dense.bias', 'base_model.encoder.layer.16.attention.self.value.weight', 'base_model.encoder.layer.19.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.19.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.8.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.11.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.10.attention.self.value.weight', 'base_model.encoder.layer.23.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.6.attention.output.LayerNorm.weight', 'base_model.encoder.layer.8.output.dense.bias', 'base_model.encoder.layer.20.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.21.output.dense.bias', 'base_model.encoder.layer.8.output.LayerNorm.bias', 'base_model.encoder.layer.6.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.22.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.11.attention.output.LayerNorm.bias', 'base_model.encoder.layer.0.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.3.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.2.output.LayerNorm.weight', 'base_model.encoder.layer.19.output.dense.bias', 'base_model.encoder.layer.16.attention.self.value.bias', 'base_model.encoder.layer.3.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.9.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.14.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.14.attention.self.query.bias', 'base_model.encoder.layer.16.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.23.intermediate.dense.bias', 'base_model.encoder.layer.18.intermediate.dense.weight', 'base_model.encoder.layer.18.attention.self.query.weight', 'base_model.encoder.layer.22.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.23.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.15.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.16.output.dense.weight', 'base_model.encoder.layer.7.attention.self.query.bias', 'base_model.encoder.layer.14.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.15.intermediate.dense.weight', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.10.attention.output.LayerNorm.bias', 'base_model.encoder.layer.11.attention.self.value.bias', 'base_model.encoder.layer.7.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.9.output.LayerNorm.bias', 'base_model.encoder.layer.11.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.15.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.8.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.5.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.2.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.6.attention.self.query.weight', 'base_model.encoder.layer.20.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.19.attention.output.dense.bias', 'base_model.encoder.layer.19.attention.self.query.bias', 'base_model.encoder.layer.20.attention.self.key.bias', 'base_model.encoder.layer.5.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.9.attention.output.dense.bias', 'base_model.encoder.layer.13.attention.output.LayerNorm.bias', 'base_model.encoder.layer.21.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.6.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.0.attention.self.value.bias', 'base_model.encoder.layer.9.output.dense.bias', 'base_model.encoder.layer.15.attention.self.key.bias', 'base_model.encoder.layer.17.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.15.intermediate.dense.bias', 'base_model.encoder.layer.3.attention.self.value.weight', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.16.output.LayerNorm.bias', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.21.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.13.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.22.attention.self.key.weight', 'base_model.encoder.layer.22.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.20.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.0.output.LayerNorm.bias', 'base_model.encoder.layer.12.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.18.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.1.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.5.intermediate.dense.weight', 'base_model.encoder.layer.15.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.5.output.dense.weight', 'base_model.encoder.layer.4.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.23.attention.self.key.bias', 'base_model.encoder.layer.11.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.0.attention.self.key.weight', 'base_model.encoder.layer.6.output.dense.bias', 'base_model.encoder.layer.2.intermediate.dense.bias', 'base_model.encoder.layer.6.attention.self.key.weight', 'base_model.encoder.layer.23.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.22.intermediate.dense.weight', 'base_model.encoder.layer.16.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.4.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.15.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.13.output.dense.bias', 'base_model.encoder.layer.12.intermediate.dense.bias', 'base_model.encoder.layer.19.intermediate.dense.bias', 'base_model.encoder.layer.2.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.5.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.14.attention.output.LayerNorm.weight', 'base_model.encoder.layer.1.intermediate.dense.bias', 'base_model.encoder.layer.1.attention.self.key.bias', 'base_model.encoder.layer.5.output.LayerNorm.weight', 'base_model.encoder.layer.17.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.23.attention.self.query.bias', 'base_model.encoder.layer.21.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.17.attention.output.dense.bias', 'base_model.encoder.layer.9.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.10.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.0.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.1.attention.output.LayerNorm.bias', 'base_model.encoder.layer.10.attention.output.dense.bias', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.14.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.6.intermediate.dense.weight', 'base_model.encoder.layer.3.attention.output.LayerNorm.weight', 'base_model.encoder.layer.17.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.11.output.LayerNorm.bias', 'base_model.encoder.layer.21.attention.self.value.weight', 'base_model.encoder.layer.22.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.21.attention.output.dense.bias', 'base_model.encoder.layer.23.output.LayerNorm.weight', 'base_model.encoder.layer.14.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.8.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.12.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.18.attention.output.LayerNorm.weight', 'base_model.encoder.layer.18.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.6.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.19.attention.output.dense.weight', 'base_model.encoder.layer.21.intermediate.dense.bias', 'base_model.encoder.layer.20.output.dense.weight', 'base_model.encoder.layer.16.intermediate.dense.bias', 'base_model.encoder.layer.7.attention.self.value.weight', 'base_model.encoder.layer.21.intermediate.dense.weight', 'base_model.encoder.layer.15.output.dense.bias', 'base_model.encoder.layer.3.attention.self.query.bias', 'base_model.encoder.layer.13.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.10.attention.output.LayerNorm.weight', 'base_model.encoder.layer.7.intermediate.dense.weight', 'base_model.encoder.layer.20.attention.self.key.weight', 'base_model.encoder.layer.3.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.9.attention.self.query.weight', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.9.intermediate.dense.bias', 'base_model.encoder.layer.21.output.dense.weight', 'base_model.encoder.layer.11.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.3.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.23.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.3.attention.output.dense.weight', 'base_model.encoder.layer.16.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.0.output.dense.weight', 'base_model.encoder.layer.10.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.12.attention.self.query.weight', 'base_model.encoder.layer.6.output.LayerNorm.bias', 'base_model.encoder.layer.18.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.13.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.21.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.5.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.13.output.LayerNorm.bias', 'base_model.encoder.layer.15.attention.self.key.weight', 'base_model.encoder.layer.3.attention.output.dense.bias', 'base_model.encoder.layer.13.attention.self.value.weight', 'base_model.encoder.layer.18.output.LayerNorm.weight', 'base_model.encoder.layer.4.attention.output.LayerNorm.weight', 'base_model.encoder.layer.10.output.dense.bias', 'base_model.encoder.layer.8.attention.self.query.weight', 'base_model.encoder.layer.11.output.dense.weight', 'base_model.encoder.layer.19.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.22.intermediate.dense.bias', 'base_model.encoder.layer.0.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.22.attention.self.query.weight', 'base_model.encoder.layer.10.attention.self.key.bias', 'base_model.embeddings.token_type_embeddings.weight', 'base_model.encoder.layer.14.output.LayerNorm.weight', 'base_model.encoder.layer.11.output.LayerNorm.weight', 'base_model.encoder.layer.11.attention.self.query.weight', 'base_model.encoder.layer.9.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.6.output.LayerNorm.weight', 'base_model.encoder.layer.12.attention.self.key.bias', 'base_model.encoder.layer.1.attention.self.value.weight', 'base_model.embeddings.word_embeddings.weight', 'base_model.encoder.layer.10.output.dense.weight', 'base_model.encoder.layer.21.output.LayerNorm.bias', 'base_model.encoder.layer.0.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.1.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.15.attention.self.query.bias', 'base_model.encoder.layer.18.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.21.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.15.attention.self.query.weight', 'base_model.encoder.layer.9.attention.self.query.bias', 'base_model.encoder.layer.0.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.6.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.4.attention.output.dense.weight', 'base_model.encoder.layer.8.attention.output.LayerNorm.bias', 'base_model.encoder.layer.11.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.19.output.LayerNorm.weight', 'base_model.encoder.layer.20.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.18.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.1.output.LayerNorm.bias', 'base_model.encoder.layer.7.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.pooler.dense.bias', 'base_model.encoder.layer.6.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.9.attention.output.LayerNorm.bias', 'base_model.encoder.layer.9.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.5.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.13.output.LayerNorm.weight', 'base_model.encoder.layer.17.attention.self.query.bias', 'base_model.encoder.layer.12.intermediate.dense.weight', 'base_model.encoder.layer.21.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.10.output.LayerNorm.bias', 'base_model.encoder.layer.10.intermediate.dense.weight', 'base_model.encoder.layer.19.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.23.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.2.attention.output.LayerNorm.weight', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.20.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.10.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.14.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.12.attention.self.query.bias', 'base_model.encoder.layer.3.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.14.attention.self.value.bias', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.3.output.LayerNorm.bias', 'base_model.encoder.layer.21.attention.self.value.bias', 'base_model.encoder.layer.17.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.18.attention.self.query.bias', 'base_model.encoder.layer.13.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.18.attention.self.value.weight', 'base_model.encoder.layer.1.output.dense.weight', 'base_model.encoder.layer.3.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.16.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.23.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.23.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.9.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.16.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.11.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.8.attention.output.dense.weight', 'base_model.encoder.layer.6.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.23.attention.output.LayerNorm.weight', 'base_model.encoder.layer.6.attention.output.dense.weight', 'base_model.encoder.layer.6.intermediate.dense.bias', 'base_model.encoder.layer.0.attention.output.dense.weight', 'base_model.encoder.layer.12.attention.self.value.weight', 'base_model.encoder.layer.12.attention.self.key.weight', 'base_model.encoder.layer.15.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.21.attention.self.key.bias', 'base_model.encoder.layer.7.attention.self.key.weight', 'base_model.encoder.layer.21.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.16.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.7.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.16.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.0.intermediate.dense.bias', 'base_model.encoder.layer.9.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.17.intermediate.dense.weight', 'base_model.encoder.layer.20.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.12.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.22.attention.output.dense.bias', 'base_model.encoder.layer.19.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.19.attention.self.value.weight', 'base_model.encoder.layer.20.intermediate.dense.weight', 'base_model.encoder.layer.18.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.7.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.1.intermediate.dense.weight', 'base_model.encoder.layer.2.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.22.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.12.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.5.attention.self.value.bias', 'base_model.encoder.layer.10.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.16.output.dense.bias', 'base_model.encoder.layer.19.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.3.output.dense.weight', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.23.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.21.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.7.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.3.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.6.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.18.attention.self.value.bias', 'base_model.encoder.layer.4.intermediate.dense.weight', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.1.attention.self.query.weight', 'base_model.encoder.layer.22.attention.output.LayerNorm.weight', 'base_model.encoder.layer.8.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.16.intermediate.dense.weight', 'base_model.encoder.layer.6.output.dense.weight', 'base_model.encoder.layer.23.output.dense.weight', 'base_model.encoder.layer.23.intermediate.dense.weight', 'base_model.encoder.layer.22.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.0.attention.self.query.weight', 'base_model.encoder.layer.8.attention.self.key.weight', 'base_model.encoder.layer.0.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.8.attention.self.value.bias', 'base_model.encoder.layer.17.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.19.attention.output.LayerNorm.bias', 'base_model.encoder.layer.16.attention.self.query.bias', 'base_model.encoder.layer.0.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.2.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.18.output.adapters.es.adapter_down.0.bias', 'base_model.encoder.layer.7.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.11.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.14.output.dense.bias', 'base_model.encoder.layer.4.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.10.attention.self.query.bias', 'base_model.encoder.layer.13.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.14.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.1.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.3.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.4.output.LayerNorm.bias', 'base_model.encoder.layer.4.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.11.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.14.output.adapters.ts.adapter_down.0.bias', 'base_model.encoder.layer.18.attention.self.key.weight', 'base_model.encoder.layer.16.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.22.attention.self.value.bias', 'base_model.encoder.layer.8.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.5.attention.output.dense.weight', 'base_model.encoder.layer.15.output.LayerNorm.bias', 'base_model.encoder.layer.10.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.20.attention.self.value.bias', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.1.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.14.attention.self.value.weight', 'base_model.encoder.layer.19.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.12.attention.output.dense.weight', 'base_model.encoder.layer.4.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.12.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.10.attention.output.dense.weight', 'base_model.encoder.layer.11.attention.output.LayerNorm.weight', 'base_model.encoder.layer.16.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.19.attention.output.LayerNorm.weight', 'base_model.encoder.layer.4.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.6.attention.self.query.bias', 'base_model.encoder.layer.7.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.4.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.1.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.20.attention.self.value.weight', 'base_model.encoder.layer.18.intermediate.dense.bias', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.6.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.0.attention.self.value.weight', 'base_model.encoder.layer.2.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.18.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.19.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.14.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.10.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.23.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.9.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.1.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.1.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.4.output.LayerNorm.weight', 'base_model.encoder.layer.2.intermediate.dense.weight', 'base_model.encoder.layer.6.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.12.attention.self.value.bias', 'base_model.encoder.layer.22.output.LayerNorm.weight', 'base_model.encoder.layer.5.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.21.attention.self.query.weight', 'base_model.encoder.layer.8.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.7.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.23.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.9.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.11.attention.self.key.bias', 'base_model.encoder.layer.7.intermediate.dense.bias', 'base_model.encoder.layer.16.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.0.output.dense.bias', 'base_model.encoder.layer.11.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.10.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.18.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.14.attention.self.key.bias', 'base_model.encoder.layer.4.attention.output.dense.bias', 'base_model.encoder.layer.11.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.10.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.8.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.5.attention.self.query.bias', 'base_model.encoder.layer.18.attention.output.dense.weight', 'base_model.encoder.layer.2.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.3.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.0.output.adapter_fusion_layer.ep,tp,es,ts.value.weight', 'base_model.encoder.layer.18.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.1.attention.output.dense.weight', 'qa_outputs.bias', 'base_model.encoder.layer.10.intermediate.dense.bias', 'base_model.encoder.layer.13.attention.self.query.weight', 'base_model.encoder.layer.8.intermediate.dense.weight', 'base_model.encoder.layer.6.output.adapters.es.adapter_down.0.weight', 'base_model.encoder.layer.18.attention.output.dense.bias', 'base_model.encoder.layer.19.attention.self.query.weight', 'base_model.encoder.layer.9.attention.self.key.weight', 'base_model.encoder.layer.8.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.13.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.20.output.dense.bias', 'base_model.encoder.layer.13.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.3.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.5.output.adapters.ep.adapter_up.weight', 'base_model.encoder.layer.20.output.adapters.ts.adapter_up.bias', 'base_model.encoder.layer.17.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.12.output.adapters.ts.adapter_up.weight', 'base_model.encoder.layer.0.attention.output.LayerNorm.weight', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.key.weight', 'base_model.encoder.layer.2.output.adapters.es.adapter_up.bias', 'base_model.encoder.layer.19.output.dense.weight', 'base_model.encoder.layer.12.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.6.output.adapters.es.adapter_up.weight', 'base_model.encoder.layer.18.attention.output.LayerNorm.bias', 'base_model.encoder.layer.2.attention.output.dense.weight', 'base_model.encoder.layer.6.output.adapters.ep.adapter_up.bias', 'base_model.encoder.layer.8.output.adapter_fusion_layer.ep,tp,es,ts.query.weight', 'base_model.encoder.layer.5.output.adapters.ep.adapter_down.0.bias', 'base_model.encoder.layer.14.output.adapters.tp.adapter_down.0.weight', 'base_model.encoder.layer.17.attention.output.LayerNorm.weight', 'base_model.encoder.layer.20.output.adapter_fusion_layer.ep,tp,es,ts.query.bias', 'base_model.encoder.layer.5.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.22.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.16.output.adapters.tp.adapter_up.weight', 'base_model.encoder.layer.12.output.adapter_fusion_layer.ep,tp,es,ts.key.bias', 'base_model.encoder.layer.14.output.adapters.ts.adapter_down.0.weight', 'base_model.encoder.layer.17.output.LayerNorm.bias', 'base_model.encoder.layer.20.output.adapters.ep.adapter_down.0.weight', 'base_model.encoder.layer.16.attention.self.key.bias', 'base_model.encoder.layer.13.output.adapters.tp.adapter_up.bias', 'base_model.encoder.layer.4.output.adapters.tp.adapter_down.0.bias', 'base_model.encoder.layer.19.intermediate.dense.weight']
- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of XLMRobertaModel were not initialized from the model checkpoint at /cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//squad/xlm-KG_LR4e-5_EPOCH2.0_maxlen384_batchsize4_gradacc8 and are newly initialized: ['encoder.layer.5.attention.self.key.bias', 'encoder.layer.10.attention.self.key.bias', 'encoder.layer.15.attention.output.dense.bias', 'encoder.layer.14.intermediate.dense.weight', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.9.attention.output.dense.weight', 'encoder.layer.10.output.LayerNorm.weight', 'encoder.layer.9.attention.self.value.bias', 'encoder.layer.1.attention.self.value.bias', 'encoder.layer.13.intermediate.dense.bias', 'encoder.layer.14.attention.self.key.weight', 'encoder.layer.3.attention.output.dense.weight', 'encoder.layer.17.output.LayerNorm.weight', 'encoder.layer.13.attention.output.dense.weight', 'encoder.layer.20.attention.output.dense.bias', 'encoder.layer.13.intermediate.dense.weight', 'encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.5.attention.self.key.weight', 'encoder.layer.18.attention.output.dense.weight', 'encoder.layer.20.attention.self.query.bias', 'encoder.layer.20.output.LayerNorm.weight', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.18.attention.self.query.weight', 'encoder.layer.20.attention.output.dense.weight', 'encoder.layer.3.attention.output.dense.bias', 'encoder.layer.20.attention.self.key.weight', 'encoder.layer.23.attention.self.value.bias', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.9.attention.self.key.bias', 'encoder.layer.9.attention.self.value.weight', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.2.output.dense.bias', 'encoder.layer.2.attention.self.value.weight', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.12.attention.self.key.weight', 'encoder.layer.13.attention.output.LayerNorm.weight', 'encoder.layer.21.attention.self.query.bias', 'encoder.layer.8.attention.output.dense.bias', 'encoder.layer.5.attention.self.query.bias', 'encoder.layer.19.output.dense.weight', 'encoder.layer.8.output.dense.bias', 'encoder.layer.6.output.dense.weight', 'encoder.layer.6.attention.output.dense.bias', 'encoder.layer.13.attention.self.query.weight', 'encoder.layer.18.attention.self.key.weight', 'encoder.layer.19.attention.output.dense.bias', 'encoder.layer.5.attention.self.value.weight', 'encoder.layer.13.attention.self.query.bias', 'encoder.layer.11.output.LayerNorm.weight', 'encoder.layer.23.intermediate.dense.weight', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.11.attention.self.query.bias', 'encoder.layer.15.attention.self.value.weight', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.19.attention.output.LayerNorm.weight', 'encoder.layer.6.attention.self.query.weight', 'encoder.layer.12.attention.self.query.bias', 'encoder.layer.11.attention.self.value.bias', 'encoder.layer.1.output.dense.bias', 'encoder.layer.10.attention.output.dense.bias', 'encoder.layer.5.output.LayerNorm.bias', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.19.attention.self.key.bias', 'encoder.layer.7.attention.self.key.bias', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.20.attention.self.query.weight', 'encoder.layer.4.attention.self.key.weight', 'embeddings.word_embeddings.weight', 'encoder.layer.12.attention.output.LayerNorm.weight', 'encoder.layer.2.attention.output.LayerNorm.bias', 'encoder.layer.14.output.dense.weight', 'encoder.layer.23.attention.output.LayerNorm.weight', 'encoder.layer.2.attention.self.value.bias', 'encoder.layer.17.attention.self.query.weight', 'encoder.layer.17.intermediate.dense.bias', 'encoder.layer.4.attention.output.dense.weight', 'encoder.layer.6.attention.self.value.weight', 'encoder.layer.18.attention.self.key.bias', 'encoder.layer.18.attention.self.value.bias', 'encoder.layer.14.output.LayerNorm.bias', 'encoder.layer.13.attention.output.dense.bias', 'embeddings.LayerNorm.weight', 'encoder.layer.5.attention.self.value.bias', 'encoder.layer.6.attention.self.value.bias', 'encoder.layer.19.intermediate.dense.bias', 'encoder.layer.9.attention.self.query.bias', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.8.attention.output.dense.weight', 'encoder.layer.7.attention.self.query.bias', 'encoder.layer.11.output.dense.weight', 'encoder.layer.1.attention.self.key.bias', 'encoder.layer.4.attention.output.dense.bias', 'encoder.layer.3.output.dense.bias', 'encoder.layer.23.attention.self.value.weight', 'encoder.layer.22.intermediate.dense.weight', 'encoder.layer.16.output.dense.bias', 'encoder.layer.13.output.LayerNorm.bias', 'encoder.layer.19.attention.self.value.bias', 'encoder.layer.16.attention.output.dense.bias', 'encoder.layer.2.attention.output.dense.bias', 'encoder.layer.18.intermediate.dense.bias', 'encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.layer.1.output.dense.weight', 'encoder.layer.5.attention.self.query.weight', 'encoder.layer.12.output.LayerNorm.bias', 'encoder.layer.21.attention.self.key.bias', 'encoder.layer.1.attention.output.dense.weight', 'encoder.layer.15.attention.output.dense.weight', 'encoder.layer.12.attention.self.value.bias', 'encoder.layer.1.attention.self.key.weight', 'encoder.layer.0.attention.self.query.bias', 'encoder.layer.11.attention.output.dense.weight', 'encoder.layer.0.attention.output.LayerNorm.weight', 'encoder.layer.3.output.dense.weight', 'encoder.layer.14.attention.self.value.weight', 'encoder.layer.9.attention.output.LayerNorm.weight', 'encoder.layer.16.attention.self.key.weight', 'encoder.layer.0.attention.self.value.bias', 'encoder.layer.0.attention.output.dense.bias', 'encoder.layer.9.attention.output.LayerNorm.bias', 'encoder.layer.4.attention.self.query.bias', 'encoder.layer.17.output.dense.weight', 'encoder.layer.6.attention.output.LayerNorm.bias', 'encoder.layer.18.attention.self.query.bias', 'encoder.layer.17.attention.self.query.bias', 'encoder.layer.4.attention.self.value.weight', 'encoder.layer.4.attention.output.LayerNorm.weight', 'encoder.layer.23.attention.output.dense.bias', 'encoder.layer.22.attention.self.value.bias', 'encoder.layer.10.attention.self.query.weight', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.18.attention.output.LayerNorm.weight', 'encoder.layer.21.intermediate.dense.bias', 'encoder.layer.3.attention.self.value.bias', 'encoder.layer.14.attention.output.LayerNorm.weight', 'encoder.layer.22.output.LayerNorm.weight', 'encoder.layer.9.attention.self.query.weight', 'encoder.layer.8.attention.self.key.bias', 'encoder.layer.17.attention.output.dense.bias', 'encoder.layer.14.attention.output.dense.weight', 'encoder.layer.11.output.LayerNorm.bias', 'encoder.layer.3.attention.self.value.weight', 'encoder.layer.15.output.dense.bias', 'pooler.dense.weight', 'encoder.layer.5.attention.output.dense.weight', 'encoder.layer.16.intermediate.dense.weight', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.10.attention.output.LayerNorm.weight', 'encoder.layer.13.output.LayerNorm.weight', 'encoder.layer.19.intermediate.dense.weight', 'encoder.layer.18.intermediate.dense.weight', 'encoder.layer.21.attention.output.dense.bias', 'encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.layer.10.attention.self.value.weight', 'encoder.layer.2.attention.self.key.bias', 'encoder.layer.8.attention.self.query.bias', 'encoder.layer.22.attention.output.LayerNorm.weight', 'encoder.layer.8.attention.self.key.weight', 'encoder.layer.11.output.dense.bias', 'encoder.layer.10.output.dense.weight', 'encoder.layer.8.attention.self.value.bias', 'encoder.layer.16.output.dense.weight', 'encoder.layer.5.attention.output.dense.bias', 'encoder.layer.4.attention.self.query.weight', 'encoder.layer.6.attention.output.LayerNorm.weight', 'encoder.layer.14.attention.output.dense.bias', 'encoder.layer.7.attention.self.value.weight', 'encoder.layer.6.attention.output.dense.weight', 'encoder.layer.8.attention.output.LayerNorm.weight', 'encoder.layer.17.attention.output.dense.weight', 'encoder.layer.15.attention.self.key.weight', 'encoder.layer.19.attention.output.LayerNorm.bias', 'encoder.layer.11.attention.self.key.bias', 'encoder.layer.12.output.LayerNorm.weight', 'encoder.layer.8.output.LayerNorm.bias', 'encoder.layer.12.attention.output.LayerNorm.bias', 'encoder.layer.22.attention.output.LayerNorm.bias', 'encoder.layer.19.attention.self.key.weight', 'encoder.layer.23.output.LayerNorm.weight', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.4.output.dense.weight', 'encoder.layer.12.intermediate.dense.bias', 'encoder.layer.20.attention.output.LayerNorm.bias', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.23.attention.self.query.weight', 'encoder.layer.14.attention.self.query.weight', 'encoder.layer.17.attention.self.key.weight', 'encoder.layer.20.attention.output.LayerNorm.weight', 'encoder.layer.2.attention.output.dense.weight', 'encoder.layer.5.attention.output.LayerNorm.weight', 'encoder.layer.21.output.LayerNorm.weight', 'encoder.layer.0.attention.self.query.weight', 'encoder.layer.23.attention.self.key.weight', 'encoder.layer.21.attention.output.dense.weight', 'encoder.layer.23.output.dense.weight', 'encoder.layer.6.output.dense.bias', 'encoder.layer.7.output.LayerNorm.weight', 'encoder.layer.16.attention.output.LayerNorm.bias', 'encoder.layer.16.attention.output.LayerNorm.weight', 'encoder.layer.13.attention.self.key.bias', 'encoder.layer.11.attention.output.dense.bias', 'encoder.layer.16.output.LayerNorm.bias', 'encoder.layer.9.output.LayerNorm.weight', 'encoder.layer.6.attention.self.key.bias', 'encoder.layer.14.intermediate.dense.bias', 'encoder.layer.4.attention.self.value.bias', 'encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.0.output.dense.weight', 'encoder.layer.20.output.dense.weight', 'encoder.layer.1.attention.output.LayerNorm.weight', 'encoder.layer.0.attention.self.key.weight', 'encoder.layer.14.attention.self.query.bias', 'encoder.layer.11.attention.self.value.weight', 'encoder.layer.18.output.LayerNorm.bias', 'embeddings.LayerNorm.bias', 'encoder.layer.17.output.LayerNorm.bias', 'encoder.layer.22.attention.self.query.weight', 'encoder.layer.1.attention.self.value.weight', 'encoder.layer.22.output.dense.weight', 'encoder.layer.15.output.LayerNorm.weight', 'encoder.layer.15.attention.self.query.bias', 'encoder.layer.0.attention.output.dense.weight', 'encoder.layer.16.attention.self.key.bias', 'encoder.layer.13.output.dense.weight', 'encoder.layer.4.output.dense.bias', 'encoder.layer.17.attention.self.key.bias', 'encoder.layer.13.attention.self.key.weight', 'encoder.layer.22.attention.output.dense.bias', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.15.attention.self.key.bias', 'encoder.layer.18.attention.self.value.weight', 'encoder.layer.17.output.dense.bias', 'encoder.layer.7.attention.output.LayerNorm.bias', 'encoder.layer.16.attention.self.query.weight', 'encoder.layer.7.attention.self.key.weight', 'encoder.layer.7.output.dense.bias', 'encoder.layer.23.output.dense.bias', 'encoder.layer.7.output.dense.weight', 'encoder.layer.11.attention.output.LayerNorm.weight', 'encoder.layer.13.attention.self.value.bias', 'encoder.layer.19.output.LayerNorm.weight', 'encoder.layer.7.attention.output.dense.bias', 'encoder.layer.16.attention.output.dense.weight', 'encoder.layer.20.attention.self.value.bias', 'encoder.layer.21.attention.output.LayerNorm.weight', 'encoder.layer.21.attention.output.LayerNorm.bias', 'encoder.layer.7.attention.output.dense.weight', 'encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.1.attention.output.dense.bias', 'encoder.layer.12.output.dense.weight', 'encoder.layer.6.attention.self.query.bias', 'pooler.dense.bias', 'encoder.layer.10.attention.self.value.bias', 'encoder.layer.13.attention.output.LayerNorm.bias', 'encoder.layer.15.output.dense.weight', 'encoder.layer.21.attention.self.value.weight', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.21.attention.self.key.weight', 'encoder.layer.12.attention.self.key.bias', 'encoder.layer.20.output.LayerNorm.bias', 'encoder.layer.15.output.LayerNorm.bias', 'encoder.layer.19.attention.self.value.weight', 'encoder.layer.1.attention.self.query.bias', 'encoder.layer.10.intermediate.dense.weight', 'encoder.layer.3.attention.self.query.weight', 'encoder.layer.18.output.dense.weight', 'encoder.layer.12.attention.self.value.weight', 'encoder.layer.12.output.dense.bias', 'encoder.layer.10.output.dense.bias', 'encoder.layer.16.output.LayerNorm.weight', 'encoder.layer.0.attention.self.value.weight', 'encoder.layer.18.attention.output.LayerNorm.bias', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.8.output.dense.weight', 'encoder.layer.15.intermediate.dense.bias', 'encoder.layer.13.output.dense.bias', 'encoder.layer.20.attention.self.value.weight', 'encoder.layer.20.intermediate.dense.bias', 'encoder.layer.19.output.dense.bias', 'encoder.layer.16.intermediate.dense.bias', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.10.attention.self.query.bias', 'encoder.layer.6.output.LayerNorm.bias', 'embeddings.token_type_embeddings.weight', 'encoder.layer.9.output.LayerNorm.bias', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.18.attention.output.dense.bias', 'encoder.layer.18.output.LayerNorm.weight', 'encoder.layer.23.attention.output.dense.weight', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.23.attention.self.query.bias', 'encoder.layer.15.intermediate.dense.weight', 'encoder.layer.21.intermediate.dense.weight', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.22.attention.self.key.weight', 'encoder.layer.9.output.dense.weight', 'encoder.layer.14.attention.output.LayerNorm.bias', 'encoder.layer.19.attention.self.query.weight', 'encoder.layer.11.attention.self.query.weight', 'encoder.layer.2.output.dense.weight', 'encoder.layer.16.attention.self.query.bias', 'encoder.layer.7.output.LayerNorm.bias', 'encoder.layer.12.intermediate.dense.weight', 'encoder.layer.17.intermediate.dense.weight', 'encoder.layer.12.attention.self.query.weight', 'encoder.layer.3.attention.self.key.bias', 'encoder.layer.20.output.dense.bias', 'encoder.layer.5.output.dense.weight', 'encoder.layer.4.attention.self.key.bias', 'encoder.layer.23.intermediate.dense.bias', 'encoder.layer.21.attention.self.value.bias', 'encoder.layer.15.attention.self.value.bias', 'encoder.layer.1.attention.self.query.weight', 'encoder.layer.8.output.LayerNorm.weight', 'encoder.layer.15.attention.output.LayerNorm.weight', 'encoder.layer.7.intermediate.dense.bias', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.14.attention.self.key.bias', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.22.intermediate.dense.bias', 'encoder.layer.16.attention.self.value.weight', 'encoder.layer.16.attention.self.value.bias', 'encoder.layer.20.attention.self.key.bias', 'encoder.layer.17.attention.self.value.bias', 'encoder.layer.23.attention.self.key.bias', 'encoder.layer.19.attention.self.query.bias', 'encoder.layer.7.attention.output.LayerNorm.weight', 'encoder.layer.10.output.LayerNorm.bias', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.18.output.dense.bias', 'encoder.layer.11.attention.self.key.weight', 'encoder.layer.23.output.LayerNorm.bias', 'encoder.layer.14.output.LayerNorm.weight', 'encoder.layer.17.attention.output.LayerNorm.weight', 'encoder.layer.9.attention.self.key.weight', 'encoder.layer.15.attention.output.LayerNorm.bias', 'encoder.layer.22.output.dense.bias', 'encoder.layer.2.attention.self.query.bias', 'encoder.layer.2.attention.self.query.weight', 'encoder.layer.3.attention.self.query.bias', 'encoder.layer.3.attention.self.key.weight', 'encoder.layer.2.attention.output.LayerNorm.weight', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.22.attention.self.query.bias', 'encoder.layer.22.attention.output.dense.weight', 'encoder.layer.7.attention.self.query.weight', 'encoder.layer.5.output.dense.bias', 'encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.19.output.LayerNorm.bias', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.10.attention.self.key.weight', 'encoder.layer.6.attention.self.key.weight', 'encoder.layer.0.output.dense.bias', 'encoder.layer.21.output.dense.weight', 'encoder.layer.22.attention.self.value.weight', 'encoder.layer.2.intermediate.dense.bias', 'embeddings.position_embeddings.weight', 'encoder.layer.21.output.LayerNorm.bias', 'encoder.layer.12.attention.output.dense.bias', 'encoder.layer.8.attention.output.LayerNorm.bias', 'encoder.layer.8.attention.self.query.weight', 'encoder.layer.14.attention.self.value.bias', 'encoder.layer.9.output.dense.bias', 'encoder.layer.13.attention.self.value.weight', 'encoder.layer.20.intermediate.dense.weight', 'encoder.layer.10.attention.output.LayerNorm.bias', 'encoder.layer.8.attention.self.value.weight', 'encoder.layer.4.attention.output.LayerNorm.bias', 'encoder.layer.23.attention.output.LayerNorm.bias', 'encoder.layer.21.output.dense.bias', 'encoder.layer.9.attention.output.dense.bias', 'encoder.layer.22.output.LayerNorm.bias', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.0.attention.self.key.bias', 'encoder.layer.7.attention.self.value.bias', 'encoder.layer.22.attention.self.key.bias', 'encoder.layer.15.attention.self.query.weight', 'encoder.layer.17.attention.self.value.weight', 'encoder.layer.2.attention.self.key.weight', 'encoder.layer.14.output.dense.bias', 'encoder.layer.19.attention.output.dense.weight', 'encoder.layer.17.attention.output.LayerNorm.bias', 'encoder.layer.21.attention.self.query.weight', 'encoder.layer.10.attention.output.dense.weight', 'encoder.layer.12.attention.output.dense.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Overwriting existing adapter 'ep'.
Overwriting existing adapter 'tp'.
Overwriting existing adapter 'es'.
Overwriting existing adapter 'ts'.
Overwriting existing adapter fusion module 'ep,tp,es,ts'
05/09/2022 20:17:45 - INFO - __main__ -   Creating features from dataset file at .
/cluster/home/yifhou/scratch_yifan/qa/xtreme_xlmr/outputs-adapter//squad/xlm-KG_LR4e-5_EPOCH2.0_maxlen384_batchsize4_gradacc8
XLMConfig {
  "architectures": [
    "XLMRobertaForMaskedLM"
  ],
  "asm": false,
  "attention_dropout": 0.1,
  "attention_probs_dropout_prob": 0.1,
  "bos_index": 0,
  "bos_token_id": 0,
  "causal": false,
  "dropout": 0.1,
  "emb_dim": 1024,
  "embed_init_std": 0.02209708691207961,
  "end_n_top": 5,
  "eos_index": 1,
  "eos_token_id": 2,
  "gelu_activation": true,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "init_std": 0.02,
  "initializer_range": 0.02,
  "intermediate_size": 4096,
  "is_encoder": true,
  "lang_id": 0,
  "layer_norm_eps": 1e-05,
  "mask_index": 5,
  "mask_token_id": 0,
  "max_position_embeddings": 514,
  "model_type": "xlm",
  "n_heads": 16,
  "n_langs": 1,
  "n_layers": 24,
  "output_past": true,
  "pad_index": 2,
  "pad_token_id": 1,
  "sinusoidal_embeddings": false,
  "start_n_top": 5,
  "summary_activation": null,
  "summary_first_dropout": 0.1,
  "summary_proj_to_labels": true,
  "summary_type": "first",
  "summary_use_proj": true,
  "transformers_version": "4.17.0",
  "type_vocab_size": 1,
  "unk_index": 3,
  "use_lang_emb": false,
  "vocab_size": 250002
}

  0%|          | 0/48 [00:00<?, ?it/s] 27%|██▋       | 13/48 [00:00<00:00, 124.64it/s] 54%|█████▍    | 26/48 [00:00<00:00, 106.59it/s] 77%|███████▋  | 37/48 [00:00<00:00, 88.82it/s] 100%|██████████| 48/48 [00:00<00:00, 101.11it/s]
convert squad examples to features:   0%|          | 0/1190 [00:00<?, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.
convert squad examples to features:   0%|          | 1/1190 [00:00<04:18,  4.59it/s]convert squad examples to features:   5%|▌         | 65/1190 [00:00<00:07, 151.93it/s]convert squad examples to features:   8%|▊         | 97/1190 [00:00<00:05, 185.64it/s]convert squad examples to features:  14%|█▎        | 161/1190 [00:00<00:04, 245.82it/s]convert squad examples to features:  16%|█▌        | 193/1190 [00:00<00:04, 244.81it/s]convert squad examples to features:  19%|█▉        | 225/1190 [00:01<00:03, 259.56it/s]convert squad examples to features:  22%|██▏       | 257/1190 [00:01<00:04, 222.88it/s]convert squad examples to features:  24%|██▍       | 289/1190 [00:01<00:04, 216.88it/s]convert squad examples to features:  27%|██▋       | 321/1190 [00:01<00:04, 211.59it/s]convert squad examples to features:  30%|██▉       | 353/1190 [00:01<00:03, 221.23it/s]convert squad examples to features:  32%|███▏      | 385/1190 [00:02<00:06, 119.61it/s]convert squad examples to features:  35%|███▌      | 417/1190 [00:02<00:05, 136.77it/s]convert squad examples to features:  38%|███▊      | 449/1190 [00:02<00:05, 129.25it/s]convert squad examples to features:  40%|████      | 481/1190 [00:02<00:04, 144.19it/s]convert squad examples to features:  43%|████▎     | 513/1190 [00:03<00:04, 152.09it/s]convert squad examples to features:  46%|████▌     | 545/1190 [00:03<00:04, 152.32it/s]convert squad examples to features:  48%|████▊     | 577/1190 [00:03<00:03, 170.37it/s]convert squad examples to features:  51%|█████     | 609/1190 [00:03<00:03, 172.53it/s]convert squad examples to features:  54%|█████▍    | 641/1190 [00:03<00:03, 171.18it/s]convert squad examples to features:  57%|█████▋    | 673/1190 [00:03<00:03, 158.84it/s]convert squad examples to features:  59%|█████▉    | 705/1190 [00:04<00:02, 171.71it/s]convert squad examples to features:  62%|██████▏   | 737/1190 [00:04<00:02, 172.44it/s]convert squad examples to features:  65%|██████▍   | 769/1190 [00:04<00:02, 187.82it/s]convert squad examples to features:  67%|██████▋   | 801/1190 [00:04<00:01, 196.19it/s]convert squad examples to features:  70%|███████   | 833/1190 [00:04<00:02, 168.59it/s]convert squad examples to features:  73%|███████▎  | 865/1190 [00:05<00:01, 172.34it/s]convert squad examples to features:  75%|███████▌  | 897/1190 [00:05<00:01, 166.27it/s]convert squad examples to features:  78%|███████▊  | 929/1190 [00:05<00:01, 173.20it/s]convert squad examples to features:  81%|████████  | 961/1190 [00:05<00:01, 176.46it/s]convert squad examples to features:  83%|████████▎ | 993/1190 [00:05<00:01, 188.13it/s]convert squad examples to features:  86%|████████▌ | 1025/1190 [00:05<00:00, 203.59it/s]convert squad examples to features:  89%|████████▉ | 1057/1190 [00:05<00:00, 223.94it/s]convert squad examples to features:  92%|█████████▏| 1089/1190 [00:06<00:00, 226.18it/s]convert squad examples to features:  94%|█████████▍| 1121/1190 [00:06<00:00, 218.64it/s]convert squad examples to features:  97%|█████████▋| 1153/1190 [00:06<00:00, 190.09it/s]convert squad examples to features: 100%|██████████| 1190/1190 [00:06<00:00, 183.87it/s]/cluster/project/sachan/yifan/softwares/anaconda/anaconda3/envs/xfactr/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2272: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

add example index and unique id:   0%|          | 0/1190 [00:00<?, ?it/s]add example index and unique id: 100%|██████████| 1190/1190 [00:00<00:00, 587271.65it/s]
05/09/2022 20:17:52 - INFO - __main__ -   Saving features into cached file ./cached_xquad.hi.json_xlm-KG_LR4e-5_EPOCH2.0_maxlen384_batchsize4_gradacc8_384_hi
05/09/2022 20:17:54 - INFO - __main__ -   ***** Running evaluation  *****
05/09/2022 20:17:54 - INFO - __main__ -     Num examples = 1382
05/09/2022 20:17:54 - INFO - __main__ -     Batch size = 8
Evaluating:   0%|          | 0/173 [00:00<?, ?it/s]Evaluating:   1%|          | 1/173 [00:00<02:28,  1.16it/s]Evaluating:   1%|          | 2/173 [00:01<01:36,  1.77it/s]Evaluating:   2%|▏         | 3/173 [00:01<01:19,  2.13it/s]Evaluating:   2%|▏         | 4/173 [00:01<01:11,  2.36it/s]Evaluating:   3%|▎         | 5/173 [00:02<01:07,  2.48it/s]Evaluating:   3%|▎         | 6/173 [00:02<01:04,  2.58it/s]Evaluating:   4%|▍         | 7/173 [00:03<01:02,  2.65it/s]Evaluating:   5%|▍         | 8/173 [00:03<01:00,  2.71it/s]Evaluating:   5%|▌         | 9/173 [00:03<01:00,  2.73it/s]Evaluating:   6%|▌         | 10/173 [00:04<00:59,  2.75it/s]Evaluating:   6%|▋         | 11/173 [00:04<00:59,  2.71it/s]Evaluating:   7%|▋         | 12/173 [00:04<00:58,  2.74it/s]Evaluating:   8%|▊         | 13/173 [00:05<00:57,  2.76it/s]Evaluating:   8%|▊         | 14/173 [00:05<00:57,  2.78it/s]Evaluating:   9%|▊         | 15/173 [00:05<00:56,  2.79it/s]Evaluating:   9%|▉         | 16/173 [00:06<00:56,  2.80it/s]Evaluating:  10%|▉         | 17/173 [00:06<00:55,  2.80it/s]Evaluating:  10%|█         | 18/173 [00:06<00:55,  2.80it/s]Evaluating:  11%|█         | 19/173 [00:07<00:54,  2.81it/s]Evaluating:  12%|█▏        | 20/173 [00:07<00:54,  2.81it/s]Evaluating:  12%|█▏        | 21/173 [00:08<00:54,  2.79it/s]Evaluating:  13%|█▎        | 22/173 [00:08<00:53,  2.80it/s]Evaluating:  13%|█▎        | 23/173 [00:08<00:53,  2.81it/s]Evaluating:  14%|█▍        | 24/173 [00:09<00:53,  2.80it/s]Evaluating:  14%|█▍        | 25/173 [00:09<00:52,  2.81it/s]Evaluating:  15%|█▌        | 26/173 [00:09<00:52,  2.81it/s]Evaluating:  16%|█▌        | 27/173 [00:10<00:52,  2.79it/s]Evaluating:  16%|█▌        | 28/173 [00:10<00:51,  2.80it/s]Evaluating:  17%|█▋        | 29/173 [00:10<00:51,  2.80it/s]Evaluating:  17%|█▋        | 30/173 [00:11<00:51,  2.80it/s]Evaluating:  18%|█▊        | 31/173 [00:11<00:50,  2.80it/s]Evaluating:  18%|█▊        | 32/173 [00:11<00:50,  2.79it/s]Evaluating:  19%|█▉        | 33/173 [00:12<00:50,  2.75it/s]Evaluating:  20%|█▉        | 34/173 [00:12<00:50,  2.76it/s]Evaluating:  20%|██        | 35/173 [00:13<00:49,  2.78it/s]Evaluating:  21%|██        | 36/173 [00:13<00:49,  2.79it/s]Evaluating:  21%|██▏       | 37/173 [00:13<00:48,  2.80it/s]Evaluating:  22%|██▏       | 38/173 [00:14<00:48,  2.79it/s]Evaluating:  23%|██▎       | 39/173 [00:14<00:47,  2.79it/s]Evaluating:  23%|██▎       | 40/173 [00:14<00:47,  2.79it/s]Evaluating:  24%|██▎       | 41/173 [00:15<00:47,  2.79it/s]Evaluating:  24%|██▍       | 42/173 [00:15<00:46,  2.79it/s]Evaluating:  25%|██▍       | 43/173 [00:15<00:46,  2.80it/s]Evaluating:  25%|██▌       | 44/173 [00:16<00:46,  2.80it/s]Evaluating:  26%|██▌       | 45/173 [00:16<00:45,  2.79it/s]Evaluating:  27%|██▋       | 46/173 [00:16<00:45,  2.79it/s]Evaluating:  27%|██▋       | 47/173 [00:17<00:45,  2.79it/s]Evaluating:  28%|██▊       | 48/173 [00:17<00:44,  2.79it/s]Evaluating:  28%|██▊       | 49/173 [00:18<00:44,  2.79it/s]Evaluating:  29%|██▉       | 50/173 [00:18<00:44,  2.79it/s]Evaluating:  29%|██▉       | 51/173 [00:18<00:44,  2.77it/s]Evaluating:  30%|███       | 52/173 [00:19<00:43,  2.78it/s]Evaluating:  31%|███       | 53/173 [00:19<00:43,  2.77it/s]Evaluating:  31%|███       | 54/173 [00:19<00:42,  2.77it/s]Evaluating:  32%|███▏      | 55/173 [00:20<00:42,  2.77it/s]Evaluating:  32%|███▏      | 56/173 [00:20<00:42,  2.78it/s]Evaluating:  33%|███▎      | 57/173 [00:20<00:41,  2.77it/s]Evaluating:  34%|███▎      | 58/173 [00:21<00:41,  2.78it/s]Evaluating:  34%|███▍      | 59/173 [00:21<00:41,  2.78it/s]Evaluating:  35%|███▍      | 60/173 [00:22<00:40,  2.78it/s]Evaluating:  35%|███▌      | 61/173 [00:22<00:40,  2.77it/s]Evaluating:  36%|███▌      | 62/173 [00:22<00:40,  2.77it/s]Evaluating:  36%|███▋      | 63/173 [00:23<00:39,  2.77it/s]Evaluating:  37%|███▋      | 64/173 [00:23<00:39,  2.78it/s]Evaluating:  38%|███▊      | 65/173 [00:23<00:38,  2.78it/s]Evaluating:  38%|███▊      | 66/173 [00:24<00:38,  2.79it/s]Evaluating:  39%|███▊      | 67/173 [00:24<00:38,  2.79it/s]Evaluating:  39%|███▉      | 68/173 [00:24<00:37,  2.79it/s]Evaluating:  40%|███▉      | 69/173 [00:25<00:37,  2.80it/s]Evaluating:  40%|████      | 70/173 [00:25<00:37,  2.78it/s]Evaluating:  41%|████      | 71/173 [00:25<00:36,  2.78it/s]Evaluating:  42%|████▏     | 72/173 [00:26<00:36,  2.78it/s]Evaluating:  42%|████▏     | 73/173 [00:26<00:36,  2.77it/s]Evaluating:  43%|████▎     | 74/173 [00:27<00:35,  2.78it/s]Evaluating:  43%|████▎     | 75/173 [00:27<00:35,  2.78it/s]Evaluating:  44%|████▍     | 76/173 [00:27<00:35,  2.77it/s]Evaluating:  45%|████▍     | 77/173 [00:28<00:34,  2.76it/s]Evaluating:  45%|████▌     | 78/173 [00:28<00:34,  2.75it/s]Evaluating:  46%|████▌     | 79/173 [00:28<00:34,  2.75it/s]Evaluating:  46%|████▌     | 80/173 [00:29<00:33,  2.75it/s]Evaluating:  47%|████▋     | 81/173 [00:29<00:33,  2.74it/s]Evaluating:  47%|████▋     | 82/173 [00:29<00:33,  2.75it/s]Evaluating:  48%|████▊     | 83/173 [00:30<00:32,  2.76it/s]Evaluating:  49%|████▊     | 84/173 [00:30<00:32,  2.75it/s]Evaluating:  49%|████▉     | 85/173 [00:31<00:31,  2.75it/s]Evaluating:  50%|████▉     | 86/173 [00:31<00:31,  2.76it/s]Evaluating:  50%|█████     | 87/173 [00:31<00:31,  2.76it/s]Evaluating:  51%|█████     | 88/173 [00:32<00:30,  2.77it/s]Evaluating:  51%|█████▏    | 89/173 [00:32<00:30,  2.77it/s]Evaluating:  52%|█████▏    | 90/173 [00:32<00:29,  2.77it/s]Evaluating:  53%|█████▎    | 91/173 [00:33<00:29,  2.77it/s]Evaluating:  53%|█████▎    | 92/173 [00:33<00:29,  2.77it/s]Evaluating:  54%|█████▍    | 93/173 [00:33<00:28,  2.77it/s]Evaluating:  54%|█████▍    | 94/173 [00:34<00:28,  2.78it/s]Evaluating:  55%|█████▍    | 95/173 [00:34<00:28,  2.78it/s]Evaluating:  55%|█████▌    | 96/173 [00:35<00:27,  2.78it/s]Evaluating:  56%|█████▌    | 97/173 [00:35<00:27,  2.78it/s]Evaluating:  57%|█████▋    | 98/173 [00:35<00:26,  2.78it/s]Evaluating:  57%|█████▋    | 99/173 [00:36<00:26,  2.77it/s]Evaluating:  58%|█████▊    | 100/173 [00:36<00:26,  2.77it/s]Evaluating:  58%|█████▊    | 101/173 [00:36<00:26,  2.76it/s]Evaluating:  59%|█████▉    | 102/173 [00:37<00:25,  2.76it/s]Evaluating:  60%|█████▉    | 103/173 [00:37<00:25,  2.76it/s]Evaluating:  60%|██████    | 104/173 [00:37<00:24,  2.76it/s]Evaluating:  61%|██████    | 105/173 [00:38<00:24,  2.77it/s]Evaluating:  61%|██████▏   | 106/173 [00:38<00:24,  2.77it/s]Evaluating:  62%|██████▏   | 107/173 [00:38<00:23,  2.77it/s]Evaluating:  62%|██████▏   | 108/173 [00:39<00:23,  2.78it/s]Evaluating:  63%|██████▎   | 109/173 [00:39<00:23,  2.78it/s]Evaluating:  64%|██████▎   | 110/173 [00:40<00:22,  2.79it/s]Evaluating:  64%|██████▍   | 111/173 [00:40<00:22,  2.79it/s]Evaluating:  65%|██████▍   | 112/173 [00:40<00:21,  2.79it/s]Evaluating:  65%|██████▌   | 113/173 [00:41<00:21,  2.79it/s]Evaluating:  66%|██████▌   | 114/173 [00:41<00:21,  2.79it/s]Evaluating:  66%|██████▋   | 115/173 [00:41<00:20,  2.79it/s]Evaluating:  67%|██████▋   | 116/173 [00:42<00:20,  2.79it/s]Evaluating:  68%|██████▊   | 117/173 [00:42<00:20,  2.80it/s]Evaluating:  68%|██████▊   | 118/173 [00:42<00:19,  2.79it/s]Evaluating:  69%|██████▉   | 119/173 [00:43<00:19,  2.78it/s]Evaluating:  69%|██████▉   | 120/173 [00:43<00:19,  2.79it/s]Evaluating:  70%|██████▉   | 121/173 [00:44<00:18,  2.79it/s]Evaluating:  71%|███████   | 122/173 [00:44<00:18,  2.79it/s]Evaluating:  71%|███████   | 123/173 [00:44<00:17,  2.79it/s]Evaluating:  72%|███████▏  | 124/173 [00:45<00:17,  2.79it/s]Evaluating:  72%|███████▏  | 125/173 [00:45<00:17,  2.79it/s]Evaluating:  73%|███████▎  | 126/173 [00:45<00:16,  2.78it/s]Evaluating:  73%|███████▎  | 127/173 [00:46<00:16,  2.78it/s]Evaluating:  74%|███████▍  | 128/173 [00:46<00:16,  2.78it/s]Evaluating:  75%|███████▍  | 129/173 [00:46<00:15,  2.79it/s]Evaluating:  75%|███████▌  | 130/173 [00:47<00:15,  2.79it/s]Evaluating:  76%|███████▌  | 131/173 [00:47<00:15,  2.78it/s]Evaluating:  76%|███████▋  | 132/173 [00:47<00:14,  2.78it/s]Evaluating:  77%|███████▋  | 133/173 [00:48<00:14,  2.78it/s]Evaluating:  77%|███████▋  | 134/173 [00:48<00:14,  2.77it/s]Evaluating:  78%|███████▊  | 135/173 [00:49<00:13,  2.75it/s]Evaluating:  79%|███████▊  | 136/173 [00:49<00:13,  2.75it/s]Evaluating:  79%|███████▉  | 137/173 [00:49<00:13,  2.74it/s]Evaluating:  80%|███████▉  | 138/173 [00:50<00:12,  2.75it/s]Evaluating:  80%|████████  | 139/173 [00:50<00:12,  2.76it/s]Evaluating:  81%|████████  | 140/173 [00:50<00:11,  2.77it/s]Evaluating:  82%|████████▏ | 141/173 [00:51<00:11,  2.77it/s]Evaluating:  82%|████████▏ | 142/173 [00:51<00:11,  2.77it/s]Evaluating:  83%|████████▎ | 143/173 [00:51<00:10,  2.79it/s]Evaluating:  83%|████████▎ | 144/173 [00:52<00:10,  2.79it/s]Evaluating:  84%|████████▍ | 145/173 [00:52<00:10,  2.79it/s]Evaluating:  84%|████████▍ | 146/173 [00:53<00:09,  2.79it/s]Evaluating:  85%|████████▍ | 147/173 [00:53<00:09,  2.79it/s]Evaluating:  86%|████████▌ | 148/173 [00:53<00:08,  2.78it/s]Evaluating:  86%|████████▌ | 149/173 [00:54<00:08,  2.78it/s]Evaluating:  87%|████████▋ | 150/173 [00:54<00:08,  2.79it/s]Evaluating:  87%|████████▋ | 151/173 [00:54<00:07,  2.79it/s]Evaluating:  88%|████████▊ | 152/173 [00:55<00:07,  2.79it/s]Evaluating:  88%|████████▊ | 153/173 [00:55<00:07,  2.79it/s]Evaluating:  89%|████████▉ | 154/173 [00:55<00:06,  2.78it/s]Evaluating:  90%|████████▉ | 155/173 [00:56<00:06,  2.79it/s]Evaluating:  90%|█████████ | 156/173 [00:56<00:06,  2.79it/s]Evaluating:  91%|█████████ | 157/173 [00:56<00:05,  2.79it/s]Evaluating:  91%|█████████▏| 158/173 [00:57<00:05,  2.79it/s]Evaluating:  92%|█████████▏| 159/173 [00:57<00:05,  2.79it/s]Evaluating:  92%|█████████▏| 160/173 [00:58<00:04,  2.78it/s]Evaluating:  93%|█████████▎| 161/173 [00:58<00:04,  2.79it/s]Evaluating:  94%|█████████▎| 162/173 [00:58<00:03,  2.79it/s]Evaluating:  94%|█████████▍| 163/173 [00:59<00:03,  2.79it/s]Evaluating:  95%|█████████▍| 164/173 [00:59<00:03,  2.79it/s]Evaluating:  95%|█████████▌| 165/173 [00:59<00:02,  2.79it/s]Evaluating:  96%|█████████▌| 166/173 [01:00<00:02,  2.79it/s]Evaluating:  97%|█████████▋| 167/173 [01:00<00:02,  2.79it/s]Evaluating:  97%|█████████▋| 168/173 [01:00<00:01,  2.79it/s]Evaluating:  98%|█████████▊| 169/173 [01:01<00:01,  2.79it/s]Evaluating:  98%|█████████▊| 170/173 [01:01<00:01,  2.78it/s]Evaluating:  99%|█████████▉| 171/173 [01:01<00:00,  2.78it/s]Evaluating:  99%|█████████▉| 172/173 [01:02<00:00,  2.78it/s]Evaluating: 100%|██████████| 173/173 [01:02<00:00,  3.02it/s]Evaluating: 100%|██████████| 173/173 [01:02<00:00,  2.76it/s]
05/09/2022 20:18:56 - INFO - __main__ -     Evaluation done in total 62.603439 secs (0.045299 sec per example)
05/09/2022 20:19:00 - INFO - __main__ -   Results: {'exact': 60.42016806722689, 'f1': 76.17015828487007, 'total': 1190, 'HasAns_exact': 60.42016806722689, 'HasAns_f1': 76.17015828487007, 'HasAns_total': 1190, 'best_exact': 60.42016806722689, 'best_exact_thresh': 0.0, 'best_f1': 76.17015828487007, 'best_f1_thresh': 0.0}
