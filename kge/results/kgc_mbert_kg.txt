Namespace(adam_epsilon=1e-06, batch_num=16, data_dir='/cluster/work/sachan/yifan/data/wikidata/downstream', device=5, epoch=10, lr=1e-08, model_dir='/cluster/work/sachan/yifan/huggingface_models/bert-base-multilingual-cased', model_name='mBERT-KG', modelkg_dir='/cluster/project/sachan/yifan/projects/Multilingual_Space/tmp/mbert_adapter', neg_num=1, patience=2, task_name='kgc', tmp_dir='./tmp/checkpoints', weight_decay=0.0001)
Some weights of the model checkpoint at /cluster/work/sachan/yifan/huggingface_models/bert-base-multilingual-cased were not used when initializing BertModel: ['cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight']
- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Overwriting existing adapter 'ep'.
Overwriting existing adapter 'tp'.
Overwriting existing adapter 'es'.
Overwriting existing adapter 'ts'.
Overwriting existing adapter fusion module 'ep,tp,es,ts'
Some weights of the model checkpoint at /cluster/work/sachan/yifan/huggingface_models/bert-base-multilingual-cased were not used when initializing BertModel: ['cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight']
- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Overwriting existing adapter 'ep'.
Overwriting existing adapter 'tp'.
Overwriting existing adapter 'es'.
Overwriting existing adapter 'ts'.
Overwriting existing adapter fusion module 'ep,tp,es,ts'
...testing...
KGC: [ el ] | test hit@1:  0.06654 hit@10:  0.21627 MRR:  0.09405
KGC: [ en ] | test hit@1:  0.1763 hit@10:  0.36213 MRR:  0.20134
KGC: [ es ] | test hit@1:  0.16094 hit@10:  0.35625 MRR:  0.1874
KGC: [ fr ] | test hit@1:  0.16344 hit@10:  0.34581 MRR:  0.1904
KGC: [ ja ] | test hit@1:  0.03581 hit@10:  0.13313 MRR:  0.05702
KGC: [ ast ] | test hit@1:  0.17109 hit@10:  0.38009 MRR:  0.20085
KGC: [ ca ] | test hit@1:  0.17438 hit@10:  0.37276 MRR:  0.20507
KGC: [ da ] | test hit@1:  0.18589 hit@10:  0.38153 MRR:  0.21189
KGC: [ de ] | test hit@1:  0.16778 hit@10:  0.35206 MRR:  0.19328
KGC: [ fa ] | test hit@1:  0.07943 hit@10:  0.20352 MRR:  0.09858
KGC: [ fi ] | test hit@1:  0.13981 hit@10:  0.33734 MRR:  0.16891
KGC: [ hu ] | test hit@1:  0.16341 hit@10:  0.3534 MRR:  0.19163
KGC: [ it ] | test hit@1:  0.16851 hit@10:  0.35141 MRR:  0.1934
KGC: [ nb ] | test hit@1:  0.18697 hit@10:  0.39455 MRR:  0.21496
KGC: [ nl ] | test hit@1:  0.17238 hit@10:  0.36631 MRR:  0.19667
KGC: [ pl ] | test hit@1:  0.16544 hit@10:  0.38259 MRR:  0.19589
KGC: [ pt ] | test hit@1:  0.1674 hit@10:  0.35019 MRR:  0.19408
KGC: [ ru ] | test hit@1:  0.07378 hit@10:  0.23034 MRR:  0.1016
KGC: [ sv ] | test hit@1:  0.16973 hit@10:  0.37454 MRR:  0.1993
KGC: [ zh ] | test hit@1:  0.04516 hit@10:  0.15014 MRR:  0.07015
