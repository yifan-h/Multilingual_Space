Some weights of the model checkpoint at /cluster/work/sachan/yifan/huggingface_models/xlm-roberta-base/ were not used when initializing XLMRobertaModel: ['lm_head.decoder.weight', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.dense.weight', 'lm_head.layer_norm.bias']
- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of the model checkpoint at /cluster/work/sachan/yifan/huggingface_models/xlm-roberta-base/ were not used when initializing XLMRobertaModel: ['lm_head.decoder.weight', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.dense.weight', 'lm_head.layer_norm.bias']
- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of the model checkpoint at /cluster/work/sachan/yifan/huggingface_models/xlm-roberta-base/ were not used when initializing XLMRobertaModel: ['lm_head.decoder.weight', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.dense.weight', 'lm_head.layer_norm.bias']
- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of the model checkpoint at /cluster/work/sachan/yifan/huggingface_models/xlm-roberta-base/ were not used when initializing XLMRobertaModel: ['lm_head.decoder.weight', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.dense.weight', 'lm_head.layer_norm.bias']
- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of the model checkpoint at /cluster/work/sachan/yifan/huggingface_models/xlm-roberta-base/ were not used when initializing XLMRobertaModel: ['lm_head.decoder.weight', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.dense.weight', 'lm_head.layer_norm.bias']
- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of the model checkpoint at /cluster/work/sachan/yifan/huggingface_models/xlm-roberta-base/ were not used when initializing XLMRobertaModel: ['lm_head.decoder.weight', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.dense.weight', 'lm_head.layer_norm.bias']
- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Namespace(adam_epsilon=1e-08, batch_num=16, data_dir='/cluster/work/sachan/yifan/data/wikidata/downstream', device=7, epoch=50, lm_lr=1e-06, lr=1e-06, model_dir='/cluster/work/sachan/yifan/huggingface_models/xlm-roberta-base/', model_name='XLM-KG', modelkg_dir='/cluster/project/sachan/yifan/projects/Multilingual_Space/tmp/xlm_80/final_v3.pt', neg_num=1, patience=2, tmp_dir='./tmp/checkpoints', weight_decay=0.005)
KGC: [ el ] | training loss:  1.9803 | val loss:  1.4846 | hit@1:  0.1377 hit@10:  0.3736
KGC: [ el ] | training loss:  1.3356 | val loss:  1.3106 | hit@1:  0.0757 hit@10:  0.3795
KGC: [ el ] | training loss:  1.2018 | val loss:  1.1252 | hit@1:  0.1121 hit@10:  0.3992
KGC: [ el ] | training loss:  1.7267 | val loss:  1.3808 | hit@1:  0.1131 hit@10:  0.3166
KGC: [ el ] | training loss:  1.2123 | val loss:  1.1897 | hit@1:  0.1268 hit@10:  0.3884
KGC: [ el ] | training loss:  1.147 | val loss:  1.3483 | hit@1:  0.0934 hit@10:  0.4002
KGC: [ el ] | training loss:  1.3134 | val loss:  1.3463 | hit@1:  0.1347 hit@10:  0.3815
KGC: [ el ] | training loss:  1.2188 | val loss:  1.267 | hit@1:  0.0757 hit@10:  0.2763
KGC: [ el ] | training loss:  1.1775 | val loss:  1.0994 | hit@1:  0.1554 hit@10:  0.4081
KGC: [ el ] | training loss:  1.0512 | val loss:  1.0408 | hit@1:  0.1357 hit@10:  0.3845
KGC: [ el ] | training loss:  1.2978 | val loss:  1.3882 | hit@1:  0.1072 hit@10:  0.3068
KGC: [ el ] | training loss:  1.134 | val loss:  1.1418 | hit@1:  0.119 hit@10:  0.3245
KGC: [ el ] | training loss:  1.1361 | val loss:  1.1673 | hit@1:  0.1111 hit@10:  0.2881
KGC: [ el ] | training loss:  1.1136 | val loss:  1.1404 | hit@1:  0.1475 hit@10:  0.3943
KGC: [ el ] | training loss:  1.0418 | val loss:  1.0537 | hit@1:  0.0718 hit@10:  0.352
KGC: [ el ] | training loss:  1.003 | val loss:  1.0732 | hit@1:  0.1268 hit@10:  0.4041
KGC: [ el ] | training loss:  0.9405 | val loss:  1.0139 | hit@1:  0.1426 hit@10:  0.4071
KGC: [ el ] | training loss:  0.9912 | val loss:  1.1097 | hit@1:  0.1337 hit@10:  0.4002
KGC: [ el ] | training loss:  1.0274 | val loss:  1.0879 | hit@1:  0.1337 hit@10:  0.3805
KGC: [ el ] | training loss:  1.0185 | val loss:  1.1323 | hit@1:  0.1131 hit@10:  0.3913
KGC: [ el ] | training loss:  0.98 | val loss:  1.0488 | hit@1:  0.0954 hit@10:  0.4071
KGC: [ el ] | training loss:  0.9724 | val loss:  1.0723 | hit@1:  0.1308 hit@10:  0.414
KGC: [ el ] | training loss:  0.9818 | val loss:  1.1352 | hit@1:  0.1367 hit@10:  0.3992
KGC: [ el ] | training loss:  0.9761 | val loss:  1.0217 | hit@1:  0.1416 hit@10:  0.4248
KGC: [ el ] | training loss:  0.949 | val loss:  1.1111 | hit@1:  0.1288 hit@10:  0.4071
KGC: [ el ] | training loss:  0.9207 | val loss:  1.0343 | hit@1:  0.1082 hit@10:  0.41
KGC: [ el ] | training loss:  0.9666 | val loss:  1.0591 | hit@1:  0.1032 hit@10:  0.4012
KGC: [ el ] | training loss:  0.9642 | val loss:  1.0906 | hit@1:  0.1072 hit@10:  0.4435
KGC: [ el ] | training loss:  0.9123 | val loss:  1.105 | hit@1:  0.0747 hit@10:  0.4159
KGC: [ el ] | training loss:  0.9403 | val loss:  1.0773 | hit@1:  0.0973 hit@10:  0.3599
KGC: [ el ] | training loss:  0.9404 | val loss:  1.0793 | hit@1:  0.1023 hit@10:  0.411
KGC: [ el ] | training loss:  0.9604 | val loss:  1.1482 | hit@1:  0.0452 hit@10:  0.3147
KGC: [ el ] | training loss:  1.1033 | val loss:  1.251 | hit@1:  0.061 hit@10:  0.4051
KGC: [ el ] | training loss:  1.0963 | val loss:  1.2502 | hit@1:  0.0757 hit@10:  0.4336
KGC: [ el ] | training loss:  1.0835 | val loss:  1.2364 | hit@1:  0.0934 hit@10:  0.4169
KGC: [ el ] | training loss:  1.128 | val loss:  1.19 | hit@1:  0.0708 hit@10:  0.3854
KGC: [ el ] | training loss:  1.0542 | val loss:  1.1366 | hit@1:  0.0501 hit@10:  0.3717
KGC: [ el ] | training loss:  1.0376 | val loss:  1.0762 | hit@1:  0.1023 hit@10:  0.4307
KGC: [ el ] | training loss:  0.9704 | val loss:  1.0927 | hit@1:  0.0639 hit@10:  0.4061
KGC: [ el ] | training loss:  1.0254 | val loss:  1.1796 | hit@1:  0.0816 hit@10:  0.4022
KGC: [ el ] | training loss:  0.9673 | val loss:  1.093 | hit@1:  0.1386 hit@10:  0.4159
KGC: [ el ] | training loss:  0.9109 | val loss:  1.1419 | hit@1:  0.0747 hit@10:  0.4287
KGC: [ el ] | training loss:  0.931 | val loss:  1.0537 | hit@1:  0.1032 hit@10:  0.413
KGC: [ el ] | training loss:  0.9495 | val loss:  1.0988 | hit@1:  0.115 hit@10:  0.4287
KGC: [ el ] | training loss:  1.0539 | val loss:  1.202 | hit@1:  0.0688 hit@10:  0.4051
KGC: [ el ] | training loss:  1.0547 | val loss:  1.1808 | hit@1:  0.0669 hit@10:  0.4041
KGC: [ el ] | training loss:  1.0518 | val loss:  1.2255 | hit@1:  0.1219 hit@10:  0.3963
KGC: [ el ] | training loss:  1.1208 | val loss:  1.1651 | hit@1:  0.0649 hit@10:  0.3953
KGC: [ el ] | training loss:  1.1602 | val loss:  1.3241 | hit@1:  0.1013 hit@10:  0.3766
KGC: [ el ] | training loss:  1.1489 | val loss:  1.2387 | hit@1:  0.0767 hit@10:  0.3559
The performance (hit@1, hit@10) of language [ el ] is:  [1.0139, 0.1426, 0.4071]
KGC: [ en ] | training loss:  1.1134 | val loss:  0.8351 | hit@1:  0.0565 hit@10:  0.1992
KGC: [ en ] | training loss:  0.7949 | val loss:  1.3576 | hit@1:  0.056 hit@10:  0.1289
KGC: [ en ] | training loss:  0.8664 | val loss:  0.8719 | hit@1:  0.0531 hit@10:  0.2073
KGC: [ en ] | training loss:  0.9378 | val loss:  0.88 | hit@1:  0.0478 hit@10:  0.1786
KGC: [ en ] | training loss:  0.8165 | val loss:  0.8238 | hit@1:  0.0382 hit@10:  0.1715
KGC: [ en ] | training loss:  0.796 | val loss:  0.7906 | hit@1:  0.0331 hit@10:  0.1743
KGC: [ en ] | training loss:  0.7549 | val loss:  0.84 | hit@1:  0.0119 hit@10:  0.1522
KGC: [ en ] | training loss:  1.0731 | val loss:  2.4267 | hit@1:  0.005 hit@10:  0.047
KGC: [ en ] | training loss:  2.8219 | val loss:  2.8323 | hit@1:  0.0003 hit@10:  0.0021
KGC: [ en ] | training loss:  2.8332 | val loss:  2.8323 | hit@1:  0.0001 hit@10:  0.002
KGC: [ en ] | training loss:  2.8332 | val loss:  2.8323 | hit@1:  0.0003 hit@10:  0.0044
KGC: [ en ] | training loss:  2.8332 | val loss:  2.8323 | hit@1:  0.0001 hit@10:  0.0042
KGC: [ en ] | training loss:  2.8332 | val loss:  2.8323 | hit@1:  0.0003 hit@10:  0.0099
KGC: [ en ] | training loss:  2.8332 | val loss:  2.8323 | hit@1:  0.0001 hit@10:  0.002
KGC: [ en ] | training loss:  2.8332 | val loss:  2.8323 | hit@1:  0.0001 hit@10:  0.002
KGC: [ en ] | training loss:  2.8332 | val loss:  2.8323 | hit@1:  0.0001 hit@10:  0.0023
KGC: [ en ] | training loss:  2.8331 | val loss:  2.8323 | hit@1:  0.0004 hit@10:  0.0021
KGC: [ en ] | training loss:  2.8331 | val loss:  2.8323 | hit@1:  0.0003 hit@10:  0.0021
KGC: [ en ] | training loss:  2.8331 | val loss:  2.8323 | hit@1:  0.0001 hit@10:  0.0019
KGC: [ en ] | training loss:  2.8331 | val loss:  2.8323 | hit@1:  0.0001 hit@10:  0.0038
KGC: [ en ] | training loss:  2.8331 | val loss:  2.8323 | hit@1:  0.0001 hit@10:  0.0016
KGC: [ en ] | training loss:  2.8331 | val loss:  2.8323 | hit@1:  0.0001 hit@10:  0.0028
KGC: [ en ] | training loss:  2.8331 | val loss:  2.8323 | hit@1:  0.0001 hit@10:  0.0019
KGC: [ en ] | training loss:  2.8331 | val loss:  2.8323 | hit@1:  0.0003 hit@10:  0.0019
KGC: [ en ] | training loss:  2.8331 | val loss:  2.8323 | hit@1:  0.0001 hit@10:  0.0023
KGC: [ en ] | training loss:  2.8331 | val loss:  2.8323 | hit@1:  0.0001 hit@10:  0.0017
KGC: [ en ] | training loss:  2.8331 | val loss:  2.8323 | hit@1:  0.0001 hit@10:  0.0021
KGC: [ en ] | training loss:  2.8331 | val loss:  2.8323 | hit@1:  0.0001 hit@10:  0.0046
KGC: [ en ] | training loss:  2.8331 | val loss:  2.8323 | hit@1:  0.0001 hit@10:  0.0021
KGC: [ en ] | training loss:  2.8331 | val loss:  2.8323 | hit@1:  0.0004 hit@10:  0.0025
KGC: [ en ] | training loss:  2.8331 | val loss:  2.8323 | hit@1:  0.0001 hit@10:  0.0019
KGC: [ en ] | training loss:  2.8331 | val loss:  2.8323 | hit@1:  0.0001 hit@10:  0.0023
KGC: [ en ] | training loss:  2.8331 | val loss:  2.8323 | hit@1:  0.0001 hit@10:  0.0016
KGC: [ en ] | training loss:  2.8331 | val loss:  2.8323 | hit@1:  0.0001 hit@10:  0.0058
KGC: [ en ] | training loss:  2.8331 | val loss:  2.8323 | hit@1:  0.0001 hit@10:  0.0087
KGC: [ en ] | training loss:  2.8331 | val loss:  2.8323 | hit@1:  0.0016 hit@10:  0.0044
KGC: [ en ] | training loss:  2.8331 | val loss:  2.8323 | hit@1:  0.0001 hit@10:  0.0017
KGC: [ en ] | training loss:  2.8331 | val loss:  2.8323 | hit@1:  0.0001 hit@10:  0.0033
KGC: [ en ] | training loss:  2.8331 | val loss:  2.8323 | hit@1:  0.0001 hit@10:  0.0016
KGC: [ en ] | training loss:  2.8331 | val loss:  2.8323 | hit@1:  0.0001 hit@10:  0.0032
KGC: [ en ] | training loss:  2.8331 | val loss:  2.8323 | hit@1:  0.0001 hit@10:  0.0024
KGC: [ en ] | training loss:  2.8331 | val loss:  2.8323 | hit@1:  0.0001 hit@10:  0.0019
KGC: [ en ] | training loss:  2.8331 | val loss:  2.8323 | hit@1:  0.0004 hit@10:  0.0032
KGC: [ en ] | training loss:  2.8331 | val loss:  2.8323 | hit@1:  0.0004 hit@10:  0.0031
KGC: [ en ] | training loss:  2.8331 | val loss:  2.8323 | hit@1:  0.0003 hit@10:  0.0051
KGC: [ en ] | training loss:  2.8331 | val loss:  2.8323 | hit@1:  0.0003 hit@10:  0.0032
KGC: [ en ] | training loss:  2.8331 | val loss:  2.8323 | hit@1:  0.0001 hit@10:  0.0023
KGC: [ en ] | training loss:  2.8331 | val loss:  2.8323 | hit@1:  0.0016 hit@10:  0.0029
KGC: [ en ] | training loss:  2.8331 | val loss:  2.8323 | hit@1:  0.0004 hit@10:  0.0023
KGC: [ en ] | training loss:  2.8331 | val loss:  2.8323 | hit@1:  0.0001 hit@10:  0.0019
The performance (hit@1, hit@10) of language [ en ] is:  [0.7906, 0.0331, 0.1743]
KGC: [ es ] | training loss:  1.2287 | val loss:  0.9155 | hit@1:  0.1094 hit@10:  0.2613
KGC: [ es ] | training loss:  1.0287 | val loss:  0.8231 | hit@1:  0.0973 hit@10:  0.2528
KGC: [ es ] | training loss:  0.8544 | val loss:  0.7127 | hit@1:  0.0484 hit@10:  0.2938
KGC: [ es ] | training loss:  0.9293 | val loss:  0.9698 | hit@1:  0.1162 hit@10:  0.2133
KGC: [ es ] | training loss:  1.0316 | val loss:  0.8622 | hit@1:  0.063 hit@10:  0.2345
KGC: [ es ] | training loss:  0.9343 | val loss:  0.7933 | hit@1:  0.0881 hit@10:  0.2262
KGC: [ es ] | training loss:  0.7972 | val loss:  0.797 | hit@1:  0.1102 hit@10:  0.2037
KGC: [ es ] | training loss:  0.8032 | val loss:  0.7877 | hit@1:  0.0875 hit@10:  0.2538
KGC: [ es ] | training loss:  1.2629 | val loss:  1.0883 | hit@1:  0.0761 hit@10:  0.258
KGC: [ es ] | training loss:  1.0578 | val loss:  0.9575 | hit@1:  0.004 hit@10:  0.2143
KGC: [ es ] | training loss:  1.0481 | val loss:  0.9999 | hit@1:  0.0085 hit@10:  0.1106
KGC: [ es ] | training loss:  1.1263 | val loss:  1.0838 | hit@1:  0.0819 hit@10:  0.122
KGC: [ es ] | training loss:  2.4628 | val loss:  2.833 | hit@1:  0.0002 hit@10:  0.0029
KGC: [ es ] | training loss:  2.8331 | val loss:  2.8331 | hit@1:  0.0002 hit@10:  0.0027
KGC: [ es ] | training loss:  2.8331 | val loss:  2.833 | hit@1:  0.0002 hit@10:  0.0021
KGC: [ es ] | training loss:  2.8342 | val loss:  2.8333 | hit@1:  0.0002 hit@10:  0.0119
KGC: [ es ] | training loss:  2.8333 | val loss:  2.833 | hit@1:  0.0002 hit@10:  0.0027
KGC: [ es ] | training loss:  2.8331 | val loss:  2.833 | hit@1:  0.0006 hit@10:  0.004
KGC: [ es ] | training loss:  2.8331 | val loss:  2.833 | hit@1:  0.0004 hit@10:  0.005
KGC: [ es ] | training loss:  2.8331 | val loss:  2.833 | hit@1:  0.0004 hit@10:  0.0048
KGC: [ es ] | training loss:  2.8331 | val loss:  2.833 | hit@1:  0.0006 hit@10:  0.0029
KGC: [ es ] | training loss:  2.8331 | val loss:  2.833 | hit@1:  0.0002 hit@10:  0.0033
KGC: [ es ] | training loss:  2.8331 | val loss:  2.833 | hit@1:  0.0004 hit@10:  0.0031
KGC: [ es ] | training loss:  2.8331 | val loss:  2.833 | hit@1:  0.0002 hit@10:  0.0025
KGC: [ es ] | training loss:  2.8331 | val loss:  2.833 | hit@1:  0.0002 hit@10:  0.0029
KGC: [ es ] | training loss:  2.8331 | val loss:  2.833 | hit@1:  0.0002 hit@10:  0.0069
KGC: [ es ] | training loss:  2.8331 | val loss:  2.833 | hit@1:  0.0004 hit@10:  0.006
KGC: [ es ] | training loss:  2.8331 | val loss:  2.833 | hit@1:  0.0002 hit@10:  0.0046
KGC: [ es ] | training loss:  2.8331 | val loss:  2.833 | hit@1:  0.0002 hit@10:  0.0025
KGC: [ es ] | training loss:  2.8331 | val loss:  2.833 | hit@1:  0.0002 hit@10:  0.0031
KGC: [ es ] | training loss:  2.8331 | val loss:  2.833 | hit@1:  0.0002 hit@10:  0.0033
KGC: [ es ] | training loss:  2.8331 | val loss:  2.833 | hit@1:  0.0002 hit@10:  0.0025
KGC: [ es ] | training loss:  2.8331 | val loss:  2.833 | hit@1:  0.0002 hit@10:  0.0029
KGC: [ es ] | training loss:  2.8331 | val loss:  2.833 | hit@1:  0.0002 hit@10:  0.0031
KGC: [ es ] | training loss:  2.8331 | val loss:  2.833 | hit@1:  0.0002 hit@10:  0.0029
KGC: [ es ] | training loss:  2.8331 | val loss:  2.833 | hit@1:  0.0002 hit@10:  0.0023
KGC: [ es ] | training loss:  2.8331 | val loss:  2.833 | hit@1:  0.0002 hit@10:  0.0046
KGC: [ es ] | training loss:  2.8331 | val loss:  2.833 | hit@1:  0.0002 hit@10:  0.0031
KGC: [ es ] | training loss:  2.8331 | val loss:  2.833 | hit@1:  0.0002 hit@10:  0.0025
KGC: [ es ] | training loss:  2.8331 | val loss:  2.833 | hit@1:  0.0002 hit@10:  0.0042
KGC: [ es ] | training loss:  2.8331 | val loss:  2.833 | hit@1:  0.0002 hit@10:  0.0025
KGC: [ es ] | training loss:  2.8331 | val loss:  2.833 | hit@1:  0.0002 hit@10:  0.0027
KGC: [ es ] | training loss:  2.8331 | val loss:  2.833 | hit@1:  0.0002 hit@10:  0.0029
KGC: [ es ] | training loss:  2.8331 | val loss:  2.833 | hit@1:  0.0002 hit@10:  0.0035
KGC: [ es ] | training loss:  2.8331 | val loss:  2.833 | hit@1:  0.0002 hit@10:  0.0029
KGC: [ es ] | training loss:  2.8331 | val loss:  2.833 | hit@1:  0.0002 hit@10:  0.0031
KGC: [ es ] | training loss:  2.8331 | val loss:  2.833 | hit@1:  0.0002 hit@10:  0.0033
KGC: [ es ] | training loss:  2.8331 | val loss:  2.833 | hit@1:  0.0002 hit@10:  0.005
KGC: [ es ] | training loss:  2.8331 | val loss:  2.833 | hit@1:  0.0004 hit@10:  0.0058
KGC: [ es ] | training loss:  2.8331 | val loss:  2.833 | hit@1:  0.0006 hit@10:  0.0033
The performance (hit@1, hit@10) of language [ es ] is:  [0.7127, 0.0484, 0.2938]
KGC: [ fr ] | training loss:  1.1199 | val loss:  0.812 | hit@1:  0.1302 hit@10:  0.3289
KGC: [ fr ] | training loss:  0.8054 | val loss:  0.856 | hit@1:  0.1335 hit@10:  0.3402
KGC: [ fr ] | training loss:  0.7675 | val loss:  0.731 | hit@1:  0.1242 hit@10:  0.333
KGC: [ fr ] | training loss:  0.7582 | val loss:  0.8151 | hit@1:  0.1105 hit@10:  0.3124
KGC: [ fr ] | training loss:  0.7622 | val loss:  0.8215 | hit@1:  0.1242 hit@10:  0.3217
KGC: [ fr ] | training loss:  0.7879 | val loss:  0.8492 | hit@1:  0.0556 hit@10:  0.322
KGC: [ fr ] | training loss:  0.8716 | val loss:  0.8349 | hit@1:  0.1088 hit@10:  0.3093
KGC: [ fr ] | training loss:  2.1029 | val loss:  2.8309 | hit@1:  0.0002 hit@10:  0.0031
KGC: [ fr ] | training loss:  2.8331 | val loss:  2.8309 | hit@1:  0.0002 hit@10:  0.0043
KGC: [ fr ] | training loss:  2.833 | val loss:  2.8309 | hit@1:  0.0002 hit@10:  0.0026
KGC: [ fr ] | training loss:  2.833 | val loss:  2.8309 | hit@1:  0.0002 hit@10:  0.005
KGC: [ fr ] | training loss:  2.8321 | val loss:  2.8279 | hit@1:  0.0002 hit@10:  0.0034
KGC: [ fr ] | training loss:  2.8321 | val loss:  2.8309 | hit@1:  0.0007 hit@10:  0.0134
KGC: [ fr ] | training loss:  2.833 | val loss:  2.8309 | hit@1:  0.0002 hit@10:  0.0031
KGC: [ fr ] | training loss:  2.833 | val loss:  2.8309 | hit@1:  0.0002 hit@10:  0.0036
KGC: [ fr ] | training loss:  2.833 | val loss:  2.8309 | hit@1:  0.0005 hit@10:  0.0041
KGC: [ fr ] | training loss:  2.833 | val loss:  2.8309 | hit@1:  0.0002 hit@10:  0.0038
KGC: [ fr ] | training loss:  2.833 | val loss:  2.8309 | hit@1:  0.0002 hit@10:  0.03
KGC: [ fr ] | training loss:  2.833 | val loss:  2.8308 | hit@1:  0.0002 hit@10:  0.0098
KGC: [ fr ] | training loss:  2.8336 | val loss:  2.8309 | hit@1:  0.0002 hit@10:  0.0038
KGC: [ fr ] | training loss:  2.833 | val loss:  2.8309 | hit@1:  0.0007 hit@10:  0.0046
KGC: [ fr ] | training loss:  2.833 | val loss:  2.8309 | hit@1:  0.0002 hit@10:  0.0029
KGC: [ fr ] | training loss:  2.833 | val loss:  2.8309 | hit@1:  0.0002 hit@10:  0.0041
KGC: [ fr ] | training loss:  2.833 | val loss:  2.8309 | hit@1:  0.0026 hit@10:  0.0206
KGC: [ fr ] | training loss:  2.833 | val loss:  2.8309 | hit@1:  0.0002 hit@10:  0.0029
KGC: [ fr ] | training loss:  2.833 | val loss:  2.8309 | hit@1:  0.0002 hit@10:  0.0034
KGC: [ fr ] | training loss:  2.833 | val loss:  2.8309 | hit@1:  0.0002 hit@10:  0.0074
KGC: [ fr ] | training loss:  2.833 | val loss:  2.8309 | hit@1:  0.0002 hit@10:  0.0038
KGC: [ fr ] | training loss:  2.833 | val loss:  2.8309 | hit@1:  0.0005 hit@10:  0.0029
KGC: [ fr ] | training loss:  2.833 | val loss:  2.8309 | hit@1:  0.0002 hit@10:  0.0036
KGC: [ fr ] | training loss:  2.833 | val loss:  2.8309 | hit@1:  0.0002 hit@10:  0.0034
KGC: [ fr ] | training loss:  2.833 | val loss:  2.8309 | hit@1:  0.0002 hit@10:  0.0053
KGC: [ fr ] | training loss:  2.833 | val loss:  2.8309 | hit@1:  0.0005 hit@10:  0.0077
KGC: [ fr ] | training loss:  2.833 | val loss:  2.8309 | hit@1:  0.0002 hit@10:  0.006
KGC: [ fr ] | training loss:  2.833 | val loss:  2.8309 | hit@1:  0.0038 hit@10:  0.0105
KGC: [ fr ] | training loss:  2.833 | val loss:  2.8309 | hit@1:  0.0002 hit@10:  0.0036
KGC: [ fr ] | training loss:  2.833 | val loss:  2.8309 | hit@1:  0.0002 hit@10:  0.0041
KGC: [ fr ] | training loss:  2.833 | val loss:  2.8309 | hit@1:  0.0002 hit@10:  0.0031
KGC: [ fr ] | training loss:  2.833 | val loss:  2.8309 | hit@1:  0.0002 hit@10:  0.0038
KGC: [ fr ] | training loss:  2.833 | val loss:  2.8309 | hit@1:  0.0005 hit@10:  0.0029
KGC: [ fr ] | training loss:  2.833 | val loss:  2.8309 | hit@1:  0.0007 hit@10:  0.0091
KGC: [ fr ] | training loss:  2.833 | val loss:  2.8309 | hit@1:  0.0002 hit@10:  0.0038
KGC: [ fr ] | training loss:  2.833 | val loss:  2.8309 | hit@1:  0.0002 hit@10:  0.0048
KGC: [ fr ] | training loss:  2.833 | val loss:  2.8309 | hit@1:  0.0002 hit@10:  0.0134
KGC: [ fr ] | training loss:  2.833 | val loss:  2.8309 | hit@1:  0.0005 hit@10:  0.0038
KGC: [ fr ] | training loss:  2.833 | val loss:  2.8309 | hit@1:  0.0005 hit@10:  0.0041
KGC: [ fr ] | training loss:  2.833 | val loss:  2.8309 | hit@1:  0.0002 hit@10:  0.0038
KGC: [ fr ] | training loss:  2.833 | val loss:  2.8309 | hit@1:  0.0002 hit@10:  0.0031
KGC: [ fr ] | training loss:  2.833 | val loss:  2.8309 | hit@1:  0.0002 hit@10:  0.005
KGC: [ fr ] | training loss:  2.833 | val loss:  2.8309 | hit@1:  0.0002 hit@10:  0.0034
The performance (hit@1, hit@10) of language [ fr ] is:  [0.731, 0.1242, 0.333]
KGC: [ ja ] | training loss:  1.6403 | val loss:  1.3119 | hit@1:  0.0833 hit@10:  0.3034
KGC: [ ja ] | training loss:  1.2624 | val loss:  1.1762 | hit@1:  0.1679 hit@10:  0.3219
KGC: [ ja ] | training loss:  1.1493 | val loss:  1.0744 | hit@1:  0.1651 hit@10:  0.3437
KGC: [ ja ] | training loss:  1.0786 | val loss:  1.0454 | hit@1:  0.1623 hit@10:  0.3386
KGC: [ ja ] | training loss:  1.1256 | val loss:  1.233 | hit@1:  0.1596 hit@10:  0.3298
KGC: [ ja ] | training loss:  1.2324 | val loss:  1.3137 | hit@1:  0.16 hit@10:  0.3178
KGC: [ ja ] | training loss:  1.1857 | val loss:  1.1791 | hit@1:  0.1725 hit@10:  0.3575
KGC: [ ja ] | training loss:  1.5372 | val loss:  2.8323 | hit@1:  0.0005 hit@10:  0.0088
KGC: [ ja ] | training loss:  2.8329 | val loss:  2.8322 | hit@1:  0.0014 hit@10:  0.0074
KGC: [ ja ] | training loss:  2.8329 | val loss:  2.8322 | hit@1:  0.0005 hit@10:  0.0074
KGC: [ ja ] | training loss:  2.8329 | val loss:  2.8322 | hit@1:  0.0014 hit@10:  0.0079
KGC: [ ja ] | training loss:  2.8329 | val loss:  2.8322 | hit@1:  0.0005 hit@10:  0.0074
KGC: [ ja ] | training loss:  2.8329 | val loss:  2.8322 | hit@1:  0.0009 hit@10:  0.0056
KGC: [ ja ] | training loss:  2.8329 | val loss:  2.8322 | hit@1:  0.0005 hit@10:  0.0056
KGC: [ ja ] | training loss:  2.8329 | val loss:  2.8322 | hit@1:  0.0005 hit@10:  0.0069
KGC: [ ja ] | training loss:  2.8329 | val loss:  2.8322 | hit@1:  0.0005 hit@10:  0.006
KGC: [ ja ] | training loss:  2.8329 | val loss:  2.8322 | hit@1:  0.0 hit@10:  0.0074
KGC: [ ja ] | training loss:  2.8329 | val loss:  2.8322 | hit@1:  0.0014 hit@10:  0.0102
KGC: [ ja ] | training loss:  2.8329 | val loss:  2.8322 | hit@1:  0.0032 hit@10:  0.0093
KGC: [ ja ] | training loss:  2.8329 | val loss:  2.8322 | hit@1:  0.0005 hit@10:  0.0083
KGC: [ ja ] | training loss:  2.8329 | val loss:  2.8322 | hit@1:  0.0028 hit@10:  0.0083
KGC: [ ja ] | training loss:  2.8329 | val loss:  2.8322 | hit@1:  0.0005 hit@10:  0.0056
KGC: [ ja ] | training loss:  2.8329 | val loss:  2.8323 | hit@1:  0.0005 hit@10:  0.006
KGC: [ ja ] | training loss:  2.8329 | val loss:  2.8322 | hit@1:  0.0005 hit@10:  0.0046
KGC: [ ja ] | training loss:  2.8329 | val loss:  2.8323 | hit@1:  0.0032 hit@10:  0.0088
KGC: [ ja ] | training loss:  2.8329 | val loss:  2.8322 | hit@1:  0.0009 hit@10:  0.0083
KGC: [ ja ] | training loss:  2.8329 | val loss:  2.8322 | hit@1:  0.0005 hit@10:  0.013
KGC: [ ja ] | training loss:  2.833 | val loss:  2.8322 | hit@1:  0.0005 hit@10:  0.0074
KGC: [ ja ] | training loss:  2.8329 | val loss:  2.8322 | hit@1:  0.0005 hit@10:  0.0046
KGC: [ ja ] | training loss:  2.8329 | val loss:  2.8322 | hit@1:  0.0019 hit@10:  0.0093
KGC: [ ja ] | training loss:  2.8329 | val loss:  2.8322 | hit@1:  0.0005 hit@10:  0.0051
KGC: [ ja ] | training loss:  2.8329 | val loss:  2.8322 | hit@1:  0.0005 hit@10:  0.006
KGC: [ ja ] | training loss:  2.8329 | val loss:  2.8322 | hit@1:  0.0014 hit@10:  0.0065
KGC: [ ja ] | training loss:  2.8329 | val loss:  2.8322 | hit@1:  0.0005 hit@10:  0.0056
KGC: [ ja ] | training loss:  2.8329 | val loss:  2.8322 | hit@1:  0.0009 hit@10:  0.0083
KGC: [ ja ] | training loss:  2.8329 | val loss:  2.8322 | hit@1:  0.0005 hit@10:  0.0069
KGC: [ ja ] | training loss:  2.8329 | val loss:  2.8322 | hit@1:  0.0005 hit@10:  0.0056
KGC: [ ja ] | training loss:  2.8329 | val loss:  2.8322 | hit@1:  0.0005 hit@10:  0.0065
KGC: [ ja ] | training loss:  2.8329 | val loss:  2.8322 | hit@1:  0.0005 hit@10:  0.0069
KGC: [ ja ] | training loss:  2.8329 | val loss:  2.8322 | hit@1:  0.0005 hit@10:  0.0056
KGC: [ ja ] | training loss:  2.8329 | val loss:  2.8322 | hit@1:  0.0023 hit@10:  0.0079
KGC: [ ja ] | training loss:  2.8329 | val loss:  2.8322 | hit@1:  0.0005 hit@10:  0.012
KGC: [ ja ] | training loss:  2.8329 | val loss:  2.8322 | hit@1:  0.0009 hit@10:  0.0065
KGC: [ ja ] | training loss:  2.8329 | val loss:  2.8322 | hit@1:  0.0009 hit@10:  0.0106
KGC: [ ja ] | training loss:  2.8329 | val loss:  2.8322 | hit@1:  0.0005 hit@10:  0.0056
KGC: [ ja ] | training loss:  2.8329 | val loss:  2.8322 | hit@1:  0.0005 hit@10:  0.006
KGC: [ ja ] | training loss:  2.8329 | val loss:  2.8322 | hit@1:  0.0009 hit@10:  0.0097
KGC: [ ja ] | training loss:  2.8329 | val loss:  2.8322 | hit@1:  0.0014 hit@10:  0.0065
KGC: [ ja ] | training loss:  2.8329 | val loss:  2.8322 | hit@1:  0.0005 hit@10:  0.0116
KGC: [ ja ] | training loss:  2.8329 | val loss:  2.8322 | hit@1:  0.0014 hit@10:  0.006
The performance (hit@1, hit@10) of language [ ja ] is:  [1.0454, 0.1623, 0.3386]
