Namespace(adam_epsilon=1e-06, batch_num=50, data_dir='/cluster/work/sachan/yifan/data/wikidata/downstream', device=5, epoch=10, lm_lr=1e-06, lr=1e-06, model_dir='/cluster/work/sachan/yifan/huggingface_models/xlm-roberta-base/', model_name='XLM', modelkg_dir='/cluster/project/sachan/yifan/projects/Multilingual_Space/tmp/xlm_80/final_v3.pt', neg_num=1, patience=2, tmp_dir='./tmp/checkpoints', weight_decay=0.005)
Some weights of the model checkpoint at /cluster/work/sachan/yifan/huggingface_models/xlm-roberta-base/ were not used when initializing XLMRobertaModel: ['lm_head.dense.weight', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.dense.bias', 'lm_head.bias', 'lm_head.layer_norm.bias']
- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of the model checkpoint at /cluster/work/sachan/yifan/huggingface_models/xlm-roberta-base/ were not used when initializing XLMRobertaModel: ['lm_head.dense.weight', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.dense.bias', 'lm_head.bias', 'lm_head.layer_norm.bias']
- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
----KGC: loss:  2.6724 | val hit@1:  0.0531 hit@10:  0.1542
KGC: [ el ] | test hit@1:  0.0698 hit@10:  0.2714
KGC: [ en ] | test hit@1:  0.0729 hit@10:  0.1593
KGC: [ es ] | test hit@1:  0.1042 hit@10:  0.236
KGC: [ fr ] | test hit@1:  0.1429 hit@10:  0.2776
KGC: [ ja ] | test hit@1:  0.0851 hit@10:  0.2364
----KGC: loss:  1.2568 | val hit@1:  0.0357 hit@10:  0.1646
KGC: [ el ] | test hit@1:  0.0659 hit@10:  0.3235
KGC: [ en ] | test hit@1:  0.0756 hit@10:  0.1779
KGC: [ es ] | test hit@1:  0.1133 hit@10:  0.2543
KGC: [ fr ] | test hit@1:  0.1302 hit@10:  0.2887
KGC: [ ja ] | test hit@1:  0.0957 hit@10:  0.271
----KGC: loss:  1.0649 | val hit@1:  0.0379 hit@10:  0.1728
KGC: [ el ] | test hit@1:  0.0629 hit@10:  0.2773
KGC: [ en ] | test hit@1:  0.0632 hit@10:  0.1681
KGC: [ es ] | test hit@1:  0.1148 hit@10:  0.2308
KGC: [ fr ] | test hit@1:  0.1477 hit@10:  0.2853
KGC: [ ja ] | test hit@1:  0.0911 hit@10:  0.2396
----KGC: loss:  1.0631 | val hit@1:  0.0519 hit@10:  0.1632
KGC: [ el ] | test hit@1:  0.0846 hit@10:  0.3048
KGC: [ en ] | test hit@1:  0.0729 hit@10:  0.1923
KGC: [ es ] | test hit@1:  0.1129 hit@10:  0.2632
KGC: [ fr ] | test hit@1:  0.1256 hit@10:  0.2704
KGC: [ ja ] | test hit@1:  0.1568 hit@10:  0.2632
----KGC: loss:  1.0221 | val hit@1:  0.0515 hit@10:  0.2022
KGC: [ el ] | test hit@1:  0.0924 hit@10:  0.3648
KGC: [ en ] | test hit@1:  0.0837 hit@10:  0.2217
KGC: [ es ] | test hit@1:  0.1156 hit@10:  0.2963
KGC: [ fr ] | test hit@1:  0.1582 hit@10:  0.3222
KGC: [ ja ] | test hit@1:  0.1272 hit@10:  0.2655
----KGC: loss:  1.2355 | val hit@1:  0.0272 hit@10:  0.1039
KGC: [ el ] | test hit@1:  0.059 hit@10:  0.2527
KGC: [ en ] | test hit@1:  0.0326 hit@10:  0.0982
KGC: [ es ] | test hit@1:  0.0574 hit@10:  0.2168
KGC: [ fr ] | test hit@1:  0.04 hit@10:  0.1611
KGC: [ ja ] | test hit@1:  0.018 hit@10:  0.1878
----KGC: loss:  1.3143 | val hit@1:  0.0465 hit@10:  0.1718
KGC: [ el ] | test hit@1:  0.0678 hit@10:  0.3294
KGC: [ en ] | test hit@1:  0.0348 hit@10:  0.1951
KGC: [ es ] | test hit@1:  0.11 hit@10:  0.2742
KGC: [ fr ] | test hit@1:  0.1335 hit@10:  0.3011
KGC: [ ja ] | test hit@1:  0.1508 hit@10:  0.2613
----KGC: loss:  1.3163 | val hit@1:  0.0353 hit@10:  0.1731
KGC: [ el ] | test hit@1:  0.0511 hit@10:  0.3638
KGC: [ en ] | test hit@1:  0.0698 hit@10:  0.2016
KGC: [ es ] | test hit@1:  0.1096 hit@10:  0.2813
KGC: [ fr ] | test hit@1:  0.123 hit@10:  0.281
KGC: [ ja ] | test hit@1:  0.019 hit@10:  0.2655
----KGC: loss:  1.4792 | val hit@1:  0.0376 hit@10:  0.125
KGC: [ el ] | test hit@1:  0.0521 hit@10:  0.2665
KGC: [ en ] | test hit@1:  0.0283 hit@10:  0.1105
KGC: [ es ] | test hit@1:  0.0734 hit@10:  0.2135
KGC: [ fr ] | test hit@1:  0.0726 hit@10:  0.228
KGC: [ ja ] | test hit@1:  0.0819 hit@10:  0.1545
----KGC: loss:  3.0904 | val hit@1:  0.0 hit@10:  0.0009
KGC: [ el ] | test hit@1:  0.002 hit@10:  0.0197
KGC: [ en ] | test hit@1:  0.0 hit@10:  0.0028
KGC: [ es ] | test hit@1:  0.0002 hit@10:  0.0037
KGC: [ fr ] | test hit@1:  0.0002 hit@10:  0.007
KGC: [ ja ] | test hit@1:  0.0009 hit@10:  0.012
The performance (hit@1, hit@10) of language [ ja ] is:  [0.25368949232585597, 0.1582, 0.3222]
