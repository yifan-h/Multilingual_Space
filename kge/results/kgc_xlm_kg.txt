Namespace(adam_epsilon=1e-06, batch_num=16, data_dir='/cluster/work/sachan/yifan/data/wikidata/downstream', device=7, epoch=10, lr=1e-08, model_dir='/cluster/work/sachan/yifan/huggingface_models/xlm-roberta-base', model_name='XLM-KG', modelkg_dir='/cluster/project/sachan/yifan/projects/Multilingual_Space/tmp/xlm_adapter', neg_num=1, patience=2, task_name='kgc', tmp_dir='./tmp/checkpoints', weight_decay=0.0001)
Some weights of the model checkpoint at /cluster/work/sachan/yifan/huggingface_models/xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.bias', 'lm_head.layer_norm.bias', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.dense.weight']
- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Overwriting existing adapter 'ep'.
Overwriting existing adapter 'tp'.
Overwriting existing adapter 'es'.
Overwriting existing adapter 'ts'.
Overwriting existing adapter fusion module 'ep,tp,es,ts'
Some weights of the model checkpoint at /cluster/work/sachan/yifan/huggingface_models/xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.bias', 'lm_head.layer_norm.bias', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.dense.weight']
- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Overwriting existing adapter 'ep'.
Overwriting existing adapter 'tp'.
Overwriting existing adapter 'es'.
Overwriting existing adapter 'ts'.
Overwriting existing adapter fusion module 'ep,tp,es,ts'
...testing...
KGC: [ el ] | test hit@1:  0.08133 hit@10:  0.21349 MRR:  0.10747
KGC: [ en ] | test hit@1:  0.11096 hit@10:  0.25568 MRR:  0.13319
KGC: [ es ] | test hit@1:  0.09607 hit@10:  0.23921 MRR:  0.12167
KGC: [ fr ] | test hit@1:  0.10054 hit@10:  0.24572 MRR:  0.12388
KGC: [ ja ] | test hit@1:  0.03114 hit@10:  0.11872 MRR:  0.05161
KGC: [ ast ] | test hit@1:  0.10981 hit@10:  0.28162 MRR:  0.13943
KGC: [ ca ] | test hit@1:  0.11186 hit@10:  0.27374 MRR:  0.13349
KGC: [ da ] | test hit@1:  0.11146 hit@10:  0.28215 MRR:  0.14255
KGC: [ de ] | test hit@1:  0.10815 hit@10:  0.26509 MRR:  0.13108
KGC: [ fa ] | test hit@1:  0.05496 hit@10:  0.13568 MRR:  0.07111
KGC: [ fi ] | test hit@1:  0.07746 hit@10:  0.23393 MRR:  0.10693
KGC: [ hu ] | test hit@1:  0.08757 hit@10:  0.23612 MRR:  0.1177
KGC: [ it ] | test hit@1:  0.11234 hit@10:  0.25844 MRR:  0.1337
KGC: [ nb ] | test hit@1:  0.1244 hit@10:  0.28119 MRR:  0.14927
KGC: [ nl ] | test hit@1:  0.10357 hit@10:  0.26761 MRR:  0.13143
KGC: [ pl ] | test hit@1:  0.09073 hit@10:  0.23082 MRR:  0.1134
KGC: [ pt ] | test hit@1:  0.09925 hit@10:  0.24623 MRR:  0.12447
KGC: [ ru ] | test hit@1:  0.04641 hit@10:  0.13751 MRR:  0.06735
KGC: [ sv ] | test hit@1:  0.11928 hit@10:  0.27898 MRR:  0.14453
KGC: [ zh ] | test hit@1:  0.03474 hit@10:  0.11386 MRR:  0.05685

KGC: [ eo ] | test hit@1:  0.16511 hit@10:  0.41433 MRR:  0.19801
KGC: [ vo ] | test hit@1:  0.35366 hit@10:  0.67683 MRR:  0.36444