Fine-tuning /cluster/home/meiliu/scratch/xtreme_mbert_3e5_4_8_tydiqa/bert-base-multilingual-cased on tydiqa using GPU 3
Load data from /cluster/home/meiliu/scratch/xtreme_mbert_3e5_4_8_tydiqa/download/, and save models to /cluster/home/meiliu/scratch/xtreme_mbert_3e5_4_8_tydiqa/outputs-org/
************************
/cluster/home/meiliu/scratch/xtreme_mbert_3e5_4_8_tydiqa/bert-base-multilingual-cased
************************

Predictions on tydiqa
  en 
05/11/2022 17:49:50 - WARNING - __main__ -   Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, 16-bits training: False
05/11/2022 17:49:53 - INFO - __main__ -   lang2id = None
05/11/2022 17:49:56 - INFO - __main__ -   Training/evaluation parameters Namespace(adam_epsilon=1e-08, cache_dir='', config_name='', data_dir=None, device=device(type='cuda'), do_eval=True, do_lower_case=False, do_train=False, doc_stride=128, eval_all_checkpoints=False, eval_lang='en', evaluate_during_training=False, fp16=False, fp16_opt_level='O1', gradient_accumulation_steps=1, learning_rate=5e-05, local_rank=-1, logging_steps=50, max_answer_length=30, max_grad_norm=1.0, max_query_length=64, max_seq_length=384, max_steps=-1, model_name_or_path='/cluster/home/meiliu/scratch/xtreme_mbert_3e5_4_8_tydiqa/outputs-org//tydiqa/_LR3e-5_EPOCH3.0_maxlen384_batchsize4_gradacc8', model_type='bert', n_best_size=20, n_gpu=1, no_cuda=False, null_score_diff_threshold=0.0, num_train_epochs=3.0, output_dir='/cluster/home/meiliu/scratch/xtreme_mbert_3e5_4_8_tydiqa/outputs-org//tydiqa/_LR3e-5_EPOCH3.0_maxlen384_batchsize4_gradacc8/predictions/tydiqa/', overwrite_cache=False, overwrite_output_dir=False, per_gpu_eval_batch_size=8, per_gpu_train_batch_size=8, predict_file='/cluster/home/meiliu/scratch/xtreme_mbert_3e5_4_8_tydiqa/download//tydiqa//tydiqa-goldp-v1.1-dev/tydiqa-goldp-dev-en.json', save_steps=50, seed=42, server_ip='', server_port='', threads=1, tokenizer_name='', train_file=None, train_lang='en', verbose_logging=False, version_2_with_negative=False, warmup_steps=0, weight_decay=0.0)
05/11/2022 17:49:56 - INFO - __main__ -   Loading checkpoint /cluster/home/meiliu/scratch/xtreme_mbert_3e5_4_8_tydiqa/outputs-org//tydiqa/_LR3e-5_EPOCH3.0_maxlen384_batchsize4_gradacc8 for evaluation
05/11/2022 17:49:56 - INFO - __main__ -   Evaluate the following checkpoints: ['/cluster/home/meiliu/scratch/xtreme_mbert_3e5_4_8_tydiqa/outputs-org//tydiqa/_LR3e-5_EPOCH3.0_maxlen384_batchsize4_gradacc8']
05/11/2022 17:49:58 - INFO - __main__ -   Creating features from dataset file at .
  0%|          | 0/440 [00:00<?, ?it/s]100%|██████████| 440/440 [00:00<00:00, 4519.31it/s]
convert squad examples to features:   0%|          | 0/440 [00:00<?, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.
convert squad examples to features:   0%|          | 1/440 [00:00<02:07,  3.46it/s]convert squad examples to features:   8%|▊         | 33/440 [00:00<00:04, 92.66it/s]convert squad examples to features:  15%|█▍        | 65/440 [00:00<00:02, 135.30it/s]convert squad examples to features:  22%|██▏       | 97/440 [00:00<00:02, 160.54it/s]convert squad examples to features:  29%|██▉       | 129/440 [00:00<00:01, 171.14it/s]convert squad examples to features:  37%|███▋      | 161/440 [00:01<00:01, 178.77it/s]convert squad examples to features:  44%|████▍     | 193/440 [00:01<00:01, 193.97it/s]convert squad examples to features:  51%|█████     | 225/440 [00:01<00:01, 197.36it/s]convert squad examples to features:  58%|█████▊    | 257/440 [00:01<00:00, 205.76it/s]convert squad examples to features:  66%|██████▌   | 289/440 [00:01<00:00, 213.23it/s]convert squad examples to features:  73%|███████▎  | 321/440 [00:01<00:00, 214.14it/s]convert squad examples to features:  80%|████████  | 353/440 [00:01<00:00, 219.30it/s]convert squad examples to features:  88%|████████▊ | 385/440 [00:02<00:00, 201.88it/s]convert squad examples to features:  95%|█████████▍| 417/440 [00:02<00:00, 215.94it/s]convert squad examples to features: 100%|██████████| 440/440 [00:02<00:00, 194.90it/s]/cluster/project/sachan/meizhen/env_anaconda/software/envs/xtreme_tmp/lib/python3.6/site-packages/transformers/tokenization_utils_base.py:2278: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  FutureWarning,

add example index and unique id:   0%|          | 0/440 [00:00<?, ?it/s]add example index and unique id: 100%|██████████| 440/440 [00:00<00:00, 390002.91it/s]
05/11/2022 17:50:00 - INFO - __main__ -   Saving features into cached file ./cached_tydiqa-goldp-dev-en.json__LR3e-5_EPOCH3.0_maxlen384_batchsize4_gradacc8_384_en
05/11/2022 17:50:01 - INFO - __main__ -   ***** Running evaluation  *****
05/11/2022 17:50:01 - INFO - __main__ -     Num examples = 449
05/11/2022 17:50:01 - INFO - __main__ -     Batch size = 8
Evaluating:   0%|          | 0/57 [00:00<?, ?it/s]Evaluating:   2%|▏         | 1/57 [00:00<00:37,  1.50it/s]Evaluating:   5%|▌         | 3/57 [00:00<00:12,  4.28it/s]Evaluating:   9%|▉         | 5/57 [00:00<00:07,  6.58it/s]Evaluating:  12%|█▏        | 7/57 [00:01<00:05,  8.44it/s]Evaluating:  16%|█▌        | 9/57 [00:01<00:04,  9.85it/s]Evaluating:  19%|█▉        | 11/57 [00:01<00:04, 10.91it/s]Evaluating:  23%|██▎       | 13/57 [00:01<00:03, 11.67it/s]Evaluating:  26%|██▋       | 15/57 [00:01<00:03, 12.23it/s]Evaluating:  30%|██▉       | 17/57 [00:01<00:03, 12.64it/s]Evaluating:  33%|███▎      | 19/57 [00:02<00:02, 12.93it/s]Evaluating:  37%|███▋      | 21/57 [00:02<00:02, 13.14it/s]Evaluating:  40%|████      | 23/57 [00:02<00:02, 13.28it/s]Evaluating:  44%|████▍     | 25/57 [00:02<00:02, 13.38it/s]Evaluating:  47%|████▋     | 27/57 [00:02<00:02, 13.45it/s]Evaluating:  51%|█████     | 29/57 [00:02<00:02, 13.48it/s]Evaluating:  54%|█████▍    | 31/57 [00:02<00:01, 13.52it/s]Evaluating:  58%|█████▊    | 33/57 [00:03<00:01, 13.54it/s]Evaluating:  61%|██████▏   | 35/57 [00:03<00:01, 13.57it/s]Evaluating:  65%|██████▍   | 37/57 [00:03<00:01, 13.58it/s]Evaluating:  68%|██████▊   | 39/57 [00:03<00:01, 13.59it/s]Evaluating:  72%|███████▏  | 41/57 [00:03<00:01, 13.60it/s]Evaluating:  75%|███████▌  | 43/57 [00:03<00:01, 13.57it/s]Evaluating:  79%|███████▉  | 45/57 [00:03<00:00, 13.60it/s]Evaluating:  82%|████████▏ | 47/57 [00:04<00:00, 13.60it/s]Evaluating:  86%|████████▌ | 49/57 [00:04<00:00, 13.61it/s]Evaluating:  89%|████████▉ | 51/57 [00:04<00:00, 13.61it/s]Evaluating:  93%|█████████▎| 53/57 [00:04<00:00, 13.60it/s]Evaluating:  96%|█████████▋| 55/57 [00:04<00:00, 13.58it/s]Evaluating: 100%|██████████| 57/57 [00:04<00:00, 12.02it/s]
05/11/2022 17:50:06 - INFO - __main__ -     Evaluation done in total 4.742329 secs (0.010562 sec per example)
05/11/2022 17:50:07 - INFO - __main__ -   Results: {'exact': 66.13636363636364, 'f1': 76.07159651274506, 'total': 440, 'HasAns_exact': 66.13636363636364, 'HasAns_f1': 76.07159651274506, 'HasAns_total': 440, 'best_exact': 66.13636363636364, 'best_exact_thresh': 0.0, 'best_f1': 76.07159651274506, 'best_f1_thresh': 0.0}
  ar 
05/11/2022 17:50:21 - WARNING - __main__ -   Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, 16-bits training: False
05/11/2022 17:50:23 - INFO - __main__ -   lang2id = None
05/11/2022 17:50:26 - INFO - __main__ -   Training/evaluation parameters Namespace(adam_epsilon=1e-08, cache_dir='', config_name='', data_dir=None, device=device(type='cuda'), do_eval=True, do_lower_case=False, do_train=False, doc_stride=128, eval_all_checkpoints=False, eval_lang='ar', evaluate_during_training=False, fp16=False, fp16_opt_level='O1', gradient_accumulation_steps=1, learning_rate=5e-05, local_rank=-1, logging_steps=50, max_answer_length=30, max_grad_norm=1.0, max_query_length=64, max_seq_length=384, max_steps=-1, model_name_or_path='/cluster/home/meiliu/scratch/xtreme_mbert_3e5_4_8_tydiqa/outputs-org//tydiqa/_LR3e-5_EPOCH3.0_maxlen384_batchsize4_gradacc8', model_type='bert', n_best_size=20, n_gpu=1, no_cuda=False, null_score_diff_threshold=0.0, num_train_epochs=3.0, output_dir='/cluster/home/meiliu/scratch/xtreme_mbert_3e5_4_8_tydiqa/outputs-org//tydiqa/_LR3e-5_EPOCH3.0_maxlen384_batchsize4_gradacc8/predictions/tydiqa/', overwrite_cache=False, overwrite_output_dir=False, per_gpu_eval_batch_size=8, per_gpu_train_batch_size=8, predict_file='/cluster/home/meiliu/scratch/xtreme_mbert_3e5_4_8_tydiqa/download//tydiqa//tydiqa-goldp-v1.1-dev/tydiqa-goldp-dev-ar.json', save_steps=50, seed=42, server_ip='', server_port='', threads=1, tokenizer_name='', train_file=None, train_lang='en', verbose_logging=False, version_2_with_negative=False, warmup_steps=0, weight_decay=0.0)
05/11/2022 17:50:26 - INFO - __main__ -   Loading checkpoint /cluster/home/meiliu/scratch/xtreme_mbert_3e5_4_8_tydiqa/outputs-org//tydiqa/_LR3e-5_EPOCH3.0_maxlen384_batchsize4_gradacc8 for evaluation
05/11/2022 17:50:26 - INFO - __main__ -   Evaluate the following checkpoints: ['/cluster/home/meiliu/scratch/xtreme_mbert_3e5_4_8_tydiqa/outputs-org//tydiqa/_LR3e-5_EPOCH3.0_maxlen384_batchsize4_gradacc8']
05/11/2022 17:50:28 - INFO - __main__ -   Creating features from dataset file at .
  0%|          | 0/921 [00:00<?, ?it/s] 57%|█████▋    | 528/921 [00:00<00:00, 5274.81it/s]100%|██████████| 921/921 [00:00<00:00, 5299.59it/s]
convert squad examples to features:   0%|          | 0/921 [00:00<?, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.
convert squad examples to features:   0%|          | 1/921 [00:00<04:53,  3.13it/s]convert squad examples to features:   4%|▎         | 33/921 [00:00<00:11, 78.29it/s]convert squad examples to features:   7%|▋         | 65/921 [00:00<00:06, 124.70it/s]convert squad examples to features:  11%|█         | 97/921 [00:00<00:05, 157.83it/s]convert squad examples to features:  14%|█▍        | 129/921 [00:00<00:04, 163.97it/s]convert squad examples to features:  17%|█▋        | 161/921 [00:01<00:04, 186.34it/s]convert squad examples to features:  21%|██        | 193/921 [00:01<00:03, 203.68it/s]convert squad examples to features:  24%|██▍       | 225/921 [00:01<00:03, 215.10it/s]convert squad examples to features:  28%|██▊       | 257/921 [00:01<00:03, 218.81it/s]convert squad examples to features:  31%|███▏      | 289/921 [00:01<00:02, 227.91it/s]convert squad examples to features:  35%|███▍      | 321/921 [00:01<00:02, 244.14it/s]convert squad examples to features:  38%|███▊      | 353/921 [00:01<00:02, 234.94it/s]convert squad examples to features:  42%|████▏     | 385/921 [00:02<00:02, 237.91it/s]convert squad examples to features:  45%|████▌     | 417/921 [00:02<00:02, 213.19it/s]convert squad examples to features:  49%|████▉     | 449/921 [00:02<00:02, 227.54it/s]convert squad examples to features:  52%|█████▏    | 481/921 [00:02<00:01, 237.24it/s]convert squad examples to features:  56%|█████▌    | 513/921 [00:02<00:01, 232.66it/s]convert squad examples to features:  59%|█████▉    | 545/921 [00:02<00:02, 185.73it/s]convert squad examples to features:  63%|██████▎   | 577/921 [00:03<00:01, 192.26it/s]convert squad examples to features:  66%|██████▌   | 609/921 [00:03<00:01, 176.69it/s]convert squad examples to features:  70%|██████▉   | 641/921 [00:03<00:01, 186.15it/s]convert squad examples to features:  73%|███████▎  | 673/921 [00:03<00:01, 195.58it/s]convert squad examples to features:  77%|███████▋  | 705/921 [00:03<00:01, 193.51it/s]convert squad examples to features:  80%|████████  | 737/921 [00:03<00:00, 198.15it/s]convert squad examples to features:  83%|████████▎ | 769/921 [00:03<00:00, 216.16it/s]convert squad examples to features:  87%|████████▋ | 801/921 [00:04<00:00, 203.39it/s]convert squad examples to features:  90%|█████████ | 833/921 [00:04<00:00, 198.57it/s]convert squad examples to features:  94%|█████████▍| 865/921 [00:04<00:00, 201.13it/s]convert squad examples to features:  97%|█████████▋| 897/921 [00:04<00:00, 161.06it/s]convert squad examples to features: 100%|██████████| 921/921 [00:04<00:00, 193.90it/s]/cluster/project/sachan/meizhen/env_anaconda/software/envs/xtreme_tmp/lib/python3.6/site-packages/transformers/tokenization_utils_base.py:2278: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  FutureWarning,

add example index and unique id:   0%|          | 0/921 [00:00<?, ?it/s]add example index and unique id: 100%|██████████| 921/921 [00:00<00:00, 386643.38it/s]
05/11/2022 17:50:33 - INFO - __main__ -   Saving features into cached file ./cached_tydiqa-goldp-dev-ar.json__LR3e-5_EPOCH3.0_maxlen384_batchsize4_gradacc8_384_ar
05/11/2022 17:50:35 - INFO - __main__ -   ***** Running evaluation  *****
05/11/2022 17:50:35 - INFO - __main__ -     Num examples = 1034
05/11/2022 17:50:35 - INFO - __main__ -     Batch size = 8
Evaluating:   0%|          | 0/130 [00:00<?, ?it/s]Evaluating:   1%|          | 1/130 [00:00<01:30,  1.43it/s]Evaluating:   2%|▏         | 3/130 [00:00<00:30,  4.11it/s]Evaluating:   4%|▍         | 5/130 [00:01<00:19,  6.28it/s]Evaluating:   5%|▌         | 7/130 [00:01<00:15,  8.13it/s]Evaluating:   7%|▋         | 9/130 [00:01<00:12,  9.59it/s]Evaluating:   8%|▊         | 11/130 [00:01<00:11, 10.69it/s]Evaluating:  10%|█         | 13/130 [00:01<00:10, 11.47it/s]Evaluating:  12%|█▏        | 15/130 [00:01<00:09, 12.07it/s]Evaluating:  13%|█▎        | 17/130 [00:01<00:09, 12.50it/s]Evaluating:  15%|█▍        | 19/130 [00:02<00:08, 12.79it/s]Evaluating:  16%|█▌        | 21/130 [00:02<00:08, 13.01it/s]Evaluating:  18%|█▊        | 23/130 [00:02<00:08, 13.18it/s]Evaluating:  19%|█▉        | 25/130 [00:02<00:07, 13.24it/s]Evaluating:  21%|██        | 27/130 [00:02<00:07, 13.34it/s]Evaluating:  22%|██▏       | 29/130 [00:02<00:07, 13.40it/s]Evaluating:  24%|██▍       | 31/130 [00:02<00:07, 13.44it/s]Evaluating:  25%|██▌       | 33/130 [00:03<00:07, 13.45it/s]Evaluating:  27%|██▋       | 35/130 [00:03<00:07, 13.46it/s]Evaluating:  28%|██▊       | 37/130 [00:03<00:06, 13.46it/s]Evaluating:  30%|███       | 39/130 [00:03<00:06, 13.47it/s]Evaluating:  32%|███▏      | 41/130 [00:03<00:06, 13.48it/s]Evaluating:  33%|███▎      | 43/130 [00:03<00:06, 13.45it/s]Evaluating:  35%|███▍      | 45/130 [00:03<00:06, 13.46it/s]Evaluating:  36%|███▌      | 47/130 [00:04<00:06, 13.46it/s]Evaluating:  38%|███▊      | 49/130 [00:04<00:06, 13.47it/s]Evaluating:  39%|███▉      | 51/130 [00:04<00:05, 13.47it/s]Evaluating:  41%|████      | 53/130 [00:04<00:05, 13.49it/s]Evaluating:  42%|████▏     | 55/130 [00:04<00:05, 13.50it/s]Evaluating:  44%|████▍     | 57/130 [00:04<00:05, 13.50it/s]Evaluating:  45%|████▌     | 59/130 [00:05<00:05, 13.48it/s]Evaluating:  47%|████▋     | 61/130 [00:05<00:05, 13.46it/s]Evaluating:  48%|████▊     | 63/130 [00:05<00:04, 13.47it/s]Evaluating:  50%|█████     | 65/130 [00:05<00:04, 13.48it/s]Evaluating:  52%|█████▏    | 67/130 [00:05<00:04, 13.48it/s]Evaluating:  53%|█████▎    | 69/130 [00:05<00:04, 13.47it/s]Evaluating:  55%|█████▍    | 71/130 [00:05<00:04, 13.49it/s]Evaluating:  56%|█████▌    | 73/130 [00:06<00:04, 13.47it/s]Evaluating:  58%|█████▊    | 75/130 [00:06<00:04, 13.47it/s]Evaluating:  59%|█████▉    | 77/130 [00:06<00:03, 13.48it/s]Evaluating:  61%|██████    | 79/130 [00:06<00:03, 13.46it/s]Evaluating:  62%|██████▏   | 81/130 [00:06<00:03, 13.46it/s]Evaluating:  64%|██████▍   | 83/130 [00:06<00:03, 13.46it/s]Evaluating:  65%|██████▌   | 85/130 [00:06<00:03, 13.47it/s]Evaluating:  67%|██████▋   | 87/130 [00:07<00:03, 13.46it/s]Evaluating:  68%|██████▊   | 89/130 [00:07<00:03, 13.43it/s]Evaluating:  70%|███████   | 91/130 [00:07<00:02, 13.44it/s]Evaluating:  72%|███████▏  | 93/130 [00:07<00:02, 13.46it/s]Evaluating:  73%|███████▎  | 95/130 [00:07<00:02, 13.46it/s]Evaluating:  75%|███████▍  | 97/130 [00:07<00:02, 13.46it/s]Evaluating:  76%|███████▌  | 99/130 [00:07<00:02, 13.46it/s]Evaluating:  78%|███████▊  | 101/130 [00:08<00:02, 13.45it/s]Evaluating:  79%|███████▉  | 103/130 [00:08<00:02, 13.38it/s]Evaluating:  81%|████████  | 105/130 [00:08<00:01, 13.39it/s]Evaluating:  82%|████████▏ | 107/130 [00:08<00:01, 13.42it/s]Evaluating:  84%|████████▍ | 109/130 [00:08<00:01, 13.44it/s]Evaluating:  85%|████████▌ | 111/130 [00:08<00:01, 13.45it/s]Evaluating:  87%|████████▋ | 113/130 [00:09<00:01, 13.44it/s]Evaluating:  88%|████████▊ | 115/130 [00:09<00:01, 13.44it/s]Evaluating:  90%|█████████ | 117/130 [00:09<00:00, 13.44it/s]Evaluating:  92%|█████████▏| 119/130 [00:09<00:00, 13.42it/s]Evaluating:  93%|█████████▎| 121/130 [00:09<00:00, 13.43it/s]Evaluating:  95%|█████████▍| 123/130 [00:09<00:00, 13.43it/s]Evaluating:  96%|█████████▌| 125/130 [00:09<00:00, 13.44it/s]Evaluating:  98%|█████████▊| 127/130 [00:10<00:00, 13.44it/s]Evaluating:  99%|█████████▉| 129/130 [00:10<00:00, 13.42it/s]Evaluating: 100%|██████████| 130/130 [00:10<00:00, 12.68it/s]
05/11/2022 17:50:45 - INFO - __main__ -     Evaluation done in total 10.255063 secs (0.009918 sec per example)
05/11/2022 17:50:48 - INFO - __main__ -   Results: {'exact': 68.18675352877307, 'f1': 81.86172308573832, 'total': 921, 'HasAns_exact': 68.18675352877307, 'HasAns_f1': 81.86172308573832, 'HasAns_total': 921, 'best_exact': 68.18675352877307, 'best_exact_thresh': 0.0, 'best_f1': 81.86172308573832, 'best_f1_thresh': 0.0}
  bn 
05/11/2022 17:50:54 - WARNING - __main__ -   Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, 16-bits training: False
05/11/2022 17:50:56 - INFO - __main__ -   lang2id = None
05/11/2022 17:50:59 - INFO - __main__ -   Training/evaluation parameters Namespace(adam_epsilon=1e-08, cache_dir='', config_name='', data_dir=None, device=device(type='cuda'), do_eval=True, do_lower_case=False, do_train=False, doc_stride=128, eval_all_checkpoints=False, eval_lang='bn', evaluate_during_training=False, fp16=False, fp16_opt_level='O1', gradient_accumulation_steps=1, learning_rate=5e-05, local_rank=-1, logging_steps=50, max_answer_length=30, max_grad_norm=1.0, max_query_length=64, max_seq_length=384, max_steps=-1, model_name_or_path='/cluster/home/meiliu/scratch/xtreme_mbert_3e5_4_8_tydiqa/outputs-org//tydiqa/_LR3e-5_EPOCH3.0_maxlen384_batchsize4_gradacc8', model_type='bert', n_best_size=20, n_gpu=1, no_cuda=False, null_score_diff_threshold=0.0, num_train_epochs=3.0, output_dir='/cluster/home/meiliu/scratch/xtreme_mbert_3e5_4_8_tydiqa/outputs-org//tydiqa/_LR3e-5_EPOCH3.0_maxlen384_batchsize4_gradacc8/predictions/tydiqa/', overwrite_cache=False, overwrite_output_dir=False, per_gpu_eval_batch_size=8, per_gpu_train_batch_size=8, predict_file='/cluster/home/meiliu/scratch/xtreme_mbert_3e5_4_8_tydiqa/download//tydiqa//tydiqa-goldp-v1.1-dev/tydiqa-goldp-dev-bn.json', save_steps=50, seed=42, server_ip='', server_port='', threads=1, tokenizer_name='', train_file=None, train_lang='en', verbose_logging=False, version_2_with_negative=False, warmup_steps=0, weight_decay=0.0)
05/11/2022 17:50:59 - INFO - __main__ -   Loading checkpoint /cluster/home/meiliu/scratch/xtreme_mbert_3e5_4_8_tydiqa/outputs-org//tydiqa/_LR3e-5_EPOCH3.0_maxlen384_batchsize4_gradacc8 for evaluation
05/11/2022 17:50:59 - INFO - __main__ -   Evaluate the following checkpoints: ['/cluster/home/meiliu/scratch/xtreme_mbert_3e5_4_8_tydiqa/outputs-org//tydiqa/_LR3e-5_EPOCH3.0_maxlen384_batchsize4_gradacc8']
05/11/2022 17:51:01 - INFO - __main__ -   Creating features from dataset file at .
  0%|          | 0/113 [00:00<?, ?it/s]100%|██████████| 113/113 [00:00<00:00, 1869.50it/s]
convert squad examples to features:   0%|          | 0/113 [00:00<?, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.
convert squad examples to features:   1%|          | 1/113 [00:00<00:42,  2.65it/s]convert squad examples to features:  29%|██▉       | 33/113 [00:00<00:01, 59.04it/s]convert squad examples to features:  58%|█████▊    | 65/113 [00:00<00:00, 78.29it/s]convert squad examples to features: 100%|██████████| 113/113 [00:01<00:00, 105.75it/s]/cluster/project/sachan/meizhen/env_anaconda/software/envs/xtreme_tmp/lib/python3.6/site-packages/transformers/tokenization_utils_base.py:2278: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  FutureWarning,

add example index and unique id:   0%|          | 0/113 [00:00<?, ?it/s]add example index and unique id: 100%|██████████| 113/113 [00:00<00:00, 279455.40it/s]
05/11/2022 17:51:03 - INFO - __main__ -   Saving features into cached file ./cached_tydiqa-goldp-dev-bn.json__LR3e-5_EPOCH3.0_maxlen384_batchsize4_gradacc8_384_bn
05/11/2022 17:51:03 - INFO - __main__ -   ***** Running evaluation  *****
05/11/2022 17:51:03 - INFO - __main__ -     Num examples = 153
05/11/2022 17:51:03 - INFO - __main__ -     Batch size = 8
Evaluating:   0%|          | 0/20 [00:00<?, ?it/s]Evaluating:   5%|▌         | 1/20 [00:00<00:11,  1.59it/s]Evaluating:  15%|█▌        | 3/20 [00:00<00:03,  4.52it/s]Evaluating:  25%|██▌       | 5/20 [00:00<00:02,  6.88it/s]Evaluating:  35%|███▌      | 7/20 [00:01<00:01,  8.62it/s]Evaluating:  45%|████▌     | 9/20 [00:01<00:01,  9.88it/s]Evaluating:  55%|█████▌    | 11/20 [00:01<00:00, 10.82it/s]Evaluating:  65%|██████▌   | 13/20 [00:01<00:00, 11.52it/s]Evaluating:  75%|███████▌  | 15/20 [00:01<00:00, 12.02it/s]Evaluating:  85%|████████▌ | 17/20 [00:01<00:00, 12.36it/s]Evaluating:  95%|█████████▌| 19/20 [00:01<00:00, 12.58it/s]Evaluating: 100%|██████████| 20/20 [00:02<00:00,  9.94it/s]
05/11/2022 17:51:05 - INFO - __main__ -     Evaluation done in total 2.013115 secs (0.013158 sec per example)
05/11/2022 17:51:05 - INFO - __main__ -   Results: {'exact': 68.14159292035399, 'f1': 76.60013536119732, 'total': 113, 'HasAns_exact': 68.14159292035399, 'HasAns_f1': 76.60013536119732, 'HasAns_total': 113, 'best_exact': 68.14159292035399, 'best_exact_thresh': 0.0, 'best_f1': 76.60013536119732, 'best_f1_thresh': 0.0}
  fi 
05/11/2022 17:51:11 - WARNING - __main__ -   Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, 16-bits training: False
05/11/2022 17:51:14 - INFO - __main__ -   lang2id = None
05/11/2022 17:51:16 - INFO - __main__ -   Training/evaluation parameters Namespace(adam_epsilon=1e-08, cache_dir='', config_name='', data_dir=None, device=device(type='cuda'), do_eval=True, do_lower_case=False, do_train=False, doc_stride=128, eval_all_checkpoints=False, eval_lang='fi', evaluate_during_training=False, fp16=False, fp16_opt_level='O1', gradient_accumulation_steps=1, learning_rate=5e-05, local_rank=-1, logging_steps=50, max_answer_length=30, max_grad_norm=1.0, max_query_length=64, max_seq_length=384, max_steps=-1, model_name_or_path='/cluster/home/meiliu/scratch/xtreme_mbert_3e5_4_8_tydiqa/outputs-org//tydiqa/_LR3e-5_EPOCH3.0_maxlen384_batchsize4_gradacc8', model_type='bert', n_best_size=20, n_gpu=1, no_cuda=False, null_score_diff_threshold=0.0, num_train_epochs=3.0, output_dir='/cluster/home/meiliu/scratch/xtreme_mbert_3e5_4_8_tydiqa/outputs-org//tydiqa/_LR3e-5_EPOCH3.0_maxlen384_batchsize4_gradacc8/predictions/tydiqa/', overwrite_cache=False, overwrite_output_dir=False, per_gpu_eval_batch_size=8, per_gpu_train_batch_size=8, predict_file='/cluster/home/meiliu/scratch/xtreme_mbert_3e5_4_8_tydiqa/download//tydiqa//tydiqa-goldp-v1.1-dev/tydiqa-goldp-dev-fi.json', save_steps=50, seed=42, server_ip='', server_port='', threads=1, tokenizer_name='', train_file=None, train_lang='en', verbose_logging=False, version_2_with_negative=False, warmup_steps=0, weight_decay=0.0)
05/11/2022 17:51:16 - INFO - __main__ -   Loading checkpoint /cluster/home/meiliu/scratch/xtreme_mbert_3e5_4_8_tydiqa/outputs-org//tydiqa/_LR3e-5_EPOCH3.0_maxlen384_batchsize4_gradacc8 for evaluation
05/11/2022 17:51:16 - INFO - __main__ -   Evaluate the following checkpoints: ['/cluster/home/meiliu/scratch/xtreme_mbert_3e5_4_8_tydiqa/outputs-org//tydiqa/_LR3e-5_EPOCH3.0_maxlen384_batchsize4_gradacc8']
05/11/2022 17:51:19 - INFO - __main__ -   Creating features from dataset file at .
  0%|          | 0/782 [00:00<?, ?it/s] 69%|██████▊   | 537/782 [00:00<00:00, 5363.14it/s]100%|██████████| 782/782 [00:00<00:00, 5482.45it/s]
convert squad examples to features:   0%|          | 0/782 [00:00<?, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.
convert squad examples to features:   0%|          | 1/782 [00:00<02:55,  4.46it/s]convert squad examples to features:   4%|▍         | 33/782 [00:00<00:06, 118.56it/s]convert squad examples to features:   8%|▊         | 65/782 [00:00<00:04, 171.34it/s]convert squad examples to features:  12%|█▏        | 97/782 [00:00<00:03, 190.04it/s]convert squad examples to features:  21%|██        | 161/782 [00:00<00:02, 236.32it/s]convert squad examples to features:  29%|██▉       | 225/782 [00:01<00:02, 246.12it/s]convert squad examples to features:  33%|███▎      | 257/782 [00:01<00:02, 215.92it/s]convert squad examples to features:  37%|███▋      | 289/782 [00:01<00:02, 235.08it/s]convert squad examples to features:  41%|████      | 321/782 [00:01<00:02, 223.65it/s]convert squad examples to features:  45%|████▌     | 353/782 [00:01<00:01, 237.13it/s]convert squad examples to features:  49%|████▉     | 385/782 [00:01<00:01, 225.43it/s]convert squad examples to features:  53%|█████▎    | 417/782 [00:01<00:01, 240.98it/s]convert squad examples to features:  57%|█████▋    | 449/782 [00:02<00:01, 223.13it/s]convert squad examples to features:  62%|██████▏   | 481/782 [00:02<00:01, 238.35it/s]convert squad examples to features:  66%|██████▌   | 513/782 [00:02<00:01, 249.78it/s]convert squad examples to features:  70%|██████▉   | 545/782 [00:02<00:00, 266.06it/s]convert squad examples to features:  74%|███████▍  | 577/782 [00:02<00:00, 248.83it/s]convert squad examples to features:  78%|███████▊  | 609/782 [00:02<00:00, 263.80it/s]convert squad examples to features:  82%|████████▏ | 641/782 [00:02<00:00, 266.30it/s]convert squad examples to features:  86%|████████▌ | 673/782 [00:02<00:00, 265.64it/s]convert squad examples to features:  90%|█████████ | 705/782 [00:03<00:00, 274.75it/s]convert squad examples to features:  94%|█████████▍| 737/782 [00:03<00:00, 269.34it/s]convert squad examples to features: 100%|██████████| 782/782 [00:03<00:00, 244.42it/s]/cluster/project/sachan/meizhen/env_anaconda/software/envs/xtreme_tmp/lib/python3.6/site-packages/transformers/tokenization_utils_base.py:2278: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  FutureWarning,

add example index and unique id:   0%|          | 0/782 [00:00<?, ?it/s]add example index and unique id: 100%|██████████| 782/782 [00:00<00:00, 533845.33it/s]
05/11/2022 17:51:22 - INFO - __main__ -   Saving features into cached file ./cached_tydiqa-goldp-dev-fi.json__LR3e-5_EPOCH3.0_maxlen384_batchsize4_gradacc8_384_fi
05/11/2022 17:51:23 - INFO - __main__ -   ***** Running evaluation  *****
05/11/2022 17:51:23 - INFO - __main__ -     Num examples = 819
05/11/2022 17:51:23 - INFO - __main__ -     Batch size = 8
Evaluating:   0%|          | 0/103 [00:00<?, ?it/s]Evaluating:   1%|          | 1/103 [00:00<00:59,  1.72it/s]Evaluating:   3%|▎         | 3/103 [00:00<00:21,  4.74it/s]Evaluating:   5%|▍         | 5/103 [00:00<00:13,  7.05it/s]Evaluating:   7%|▋         | 7/103 [00:01<00:10,  8.85it/s]Evaluating:   9%|▊         | 9/103 [00:01<00:09, 10.17it/s]Evaluating:  11%|█         | 11/103 [00:01<00:08, 11.14it/s]Evaluating:  13%|█▎        | 13/103 [00:01<00:07, 11.81it/s]Evaluating:  15%|█▍        | 15/103 [00:01<00:07, 12.31it/s]Evaluating:  17%|█▋        | 17/103 [00:01<00:06, 12.65it/s]Evaluating:  18%|█▊        | 19/103 [00:01<00:06, 12.90it/s]Evaluating:  20%|██        | 21/103 [00:02<00:06, 13.11it/s]Evaluating:  22%|██▏       | 23/103 [00:02<00:06, 13.23it/s]Evaluating:  24%|██▍       | 25/103 [00:02<00:05, 13.30it/s]Evaluating:  26%|██▌       | 27/103 [00:02<00:05, 13.36it/s]Evaluating:  28%|██▊       | 29/103 [00:02<00:05, 13.38it/s]Evaluating:  30%|███       | 31/103 [00:02<00:05, 13.41it/s]Evaluating:  32%|███▏      | 33/103 [00:02<00:05, 13.42it/s]Evaluating:  34%|███▍      | 35/103 [00:03<00:05, 13.43it/s]Evaluating:  36%|███▌      | 37/103 [00:03<00:04, 13.45it/s]Evaluating:  38%|███▊      | 39/103 [00:03<00:04, 13.44it/s]Evaluating:  40%|███▉      | 41/103 [00:03<00:04, 13.45it/s]Evaluating:  42%|████▏     | 43/103 [00:03<00:04, 13.44it/s]Evaluating:  44%|████▎     | 45/103 [00:03<00:04, 13.45it/s]Evaluating:  46%|████▌     | 47/103 [00:04<00:04, 13.43it/s]Evaluating:  48%|████▊     | 49/103 [00:04<00:04, 13.43it/s]Evaluating:  50%|████▉     | 51/103 [00:04<00:03, 13.44it/s]Evaluating:  51%|█████▏    | 53/103 [00:04<00:03, 13.45it/s]Evaluating:  53%|█████▎    | 55/103 [00:04<00:03, 13.44it/s]Evaluating:  55%|█████▌    | 57/103 [00:04<00:03, 13.43it/s]Evaluating:  57%|█████▋    | 59/103 [00:04<00:03, 13.41it/s]Evaluating:  59%|█████▉    | 61/103 [00:05<00:03, 13.41it/s]Evaluating:  61%|██████    | 63/103 [00:05<00:02, 13.41it/s]Evaluating:  63%|██████▎   | 65/103 [00:05<00:02, 13.40it/s]Evaluating:  65%|██████▌   | 67/103 [00:05<00:02, 13.41it/s]Evaluating:  67%|██████▋   | 69/103 [00:05<00:02, 13.40it/s]Evaluating:  69%|██████▉   | 71/103 [00:05<00:02, 13.40it/s]Evaluating:  71%|███████   | 73/103 [00:05<00:02, 12.79it/s]Evaluating:  73%|███████▎  | 75/103 [00:06<00:02, 12.99it/s]Evaluating:  75%|███████▍  | 77/103 [00:06<00:01, 13.11it/s]Evaluating:  77%|███████▋  | 79/103 [00:06<00:01, 13.21it/s]Evaluating:  79%|███████▊  | 81/103 [00:06<00:01, 13.27it/s]Evaluating:  81%|████████  | 83/103 [00:06<00:01, 13.32it/s]Evaluating:  83%|████████▎ | 85/103 [00:06<00:01, 13.36it/s]Evaluating:  84%|████████▍ | 87/103 [00:07<00:01, 13.37it/s]Evaluating:  86%|████████▋ | 89/103 [00:07<00:01, 11.30it/s]Evaluating:  88%|████████▊ | 91/103 [00:07<00:01, 11.87it/s]Evaluating:  90%|█████████ | 93/103 [00:07<00:00, 12.32it/s]Evaluating:  92%|█████████▏| 95/103 [00:07<00:00, 12.63it/s]Evaluating:  94%|█████████▍| 97/103 [00:07<00:00, 12.86it/s]Evaluating:  96%|█████████▌| 99/103 [00:08<00:00, 13.02it/s]Evaluating:  98%|█████████▊| 101/103 [00:08<00:00, 13.12it/s]Evaluating: 100%|██████████| 103/103 [00:08<00:00, 14.47it/s]Evaluating: 100%|██████████| 103/103 [00:08<00:00, 12.47it/s]
05/11/2022 17:51:31 - INFO - __main__ -     Evaluation done in total 8.257574 secs (0.010083 sec per example)
05/11/2022 17:51:34 - INFO - __main__ -   Results: {'exact': 69.30946291560102, 'f1': 80.75532001204597, 'total': 782, 'HasAns_exact': 69.30946291560102, 'HasAns_f1': 80.75532001204597, 'HasAns_total': 782, 'best_exact': 69.30946291560102, 'best_exact_thresh': 0.0, 'best_f1': 80.75532001204597, 'best_f1_thresh': 0.0}
  id 
05/11/2022 17:51:48 - WARNING - __main__ -   Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, 16-bits training: False
05/11/2022 17:51:50 - INFO - __main__ -   lang2id = None
05/11/2022 17:51:53 - INFO - __main__ -   Training/evaluation parameters Namespace(adam_epsilon=1e-08, cache_dir='', config_name='', data_dir=None, device=device(type='cuda'), do_eval=True, do_lower_case=False, do_train=False, doc_stride=128, eval_all_checkpoints=False, eval_lang='id', evaluate_during_training=False, fp16=False, fp16_opt_level='O1', gradient_accumulation_steps=1, learning_rate=5e-05, local_rank=-1, logging_steps=50, max_answer_length=30, max_grad_norm=1.0, max_query_length=64, max_seq_length=384, max_steps=-1, model_name_or_path='/cluster/home/meiliu/scratch/xtreme_mbert_3e5_4_8_tydiqa/outputs-org//tydiqa/_LR3e-5_EPOCH3.0_maxlen384_batchsize4_gradacc8', model_type='bert', n_best_size=20, n_gpu=1, no_cuda=False, null_score_diff_threshold=0.0, num_train_epochs=3.0, output_dir='/cluster/home/meiliu/scratch/xtreme_mbert_3e5_4_8_tydiqa/outputs-org//tydiqa/_LR3e-5_EPOCH3.0_maxlen384_batchsize4_gradacc8/predictions/tydiqa/', overwrite_cache=False, overwrite_output_dir=False, per_gpu_eval_batch_size=8, per_gpu_train_batch_size=8, predict_file='/cluster/home/meiliu/scratch/xtreme_mbert_3e5_4_8_tydiqa/download//tydiqa//tydiqa-goldp-v1.1-dev/tydiqa-goldp-dev-id.json', save_steps=50, seed=42, server_ip='', server_port='', threads=1, tokenizer_name='', train_file=None, train_lang='en', verbose_logging=False, version_2_with_negative=False, warmup_steps=0, weight_decay=0.0)
05/11/2022 17:51:53 - INFO - __main__ -   Loading checkpoint /cluster/home/meiliu/scratch/xtreme_mbert_3e5_4_8_tydiqa/outputs-org//tydiqa/_LR3e-5_EPOCH3.0_maxlen384_batchsize4_gradacc8 for evaluation
05/11/2022 17:51:53 - INFO - __main__ -   Evaluate the following checkpoints: ['/cluster/home/meiliu/scratch/xtreme_mbert_3e5_4_8_tydiqa/outputs-org//tydiqa/_LR3e-5_EPOCH3.0_maxlen384_batchsize4_gradacc8']
05/11/2022 17:51:56 - INFO - __main__ -   Creating features from dataset file at .
  0%|          | 0/565 [00:00<?, ?it/s] 62%|██████▏   | 351/565 [00:00<00:00, 3505.53it/s]100%|██████████| 565/565 [00:00<00:00, 3945.56it/s]
convert squad examples to features:   0%|          | 0/565 [00:00<?, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.
convert squad examples to features:   0%|          | 1/565 [00:00<02:36,  3.61it/s]convert squad examples to features:   6%|▌         | 33/565 [00:00<00:06, 87.25it/s]convert squad examples to features:  12%|█▏        | 65/565 [00:00<00:04, 118.92it/s]convert squad examples to features:  17%|█▋        | 97/565 [00:00<00:03, 141.30it/s]convert squad examples to features:  23%|██▎       | 129/565 [00:00<00:02, 162.81it/s]convert squad examples to features:  28%|██▊       | 161/565 [00:01<00:02, 188.04it/s]convert squad examples to features:  34%|███▍      | 193/565 [00:01<00:01, 211.69it/s]convert squad examples to features:  40%|███▉      | 225/565 [00:01<00:01, 218.37it/s]convert squad examples to features:  45%|████▌     | 257/565 [00:01<00:01, 220.03it/s]convert squad examples to features:  51%|█████     | 289/565 [00:01<00:01, 231.39it/s]convert squad examples to features:  57%|█████▋    | 321/565 [00:01<00:01, 214.83it/s]convert squad examples to features:  62%|██████▏   | 353/565 [00:01<00:00, 230.00it/s]convert squad examples to features:  68%|██████▊   | 385/565 [00:02<00:00, 226.42it/s]convert squad examples to features:  74%|███████▍  | 417/565 [00:02<00:00, 235.61it/s]convert squad examples to features:  79%|███████▉  | 449/565 [00:02<00:00, 232.98it/s]convert squad examples to features:  85%|████████▌ | 481/565 [00:02<00:00, 230.62it/s]convert squad examples to features:  91%|█████████ | 513/565 [00:02<00:00, 234.85it/s]convert squad examples to features:  96%|█████████▋| 545/565 [00:02<00:00, 229.81it/s]convert squad examples to features: 100%|██████████| 565/565 [00:02<00:00, 206.02it/s]/cluster/project/sachan/meizhen/env_anaconda/software/envs/xtreme_tmp/lib/python3.6/site-packages/transformers/tokenization_utils_base.py:2278: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  FutureWarning,

add example index and unique id:   0%|          | 0/565 [00:00<?, ?it/s]add example index and unique id: 100%|██████████| 565/565 [00:00<00:00, 384642.39it/s]
05/11/2022 17:51:59 - INFO - __main__ -   Saving features into cached file ./cached_tydiqa-goldp-dev-id.json__LR3e-5_EPOCH3.0_maxlen384_batchsize4_gradacc8_384_id
05/11/2022 17:51:59 - INFO - __main__ -   ***** Running evaluation  *****
05/11/2022 17:51:59 - INFO - __main__ -     Num examples = 587
05/11/2022 17:51:59 - INFO - __main__ -     Batch size = 8
Evaluating:   0%|          | 0/74 [00:00<?, ?it/s]Evaluating:   1%|▏         | 1/74 [00:00<00:49,  1.49it/s]Evaluating:   4%|▍         | 3/74 [00:00<00:16,  4.26it/s]Evaluating:   7%|▋         | 5/74 [00:00<00:10,  6.53it/s]Evaluating:   9%|▉         | 7/74 [00:01<00:08,  8.33it/s]Evaluating:  12%|█▏        | 9/74 [00:01<00:06,  9.69it/s]Evaluating:  15%|█▍        | 11/74 [00:01<00:05, 10.68it/s]Evaluating:  18%|█▊        | 13/74 [00:01<00:05, 11.39it/s]Evaluating:  20%|██        | 15/74 [00:01<00:04, 11.97it/s]Evaluating:  23%|██▎       | 17/74 [00:01<00:04, 12.36it/s]Evaluating:  26%|██▌       | 19/74 [00:02<00:04, 12.64it/s]Evaluating:  28%|██▊       | 21/74 [00:02<00:04, 12.84it/s]Evaluating:  31%|███       | 23/74 [00:02<00:03, 12.99it/s]Evaluating:  34%|███▍      | 25/74 [00:02<00:03, 13.11it/s]Evaluating:  36%|███▋      | 27/74 [00:02<00:03, 13.17it/s]Evaluating:  39%|███▉      | 29/74 [00:02<00:03, 13.22it/s]Evaluating:  42%|████▏     | 31/74 [00:02<00:03, 13.28it/s]Evaluating:  45%|████▍     | 33/74 [00:03<00:03, 13.31it/s]Evaluating:  47%|████▋     | 35/74 [00:03<00:02, 13.32it/s]Evaluating:  50%|█████     | 37/74 [00:03<00:02, 13.34it/s]Evaluating:  53%|█████▎    | 39/74 [00:03<00:02, 13.33it/s]Evaluating:  55%|█████▌    | 41/74 [00:03<00:02, 13.36it/s]Evaluating:  58%|█████▊    | 43/74 [00:03<00:02, 13.34it/s]Evaluating:  61%|██████    | 45/74 [00:03<00:02, 13.36it/s]Evaluating:  64%|██████▎   | 47/74 [00:04<00:02, 13.36it/s]Evaluating:  66%|██████▌   | 49/74 [00:04<00:01, 13.36it/s]Evaluating:  69%|██████▉   | 51/74 [00:04<00:01, 13.37it/s]Evaluating:  72%|███████▏  | 53/74 [00:04<00:01, 13.37it/s]Evaluating:  74%|███████▍  | 55/74 [00:04<00:01, 13.38it/s]Evaluating:  77%|███████▋  | 57/74 [00:04<00:01, 13.39it/s]Evaluating:  80%|███████▉  | 59/74 [00:05<00:01, 13.37it/s]Evaluating:  82%|████████▏ | 61/74 [00:05<00:00, 13.37it/s]Evaluating:  85%|████████▌ | 63/74 [00:05<00:00, 13.35it/s]Evaluating:  88%|████████▊ | 65/74 [00:05<00:00, 13.27it/s]Evaluating:  91%|█████████ | 67/74 [00:05<00:00, 13.30it/s]Evaluating:  93%|█████████▎| 69/74 [00:05<00:00, 13.34it/s]Evaluating:  96%|█████████▌| 71/74 [00:05<00:00, 13.33it/s]Evaluating:  99%|█████████▊| 73/74 [00:06<00:00, 13.33it/s]Evaluating: 100%|██████████| 74/74 [00:06<00:00, 12.10it/s]
05/11/2022 17:52:06 - INFO - __main__ -     Evaluation done in total 6.119056 secs (0.010424 sec per example)
05/11/2022 17:52:08 - INFO - __main__ -   Results: {'exact': 75.57522123893806, 'f1': 85.01668618387964, 'total': 565, 'HasAns_exact': 75.57522123893806, 'HasAns_f1': 85.01668618387964, 'HasAns_total': 565, 'best_exact': 75.57522123893806, 'best_exact_thresh': 0.0, 'best_f1': 85.01668618387964, 'best_f1_thresh': 0.0}
  ko 
05/11/2022 17:52:14 - WARNING - __main__ -   Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, 16-bits training: False
05/11/2022 17:52:17 - INFO - __main__ -   lang2id = None
05/11/2022 17:52:19 - INFO - __main__ -   Training/evaluation parameters Namespace(adam_epsilon=1e-08, cache_dir='', config_name='', data_dir=None, device=device(type='cuda'), do_eval=True, do_lower_case=False, do_train=False, doc_stride=128, eval_all_checkpoints=False, eval_lang='ko', evaluate_during_training=False, fp16=False, fp16_opt_level='O1', gradient_accumulation_steps=1, learning_rate=5e-05, local_rank=-1, logging_steps=50, max_answer_length=30, max_grad_norm=1.0, max_query_length=64, max_seq_length=384, max_steps=-1, model_name_or_path='/cluster/home/meiliu/scratch/xtreme_mbert_3e5_4_8_tydiqa/outputs-org//tydiqa/_LR3e-5_EPOCH3.0_maxlen384_batchsize4_gradacc8', model_type='bert', n_best_size=20, n_gpu=1, no_cuda=False, null_score_diff_threshold=0.0, num_train_epochs=3.0, output_dir='/cluster/home/meiliu/scratch/xtreme_mbert_3e5_4_8_tydiqa/outputs-org//tydiqa/_LR3e-5_EPOCH3.0_maxlen384_batchsize4_gradacc8/predictions/tydiqa/', overwrite_cache=False, overwrite_output_dir=False, per_gpu_eval_batch_size=8, per_gpu_train_batch_size=8, predict_file='/cluster/home/meiliu/scratch/xtreme_mbert_3e5_4_8_tydiqa/download//tydiqa//tydiqa-goldp-v1.1-dev/tydiqa-goldp-dev-ko.json', save_steps=50, seed=42, server_ip='', server_port='', threads=1, tokenizer_name='', train_file=None, train_lang='en', verbose_logging=False, version_2_with_negative=False, warmup_steps=0, weight_decay=0.0)
05/11/2022 17:52:19 - INFO - __main__ -   Loading checkpoint /cluster/home/meiliu/scratch/xtreme_mbert_3e5_4_8_tydiqa/outputs-org//tydiqa/_LR3e-5_EPOCH3.0_maxlen384_batchsize4_gradacc8 for evaluation
05/11/2022 17:52:19 - INFO - __main__ -   Evaluate the following checkpoints: ['/cluster/home/meiliu/scratch/xtreme_mbert_3e5_4_8_tydiqa/outputs-org//tydiqa/_LR3e-5_EPOCH3.0_maxlen384_batchsize4_gradacc8']
05/11/2022 17:52:22 - INFO - __main__ -   Creating features from dataset file at .
  0%|          | 0/276 [00:00<?, ?it/s]100%|██████████| 276/276 [00:00<00:00, 9078.01it/s]
convert squad examples to features:   0%|          | 0/276 [00:00<?, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.
convert squad examples to features:   0%|          | 1/276 [00:00<01:12,  3.78it/s]convert squad examples to features:  12%|█▏        | 33/276 [00:00<00:02, 96.66it/s]convert squad examples to features:  24%|██▎       | 65/276 [00:00<00:01, 151.90it/s]convert squad examples to features:  35%|███▌      | 97/276 [00:00<00:01, 176.77it/s]convert squad examples to features:  47%|████▋     | 129/276 [00:00<00:01, 146.29it/s]convert squad examples to features:  70%|██████▉   | 193/276 [00:01<00:00, 204.71it/s]convert squad examples to features:  82%|████████▏ | 225/276 [00:01<00:00, 218.26it/s]convert squad examples to features: 100%|██████████| 276/276 [00:01<00:00, 203.99it/s]/cluster/project/sachan/meizhen/env_anaconda/software/envs/xtreme_tmp/lib/python3.6/site-packages/transformers/tokenization_utils_base.py:2278: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  FutureWarning,

add example index and unique id:   0%|          | 0/276 [00:00<?, ?it/s]add example index and unique id: 100%|██████████| 276/276 [00:00<00:00, 712825.06it/s]
05/11/2022 17:52:23 - INFO - __main__ -   Saving features into cached file ./cached_tydiqa-goldp-dev-ko.json__LR3e-5_EPOCH3.0_maxlen384_batchsize4_gradacc8_384_ko
05/11/2022 17:52:24 - INFO - __main__ -   ***** Running evaluation  *****
05/11/2022 17:52:24 - INFO - __main__ -     Num examples = 306
05/11/2022 17:52:24 - INFO - __main__ -     Batch size = 8
Evaluating:   0%|          | 0/39 [00:00<?, ?it/s]Evaluating:   3%|▎         | 1/39 [00:00<00:21,  1.74it/s]Evaluating:   8%|▊         | 3/39 [00:00<00:07,  4.76it/s]Evaluating:  13%|█▎        | 5/39 [00:00<00:04,  7.09it/s]Evaluating:  18%|█▊        | 7/39 [00:01<00:03,  8.86it/s]Evaluating:  23%|██▎       | 9/39 [00:01<00:02, 10.18it/s]Evaluating:  28%|██▊       | 11/39 [00:01<00:02, 11.12it/s]Evaluating:  33%|███▎      | 13/39 [00:01<00:02, 11.79it/s]Evaluating:  38%|███▊      | 15/39 [00:01<00:01, 12.28it/s]Evaluating:  44%|████▎     | 17/39 [00:01<00:01, 12.62it/s]Evaluating:  49%|████▊     | 19/39 [00:01<00:01, 12.76it/s]Evaluating:  54%|█████▍    | 21/39 [00:02<00:01, 12.96it/s]Evaluating:  59%|█████▉    | 23/39 [00:02<00:01, 13.10it/s]Evaluating:  64%|██████▍   | 25/39 [00:02<00:01, 13.19it/s]Evaluating:  69%|██████▉   | 27/39 [00:02<00:00, 13.26it/s]Evaluating:  74%|███████▍  | 29/39 [00:02<00:00, 13.31it/s]Evaluating:  79%|███████▉  | 31/39 [00:02<00:00, 13.34it/s]Evaluating:  85%|████████▍ | 33/39 [00:02<00:00, 13.37it/s]Evaluating:  90%|████████▉ | 35/39 [00:03<00:00, 13.37it/s]Evaluating:  95%|█████████▍| 37/39 [00:03<00:00, 13.38it/s]Evaluating: 100%|██████████| 39/39 [00:03<00:00, 11.55it/s]
05/11/2022 17:52:27 - INFO - __main__ -     Evaluation done in total 3.375593 secs (0.011031 sec per example)
05/11/2022 17:52:28 - INFO - __main__ -   Results: {'exact': 58.333333333333336, 'f1': 68.65614418662622, 'total': 276, 'HasAns_exact': 58.333333333333336, 'HasAns_f1': 68.65614418662622, 'HasAns_total': 276, 'best_exact': 58.333333333333336, 'best_exact_thresh': 0.0, 'best_f1': 68.65614418662622, 'best_f1_thresh': 0.0}
  ru 
05/11/2022 17:52:34 - WARNING - __main__ -   Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, 16-bits training: False
05/11/2022 17:52:36 - INFO - __main__ -   lang2id = None
05/11/2022 17:52:39 - INFO - __main__ -   Training/evaluation parameters Namespace(adam_epsilon=1e-08, cache_dir='', config_name='', data_dir=None, device=device(type='cuda'), do_eval=True, do_lower_case=False, do_train=False, doc_stride=128, eval_all_checkpoints=False, eval_lang='ru', evaluate_during_training=False, fp16=False, fp16_opt_level='O1', gradient_accumulation_steps=1, learning_rate=5e-05, local_rank=-1, logging_steps=50, max_answer_length=30, max_grad_norm=1.0, max_query_length=64, max_seq_length=384, max_steps=-1, model_name_or_path='/cluster/home/meiliu/scratch/xtreme_mbert_3e5_4_8_tydiqa/outputs-org//tydiqa/_LR3e-5_EPOCH3.0_maxlen384_batchsize4_gradacc8', model_type='bert', n_best_size=20, n_gpu=1, no_cuda=False, null_score_diff_threshold=0.0, num_train_epochs=3.0, output_dir='/cluster/home/meiliu/scratch/xtreme_mbert_3e5_4_8_tydiqa/outputs-org//tydiqa/_LR3e-5_EPOCH3.0_maxlen384_batchsize4_gradacc8/predictions/tydiqa/', overwrite_cache=False, overwrite_output_dir=False, per_gpu_eval_batch_size=8, per_gpu_train_batch_size=8, predict_file='/cluster/home/meiliu/scratch/xtreme_mbert_3e5_4_8_tydiqa/download//tydiqa//tydiqa-goldp-v1.1-dev/tydiqa-goldp-dev-ru.json', save_steps=50, seed=42, server_ip='', server_port='', threads=1, tokenizer_name='', train_file=None, train_lang='en', verbose_logging=False, version_2_with_negative=False, warmup_steps=0, weight_decay=0.0)
05/11/2022 17:52:39 - INFO - __main__ -   Loading checkpoint /cluster/home/meiliu/scratch/xtreme_mbert_3e5_4_8_tydiqa/outputs-org//tydiqa/_LR3e-5_EPOCH3.0_maxlen384_batchsize4_gradacc8 for evaluation
05/11/2022 17:52:39 - INFO - __main__ -   Evaluate the following checkpoints: ['/cluster/home/meiliu/scratch/xtreme_mbert_3e5_4_8_tydiqa/outputs-org//tydiqa/_LR3e-5_EPOCH3.0_maxlen384_batchsize4_gradacc8']
05/11/2022 17:52:41 - INFO - __main__ -   Creating features from dataset file at .
  0%|          | 0/812 [00:00<?, ?it/s] 57%|█████▋    | 460/812 [00:00<00:00, 4597.63it/s]100%|██████████| 812/812 [00:00<00:00, 4650.86it/s]
convert squad examples to features:   0%|          | 0/812 [00:00<?, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.
convert squad examples to features:   0%|          | 1/812 [00:00<03:57,  3.41it/s]convert squad examples to features:   4%|▍         | 33/812 [00:00<00:08, 87.31it/s]convert squad examples to features:   8%|▊         | 65/812 [00:00<00:06, 113.85it/s]convert squad examples to features:  12%|█▏        | 97/812 [00:00<00:05, 134.34it/s]convert squad examples to features:  16%|█▌        | 129/812 [00:01<00:05, 134.91it/s]convert squad examples to features:  20%|█▉        | 161/812 [00:01<00:04, 138.18it/s]convert squad examples to features:  24%|██▍       | 193/812 [00:01<00:05, 111.94it/s]convert squad examples to features:  28%|██▊       | 225/812 [00:01<00:04, 117.75it/s]convert squad examples to features:  32%|███▏      | 257/812 [00:02<00:04, 138.62it/s]convert squad examples to features:  36%|███▌      | 289/812 [00:02<00:03, 167.91it/s]convert squad examples to features:  40%|███▉      | 321/812 [00:02<00:02, 177.40it/s]convert squad examples to features:  43%|████▎     | 353/812 [00:02<00:02, 164.45it/s]convert squad examples to features:  47%|████▋     | 385/812 [00:02<00:02, 175.39it/s]convert squad examples to features:  51%|█████▏    | 417/812 [00:02<00:02, 186.60it/s]convert squad examples to features:  55%|█████▌    | 449/812 [00:03<00:01, 207.86it/s]convert squad examples to features:  59%|█████▉    | 481/812 [00:03<00:01, 205.64it/s]convert squad examples to features:  63%|██████▎   | 513/812 [00:03<00:01, 185.39it/s]convert squad examples to features:  67%|██████▋   | 545/812 [00:03<00:01, 186.71it/s]convert squad examples to features:  71%|███████   | 577/812 [00:03<00:01, 196.29it/s]convert squad examples to features:  75%|███████▌  | 609/812 [00:03<00:01, 196.05it/s]convert squad examples to features:  79%|███████▉  | 641/812 [00:03<00:00, 202.78it/s]convert squad examples to features:  83%|████████▎ | 673/812 [00:04<00:00, 192.27it/s]convert squad examples to features:  87%|████████▋ | 705/812 [00:04<00:00, 167.25it/s]convert squad examples to features:  91%|█████████ | 737/812 [00:04<00:00, 170.43it/s]convert squad examples to features:  95%|█████████▍| 769/812 [00:04<00:00, 172.56it/s]convert squad examples to features:  99%|█████████▊| 801/812 [00:04<00:00, 197.08it/s]convert squad examples to features: 100%|██████████| 812/812 [00:04<00:00, 165.66it/s]/cluster/project/sachan/meizhen/env_anaconda/software/envs/xtreme_tmp/lib/python3.6/site-packages/transformers/tokenization_utils_base.py:2278: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  FutureWarning,

add example index and unique id:   0%|          | 0/812 [00:00<?, ?it/s]add example index and unique id: 100%|██████████| 812/812 [00:00<00:00, 454406.25it/s]
05/11/2022 17:52:46 - INFO - __main__ -   Saving features into cached file ./cached_tydiqa-goldp-dev-ru.json__LR3e-5_EPOCH3.0_maxlen384_batchsize4_gradacc8_384_ru
05/11/2022 17:52:47 - INFO - __main__ -   ***** Running evaluation  *****
05/11/2022 17:52:47 - INFO - __main__ -     Num examples = 914
05/11/2022 17:52:47 - INFO - __main__ -     Batch size = 8
Evaluating:   0%|          | 0/115 [00:00<?, ?it/s]Evaluating:   1%|          | 1/115 [00:00<01:07,  1.70it/s]Evaluating:   3%|▎         | 3/115 [00:00<00:23,  4.76it/s]Evaluating:   4%|▍         | 5/115 [00:00<00:15,  7.14it/s]Evaluating:   6%|▌         | 7/115 [00:01<00:12,  8.90it/s]Evaluating:   8%|▊         | 9/115 [00:01<00:10, 10.15it/s]Evaluating:  10%|▉         | 11/115 [00:01<00:09, 11.05it/s]Evaluating:  11%|█▏        | 13/115 [00:01<00:08, 11.70it/s]Evaluating:  13%|█▎        | 15/115 [00:01<00:08, 12.21it/s]Evaluating:  15%|█▍        | 17/115 [00:01<00:07, 12.56it/s]Evaluating:  17%|█▋        | 19/115 [00:01<00:07, 12.80it/s]Evaluating:  18%|█▊        | 21/115 [00:02<00:07, 13.00it/s]Evaluating:  20%|██        | 23/115 [00:02<00:07, 13.13it/s]Evaluating:  22%|██▏       | 25/115 [00:02<00:06, 13.23it/s]Evaluating:  23%|██▎       | 27/115 [00:02<00:06, 13.29it/s]Evaluating:  25%|██▌       | 29/115 [00:02<00:06, 13.31it/s]Evaluating:  27%|██▋       | 31/115 [00:02<00:06, 13.33it/s]Evaluating:  29%|██▊       | 33/115 [00:02<00:06, 13.36it/s]Evaluating:  30%|███       | 35/115 [00:03<00:05, 13.38it/s]Evaluating:  32%|███▏      | 37/115 [00:03<00:05, 13.38it/s]Evaluating:  34%|███▍      | 39/115 [00:03<00:05, 13.38it/s]Evaluating:  36%|███▌      | 41/115 [00:03<00:05, 13.36it/s]Evaluating:  37%|███▋      | 43/115 [00:03<00:05, 12.99it/s]Evaluating:  39%|███▉      | 45/115 [00:03<00:05, 13.12it/s]Evaluating:  41%|████      | 47/115 [00:04<00:05, 13.21it/s]Evaluating:  43%|████▎     | 49/115 [00:04<00:04, 13.27it/s]Evaluating:  44%|████▍     | 51/115 [00:04<00:04, 13.31it/s]Evaluating:  46%|████▌     | 53/115 [00:04<00:04, 13.31it/s]Evaluating:  48%|████▊     | 55/115 [00:04<00:04, 13.35it/s]Evaluating:  50%|████▉     | 57/115 [00:04<00:04, 13.36it/s]Evaluating:  51%|█████▏    | 59/115 [00:05<00:05, 11.14it/s]Evaluating:  53%|█████▎    | 61/115 [00:05<00:04, 11.72it/s]Evaluating:  55%|█████▍    | 63/115 [00:05<00:04, 12.19it/s]Evaluating:  57%|█████▋    | 65/115 [00:05<00:03, 12.53it/s]Evaluating:  58%|█████▊    | 67/115 [00:05<00:03, 12.76it/s]Evaluating:  60%|██████    | 69/115 [00:05<00:03, 12.95it/s]Evaluating:  62%|██████▏   | 71/115 [00:05<00:03, 13.06it/s]Evaluating:  63%|██████▎   | 73/115 [00:06<00:03, 13.17it/s]Evaluating:  65%|██████▌   | 75/115 [00:06<00:03, 13.23it/s]Evaluating:  67%|██████▋   | 77/115 [00:06<00:02, 13.27it/s]Evaluating:  69%|██████▊   | 79/115 [00:06<00:02, 13.28it/s]Evaluating:  70%|███████   | 81/115 [00:06<00:02, 13.33it/s]Evaluating:  72%|███████▏  | 83/115 [00:06<00:02, 13.35it/s]Evaluating:  74%|███████▍  | 85/115 [00:06<00:02, 13.35it/s]Evaluating:  76%|███████▌  | 87/115 [00:07<00:02, 13.34it/s]Evaluating:  77%|███████▋  | 89/115 [00:07<00:01, 13.31it/s]Evaluating:  79%|███████▉  | 91/115 [00:07<00:01, 13.35it/s]Evaluating:  81%|████████  | 93/115 [00:07<00:01, 13.36it/s]Evaluating:  83%|████████▎ | 95/115 [00:07<00:01, 13.36it/s]Evaluating:  84%|████████▍ | 97/115 [00:07<00:01, 13.37it/s]Evaluating:  86%|████████▌ | 99/115 [00:08<00:01, 13.36it/s]Evaluating:  88%|████████▊ | 101/115 [00:08<00:01, 13.35it/s]Evaluating:  90%|████████▉ | 103/115 [00:08<00:00, 13.35it/s]Evaluating:  91%|█████████▏| 105/115 [00:08<00:00, 13.35it/s]Evaluating:  93%|█████████▎| 107/115 [00:08<00:00, 13.35it/s]Evaluating:  95%|█████████▍| 109/115 [00:08<00:00, 13.34it/s]Evaluating:  97%|█████████▋| 111/115 [00:08<00:00, 13.35it/s]Evaluating:  98%|█████████▊| 113/115 [00:09<00:00, 13.35it/s]Evaluating: 100%|██████████| 115/115 [00:09<00:00, 12.53it/s]
05/11/2022 17:52:56 - INFO - __main__ -     Evaluation done in total 9.179184 secs (0.010043 sec per example)
05/11/2022 17:52:59 - INFO - __main__ -   Results: {'exact': 60.09852216748769, 'f1': 76.40780421795793, 'total': 812, 'HasAns_exact': 60.09852216748769, 'HasAns_f1': 76.40780421795793, 'HasAns_total': 812, 'best_exact': 60.09852216748769, 'best_exact_thresh': 0.0, 'best_f1': 76.40780421795793, 'best_f1_thresh': 0.0}
  sw 
05/11/2022 17:53:13 - WARNING - __main__ -   Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, 16-bits training: False
05/11/2022 17:53:15 - INFO - __main__ -   lang2id = None
05/11/2022 17:53:18 - INFO - __main__ -   Training/evaluation parameters Namespace(adam_epsilon=1e-08, cache_dir='', config_name='', data_dir=None, device=device(type='cuda'), do_eval=True, do_lower_case=False, do_train=False, doc_stride=128, eval_all_checkpoints=False, eval_lang='sw', evaluate_during_training=False, fp16=False, fp16_opt_level='O1', gradient_accumulation_steps=1, learning_rate=5e-05, local_rank=-1, logging_steps=50, max_answer_length=30, max_grad_norm=1.0, max_query_length=64, max_seq_length=384, max_steps=-1, model_name_or_path='/cluster/home/meiliu/scratch/xtreme_mbert_3e5_4_8_tydiqa/outputs-org//tydiqa/_LR3e-5_EPOCH3.0_maxlen384_batchsize4_gradacc8', model_type='bert', n_best_size=20, n_gpu=1, no_cuda=False, null_score_diff_threshold=0.0, num_train_epochs=3.0, output_dir='/cluster/home/meiliu/scratch/xtreme_mbert_3e5_4_8_tydiqa/outputs-org//tydiqa/_LR3e-5_EPOCH3.0_maxlen384_batchsize4_gradacc8/predictions/tydiqa/', overwrite_cache=False, overwrite_output_dir=False, per_gpu_eval_batch_size=8, per_gpu_train_batch_size=8, predict_file='/cluster/home/meiliu/scratch/xtreme_mbert_3e5_4_8_tydiqa/download//tydiqa//tydiqa-goldp-v1.1-dev/tydiqa-goldp-dev-sw.json', save_steps=50, seed=42, server_ip='', server_port='', threads=1, tokenizer_name='', train_file=None, train_lang='en', verbose_logging=False, version_2_with_negative=False, warmup_steps=0, weight_decay=0.0)
05/11/2022 17:53:18 - INFO - __main__ -   Loading checkpoint /cluster/home/meiliu/scratch/xtreme_mbert_3e5_4_8_tydiqa/outputs-org//tydiqa/_LR3e-5_EPOCH3.0_maxlen384_batchsize4_gradacc8 for evaluation
05/11/2022 17:53:18 - INFO - __main__ -   Evaluate the following checkpoints: ['/cluster/home/meiliu/scratch/xtreme_mbert_3e5_4_8_tydiqa/outputs-org//tydiqa/_LR3e-5_EPOCH3.0_maxlen384_batchsize4_gradacc8']
05/11/2022 17:53:20 - INFO - __main__ -   Creating features from dataset file at .
  0%|          | 0/499 [00:00<?, ?it/s]100%|██████████| 499/499 [00:00<00:00, 7859.31it/s]
convert squad examples to features:   0%|          | 0/499 [00:00<?, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.
convert squad examples to features:   0%|          | 1/499 [00:00<01:51,  4.46it/s]convert squad examples to features:   7%|▋         | 33/499 [00:00<00:03, 116.59it/s]convert squad examples to features:  13%|█▎        | 65/499 [00:00<00:02, 168.73it/s]convert squad examples to features:  19%|█▉        | 97/499 [00:00<00:02, 200.33it/s]convert squad examples to features:  26%|██▌       | 129/499 [00:00<00:01, 224.51it/s]convert squad examples to features:  32%|███▏      | 161/499 [00:00<00:01, 246.68it/s]convert squad examples to features:  39%|███▊      | 193/499 [00:00<00:01, 255.74it/s]convert squad examples to features:  45%|████▌     | 225/499 [00:01<00:01, 270.37it/s]convert squad examples to features:  52%|█████▏    | 257/499 [00:01<00:00, 269.97it/s]convert squad examples to features:  58%|█████▊    | 289/499 [00:01<00:00, 279.79it/s]convert squad examples to features:  71%|███████   | 353/499 [00:01<00:00, 323.98it/s]convert squad examples to features:  84%|████████▎ | 417/499 [00:01<00:00, 320.18it/s]convert squad examples to features:  96%|█████████▋| 481/499 [00:01<00:00, 364.75it/s]convert squad examples to features: 100%|██████████| 499/499 [00:01<00:00, 282.28it/s]/cluster/project/sachan/meizhen/env_anaconda/software/envs/xtreme_tmp/lib/python3.6/site-packages/transformers/tokenization_utils_base.py:2278: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  FutureWarning,

add example index and unique id:   0%|          | 0/499 [00:00<?, ?it/s]add example index and unique id: 100%|██████████| 499/499 [00:00<00:00, 390768.80it/s]
05/11/2022 17:53:22 - INFO - __main__ -   Saving features into cached file ./cached_tydiqa-goldp-dev-sw.json__LR3e-5_EPOCH3.0_maxlen384_batchsize4_gradacc8_384_sw
05/11/2022 17:53:23 - INFO - __main__ -   ***** Running evaluation  *****
05/11/2022 17:53:23 - INFO - __main__ -     Num examples = 504
05/11/2022 17:53:23 - INFO - __main__ -     Batch size = 8
Evaluating:   0%|          | 0/63 [00:00<?, ?it/s]Evaluating:   2%|▏         | 1/63 [00:00<00:39,  1.56it/s]Evaluating:   5%|▍         | 3/63 [00:00<00:13,  4.49it/s]Evaluating:   8%|▊         | 5/63 [00:00<00:08,  6.82it/s]Evaluating:  11%|█         | 7/63 [00:01<00:06,  8.62it/s]Evaluating:  14%|█▍        | 9/63 [00:01<00:05,  9.96it/s]Evaluating:  17%|█▋        | 11/63 [00:01<00:04, 10.94it/s]Evaluating:  21%|██        | 13/63 [00:01<00:04, 11.62it/s]Evaluating:  24%|██▍       | 15/63 [00:01<00:03, 12.15it/s]Evaluating:  27%|██▋       | 17/63 [00:01<00:03, 12.52it/s]Evaluating:  30%|███       | 19/63 [00:01<00:03, 12.80it/s]Evaluating:  33%|███▎      | 21/63 [00:02<00:03, 12.98it/s]Evaluating:  37%|███▋      | 23/63 [00:02<00:03, 13.11it/s]Evaluating:  40%|███▉      | 25/63 [00:02<00:02, 13.21it/s]Evaluating:  43%|████▎     | 27/63 [00:02<00:02, 13.27it/s]Evaluating:  46%|████▌     | 29/63 [00:02<00:02, 12.81it/s]Evaluating:  49%|████▉     | 31/63 [00:02<00:02, 12.99it/s]Evaluating:  52%|█████▏    | 33/63 [00:03<00:02, 13.12it/s]Evaluating:  56%|█████▌    | 35/63 [00:03<00:02, 13.21it/s]Evaluating:  59%|█████▊    | 37/63 [00:03<00:01, 13.27it/s]Evaluating:  62%|██████▏   | 39/63 [00:03<00:01, 13.33it/s]Evaluating:  65%|██████▌   | 41/63 [00:03<00:01, 13.36it/s]Evaluating:  68%|██████▊   | 43/63 [00:03<00:01, 13.35it/s]Evaluating:  71%|███████▏  | 45/63 [00:03<00:01, 13.38it/s]Evaluating:  75%|███████▍  | 47/63 [00:04<00:01, 13.39it/s]Evaluating:  78%|███████▊  | 49/63 [00:04<00:01, 13.40it/s]Evaluating:  81%|████████  | 51/63 [00:04<00:00, 13.39it/s]Evaluating:  84%|████████▍ | 53/63 [00:04<00:00, 13.29it/s]Evaluating:  87%|████████▋ | 55/63 [00:04<00:00, 13.29it/s]Evaluating:  90%|█████████ | 57/63 [00:04<00:00, 13.30it/s]Evaluating:  94%|█████████▎| 59/63 [00:04<00:00, 13.28it/s]Evaluating:  97%|█████████▋| 61/63 [00:05<00:00, 13.28it/s]Evaluating: 100%|██████████| 63/63 [00:05<00:00, 13.29it/s]Evaluating: 100%|██████████| 63/63 [00:05<00:00, 11.89it/s]
05/11/2022 17:53:28 - INFO - __main__ -     Evaluation done in total 5.299250 secs (0.010514 sec per example)
05/11/2022 17:53:30 - INFO - __main__ -   Results: {'exact': 73.54709418837675, 'f1': 81.68169912315754, 'total': 499, 'HasAns_exact': 73.54709418837675, 'HasAns_f1': 81.68169912315754, 'HasAns_total': 499, 'best_exact': 73.54709418837675, 'best_exact_thresh': 0.0, 'best_f1': 81.68169912315754, 'best_f1_thresh': 0.0}
  te 
05/11/2022 17:53:36 - WARNING - __main__ -   Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, 16-bits training: False
05/11/2022 17:53:38 - INFO - __main__ -   lang2id = None
05/11/2022 17:53:41 - INFO - __main__ -   Training/evaluation parameters Namespace(adam_epsilon=1e-08, cache_dir='', config_name='', data_dir=None, device=device(type='cuda'), do_eval=True, do_lower_case=False, do_train=False, doc_stride=128, eval_all_checkpoints=False, eval_lang='te', evaluate_during_training=False, fp16=False, fp16_opt_level='O1', gradient_accumulation_steps=1, learning_rate=5e-05, local_rank=-1, logging_steps=50, max_answer_length=30, max_grad_norm=1.0, max_query_length=64, max_seq_length=384, max_steps=-1, model_name_or_path='/cluster/home/meiliu/scratch/xtreme_mbert_3e5_4_8_tydiqa/outputs-org//tydiqa/_LR3e-5_EPOCH3.0_maxlen384_batchsize4_gradacc8', model_type='bert', n_best_size=20, n_gpu=1, no_cuda=False, null_score_diff_threshold=0.0, num_train_epochs=3.0, output_dir='/cluster/home/meiliu/scratch/xtreme_mbert_3e5_4_8_tydiqa/outputs-org//tydiqa/_LR3e-5_EPOCH3.0_maxlen384_batchsize4_gradacc8/predictions/tydiqa/', overwrite_cache=False, overwrite_output_dir=False, per_gpu_eval_batch_size=8, per_gpu_train_batch_size=8, predict_file='/cluster/home/meiliu/scratch/xtreme_mbert_3e5_4_8_tydiqa/download//tydiqa//tydiqa-goldp-v1.1-dev/tydiqa-goldp-dev-te.json', save_steps=50, seed=42, server_ip='', server_port='', threads=1, tokenizer_name='', train_file=None, train_lang='en', verbose_logging=False, version_2_with_negative=False, warmup_steps=0, weight_decay=0.0)
05/11/2022 17:53:41 - INFO - __main__ -   Loading checkpoint /cluster/home/meiliu/scratch/xtreme_mbert_3e5_4_8_tydiqa/outputs-org//tydiqa/_LR3e-5_EPOCH3.0_maxlen384_batchsize4_gradacc8 for evaluation
05/11/2022 17:53:41 - INFO - __main__ -   Evaluate the following checkpoints: ['/cluster/home/meiliu/scratch/xtreme_mbert_3e5_4_8_tydiqa/outputs-org//tydiqa/_LR3e-5_EPOCH3.0_maxlen384_batchsize4_gradacc8']
05/11/2022 17:53:43 - INFO - __main__ -   Creating features from dataset file at .
  0%|          | 0/669 [00:00<?, ?it/s] 76%|███████▌  | 509/669 [00:00<00:00, 5080.24it/s]100%|██████████| 669/669 [00:00<00:00, 5114.06it/s]
convert squad examples to features:   0%|          | 0/669 [00:00<?, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.
convert squad examples to features:   0%|          | 1/669 [00:00<03:29,  3.19it/s]convert squad examples to features:   5%|▍         | 33/669 [00:00<00:08, 71.38it/s]convert squad examples to features:  10%|▉         | 65/669 [00:00<00:05, 106.77it/s]convert squad examples to features:  14%|█▍        | 97/669 [00:01<00:06, 84.33it/s] convert squad examples to features:  19%|█▉        | 129/669 [00:01<00:04, 108.44it/s]convert squad examples to features:  24%|██▍       | 161/669 [00:01<00:03, 132.46it/s]convert squad examples to features:  29%|██▉       | 193/669 [00:01<00:03, 147.76it/s]convert squad examples to features:  34%|███▎      | 225/669 [00:01<00:02, 167.31it/s]convert squad examples to features:  38%|███▊      | 257/669 [00:02<00:02, 171.97it/s]convert squad examples to features:  43%|████▎     | 289/669 [00:02<00:02, 188.03it/s]convert squad examples to features:  48%|████▊     | 321/669 [00:02<00:01, 190.93it/s]convert squad examples to features:  53%|█████▎    | 353/669 [00:02<00:01, 208.99it/s]convert squad examples to features:  58%|█████▊    | 385/669 [00:02<00:01, 216.99it/s]convert squad examples to features:  62%|██████▏   | 417/669 [00:02<00:01, 189.38it/s]convert squad examples to features:  67%|██████▋   | 449/669 [00:02<00:01, 199.62it/s]convert squad examples to features:  72%|███████▏  | 481/669 [00:03<00:00, 191.16it/s]convert squad examples to features:  77%|███████▋  | 513/669 [00:03<00:00, 195.80it/s]convert squad examples to features:  81%|████████▏ | 545/669 [00:03<00:00, 199.45it/s]convert squad examples to features:  86%|████████▌ | 577/669 [00:03<00:00, 201.16it/s]convert squad examples to features:  91%|█████████ | 609/669 [00:03<00:00, 195.68it/s]convert squad examples to features:  96%|█████████▌| 641/669 [00:03<00:00, 211.95it/s]convert squad examples to features: 100%|██████████| 669/669 [00:03<00:00, 172.92it/s]/cluster/project/sachan/meizhen/env_anaconda/software/envs/xtreme_tmp/lib/python3.6/site-packages/transformers/tokenization_utils_base.py:2278: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  FutureWarning,

add example index and unique id:   0%|          | 0/669 [00:00<?, ?it/s]add example index and unique id: 100%|██████████| 669/669 [00:00<00:00, 382131.20it/s]
05/11/2022 17:53:47 - INFO - __main__ -   Saving features into cached file ./cached_tydiqa-goldp-dev-te.json__LR3e-5_EPOCH3.0_maxlen384_batchsize4_gradacc8_384_te
05/11/2022 17:53:48 - INFO - __main__ -   ***** Running evaluation  *****
05/11/2022 17:53:48 - INFO - __main__ -     Num examples = 828
05/11/2022 17:53:48 - INFO - __main__ -     Batch size = 8
Evaluating:   0%|          | 0/104 [00:00<?, ?it/s]Evaluating:   1%|          | 1/104 [00:00<01:10,  1.46it/s]Evaluating:   3%|▎         | 3/104 [00:00<00:24,  4.18it/s]Evaluating:   5%|▍         | 5/104 [00:01<00:15,  6.46it/s]Evaluating:   7%|▋         | 7/104 [00:01<00:11,  8.28it/s]Evaluating:   9%|▊         | 9/104 [00:01<00:09,  9.69it/s]Evaluating:  11%|█         | 11/104 [00:01<00:08, 10.73it/s]Evaluating:  12%|█▎        | 13/104 [00:01<00:07, 11.49it/s]Evaluating:  14%|█▍        | 15/104 [00:01<00:07, 12.05it/s]Evaluating:  16%|█▋        | 17/104 [00:01<00:06, 12.45it/s]Evaluating:  18%|█▊        | 19/104 [00:02<00:06, 12.73it/s]Evaluating:  20%|██        | 21/104 [00:02<00:06, 12.91it/s]Evaluating:  22%|██▏       | 23/104 [00:02<00:06, 13.06it/s]Evaluating:  24%|██▍       | 25/104 [00:02<00:05, 13.17it/s]Evaluating:  26%|██▌       | 27/104 [00:02<00:05, 13.25it/s]Evaluating:  28%|██▊       | 29/104 [00:02<00:05, 13.24it/s]Evaluating:  30%|██▉       | 31/104 [00:02<00:05, 13.30it/s]Evaluating:  32%|███▏      | 33/104 [00:03<00:05, 13.34it/s]Evaluating:  34%|███▎      | 35/104 [00:03<00:05, 13.36it/s]Evaluating:  36%|███▌      | 37/104 [00:03<00:05, 13.37it/s]Evaluating:  38%|███▊      | 39/104 [00:03<00:04, 13.38it/s]Evaluating:  39%|███▉      | 41/104 [00:03<00:04, 13.39it/s]Evaluating:  41%|████▏     | 43/104 [00:03<00:04, 13.38it/s]Evaluating:  43%|████▎     | 45/104 [00:03<00:04, 13.39it/s]Evaluating:  45%|████▌     | 47/104 [00:04<00:04, 13.37it/s]Evaluating:  47%|████▋     | 49/104 [00:04<00:04, 13.38it/s]Evaluating:  49%|████▉     | 51/104 [00:04<00:03, 13.39it/s]Evaluating:  51%|█████     | 53/104 [00:04<00:03, 13.40it/s]Evaluating:  53%|█████▎    | 55/104 [00:04<00:03, 13.32it/s]Evaluating:  55%|█████▍    | 57/104 [00:04<00:03, 13.34it/s]Evaluating:  57%|█████▋    | 59/104 [00:05<00:03, 13.35it/s]Evaluating:  59%|█████▊    | 61/104 [00:05<00:03, 13.35it/s]Evaluating:  61%|██████    | 63/104 [00:05<00:03, 13.32it/s]Evaluating:  62%|██████▎   | 65/104 [00:05<00:02, 13.21it/s]Evaluating:  64%|██████▍   | 67/104 [00:05<00:02, 13.20it/s]Evaluating:  66%|██████▋   | 69/104 [00:05<00:02, 13.21it/s]Evaluating:  68%|██████▊   | 71/104 [00:05<00:02, 13.21it/s]Evaluating:  70%|███████   | 73/104 [00:06<00:02, 13.19it/s]Evaluating:  72%|███████▏  | 75/104 [00:06<00:02, 13.21it/s]Evaluating:  74%|███████▍  | 77/104 [00:06<00:02, 13.25it/s]Evaluating:  76%|███████▌  | 79/104 [00:06<00:01, 13.28it/s]Evaluating:  78%|███████▊  | 81/104 [00:06<00:01, 13.29it/s]Evaluating:  80%|███████▉  | 83/104 [00:06<00:01, 13.28it/s]Evaluating:  82%|████████▏ | 85/104 [00:07<00:01, 13.25it/s]Evaluating:  84%|████████▎ | 87/104 [00:07<00:01, 13.25it/s]Evaluating:  86%|████████▌ | 89/104 [00:07<00:01, 12.61it/s]Evaluating:  88%|████████▊ | 91/104 [00:07<00:01, 12.81it/s]Evaluating:  89%|████████▉ | 93/104 [00:07<00:00, 12.98it/s]Evaluating:  91%|█████████▏| 95/104 [00:07<00:00, 13.10it/s]Evaluating:  93%|█████████▎| 97/104 [00:07<00:00, 13.18it/s]Evaluating:  95%|█████████▌| 99/104 [00:08<00:00, 13.23it/s]Evaluating:  97%|█████████▋| 101/104 [00:08<00:00, 13.17it/s]Evaluating:  99%|█████████▉| 103/104 [00:08<00:00, 10.87it/s]Evaluating: 100%|██████████| 104/104 [00:08<00:00, 12.19it/s]
05/11/2022 17:53:57 - INFO - __main__ -     Evaluation done in total 8.530264 secs (0.010302 sec per example)
05/11/2022 17:53:59 - INFO - __main__ -   Results: {'exact': 69.80568011958147, 'f1': 83.49799096435869, 'total': 669, 'HasAns_exact': 69.80568011958147, 'HasAns_f1': 83.49799096435869, 'HasAns_total': 669, 'best_exact': 69.80568011958147, 'best_exact_thresh': 0.0, 'best_f1': 83.49799096435869, 'best_f1_thresh': 0.0}
